Running MNB with seed 1
Running MNB with seed 2
Running MNB with seed 3
Running MNB with seed 4
Running MNB with seed 5
Running MNB with seed 6
Running MNB with seed 7
Running MNB with seed 8
Running MNB with seed 9
Running MNB with seed 10
Running MNB with seed 11
Running MNB with seed 12
Running MNB with seed 13
Running MNB with seed 14
Running MNB with seed 15
Running MNB with seed 16
Running MNB with seed 17
Running MNB with seed 18
Running MNB with seed 19
Running MNB with seed 20
Running MNB with seed 21
Running MNB with seed 22
Running MNB with seed 23
Running MNB with seed 24
Running MNB with seed 25
Running MNB with seed 26
Running MNB with seed 27
Running MNB with seed 28
Running MNB with seed 29
Running MNB with seed 30
Running MNB with seed 31
Running MNB with seed 32
Running MNB with seed 33
Running MNB with seed 34
Running MNB with seed 35
Running MNB with seed 36
Running MNB with seed 37
Running MNB with seed 38
Running MNB with seed 39
Running MNB with seed 40
Running MNB with seed 41
Running MNB with seed 42
Running MNB with seed 43
Running MNB with seed 44
Running MNB with seed 45
Running MNB with seed 46
Running MNB with seed 47
Running MNB with seed 48
Running MNB with seed 49
Running MNB with seed 50
Running MNB with seed 51
Running MNB with seed 52
Running MNB with seed 53
Running MNB with seed 54
Running MNB with seed 55
Running MNB with seed 56
Running MNB with seed 57
Running MNB with seed 58
Running MNB with seed 59
Running MNB with seed 60
Running MNB with seed 61
Running MNB with seed 62
Running MNB with seed 63
Running MNB with seed 64
Running MNB with seed 65
Running MNB with seed 66
Running MNB with seed 67
Running MNB with seed 68
Running MNB with seed 69
Running MNB with seed 70
Running MNB with seed 71
Running MNB with seed 72
Running MNB with seed 73
Running MNB with seed 74
Running MNB with seed 75
Running MNB with seed 76
Running MNB with seed 77
Running MNB with seed 78
Running MNB with seed 79
Running MNB with seed 80
Running MNB with seed 81
Running MNB with seed 82
Running MNB with seed 83
Running MNB with seed 84
Running MNB with seed 85
Running MNB with seed 86
Running MNB with seed 87
Running MNB with seed 88
Running MNB with seed 89
Running MNB with seed 90
Running MNB with seed 91
Running MNB with seed 92
Running MNB with seed 93
Running MNB with seed 94
Running MNB with seed 95
Running MNB with seed 96
Running MNB with seed 97
Running MNB with seed 98
Running MNB with seed 99
Running MNB with seed 100
Running MNB with seed 1
Running MNB with seed 2
Running MNB with seed 3
Running MNB with seed 4
Running MNB with seed 5
Running MNB with seed 6
Running MNB with seed 7
Running MNB with seed 8
Running MNB with seed 9
Running MNB with seed 10
Running MNB with seed 11
Running MNB with seed 12
Running MNB with seed 13
Running MNB with seed 14
Running MNB with seed 15
Running MNB with seed 16
Running MNB with seed 17
Running MNB with seed 18
Running MNB with seed 19
Running MNB with seed 20
Running MNB with seed 21
Running MNB with seed 22
Running MNB with seed 23
Running MNB with seed 24
Running MNB with seed 25
Running MNB with seed 26
Running MNB with seed 27
Running MNB with seed 28
Running MNB with seed 29
Running MNB with seed 30
Running MNB with seed 31
Running MNB with seed 32
Running MNB with seed 33
Running MNB with seed 34
Running MNB with seed 35
Running MNB with seed 36
Running MNB with seed 37
Running MNB with seed 38
Running MNB with seed 39
Running MNB with seed 40
Running MNB with seed 41
Running MNB with seed 42
Running MNB with seed 43
Running MNB with seed 44
Running MNB with seed 45
Running MNB with seed 46
Running MNB with seed 47
Running MNB with seed 48
Running MNB with seed 49
Running MNB with seed 50
Running MNB with seed 51
Running MNB with seed 52
Running MNB with seed 53
Running MNB with seed 54
Running MNB with seed 55
Running MNB with seed 56
Running MNB with seed 57
Running MNB with seed 58
Running MNB with seed 59
Running MNB with seed 60
Running MNB with seed 61
Running MNB with seed 62
Running MNB with seed 63
Running MNB with seed 64
Running MNB with seed 65
Running MNB with seed 66
Running MNB with seed 67
Running MNB with seed 68
Running MNB with seed 69
Running MNB with seed 70
Running MNB with seed 71
Running MNB with seed 72
Running MNB with seed 73
Running MNB with seed 74
Running MNB with seed 75
Running MNB with seed 76
Running MNB with seed 77
Running MNB with seed 78
Running MNB with seed 79
Running MNB with seed 80
Running MNB with seed 81
Running MNB with seed 82
Running MNB with seed 83
Running MNB with seed 84
Running MNB with seed 85
Running MNB with seed 86
Running MNB with seed 87
Running MNB with seed 88
Running MNB with seed 89
Running MNB with seed 90
Running MNB with seed 91
Running MNB with seed 92
Running MNB with seed 93
Running MNB with seed 94
Running MNB with seed 95
Running MNB with seed 96
Running MNB with seed 97
Running MNB with seed 98
Running MNB with seed 99
Running MNB with seed 100
Running MNB with seed 1
Running MNB with seed 2
Running MNB with seed 3
Running MNB with seed 4
Running MNB with seed 5
Running MNB with seed 6
Running MNB with seed 7
Running MNB with seed 8
Running MNB with seed 9
Running MNB with seed 10
Running MNB with seed 11
Running MNB with seed 12
Running MNB with seed 13
Running MNB with seed 14
Running MNB with seed 15
Running MNB with seed 16
Running MNB with seed 17
Running MNB with seed 18
Running MNB with seed 19
Running MNB with seed 20
Running MNB with seed 21
Running MNB with seed 22
Running MNB with seed 23
Running MNB with seed 24
Running MNB with seed 25
Running MNB with seed 26
Running MNB with seed 27
Running MNB with seed 28
Running MNB with seed 29
Running MNB with seed 30
Running MNB with seed 31
Running MNB with seed 32
Running MNB with seed 33
Running MNB with seed 34
Running MNB with seed 35
Running MNB with seed 36
Running MNB with seed 37
Running MNB with seed 38
Running MNB with seed 39
Running MNB with seed 40
Running MNB with seed 41
Running MNB with seed 42
Running MNB with seed 43
Running MNB with seed 44
Running MNB with seed 45
Running MNB with seed 46
Running MNB with seed 47
Running MNB with seed 48
Running MNB with seed 49
Running MNB with seed 50
Running MNB with seed 51
Running MNB with seed 52
Running MNB with seed 53
Running MNB with seed 54
Running MNB with seed 55
Running MNB with seed 56
Running MNB with seed 57
Running MNB with seed 58
Running MNB with seed 59
Running MNB with seed 60
Running MNB with seed 61
Running MNB with seed 62
Running MNB with seed 63
Running MNB with seed 64
Running MNB with seed 65
Running MNB with seed 66
Running MNB with seed 67
Running MNB with seed 68
Running MNB with seed 69
Running MNB with seed 70
Running MNB with seed 71
Running MNB with seed 72
Running MNB with seed 73
Running MNB with seed 74
Running MNB with seed 75
Running MNB with seed 76
Running MNB with seed 77
Running MNB with seed 78
Running MNB with seed 79
Running MNB with seed 80
Running MNB with seed 81
Running MNB with seed 82
Running MNB with seed 83
Running MNB with seed 84
Running MNB with seed 85
Running MNB with seed 86
Running MNB with seed 87
Running MNB with seed 88
Running MNB with seed 89
Running MNB with seed 90
Running MNB with seed 91
Running MNB with seed 92
Running MNB with seed 93
Running MNB with seed 94
Running MNB with seed 95
Running MNB with seed 96
Running MNB with seed 97
Running MNB with seed 98
Running MNB with seed 99
Running MNB with seed 100
Running MNB with seed 1
Running MNB with seed 2
Running MNB with seed 3
Running MNB with seed 4
Running MNB with seed 5
Running MNB with seed 6
Running MNB with seed 7
Running MNB with seed 8
Running MNB with seed 9
Running MNB with seed 10
Running MNB with seed 11
Running MNB with seed 12
Running MNB with seed 13
Running MNB with seed 14
Running MNB with seed 15
Running MNB with seed 16
Running MNB with seed 17
Running MNB with seed 18
Running MNB with seed 19
Running MNB with seed 20
Running MNB with seed 21
Running MNB with seed 22
Running MNB with seed 23
Running MNB with seed 24
Running MNB with seed 25
Running MNB with seed 26
Running MNB with seed 27
Running MNB with seed 28
Running MNB with seed 29
Running MNB with seed 30
Running MNB with seed 31
Running MNB with seed 32
Running MNB with seed 33
Running MNB with seed 34
Running MNB with seed 35
Running MNB with seed 36
Running MNB with seed 37
Running MNB with seed 38
Running MNB with seed 39
Running MNB with seed 40
Running MNB with seed 41
Running MNB with seed 42
Running MNB with seed 43
Running MNB with seed 44
Running MNB with seed 45
Running MNB with seed 46
Running MNB with seed 47
Running MNB with seed 48
Running MNB with seed 49
Running MNB with seed 50
Running MNB with seed 51
Running MNB with seed 52
Running MNB with seed 53
Running MNB with seed 54
Running MNB with seed 55
Running MNB with seed 56
Running MNB with seed 57
Running MNB with seed 58
Running MNB with seed 59
Running MNB with seed 60
Running MNB with seed 61
Running MNB with seed 62
Running MNB with seed 63
Running MNB with seed 64
Running MNB with seed 65
Running MNB with seed 66
Running MNB with seed 67
Running MNB with seed 68
Running MNB with seed 69
Running MNB with seed 70
Running MNB with seed 71
Running MNB with seed 72
Running MNB with seed 73
Running MNB with seed 74
Running MNB with seed 75
Running MNB with seed 76
Running MNB with seed 77
Running MNB with seed 78
Running MNB with seed 79
Running MNB with seed 80
Running MNB with seed 81
Running MNB with seed 82
Running MNB with seed 83
Running MNB with seed 84
Running MNB with seed 85
Running MNB with seed 86
Running MNB with seed 87
Running MNB with seed 88
Running MNB with seed 89
Running MNB with seed 90
Running MNB with seed 91
Running MNB with seed 92
Running MNB with seed 93
Running MNB with seed 94
Running MNB with seed 95
Running MNB with seed 96
Running MNB with seed 97
Running MNB with seed 98
Running MNB with seed 99
Running MNB with seed 100
Running MNB with seed 1
Running MNB with seed 2
Running MNB with seed 3
Running MNB with seed 4
Running MNB with seed 5
Running MNB with seed 6
Running MNB with seed 7
Running MNB with seed 8
Running MNB with seed 9
Running MNB with seed 10
Running MNB with seed 11
Running MNB with seed 12
Running MNB with seed 13
Running MNB with seed 14
Running MNB with seed 15
Running MNB with seed 16
Running MNB with seed 17
Running MNB with seed 18
Running MNB with seed 19
Running MNB with seed 20
Running MNB with seed 21
Running MNB with seed 22
Running MNB with seed 23
Running MNB with seed 24
Running MNB with seed 25
Running MNB with seed 26
Running MNB with seed 27
Running MNB with seed 28
Running MNB with seed 29
Running MNB with seed 30
Running MNB with seed 31
Running MNB with seed 32
Running MNB with seed 33
Running MNB with seed 34
Running MNB with seed 35
Running MNB with seed 36
Running MNB with seed 37
Running MNB with seed 38
Running MNB with seed 39
Running MNB with seed 40
Running MNB with seed 41
Running MNB with seed 42
Running MNB with seed 43
Running MNB with seed 44
Running MNB with seed 45
Running MNB with seed 46
Running MNB with seed 47
Running MNB with seed 48
Running MNB with seed 49
Running MNB with seed 50
Running MNB with seed 51
Running MNB with seed 52
Running MNB with seed 53
Running MNB with seed 54
Running MNB with seed 55
Running MNB with seed 56
Running MNB with seed 57
Running MNB with seed 58
Running MNB with seed 59
Running MNB with seed 60
Running MNB with seed 61
Running MNB with seed 62
Running MNB with seed 63
Running MNB with seed 64
Running MNB with seed 65
Running MNB with seed 66
Running MNB with seed 67
Running MNB with seed 68
Running MNB with seed 69
Running MNB with seed 70
Running MNB with seed 71
Running MNB with seed 72
Running MNB with seed 73
Running MNB with seed 74
Running MNB with seed 75
Running MNB with seed 76
Running MNB with seed 77
Running MNB with seed 78
Running MNB with seed 79
Running MNB with seed 80
Running MNB with seed 81
Running MNB with seed 82
Running MNB with seed 83
Running MNB with seed 84
Running MNB with seed 85
Running MNB with seed 86
Running MNB with seed 87
Running MNB with seed 88
Running MNB with seed 89
Running MNB with seed 90
Running MNB with seed 91
Running MNB with seed 92
Running MNB with seed 93
Running MNB with seed 94
Running MNB with seed 95
Running MNB with seed 96
Running MNB with seed 97
Running MNB with seed 98
Running MNB with seed 99
Running MNB with seed 100
Running MNB with seed 1
Running MNB with seed 2
Running MNB with seed 3
Running MNB with seed 4
Running MNB with seed 5
Running MNB with seed 6
Running MNB with seed 7
Running MNB with seed 8
Running MNB with seed 9
Running MNB with seed 10
Running MNB with seed 11
Running MNB with seed 12
Running MNB with seed 13
Running MNB with seed 14
Running MNB with seed 15
Running MNB with seed 16
Running MNB with seed 17
Running MNB with seed 18
Running MNB with seed 19
Running MNB with seed 20
Running MNB with seed 21
Running MNB with seed 22
Running MNB with seed 23
Running MNB with seed 24
Running MNB with seed 25
Running MNB with seed 26
Running MNB with seed 27
Running MNB with seed 28
Running MNB with seed 29
Running MNB with seed 30
Running MNB with seed 31
Running MNB with seed 32
Running MNB with seed 33
Running MNB with seed 34
Running MNB with seed 35
Running MNB with seed 36
Running MNB with seed 37
Running MNB with seed 38
Running MNB with seed 39
Running MNB with seed 40
Running MNB with seed 41
Running MNB with seed 42
Running MNB with seed 43
Running MNB with seed 44
Running MNB with seed 45
Running MNB with seed 46
Running MNB with seed 47
Running MNB with seed 48
Running MNB with seed 49
Running MNB with seed 50
Running MNB with seed 51
Running MNB with seed 52
Running MNB with seed 53
Running MNB with seed 54
Running MNB with seed 55
Running MNB with seed 56
Running MNB with seed 57
Running MNB with seed 58
Running MNB with seed 59
Running MNB with seed 60
Running MNB with seed 61
Running MNB with seed 62
Running MNB with seed 63
Running MNB with seed 64
Running MNB with seed 65
Running MNB with seed 66
Running MNB with seed 67
Running MNB with seed 68
Running MNB with seed 69
Running MNB with seed 70
Running MNB with seed 71
Running MNB with seed 72
Running MNB with seed 73
Running MNB with seed 74
Running MNB with seed 75
Running MNB with seed 76
Running MNB with seed 77
Running MNB with seed 78
Running MNB with seed 79
Running MNB with seed 80
Running MNB with seed 81
Running MNB with seed 82
Running MNB with seed 83
Running MNB with seed 84
Running MNB with seed 85
Running MNB with seed 86
Running MNB with seed 87
Running MNB with seed 88
Running MNB with seed 89
Running MNB with seed 90
Running MNB with seed 91
Running MNB with seed 92
Running MNB with seed 93
Running MNB with seed 94
Running MNB with seed 95
Running MNB with seed 96
Running MNB with seed 97
Running MNB with seed 98
Running MNB with seed 99
Running MNB with seed 100
Running train_nn.py with seed 1
CUDA:False
Training samples count:  550
Training on 30 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1374, Training Loss: 0.1374, Initial Validation Loss: 0.1345, Validation Loss: 0.1345,V Acc: 0.2589, Top 70th Acc: 0.3544, Bottom 30th Acc: 0.0303
Fold [1/5] Epoch [10/100] Initial Loss: 0.1374, Training Loss: 0.0341, Initial Validation Loss: 0.1345, Validation Loss: 0.0434,V Acc: 0.7946, Top 70th Acc: 0.8987, Bottom 30th Acc: 0.5455
Fold [1/5] Epoch [20/100] Initial Loss: 0.1374, Training Loss: 0.0179, Initial Validation Loss: 0.1345, Validation Loss: 0.0360,V Acc: 0.8393, Top 70th Acc: 0.9241, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.9113924050632911
1 0 [array([0.45023918, 0.08449278, 0.02317935, 0.05781708, 0.38427162],
      dtype=float32)]
Fold [2/5] Epoch [0/100] Initial Loss: 0.1411, Training Loss: 0.1411, Initial Validation Loss: 0.1352, Validation Loss: 0.1352,V Acc: 0.3604, Top 70th Acc: 0.4103, Bottom 30th Acc: 0.2424
Fold [2/5] Epoch [10/100] Initial Loss: 0.1411, Training Loss: 0.0382, Initial Validation Loss: 0.1352, Validation Loss: 0.0423,V Acc: 0.7928, Top 70th Acc: 0.8718, Bottom 30th Acc: 0.6061
Fold [2/5] Epoch [20/100] Initial Loss: 0.1411, Training Loss: 0.0187, Initial Validation Loss: 0.1352, Validation Loss: 0.0317,V Acc: 0.8468, Top 70th Acc: 0.8974, Bottom 30th Acc: 0.7273
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.8846153846153846
Fold [3/5] Epoch [0/100] Initial Loss: 0.1425, Training Loss: 0.1425, Initial Validation Loss: 0.1347, Validation Loss: 0.1347,V Acc: 0.2636, Top 70th Acc: 0.3247, Bottom 30th Acc: 0.1212
Fold [3/5] Epoch [10/100] Initial Loss: 0.1425, Training Loss: 0.0258, Initial Validation Loss: 0.1347, Validation Loss: 0.0387,V Acc: 0.8000, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.4545
Fold [3/5] Epoch [20/100] Initial Loss: 0.1425, Training Loss: 0.0179, Initial Validation Loss: 0.1347, Validation Loss: 0.0347,V Acc: 0.8091, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.4545
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.948051948051948
Fold [4/5] Epoch [0/100] Initial Loss: 0.1374, Training Loss: 0.1374, Initial Validation Loss: 0.1295, Validation Loss: 0.1295,V Acc: 0.3394, Top 70th Acc: 0.3896, Bottom 30th Acc: 0.2188
Fold [4/5] Epoch [10/100] Initial Loss: 0.1374, Training Loss: 0.0353, Initial Validation Loss: 0.1295, Validation Loss: 0.0325,V Acc: 0.8257, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.5938
Fold [4/5] Epoch [20/100] Initial Loss: 0.1374, Training Loss: 0.0201, Initial Validation Loss: 0.1295, Validation Loss: 0.0256,V Acc: 0.8624, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.7188
Fold [4/5] Epoch [30/100] Initial Loss: 0.1374, Training Loss: 0.0173, Initial Validation Loss: 0.1295, Validation Loss: 0.0241,V Acc: 0.8807, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.7812
Fold [4/5] Epoch [40/100] Initial Loss: 0.1374, Training Loss: 0.0160, Initial Validation Loss: 0.1295, Validation Loss: 0.0232,V Acc: 0.8899, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.8125
Fold [4/5] Epoch [50/100] Initial Loss: 0.1374, Training Loss: 0.0149, Initial Validation Loss: 0.1295, Validation Loss: 0.0237,V Acc: 0.8807, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.7812
Stopping early at Epoch (base 0): 53  Rolling back to Epoch (base 0): 48  Top Validation Acc: 0.922077922077922
Fold [5/5] Epoch [0/100] Initial Loss: 0.1368, Training Loss: 0.1368, Initial Validation Loss: 0.1299, Validation Loss: 0.1299,V Acc: 0.3333, Top 70th Acc: 0.3289, Bottom 30th Acc: 0.3438
Fold [5/5] Epoch [10/100] Initial Loss: 0.1368, Training Loss: 0.0294, Initial Validation Loss: 0.1299, Validation Loss: 0.0381,V Acc: 0.8426, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.6250
Fold [5/5] Epoch [20/100] Initial Loss: 0.1368, Training Loss: 0.0180, Initial Validation Loss: 0.1299, Validation Loss: 0.0326,V Acc: 0.8426, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.5938
Stopping early at Epoch (base 0): 27  Rolling back to Epoch (base 0): 22  Top Validation Acc: 0.9473684210526315
Running train_nn.py with seed 2
CUDA:False
Training samples count:  550
Training on 30 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1404, Training Loss: 0.1404, Initial Validation Loss: 0.1347, Validation Loss: 0.1347,V Acc: 0.2500, Top 70th Acc: 0.2658, Bottom 30th Acc: 0.2121
Fold [1/5] Epoch [10/100] Initial Loss: 0.1404, Training Loss: 0.0390, Initial Validation Loss: 0.1347, Validation Loss: 0.0426,V Acc: 0.7857, Top 70th Acc: 0.9241, Bottom 30th Acc: 0.4545
Fold [1/5] Epoch [20/100] Initial Loss: 0.1404, Training Loss: 0.0182, Initial Validation Loss: 0.1347, Validation Loss: 0.0292,V Acc: 0.8571, Top 70th Acc: 0.9494, Bottom 30th Acc: 0.6364
Fold [1/5] Epoch [30/100] Initial Loss: 0.1404, Training Loss: 0.0148, Initial Validation Loss: 0.1347, Validation Loss: 0.0275,V Acc: 0.8571, Top 70th Acc: 0.9620, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 37  Rolling back to Epoch (base 0): 32  Top Validation Acc: 0.9367088607594937
2 0 [array([0.7628364 , 0.08205136, 0.01976954, 0.04539297, 0.0899498 ],
      dtype=float32)]
Fold [2/5] Epoch [0/100] Initial Loss: 0.1393, Training Loss: 0.1393, Initial Validation Loss: 0.1360, Validation Loss: 0.1360,V Acc: 0.3514, Top 70th Acc: 0.3590, Bottom 30th Acc: 0.3333
Fold [2/5] Epoch [10/100] Initial Loss: 0.1393, Training Loss: 0.0404, Initial Validation Loss: 0.1360, Validation Loss: 0.0424,V Acc: 0.8018, Top 70th Acc: 0.8718, Bottom 30th Acc: 0.6364
Fold [2/5] Epoch [20/100] Initial Loss: 0.1393, Training Loss: 0.0200, Initial Validation Loss: 0.1360, Validation Loss: 0.0310,V Acc: 0.8288, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.9358974358974359
Fold [3/5] Epoch [0/100] Initial Loss: 0.1383, Training Loss: 0.1383, Initial Validation Loss: 0.1344, Validation Loss: 0.1344,V Acc: 0.3000, Top 70th Acc: 0.3117, Bottom 30th Acc: 0.2727
Fold [3/5] Epoch [10/100] Initial Loss: 0.1383, Training Loss: 0.0306, Initial Validation Loss: 0.1344, Validation Loss: 0.0421,V Acc: 0.8091, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.5758
Fold [3/5] Epoch [20/100] Initial Loss: 0.1383, Training Loss: 0.0173, Initial Validation Loss: 0.1344, Validation Loss: 0.0368,V Acc: 0.7909, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.4848
Stopping early at Epoch (base 0): 21  Rolling back to Epoch (base 0): 16  Top Validation Acc: 0.922077922077922
Fold [4/5] Epoch [0/100] Initial Loss: 0.1447, Training Loss: 0.1447, Initial Validation Loss: 0.1339, Validation Loss: 0.1339,V Acc: 0.2477, Top 70th Acc: 0.3247, Bottom 30th Acc: 0.0625
Fold [4/5] Epoch [10/100] Initial Loss: 0.1447, Training Loss: 0.0276, Initial Validation Loss: 0.1339, Validation Loss: 0.0319,V Acc: 0.8349, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.5625
Fold [4/5] Epoch [20/100] Initial Loss: 0.1447, Training Loss: 0.0178, Initial Validation Loss: 0.1339, Validation Loss: 0.0284,V Acc: 0.8532, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.6562
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.961038961038961
Fold [5/5] Epoch [0/100] Initial Loss: 0.1393, Training Loss: 0.1393, Initial Validation Loss: 0.1332, Validation Loss: 0.1332,V Acc: 0.3056, Top 70th Acc: 0.3947, Bottom 30th Acc: 0.0938
Fold [5/5] Epoch [10/100] Initial Loss: 0.1393, Training Loss: 0.0320, Initial Validation Loss: 0.1332, Validation Loss: 0.0368,V Acc: 0.8519, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.6250
Fold [5/5] Epoch [20/100] Initial Loss: 0.1393, Training Loss: 0.0174, Initial Validation Loss: 0.1332, Validation Loss: 0.0299,V Acc: 0.8611, Top 70th Acc: 0.9868, Bottom 30th Acc: 0.5625
Stopping early at Epoch (base 0): 28  Rolling back to Epoch (base 0): 23  Top Validation Acc: 0.9736842105263158
Running train_nn.py with seed 3
CUDA:False
Training samples count:  550
Training on 30 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1391, Training Loss: 0.1391, Initial Validation Loss: 0.1350, Validation Loss: 0.1350,V Acc: 0.2500, Top 70th Acc: 0.2911, Bottom 30th Acc: 0.1515Running train_nn.py with seed 1
CUDA:False
Training samples count:  550
Training on 21 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1316, Training Loss: 0.1316, Initial Validation Loss: 0.1180, Validation Loss: 0.1180,V Acc: 0.4911, Top 70th Acc: 0.6203, Bottom 30th Acc: 0.1818
Fold [1/5] Epoch [10/100] Initial Loss: 0.1316, Training Loss: 0.0228, Initial Validation Loss: 0.1180, Validation Loss: 0.0258,V Acc: 0.8839, Top 70th Acc: 1.0000, Bottom 30th Acc: 0.6061
Fold [1/5] Epoch [20/100] Initial Loss: 0.1316, Training Loss: 0.0166, Initial Validation Loss: 0.1180, Validation Loss: 0.0275,V Acc: 0.8839, Top 70th Acc: 0.9747, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.9746835443037974
1 0 [array([0.76476103, 0.0324834 , 0.015157  , 0.08565501, 0.10194353],
      dtype=float32)]
Fold [2/5] Epoch [0/100] Initial Loss: 0.1332, Training Loss: 0.1332, Initial Validation Loss: 0.1189, Validation Loss: 0.1189,V Acc: 0.4685, Top 70th Acc: 0.5256, Bottom 30th Acc: 0.3333
Fold [2/5] Epoch [10/100] Initial Loss: 0.1332, Training Loss: 0.0209, Initial Validation Loss: 0.1189, Validation Loss: 0.0256,V Acc: 0.8559, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 17  Rolling back to Epoch (base 0): 12  Top Validation Acc: 0.9615384615384616
Fold [3/5] Epoch [0/100] Initial Loss: 0.1273, Training Loss: 0.1273, Initial Validation Loss: 0.1140, Validation Loss: 0.1140,V Acc: 0.4545, Top 70th Acc: 0.5455, Bottom 30th Acc: 0.2424
Fold [3/5] Epoch [10/100] Initial Loss: 0.1273, Training Loss: 0.0201, Initial Validation Loss: 0.1140, Validation Loss: 0.0414,V Acc: 0.8000, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.5152
Stopping early at Epoch (base 0): 19  Rolling back to Epoch (base 0): 14  Top Validation Acc: 0.961038961038961
Fold [4/5] Epoch [0/100] Initial Loss: 0.1340, Training Loss: 0.1340, Initial Validation Loss: 0.1177, Validation Loss: 0.1177,V Acc: 0.4312, Top 70th Acc: 0.5844, Bottom 30th Acc: 0.0625
Fold [4/5] Epoch [10/100] Initial Loss: 0.1340, Training Loss: 0.0223, Initial Validation Loss: 0.1177, Validation Loss: 0.0262,V Acc: 0.8716, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6875
Fold [4/5] Epoch [20/100] Initial Loss: 0.1340, Training Loss: 0.0178, Initial Validation Loss: 0.1177, Validation Loss: 0.0172,V Acc: 0.9174, Top 70th Acc: 0.9870, Bottom 30th Acc: 0.7500
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.974025974025974
Fold [5/5] Epoch [0/100] Initial Loss: 0.1317, Training Loss: 0.1317, Initial Validation Loss: 0.1164, Validation Loss: 0.1164,V Acc: 0.5093, Top 70th Acc: 0.6447, Bottom 30th Acc: 0.1875
Fold [5/5] Epoch [10/100] Initial Loss: 0.1317, Training Loss: 0.0226, Initial Validation Loss: 0.1164, Validation Loss: 0.0215,V Acc: 0.9167, Top 70th Acc: 0.9868, Bottom 30th Acc: 0.7500
Fold [5/5] Epoch [20/100] Initial Loss: 0.1317, Training Loss: 0.0161, Initial Validation Loss: 0.1164, Validation Loss: 0.0194,V Acc: 0.9074, Top 70th Acc: 0.9737, Bottom 30th Acc: 0.7500
Stopping early at Epoch (base 0): 20  Rolling back to Epoch (base 0): 15  Top Validation Acc: 0.9736842105263158
Running train_nn.py with seed 2
CUDA:False
Training samples count:  550
Training on 21 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1311, Training Loss: 0.1311, Initial Validation Loss: 0.1190, Validation Loss: 0.1190,V Acc: 0.4196, Top 70th Acc: 0.5190, Bottom 30th Acc: 0.1818
Fold [1/5] Epoch [10/100] Initial Loss: 0.1311, Training Loss: 0.0248, Initial Validation Loss: 0.1190, Validation Loss: 0.0321,V Acc: 0.8661, Top 70th Acc: 0.9747, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 16  Rolling back to Epoch (base 0): 11  Top Validation Acc: 0.9620253164556962
2 0 [array([0.7434311 , 0.04803066, 0.03462602, 0.12477621, 0.04913601],
      dtype=float32)]
Fold [2/5] Epoch [0/100] Initial Loss: 0.1363, Training Loss: 0.1363, Initial Validation Loss: 0.1320, Validation Loss: 0.1320,V Acc: 0.2973, Top 70th Acc: 0.3462, Bottom 30th Acc: 0.1818
Fold [2/5] Epoch [10/100] Initial Loss: 0.1363, Training Loss: 0.0255, Initial Validation Loss: 0.1320, Validation Loss: 0.0268,V Acc: 0.8559, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.6061
Fold [2/5] Epoch [20/100] Initial Loss: 0.1363, Training Loss: 0.0175, Initial Validation Loss: 0.1320, Validation Loss: 0.0184,V Acc: 0.9099, Top 70th Acc: 0.9872, Bottom 30th Acc: 0.7273
Stopping early at Epoch (base 0): 28  Rolling back to Epoch (base 0): 23  Top Validation Acc: 0.9487179487179487
Fold [3/5] Epoch [0/100] Initial Loss: 0.1304, Training Loss: 0.1304, Initial Validation Loss: 0.1117, Validation Loss: 0.1117,V Acc: 0.4818, Top 70th Acc: 0.6234, Bottom 30th Acc: 0.1515
Fold [3/5] Epoch [10/100] Initial Loss: 0.1304, Training Loss: 0.0201, Initial Validation Loss: 0.1117, Validation Loss: 0.0361,V Acc: 0.8182, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 14  Rolling back to Epoch (base 0): 9  Top Validation Acc: 0.922077922077922
Fold [4/5] Epoch [0/100] Initial Loss: 0.1327, Training Loss: 0.1327, Initial Validation Loss: 0.1142, Validation Loss: 0.1142,V Acc: 0.5780, Top 70th Acc: 0.7143, Bottom 30th Acc: 0.2500
Fold [4/5] Epoch [10/100] Initial Loss: 0.1327, Training Loss: 0.0232, Initial Validation Loss: 0.1142, Validation Loss: 0.0234,V Acc: 0.9083, Top 70th Acc: 0.9870, Bottom 30th Acc: 0.7188
Fold [4/5] Epoch [20/100] Initial Loss: 0.1327, Training Loss: 0.0154, Initial Validation Loss: 0.1142, Validation Loss: 0.0145,V Acc: 0.9358, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.8438
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.974025974025974
Fold [5/5] Epoch [0/100] Initial Loss: 0.1273, Training Loss: 0.1273, Initial Validation Loss: 0.1123, Validation Loss: 0.1123,V Acc: 0.4444, Top 70th Acc: 0.5395, Bottom 30th Acc: 0.2188
Fold [5/5] Epoch [10/100] Initial Loss: 0.1273, Training Loss: 0.0210, Initial Validation Loss: 0.1123, Validation Loss: 0.0358,V Acc: 0.8241, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.5625
Fold [5/5] Epoch [20/100] Initial Loss: 0.1273, Training Loss: 0.0150, Initial Validation Loss: 0.1123, Validation Loss: 0.0282,V Acc: 0.8796, Top 70th Acc: 0.9737, Bottom 30th Acc: 0.6562
Stopping early at Epoch (base 0): 27  Rolling back to Epoch (base 0): 22  Top Validation Acc: 0.9605263157894737
Running train_nn.py with seed 3
CUDA:False
Training samples count:  550
Training on 21 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1327, Training Loss: 0.1327, Initial Validation Loss: 0.1194, Validation Loss: 0.1194,V Acc: 0.4375, Top 70th Acc: 0.5823, Bottom 30th Acc: 0.0909
Fold [1/5] Epoch [10/100] Initial Loss: 0.1327, Training Loss: 0.0242, Initial Validation Loss: 0.1194, Validation Loss: 0.0271,V Acc: 0.8750, Top 70th Acc: 0.9747, Bottom 30th Acc: 0.6364
Fold [1/5] Epoch [20/100] Initial Loss: 0.1327, Training Loss: 0.0162, Initial Validation Loss: 0.1194, Validation Loss: 0.0212,V Acc: 0.8750, Top 70th Acc: 0.9494, Bottom 30th Acc: 0.6970
Fold [1/5] Epoch [30/100] Initial Loss: 0.1327, Training Loss: 0.0141, Initial Validation Loss: 0.1194, Validation Loss: 0.0189,V Acc: 0.8929, Top 70th Acc: 0.9747, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 38  Rolling back to Epoch (base 0): 33  Top Validation Acc: 0.9620253164556962
Fold [2/5] Epoch [0/100] Initial Loss: 0.1289, Training Loss: 0.1289, Initial Validation Loss: 0.1163, Validation Loss: 0.1163,V Acc: 0.5135, Top 70th Acc: 0.6410, Bottom 30th Acc: 0.2121
Fold [2/5] Epoch [10/100] Initial Loss: 0.1289, Training Loss: 0.0265, Initial Validation Loss: 0.1163, Validation Loss: 0.0345,V Acc: 0.8559, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 16  Rolling back to Epoch (base 0): 11  Top Validation Acc: 0.9358974358974359
3 1 [array([0.6626476 , 0.01175006, 0.11198866, 0.15420333, 0.05941034],
      dtype=float32)]
Fold [3/5] Epoch [0/100] Initial Loss: 0.1334, Training Loss: 0.1334, Initial Validation Loss: 0.1210, Validation Loss: 0.1210,V Acc: 0.5091, Top 70th Acc: 0.6104, Bottom 30th Acc: 0.2727
Fold [3/5] Epoch [10/100] Initial Loss: 0.1334, Training Loss: 0.0244, Initial Validation Loss: 0.1210, Validation Loss: 0.0260,V Acc: 0.8636, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.6061Running train_nn.py with seed 1
CUDA:False
Training samples count:  550
Training on 40 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1386, Training Loss: 0.1386, Initial Validation Loss: 0.1332, Validation Loss: 0.1332,V Acc: 0.3214, Top 70th Acc: 0.4177, Bottom 30th Acc: 0.0909
Fold [1/5] Epoch [10/100] Initial Loss: 0.1386, Training Loss: 0.0353, Initial Validation Loss: 0.1332, Validation Loss: 0.0463,V Acc: 0.7589, Top 70th Acc: 0.8861, Bottom 30th Acc: 0.4545
Fold [1/5] Epoch [20/100] Initial Loss: 0.1386, Training Loss: 0.0137, Initial Validation Loss: 0.1332, Validation Loss: 0.0323,V Acc: 0.8393, Top 70th Acc: 0.9367, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.9367088607594937
1 0 [array([0.4996328 , 0.06527335, 0.05783112, 0.11858921, 0.25867355],
      dtype=float32)]
Fold [2/5] Epoch [0/100] Initial Loss: 0.1398, Training Loss: 0.1398, Initial Validation Loss: 0.1332, Validation Loss: 0.1332,V Acc: 0.3964, Top 70th Acc: 0.4487, Bottom 30th Acc: 0.2727
Fold [2/5] Epoch [10/100] Initial Loss: 0.1398, Training Loss: 0.0249, Initial Validation Loss: 0.1332, Validation Loss: 0.0339,V Acc: 0.8288, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.6061
Fold [2/5] Epoch [20/100] Initial Loss: 0.1398, Training Loss: 0.0131, Initial Validation Loss: 0.1332, Validation Loss: 0.0287,V Acc: 0.8559, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 22  Rolling back to Epoch (base 0): 17  Top Validation Acc: 0.9358974358974359
Fold [3/5] Epoch [0/100] Initial Loss: 0.1381, Training Loss: 0.1381, Initial Validation Loss: 0.1351, Validation Loss: 0.1351,V Acc: 0.3273, Top 70th Acc: 0.3636, Bottom 30th Acc: 0.2424
Fold [3/5] Epoch [10/100] Initial Loss: 0.1381, Training Loss: 0.0313, Initial Validation Loss: 0.1351, Validation Loss: 0.0482,V Acc: 0.7545, Top 70th Acc: 0.8831, Bottom 30th Acc: 0.4545
Fold [3/5] Epoch [20/100] Initial Loss: 0.1381, Training Loss: 0.0154, Initial Validation Loss: 0.1351, Validation Loss: 0.0392,V Acc: 0.8455, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.6970
Fold [3/5] Epoch [30/100] Initial Loss: 0.1381, Training Loss: 0.0112, Initial Validation Loss: 0.1351, Validation Loss: 0.0353,V Acc: 0.8455, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.6364
Fold [3/5] Epoch [40/100] Initial Loss: 0.1381, Training Loss: 0.0100, Initial Validation Loss: 0.1351, Validation Loss: 0.0337,V Acc: 0.8818, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.7273
Stopping early at Epoch (base 0): 48  Rolling back to Epoch (base 0): 43  Top Validation Acc: 0.961038961038961
Fold [4/5] Epoch [0/100] Initial Loss: 0.1401, Training Loss: 0.1401, Initial Validation Loss: 0.1323, Validation Loss: 0.1323,V Acc: 0.2569, Top 70th Acc: 0.2597, Bottom 30th Acc: 0.2500
Fold [4/5] Epoch [10/100] Initial Loss: 0.1401, Training Loss: 0.0336, Initial Validation Loss: 0.1323, Validation Loss: 0.0350,V Acc: 0.8257, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.5938
Fold [4/5] Epoch [20/100] Initial Loss: 0.1401, Training Loss: 0.0146, Initial Validation Loss: 0.1323, Validation Loss: 0.0277,V Acc: 0.8716, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6875
Stopping early at Epoch (base 0): 21  Rolling back to Epoch (base 0): 16  Top Validation Acc: 0.948051948051948
Fold [5/5] Epoch [0/100] Initial Loss: 0.1386, Training Loss: 0.1386, Initial Validation Loss: 0.1308, Validation Loss: 0.1308,V Acc: 0.2593, Top 70th Acc: 0.3026, Bottom 30th Acc: 0.1562
Fold [5/5] Epoch [10/100] Initial Loss: 0.1386, Training Loss: 0.0306, Initial Validation Loss: 0.1308, Validation Loss: 0.0360,V Acc: 0.8519, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.5938
Fold [5/5] Epoch [20/100] Initial Loss: 0.1386, Training Loss: 0.0142, Initial Validation Loss: 0.1308, Validation Loss: 0.0304,V Acc: 0.8241, Top 70th Acc: 0.9737, Bottom 30th Acc: 0.4688
Stopping early at Epoch (base 0): 22  Rolling back to Epoch (base 0): 17  Top Validation Acc: 0.9736842105263158
Running train_nn.py with seed 2
CUDA:False
Training samples count:  550
Training on 40 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1425, Training Loss: 0.1425, Initial Validation Loss: 0.1335, Validation Loss: 0.1335,V Acc: 0.2500, Top 70th Acc: 0.3038, Bottom 30th Acc: 0.1212
Fold [1/5] Epoch [10/100] Initial Loss: 0.1425, Training Loss: 0.0312, Initial Validation Loss: 0.1335, Validation Loss: 0.0408,V Acc: 0.7946, Top 70th Acc: 0.9114, Bottom 30th Acc: 0.5152
Fold [1/5] Epoch [20/100] Initial Loss: 0.1425, Training Loss: 0.0139, Initial Validation Loss: 0.1335, Validation Loss: 0.0317,V Acc: 0.8393, Top 70th Acc: 0.9494, Bottom 30th Acc: 0.5758
Fold [1/5] Epoch [30/100] Initial Loss: 0.1425, Training Loss: 0.0111, Initial Validation Loss: 0.1335, Validation Loss: 0.0292,V Acc: 0.8571, Top 70th Acc: 0.9747, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 39  Rolling back to Epoch (base 0): 34  Top Validation Acc: 0.9620253164556962
2 0 [array([0.36922327, 0.09380368, 0.06413726, 0.0707254 , 0.40211043],
      dtype=float32)]
Fold [2/5] Epoch [0/100] Initial Loss: 0.1363, Training Loss: 0.1363, Initial Validation Loss: 0.1324, Validation Loss: 0.1324,V Acc: 0.3874, Top 70th Acc: 0.4359, Bottom 30th Acc: 0.2727
Fold [2/5] Epoch [10/100] Initial Loss: 0.1363, Training Loss: 0.0365, Initial Validation Loss: 0.1324, Validation Loss: 0.0423,V Acc: 0.7838, Top 70th Acc: 0.8974, Bottom 30th Acc: 0.5152
Fold [2/5] Epoch [20/100] Initial Loss: 0.1363, Training Loss: 0.0166, Initial Validation Loss: 0.1324, Validation Loss: 0.0326,V Acc: 0.8288, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.9230769230769231
Fold [3/5] Epoch [0/100] Initial Loss: 0.1441, Training Loss: 0.1441, Initial Validation Loss: 0.1369, Validation Loss: 0.1369,V Acc: 0.2545, Top 70th Acc: 0.3117, Bottom 30th Acc: 0.1212
Fold [3/5] Epoch [10/100] Initial Loss: 0.1441, Training Loss: 0.0381, Initial Validation Loss: 0.1369, Validation Loss: 0.0502,V Acc: 0.7636, Top 70th Acc: 0.8571, Bottom 30th Acc: 0.5455
Fold [3/5] Epoch [20/100] Initial Loss: 0.1441, Training Loss: 0.0136, Initial Validation Loss: 0.1369, Validation Loss: 0.0339,V Acc: 0.8182, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 22  Rolling back to Epoch (base 0): 17  Top Validation Acc: 0.922077922077922
Fold [4/5] Epoch [0/100] Initial Loss: 0.1384, Training Loss: 0.1384, Initial Validation Loss: 0.1321, Validation Loss: 0.1321,V Acc: 0.2477, Top 70th Acc: 0.3247, Bottom 30th Acc: 0.0625
Fold [4/5] Epoch [10/100] Initial Loss: 0.1384, Training Loss: 0.0276, Initial Validation Loss: 0.1321, Validation Loss: 0.0281,V Acc: 0.8991, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.7500
Fold [4/5] Epoch [20/100] Initial Loss: 0.1384, Training Loss: 0.0146, Initial Validation Loss: 0.1321, Validation Loss: 0.0230,V Acc: 0.8807, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.7188
Stopping early at Epoch (base 0): 21  Rolling back to Epoch (base 0): 16  Top Validation Acc: 0.935064935064935
Fold [5/5] Epoch [0/100] Initial Loss: 0.1425, Training Loss: 0.1425, Initial Validation Loss: 0.1341, Validation Loss: 0.1341,V Acc: 0.2500, Top 70th Acc: 0.3421, Bottom 30th Acc: 0.0312
Fold [5/5] Epoch [10/100] Initial Loss: 0.1425, Training Loss: 0.0340, Initial Validation Loss: 0.1341, Validation Loss: 0.0408,V Acc: 0.8056, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.5000
Fold [5/5] Epoch [20/100] Initial Loss: 0.1425, Training Loss: 0.0142, Initial Validation Loss: 0.1341, Validation Loss: 0.0282,V Acc: 0.8333, Top 70th Acc: 1.0000, Bottom 30th Acc: 0.4375
Stopping early at Epoch (base 0): 28  Rolling back to Epoch (base 0): 23  Top Validation Acc: 1.0
Running train_nn.py with seed 3
CUDA:False
Training samples count:  550
Training on 40 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1416, Training Loss: 0.1416, Initial Validation Loss: 0.1344, Validation Loss: 0.1344,V Acc: 0.2589, Top 70th Acc: 0.3418, Bottom 30th Acc: 0.0606
Fold [1/5] Epoch [10/100] Initial Loss: 0.1416, Training Loss: 0.0291, Initial Validation Loss: 0.1344, Validation Loss: 0.0393,V Acc: 0.8036, Top 70th Acc: 0.9241, Bottom 30th Acc: 0.5152
Running train_nn.py with seed 1
CUDA:False
Training samples count:  550
Training on 20 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1384, Training Loss: 0.1384, Initial Validation Loss: 0.1330, Validation Loss: 0.1330,V Acc: 0.3214, Top 70th Acc: 0.3797, Bottom 30th Acc: 0.1818
Fold [1/5] Epoch [10/100] Initial Loss: 0.1384, Training Loss: 0.0335, Initial Validation Loss: 0.1330, Validation Loss: 0.0394,V Acc: 0.8304, Top 70th Acc: 0.9241, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 18  Rolling back to Epoch (base 0): 13  Top Validation Acc: 0.9113924050632911
1 0 [array([0.26377013, 0.08364911, 0.12746695, 0.24005893, 0.28505492],
      dtype=float32)]
Fold [2/5] Epoch [0/100] Initial Loss: 0.1371, Training Loss: 0.1371, Initial Validation Loss: 0.1301, Validation Loss: 0.1301,V Acc: 0.4505, Top 70th Acc: 0.5513, Bottom 30th Acc: 0.2121
Fold [2/5] Epoch [10/100] Initial Loss: 0.1371, Training Loss: 0.0303, Initial Validation Loss: 0.1301, Validation Loss: 0.0369,V Acc: 0.8108, Top 70th Acc: 0.8718, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 18  Rolling back to Epoch (base 0): 13  Top Validation Acc: 0.8974358974358975
Fold [3/5] Epoch [0/100] Initial Loss: 0.1374, Training Loss: 0.1374, Initial Validation Loss: 0.1298, Validation Loss: 0.1298,V Acc: 0.4545, Top 70th Acc: 0.5325, Bottom 30th Acc: 0.2727
Fold [3/5] Epoch [10/100] Initial Loss: 0.1374, Training Loss: 0.0343, Initial Validation Loss: 0.1298, Validation Loss: 0.0474,V Acc: 0.8182, Top 70th Acc: 0.8831, Bottom 30th Acc: 0.6667
Fold [3/5] Epoch [20/100] Initial Loss: 0.1374, Training Loss: 0.0241, Initial Validation Loss: 0.1298, Validation Loss: 0.0380,V Acc: 0.8091, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.4545
Fold [3/5] Epoch [30/100] Initial Loss: 0.1374, Training Loss: 0.0216, Initial Validation Loss: 0.1298, Validation Loss: 0.0376,V Acc: 0.8182, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 30  Rolling back to Epoch (base 0): 25  Top Validation Acc: 0.935064935064935
Fold [4/5] Epoch [0/100] Initial Loss: 0.1400, Training Loss: 0.1400, Initial Validation Loss: 0.1316, Validation Loss: 0.1316,V Acc: 0.3211, Top 70th Acc: 0.4026, Bottom 30th Acc: 0.1250
Fold [4/5] Epoch [10/100] Initial Loss: 0.1400, Training Loss: 0.0447, Initial Validation Loss: 0.1316, Validation Loss: 0.0392,V Acc: 0.8165, Top 70th Acc: 0.8961, Bottom 30th Acc: 0.6250
Fold [4/5] Epoch [20/100] Initial Loss: 0.1400, Training Loss: 0.0255, Initial Validation Loss: 0.1316, Validation Loss: 0.0307,V Acc: 0.8349, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.5938
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.922077922077922
Fold [5/5] Epoch [0/100] Initial Loss: 0.1392, Training Loss: 0.1392, Initial Validation Loss: 0.1331, Validation Loss: 0.1331,V Acc: 0.2500, Top 70th Acc: 0.3158, Bottom 30th Acc: 0.0938
Fold [5/5] Epoch [10/100] Initial Loss: 0.1392, Training Loss: 0.0447, Initial Validation Loss: 0.1331, Validation Loss: 0.0511,V Acc: 0.7778, Top 70th Acc: 0.8816, Bottom 30th Acc: 0.5312
Fold [5/5] Epoch [20/100] Initial Loss: 0.1392, Training Loss: 0.0246, Initial Validation Loss: 0.1331, Validation Loss: 0.0362,V Acc: 0.8333, Top 70th Acc: 0.9079, Bottom 30th Acc: 0.6562
Fold [5/5] Epoch [30/100] Initial Loss: 0.1392, Training Loss: 0.0211, Initial Validation Loss: 0.1331, Validation Loss: 0.0358,V Acc: 0.8426, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.6250
Stopping early at Epoch (base 0): 30  Rolling back to Epoch (base 0): 25  Top Validation Acc: 0.9342105263157895
Running train_nn.py with seed 2
CUDA:False
Training samples count:  550
Training on 20 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1392, Training Loss: 0.1392, Initial Validation Loss: 0.1327, Validation Loss: 0.1327,V Acc: 0.2946, Top 70th Acc: 0.2152, Bottom 30th Acc: 0.4848
Fold [1/5] Epoch [10/100] Initial Loss: 0.1392, Training Loss: 0.0434, Initial Validation Loss: 0.1327, Validation Loss: 0.0463,V Acc: 0.7768, Top 70th Acc: 0.8734, Bottom 30th Acc: 0.5455
Fold [1/5] Epoch [20/100] Initial Loss: 0.1392, Training Loss: 0.0259, Initial Validation Loss: 0.1327, Validation Loss: 0.0325,V Acc: 0.8661, Top 70th Acc: 0.9367, Bottom 30th Acc: 0.6970
Fold [1/5] Epoch [30/100] Initial Loss: 0.1392, Training Loss: 0.0233, Initial Validation Loss: 0.1327, Validation Loss: 0.0305,V Acc: 0.8750, Top 70th Acc: 0.9367, Bottom 30th Acc: 0.7273
Stopping early at Epoch (base 0): 39  Rolling back to Epoch (base 0): 34  Top Validation Acc: 0.9367088607594937
2 0 [array([0.539243  , 0.07959242, 0.06693923, 0.19151591, 0.12270947],
      dtype=float32)]
Fold [2/5] Epoch [0/100] Initial Loss: 0.1388, Training Loss: 0.1388, Initial Validation Loss: 0.1360, Validation Loss: 0.1360,V Acc: 0.2703, Top 70th Acc: 0.3077, Bottom 30th Acc: 0.1818
Fold [2/5] Epoch [10/100] Initial Loss: 0.1388, Training Loss: 0.0361, Initial Validation Loss: 0.1360, Validation Loss: 0.0412,V Acc: 0.7838, Top 70th Acc: 0.8846, Bottom 30th Acc: 0.5455
Fold [2/5] Epoch [20/100] Initial Loss: 0.1388, Training Loss: 0.0242, Initial Validation Loss: 0.1360, Validation Loss: 0.0378,V Acc: 0.7748, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.4242
Stopping early at Epoch (base 0): 22  Rolling back to Epoch (base 0): 17  Top Validation Acc: 0.9230769230769231
Fold [3/5] Epoch [0/100] Initial Loss: 0.1396, Training Loss: 0.1396, Initial Validation Loss: 0.1354, Validation Loss: 0.1354,V Acc: 0.2545, Top 70th Acc: 0.3377, Bottom 30th Acc: 0.0606
Fold [3/5] Epoch [10/100] Initial Loss: 0.1396, Training Loss: 0.0342, Initial Validation Loss: 0.1354, Validation Loss: 0.0429,V Acc: 0.8000, Top 70th Acc: 0.8701, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 19  Rolling back to Epoch (base 0): 14  Top Validation Acc: 0.8961038961038961
Fold [4/5] Epoch [0/100] Initial Loss: 0.1387, Training Loss: 0.1387, Initial Validation Loss: 0.1316, Validation Loss: 0.1316,V Acc: 0.2936, Top 70th Acc: 0.3636, Bottom 30th Acc: 0.1250
Fold [4/5] Epoch [10/100] Initial Loss: 0.1387, Training Loss: 0.0351, Initial Validation Loss: 0.1316, Validation Loss: 0.0342,V Acc: 0.8532, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6250
Fold [4/5] Epoch [20/100] Initial Loss: 0.1387, Training Loss: 0.0244, Initial Validation Loss: 0.1316, Validation Loss: 0.0287,V Acc: 0.8716, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.6562
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.961038961038961
Fold [5/5] Epoch [0/100] Initial Loss: 0.1447, Training Loss: 0.1447, Initial Validation Loss: 0.1304, Validation Loss: 0.1304,V Acc: 0.3148, Top 70th Acc: 0.4079, Bottom 30th Acc: 0.0938
Fold [5/5] Epoch [10/100] Initial Loss: 0.1447, Training Loss: 0.0338, Initial Validation Loss: 0.1304, Validation Loss: 0.0430,V Acc: 0.7870, Top 70th Acc: 0.8947, Bottom 30th Acc: 0.5312
Fold [5/5] Epoch [20/100] Initial Loss: 0.1447, Training Loss: 0.0241, Initial Validation Loss: 0.1304, Validation Loss: 0.0373,V Acc: 0.8333, Top 70th Acc: 0.9211, Bottom 30th Acc: 0.6250
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.9342105263157895
Running train_nn.py with seed 3
CUDA:False
Training samples count:  550
Training on 20 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1372, Training Loss: 0.1372, Initial Validation Loss: 0.1300, Validation Loss: 0.1300,V Acc: 0.3304, Top 70th Acc: 0.3924, Bottom 30th Acc: 0.1818
Fold [1/5] Epoch [10/100] Initial Loss: 0.1372, Training Loss: 0.0339, Initial Validation Loss: 0.1300, Validation Loss: 0.0378,V Acc: 0.8214, Top 70th Acc: 0.8987, Bottom 30th Acc: 0.6364
Fold [1/5] Epoch [20/100] Initial Loss: 0.1372, Training Loss: 0.0231, Initial Validation Loss: 0.1300, Validation Loss: 0.0343,V Acc: 0.8125, Top 70th Acc: 0.9367, Bottom 30th Acc: 0.5152
Stopping early at Epoch (base 0): 22  Rolling back to Epoch (base 0): 17  Top Validation Acc: 0.9113924050632911
Fold [2/5] Epoch [0/100] Initial Loss: 0.1398, Training Loss: 0.1398, Initial Validation Loss: 0.1362, Validation Loss: 0.1362,V Acc: 0.3514, Top 70th Acc: 0.3462, Bottom 30th Acc: 0.3636
Fold [2/5] Epoch [10/100] Initial Loss: 0.1398, Training Loss: 0.0338, Initial Validation Loss: 0.1362, Validation Loss: 0.0413,V Acc: 0.8288, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.5758Running train_nn.py with seed 1
CUDA:False
Training samples count:  550
Training on 2 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1385, Training Loss: 0.1385, Initial Validation Loss: 0.1339, Validation Loss: 0.1339,V Acc: 0.2679, Top 70th Acc: 0.3671, Bottom 30th Acc: 0.0303
Fold [1/5] Epoch [10/100] Initial Loss: 0.1385, Training Loss: 0.0797, Initial Validation Loss: 0.1339, Validation Loss: 0.0848,V Acc: 0.5982, Top 70th Acc: 0.7089, Bottom 30th Acc: 0.3333
Fold [1/5] Epoch [20/100] Initial Loss: 0.1385, Training Loss: 0.0781, Initial Validation Loss: 0.1339, Validation Loss: 0.0824,V Acc: 0.5893, Top 70th Acc: 0.7215, Bottom 30th Acc: 0.2727
Stopping early at Epoch (base 0): 20  Rolling back to Epoch (base 0): 15  Top Validation Acc: 0.7215189873417721
1 0 [array([0.11558194, 0.37739968, 0.18512931, 0.18764248, 0.13424656],
      dtype=float32)]
Fold [2/5] Epoch [0/100] Initial Loss: 0.1312, Training Loss: 0.1312, Initial Validation Loss: 0.1191, Validation Loss: 0.1191,V Acc: 0.4324, Top 70th Acc: 0.5128, Bottom 30th Acc: 0.2424
Fold [2/5] Epoch [10/100] Initial Loss: 0.1312, Training Loss: 0.0817, Initial Validation Loss: 0.1191, Validation Loss: 0.0798,V Acc: 0.6036, Top 70th Acc: 0.7436, Bottom 30th Acc: 0.2727
Fold [2/5] Epoch [20/100] Initial Loss: 0.1312, Training Loss: 0.0795, Initial Validation Loss: 0.1191, Validation Loss: 0.0781,V Acc: 0.6126, Top 70th Acc: 0.7564, Bottom 30th Acc: 0.2727
Fold [2/5] Epoch [30/100] Initial Loss: 0.1312, Training Loss: 0.0790, Initial Validation Loss: 0.1191, Validation Loss: 0.0768,V Acc: 0.6396, Top 70th Acc: 0.7564, Bottom 30th Acc: 0.3636
Stopping early at Epoch (base 0): 34  Rolling back to Epoch (base 0): 29  Top Validation Acc: 0.7564102564102564
Fold [3/5] Epoch [0/100] Initial Loss: 0.1398, Training Loss: 0.1398, Initial Validation Loss: 0.1316, Validation Loss: 0.1316,V Acc: 0.3727, Top 70th Acc: 0.4286, Bottom 30th Acc: 0.2424
Fold [3/5] Epoch [10/100] Initial Loss: 0.1398, Training Loss: 0.0797, Initial Validation Loss: 0.1316, Validation Loss: 0.0847,V Acc: 0.6273, Top 70th Acc: 0.7143, Bottom 30th Acc: 0.4242
Fold [3/5] Epoch [20/100] Initial Loss: 0.1398, Training Loss: 0.0775, Initial Validation Loss: 0.1316, Validation Loss: 0.0835,V Acc: 0.6273, Top 70th Acc: 0.7403, Bottom 30th Acc: 0.3636
Fold [3/5] Epoch [30/100] Initial Loss: 0.1398, Training Loss: 0.0768, Initial Validation Loss: 0.1316, Validation Loss: 0.0826,V Acc: 0.6455, Top 70th Acc: 0.7403, Bottom 30th Acc: 0.4242
Stopping early at Epoch (base 0): 38  Rolling back to Epoch (base 0): 33  Top Validation Acc: 0.7142857142857143
Fold [4/5] Epoch [0/100] Initial Loss: 0.1312, Training Loss: 0.1312, Initial Validation Loss: 0.1146, Validation Loss: 0.1146,V Acc: 0.4312, Top 70th Acc: 0.4935, Bottom 30th Acc: 0.2812
Fold [4/5] Epoch [10/100] Initial Loss: 0.1312, Training Loss: 0.0831, Initial Validation Loss: 0.1146, Validation Loss: 0.0709,V Acc: 0.6789, Top 70th Acc: 0.7532, Bottom 30th Acc: 0.5000
Fold [4/5] Epoch [20/100] Initial Loss: 0.1312, Training Loss: 0.0817, Initial Validation Loss: 0.1146, Validation Loss: 0.0686,V Acc: 0.6881, Top 70th Acc: 0.7662, Bottom 30th Acc: 0.5000
Stopping early at Epoch (base 0): 29  Rolling back to Epoch (base 0): 24  Top Validation Acc: 0.7662337662337663
Fold [5/5] Epoch [0/100] Initial Loss: 0.1361, Training Loss: 0.1361, Initial Validation Loss: 0.1243, Validation Loss: 0.1243,V Acc: 0.4167, Top 70th Acc: 0.4605, Bottom 30th Acc: 0.3125
Fold [5/5] Epoch [10/100] Initial Loss: 0.1361, Training Loss: 0.0800, Initial Validation Loss: 0.1243, Validation Loss: 0.0811,V Acc: 0.6204, Top 70th Acc: 0.6974, Bottom 30th Acc: 0.4375
Fold [5/5] Epoch [20/100] Initial Loss: 0.1361, Training Loss: 0.0774, Initial Validation Loss: 0.1243, Validation Loss: 0.0800,V Acc: 0.6019, Top 70th Acc: 0.6711, Bottom 30th Acc: 0.4375
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.6842105263157895
Running train_nn.py with seed 2
CUDA:False
Training samples count:  550
Training on 2 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1411, Training Loss: 0.1411, Initial Validation Loss: 0.1349, Validation Loss: 0.1349,V Acc: 0.2500, Top 70th Acc: 0.3544, Bottom 30th Acc: 0.0000
Fold [1/5] Epoch [10/100] Initial Loss: 0.1411, Training Loss: 0.0834, Initial Validation Loss: 0.1349, Validation Loss: 0.0785,V Acc: 0.6429, Top 70th Acc: 0.7722, Bottom 30th Acc: 0.3333
Fold [1/5] Epoch [20/100] Initial Loss: 0.1411, Training Loss: 0.0805, Initial Validation Loss: 0.1349, Validation Loss: 0.0763,V Acc: 0.6518, Top 70th Acc: 0.7595, Bottom 30th Acc: 0.3939
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.759493670886076
2 0 [array([0.11506061, 0.35454443, 0.1667633 , 0.20166986, 0.16196185],
      dtype=float32)]
Fold [2/5] Epoch [0/100] Initial Loss: 0.1343, Training Loss: 0.1343, Initial Validation Loss: 0.1272, Validation Loss: 0.1272,V Acc: 0.4234, Top 70th Acc: 0.5256, Bottom 30th Acc: 0.1818
Fold [2/5] Epoch [10/100] Initial Loss: 0.1343, Training Loss: 0.0817, Initial Validation Loss: 0.1272, Validation Loss: 0.0808,V Acc: 0.6396, Top 70th Acc: 0.7436, Bottom 30th Acc: 0.3939
Fold [2/5] Epoch [20/100] Initial Loss: 0.1343, Training Loss: 0.0794, Initial Validation Loss: 0.1272, Validation Loss: 0.0796,V Acc: 0.6306, Top 70th Acc: 0.7308, Bottom 30th Acc: 0.3939
Stopping early at Epoch (base 0): 29  Rolling back to Epoch (base 0): 24  Top Validation Acc: 0.717948717948718
Fold [3/5] Epoch [0/100] Initial Loss: 0.1363, Training Loss: 0.1363, Initial Validation Loss: 0.1261, Validation Loss: 0.1261,V Acc: 0.3273, Top 70th Acc: 0.4156, Bottom 30th Acc: 0.1212
Fold [3/5] Epoch [10/100] Initial Loss: 0.1363, Training Loss: 0.0783, Initial Validation Loss: 0.1261, Validation Loss: 0.0841,V Acc: 0.5727, Top 70th Acc: 0.7013, Bottom 30th Acc: 0.2727
Fold [3/5] Epoch [20/100] Initial Loss: 0.1363, Training Loss: 0.0767, Initial Validation Loss: 0.1261, Validation Loss: 0.0836,V Acc: 0.5909, Top 70th Acc: 0.7143, Bottom 30th Acc: 0.3030
Stopping early at Epoch (base 0): 29  Rolling back to Epoch (base 0): 24  Top Validation Acc: 0.7272727272727273
Fold [4/5] Epoch [0/100] Initial Loss: 0.1391, Training Loss: 0.1391, Initial Validation Loss: 0.1302, Validation Loss: 0.1302,V Acc: 0.4495, Top 70th Acc: 0.5195, Bottom 30th Acc: 0.2812
Fold [4/5] Epoch [10/100] Initial Loss: 0.1391, Training Loss: 0.0816, Initial Validation Loss: 0.1302, Validation Loss: 0.0803,V Acc: 0.6147, Top 70th Acc: 0.7532, Bottom 30th Acc: 0.2812
Fold [4/5] Epoch [20/100] Initial Loss: 0.1391, Training Loss: 0.0789, Initial Validation Loss: 0.1302, Validation Loss: 0.0778,V Acc: 0.6239, Top 70th Acc: 0.7532, Bottom 30th Acc: 0.3125
Fold [4/5] Epoch [30/100] Initial Loss: 0.1391, Training Loss: 0.0785, Initial Validation Loss: 0.1302, Validation Loss: 0.0768,V Acc: 0.6239, Top 70th Acc: 0.7662, Bottom 30th Acc: 0.2812
Fold [4/5] Epoch [40/100] Initial Loss: 0.1391, Training Loss: 0.0779, Initial Validation Loss: 0.1302, Validation Loss: 0.0773,V Acc: 0.6330, Top 70th Acc: 0.7662, Bottom 30th Acc: 0.3125
Stopping early at Epoch (base 0): 49  Rolling back to Epoch (base 0): 44  Top Validation Acc: 0.7922077922077922
Fold [5/5] Epoch [0/100] Initial Loss: 0.1356, Training Loss: 0.1356, Initial Validation Loss: 0.1218, Validation Loss: 0.1218,V Acc: 0.5370, Top 70th Acc: 0.5395, Bottom 30th Acc: 0.5312
Fold [5/5] Epoch [10/100] Initial Loss: 0.1356, Training Loss: 0.0817, Initial Validation Loss: 0.1218, Validation Loss: 0.0757,V Acc: 0.6574, Top 70th Acc: 0.7237, Bottom 30th Acc: 0.5000
Fold [5/5] Epoch [20/100] Initial Loss: 0.1356, Training Loss: 0.0792, Initial Validation Loss: 0.1218, Validation Loss: 0.0737,V Acc: 0.6759, Top 70th Acc: 0.7500, Bottom 30th Acc: 0.5000
Fold [5/5] Epoch [30/100] Initial Loss: 0.1356, Training Loss: 0.0783, Initial Validation Loss: 0.1218, Validation Loss: 0.0738,V Acc: 0.6759, Top 70th Acc: 0.7237, Bottom 30th Acc: 0.5625
Fold [5/5] Epoch [40/100] Initial Loss: 0.1356, Training Loss: 0.0777, Initial Validation Loss: 0.1218, Validation Loss: 0.0732,V Acc: 0.6759, Top 70th Acc: 0.7500, Bottom 30th Acc: 0.5000
Stopping early at Epoch (base 0):Running train_nn.py with seed 1
CUDA:False
Training samples count:  550
Training on 162 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1388, Training Loss: 0.1388, Initial Validation Loss: 0.1360, Validation Loss: 0.1360,V Acc: 0.2768, Top 70th Acc: 0.3544, Bottom 30th Acc: 0.0909
Fold [1/5] Epoch [10/100] Initial Loss: 0.1388, Training Loss: 0.0156, Initial Validation Loss: 0.1360, Validation Loss: 0.0396,V Acc: 0.8393, Top 70th Acc: 0.8987, Bottom 30th Acc: 0.6970
Fold [1/5] Epoch [20/100] Initial Loss: 0.1388, Training Loss: 0.0054, Initial Validation Loss: 0.1360, Validation Loss: 0.0321,V Acc: 0.8482, Top 70th Acc: 0.9367, Bottom 30th Acc: 0.6364
Fold [1/5] Epoch [30/100] Initial Loss: 0.1388, Training Loss: 0.0041, Initial Validation Loss: 0.1360, Validation Loss: 0.0312,V Acc: 0.8571, Top 70th Acc: 0.9494, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 37  Rolling back to Epoch (base 0): 32  Top Validation Acc: 0.9493670886075949
1 0 [array([0.39702448, 0.03140875, 0.06335971, 0.16238993, 0.34581715],
      dtype=float32)]
Fold [2/5] Epoch [0/100] Initial Loss: 0.1382, Training Loss: 0.1382, Initial Validation Loss: 0.1349, Validation Loss: 0.1349,V Acc: 0.2613, Top 70th Acc: 0.3718, Bottom 30th Acc: 0.0000
Fold [2/5] Epoch [10/100] Initial Loss: 0.1382, Training Loss: 0.0147, Initial Validation Loss: 0.1349, Validation Loss: 0.0286,V Acc: 0.8468, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.5758
Fold [2/5] Epoch [20/100] Initial Loss: 0.1382, Training Loss: 0.0052, Initial Validation Loss: 0.1349, Validation Loss: 0.0262,V Acc: 0.8649, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 21  Rolling back to Epoch (base 0): 16  Top Validation Acc: 0.9487179487179487
Fold [3/5] Epoch [0/100] Initial Loss: 0.1386, Training Loss: 0.1386, Initial Validation Loss: 0.1353, Validation Loss: 0.1353,V Acc: 0.3273, Top 70th Acc: 0.3506, Bottom 30th Acc: 0.2727
Fold [3/5] Epoch [10/100] Initial Loss: 0.1386, Training Loss: 0.0186, Initial Validation Loss: 0.1353, Validation Loss: 0.0439,V Acc: 0.7909, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.4848
Fold [3/5] Epoch [20/100] Initial Loss: 0.1386, Training Loss: 0.0057, Initial Validation Loss: 0.1353, Validation Loss: 0.0414,V Acc: 0.8000, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.5152
Fold [3/5] Epoch [30/100] Initial Loss: 0.1386, Training Loss: 0.0045, Initial Validation Loss: 0.1353, Validation Loss: 0.0405,V Acc: 0.8091, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.4848
Fold [3/5] Epoch [40/100] Initial Loss: 0.1386, Training Loss: 0.0041, Initial Validation Loss: 0.1353, Validation Loss: 0.0398,V Acc: 0.8091, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.5152
Fold [3/5] Epoch [50/100] Initial Loss: 0.1386, Training Loss: 0.0037, Initial Validation Loss: 0.1353, Validation Loss: 0.0388,V Acc: 0.8273, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.5758
Fold [3/5] Epoch [60/100] Initial Loss: 0.1386, Training Loss: 0.0035, Initial Validation Loss: 0.1353, Validation Loss: 0.0382,V Acc: 0.8091, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.4848
Fold [3/5] Epoch [70/100] Initial Loss: 0.1386, Training Loss: 0.0035, Initial Validation Loss: 0.1353, Validation Loss: 0.0373,V Acc: 0.8364, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.5758
Fold [3/5] Epoch [80/100] Initial Loss: 0.1386, Training Loss: 0.0034, Initial Validation Loss: 0.1353, Validation Loss: 0.0368,V Acc: 0.8364, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.5758
Fold [3/5] Epoch [90/100] Initial Loss: 0.1386, Training Loss: 0.0033, Initial Validation Loss: 0.1353, Validation Loss: 0.0366,V Acc: 0.8455, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 93  Rolling back to Epoch (base 0): 88  Top Validation Acc: 0.948051948051948
Fold [4/5] Epoch [0/100] Initial Loss: 0.1444, Training Loss: 0.1444, Initial Validation Loss: 0.1324, Validation Loss: 0.1324,V Acc: 0.3028, Top 70th Acc: 0.4156, Bottom 30th Acc: 0.0312
Fold [4/5] Epoch [10/100] Initial Loss: 0.1444, Training Loss: 0.0229, Initial Validation Loss: 0.1324, Validation Loss: 0.0306,V Acc: 0.8624, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6562
Fold [4/5] Epoch [20/100] Initial Loss: 0.1444, Training Loss: 0.0072, Initial Validation Loss: 0.1324, Validation Loss: 0.0240,V Acc: 0.8991, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.7812
Fold [4/5] Epoch [30/100] Initial Loss: 0.1444, Training Loss: 0.0048, Initial Validation Loss: 0.1324, Validation Loss: 0.0212,V Acc: 0.9083, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.7812
Stopping early at Epoch (base 0): 35  Rolling back to Epoch (base 0): 30  Top Validation Acc: 0.961038961038961
Fold [5/5] Epoch [0/100] Initial Loss: 0.1384, Training Loss: 0.1384, Initial Validation Loss: 0.1315, Validation Loss: 0.1315,V Acc: 0.3519, Top 70th Acc: 0.4342, Bottom 30th Acc: 0.1562
Fold [5/5] Epoch [10/100] Initial Loss: 0.1384, Training Loss: 0.0128, Initial Validation Loss: 0.1315, Validation Loss: 0.0304,V Acc: 0.8611, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.6250
Stopping early at Epoch (base 0): 18  Rolling back to Epoch (base 0): 13  Top Validation Acc: 0.9736842105263158
Running train_nn.py with seed 2
CUDA:False
Training samples count:  550
Training on 162 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1406, Training Loss: 0.1406, Initial Validation Loss: 0.1346, Validation Loss: 0.1346,V Acc: 0.2500, Top 70th Acc: 0.3038, Bottom 30th Acc: 0.1212
Fold [1/5] Epoch [10/100] Initial Loss: 0.1406, Training Loss: 0.0182, Initial Validation Loss: 0.1346, Validation Loss: 0.0374,V Acc: 0.8214, Top 70th Acc: 0.9494, Bottom 30th Acc: 0.5152
Fold [1/5] Epoch [20/100] Initial Loss: 0.1406, Training Loss: 0.0051, Initial Validation Loss: 0.1346, Validation Loss: 0.0334,V Acc: 0.8304, Top 70th Acc: 0.9620, Bottom 30th Acc: 0.5152
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.9620253164556962
2 0 [array([0.33332074, 0.07972559, 0.08124322, 0.21164908, 0.29406133],
      dtype=float32)]
Fold [2/5] Epoch [0/100] Initial Loss: 0.1384, Training Loss: 0.1384, Initial Validation Loss: 0.1345, Validation Loss: 0.1345,V Acc: 0.3153, Top 70th Acc: 0.3590, Bottom 30th Acc: 0.2121
Fold [2/5] Epoch [10/100] Initial Loss: 0.1384, Training Loss: 0.0169, Initial Validation Loss: 0.1345, Validation Loss: 0.0322,V Acc: 0.8198, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.5455
Fold [2/5] Epoch [20/100] Initial Loss: 0.1384, Training Loss: 0.0052, Initial Validation Loss: 0.1345, Validation Loss: 0.0264,V Acc: 0.8829, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.7576
Fold [2/5] Epoch [30/100] Initial Loss: 0.1384, Training Loss: 0.0042, Initial Validation Loss: 0.1345, Validation Loss: 0.0250,V Acc: 0.8829, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.7576
Fold [2/5] Epoch [40/100] Initial Loss: 0.1384, Training Loss: 0.0039, Initial Validation Loss: 0.1345, Validation Loss: 0.0242,V Acc: 0.8829, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.7273
Stopping early at Epoch (base 0): 45  Rolling back to Epoch (base 0): 40  Top Validation Acc: 0.9487179487179487
Fold [3/5] Epoch [0/100] Initial Loss: 0.1403, Training Loss: 0.1403, Initial Validation Loss: 0.1320, Validation Loss: 0.1320,V Acc: 0.4364, Top 70th Acc: 0.4805, Bottom 30th Acc: 0.3333
Fold [3/5] Epoch [10/100] Initial Loss: 0.1403, Training Loss: 0.0151, Initial Validation Loss: 0.1320, Validation Loss: 0.0469,V Acc: 0.7636, Top 70th Acc: 0.8571, Bottom 30th Acc: 0.5455
Fold [3/5] Epoch [20/100] Initial Loss: 0.1403, Training Loss: 0.0054, Initial Validation Loss: 0.1320, Validation Loss: 0.0412,V Acc: 0.7727, Top 70th Acc: 0.8831, Bottom 30th Acc: 0.5152
Fold [3/5] Epoch [30/100] Initial Loss: 0.1403, Training Loss: 0.0042, Initial Validation Loss: 0.1320, Validation Loss: 0.0381,V Acc: 0.7909, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.4848
Fold [3/5] Epoch [40/100] Initial Loss: 0.1403, Training Loss: 0.0039, Initial Validation Loss: 0.1320, Validation Loss: 0.0376,V Acc: 0.7909, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.5152
Fold [3/5] Epoch [50/100] Initial Loss: 0.1403, Training Loss: 0.0038, Initial Validation Loss: 0.1320, Validation Loss: 0.0365,V Acc: 0.8000, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.5455
Fold [3/5] Epoch [60/100] Initial Loss: 0.1403, Training Loss: 0.0037, Initial Validation Loss: 0.1320, Validation Loss: 0.0362,V Acc: 0.7909, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.5152
Fold [3/5] Epoch [20/100] Initial Loss: 0.1334, Training Loss: 0.0151, Initial Validation Loss: 0.1210, Validation Loss: 0.0225,V Acc: 0.8818, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 28  Rolling back to Epoch (base 0): 23  Top Validation Acc: 0.974025974025974
Fold [4/5] Epoch [0/100] Initial Loss: 0.1373, Training Loss: 0.1373, Initial Validation Loss: 0.1280, Validation Loss: 0.1280,V Acc: 0.2569, Top 70th Acc: 0.3506, Bottom 30th Acc: 0.0312
Fold [4/5] Epoch [10/100] Initial Loss: 0.1373, Training Loss: 0.0275, Initial Validation Loss: 0.1280, Validation Loss: 0.0236,V Acc: 0.8807, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.7188
Fold [4/5] Epoch [20/100] Initial Loss: 0.1373, Training Loss: 0.0179, Initial Validation Loss: 0.1280, Validation Loss: 0.0232,V Acc: 0.8624, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.5938
Stopping early at Epoch (base 0): 22  Rolling back to Epoch (base 0): 17  Top Validation Acc: 0.974025974025974
Fold [5/5] Epoch [0/100] Initial Loss: 0.1382, Training Loss: 0.1382, Initial Validation Loss: 0.1281, Validation Loss: 0.1281,V Acc: 0.4259, Top 70th Acc: 0.5526, Bottom 30th Acc: 0.1250
Fold [5/5] Epoch [10/100] Initial Loss: 0.1382, Training Loss: 0.0217, Initial Validation Loss: 0.1281, Validation Loss: 0.0320,V Acc: 0.8333, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.5312
Fold [5/5] Epoch [20/100] Initial Loss: 0.1382, Training Loss: 0.0150, Initial Validation Loss: 0.1281, Validation Loss: 0.0286,V Acc: 0.8796, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.7500
Stopping early at Epoch (base 0): 28  Rolling back to Epoch (base 0): 23  Top Validation Acc: 0.9473684210526315
Running train_nn.py with seed 4
CUDA:False
Training samples count:  550
Training on 21 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1343, Training Loss: 0.1343, Initial Validation Loss: 0.1231, Validation Loss: 0.1231,V Acc: 0.4821, Top 70th Acc: 0.6456, Bottom 30th Acc: 0.0909
Fold [1/5] Epoch [10/100] Initial Loss: 0.1343, Training Loss: 0.0224, Initial Validation Loss: 0.1231, Validation Loss: 0.0271,V Acc: 0.8661, Top 70th Acc: 0.9747, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 16  Rolling back to Epoch (base 0): 11  Top Validation Acc: 0.9620253164556962
4 0 [array([0.8188249 , 0.00911582, 0.04524839, 0.06917053, 0.05764031],
      dtype=float32)]
Fold [2/5] Epoch [0/100] Initial Loss: 0.1352, Training Loss: 0.1352, Initial Validation Loss: 0.1223, Validation Loss: 0.1223,V Acc: 0.4324, Top 70th Acc: 0.5128, Bottom 30th Acc: 0.2424
Fold [2/5] Epoch [10/100] Initial Loss: 0.1352, Training Loss: 0.0215, Initial Validation Loss: 0.1223, Validation Loss: 0.0303,V Acc: 0.8649, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.6364
Fold [2/5] Epoch [20/100] Initial Loss: 0.1352, Training Loss: 0.0152, Initial Validation Loss: 0.1223, Validation Loss: 0.0267,V Acc: 0.8649, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 20  Rolling back to Epoch (base 0): 15  Top Validation Acc: 0.9615384615384616
Fold [3/5] Epoch [0/100] Initial Loss: 0.1360, Training Loss: 0.1360, Initial Validation Loss: 0.1259, Validation Loss: 0.1259,V Acc: 0.4636, Top 70th Acc: 0.5195, Bottom 30th Acc: 0.3333
Fold [3/5] Epoch [10/100] Initial Loss: 0.1360, Training Loss: 0.0223, Initial Validation Loss: 0.1259, Validation Loss: 0.0239,V Acc: 0.8636, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 17  Rolling back to Epoch (base 0): 12  Top Validation Acc: 0.974025974025974
Fold [4/5] Epoch [0/100] Initial Loss: 0.1387, Training Loss: 0.1387, Initial Validation Loss: 0.1291, Validation Loss: 0.1291,V Acc: 0.3578, Top 70th Acc: 0.3506, Bottom 30th Acc: 0.3750
Fold [4/5] Epoch [10/100] Initial Loss: 0.1387, Training Loss: 0.0244, Initial Validation Loss: 0.1291, Validation Loss: 0.0230,V Acc: 0.8991, Top 70th Acc: 0.9870, Bottom 30th Acc: 0.6875
Fold [4/5] Epoch [20/100] Initial Loss: 0.1387, Training Loss: 0.0166, Initial Validation Loss: 0.1291, Validation Loss: 0.0201,V Acc: 0.9174, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.7812
Stopping early at Epoch (base 0): 29  Rolling back to Epoch (base 0): 24  Top Validation Acc: 0.987012987012987
Fold [5/5] Epoch [0/100] Initial Loss: 0.1369, Training Loss: 0.1369, Initial Validation Loss: 0.1252, Validation Loss: 0.1252,V Acc: 0.3981, Top 70th Acc: 0.4474, Bottom 30th Acc: 0.2812
Fold [5/5] Epoch [10/100] Initial Loss: 0.1369, Training Loss: 0.0214, Initial Validation Loss: 0.1252, Validation Loss: 0.0293,V Acc: 0.8611, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.6250
Stopping early at Epoch (base 0): 19  Rolling back to Epoch (base 0): 14  Top Validation Acc: 0.9342105263157895
Running train_nn.py with seed 5
CUDA:False
Training samples count:  550
Training on 21 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1352, Training Loss: 0.1352, Initial Validation Loss: 0.1214, Validation Loss: 0.1214,V Acc: 0.5714, Top 70th Acc: 0.6709, Bottom 30th Acc: 0.3333
Fold [1/5] Epoch [10/100] Initial Loss: 0.1352, Training Loss: 0.0241, Initial Validation Loss: 0.1214, Validation Loss: 0.0289,V Acc: 0.8571, Top 70th Acc: 0.9367, Bottom 30th Acc: 0.6667
Fold [1/5] Epoch [20/100] Initial Loss: 0.1352, Training Loss: 0.0153, Initial Validation Loss: 0.1214, Validation Loss: 0.0265,V Acc: 0.8661, Top 70th Acc: 0.9367, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.9746835443037974
Fold [2/5] Epoch [0/100] Initial Loss: 0.1389, Training Loss: 0.1389, Initial Validation Loss: 0.1306, Validation Loss: 0.1306,V Acc: 0.2883, Top 70th Acc: 0.3462, Bottom 30th Acc: 0.1515
Fold [2/5] Epoch [10/100] Initial Loss: 0.1389, Training Loss: 0.0227, Initial Validation Loss: 0.1306, Validation Loss: 0.0247,V Acc: 0.9189, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.8182
Stopping early at Epoch (base 0): 18  Rolling back to Epoch (base 0): 13  Top Validation Acc: 0.9743589743589743
Fold [3/5] Epoch [0/100] Initial Loss: 0.1421, Training Loss: 0.1421, Initial Validation Loss: 0.1239, Validation Loss: 0.1239,V Acc: 0.3818, Top 70th Acc: 0.4675, Bottom 30th Acc: 0.1818
Fold [3/5] Epoch [10/100] Initial Loss: 0.1421, Training Loss: 0.0232, Initial Validation Loss: 0.1239, Validation Loss: 0.0199,V Acc: 0.9091, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.7576
Fold [3/5] Epoch [20/100] Initial Loss: 0.1421, Training Loss: 0.0168, Initial Validation Loss: 0.1239, Validation Loss: 0.0196,V Acc: 0.9182, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.8182
Stopping early at Epoch (base 0): 20  Rolling back to Epoch (base 0): 15  Top Validation Acc: 0.961038961038961
5 2 [array([0.75738674, 0.01755622, 0.03299605, 0.09660091, 0.09546009],
      dtype=float32)]
Fold [4/5] Epoch [0/100] Initial Loss: 0.1394, Training Loss: 0.1394, Initial Validation Loss: 0.1274, Validation Loss: 0.1274,V Acc: 0.4495, Top 70th Acc: 0.5584, Bottom 30th Acc: 0.1875
Fold [4/5] Epoch [10/100] Initial Loss: 0.1394, Training Loss: 0.0244, Initial Validation Loss: 0.1274, Validation Loss: 0.0306,V Acc: 0.8440, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.5938
Stopping early at Epoch (base 0): 18  Rolling back to Epoch (base 0): 13  Top Validation Acc: 0.974025974025974
Fold [5/5] Epoch [0/100] Initial Loss: 0.1316, Training Loss: 0.1316, Initial Validation Loss: 0.1184, Validation Loss: 0.1184,V Acc: 0.4167, Top 70th Acc: 0.5263, Bottom 30th Acc: 0.1562
Fold [5/5] Epoch [10/100] Initial Loss: 0.1316, Training Loss: 0.0215, Initial Validation Loss: 0.1184, Validation Loss: 0.0281,V Acc: 0.8519, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.5938
Fold [5/5] Epoch [20/100] Initial Loss: 0.1316, Training Loss: 0.0151, Initial Validation Loss: 0.1184, Validation Loss: 0.0211,V Acc: 0.8796, Top 70th Acc: 0.9868, Bottom 30th Acc: 0.6250
Fold [5/5] Epoch [30/100] Initial Loss: 0.1316, Training Loss: 0.0129, Initial Validation Loss: 0.1184, Validation Loss: 0.0247,V Acc: 0.8704, Top 70th Acc: 0.9737, Bottom 30th Acc: 0.6250
Stopping early at Epoch (base 0): 34  Rolling back to Epoch (base 0): 29  Top Validation Acc: 0.9868421052631579
Running train_nn.py with seed 6
CUDA:False
Training samples count:  550
Training on 21 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1285, Training Loss: 0.1285, Initial Validation Loss: 0.1197, Validation Loss: 0.1197,V Acc: 0.4554, Top 70th Acc: 0.5570, Bottom 30th Acc: 0.2121Fold [1/5] Epoch [20/100] Initial Loss: 0.1416, Training Loss: 0.0141, Initial Validation Loss: 0.1344, Validation Loss: 0.0295,V Acc: 0.8482, Top 70th Acc: 0.9494, Bottom 30th Acc: 0.6061
Fold [1/5] Epoch [30/100] Initial Loss: 0.1416, Training Loss: 0.0110, Initial Validation Loss: 0.1344, Validation Loss: 0.0283,V Acc: 0.8571, Top 70th Acc: 0.9367, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 31  Rolling back to Epoch (base 0): 26  Top Validation Acc: 0.9493670886075949
Fold [2/5] Epoch [0/100] Initial Loss: 0.1387, Training Loss: 0.1387, Initial Validation Loss: 0.1356, Validation Loss: 0.1356,V Acc: 0.2523, Top 70th Acc: 0.3462, Bottom 30th Acc: 0.0303
Fold [2/5] Epoch [10/100] Initial Loss: 0.1387, Training Loss: 0.0452, Initial Validation Loss: 0.1356, Validation Loss: 0.0594,V Acc: 0.7117, Top 70th Acc: 0.8333, Bottom 30th Acc: 0.4242
Fold [2/5] Epoch [20/100] Initial Loss: 0.1387, Training Loss: 0.0195, Initial Validation Loss: 0.1356, Validation Loss: 0.0376,V Acc: 0.8378, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.6364
Fold [2/5] Epoch [30/100] Initial Loss: 0.1387, Training Loss: 0.0119, Initial Validation Loss: 0.1356, Validation Loss: 0.0326,V Acc: 0.8649, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.6667
Fold [2/5] Epoch [40/100] Initial Loss: 0.1387, Training Loss: 0.0107, Initial Validation Loss: 0.1356, Validation Loss: 0.0334,V Acc: 0.8378, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 43  Rolling back to Epoch (base 0): 38  Top Validation Acc: 0.9615384615384616
3 1 [array([0.6743238 , 0.04921065, 0.01691111, 0.10250105, 0.15705341],
      dtype=float32)]
Fold [3/5] Epoch [0/100] Initial Loss: 0.1381, Training Loss: 0.1381, Initial Validation Loss: 0.1298, Validation Loss: 0.1298,V Acc: 0.3000, Top 70th Acc: 0.3766, Bottom 30th Acc: 0.1212
Fold [3/5] Epoch [10/100] Initial Loss: 0.1381, Training Loss: 0.0398, Initial Validation Loss: 0.1298, Validation Loss: 0.0396,V Acc: 0.8182, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.5455
Fold [3/5] Epoch [20/100] Initial Loss: 0.1381, Training Loss: 0.0143, Initial Validation Loss: 0.1298, Validation Loss: 0.0250,V Acc: 0.8273, Top 70th Acc: 0.9870, Bottom 30th Acc: 0.4545
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.987012987012987
Fold [4/5] Epoch [0/100] Initial Loss: 0.1375, Training Loss: 0.1375, Initial Validation Loss: 0.1296, Validation Loss: 0.1296,V Acc: 0.4220, Top 70th Acc: 0.5584, Bottom 30th Acc: 0.0938
Fold [4/5] Epoch [10/100] Initial Loss: 0.1375, Training Loss: 0.0232, Initial Validation Loss: 0.1296, Validation Loss: 0.0368,V Acc: 0.7982, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.5000
Fold [4/5] Epoch [20/100] Initial Loss: 0.1375, Training Loss: 0.0131, Initial Validation Loss: 0.1296, Validation Loss: 0.0315,V Acc: 0.7890, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.4688
Fold [4/5] Epoch [30/100] Initial Loss: 0.1375, Training Loss: 0.0110, Initial Validation Loss: 0.1296, Validation Loss: 0.0312,V Acc: 0.7982, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.4375
Fold [4/5] Epoch [40/100] Initial Loss: 0.1375, Training Loss: 0.0101, Initial Validation Loss: 0.1296, Validation Loss: 0.0310,V Acc: 0.7890, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.4062
Stopping early at Epoch (base 0): 40  Rolling back to Epoch (base 0): 35  Top Validation Acc: 0.948051948051948
Fold [5/5] Epoch [0/100] Initial Loss: 0.1408, Training Loss: 0.1408, Initial Validation Loss: 0.1333, Validation Loss: 0.1333,V Acc: 0.2500, Top 70th Acc: 0.3158, Bottom 30th Acc: 0.0938
Fold [5/5] Epoch [10/100] Initial Loss: 0.1408, Training Loss: 0.0417, Initial Validation Loss: 0.1333, Validation Loss: 0.0493,V Acc: 0.7407, Top 70th Acc: 0.8684, Bottom 30th Acc: 0.4375
Fold [5/5] Epoch [20/100] Initial Loss: 0.1408, Training Loss: 0.0174, Initial Validation Loss: 0.1333, Validation Loss: 0.0284,V Acc: 0.8611, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.6562
Fold [5/5] Epoch [30/100] Initial Loss: 0.1408, Training Loss: 0.0124, Initial Validation Loss: 0.1333, Validation Loss: 0.0265,V Acc: 0.8889, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.7188
Stopping early at Epoch (base 0): 31  Rolling back to Epoch (base 0): 26  Top Validation Acc: 0.9473684210526315
Running train_nn.py with seed 4
CUDA:False
Training samples count:  550
Training on 40 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1433, Training Loss: 0.1433, Initial Validation Loss: 0.1386, Validation Loss: 0.1386,V Acc: 0.2857, Top 70th Acc: 0.3671, Bottom 30th Acc: 0.0909
Fold [1/5] Epoch [10/100] Initial Loss: 0.1433, Training Loss: 0.0250, Initial Validation Loss: 0.1386, Validation Loss: 0.0383,V Acc: 0.8214, Top 70th Acc: 0.9620, Bottom 30th Acc: 0.4848
Fold [1/5] Epoch [20/100] Initial Loss: 0.1433, Training Loss: 0.0129, Initial Validation Loss: 0.1386, Validation Loss: 0.0325,V Acc: 0.8214, Top 70th Acc: 0.9494, Bottom 30th Acc: 0.5152
Fold [1/5] Epoch [30/100] Initial Loss: 0.1433, Training Loss: 0.0108, Initial Validation Loss: 0.1386, Validation Loss: 0.0314,V Acc: 0.8482, Top 70th Acc: 0.9620, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 33  Rolling back to Epoch (base 0): 28  Top Validation Acc: 0.9620253164556962
4 0 [array([0.4397456 , 0.14282943, 0.11697854, 0.07312275, 0.22732377],
      dtype=float32)]
Fold [2/5] Epoch [0/100] Initial Loss: 0.1399, Training Loss: 0.1399, Initial Validation Loss: 0.1287, Validation Loss: 0.1287,V Acc: 0.3153, Top 70th Acc: 0.3974, Bottom 30th Acc: 0.1212
Fold [2/5] Epoch [10/100] Initial Loss: 0.1399, Training Loss: 0.0325, Initial Validation Loss: 0.1287, Validation Loss: 0.0315,V Acc: 0.8198, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.4848
Fold [2/5] Epoch [20/100] Initial Loss: 0.1399, Training Loss: 0.0159, Initial Validation Loss: 0.1287, Validation Loss: 0.0262,V Acc: 0.8559, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 28  Rolling back to Epoch (base 0): 23  Top Validation Acc: 0.9487179487179487
Fold [3/5] Epoch [0/100] Initial Loss: 0.1364, Training Loss: 0.1364, Initial Validation Loss: 0.1322, Validation Loss: 0.1322,V Acc: 0.3455, Top 70th Acc: 0.4026, Bottom 30th Acc: 0.2121
Fold [3/5] Epoch [10/100] Initial Loss: 0.1364, Training Loss: 0.0235, Initial Validation Loss: 0.1322, Validation Loss: 0.0360,V Acc: 0.8364, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.6061
Fold [3/5] Epoch [20/100] Initial Loss: 0.1364, Training Loss: 0.0136, Initial Validation Loss: 0.1322, Validation Loss: 0.0331,V Acc: 0.8545, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.6970
Fold [3/5] Epoch [30/100] Initial Loss: 0.1364, Training Loss: 0.0114, Initial Validation Loss: 0.1322, Validation Loss: 0.0320,V Acc: 0.8727, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.7576
Stopping early at Epoch (base 0): 37  Rolling back to Epoch (base 0): 32  Top Validation Acc: 0.935064935064935
Fold [4/5] Epoch [0/100] Initial Loss: 0.1411, Training Loss: 0.1411, Initial Validation Loss: 0.1343, Validation Loss: 0.1343,V Acc: 0.2477, Top 70th Acc: 0.3117, Bottom 30th Acc: 0.0938
Fold [4/5] Epoch [10/100] Initial Loss: 0.1411, Training Loss: 0.0453, Initial Validation Loss: 0.1343, Validation Loss: 0.0493,V Acc: 0.7890, Top 70th Acc: 0.8701, Bottom 30th Acc: 0.5938
Fold [4/5] Epoch [20/100] Initial Loss: 0.1411, Training Loss: 0.0189, Initial Validation Loss: 0.1343, Validation Loss: 0.0301,V Acc: 0.8440, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.6250
Fold [4/5] Epoch [30/100] Initial Loss: 0.1411, Training Loss: 0.0123, Initial Validation Loss: 0.1343, Validation Loss: 0.0284,V Acc: 0.8624, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6562
Stopping early at Epoch (base 0): 33  Rolling back to Epoch (base 0): 28  Top Validation Acc: 0.948051948051948
Fold [5/5] Epoch [0/100] Initial Loss: 0.1376, Training Loss: 0.1376, Initial Validation Loss: 0.1322, Validation Loss: 0.1322,V Acc: 0.2500, Top 70th Acc: 0.3158, Bottom 30th Acc: 0.0938
Fold [5/5] Epoch [10/100] Initial Loss: 0.1376, Training Loss: 0.0400, Initial Validation Loss: 0.1322, Validation Loss: 0.0515,V Acc: 0.7593, Top 70th Acc: 0.8947, Bottom 30th Acc: 0.4375
Fold [5/5] Epoch [20/100] Initial Loss: 0.1376, Training Loss: 0.0164, Initial Validation Loss: 0.1322, Validation Loss: 0.0358,V Acc: 0.8148, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.4688
Fold [1/5] Epoch [10/100] Initial Loss: 0.1391, Training Loss: 0.0438, Initial Validation Loss: 0.1350, Validation Loss: 0.0514,V Acc: 0.7321, Top 70th Acc: 0.8481, Bottom 30th Acc: 0.4545
Fold [1/5] Epoch [20/100] Initial Loss: 0.1391, Training Loss: 0.0262, Initial Validation Loss: 0.1350, Validation Loss: 0.0419,V Acc: 0.7589, Top 70th Acc: 0.9114, Bottom 30th Acc: 0.3939
Fold [1/5] Epoch [30/100] Initial Loss: 0.1391, Training Loss: 0.0173, Initial Validation Loss: 0.1350, Validation Loss: 0.0358,V Acc: 0.8125, Top 70th Acc: 0.9367, Bottom 30th Acc: 0.5152
Stopping early at Epoch (base 0): 35  Rolling back to Epoch (base 0): 30  Top Validation Acc: 0.9367088607594937
Fold [2/5] Epoch [0/100] Initial Loss: 0.1434, Training Loss: 0.1434, Initial Validation Loss: 0.1361, Validation Loss: 0.1361,V Acc: 0.2973, Top 70th Acc: 0.3333, Bottom 30th Acc: 0.2121
Fold [2/5] Epoch [10/100] Initial Loss: 0.1434, Training Loss: 0.0279, Initial Validation Loss: 0.1361, Validation Loss: 0.0384,V Acc: 0.8288, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 17  Rolling back to Epoch (base 0): 12  Top Validation Acc: 0.9487179487179487
3 1 [array([0.56059766, 0.13907722, 0.04715968, 0.13639152, 0.1167739 ],
      dtype=float32)]
Fold [3/5] Epoch [0/100] Initial Loss: 0.1393, Training Loss: 0.1393, Initial Validation Loss: 0.1322, Validation Loss: 0.1322,V Acc: 0.3727, Top 70th Acc: 0.4416, Bottom 30th Acc: 0.2121
Fold [3/5] Epoch [10/100] Initial Loss: 0.1393, Training Loss: 0.0308, Initial Validation Loss: 0.1322, Validation Loss: 0.0306,V Acc: 0.8364, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.5455
Fold [3/5] Epoch [20/100] Initial Loss: 0.1393, Training Loss: 0.0201, Initial Validation Loss: 0.1322, Validation Loss: 0.0265,V Acc: 0.8636, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.974025974025974
Fold [4/5] Epoch [0/100] Initial Loss: 0.1381, Training Loss: 0.1381, Initial Validation Loss: 0.1294, Validation Loss: 0.1294,V Acc: 0.3394, Top 70th Acc: 0.3636, Bottom 30th Acc: 0.2812
Fold [4/5] Epoch [10/100] Initial Loss: 0.1381, Training Loss: 0.0295, Initial Validation Loss: 0.1294, Validation Loss: 0.0421,V Acc: 0.7982, Top 70th Acc: 0.8831, Bottom 30th Acc: 0.5938
Fold [4/5] Epoch [20/100] Initial Loss: 0.1381, Training Loss: 0.0186, Initial Validation Loss: 0.1294, Validation Loss: 0.0386,V Acc: 0.7890, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.5000
Fold [4/5] Epoch [30/100] Initial Loss: 0.1381, Training Loss: 0.0165, Initial Validation Loss: 0.1294, Validation Loss: 0.0374,V Acc: 0.7798, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.4688
Stopping early at Epoch (base 0): 32  Rolling back to Epoch (base 0): 27  Top Validation Acc: 0.9090909090909091
Fold [5/5] Epoch [0/100] Initial Loss: 0.1387, Training Loss: 0.1387, Initial Validation Loss: 0.1339, Validation Loss: 0.1339,V Acc: 0.2315, Top 70th Acc: 0.2368, Bottom 30th Acc: 0.2188
Fold [5/5] Epoch [10/100] Initial Loss: 0.1387, Training Loss: 0.0374, Initial Validation Loss: 0.1339, Validation Loss: 0.0418,V Acc: 0.8148, Top 70th Acc: 0.8684, Bottom 30th Acc: 0.6875
Fold [5/5] Epoch [20/100] Initial Loss: 0.1387, Training Loss: 0.0199, Initial Validation Loss: 0.1339, Validation Loss: 0.0313,V Acc: 0.8519, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.6562
Stopping early at Epoch (base 0): 28  Rolling back to Epoch (base 0): 23  Top Validation Acc: 0.9210526315789473
Running train_nn.py with seed 4
CUDA:False
Training samples count:  550
Training on 30 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1406, Training Loss: 0.1406, Initial Validation Loss: 0.1385, Validation Loss: 0.1385,V Acc: 0.3214, Top 70th Acc: 0.3671, Bottom 30th Acc: 0.2121
Fold [1/5] Epoch [10/100] Initial Loss: 0.1406, Training Loss: 0.0282, Initial Validation Loss: 0.1385, Validation Loss: 0.0403,V Acc: 0.8036, Top 70th Acc: 0.9241, Bottom 30th Acc: 0.5152
Fold [1/5] Epoch [20/100] Initial Loss: 0.1406, Training Loss: 0.0170, Initial Validation Loss: 0.1385, Validation Loss: 0.0368,V Acc: 0.8304, Top 70th Acc: 0.9494, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 20  Rolling back to Epoch (base 0): 15  Top Validation Acc: 0.9493670886075949
4 0 [array([0.5324574 , 0.10573894, 0.09870289, 0.08438515, 0.17871563],
      dtype=float32)]
Fold [2/5] Epoch [0/100] Initial Loss: 0.1407, Training Loss: 0.1407, Initial Validation Loss: 0.1279, Validation Loss: 0.1279,V Acc: 0.4685, Top 70th Acc: 0.5513, Bottom 30th Acc: 0.2727
Fold [2/5] Epoch [10/100] Initial Loss: 0.1407, Training Loss: 0.0356, Initial Validation Loss: 0.1279, Validation Loss: 0.0396,V Acc: 0.7928, Top 70th Acc: 0.8846, Bottom 30th Acc: 0.5758
Fold [2/5] Epoch [20/100] Initial Loss: 0.1407, Training Loss: 0.0209, Initial Validation Loss: 0.1279, Validation Loss: 0.0298,V Acc: 0.8468, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.6667
Fold [2/5] Epoch [30/100] Initial Loss: 0.1407, Training Loss: 0.0174, Initial Validation Loss: 0.1279, Validation Loss: 0.0276,V Acc: 0.8559, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 35  Rolling back to Epoch (base 0): 30  Top Validation Acc: 0.9358974358974359
Fold [3/5] Epoch [0/100] Initial Loss: 0.1386, Training Loss: 0.1386, Initial Validation Loss: 0.1348, Validation Loss: 0.1348,V Acc: 0.2909, Top 70th Acc: 0.3377, Bottom 30th Acc: 0.1818
Fold [3/5] Epoch [10/100] Initial Loss: 0.1386, Training Loss: 0.0411, Initial Validation Loss: 0.1348, Validation Loss: 0.0479,V Acc: 0.7636, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.4242
Fold [3/5] Epoch [20/100] Initial Loss: 0.1386, Training Loss: 0.0193, Initial Validation Loss: 0.1348, Validation Loss: 0.0323,V Acc: 0.8364, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.5152
Stopping early at Epoch (base 0): 29  Rolling back to Epoch (base 0): 24  Top Validation Acc: 0.961038961038961
Fold [4/5] Epoch [0/100] Initial Loss: 0.1420, Training Loss: 0.1420, Initial Validation Loss: 0.1328, Validation Loss: 0.1328,V Acc: 0.2477, Top 70th Acc: 0.3377, Bottom 30th Acc: 0.0312
Fold [4/5] Epoch [10/100] Initial Loss: 0.1420, Training Loss: 0.0378, Initial Validation Loss: 0.1328, Validation Loss: 0.0397,V Acc: 0.8257, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.5625
Fold [4/5] Epoch [20/100] Initial Loss: 0.1420, Training Loss: 0.0208, Initial Validation Loss: 0.1328, Validation Loss: 0.0316,V Acc: 0.8165, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.5312
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.935064935064935
Fold [5/5] Epoch [0/100] Initial Loss: 0.1384, Training Loss: 0.1384, Initial Validation Loss: 0.1314, Validation Loss: 0.1314,V Acc: 0.4074, Top 70th Acc: 0.4737, Bottom 30th Acc: 0.2500
Fold [5/5] Epoch [10/100] Initial Loss: 0.1384, Training Loss: 0.0287, Initial Validation Loss: 0.1314, Validation Loss: 0.0406,V Acc: 0.8148, Top 70th Acc: 0.9079, Bottom 30th Acc: 0.5938
Fold [5/5] Epoch [20/100] Initial Loss: 0.1384, Training Loss: 0.0182, Initial Validation Loss: 0.1314, Validation Loss: 0.0360,V Acc: 0.8056, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.4688
Stopping early at Epoch (base 0): 21  Rolling back to Epoch (base 0): 16  Top Validation Acc: 0.9342105263157895
Running train_nn.py with seed 5
CUDA:False
Training samples count:  550
Training on 30 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1420, Training Loss: 0.1420, Initial Validation Loss: 0.1379, Validation Loss: 0.1379,V Acc: 0.3304, Top 70th Acc: 0.3291, Bottom 30th Acc: 0.3333
Fold [1/5] Epoch [10/100] Initial Loss: 0.1420, Training Loss: 0.0366, Initial Validation Loss: 0.1379, Validation Loss: 0.0428,V Acc: 0.8036, Top 70th Acc: 0.8861, Bottom 30th Acc: 0.6061
Fold [1/5] Epoch [20/100] Initial Loss: 0.1420, Training Loss: 0.0191, Initial Validation Loss: 0.1379, Validation Loss: 0.0311,V Acc: 0.8393, Top 70th Acc: 0.9367, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.9493670886075949
Fold [2/5] Epoch [0/100] Initial Loss: 0.1398, Training Loss: 0.1398, Initial Validation Loss: 0.1341, Validation Loss: 0.1341,V Acc: 0.3153, Top 70th Acc: 0.3333, Bottom 30th Acc: 0.2727 43  Rolling back to Epoch (base 0): 38  Top Validation Acc: 0.75
Running train_nn.py with seed 3
CUDA:False
Training samples count:  550
Training on 2 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1346, Training Loss: 0.1346, Initial Validation Loss: 0.1198, Validation Loss: 0.1198,V Acc: 0.4018, Top 70th Acc: 0.5316, Bottom 30th Acc: 0.0909
Fold [1/5] Epoch [10/100] Initial Loss: 0.1346, Training Loss: 0.0819, Initial Validation Loss: 0.1198, Validation Loss: 0.0726,V Acc: 0.6339, Top 70th Acc: 0.7595, Bottom 30th Acc: 0.3333
Fold [1/5] Epoch [20/100] Initial Loss: 0.1346, Training Loss: 0.0804, Initial Validation Loss: 0.1198, Validation Loss: 0.0716,V Acc: 0.6607, Top 70th Acc: 0.7468, Bottom 30th Acc: 0.4545
Fold [1/5] Epoch [30/100] Initial Loss: 0.1346, Training Loss: 0.0796, Initial Validation Loss: 0.1198, Validation Loss: 0.0711,V Acc: 0.6518, Top 70th Acc: 0.7595, Bottom 30th Acc: 0.3939
Fold [1/5] Epoch [40/100] Initial Loss: 0.1346, Training Loss: 0.0797, Initial Validation Loss: 0.1198, Validation Loss: 0.0706,V Acc: 0.6607, Top 70th Acc: 0.7722, Bottom 30th Acc: 0.3939
Fold [1/5] Epoch [50/100] Initial Loss: 0.1346, Training Loss: 0.0793, Initial Validation Loss: 0.1198, Validation Loss: 0.0701,V Acc: 0.6429, Top 70th Acc: 0.7595, Bottom 30th Acc: 0.3636
Fold [1/5] Epoch [60/100] Initial Loss: 0.1346, Training Loss: 0.0791, Initial Validation Loss: 0.1198, Validation Loss: 0.0697,V Acc: 0.6429, Top 70th Acc: 0.7595, Bottom 30th Acc: 0.3636
Fold [1/5] Epoch [70/100] Initial Loss: 0.1346, Training Loss: 0.0791, Initial Validation Loss: 0.1198, Validation Loss: 0.0696,V Acc: 0.6518, Top 70th Acc: 0.7722, Bottom 30th Acc: 0.3636
Stopping early at Epoch (base 0): 74  Rolling back to Epoch (base 0): 69  Top Validation Acc: 0.7721518987341772
Fold [2/5] Epoch [0/100] Initial Loss: 0.1331, Training Loss: 0.1331, Initial Validation Loss: 0.1243, Validation Loss: 0.1243,V Acc: 0.4054, Top 70th Acc: 0.5385, Bottom 30th Acc: 0.0909
Fold [2/5] Epoch [10/100] Initial Loss: 0.1331, Training Loss: 0.0781, Initial Validation Loss: 0.1243, Validation Loss: 0.0902,V Acc: 0.5856, Top 70th Acc: 0.6667, Bottom 30th Acc: 0.3939
Fold [2/5] Epoch [20/100] Initial Loss: 0.1331, Training Loss: 0.0745, Initial Validation Loss: 0.1243, Validation Loss: 0.0910,V Acc: 0.5946, Top 70th Acc: 0.6667, Bottom 30th Acc: 0.4242
Stopping early at Epoch (base 0): 22  Rolling back to Epoch (base 0): 17  Top Validation Acc: 0.6666666666666666
3 1 [array([0.10837995, 0.39094025, 0.1525528 , 0.21522522, 0.13290171],
      dtype=float32)]
Fold [3/5] Epoch [0/100] Initial Loss: 0.1402, Training Loss: 0.1402, Initial Validation Loss: 0.1297, Validation Loss: 0.1297,V Acc: 0.4000, Top 70th Acc: 0.3506, Bottom 30th Acc: 0.5152
Fold [3/5] Epoch [10/100] Initial Loss: 0.1402, Training Loss: 0.0841, Initial Validation Loss: 0.1297, Validation Loss: 0.0733,V Acc: 0.6455, Top 70th Acc: 0.7532, Bottom 30th Acc: 0.3939
Fold [3/5] Epoch [20/100] Initial Loss: 0.1402, Training Loss: 0.0812, Initial Validation Loss: 0.1297, Validation Loss: 0.0709,V Acc: 0.6727, Top 70th Acc: 0.7792, Bottom 30th Acc: 0.4242
Fold [3/5] Epoch [30/100] Initial Loss: 0.1402, Training Loss: 0.0800, Initial Validation Loss: 0.1297, Validation Loss: 0.0717,V Acc: 0.6727, Top 70th Acc: 0.7922, Bottom 30th Acc: 0.3939
Fold [3/5] Epoch [40/100] Initial Loss: 0.1402, Training Loss: 0.0801, Initial Validation Loss: 0.1297, Validation Loss: 0.0698,V Acc: 0.6818, Top 70th Acc: 0.8312, Bottom 30th Acc: 0.3333
Fold [3/5] Epoch [50/100] Initial Loss: 0.1402, Training Loss: 0.0797, Initial Validation Loss: 0.1297, Validation Loss: 0.0697,V Acc: 0.6909, Top 70th Acc: 0.8052, Bottom 30th Acc: 0.4242
Stopping early at Epoch (base 0): 51  Rolling back to Epoch (base 0): 46  Top Validation Acc: 0.8181818181818182
Fold [4/5] Epoch [0/100] Initial Loss: 0.1301, Training Loss: 0.1301, Initial Validation Loss: 0.1154, Validation Loss: 0.1154,V Acc: 0.5046, Top 70th Acc: 0.6104, Bottom 30th Acc: 0.2500
Fold [4/5] Epoch [10/100] Initial Loss: 0.1301, Training Loss: 0.0810, Initial Validation Loss: 0.1154, Validation Loss: 0.0809,V Acc: 0.5963, Top 70th Acc: 0.7532, Bottom 30th Acc: 0.2188
Fold [4/5] Epoch [20/100] Initial Loss: 0.1301, Training Loss: 0.0793, Initial Validation Loss: 0.1154, Validation Loss: 0.0790,V Acc: 0.6147, Top 70th Acc: 0.7532, Bottom 30th Acc: 0.2812
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.7532467532467533
Fold [5/5] Epoch [0/100] Initial Loss: 0.1429, Training Loss: 0.1429, Initial Validation Loss: 0.1343, Validation Loss: 0.1343,V Acc: 0.2500, Top 70th Acc: 0.3553, Bottom 30th Acc: 0.0000
Fold [5/5] Epoch [10/100] Initial Loss: 0.1429, Training Loss: 0.0810, Initial Validation Loss: 0.1343, Validation Loss: 0.0817,V Acc: 0.6296, Top 70th Acc: 0.7632, Bottom 30th Acc: 0.3125
Fold [5/5] Epoch [20/100] Initial Loss: 0.1429, Training Loss: 0.0790, Initial Validation Loss: 0.1343, Validation Loss: 0.0784,V Acc: 0.6389, Top 70th Acc: 0.7368, Bottom 30th Acc: 0.4062
Stopping early at Epoch (base 0): 22  Rolling back to Epoch (base 0): 17  Top Validation Acc: 0.7368421052631579
Running train_nn.py with seed 4
CUDA:False
Training samples count:  550
Training on 2 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1337, Training Loss: 0.1337, Initial Validation Loss: 0.1263, Validation Loss: 0.1263,V Acc: 0.3661, Top 70th Acc: 0.4937, Bottom 30th Acc: 0.0606
Fold [1/5] Epoch [10/100] Initial Loss: 0.1337, Training Loss: 0.0820, Initial Validation Loss: 0.1263, Validation Loss: 0.0795,V Acc: 0.5893, Top 70th Acc: 0.7468, Bottom 30th Acc: 0.2121
Fold [1/5] Epoch [20/100] Initial Loss: 0.1337, Training Loss: 0.0798, Initial Validation Loss: 0.1263, Validation Loss: 0.0781,V Acc: 0.6250, Top 70th Acc: 0.7468, Bottom 30th Acc: 0.3333
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.7468354430379747
4 0 [array([0.10661996, 0.3554576 , 0.17863321, 0.2054449 , 0.15384428],
      dtype=float32)]
Fold [2/5] Epoch [0/100] Initial Loss: 0.1389, Training Loss: 0.1389, Initial Validation Loss: 0.1260, Validation Loss: 0.1260,V Acc: 0.4865, Top 70th Acc: 0.5256, Bottom 30th Acc: 0.3939
Fold [2/5] Epoch [10/100] Initial Loss: 0.1389, Training Loss: 0.0825, Initial Validation Loss: 0.1260, Validation Loss: 0.0710,V Acc: 0.6396, Top 70th Acc: 0.8077, Bottom 30th Acc: 0.2424
Fold [2/5] Epoch [20/100] Initial Loss: 0.1389, Training Loss: 0.0815, Initial Validation Loss: 0.1260, Validation Loss: 0.0691,V Acc: 0.6486, Top 70th Acc: 0.7949, Bottom 30th Acc: 0.3030
Fold [2/5] Epoch [30/100] Initial Loss: 0.1389, Training Loss: 0.0811, Initial Validation Loss: 0.1260, Validation Loss: 0.0699,V Acc: 0.6486, Top 70th Acc: 0.7949, Bottom 30th Acc: 0.3030
Stopping early at Epoch (base 0): 34  Rolling back to Epoch (base 0): 29  Top Validation Acc: 0.782051282051282
Fold [3/5] Epoch [0/100] Initial Loss: 0.1408, Training Loss: 0.1408, Initial Validation Loss: 0.1311, Validation Loss: 0.1311,V Acc: 0.4545, Top 70th Acc: 0.5844, Bottom 30th Acc: 0.1515
Fold [3/5] Epoch [10/100] Initial Loss: 0.1408, Training Loss: 0.0805, Initial Validation Loss: 0.1311, Validation Loss: 0.0799,V Acc: 0.6364, Top 70th Acc: 0.7532, Bottom 30th Acc: 0.3636
Fold [3/5] Epoch [20/100] Initial Loss: 0.1408, Training Loss: 0.0778, Initial Validation Loss: 0.1311, Validation Loss: 0.0788,V Acc: 0.6545, Top 70th Acc: 0.7013, Bottom 30th Acc: 0.5455
Fold [3/5] Epoch [30/100] Initial Loss: 0.1408, Training Loss: 0.0772, Initial Validation Loss: 0.1311, Validation Loss: 0.0778,V Acc: 0.6545, Top 70th Acc: 0.7403, Bottom 30th Acc: 0.4545
Stopping early at Epoch (base 0): 37  Rolling back to Epoch (base 0): 32  Top Validation Acc: 0.7272727272727273
Fold [4/5] Epoch [0/100] Initial Loss: 0.1380, Training Loss: 0.1380, Initial Validation Loss: 0.1281, Validation Loss: 0.1281,V Acc: 0.2661, Top 70th Acc: 0.3377, Bottom 30th Acc: 0.0938
Fold [4/5] Epoch [10/100] Initial Loss: 0.1380, Training Loss: 0.0791, Initial Validation Loss: 0.1281, Validation Loss: 0.0813,V Acc: 0.6239, Top 70th Acc: 0.6883, Bottom 30th Acc: 0.4688
Fold [4/5] Epoch [20/100] Initial Loss: 0.1380, Training Loss: 0.0772, Initial Validation Loss: 0.1281, Validation Loss: 0.0810,V Acc: 0.6147, Top 70th Acc: 0.7273, Bottom 30th Acc: 0.3438
Fold [2/5] Epoch [20/100] Initial Loss: 0.1398, Training Loss: 0.0218, Initial Validation Loss: 0.1362, Validation Loss: 0.0370,V Acc: 0.8559, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 29  Rolling back to Epoch (base 0): 24  Top Validation Acc: 0.9358974358974359
3 1 [array([0.32173657, 0.09350632, 0.07302382, 0.35609114, 0.15564208],
      dtype=float32)]
Fold [3/5] Epoch [0/100] Initial Loss: 0.1399, Training Loss: 0.1399, Initial Validation Loss: 0.1312, Validation Loss: 0.1312,V Acc: 0.3091, Top 70th Acc: 0.3766, Bottom 30th Acc: 0.1515
Fold [3/5] Epoch [10/100] Initial Loss: 0.1399, Training Loss: 0.0412, Initial Validation Loss: 0.1312, Validation Loss: 0.0345,V Acc: 0.8545, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.6061
Fold [3/5] Epoch [20/100] Initial Loss: 0.1399, Training Loss: 0.0250, Initial Validation Loss: 0.1312, Validation Loss: 0.0284,V Acc: 0.8455, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.5758
Fold [3/5] Epoch [30/100] Initial Loss: 0.1399, Training Loss: 0.0228, Initial Validation Loss: 0.1312, Validation Loss: 0.0257,V Acc: 0.8455, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 36  Rolling back to Epoch (base 0): 31  Top Validation Acc: 0.961038961038961
Fold [4/5] Epoch [0/100] Initial Loss: 0.1408, Training Loss: 0.1408, Initial Validation Loss: 0.1307, Validation Loss: 0.1307,V Acc: 0.3853, Top 70th Acc: 0.4156, Bottom 30th Acc: 0.3125
Fold [4/5] Epoch [10/100] Initial Loss: 0.1408, Training Loss: 0.0360, Initial Validation Loss: 0.1307, Validation Loss: 0.0410,V Acc: 0.8073, Top 70th Acc: 0.8961, Bottom 30th Acc: 0.5938
Stopping early at Epoch (base 0): 19  Rolling back to Epoch (base 0): 14  Top Validation Acc: 0.8961038961038961
Fold [5/5] Epoch [0/100] Initial Loss: 0.1391, Training Loss: 0.1391, Initial Validation Loss: 0.1347, Validation Loss: 0.1347,V Acc: 0.3241, Top 70th Acc: 0.3289, Bottom 30th Acc: 0.3125
Fold [5/5] Epoch [10/100] Initial Loss: 0.1391, Training Loss: 0.0423, Initial Validation Loss: 0.1347, Validation Loss: 0.0473,V Acc: 0.7500, Top 70th Acc: 0.8684, Bottom 30th Acc: 0.4688
Fold [5/5] Epoch [20/100] Initial Loss: 0.1391, Training Loss: 0.0232, Initial Validation Loss: 0.1347, Validation Loss: 0.0321,V Acc: 0.8148, Top 70th Acc: 0.9211, Bottom 30th Acc: 0.5625
Fold [5/5] Epoch [30/100] Initial Loss: 0.1391, Training Loss: 0.0208, Initial Validation Loss: 0.1347, Validation Loss: 0.0303,V Acc: 0.8426, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.5938
Stopping early at Epoch (base 0): 30  Rolling back to Epoch (base 0): 25  Top Validation Acc: 0.9473684210526315
Running train_nn.py with seed 4
CUDA:False
Training samples count:  550
Training on 20 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1399, Training Loss: 0.1399, Initial Validation Loss: 0.1368, Validation Loss: 0.1368,V Acc: 0.2857, Top 70th Acc: 0.3165, Bottom 30th Acc: 0.2121
Fold [1/5] Epoch [10/100] Initial Loss: 0.1399, Training Loss: 0.0404, Initial Validation Loss: 0.1368, Validation Loss: 0.0480,V Acc: 0.7589, Top 70th Acc: 0.8861, Bottom 30th Acc: 0.4545
Fold [1/5] Epoch [20/100] Initial Loss: 0.1399, Training Loss: 0.0230, Initial Validation Loss: 0.1368, Validation Loss: 0.0345,V Acc: 0.8393, Top 70th Acc: 0.9494, Bottom 30th Acc: 0.5758
Fold [1/5] Epoch [30/100] Initial Loss: 0.1399, Training Loss: 0.0210, Initial Validation Loss: 0.1368, Validation Loss: 0.0323,V Acc: 0.8482, Top 70th Acc: 0.9494, Bottom 30th Acc: 0.6061
Fold [1/5] Epoch [40/100] Initial Loss: 0.1399, Training Loss: 0.0200, Initial Validation Loss: 0.1368, Validation Loss: 0.0324,V Acc: 0.8304, Top 70th Acc: 0.9494, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 48  Rolling back to Epoch (base 0): 43  Top Validation Acc: 0.9493670886075949
4 0 [array([0.53930336, 0.13996407, 0.11921319, 0.15266478, 0.04885451],
      dtype=float32)]
Fold [2/5] Epoch [0/100] Initial Loss: 0.1418, Training Loss: 0.1418, Initial Validation Loss: 0.1349, Validation Loss: 0.1349,V Acc: 0.2793, Top 70th Acc: 0.2692, Bottom 30th Acc: 0.3030
Fold [2/5] Epoch [10/100] Initial Loss: 0.1418, Training Loss: 0.0330, Initial Validation Loss: 0.1349, Validation Loss: 0.0342,V Acc: 0.8108, Top 70th Acc: 0.8974, Bottom 30th Acc: 0.6061
Fold [2/5] Epoch [20/100] Initial Loss: 0.1418, Training Loss: 0.0236, Initial Validation Loss: 0.1349, Validation Loss: 0.0309,V Acc: 0.8468, Top 70th Acc: 0.8846, Bottom 30th Acc: 0.7576
Fold [2/5] Epoch [30/100] Initial Loss: 0.1418, Training Loss: 0.0214, Initial Validation Loss: 0.1349, Validation Loss: 0.0290,V Acc: 0.8468, Top 70th Acc: 0.8846, Bottom 30th Acc: 0.7576
Stopping early at Epoch (base 0): 35  Rolling back to Epoch (base 0): 30  Top Validation Acc: 0.8974358974358975
Fold [3/5] Epoch [0/100] Initial Loss: 0.1401, Training Loss: 0.1401, Initial Validation Loss: 0.1335, Validation Loss: 0.1335,V Acc: 0.4182, Top 70th Acc: 0.4286, Bottom 30th Acc: 0.3939
Fold [3/5] Epoch [10/100] Initial Loss: 0.1401, Training Loss: 0.0324, Initial Validation Loss: 0.1335, Validation Loss: 0.0392,V Acc: 0.8091, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.4848
Fold [3/5] Epoch [20/100] Initial Loss: 0.1401, Training Loss: 0.0229, Initial Validation Loss: 0.1335, Validation Loss: 0.0318,V Acc: 0.8364, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.5152
Stopping early at Epoch (base 0): 29  Rolling back to Epoch (base 0): 24  Top Validation Acc: 0.948051948051948
Fold [4/5] Epoch [0/100] Initial Loss: 0.1389, Training Loss: 0.1389, Initial Validation Loss: 0.1309, Validation Loss: 0.1309,V Acc: 0.3670, Top 70th Acc: 0.4286, Bottom 30th Acc: 0.2188
Fold [4/5] Epoch [10/100] Initial Loss: 0.1389, Training Loss: 0.0359, Initial Validation Loss: 0.1309, Validation Loss: 0.0352,V Acc: 0.8624, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.7188
Fold [4/5] Epoch [20/100] Initial Loss: 0.1389, Training Loss: 0.0247, Initial Validation Loss: 0.1309, Validation Loss: 0.0279,V Acc: 0.8807, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.7812
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.948051948051948
Fold [5/5] Epoch [0/100] Initial Loss: 0.1392, Training Loss: 0.1392, Initial Validation Loss: 0.1320, Validation Loss: 0.1320,V Acc: 0.2778, Top 70th Acc: 0.3158, Bottom 30th Acc: 0.1875
Fold [5/5] Epoch [10/100] Initial Loss: 0.1392, Training Loss: 0.0456, Initial Validation Loss: 0.1320, Validation Loss: 0.0554,V Acc: 0.7037, Top 70th Acc: 0.8421, Bottom 30th Acc: 0.3750
Fold [5/5] Epoch [20/100] Initial Loss: 0.1392, Training Loss: 0.0236, Initial Validation Loss: 0.1320, Validation Loss: 0.0374,V Acc: 0.8148, Top 70th Acc: 0.8947, Bottom 30th Acc: 0.6250
Fold [5/5] Epoch [30/100] Initial Loss: 0.1392, Training Loss: 0.0203, Initial Validation Loss: 0.1320, Validation Loss: 0.0352,V Acc: 0.8241, Top 70th Acc: 0.9079, Bottom 30th Acc: 0.6250
Stopping early at Epoch (base 0): 38  Rolling back to Epoch (base 0): 33  Top Validation Acc: 0.9078947368421053
Running train_nn.py with seed 5
CUDA:False
Training samples count:  550
Training on 20 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1404, Training Loss: 0.1404, Initial Validation Loss: 0.1362, Validation Loss: 0.1362,V Acc: 0.3661, Top 70th Acc: 0.4177, Bottom 30th Acc: 0.2424
Fold [1/5] Epoch [10/100] Initial Loss: 0.1404, Training Loss: 0.0421, Initial Validation Loss: 0.1362, Validation Loss: 0.0489,V Acc: 0.7768, Top 70th Acc: 0.8481, Bottom 30th Acc: 0.6061
Fold [1/5] Epoch [20/100] Initial Loss: 0.1404, Training Loss: 0.0261, Initial Validation Loss: 0.1362, Validation Loss: 0.0352,V Acc: 0.8393, Top 70th Acc: 0.9241, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 29  Rolling back to Epoch (base 0): 24  Top Validation Acc: 0.9113924050632911
Fold [2/5] Epoch [0/100] Initial Loss: 0.1437, Training Loss: 0.1437, Initial Validation Loss: 0.1369, Validation Loss: 0.1369,V Acc: 0.2703, Top 70th Acc: 0.3077, Bottom 30th Acc: 0.1818
Fold [2/5] Epoch [10/100] Initial Loss: 0.1437, Training Loss: 0.0511, Initial Validation Loss: 0.1369, Validation Loss: 0.0536,V Acc: 0.7477, Top 70th Acc: 0.8590, Bottom 30th Acc: 0.4848
Fold [2/5] Epoch [20/100] Initial Loss: 0.1437, Training Loss: 0.0258, Initial Validation Loss: 0.1369, Validation Loss: 0.0412,V Acc: 0.7838, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.4848training rf with seed 1
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 2 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 2
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 2 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 3
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 2 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 4
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 2 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 5
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 2 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 6
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 2 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 7
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 2 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 8
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 2 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 9
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 2 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 10
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 2 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 11
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 2 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 12
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 2 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 13
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 2 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 14
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 2 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 15
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 2 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 16
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 2 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 17
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 2 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 18
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 2 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 19
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 2 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 20
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 2 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 21
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 2 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 22
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 2 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 23
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 2 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 24
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 2 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 25
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 2 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 26
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 2 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 27
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 2 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 28
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 2 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 29
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 2 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 30
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 2 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 31
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 2 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 32
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 2 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 33
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 2 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 34
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 2 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 35
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 2 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 36
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 2 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 37
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 2 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 38
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 2 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 39
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 2 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 40
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 2 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 41
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 2 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 42
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 2 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 43
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 2 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 44
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 2 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 45
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 2 features
Fold: 1
Fold [3/5] Epoch [70/100] Initial Loss: 0.1403, Training Loss: 0.0037, Initial Validation Loss: 0.1320, Validation Loss: 0.0353,V Acc: 0.7909, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.4848
Fold [3/5] Epoch [80/100] Initial Loss: 0.1403, Training Loss: 0.0036, Initial Validation Loss: 0.1320, Validation Loss: 0.0345,V Acc: 0.8091, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 85  Rolling back to Epoch (base 0): 80  Top Validation Acc: 0.922077922077922
Fold [4/5] Epoch [0/100] Initial Loss: 0.1387, Training Loss: 0.1387, Initial Validation Loss: 0.1331, Validation Loss: 0.1331,V Acc: 0.3853, Top 70th Acc: 0.4416, Bottom 30th Acc: 0.2500
Fold [4/5] Epoch [10/100] Initial Loss: 0.1387, Training Loss: 0.0134, Initial Validation Loss: 0.1331, Validation Loss: 0.0302,V Acc: 0.8716, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6875
Fold [4/5] Epoch [20/100] Initial Loss: 0.1387, Training Loss: 0.0050, Initial Validation Loss: 0.1331, Validation Loss: 0.0267,V Acc: 0.8624, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.6250
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.961038961038961
Fold [5/5] Epoch [0/100] Initial Loss: 0.1393, Training Loss: 0.1393, Initial Validation Loss: 0.1320, Validation Loss: 0.1320,V Acc: 0.4352, Top 70th Acc: 0.5263, Bottom 30th Acc: 0.2188
Fold [5/5] Epoch [10/100] Initial Loss: 0.1393, Training Loss: 0.0137, Initial Validation Loss: 0.1320, Validation Loss: 0.0298,V Acc: 0.8889, Top 70th Acc: 1.0000, Bottom 30th Acc: 0.6250
Fold [5/5] Epoch [20/100] Initial Loss: 0.1393, Training Loss: 0.0048, Initial Validation Loss: 0.1320, Validation Loss: 0.0248,V Acc: 0.8796, Top 70th Acc: 1.0000, Bottom 30th Acc: 0.5938
Fold [5/5] Epoch [30/100] Initial Loss: 0.1393, Training Loss: 0.0038, Initial Validation Loss: 0.1320, Validation Loss: 0.0232,V Acc: 0.9167, Top 70th Acc: 1.0000, Bottom 30th Acc: 0.7188
Stopping early at Epoch (base 0): 38  Rolling back to Epoch (base 0): 33  Top Validation Acc: 1.0
Running train_nn.py with seed 3
CUDA:False
Training samples count:  550
Training on 162 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1412, Training Loss: 0.1412, Initial Validation Loss: 0.1352, Validation Loss: 0.1352,V Acc: 0.2500, Top 70th Acc: 0.2785, Bottom 30th Acc: 0.1818
Fold [1/5] Epoch [10/100] Initial Loss: 0.1412, Training Loss: 0.0314, Initial Validation Loss: 0.1352, Validation Loss: 0.0469,V Acc: 0.7500, Top 70th Acc: 0.8987, Bottom 30th Acc: 0.3939
Fold [1/5] Epoch [20/100] Initial Loss: 0.1412, Training Loss: 0.0066, Initial Validation Loss: 0.1352, Validation Loss: 0.0353,V Acc: 0.7857, Top 70th Acc: 0.9241, Bottom 30th Acc: 0.4545
Fold [1/5] Epoch [30/100] Initial Loss: 0.1412, Training Loss: 0.0042, Initial Validation Loss: 0.1352, Validation Loss: 0.0331,V Acc: 0.7946, Top 70th Acc: 0.9367, Bottom 30th Acc: 0.4545
Fold [1/5] Epoch [40/100] Initial Loss: 0.1412, Training Loss: 0.0037, Initial Validation Loss: 0.1352, Validation Loss: 0.0324,V Acc: 0.8036, Top 70th Acc: 0.9367, Bottom 30th Acc: 0.4848
Fold [1/5] Epoch [50/100] Initial Loss: 0.1412, Training Loss: 0.0034, Initial Validation Loss: 0.1352, Validation Loss: 0.0316,V Acc: 0.8125, Top 70th Acc: 0.9367, Bottom 30th Acc: 0.5152
Fold [1/5] Epoch [60/100] Initial Loss: 0.1412, Training Loss: 0.0033, Initial Validation Loss: 0.1352, Validation Loss: 0.0312,V Acc: 0.8125, Top 70th Acc: 0.9367, Bottom 30th Acc: 0.5152
Fold [1/5] Epoch [70/100] Initial Loss: 0.1412, Training Loss: 0.0033, Initial Validation Loss: 0.1352, Validation Loss: 0.0308,V Acc: 0.8214, Top 70th Acc: 0.9494, Bottom 30th Acc: 0.5152
Fold [1/5] Epoch [80/100] Initial Loss: 0.1412, Training Loss: 0.0032, Initial Validation Loss: 0.1352, Validation Loss: 0.0304,V Acc: 0.8214, Top 70th Acc: 0.9494, Bottom 30th Acc: 0.5152
Fold [1/5] Epoch [90/100] Initial Loss: 0.1412, Training Loss: 0.0032, Initial Validation Loss: 0.1352, Validation Loss: 0.0301,V Acc: 0.8214, Top 70th Acc: 0.9620, Bottom 30th Acc: 0.4848
Stopping early at Epoch (base 0): 98  Rolling back to Epoch (base 0): 93  Top Validation Acc: 0.9620253164556962
Fold [2/5] Epoch [0/100] Initial Loss: 0.1376, Training Loss: 0.1376, Initial Validation Loss: 0.1337, Validation Loss: 0.1337,V Acc: 0.3784, Top 70th Acc: 0.3974, Bottom 30th Acc: 0.3333
Fold [2/5] Epoch [10/100] Initial Loss: 0.1376, Training Loss: 0.0175, Initial Validation Loss: 0.1337, Validation Loss: 0.0387,V Acc: 0.8198, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.5758
Fold [2/5] Epoch [20/100] Initial Loss: 0.1376, Training Loss: 0.0055, Initial Validation Loss: 0.1337, Validation Loss: 0.0350,V Acc: 0.8288, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.5455
Fold [2/5] Epoch [30/100] Initial Loss: 0.1376, Training Loss: 0.0043, Initial Validation Loss: 0.1337, Validation Loss: 0.0334,V Acc: 0.8378, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.5758
Fold [2/5] Epoch [40/100] Initial Loss: 0.1376, Training Loss: 0.0039, Initial Validation Loss: 0.1337, Validation Loss: 0.0317,V Acc: 0.8468, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 44  Rolling back to Epoch (base 0): 39  Top Validation Acc: 0.9743589743589743
3 1 [array([0.19924623, 0.0776329 , 0.04310104, 0.2894003 , 0.39061955],
      dtype=float32)]
Fold [3/5] Epoch [0/100] Initial Loss: 0.1386, Training Loss: 0.1386, Initial Validation Loss: 0.1311, Validation Loss: 0.1311,V Acc: 0.3727, Top 70th Acc: 0.4805, Bottom 30th Acc: 0.1212
Fold [3/5] Epoch [10/100] Initial Loss: 0.1386, Training Loss: 0.0137, Initial Validation Loss: 0.1311, Validation Loss: 0.0262,V Acc: 0.8455, Top 70th Acc: 0.9870, Bottom 30th Acc: 0.5152
Fold [3/5] Epoch [20/100] Initial Loss: 0.1386, Training Loss: 0.0048, Initial Validation Loss: 0.1311, Validation Loss: 0.0236,V Acc: 0.8727, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 21  Rolling back to Epoch (base 0): 16  Top Validation Acc: 0.987012987012987
Fold [4/5] Epoch [0/100] Initial Loss: 0.1393, Training Loss: 0.1393, Initial Validation Loss: 0.1335, Validation Loss: 0.1335,V Acc: 0.2477, Top 70th Acc: 0.2987, Bottom 30th Acc: 0.1250
Fold [4/5] Epoch [10/100] Initial Loss: 0.1393, Training Loss: 0.0211, Initial Validation Loss: 0.1335, Validation Loss: 0.0370,V Acc: 0.8073, Top 70th Acc: 0.8961, Bottom 30th Acc: 0.5938
Fold [4/5] Epoch [20/100] Initial Loss: 0.1393, Training Loss: 0.0058, Initial Validation Loss: 0.1335, Validation Loss: 0.0301,V Acc: 0.8257, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.5312
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.948051948051948
Fold [5/5] Epoch [0/100] Initial Loss: 0.1381, Training Loss: 0.1381, Initial Validation Loss: 0.1336, Validation Loss: 0.1336,V Acc: 0.3148, Top 70th Acc: 0.4079, Bottom 30th Acc: 0.0938
Fold [5/5] Epoch [10/100] Initial Loss: 0.1381, Training Loss: 0.0177, Initial Validation Loss: 0.1336, Validation Loss: 0.0360,V Acc: 0.8426, Top 70th Acc: 0.9079, Bottom 30th Acc: 0.6875
Fold [5/5] Epoch [20/100] Initial Loss: 0.1381, Training Loss: 0.0053, Initial Validation Loss: 0.1336, Validation Loss: 0.0309,V Acc: 0.8519, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.6562
Fold [5/5] Epoch [30/100] Initial Loss: 0.1381, Training Loss: 0.0041, Initial Validation Loss: 0.1336, Validation Loss: 0.0286,V Acc: 0.8519, Top 70th Acc: 0.9737, Bottom 30th Acc: 0.5625
Fold [5/5] Epoch [40/100] Initial Loss: 0.1381, Training Loss: 0.0037, Initial Validation Loss: 0.1336, Validation Loss: 0.0277,V Acc: 0.8519, Top 70th Acc: 0.9868, Bottom 30th Acc: 0.5312
Stopping early at Epoch (base 0): 45  Rolling back to Epoch (base 0): 40  Top Validation Acc: 0.9868421052631579
Running train_nn.py with seed 4
CUDA:False
Training samples count:  550
Training on 162 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1409, Training Loss: 0.1409, Initial Validation Loss: 0.1374, Validation Loss: 0.1374,V Acc: 0.3125, Top 70th Acc: 0.3671, Bottom 30th Acc: 0.1818
Fold [1/5] Epoch [10/100] Initial Loss: 0.1409, Training Loss: 0.0152, Initial Validation Loss: 0.1374, Validation Loss: 0.0333,V Acc: 0.8571, Top 70th Acc: 0.9620, Bottom 30th Acc: 0.6061
Fold [1/5] Epoch [20/100] Initial Loss: 0.1409, Training Loss: 0.0047, Initial Validation Loss: 0.1374, Validation Loss: 0.0282,V Acc: 0.8571, Top 70th Acc: 0.9620, Bottom 30th Acc: 0.6061
Fold [1/5] Epoch [10/100] Initial Loss: 0.1285, Training Loss: 0.0225, Initial Validation Loss: 0.1197, Validation Loss: 0.0259,V Acc: 0.8750, Top 70th Acc: 0.9747, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 16  Rolling back to Epoch (base 0): 11  Top Validation Acc: 0.9493670886075949
Fold [2/5] Epoch [0/100] Initial Loss: 0.1340, Training Loss: 0.1340, Initial Validation Loss: 0.1193, Validation Loss: 0.1193,V Acc: 0.4234, Top 70th Acc: 0.5513, Bottom 30th Acc: 0.1212
Fold [2/5] Epoch [10/100] Initial Loss: 0.1340, Training Loss: 0.0257, Initial Validation Loss: 0.1193, Validation Loss: 0.0279,V Acc: 0.8829, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.7273
Stopping early at Epoch (base 0): 16  Rolling back to Epoch (base 0): 11  Top Validation Acc: 0.9487179487179487
Fold [3/5] Epoch [0/100] Initial Loss: 0.1392, Training Loss: 0.1392, Initial Validation Loss: 0.1299, Validation Loss: 0.1299,V Acc: 0.4000, Top 70th Acc: 0.5065, Bottom 30th Acc: 0.1515
Fold [3/5] Epoch [10/100] Initial Loss: 0.1392, Training Loss: 0.0240, Initial Validation Loss: 0.1299, Validation Loss: 0.0318,V Acc: 0.8636, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.7273
Fold [3/5] Epoch [20/100] Initial Loss: 0.1392, Training Loss: 0.0150, Initial Validation Loss: 0.1299, Validation Loss: 0.0248,V Acc: 0.8909, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.7576
Fold [3/5] Epoch [30/100] Initial Loss: 0.1392, Training Loss: 0.0135, Initial Validation Loss: 0.1299, Validation Loss: 0.0256,V Acc: 0.8909, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.7273
Stopping early at Epoch (base 0): 34  Rolling back to Epoch (base 0): 29  Top Validation Acc: 0.948051948051948
Fold [4/5] Epoch [0/100] Initial Loss: 0.1340, Training Loss: 0.1340, Initial Validation Loss: 0.1179, Validation Loss: 0.1179,V Acc: 0.4587, Top 70th Acc: 0.5325, Bottom 30th Acc: 0.2812
Fold [4/5] Epoch [10/100] Initial Loss: 0.1340, Training Loss: 0.0217, Initial Validation Loss: 0.1179, Validation Loss: 0.0308,V Acc: 0.8257, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.5312
Stopping early at Epoch (base 0): 18  Rolling back to Epoch (base 0): 13  Top Validation Acc: 0.961038961038961
Fold [5/5] Epoch [0/100] Initial Loss: 0.1377, Training Loss: 0.1377, Initial Validation Loss: 0.1260, Validation Loss: 0.1260,V Acc: 0.3704, Top 70th Acc: 0.4079, Bottom 30th Acc: 0.2812
Fold [5/5] Epoch [10/100] Initial Loss: 0.1377, Training Loss: 0.0247, Initial Validation Loss: 0.1260, Validation Loss: 0.0276,V Acc: 0.8704, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.6562
Fold [5/5] Epoch [20/100] Initial Loss: 0.1377, Training Loss: 0.0146, Initial Validation Loss: 0.1260, Validation Loss: 0.0327,V Acc: 0.8611, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.6875
Stopping early at Epoch (base 0): 20  Rolling back to Epoch (base 0): 15  Top Validation Acc: 0.9342105263157895
6 4 [array([0.7210642 , 0.01660126, 0.04596495, 0.16254833, 0.05382132],
      dtype=float32)]
Running train_nn.py with seed 7
CUDA:False
Training samples count:  550
Training on 21 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1326, Training Loss: 0.1326, Initial Validation Loss: 0.1198, Validation Loss: 0.1198,V Acc: 0.4821, Top 70th Acc: 0.5949, Bottom 30th Acc: 0.2121
Fold [1/5] Epoch [10/100] Initial Loss: 0.1326, Training Loss: 0.0210, Initial Validation Loss: 0.1198, Validation Loss: 0.0279,V Acc: 0.8571, Top 70th Acc: 0.9494, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 16  Rolling back to Epoch (base 0): 11  Top Validation Acc: 0.9240506329113924
Fold [2/5] Epoch [0/100] Initial Loss: 0.1406, Training Loss: 0.1406, Initial Validation Loss: 0.1285, Validation Loss: 0.1285,V Acc: 0.2613, Top 70th Acc: 0.3590, Bottom 30th Acc: 0.0303
Fold [2/5] Epoch [10/100] Initial Loss: 0.1406, Training Loss: 0.0207, Initial Validation Loss: 0.1285, Validation Loss: 0.0311,V Acc: 0.8468, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.5758
Fold [2/5] Epoch [20/100] Initial Loss: 0.1406, Training Loss: 0.0144, Initial Validation Loss: 0.1285, Validation Loss: 0.0323,V Acc: 0.8288, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.9871794871794872
Fold [3/5] Epoch [0/100] Initial Loss: 0.1373, Training Loss: 0.1373, Initial Validation Loss: 0.1309, Validation Loss: 0.1309,V Acc: 0.3636, Top 70th Acc: 0.4545, Bottom 30th Acc: 0.1515
Fold [3/5] Epoch [10/100] Initial Loss: 0.1373, Training Loss: 0.0219, Initial Validation Loss: 0.1309, Validation Loss: 0.0356,V Acc: 0.8545, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6364
Fold [3/5] Epoch [20/100] Initial Loss: 0.1373, Training Loss: 0.0145, Initial Validation Loss: 0.1309, Validation Loss: 0.0296,V Acc: 0.8818, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.961038961038961
Fold [4/5] Epoch [0/100] Initial Loss: 0.1337, Training Loss: 0.1337, Initial Validation Loss: 0.1264, Validation Loss: 0.1264,V Acc: 0.4587, Top 70th Acc: 0.5844, Bottom 30th Acc: 0.1562
Fold [4/5] Epoch [10/100] Initial Loss: 0.1337, Training Loss: 0.0243, Initial Validation Loss: 0.1264, Validation Loss: 0.0186,V Acc: 0.9174, Top 70th Acc: 1.0000, Bottom 30th Acc: 0.7188
Stopping early at Epoch (base 0): 15  Rolling back to Epoch (base 0): 10  Top Validation Acc: 0.987012987012987
7 3 [array([0.80323243, 0.01487582, 0.02334979, 0.11188562, 0.04665634],
      dtype=float32)]
Fold [5/5] Epoch [0/100] Initial Loss: 0.1377, Training Loss: 0.1377, Initial Validation Loss: 0.1285, Validation Loss: 0.1285,V Acc: 0.4259, Top 70th Acc: 0.5921, Bottom 30th Acc: 0.0312
Fold [5/5] Epoch [10/100] Initial Loss: 0.1377, Training Loss: 0.0262, Initial Validation Loss: 0.1285, Validation Loss: 0.0325,V Acc: 0.8519, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.6562
Fold [5/5] Epoch [20/100] Initial Loss: 0.1377, Training Loss: 0.0200, Initial Validation Loss: 0.1285, Validation Loss: 0.0230,V Acc: 0.8889, Top 70th Acc: 0.9737, Bottom 30th Acc: 0.6875
Stopping early at Epoch (base 0): 27  Rolling back to Epoch (base 0): 22  Top Validation Acc: 0.9868421052631579
Running train_nn.py with seed 8
CUDA:False
Training samples count:  550
Training on 21 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1348, Training Loss: 0.1348, Initial Validation Loss: 0.1211, Validation Loss: 0.1211,V Acc: 0.4643, Top 70th Acc: 0.5443, Bottom 30th Acc: 0.2727
Fold [1/5] Epoch [10/100] Initial Loss: 0.1348, Training Loss: 0.0217, Initial Validation Loss: 0.1211, Validation Loss: 0.0298,V Acc: 0.8214, Top 70th Acc: 0.9747, Bottom 30th Acc: 0.4545
Fold [1/5] Epoch [20/100] Initial Loss: 0.1348, Training Loss: 0.0153, Initial Validation Loss: 0.1211, Validation Loss: 0.0289,V Acc: 0.8304, Top 70th Acc: 0.9620, Bottom 30th Acc: 0.5152
Stopping early at Epoch (base 0): 20  Rolling back to Epoch (base 0): 15  Top Validation Acc: 0.9620253164556962
Fold [2/5] Epoch [0/100] Initial Loss: 0.1381, Training Loss: 0.1381, Initial Validation Loss: 0.1278, Validation Loss: 0.1278,V Acc: 0.4505, Top 70th Acc: 0.5000, Bottom 30th Acc: 0.3333
Fold [2/5] Epoch [10/100] Initial Loss: 0.1381, Training Loss: 0.0295, Initial Validation Loss: 0.1278, Validation Loss: 0.0345,V Acc: 0.8198, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.4848
Fold [2/5] Epoch [20/100] Initial Loss: 0.1381, Training Loss: 0.0145, Initial Validation Loss: 0.1278, Validation Loss: 0.0233,V Acc: 0.8829, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.6970
Fold [2/5] Epoch [30/100] Initial Loss: 0.1381, Training Loss: 0.0132, Initial Validation Loss: 0.1278, Validation Loss: 0.0238,V Acc: 0.8919, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.7273
Stopping early at Epoch (base 0): 30  Rolling back to Epoch (base 0): 25  Top Validation Acc: 0.9615384615384616
Fold [3/5] Epoch [0/100] Initial Loss: 0.1369, Training Loss: 0.1369, Initial Validation Loss: 0.1304, Validation Loss: 0.1304,V Acc: 0.5182, Top 70th Acc: 0.6623, Bottom 30th Acc: 0.1818
Fold [3/5] Epoch [10/100] Initial Loss: 0.1369, Training Loss: 0.0233, Initial Validation Loss: 0.1304, Validation Loss: 0.0233,V Acc: 0.9000, Top 70th Acc: 1.0000, Bottom 30th Acc: 0.6667
Fold [3/5] Epoch [20/100] Initial Loss: 0.1369, Training Loss: 0.0158, Initial Validation Loss: 0.1304, Validation Loss: 0.0204,V Acc: 0.9091, Top 70th Acc: 0.9870, Bottom 30th Acc: 0.7273
Fold [4/5] Epoch [30/100] Initial Loss: 0.1380, Training Loss: 0.0766, Initial Validation Loss: 0.1281, Validation Loss: 0.0809,V Acc: 0.6514, Top 70th Acc: 0.7273, Bottom 30th Acc: 0.4688
Stopping early at Epoch (base 0): 31  Rolling back to Epoch (base 0): 26  Top Validation Acc: 0.7142857142857143
Fold [5/5] Epoch [0/100] Initial Loss: 0.1420, Training Loss: 0.1420, Initial Validation Loss: 0.1332, Validation Loss: 0.1332,V Acc: 0.2963, Top 70th Acc: 0.3816, Bottom 30th Acc: 0.0938
Fold [5/5] Epoch [10/100] Initial Loss: 0.1420, Training Loss: 0.0780, Initial Validation Loss: 0.1332, Validation Loss: 0.0860,V Acc: 0.5648, Top 70th Acc: 0.6711, Bottom 30th Acc: 0.3125
Stopping early at Epoch (base 0): 12  Rolling back to Epoch (base 0): 7  Top Validation Acc: 0.6578947368421053
Running train_nn.py with seed 5
CUDA:False
Training samples count:  550
Training on 2 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1427, Training Loss: 0.1427, Initial Validation Loss: 0.1379, Validation Loss: 0.1379,V Acc: 0.2768, Top 70th Acc: 0.3418, Bottom 30th Acc: 0.1212
Fold [1/5] Epoch [10/100] Initial Loss: 0.1427, Training Loss: 0.0815, Initial Validation Loss: 0.1379, Validation Loss: 0.0797,V Acc: 0.6161, Top 70th Acc: 0.7089, Bottom 30th Acc: 0.3939
Fold [1/5] Epoch [20/100] Initial Loss: 0.1427, Training Loss: 0.0796, Initial Validation Loss: 0.1379, Validation Loss: 0.0771,V Acc: 0.6161, Top 70th Acc: 0.7215, Bottom 30th Acc: 0.3636
Fold [1/5] Epoch [30/100] Initial Loss: 0.1427, Training Loss: 0.0791, Initial Validation Loss: 0.1379, Validation Loss: 0.0761,V Acc: 0.6339, Top 70th Acc: 0.7468, Bottom 30th Acc: 0.3636
Fold [1/5] Epoch [40/100] Initial Loss: 0.1427, Training Loss: 0.0783, Initial Validation Loss: 0.1379, Validation Loss: 0.0762,V Acc: 0.6250, Top 70th Acc: 0.7722, Bottom 30th Acc: 0.2727
Fold [1/5] Epoch [50/100] Initial Loss: 0.1427, Training Loss: 0.0776, Initial Validation Loss: 0.1379, Validation Loss: 0.0769,V Acc: 0.6339, Top 70th Acc: 0.7089, Bottom 30th Acc: 0.4545
Stopping early at Epoch (base 0): 56  Rolling back to Epoch (base 0): 51  Top Validation Acc: 0.7468354430379747
Fold [2/5] Epoch [0/100] Initial Loss: 0.1417, Training Loss: 0.1417, Initial Validation Loss: 0.1313, Validation Loss: 0.1313,V Acc: 0.2883, Top 70th Acc: 0.3590, Bottom 30th Acc: 0.1212
Fold [2/5] Epoch [10/100] Initial Loss: 0.1417, Training Loss: 0.0818, Initial Validation Loss: 0.1313, Validation Loss: 0.0761,V Acc: 0.6396, Top 70th Acc: 0.7692, Bottom 30th Acc: 0.3333
Stopping early at Epoch (base 0): 17  Rolling back to Epoch (base 0): 12  Top Validation Acc: 0.7564102564102564
Fold [3/5] Epoch [0/100] Initial Loss: 0.1431, Training Loss: 0.1431, Initial Validation Loss: 0.1330, Validation Loss: 0.1330,V Acc: 0.2545, Top 70th Acc: 0.3247, Bottom 30th Acc: 0.0909
Fold [3/5] Epoch [10/100] Initial Loss: 0.1431, Training Loss: 0.0827, Initial Validation Loss: 0.1330, Validation Loss: 0.0826,V Acc: 0.6182, Top 70th Acc: 0.7273, Bottom 30th Acc: 0.3636
Fold [3/5] Epoch [20/100] Initial Loss: 0.1431, Training Loss: 0.0793, Initial Validation Loss: 0.1330, Validation Loss: 0.0809,V Acc: 0.6091, Top 70th Acc: 0.7143, Bottom 30th Acc: 0.3636
Fold [3/5] Epoch [30/100] Initial Loss: 0.1431, Training Loss: 0.0784, Initial Validation Loss: 0.1330, Validation Loss: 0.0801,V Acc: 0.6182, Top 70th Acc: 0.7143, Bottom 30th Acc: 0.3939
Fold [3/5] Epoch [40/100] Initial Loss: 0.1431, Training Loss: 0.0780, Initial Validation Loss: 0.1330, Validation Loss: 0.0796,V Acc: 0.6182, Top 70th Acc: 0.7143, Bottom 30th Acc: 0.3939
Fold [3/5] Epoch [50/100] Initial Loss: 0.1431, Training Loss: 0.0775, Initial Validation Loss: 0.1330, Validation Loss: 0.0787,V Acc: 0.6182, Top 70th Acc: 0.7143, Bottom 30th Acc: 0.3939
Stopping early at Epoch (base 0): 55  Rolling back to Epoch (base 0): 50  Top Validation Acc: 0.7142857142857143
5 2 [array([0.13278966, 0.33651942, 0.14165217, 0.22001708, 0.16902168],
      dtype=float32)]
Fold [4/5] Epoch [0/100] Initial Loss: 0.1343, Training Loss: 0.1343, Initial Validation Loss: 0.1226, Validation Loss: 0.1226,V Acc: 0.3945, Top 70th Acc: 0.5065, Bottom 30th Acc: 0.1250
Fold [4/5] Epoch [10/100] Initial Loss: 0.1343, Training Loss: 0.0802, Initial Validation Loss: 0.1226, Validation Loss: 0.0791,V Acc: 0.6330, Top 70th Acc: 0.7143, Bottom 30th Acc: 0.4375
Fold [4/5] Epoch [20/100] Initial Loss: 0.1343, Training Loss: 0.0782, Initial Validation Loss: 0.1226, Validation Loss: 0.0770,V Acc: 0.6330, Top 70th Acc: 0.7273, Bottom 30th Acc: 0.4062
Fold [4/5] Epoch [30/100] Initial Loss: 0.1343, Training Loss: 0.0775, Initial Validation Loss: 0.1226, Validation Loss: 0.0762,V Acc: 0.6330, Top 70th Acc: 0.7532, Bottom 30th Acc: 0.3438
Stopping early at Epoch (base 0): 37  Rolling back to Epoch (base 0): 32  Top Validation Acc: 0.7532467532467533
Fold [5/5] Epoch [0/100] Initial Loss: 0.1308, Training Loss: 0.1308, Initial Validation Loss: 0.1166, Validation Loss: 0.1166,V Acc: 0.5648, Top 70th Acc: 0.6184, Bottom 30th Acc: 0.4375
Fold [5/5] Epoch [10/100] Initial Loss: 0.1308, Training Loss: 0.0787, Initial Validation Loss: 0.1166, Validation Loss: 0.0818,V Acc: 0.6296, Top 70th Acc: 0.7500, Bottom 30th Acc: 0.3438
Fold [5/5] Epoch [20/100] Initial Loss: 0.1308, Training Loss: 0.0770, Initial Validation Loss: 0.1166, Validation Loss: 0.0794,V Acc: 0.6574, Top 70th Acc: 0.7632, Bottom 30th Acc: 0.4062
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.75
Running train_nn.py with seed 6
CUDA:False
Training samples count:  550
Training on 2 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1369, Training Loss: 0.1369, Initial Validation Loss: 0.1303, Validation Loss: 0.1303,V Acc: 0.4821, Top 70th Acc: 0.5823, Bottom 30th Acc: 0.2424
Fold [1/5] Epoch [10/100] Initial Loss: 0.1369, Training Loss: 0.0836, Initial Validation Loss: 0.1303, Validation Loss: 0.0744,V Acc: 0.6875, Top 70th Acc: 0.8101, Bottom 30th Acc: 0.3939
Fold [1/5] Epoch [20/100] Initial Loss: 0.1369, Training Loss: 0.0813, Initial Validation Loss: 0.1303, Validation Loss: 0.0721,V Acc: 0.6964, Top 70th Acc: 0.7975, Bottom 30th Acc: 0.4545
Stopping early at Epoch (base 0): 28  Rolling back to Epoch (base 0): 23  Top Validation Acc: 0.810126582278481
Fold [2/5] Epoch [0/100] Initial Loss: 0.1342, Training Loss: 0.1342, Initial Validation Loss: 0.1241, Validation Loss: 0.1241,V Acc: 0.5766, Top 70th Acc: 0.6923, Bottom 30th Acc: 0.3030
Fold [2/5] Epoch [10/100] Initial Loss: 0.1342, Training Loss: 0.0804, Initial Validation Loss: 0.1241, Validation Loss: 0.0802,V Acc: 0.6486, Top 70th Acc: 0.7436, Bottom 30th Acc: 0.4242
Fold [2/5] Epoch [20/100] Initial Loss: 0.1342, Training Loss: 0.0789, Initial Validation Loss: 0.1241, Validation Loss: 0.0786,V Acc: 0.6577, Top 70th Acc: 0.7436, Bottom 30th Acc: 0.4545
Stopping early at Epoch (base 0): 20  Rolling back to Epoch (base 0): 15  Top Validation Acc: 0.7435897435897436
Fold [3/5] Epoch [0/100] Initial Loss: 0.1358, Training Loss: 0.1358, Initial Validation Loss: 0.1287, Validation Loss: 0.1287,V Acc: 0.5182, Top 70th Acc: 0.5714, Bottom 30th Acc: 0.3939
Fold [3/5] Epoch [10/100] Initial Loss: 0.1358, Training Loss: 0.0805, Initial Validation Loss: 0.1287, Validation Loss: 0.0836,V Acc: 0.6000, Top 70th Acc: 0.6883, Bottom 30th Acc: 0.3939
Fold [3/5] Epoch [20/100] Initial Loss: 0.1358, Training Loss: 0.0777, Initial Validation Loss: 0.1287, Validation Loss: 0.0824,V Acc: 0.6091, Top 70th Acc: 0.7013, Bottom 30th Acc: 0.3939
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.7012987012987013
Fold [4/5] Epoch [0/100] Initial Loss: 0.1419, Training Loss: 0.1419, Initial Validation Loss: 0.1286, Validation Loss: 0.1286,V Acc: 0.3394, Top 70th Acc: 0.4286, Bottom 30th Acc: 0.1250
Fold [4/5] Epoch [10/100] Initial Loss: 0.1419, Training Loss: 0.0812, Initial Validation Loss: 0.1286, Validation Loss: 0.0814,V Acc: 0.6055, Top 70th Acc: 0.7662, Bottom 30th Acc: 0.2188
Fold [4/5] Epoch [20/100] Initial Loss: 0.1419, Training Loss: 0.0785, Initial Validation Loss: 0.1286, Validation Loss: 0.0795,V Acc: 0.6239, Top 70th Acc: 0.7662, Bottom 30th Acc: 0.2812
Fold [5/5] Epoch [30/100] Initial Loss: 0.1376, Training Loss: 0.0124, Initial Validation Loss: 0.1322, Validation Loss: 0.0339,V Acc: 0.8241, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.5312
Stopping early at Epoch (base 0): 31  Rolling back to Epoch (base 0): 26  Top Validation Acc: 0.9605263157894737
Running train_nn.py with seed 5
CUDA:False
Training samples count:  550
Training on 40 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1383, Training Loss: 0.1383, Initial Validation Loss: 0.1356, Validation Loss: 0.1356,V Acc: 0.2679, Top 70th Acc: 0.3291, Bottom 30th Acc: 0.1212
Fold [1/5] Epoch [10/100] Initial Loss: 0.1383, Training Loss: 0.0335, Initial Validation Loss: 0.1356, Validation Loss: 0.0428,V Acc: 0.7946, Top 70th Acc: 0.8861, Bottom 30th Acc: 0.5758
Fold [1/5] Epoch [20/100] Initial Loss: 0.1383, Training Loss: 0.0147, Initial Validation Loss: 0.1356, Validation Loss: 0.0270,V Acc: 0.8750, Top 70th Acc: 0.9620, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 29  Rolling back to Epoch (base 0): 24  Top Validation Acc: 0.9746835443037974
Fold [2/5] Epoch [0/100] Initial Loss: 0.1403, Training Loss: 0.1403, Initial Validation Loss: 0.1328, Validation Loss: 0.1328,V Acc: 0.3153, Top 70th Acc: 0.3974, Bottom 30th Acc: 0.1212
Fold [2/5] Epoch [10/100] Initial Loss: 0.1403, Training Loss: 0.0309, Initial Validation Loss: 0.1328, Validation Loss: 0.0395,V Acc: 0.8288, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.5455
Fold [2/5] Epoch [20/100] Initial Loss: 0.1403, Training Loss: 0.0149, Initial Validation Loss: 0.1328, Validation Loss: 0.0315,V Acc: 0.8108, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.4545
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.9615384615384616
Fold [3/5] Epoch [0/100] Initial Loss: 0.1389, Training Loss: 0.1389, Initial Validation Loss: 0.1307, Validation Loss: 0.1307,V Acc: 0.2727, Top 70th Acc: 0.3636, Bottom 30th Acc: 0.0606
Fold [3/5] Epoch [10/100] Initial Loss: 0.1389, Training Loss: 0.0255, Initial Validation Loss: 0.1307, Validation Loss: 0.0292,V Acc: 0.9091, Top 70th Acc: 0.9870, Bottom 30th Acc: 0.7273
Fold [3/5] Epoch [20/100] Initial Loss: 0.1389, Training Loss: 0.0131, Initial Validation Loss: 0.1307, Validation Loss: 0.0252,V Acc: 0.9091, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.7576
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.961038961038961
5 2 [array([0.5949753 , 0.03183484, 0.03779668, 0.19999647, 0.13539676],
      dtype=float32)]
Fold [4/5] Epoch [0/100] Initial Loss: 0.1411, Training Loss: 0.1411, Initial Validation Loss: 0.1330, Validation Loss: 0.1330,V Acc: 0.3670, Top 70th Acc: 0.3506, Bottom 30th Acc: 0.4062
Fold [4/5] Epoch [10/100] Initial Loss: 0.1411, Training Loss: 0.0383, Initial Validation Loss: 0.1330, Validation Loss: 0.0433,V Acc: 0.7982, Top 70th Acc: 0.8961, Bottom 30th Acc: 0.5625
Fold [4/5] Epoch [20/100] Initial Loss: 0.1411, Training Loss: 0.0146, Initial Validation Loss: 0.1330, Validation Loss: 0.0326,V Acc: 0.8440, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.6250
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.922077922077922
Fold [5/5] Epoch [0/100] Initial Loss: 0.1395, Training Loss: 0.1395, Initial Validation Loss: 0.1340, Validation Loss: 0.1340,V Acc: 0.2963, Top 70th Acc: 0.3421, Bottom 30th Acc: 0.1875
Fold [5/5] Epoch [10/100] Initial Loss: 0.1395, Training Loss: 0.0391, Initial Validation Loss: 0.1340, Validation Loss: 0.0433,V Acc: 0.7963, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.4375
Fold [5/5] Epoch [20/100] Initial Loss: 0.1395, Training Loss: 0.0162, Initial Validation Loss: 0.1340, Validation Loss: 0.0244,V Acc: 0.8611, Top 70th Acc: 0.9737, Bottom 30th Acc: 0.5938
Fold [5/5] Epoch [30/100] Initial Loss: 0.1395, Training Loss: 0.0130, Initial Validation Loss: 0.1340, Validation Loss: 0.0230,V Acc: 0.8704, Top 70th Acc: 0.9737, Bottom 30th Acc: 0.6250
Stopping early at Epoch (base 0): 34  Rolling back to Epoch (base 0): 29  Top Validation Acc: 0.9736842105263158
Running train_nn.py with seed 6
CUDA:False
Training samples count:  550
Training on 40 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1388, Training Loss: 0.1388, Initial Validation Loss: 0.1395, Validation Loss: 0.1395,V Acc: 0.2679, Top 70th Acc: 0.2278, Bottom 30th Acc: 0.3636
Fold [1/5] Epoch [10/100] Initial Loss: 0.1388, Training Loss: 0.0327, Initial Validation Loss: 0.1395, Validation Loss: 0.0411,V Acc: 0.8125, Top 70th Acc: 0.9494, Bottom 30th Acc: 0.4848
Fold [1/5] Epoch [20/100] Initial Loss: 0.1388, Training Loss: 0.0123, Initial Validation Loss: 0.1395, Validation Loss: 0.0341,V Acc: 0.8125, Top 70th Acc: 0.9367, Bottom 30th Acc: 0.5152
Stopping early at Epoch (base 0): 27  Rolling back to Epoch (base 0): 22  Top Validation Acc: 0.9493670886075949
Fold [2/5] Epoch [0/100] Initial Loss: 0.1408, Training Loss: 0.1408, Initial Validation Loss: 0.1366, Validation Loss: 0.1366,V Acc: 0.3333, Top 70th Acc: 0.4231, Bottom 30th Acc: 0.1212
Fold [2/5] Epoch [10/100] Initial Loss: 0.1408, Training Loss: 0.0347, Initial Validation Loss: 0.1366, Validation Loss: 0.0396,V Acc: 0.8288, Top 70th Acc: 0.8974, Bottom 30th Acc: 0.6667
Fold [2/5] Epoch [20/100] Initial Loss: 0.1408, Training Loss: 0.0165, Initial Validation Loss: 0.1366, Validation Loss: 0.0289,V Acc: 0.8468, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.6667
Fold [2/5] Epoch [30/100] Initial Loss: 0.1408, Training Loss: 0.0123, Initial Validation Loss: 0.1366, Validation Loss: 0.0272,V Acc: 0.8649, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 33  Rolling back to Epoch (base 0): 28  Top Validation Acc: 0.9358974358974359
Fold [3/5] Epoch [0/100] Initial Loss: 0.1401, Training Loss: 0.1401, Initial Validation Loss: 0.1346, Validation Loss: 0.1346,V Acc: 0.3636, Top 70th Acc: 0.4286, Bottom 30th Acc: 0.2121
Fold [3/5] Epoch [10/100] Initial Loss: 0.1401, Training Loss: 0.0296, Initial Validation Loss: 0.1346, Validation Loss: 0.0410,V Acc: 0.8364, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.6667
Fold [3/5] Epoch [20/100] Initial Loss: 0.1401, Training Loss: 0.0137, Initial Validation Loss: 0.1346, Validation Loss: 0.0344,V Acc: 0.8545, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.7273
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.9090909090909091
Fold [4/5] Epoch [0/100] Initial Loss: 0.1393, Training Loss: 0.1393, Initial Validation Loss: 0.1307, Validation Loss: 0.1307,V Acc: 0.3028, Top 70th Acc: 0.3377, Bottom 30th Acc: 0.2188
Fold [4/5] Epoch [10/100] Initial Loss: 0.1393, Training Loss: 0.0271, Initial Validation Loss: 0.1307, Validation Loss: 0.0361,V Acc: 0.8165, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.5625
Fold [4/5] Epoch [20/100] Initial Loss: 0.1393, Training Loss: 0.0138, Initial Validation Loss: 0.1307, Validation Loss: 0.0293,V Acc: 0.8532, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.5625
Stopping early at Epoch (base 0): 29  Rolling back to Epoch (base 0): 24  Top Validation Acc: 0.948051948051948
Fold [5/5] Epoch [0/100] Initial Loss: 0.1411, Training Loss: 0.1411, Initial Validation Loss: 0.1301, Validation Loss: 0.1301,V Acc: 0.2500, Top 70th Acc: 0.3026, Bottom 30th Acc: 0.1250
Fold [5/5] Epoch [10/100] Initial Loss: 0.1411, Training Loss: 0.0312, Initial Validation Loss: 0.1301, Validation Loss: 0.0390,V Acc: 0.8148, Top 70th Acc: 0.9211, Bottom 30th Acc: 0.5625
Fold [5/5] Epoch [20/100] Initial Loss: 0.1411, Training Loss: 0.0155, Initial Validation Loss: 0.1301, Validation Loss: 0.0290,V Acc: 0.8704, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.6875
Stopping early at Epoch (base 0): 27  Rolling back to Epoch (base 0): 22  Top Validation Acc: 0.9473684210526315
6 4 [array([0.45854944, 0.17485775, 0.03648611, 0.09145863, 0.23864818],
      dtype=float32)]
Running train_nn.py with seed 7
CUDA:False
Training samples count:  550
Training on 40 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1373, Training Loss: 0.1373, Initial Validation Loss: 0.1315, Validation Loss: 0.1315,V Acc: 0.3393, Top 70th Acc: 0.3291, Bottom 30th Acc: 0.3636
Fold [1/5] Epoch [10/100] Initial Loss: 0.1373, Training Loss: 0.0278, Initial Validation Loss: 0.1315, Validation Loss: 0.0365,V Acc: 0.8482, Top 70th Acc: 0.9367, Bottom 30th Acc: 0.6364
Fold [2/5] Epoch [10/100] Initial Loss: 0.1398, Training Loss: 0.0350, Initial Validation Loss: 0.1341, Validation Loss: 0.0434,V Acc: 0.7838, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.4848
Fold [2/5] Epoch [20/100] Initial Loss: 0.1398, Training Loss: 0.0197, Initial Validation Loss: 0.1341, Validation Loss: 0.0314,V Acc: 0.8378, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.9487179487179487
Fold [3/5] Epoch [0/100] Initial Loss: 0.1414, Training Loss: 0.1414, Initial Validation Loss: 0.1334, Validation Loss: 0.1334,V Acc: 0.2545, Top 70th Acc: 0.3117, Bottom 30th Acc: 0.1212
Fold [3/5] Epoch [10/100] Initial Loss: 0.1414, Training Loss: 0.0381, Initial Validation Loss: 0.1334, Validation Loss: 0.0425,V Acc: 0.8182, Top 70th Acc: 0.8961, Bottom 30th Acc: 0.6364
Fold [3/5] Epoch [20/100] Initial Loss: 0.1414, Training Loss: 0.0184, Initial Validation Loss: 0.1334, Validation Loss: 0.0324,V Acc: 0.8364, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.935064935064935
5 2 [array([0.6117526 , 0.08380195, 0.0242592 , 0.11397587, 0.16621038],
      dtype=float32)]
Fold [4/5] Epoch [0/100] Initial Loss: 0.1418, Training Loss: 0.1418, Initial Validation Loss: 0.1318, Validation Loss: 0.1318,V Acc: 0.2569, Top 70th Acc: 0.2727, Bottom 30th Acc: 0.2188
Fold [4/5] Epoch [10/100] Initial Loss: 0.1418, Training Loss: 0.0319, Initial Validation Loss: 0.1318, Validation Loss: 0.0365,V Acc: 0.8257, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.6250
Fold [4/5] Epoch [20/100] Initial Loss: 0.1418, Training Loss: 0.0180, Initial Validation Loss: 0.1318, Validation Loss: 0.0307,V Acc: 0.8349, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.5938
Stopping early at Epoch (base 0): 28  Rolling back to Epoch (base 0): 23  Top Validation Acc: 0.948051948051948
Fold [5/5] Epoch [0/100] Initial Loss: 0.1384, Training Loss: 0.1384, Initial Validation Loss: 0.1302, Validation Loss: 0.1302,V Acc: 0.2778, Top 70th Acc: 0.3553, Bottom 30th Acc: 0.0938
Fold [5/5] Epoch [10/100] Initial Loss: 0.1384, Training Loss: 0.0287, Initial Validation Loss: 0.1302, Validation Loss: 0.0297,V Acc: 0.8796, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.6875
Fold [5/5] Epoch [20/100] Initial Loss: 0.1384, Training Loss: 0.0182, Initial Validation Loss: 0.1302, Validation Loss: 0.0256,V Acc: 0.8704, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.6875
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.9473684210526315
Running train_nn.py with seed 6
CUDA:False
Training samples count:  550
Training on 30 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1404, Training Loss: 0.1404, Initial Validation Loss: 0.1375, Validation Loss: 0.1375,V Acc: 0.2500, Top 70th Acc: 0.2405, Bottom 30th Acc: 0.2727
Fold [1/5] Epoch [10/100] Initial Loss: 0.1404, Training Loss: 0.0437, Initial Validation Loss: 0.1375, Validation Loss: 0.0486,V Acc: 0.7500, Top 70th Acc: 0.8734, Bottom 30th Acc: 0.4545
Fold [1/5] Epoch [20/100] Initial Loss: 0.1404, Training Loss: 0.0201, Initial Validation Loss: 0.1375, Validation Loss: 0.0368,V Acc: 0.8036, Top 70th Acc: 0.8987, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 21  Rolling back to Epoch (base 0): 16  Top Validation Acc: 0.8987341772151899
Fold [2/5] Epoch [0/100] Initial Loss: 0.1376, Training Loss: 0.1376, Initial Validation Loss: 0.1355, Validation Loss: 0.1355,V Acc: 0.2523, Top 70th Acc: 0.3462, Bottom 30th Acc: 0.0303
Fold [2/5] Epoch [10/100] Initial Loss: 0.1376, Training Loss: 0.0410, Initial Validation Loss: 0.1355, Validation Loss: 0.0420,V Acc: 0.7658, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.4242
Fold [2/5] Epoch [20/100] Initial Loss: 0.1376, Training Loss: 0.0217, Initial Validation Loss: 0.1355, Validation Loss: 0.0252,V Acc: 0.8829, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.6667
Fold [2/5] Epoch [30/100] Initial Loss: 0.1376, Training Loss: 0.0181, Initial Validation Loss: 0.1355, Validation Loss: 0.0256,V Acc: 0.8559, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 32  Rolling back to Epoch (base 0): 27  Top Validation Acc: 0.9743589743589743
Fold [3/5] Epoch [0/100] Initial Loss: 0.1382, Training Loss: 0.1382, Initial Validation Loss: 0.1340, Validation Loss: 0.1340,V Acc: 0.3545, Top 70th Acc: 0.3506, Bottom 30th Acc: 0.3636
Fold [3/5] Epoch [10/100] Initial Loss: 0.1382, Training Loss: 0.0316, Initial Validation Loss: 0.1340, Validation Loss: 0.0422,V Acc: 0.8273, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.6364
Fold [3/5] Epoch [20/100] Initial Loss: 0.1382, Training Loss: 0.0176, Initial Validation Loss: 0.1340, Validation Loss: 0.0376,V Acc: 0.8273, Top 70th Acc: 0.8961, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.922077922077922
Fold [4/5] Epoch [0/100] Initial Loss: 0.1391, Training Loss: 0.1391, Initial Validation Loss: 0.1313, Validation Loss: 0.1313,V Acc: 0.2385, Top 70th Acc: 0.2987, Bottom 30th Acc: 0.0938
Fold [4/5] Epoch [10/100] Initial Loss: 0.1391, Training Loss: 0.0325, Initial Validation Loss: 0.1313, Validation Loss: 0.0434,V Acc: 0.7798, Top 70th Acc: 0.8831, Bottom 30th Acc: 0.5312
Fold [4/5] Epoch [20/100] Initial Loss: 0.1391, Training Loss: 0.0186, Initial Validation Loss: 0.1313, Validation Loss: 0.0352,V Acc: 0.7982, Top 70th Acc: 0.8961, Bottom 30th Acc: 0.5625
Fold [4/5] Epoch [30/100] Initial Loss: 0.1391, Training Loss: 0.0160, Initial Validation Loss: 0.1313, Validation Loss: 0.0330,V Acc: 0.8257, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.5312
Stopping early at Epoch (base 0): 34  Rolling back to Epoch (base 0): 29  Top Validation Acc: 0.922077922077922
Fold [5/5] Epoch [0/100] Initial Loss: 0.1412, Training Loss: 0.1412, Initial Validation Loss: 0.1286, Validation Loss: 0.1286,V Acc: 0.2963, Top 70th Acc: 0.3289, Bottom 30th Acc: 0.2188
Fold [5/5] Epoch [10/100] Initial Loss: 0.1412, Training Loss: 0.0276, Initial Validation Loss: 0.1286, Validation Loss: 0.0370,V Acc: 0.8333, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.5625
Fold [5/5] Epoch [20/100] Initial Loss: 0.1412, Training Loss: 0.0176, Initial Validation Loss: 0.1286, Validation Loss: 0.0322,V Acc: 0.8796, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.7188
Fold [5/5] Epoch [30/100] Initial Loss: 0.1412, Training Loss: 0.0153, Initial Validation Loss: 0.1286, Validation Loss: 0.0322,V Acc: 0.8611, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.6562
Stopping early at Epoch (base 0): 31  Rolling back to Epoch (base 0): 26  Top Validation Acc: 0.9736842105263158
6 4 [array([0.59404874, 0.20030607, 0.02481788, 0.09696113, 0.08386613],
      dtype=float32)]
Running train_nn.py with seed 7
CUDA:False
Training samples count:  550
Training on 30 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1425, Training Loss: 0.1425, Initial Validation Loss: 0.1374, Validation Loss: 0.1374,V Acc: 0.2500, Top 70th Acc: 0.2152, Bottom 30th Acc: 0.3333
Fold [1/5] Epoch [10/100] Initial Loss: 0.1425, Training Loss: 0.0356, Initial Validation Loss: 0.1374, Validation Loss: 0.0431,V Acc: 0.8036, Top 70th Acc: 0.9114, Bottom 30th Acc: 0.5455
Fold [1/5] Epoch [20/100] Initial Loss: 0.1425, Training Loss: 0.0216, Initial Validation Loss: 0.1374, Validation Loss: 0.0348,V Acc: 0.8571, Top 70th Acc: 0.9241, Bottom 30th Acc: 0.6970
Fold [1/5] Epoch [30/100] Initial Loss: 0.1425, Training Loss: 0.0180, Initial Validation Loss: 0.1374, Validation Loss: 0.0309,V Acc: 0.8839, Top 70th Acc: 0.9367, Bottom 30th Acc: 0.7576
Stopping early at Epoch (base 0): 39  Rolling back to Epoch (base 0): 34  Top Validation Acc: 0.9493670886075949
Fold [2/5] Epoch [0/100] Initial Loss: 0.1427, Training Loss: 0.1427, Initial Validation Loss: 0.1323, Validation Loss: 0.1323,V Acc: 0.2883, Top 70th Acc: 0.3333, Bottom 30th Acc: 0.1818
Fold [2/5] Epoch [10/100] Initial Loss: 0.1427, Training Loss: 0.0396, Initial Validation Loss: 0.1323, Validation Loss: 0.0470,V Acc: 0.6937, Top 70th Acc: 0.8974, Bottom 30th Acc: 0.2121
Fold [2/5] Epoch [20/100] Initial Loss: 0.1427, Training Loss: 0.0201, Initial Validation Loss: 0.1323, Validation Loss: 0.0352,V Acc: 0.8018, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.4848
Fold [2/5] Epoch [30/100] Initial Loss: 0.1437, Training Loss: 0.0209, Initial Validation Loss: 0.1369, Validation Loss: 0.0380,V Acc: 0.7838, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.4242
Stopping early at Epoch (base 0): 34  Rolling back to Epoch (base 0): 29  Top Validation Acc: 0.9102564102564102
Fold [3/5] Epoch [0/100] Initial Loss: 0.1382, Training Loss: 0.1382, Initial Validation Loss: 0.1312, Validation Loss: 0.1312,V Acc: 0.3364, Top 70th Acc: 0.2597, Bottom 30th Acc: 0.5152
Fold [3/5] Epoch [10/100] Initial Loss: 0.1382, Training Loss: 0.0333, Initial Validation Loss: 0.1312, Validation Loss: 0.0327,V Acc: 0.8545, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6364
Fold [3/5] Epoch [20/100] Initial Loss: 0.1382, Training Loss: 0.0245, Initial Validation Loss: 0.1312, Validation Loss: 0.0281,V Acc: 0.8909, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.7576
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.948051948051948
5 2 [array([0.37787452, 0.0749357 , 0.1816195 , 0.22721383, 0.13835649],
      dtype=float32)]
Fold [4/5] Epoch [0/100] Initial Loss: 0.1382, Training Loss: 0.1382, Initial Validation Loss: 0.1307, Validation Loss: 0.1307,V Acc: 0.4220, Top 70th Acc: 0.4675, Bottom 30th Acc: 0.3125
Fold [4/5] Epoch [10/100] Initial Loss: 0.1382, Training Loss: 0.0336, Initial Validation Loss: 0.1307, Validation Loss: 0.0373,V Acc: 0.8257, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.6250
Fold [4/5] Epoch [20/100] Initial Loss: 0.1382, Training Loss: 0.0226, Initial Validation Loss: 0.1307, Validation Loss: 0.0324,V Acc: 0.8349, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.6250
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.922077922077922
Fold [5/5] Epoch [0/100] Initial Loss: 0.1381, Training Loss: 0.1381, Initial Validation Loss: 0.1298, Validation Loss: 0.1298,V Acc: 0.3519, Top 70th Acc: 0.4474, Bottom 30th Acc: 0.1250
Fold [5/5] Epoch [10/100] Initial Loss: 0.1381, Training Loss: 0.0443, Initial Validation Loss: 0.1298, Validation Loss: 0.0453,V Acc: 0.7870, Top 70th Acc: 0.9211, Bottom 30th Acc: 0.4688
Fold [5/5] Epoch [20/100] Initial Loss: 0.1381, Training Loss: 0.0265, Initial Validation Loss: 0.1298, Validation Loss: 0.0326,V Acc: 0.8241, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.5000
Fold [5/5] Epoch [30/100] Initial Loss: 0.1381, Training Loss: 0.0232, Initial Validation Loss: 0.1298, Validation Loss: 0.0281,V Acc: 0.8611, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.6250
Stopping early at Epoch (base 0): 33  Rolling back to Epoch (base 0): 28  Top Validation Acc: 0.9736842105263158
Running train_nn.py with seed 6
CUDA:False
Training samples count:  550
Training on 20 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1386, Training Loss: 0.1386, Initial Validation Loss: 0.1380, Validation Loss: 0.1380,V Acc: 0.2589, Top 70th Acc: 0.1519, Bottom 30th Acc: 0.5152
Fold [1/5] Epoch [10/100] Initial Loss: 0.1386, Training Loss: 0.0435, Initial Validation Loss: 0.1380, Validation Loss: 0.0452,V Acc: 0.8125, Top 70th Acc: 0.8861, Bottom 30th Acc: 0.6364
Fold [1/5] Epoch [20/100] Initial Loss: 0.1386, Training Loss: 0.0273, Initial Validation Loss: 0.1380, Validation Loss: 0.0323,V Acc: 0.8304, Top 70th Acc: 0.9494, Bottom 30th Acc: 0.5455
Fold [1/5] Epoch [30/100] Initial Loss: 0.1386, Training Loss: 0.0224, Initial Validation Loss: 0.1380, Validation Loss: 0.0305,V Acc: 0.8393, Top 70th Acc: 0.9494, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 30  Rolling back to Epoch (base 0): 25  Top Validation Acc: 0.9493670886075949
Fold [2/5] Epoch [0/100] Initial Loss: 0.1390, Training Loss: 0.1390, Initial Validation Loss: 0.1359, Validation Loss: 0.1359,V Acc: 0.3694, Top 70th Acc: 0.3974, Bottom 30th Acc: 0.3030
Fold [2/5] Epoch [10/100] Initial Loss: 0.1390, Training Loss: 0.0413, Initial Validation Loss: 0.1359, Validation Loss: 0.0400,V Acc: 0.8378, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.6061
Fold [2/5] Epoch [20/100] Initial Loss: 0.1390, Training Loss: 0.0250, Initial Validation Loss: 0.1359, Validation Loss: 0.0286,V Acc: 0.8739, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.6970
Fold [2/5] Epoch [30/100] Initial Loss: 0.1390, Training Loss: 0.0226, Initial Validation Loss: 0.1359, Validation Loss: 0.0297,V Acc: 0.8739, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 33  Rolling back to Epoch (base 0): 28  Top Validation Acc: 0.9615384615384616
Fold [3/5] Epoch [0/100] Initial Loss: 0.1398, Training Loss: 0.1398, Initial Validation Loss: 0.1356, Validation Loss: 0.1356,V Acc: 0.2727, Top 70th Acc: 0.3247, Bottom 30th Acc: 0.1515
Fold [3/5] Epoch [10/100] Initial Loss: 0.1398, Training Loss: 0.0348, Initial Validation Loss: 0.1356, Validation Loss: 0.0483,V Acc: 0.8000, Top 70th Acc: 0.8571, Bottom 30th Acc: 0.6667
Fold [3/5] Epoch [20/100] Initial Loss: 0.1398, Training Loss: 0.0222, Initial Validation Loss: 0.1356, Validation Loss: 0.0389,V Acc: 0.8273, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.6364
Fold [3/5] Epoch [30/100] Initial Loss: 0.1398, Training Loss: 0.0194, Initial Validation Loss: 0.1356, Validation Loss: 0.0386,V Acc: 0.8182, Top 70th Acc: 0.8961, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 32  Rolling back to Epoch (base 0): 27  Top Validation Acc: 0.9090909090909091
Fold [4/5] Epoch [0/100] Initial Loss: 0.1374, Training Loss: 0.1374, Initial Validation Loss: 0.1243, Validation Loss: 0.1243,V Acc: 0.4587, Top 70th Acc: 0.5325, Bottom 30th Acc: 0.2812
Fold [4/5] Epoch [10/100] Initial Loss: 0.1374, Training Loss: 0.0354, Initial Validation Loss: 0.1243, Validation Loss: 0.0434,V Acc: 0.7615, Top 70th Acc: 0.8701, Bottom 30th Acc: 0.5000
Fold [4/5] Epoch [20/100] Initial Loss: 0.1374, Training Loss: 0.0234, Initial Validation Loss: 0.1243, Validation Loss: 0.0369,V Acc: 0.7890, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.5000
Fold [4/5] Epoch [30/100] Initial Loss: 0.1374, Training Loss: 0.0209, Initial Validation Loss: 0.1243, Validation Loss: 0.0345,V Acc: 0.7982, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.5000
Stopping early at Epoch (base 0): 39  Rolling back to Epoch (base 0): 34  Top Validation Acc: 0.922077922077922
Fold [5/5] Epoch [0/100] Initial Loss: 0.1396, Training Loss: 0.1396, Initial Validation Loss: 0.1304, Validation Loss: 0.1304,V Acc: 0.2315, Top 70th Acc: 0.2500, Bottom 30th Acc: 0.1875
Fold [5/5] Epoch [10/100] Initial Loss: 0.1396, Training Loss: 0.0310, Initial Validation Loss: 0.1304, Validation Loss: 0.0360,V Acc: 0.8426, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.5938
Fold [5/5] Epoch [20/100] Initial Loss: 0.1396, Training Loss: 0.0226, Initial Validation Loss: 0.1304, Validation Loss: 0.0328,V Acc: 0.8426, Top 70th Acc: 0.9211, Bottom 30th Acc: 0.6562
Stopping early at Epoch (base 0): 20  Rolling back to Epoch (base 0): 15  Top Validation Acc: 0.9210526315789473
6 4 [array([0.43536353, 0.16974011, 0.10048894, 0.14815646, 0.14625092],
      dtype=float32)]
Running train_nn.py with seed 7
CUDA:False
Training samples count:  550
Training on 20 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1417, Training Loss: 0.1417, Initial Validation Loss: 0.1351, Validation Loss: 0.1351,V Acc: 0.2589, Top 70th Acc: 0.3291, Bottom 30th Acc: 0.0909
Fold [1/5] Epoch [10/100] Initial Loss: 0.1417, Training Loss: 0.0460, Initial Validation Loss: 0.1351, Validation Loss: 0.0515,V Acc: 0.7589, Top 70th Acc: 0.8481, Bottom 30th Acc: 0.5455
Fold [1/5] Epoch [20/100] Initial Loss: 0.1417, Training Loss: 0.0263, Initial Validation Loss: 0.1351, Validation Loss: 0.0373,V Acc: 0.8304, Top 70th Acc: 0.9114, Bottom 30th Acc: 0.6364
Fold [1/5] Epoch [30/100] Initial Loss: 0.1417, Training Loss: 0.0225, Initial Validation Loss: 0.1351, Validation Loss: 0.0346,V Acc: 0.8304, Top 70th Acc: 0.9241, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 30  Rolling back to Epoch (base 0): 25  Top Validation Acc: 0.9240506329113924
Fold [2/5] Epoch [0/100] Initial Loss: 0.1376, Training Loss: 0.1376, Initial Validation Loss: 0.1277, Validation Loss: 0.1277,V Acc: 0.4505, Top 70th Acc: 0.5513, Bottom 30th Acc: 0.2121
Fold [2/5] Epoch [10/100] Initial Loss: 0.1376, Training Loss: 0.0478, Initial Validation Loss: 0.1277, Validation Loss: 0.0525,V Acc: 0.7387, Top 70th Acc: 0.8590, Bottom 30th Acc: 0.4545
Fold [3/5] Epoch [30/100] Initial Loss: 0.1369, Training Loss: 0.0135, Initial Validation Loss: 0.1304, Validation Loss: 0.0195,V Acc: 0.9273, Top 70th Acc: 1.0000, Bottom 30th Acc: 0.7576
Stopping early at Epoch (base 0): 31  Rolling back to Epoch (base 0): 26  Top Validation Acc: 1.0
8 2 [array([0.8445684 , 0.02279957, 0.02113723, 0.07051456, 0.04098024],
      dtype=float32)]
Fold [4/5] Epoch [0/100] Initial Loss: 0.1310, Training Loss: 0.1310, Initial Validation Loss: 0.1130, Validation Loss: 0.1130,V Acc: 0.5229, Top 70th Acc: 0.6623, Bottom 30th Acc: 0.1875
Fold [4/5] Epoch [10/100] Initial Loss: 0.1310, Training Loss: 0.0218, Initial Validation Loss: 0.1130, Validation Loss: 0.0282,V Acc: 0.8349, Top 70th Acc: 0.9870, Bottom 30th Acc: 0.4688
Fold [4/5] Epoch [20/100] Initial Loss: 0.1310, Training Loss: 0.0159, Initial Validation Loss: 0.1130, Validation Loss: 0.0255,V Acc: 0.8991, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.7500
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.948051948051948
Fold [5/5] Epoch [0/100] Initial Loss: 0.1329, Training Loss: 0.1329, Initial Validation Loss: 0.1141, Validation Loss: 0.1141,V Acc: 0.4444, Top 70th Acc: 0.5789, Bottom 30th Acc: 0.1250
Fold [5/5] Epoch [10/100] Initial Loss: 0.1329, Training Loss: 0.0233, Initial Validation Loss: 0.1141, Validation Loss: 0.0290,V Acc: 0.8519, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.5938
Fold [5/5] Epoch [20/100] Initial Loss: 0.1329, Training Loss: 0.0155, Initial Validation Loss: 0.1141, Validation Loss: 0.0288,V Acc: 0.8519, Top 70th Acc: 0.9868, Bottom 30th Acc: 0.5312
Stopping early at Epoch (base 0): 20  Rolling back to Epoch (base 0): 15  Top Validation Acc: 0.9868421052631579
Running train_nn.py with seed 9
CUDA:False
Training samples count:  550
Training on 21 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1399, Training Loss: 0.1399, Initial Validation Loss: 0.1385, Validation Loss: 0.1385,V Acc: 0.2679, Top 70th Acc: 0.2658, Bottom 30th Acc: 0.2727
Fold [1/5] Epoch [10/100] Initial Loss: 0.1399, Training Loss: 0.0237, Initial Validation Loss: 0.1385, Validation Loss: 0.0338,V Acc: 0.8482, Top 70th Acc: 0.9494, Bottom 30th Acc: 0.6061
Fold [1/5] Epoch [20/100] Initial Loss: 0.1399, Training Loss: 0.0155, Initial Validation Loss: 0.1385, Validation Loss: 0.0320,V Acc: 0.8214, Top 70th Acc: 0.9241, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.9746835443037974
Fold [2/5] Epoch [0/100] Initial Loss: 0.1379, Training Loss: 0.1379, Initial Validation Loss: 0.1286, Validation Loss: 0.1286,V Acc: 0.4414, Top 70th Acc: 0.5000, Bottom 30th Acc: 0.3030
Fold [2/5] Epoch [10/100] Initial Loss: 0.1379, Training Loss: 0.0233, Initial Validation Loss: 0.1286, Validation Loss: 0.0323,V Acc: 0.8829, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.7576
Stopping early at Epoch (base 0): 19  Rolling back to Epoch (base 0): 14  Top Validation Acc: 0.9487179487179487
Fold [3/5] Epoch [0/100] Initial Loss: 0.1392, Training Loss: 0.1392, Initial Validation Loss: 0.1281, Validation Loss: 0.1281,V Acc: 0.5000, Top 70th Acc: 0.5714, Bottom 30th Acc: 0.3333
Fold [3/5] Epoch [10/100] Initial Loss: 0.1392, Training Loss: 0.0234, Initial Validation Loss: 0.1281, Validation Loss: 0.0300,V Acc: 0.8727, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 17  Rolling back to Epoch (base 0): 12  Top Validation Acc: 0.987012987012987
Fold [4/5] Epoch [0/100] Initial Loss: 0.1374, Training Loss: 0.1374, Initial Validation Loss: 0.1222, Validation Loss: 0.1222,V Acc: 0.4679, Top 70th Acc: 0.6104, Bottom 30th Acc: 0.1250
Fold [4/5] Epoch [10/100] Initial Loss: 0.1374, Training Loss: 0.0248, Initial Validation Loss: 0.1222, Validation Loss: 0.0232,V Acc: 0.8899, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.6875
Stopping early at Epoch (base 0): 17  Rolling back to Epoch (base 0): 12  Top Validation Acc: 0.974025974025974
9 3 [array([0.81301934, 0.01535233, 0.02746777, 0.1060546 , 0.03810601],
      dtype=float32)]
Fold [5/5] Epoch [0/100] Initial Loss: 0.1327, Training Loss: 0.1327, Initial Validation Loss: 0.1141, Validation Loss: 0.1141,V Acc: 0.6204, Top 70th Acc: 0.8158, Bottom 30th Acc: 0.1562
Fold [5/5] Epoch [10/100] Initial Loss: 0.1327, Training Loss: 0.0216, Initial Validation Loss: 0.1141, Validation Loss: 0.0282,V Acc: 0.8611, Top 70th Acc: 0.9868, Bottom 30th Acc: 0.5625
Fold [5/5] Epoch [20/100] Initial Loss: 0.1327, Training Loss: 0.0157, Initial Validation Loss: 0.1141, Validation Loss: 0.0273,V Acc: 0.8796, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.7188
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.9868421052631579
Running train_nn.py with seed 10
CUDA:False
Training samples count:  550
Training on 21 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1312, Training Loss: 0.1312, Initial Validation Loss: 0.1090, Validation Loss: 0.1090,V Acc: 0.5893, Top 70th Acc: 0.7215, Bottom 30th Acc: 0.2727
Fold [1/5] Epoch [10/100] Initial Loss: 0.1312, Training Loss: 0.0210, Initial Validation Loss: 0.1090, Validation Loss: 0.0292,V Acc: 0.8393, Top 70th Acc: 0.9241, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 11  Rolling back to Epoch (base 0): 6  Top Validation Acc: 0.9367088607594937
Fold [2/5] Epoch [0/100] Initial Loss: 0.1401, Training Loss: 0.1401, Initial Validation Loss: 0.1338, Validation Loss: 0.1338,V Acc: 0.3874, Top 70th Acc: 0.4231, Bottom 30th Acc: 0.3030
Fold [2/5] Epoch [10/100] Initial Loss: 0.1401, Training Loss: 0.0242, Initial Validation Loss: 0.1338, Validation Loss: 0.0299,V Acc: 0.8559, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.5758
Fold [2/5] Epoch [20/100] Initial Loss: 0.1401, Training Loss: 0.0174, Initial Validation Loss: 0.1338, Validation Loss: 0.0245,V Acc: 0.8649, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 27  Rolling back to Epoch (base 0): 22  Top Validation Acc: 1.0
Fold [3/5] Epoch [0/100] Initial Loss: 0.1332, Training Loss: 0.1332, Initial Validation Loss: 0.1199, Validation Loss: 0.1199,V Acc: 0.4000, Top 70th Acc: 0.5455, Bottom 30th Acc: 0.0606
Fold [3/5] Epoch [10/100] Initial Loss: 0.1332, Training Loss: 0.0201, Initial Validation Loss: 0.1199, Validation Loss: 0.0245,V Acc: 0.8727, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.6364
Fold [3/5] Epoch [20/100] Initial Loss: 0.1332, Training Loss: 0.0150, Initial Validation Loss: 0.1199, Validation Loss: 0.0249,V Acc: 0.8818, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 28  Rolling back to Epoch (base 0): 23  Top Validation Acc: 0.922077922077922
10 2 [array([0.7550023 , 0.0155523 , 0.02325913, 0.08396377, 0.12222251],
      dtype=float32)]
Fold [4/5] Epoch [0/100] Initial Loss: 0.1315, Training Loss: 0.1315, Initial Validation Loss: 0.1180, Validation Loss: 0.1180,V Acc: 0.4771, Top 70th Acc: 0.5844, Bottom 30th Acc: 0.2188
Fold [4/5] Epoch [10/100] Initial Loss: 0.1315, Training Loss: 0.0256, Initial Validation Loss: 0.1180, Validation Loss: 0.0285,V Acc: 0.8899, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.6875
Stopping early at Epoch (base 0): 15  Rolling back to Epoch (base 0): 10  Top Validation Acc: 0.974025974025974
Fold [5/5] Epoch [0/100] Initial Loss: 0.1339, Training Loss: 0.1339, Initial Validation Loss: 0.1255, Validation Loss: 0.1255,V Acc: 0.3981, Top 70th Acc: 0.5000, Bottom 30th Acc: 0.1562
Fold [5/5] Epoch [10/100] Initial Loss: 0.1339, Training Loss: 0.0283, Initial Validation Loss: 0.1255, Validation Loss: 0.0262,V Acc: 0.9074, Top 70th Acc: 1.0000, Bottom 30th Acc: 0.6875
Fold [5/5] Epoch [20/100] Initial Loss: 0.1339, Training Loss: 0.0163, Initial Validation Loss: 0.1255, Validation Loss: 0.0225,V Acc: 0.8981, Top 70th Acc: 0.9868, Bottom 30th Acc: 0.6875
Stopping early at Epoch (base 0): 27  Rolling back to Epoch (base 0): 22  Top Validation Acc: 1.0
Running train_nn.py with seed 11
CUDA:False
Training samples count:  550
Training on 21 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1337, Training Loss: 0.1337, Initial Validation Loss: 0.1238, Validation Loss: 0.1238,V Acc: 0.3661, Top 70th Acc: 0.4810, Bottom 30th Acc: 0.0909
Fold [1/5] Epoch [30/100] Initial Loss: 0.1409, Training Loss: 0.0036, Initial Validation Loss: 0.1374, Validation Loss: 0.0276,V Acc: 0.8750, Top 70th Acc: 0.9494, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 31  Rolling back to Epoch (base 0): 26  Top Validation Acc: 0.9493670886075949
4 0 [array([0.37089306, 0.11849513, 0.07383856, 0.17517407, 0.26159924],
      dtype=float32)]
Fold [2/5] Epoch [0/100] Initial Loss: 0.1403, Training Loss: 0.1403, Initial Validation Loss: 0.1339, Validation Loss: 0.1339,V Acc: 0.2703, Top 70th Acc: 0.3462, Bottom 30th Acc: 0.0909
Fold [2/5] Epoch [10/100] Initial Loss: 0.1403, Training Loss: 0.0190, Initial Validation Loss: 0.1339, Validation Loss: 0.0304,V Acc: 0.8649, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.6970
Fold [2/5] Epoch [20/100] Initial Loss: 0.1403, Training Loss: 0.0055, Initial Validation Loss: 0.1339, Validation Loss: 0.0262,V Acc: 0.8559, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.9358974358974359
Fold [3/5] Epoch [0/100] Initial Loss: 0.1388, Training Loss: 0.1388, Initial Validation Loss: 0.1360, Validation Loss: 0.1360,V Acc: 0.2636, Top 70th Acc: 0.3506, Bottom 30th Acc: 0.0606
Fold [3/5] Epoch [10/100] Initial Loss: 0.1388, Training Loss: 0.0154, Initial Validation Loss: 0.1360, Validation Loss: 0.0344,V Acc: 0.8273, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.4848
Stopping early at Epoch (base 0): 19  Rolling back to Epoch (base 0): 14  Top Validation Acc: 0.961038961038961
Fold [4/5] Epoch [0/100] Initial Loss: 0.1397, Training Loss: 0.1397, Initial Validation Loss: 0.1340, Validation Loss: 0.1340,V Acc: 0.2477, Top 70th Acc: 0.3117, Bottom 30th Acc: 0.0938
Fold [4/5] Epoch [10/100] Initial Loss: 0.1397, Training Loss: 0.0265, Initial Validation Loss: 0.1340, Validation Loss: 0.0372,V Acc: 0.8257, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.5938
Fold [4/5] Epoch [20/100] Initial Loss: 0.1397, Training Loss: 0.0049, Initial Validation Loss: 0.1340, Validation Loss: 0.0255,V Acc: 0.8716, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.7188
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.935064935064935
Fold [5/5] Epoch [0/100] Initial Loss: 0.1394, Training Loss: 0.1394, Initial Validation Loss: 0.1335, Validation Loss: 0.1335,V Acc: 0.3889, Top 70th Acc: 0.3947, Bottom 30th Acc: 0.3750
Fold [5/5] Epoch [10/100] Initial Loss: 0.1394, Training Loss: 0.0217, Initial Validation Loss: 0.1335, Validation Loss: 0.0434,V Acc: 0.8148, Top 70th Acc: 0.9211, Bottom 30th Acc: 0.5625
Fold [5/5] Epoch [20/100] Initial Loss: 0.1394, Training Loss: 0.0057, Initial Validation Loss: 0.1335, Validation Loss: 0.0376,V Acc: 0.8148, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.5312
Fold [5/5] Epoch [30/100] Initial Loss: 0.1394, Training Loss: 0.0042, Initial Validation Loss: 0.1335, Validation Loss: 0.0356,V Acc: 0.8148, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.5312
Fold [5/5] Epoch [40/100] Initial Loss: 0.1394, Training Loss: 0.0039, Initial Validation Loss: 0.1335, Validation Loss: 0.0348,V Acc: 0.8241, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.5625
Fold [5/5] Epoch [50/100] Initial Loss: 0.1394, Training Loss: 0.0037, Initial Validation Loss: 0.1335, Validation Loss: 0.0343,V Acc: 0.8519, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.6250
Stopping early at Epoch (base 0): 58  Rolling back to Epoch (base 0): 53  Top Validation Acc: 0.9473684210526315
Running train_nn.py with seed 5
CUDA:False
Training samples count:  550
Training on 162 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1375, Training Loss: 0.1375, Initial Validation Loss: 0.1362, Validation Loss: 0.1362,V Acc: 0.3304, Top 70th Acc: 0.3797, Bottom 30th Acc: 0.2121
Fold [1/5] Epoch [10/100] Initial Loss: 0.1375, Training Loss: 0.0267, Initial Validation Loss: 0.1362, Validation Loss: 0.0482,V Acc: 0.7411, Top 70th Acc: 0.8734, Bottom 30th Acc: 0.4242
Fold [1/5] Epoch [20/100] Initial Loss: 0.1375, Training Loss: 0.0061, Initial Validation Loss: 0.1362, Validation Loss: 0.0395,V Acc: 0.7857, Top 70th Acc: 0.9241, Bottom 30th Acc: 0.4545
Fold [1/5] Epoch [30/100] Initial Loss: 0.1375, Training Loss: 0.0039, Initial Validation Loss: 0.1362, Validation Loss: 0.0378,V Acc: 0.7679, Top 70th Acc: 0.9367, Bottom 30th Acc: 0.3636
Stopping early at Epoch (base 0): 34  Rolling back to Epoch (base 0): 29  Top Validation Acc: 0.9493670886075949
Fold [2/5] Epoch [0/100] Initial Loss: 0.1411, Training Loss: 0.1411, Initial Validation Loss: 0.1357, Validation Loss: 0.1357,V Acc: 0.3423, Top 70th Acc: 0.3718, Bottom 30th Acc: 0.2727
Fold [2/5] Epoch [10/100] Initial Loss: 0.1411, Training Loss: 0.0217, Initial Validation Loss: 0.1357, Validation Loss: 0.0393,V Acc: 0.8198, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.5455
Fold [2/5] Epoch [20/100] Initial Loss: 0.1411, Training Loss: 0.0050, Initial Validation Loss: 0.1357, Validation Loss: 0.0341,V Acc: 0.8468, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 21  Rolling back to Epoch (base 0): 16  Top Validation Acc: 0.9487179487179487
Fold [3/5] Epoch [0/100] Initial Loss: 0.1424, Training Loss: 0.1424, Initial Validation Loss: 0.1335, Validation Loss: 0.1335,V Acc: 0.3182, Top 70th Acc: 0.3896, Bottom 30th Acc: 0.1515
Fold [3/5] Epoch [10/100] Initial Loss: 0.1424, Training Loss: 0.0325, Initial Validation Loss: 0.1335, Validation Loss: 0.0508,V Acc: 0.8273, Top 70th Acc: 0.8831, Bottom 30th Acc: 0.6970
Fold [3/5] Epoch [20/100] Initial Loss: 0.1424, Training Loss: 0.0074, Initial Validation Loss: 0.1335, Validation Loss: 0.0335,V Acc: 0.8636, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.7576
Fold [3/5] Epoch [30/100] Initial Loss: 0.1424, Training Loss: 0.0049, Initial Validation Loss: 0.1335, Validation Loss: 0.0315,V Acc: 0.8727, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.7576
Fold [3/5] Epoch [40/100] Initial Loss: 0.1424, Training Loss: 0.0039, Initial Validation Loss: 0.1335, Validation Loss: 0.0307,V Acc: 0.8727, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.7576
Stopping early at Epoch (base 0): 42  Rolling back to Epoch (base 0): 37  Top Validation Acc: 0.935064935064935
5 2 [array([0.15392333, 0.02314783, 0.04036498, 0.33234102, 0.4502228 ],
      dtype=float32)]
Fold [4/5] Epoch [0/100] Initial Loss: 0.1387, Training Loss: 0.1387, Initial Validation Loss: 0.1290, Validation Loss: 0.1290,V Acc: 0.3761, Top 70th Acc: 0.4935, Bottom 30th Acc: 0.0938
Fold [4/5] Epoch [10/100] Initial Loss: 0.1387, Training Loss: 0.0173, Initial Validation Loss: 0.1290, Validation Loss: 0.0349,V Acc: 0.8440, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.6562
Fold [4/5] Epoch [20/100] Initial Loss: 0.1387, Training Loss: 0.0057, Initial Validation Loss: 0.1290, Validation Loss: 0.0319,V Acc: 0.8349, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.5625
Fold [4/5] Epoch [30/100] Initial Loss: 0.1387, Training Loss: 0.0044, Initial Validation Loss: 0.1290, Validation Loss: 0.0310,V Acc: 0.8349, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.5625
Fold [4/5] Epoch [40/100] Initial Loss: 0.1387, Training Loss: 0.0041, Initial Validation Loss: 0.1290, Validation Loss: 0.0305,V Acc: 0.8349, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.5625
Fold [4/5] Epoch [50/100] Initial Loss: 0.1387, Training Loss: 0.0039, Initial Validation Loss: 0.1290, Validation Loss: 0.0303,V Acc: 0.8349, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.5625
Stopping early at Epoch (base 0): 54  Rolling back to Epoch (base 0): 49  Top Validation Acc: 0.948051948051948
Fold [5/5] Epoch [0/100] Initial Loss: 0.1392, Training Loss: 0.1392, Initial Validation Loss: 0.1353, Validation Loss: 0.1353,V Acc: 0.2500, Top 70th Acc: 0.2632, Bottom 30th Acc: 0.2188
Fold [5/5] Epoch [10/100] Initial Loss: 0.1392, Training Loss: 0.0264, Initial Validation Loss: 0.1353, Validation Loss: 0.0376,V Acc: 0.8148, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.4688
Fold [5/5] Epoch [20/100] Initial Loss: 0.1392, Training Loss: 0.0055, Initial Validation Loss: 0.1353, Validation Loss: 0.0244,V Acc: 0.8704, Top 70th Acc: 0.9868, Bottom 30th Acc: 0.5938
Fold [5/5] Epoch [30/100] Initial Loss: 0.1392, Training Loss: 0.0042, Initial Validation Loss: 0.1353, Validation Loss: 0.0236,V Acc: 0.8519, Top 70th Acc: 0.9868, Bottom 30th Acc: 0.5312
Fold [4/5] Epoch [30/100] Initial Loss: 0.1419, Training Loss: 0.0778, Initial Validation Loss: 0.1286, Validation Loss: 0.0794,V Acc: 0.6147, Top 70th Acc: 0.7532, Bottom 30th Acc: 0.2812
Stopping early at Epoch (base 0): 34  Rolling back to Epoch (base 0): 29  Top Validation Acc: 0.7402597402597403
Fold [5/5] Epoch [0/100] Initial Loss: 0.1355, Training Loss: 0.1355, Initial Validation Loss: 0.1205, Validation Loss: 0.1205,V Acc: 0.4259, Top 70th Acc: 0.5263, Bottom 30th Acc: 0.1875
Fold [5/5] Epoch [10/100] Initial Loss: 0.1355, Training Loss: 0.0791, Initial Validation Loss: 0.1205, Validation Loss: 0.0791,V Acc: 0.5648, Top 70th Acc: 0.6842, Bottom 30th Acc: 0.2812
Fold [5/5] Epoch [20/100] Initial Loss: 0.1355, Training Loss: 0.0777, Initial Validation Loss: 0.1205, Validation Loss: 0.0791,V Acc: 0.5648, Top 70th Acc: 0.6711, Bottom 30th Acc: 0.3125
Stopping early at Epoch (base 0): 21  Rolling back to Epoch (base 0): 16  Top Validation Acc: 0.6710526315789473
6 4 [array([0.1366143 , 0.37954262, 0.12586783, 0.21065094, 0.14732437],
      dtype=float32)]
Running train_nn.py with seed 7
CUDA:False
Training samples count:  550
Training on 2 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1367, Training Loss: 0.1367, Initial Validation Loss: 0.1293, Validation Loss: 0.1293,V Acc: 0.3750, Top 70th Acc: 0.5063, Bottom 30th Acc: 0.0606
Fold [1/5] Epoch [10/100] Initial Loss: 0.1367, Training Loss: 0.0811, Initial Validation Loss: 0.1293, Validation Loss: 0.0812,V Acc: 0.5982, Top 70th Acc: 0.7215, Bottom 30th Acc: 0.3030
Stopping early at Epoch (base 0): 16  Rolling back to Epoch (base 0): 11  Top Validation Acc: 0.7215189873417721
Fold [2/5] Epoch [0/100] Initial Loss: 0.1332, Training Loss: 0.1332, Initial Validation Loss: 0.1173, Validation Loss: 0.1173,V Acc: 0.5225, Top 70th Acc: 0.6026, Bottom 30th Acc: 0.3333
Fold [2/5] Epoch [10/100] Initial Loss: 0.1332, Training Loss: 0.0811, Initial Validation Loss: 0.1173, Validation Loss: 0.0773,V Acc: 0.6306, Top 70th Acc: 0.7308, Bottom 30th Acc: 0.3939
Fold [2/5] Epoch [20/100] Initial Loss: 0.1332, Training Loss: 0.0792, Initial Validation Loss: 0.1173, Validation Loss: 0.0755,V Acc: 0.6216, Top 70th Acc: 0.7436, Bottom 30th Acc: 0.3333
Stopping early at Epoch (base 0): 29  Rolling back to Epoch (base 0): 24  Top Validation Acc: 0.7307692307692307
Fold [3/5] Epoch [0/100] Initial Loss: 0.1383, Training Loss: 0.1383, Initial Validation Loss: 0.1302, Validation Loss: 0.1302,V Acc: 0.4182, Top 70th Acc: 0.4675, Bottom 30th Acc: 0.3030
Fold [3/5] Epoch [10/100] Initial Loss: 0.1383, Training Loss: 0.0801, Initial Validation Loss: 0.1302, Validation Loss: 0.0820,V Acc: 0.6455, Top 70th Acc: 0.7403, Bottom 30th Acc: 0.4242
Fold [3/5] Epoch [20/100] Initial Loss: 0.1383, Training Loss: 0.0782, Initial Validation Loss: 0.1302, Validation Loss: 0.0797,V Acc: 0.6455, Top 70th Acc: 0.7532, Bottom 30th Acc: 0.3939
Fold [3/5] Epoch [30/100] Initial Loss: 0.1383, Training Loss: 0.0777, Initial Validation Loss: 0.1302, Validation Loss: 0.0793,V Acc: 0.6364, Top 70th Acc: 0.7662, Bottom 30th Acc: 0.3333
Stopping early at Epoch (base 0): 31  Rolling back to Epoch (base 0): 26  Top Validation Acc: 0.7272727272727273
Fold [4/5] Epoch [0/100] Initial Loss: 0.1306, Training Loss: 0.1306, Initial Validation Loss: 0.1237, Validation Loss: 0.1237,V Acc: 0.4312, Top 70th Acc: 0.4675, Bottom 30th Acc: 0.3438
Fold [4/5] Epoch [10/100] Initial Loss: 0.1306, Training Loss: 0.0799, Initial Validation Loss: 0.1237, Validation Loss: 0.0839,V Acc: 0.6330, Top 70th Acc: 0.7273, Bottom 30th Acc: 0.4062
Fold [4/5] Epoch [20/100] Initial Loss: 0.1306, Training Loss: 0.0780, Initial Validation Loss: 0.1237, Validation Loss: 0.0815,V Acc: 0.6514, Top 70th Acc: 0.7532, Bottom 30th Acc: 0.4062
Fold [4/5] Epoch [30/100] Initial Loss: 0.1306, Training Loss: 0.0777, Initial Validation Loss: 0.1237, Validation Loss: 0.0809,V Acc: 0.6514, Top 70th Acc: 0.7532, Bottom 30th Acc: 0.4062
Fold [4/5] Epoch [40/100] Initial Loss: 0.1306, Training Loss: 0.0772, Initial Validation Loss: 0.1237, Validation Loss: 0.0805,V Acc: 0.6514, Top 70th Acc: 0.7532, Bottom 30th Acc: 0.4062
Stopping early at Epoch (base 0): 44  Rolling back to Epoch (base 0): 39  Top Validation Acc: 0.7662337662337663
7 3 [array([0.10981462, 0.36264536, 0.14899302, 0.22939444, 0.14915258],
      dtype=float32)]
Fold [5/5] Epoch [0/100] Initial Loss: 0.1424, Training Loss: 0.1424, Initial Validation Loss: 0.1314, Validation Loss: 0.1314,V Acc: 0.2870, Top 70th Acc: 0.3816, Bottom 30th Acc: 0.0625
Fold [5/5] Epoch [10/100] Initial Loss: 0.1424, Training Loss: 0.0819, Initial Validation Loss: 0.1314, Validation Loss: 0.0736,V Acc: 0.6574, Top 70th Acc: 0.7237, Bottom 30th Acc: 0.5000
Fold [5/5] Epoch [20/100] Initial Loss: 0.1424, Training Loss: 0.0797, Initial Validation Loss: 0.1314, Validation Loss: 0.0724,V Acc: 0.6574, Top 70th Acc: 0.7237, Bottom 30th Acc: 0.5000
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.7236842105263158
Running train_nn.py with seed 8
CUDA:False
Training samples count:  550
Training on 2 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1294, Training Loss: 0.1294, Initial Validation Loss: 0.1197, Validation Loss: 0.1197,V Acc: 0.4732, Top 70th Acc: 0.4684, Bottom 30th Acc: 0.4848
Fold [1/5] Epoch [10/100] Initial Loss: 0.1294, Training Loss: 0.0833, Initial Validation Loss: 0.1197, Validation Loss: 0.0711,V Acc: 0.6696, Top 70th Acc: 0.8101, Bottom 30th Acc: 0.3333
Fold [1/5] Epoch [20/100] Initial Loss: 0.1294, Training Loss: 0.0810, Initial Validation Loss: 0.1197, Validation Loss: 0.0675,V Acc: 0.6786, Top 70th Acc: 0.8101, Bottom 30th Acc: 0.3636
Fold [1/5] Epoch [30/100] Initial Loss: 0.1294, Training Loss: 0.0805, Initial Validation Loss: 0.1197, Validation Loss: 0.0663,V Acc: 0.6786, Top 70th Acc: 0.8228, Bottom 30th Acc: 0.3333
Stopping early at Epoch (base 0): 33  Rolling back to Epoch (base 0): 28  Top Validation Acc: 0.8227848101265823
Fold [2/5] Epoch [0/100] Initial Loss: 0.1364, Training Loss: 0.1364, Initial Validation Loss: 0.1275, Validation Loss: 0.1275,V Acc: 0.4144, Top 70th Acc: 0.4359, Bottom 30th Acc: 0.3636
Fold [2/5] Epoch [10/100] Initial Loss: 0.1364, Training Loss: 0.0791, Initial Validation Loss: 0.1275, Validation Loss: 0.0843,V Acc: 0.5946, Top 70th Acc: 0.6923, Bottom 30th Acc: 0.3636
Stopping early at Epoch (base 0): 15  Rolling back to Epoch (base 0): 10  Top Validation Acc: 0.7051282051282052
Fold [3/5] Epoch [0/100] Initial Loss: 0.1396, Training Loss: 0.1396, Initial Validation Loss: 0.1340, Validation Loss: 0.1340,V Acc: 0.2727, Top 70th Acc: 0.3506, Bottom 30th Acc: 0.0909
Fold [3/5] Epoch [10/100] Initial Loss: 0.1396, Training Loss: 0.0807, Initial Validation Loss: 0.1340, Validation Loss: 0.0810,V Acc: 0.5727, Top 70th Acc: 0.7532, Bottom 30th Acc: 0.1515
Fold [3/5] Epoch [20/100] Initial Loss: 0.1396, Training Loss: 0.0792, Initial Validation Loss: 0.1340, Validation Loss: 0.0793,V Acc: 0.6182, Top 70th Acc: 0.7403, Bottom 30th Acc: 0.3333
Fold [3/5] Epoch [30/100] Initial Loss: 0.1396, Training Loss: 0.0787, Initial Validation Loss: 0.1340, Validation Loss: 0.0788,V Acc: 0.6182, Top 70th Acc: 0.7403, Bottom 30th Acc: 0.3333
Stopping early at Epoch (base 0): 30  Rolling back to Epoch (base 0): 25  Top Validation Acc: 0.7402597402597403
8 2 [array([0.11884498, 0.39560348, 0.13757384, 0.19120233, 0.15677539],
      dtype=float32)]
Fold [4/5] Epoch [0/100] Initial Loss: 0.1379, Training Loss: 0.1379, Initial Validation Loss: 0.1273, Validation Loss: 0.1273,V Acc: 0.3670, Top 70th Acc: 0.4935, Bottom 30th Acc: 0.0625
Fold [4/5] Epoch [10/100] Initial Loss: 0.1379, Training Loss: 0.0796, Initial Validation Loss: 0.1273, Validation Loss: 0.0826,V Acc: 0.6239, Top 70th Acc: 0.6883, Bottom 30th Acc: 0.4688
Fold [4/5] Epoch [20/100] Initial Loss: 0.1379, Training Loss: 0.0774, Initial Validation Loss: 0.1273, Validation Loss: 0.0817,V Acc: 0.6330, Top 70th Acc: 0.7013, Bottom 30th Acc: 0.4688
Stopping early at Epoch (base 0): 22  Rolling back to Epoch (base 0): 17  Top Validation Acc: 0.7012987012987013
Fold [5/5] Epoch [0/100] Initial Loss: 0.1418, Training Loss: 0.1418, Initial Validation Loss: 0.1275, Validation Loss: 0.1275,V Acc: 0.2500, Top 70th Acc: 0.3553, Bottom 30th Acc: 0.0000
Fold [1/5] Epoch [20/100] Initial Loss: 0.1373, Training Loss: 0.0143, Initial Validation Loss: 0.1315, Validation Loss: 0.0305,V Acc: 0.8571, Top 70th Acc: 0.9494, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 27  Rolling back to Epoch (base 0): 22  Top Validation Acc: 0.9493670886075949
Fold [2/5] Epoch [0/100] Initial Loss: 0.1395, Training Loss: 0.1395, Initial Validation Loss: 0.1314, Validation Loss: 0.1314,V Acc: 0.2973, Top 70th Acc: 0.3462, Bottom 30th Acc: 0.1818
Fold [2/5] Epoch [10/100] Initial Loss: 0.1395, Training Loss: 0.0273, Initial Validation Loss: 0.1314, Validation Loss: 0.0346,V Acc: 0.8198, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.5455
Fold [2/5] Epoch [20/100] Initial Loss: 0.1395, Training Loss: 0.0144, Initial Validation Loss: 0.1314, Validation Loss: 0.0311,V Acc: 0.8108, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.4848
Fold [2/5] Epoch [30/100] Initial Loss: 0.1395, Training Loss: 0.0122, Initial Validation Loss: 0.1314, Validation Loss: 0.0306,V Acc: 0.8108, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.5152
Stopping early at Epoch (base 0): 31  Rolling back to Epoch (base 0): 26  Top Validation Acc: 0.9487179487179487
Fold [3/5] Epoch [0/100] Initial Loss: 0.1410, Training Loss: 0.1410, Initial Validation Loss: 0.1340, Validation Loss: 0.1340,V Acc: 0.3455, Top 70th Acc: 0.4026, Bottom 30th Acc: 0.2121
Fold [3/5] Epoch [10/100] Initial Loss: 0.1410, Training Loss: 0.0348, Initial Validation Loss: 0.1340, Validation Loss: 0.0398,V Acc: 0.8364, Top 70th Acc: 0.8961, Bottom 30th Acc: 0.6970
Fold [3/5] Epoch [20/100] Initial Loss: 0.1410, Training Loss: 0.0164, Initial Validation Loss: 0.1340, Validation Loss: 0.0265,V Acc: 0.8818, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.7273
Fold [3/5] Epoch [30/100] Initial Loss: 0.1410, Training Loss: 0.0132, Initial Validation Loss: 0.1340, Validation Loss: 0.0234,V Acc: 0.8909, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.7273
Stopping early at Epoch (base 0): 37  Rolling back to Epoch (base 0): 32  Top Validation Acc: 0.961038961038961
Fold [4/5] Epoch [0/100] Initial Loss: 0.1396, Training Loss: 0.1396, Initial Validation Loss: 0.1349, Validation Loss: 0.1349,V Acc: 0.3486, Top 70th Acc: 0.4545, Bottom 30th Acc: 0.0938
Fold [4/5] Epoch [10/100] Initial Loss: 0.1396, Training Loss: 0.0318, Initial Validation Loss: 0.1349, Validation Loss: 0.0419,V Acc: 0.8073, Top 70th Acc: 0.8831, Bottom 30th Acc: 0.6250
Fold [4/5] Epoch [20/100] Initial Loss: 0.1396, Training Loss: 0.0169, Initial Validation Loss: 0.1349, Validation Loss: 0.0350,V Acc: 0.8257, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.5625
Stopping early at Epoch (base 0): 27  Rolling back to Epoch (base 0): 22  Top Validation Acc: 0.935064935064935
7 3 [array([0.4288028 , 0.11734082, 0.1581077 , 0.16884238, 0.1269063 ],
      dtype=float32)]
Fold [5/5] Epoch [0/100] Initial Loss: 0.1363, Training Loss: 0.1363, Initial Validation Loss: 0.1266, Validation Loss: 0.1266,V Acc: 0.4074, Top 70th Acc: 0.5000, Bottom 30th Acc: 0.1875
Fold [5/5] Epoch [10/100] Initial Loss: 0.1363, Training Loss: 0.0354, Initial Validation Loss: 0.1266, Validation Loss: 0.0407,V Acc: 0.8056, Top 70th Acc: 0.9079, Bottom 30th Acc: 0.5625
Fold [5/5] Epoch [20/100] Initial Loss: 0.1363, Training Loss: 0.0148, Initial Validation Loss: 0.1266, Validation Loss: 0.0304,V Acc: 0.8704, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.6875
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.9473684210526315
Running train_nn.py with seed 8
CUDA:False
Training samples count:  550
Training on 40 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1406, Training Loss: 0.1406, Initial Validation Loss: 0.1383, Validation Loss: 0.1383,V Acc: 0.2500, Top 70th Acc: 0.3291, Bottom 30th Acc: 0.0606
Fold [1/5] Epoch [10/100] Initial Loss: 0.1406, Training Loss: 0.0282, Initial Validation Loss: 0.1383, Validation Loss: 0.0375,V Acc: 0.8393, Top 70th Acc: 0.9494, Bottom 30th Acc: 0.5758
Fold [1/5] Epoch [20/100] Initial Loss: 0.1406, Training Loss: 0.0155, Initial Validation Loss: 0.1383, Validation Loss: 0.0312,V Acc: 0.8125, Top 70th Acc: 0.9747, Bottom 30th Acc: 0.4242
Stopping early at Epoch (base 0): 22  Rolling back to Epoch (base 0): 17  Top Validation Acc: 0.9746835443037974
Fold [2/5] Epoch [0/100] Initial Loss: 0.1371, Training Loss: 0.1371, Initial Validation Loss: 0.1295, Validation Loss: 0.1295,V Acc: 0.3694, Top 70th Acc: 0.4872, Bottom 30th Acc: 0.0909
Fold [2/5] Epoch [10/100] Initial Loss: 0.1371, Training Loss: 0.0377, Initial Validation Loss: 0.1295, Validation Loss: 0.0446,V Acc: 0.7568, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.3939
Fold [2/5] Epoch [20/100] Initial Loss: 0.1371, Training Loss: 0.0144, Initial Validation Loss: 0.1295, Validation Loss: 0.0325,V Acc: 0.8108, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 22  Rolling back to Epoch (base 0): 17  Top Validation Acc: 0.8974358974358975
Fold [3/5] Epoch [0/100] Initial Loss: 0.1378, Training Loss: 0.1378, Initial Validation Loss: 0.1321, Validation Loss: 0.1321,V Acc: 0.3636, Top 70th Acc: 0.4286, Bottom 30th Acc: 0.2121
Fold [3/5] Epoch [10/100] Initial Loss: 0.1378, Training Loss: 0.0383, Initial Validation Loss: 0.1321, Validation Loss: 0.0477,V Acc: 0.7727, Top 70th Acc: 0.8831, Bottom 30th Acc: 0.5152
Fold [3/5] Epoch [20/100] Initial Loss: 0.1378, Training Loss: 0.0173, Initial Validation Loss: 0.1321, Validation Loss: 0.0261,V Acc: 0.8636, Top 70th Acc: 0.9870, Bottom 30th Acc: 0.5758
Fold [3/5] Epoch [30/100] Initial Loss: 0.1378, Training Loss: 0.0132, Initial Validation Loss: 0.1321, Validation Loss: 0.0242,V Acc: 0.8636, Top 70th Acc: 0.9870, Bottom 30th Acc: 0.5758
Fold [3/5] Epoch [40/100] Initial Loss: 0.1378, Training Loss: 0.0112, Initial Validation Loss: 0.1321, Validation Loss: 0.0241,V Acc: 0.8636, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 42  Rolling back to Epoch (base 0): 37  Top Validation Acc: 0.987012987012987
8 2 [array([0.7515566 , 0.04337667, 0.05700311, 0.0725835 , 0.07548005],
      dtype=float32)]
Fold [4/5] Epoch [0/100] Initial Loss: 0.1398, Training Loss: 0.1398, Initial Validation Loss: 0.1329, Validation Loss: 0.1329,V Acc: 0.2477, Top 70th Acc: 0.2987, Bottom 30th Acc: 0.1250
Fold [4/5] Epoch [10/100] Initial Loss: 0.1398, Training Loss: 0.0449, Initial Validation Loss: 0.1329, Validation Loss: 0.0599,V Acc: 0.7156, Top 70th Acc: 0.8182, Bottom 30th Acc: 0.4688
Fold [4/5] Epoch [20/100] Initial Loss: 0.1398, Training Loss: 0.0171, Initial Validation Loss: 0.1329, Validation Loss: 0.0421,V Acc: 0.7798, Top 70th Acc: 0.8312, Bottom 30th Acc: 0.6562
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.8311688311688312
Fold [5/5] Epoch [0/100] Initial Loss: 0.1388, Training Loss: 0.1388, Initial Validation Loss: 0.1275, Validation Loss: 0.1275,V Acc: 0.3148, Top 70th Acc: 0.4079, Bottom 30th Acc: 0.0938
Fold [5/5] Epoch [10/100] Initial Loss: 0.1388, Training Loss: 0.0316, Initial Validation Loss: 0.1275, Validation Loss: 0.0380,V Acc: 0.8333, Top 70th Acc: 0.9211, Bottom 30th Acc: 0.6250
Fold [5/5] Epoch [20/100] Initial Loss: 0.1388, Training Loss: 0.0143, Initial Validation Loss: 0.1275, Validation Loss: 0.0329,V Acc: 0.8148, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.5312
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.9342105263157895
Running train_nn.py with seed 9
CUDA:False
Training samples count:  550
Training on 40 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1400, Training Loss: 0.1400, Initial Validation Loss: 0.1383, Validation Loss: 0.1383,V Acc: 0.2857, Top 70th Acc: 0.3165, Bottom 30th Acc: 0.2121
Fold [1/5] Epoch [10/100] Initial Loss: 0.1400, Training Loss: 0.0252, Initial Validation Loss: 0.1383, Validation Loss: 0.0373,V Acc: 0.8571, Top 70th Acc: 0.8987, Bottom 30th Acc: 0.7576
Fold [1/5] Epoch [20/100] Initial Loss: 0.1400, Training Loss: 0.0137, Initial Validation Loss: 0.1383, Validation Loss: 0.0321,V Acc: 0.8482, Top 70th Acc: 0.9241, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 27  Rolling back to Epoch (base 0): 22  Top Validation Acc:training rf with seed 1
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 21 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 2
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 21 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 3
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 21 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 4
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 21 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 5
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 21 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 6
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 21 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 7
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 21 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 8
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 21 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 9
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 21 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 10
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 21 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 11
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 21 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 12
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 21 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 13
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 21 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 14
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 21 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 15
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 21 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 16
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 21 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 17
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 21 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 18
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 21 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 19
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 21 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 20
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 21 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 21
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 21 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 22
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 21 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 23
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 21 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 24
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 21 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 25
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 21 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 26
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 21 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 27
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 21 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 28
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 21 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 29
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 21 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 30
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 21 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 31
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 21 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 32
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 21 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 33
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 21 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 34
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 21 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 35
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 21 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 36
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 21 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 37
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 21 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 38
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 21 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 39
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 21 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 40
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 21 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 41
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 21 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 42
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 21 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 43
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 21 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 44
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 21 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 45
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Fold [2/5] Epoch [30/100] Initial Loss: 0.1427, Training Loss: 0.0164, Initial Validation Loss: 0.1323, Validation Loss: 0.0335,V Acc: 0.7928, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.4242
Stopping early at Epoch (base 0): 34  Rolling back to Epoch (base 0): 29  Top Validation Acc: 0.9487179487179487
Fold [3/5] Epoch [0/100] Initial Loss: 0.1401, Training Loss: 0.1401, Initial Validation Loss: 0.1345, Validation Loss: 0.1345,V Acc: 0.3000, Top 70th Acc: 0.3377, Bottom 30th Acc: 0.2121
Fold [3/5] Epoch [10/100] Initial Loss: 0.1401, Training Loss: 0.0341, Initial Validation Loss: 0.1345, Validation Loss: 0.0403,V Acc: 0.8182, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.5758
Fold [3/5] Epoch [20/100] Initial Loss: 0.1401, Training Loss: 0.0205, Initial Validation Loss: 0.1345, Validation Loss: 0.0320,V Acc: 0.8364, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.9090909090909091
Fold [4/5] Epoch [0/100] Initial Loss: 0.1403, Training Loss: 0.1403, Initial Validation Loss: 0.1352, Validation Loss: 0.1352,V Acc: 0.3303, Top 70th Acc: 0.4286, Bottom 30th Acc: 0.0938
Fold [4/5] Epoch [10/100] Initial Loss: 0.1403, Training Loss: 0.0330, Initial Validation Loss: 0.1352, Validation Loss: 0.0401,V Acc: 0.8165, Top 70th Acc: 0.8961, Bottom 30th Acc: 0.6250
Fold [4/5] Epoch [20/100] Initial Loss: 0.1403, Training Loss: 0.0199, Initial Validation Loss: 0.1352, Validation Loss: 0.0319,V Acc: 0.8349, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.5625
Stopping early at Epoch (base 0): 27  Rolling back to Epoch (base 0): 22  Top Validation Acc: 0.961038961038961
7 3 [array([0.6269746 , 0.06371262, 0.07822618, 0.12523358, 0.10585306],
      dtype=float32)]
Fold [5/5] Epoch [0/100] Initial Loss: 0.1392, Training Loss: 0.1392, Initial Validation Loss: 0.1315, Validation Loss: 0.1315,V Acc: 0.3796, Top 70th Acc: 0.4605, Bottom 30th Acc: 0.1875
Fold [5/5] Epoch [10/100] Initial Loss: 0.1392, Training Loss: 0.0300, Initial Validation Loss: 0.1315, Validation Loss: 0.0350,V Acc: 0.8333, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.5625
Fold [5/5] Epoch [20/100] Initial Loss: 0.1392, Training Loss: 0.0195, Initial Validation Loss: 0.1315, Validation Loss: 0.0317,V Acc: 0.8241, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.5312
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.9736842105263158
Running train_nn.py with seed 8
CUDA:False
Training samples count:  550
Training on 30 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1397, Training Loss: 0.1397, Initial Validation Loss: 0.1388, Validation Loss: 0.1388,V Acc: 0.2321, Top 70th Acc: 0.2658, Bottom 30th Acc: 0.1515
Fold [1/5] Epoch [10/100] Initial Loss: 0.1397, Training Loss: 0.0284, Initial Validation Loss: 0.1388, Validation Loss: 0.0304,V Acc: 0.8661, Top 70th Acc: 0.9620, Bottom 30th Acc: 0.6364
Fold [1/5] Epoch [20/100] Initial Loss: 0.1397, Training Loss: 0.0187, Initial Validation Loss: 0.1388, Validation Loss: 0.0257,V Acc: 0.8482, Top 70th Acc: 0.9873, Bottom 30th Acc: 0.5152
Stopping early at Epoch (base 0): 29  Rolling back to Epoch (base 0): 24  Top Validation Acc: 0.9746835443037974
Fold [2/5] Epoch [0/100] Initial Loss: 0.1412, Training Loss: 0.1412, Initial Validation Loss: 0.1328, Validation Loss: 0.1328,V Acc: 0.2793, Top 70th Acc: 0.3718, Bottom 30th Acc: 0.0606
Fold [2/5] Epoch [10/100] Initial Loss: 0.1412, Training Loss: 0.0364, Initial Validation Loss: 0.1328, Validation Loss: 0.0368,V Acc: 0.8378, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.5758
Fold [2/5] Epoch [20/100] Initial Loss: 0.1412, Training Loss: 0.0186, Initial Validation Loss: 0.1328, Validation Loss: 0.0298,V Acc: 0.8468, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 22  Rolling back to Epoch (base 0): 17  Top Validation Acc: 0.9358974358974359
Fold [3/5] Epoch [0/100] Initial Loss: 0.1388, Training Loss: 0.1388, Initial Validation Loss: 0.1316, Validation Loss: 0.1316,V Acc: 0.3091, Top 70th Acc: 0.4156, Bottom 30th Acc: 0.0606
Fold [3/5] Epoch [10/100] Initial Loss: 0.1388, Training Loss: 0.0312, Initial Validation Loss: 0.1316, Validation Loss: 0.0375,V Acc: 0.8545, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.6061
Fold [3/5] Epoch [20/100] Initial Loss: 0.1388, Training Loss: 0.0175, Initial Validation Loss: 0.1316, Validation Loss: 0.0276,V Acc: 0.8636, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.6061
Fold [3/5] Epoch [30/100] Initial Loss: 0.1388, Training Loss: 0.0146, Initial Validation Loss: 0.1316, Validation Loss: 0.0276,V Acc: 0.8636, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 30  Rolling back to Epoch (base 0): 25  Top Validation Acc: 0.974025974025974
8 2 [array([0.73785406, 0.06651393, 0.03673518, 0.06851107, 0.09038573],
      dtype=float32)]
Fold [4/5] Epoch [0/100] Initial Loss: 0.1389, Training Loss: 0.1389, Initial Validation Loss: 0.1309, Validation Loss: 0.1309,V Acc: 0.3119, Top 70th Acc: 0.3766, Bottom 30th Acc: 0.1562
Fold [4/5] Epoch [10/100] Initial Loss: 0.1389, Training Loss: 0.0297, Initial Validation Loss: 0.1309, Validation Loss: 0.0474,V Acc: 0.7706, Top 70th Acc: 0.8312, Bottom 30th Acc: 0.6250
Fold [4/5] Epoch [20/100] Initial Loss: 0.1389, Training Loss: 0.0185, Initial Validation Loss: 0.1309, Validation Loss: 0.0442,V Acc: 0.7706, Top 70th Acc: 0.8701, Bottom 30th Acc: 0.5312
Fold [4/5] Epoch [30/100] Initial Loss: 0.1389, Training Loss: 0.0148, Initial Validation Loss: 0.1309, Validation Loss: 0.0410,V Acc: 0.7890, Top 70th Acc: 0.8571, Bottom 30th Acc: 0.6250
Fold [4/5] Epoch [40/100] Initial Loss: 0.1389, Training Loss: 0.0135, Initial Validation Loss: 0.1309, Validation Loss: 0.0405,V Acc: 0.7982, Top 70th Acc: 0.8701, Bottom 30th Acc: 0.6250
Stopping early at Epoch (base 0): 40  Rolling back to Epoch (base 0): 35  Top Validation Acc: 0.8701298701298701
Fold [5/5] Epoch [0/100] Initial Loss: 0.1397, Training Loss: 0.1397, Initial Validation Loss: 0.1298, Validation Loss: 0.1298,V Acc: 0.2778, Top 70th Acc: 0.3421, Bottom 30th Acc: 0.1250
Fold [5/5] Epoch [10/100] Initial Loss: 0.1397, Training Loss: 0.0252, Initial Validation Loss: 0.1298, Validation Loss: 0.0337,V Acc: 0.8241, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.5312
Fold [5/5] Epoch [20/100] Initial Loss: 0.1397, Training Loss: 0.0159, Initial Validation Loss: 0.1298, Validation Loss: 0.0319,V Acc: 0.8241, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.5625
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.9342105263157895
Running train_nn.py with seed 9
CUDA:False
Training samples count:  550
Training on 30 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1417, Training Loss: 0.1417, Initial Validation Loss: 0.1387, Validation Loss: 0.1387,V Acc: 0.3125, Top 70th Acc: 0.3671, Bottom 30th Acc: 0.1818
Fold [1/5] Epoch [10/100] Initial Loss: 0.1417, Training Loss: 0.0329, Initial Validation Loss: 0.1387, Validation Loss: 0.0450,V Acc: 0.8214, Top 70th Acc: 0.8987, Bottom 30th Acc: 0.6364
Fold [1/5] Epoch [20/100] Initial Loss: 0.1417, Training Loss: 0.0213, Initial Validation Loss: 0.1387, Validation Loss: 0.0405,V Acc: 0.7768, Top 70th Acc: 0.8734, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 27  Rolling back to Epoch (base 0): 22  Top Validation Acc: 0.8860759493670886
Fold [2/5] Epoch [0/100] Initial Loss: 0.1444, Training Loss: 0.1444, Initial Validation Loss: 0.1372, Validation Loss: 0.1372,V Acc: 0.2703, Top 70th Acc: 0.2692, Bottom 30th Acc: 0.2727
Fold [2/5] Epoch [10/100] Initial Loss: 0.1444, Training Loss: 0.0304, Initial Validation Loss: 0.1372, Validation Loss: 0.0355,V Acc: 0.8198, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 17  Rolling back to Epoch (base 0): 12  Top Validation Acc: 0.9487179487179487
Fold [3/5] Epoch [0/100] Initial Loss: 0.1385, Training Loss: 0.1385, Initial Validation Loss: 0.1304, Validation Loss: 0.1304,V Acc: 0.4000, Top 70th Acc: 0.4935, Bottom 30th Acc: 0.1818
Fold [3/5] Epoch [10/100] Initial Loss: 0.1385, Training Loss: 0.0332, Initial Validation Loss: 0.1304, Validation Loss: 0.0338,V Acc: 0.8455, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.6364
Fold [2/5] Epoch [20/100] Initial Loss: 0.1376, Training Loss: 0.0282, Initial Validation Loss: 0.1277, Validation Loss: 0.0341,V Acc: 0.8559, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.6970
Fold [2/5] Epoch [30/100] Initial Loss: 0.1376, Training Loss: 0.0227, Initial Validation Loss: 0.1277, Validation Loss: 0.0309,V Acc: 0.8378, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.6061
Fold [2/5] Epoch [40/100] Initial Loss: 0.1376, Training Loss: 0.0211, Initial Validation Loss: 0.1277, Validation Loss: 0.0313,V Acc: 0.8468, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 43  Rolling back to Epoch (base 0): 38  Top Validation Acc: 0.9358974358974359
Fold [3/5] Epoch [0/100] Initial Loss: 0.1391, Training Loss: 0.1391, Initial Validation Loss: 0.1316, Validation Loss: 0.1316,V Acc: 0.3273, Top 70th Acc: 0.4286, Bottom 30th Acc: 0.0909
Fold [3/5] Epoch [10/100] Initial Loss: 0.1391, Training Loss: 0.0431, Initial Validation Loss: 0.1316, Validation Loss: 0.0463,V Acc: 0.8091, Top 70th Acc: 0.8961, Bottom 30th Acc: 0.6061
Fold [3/5] Epoch [20/100] Initial Loss: 0.1391, Training Loss: 0.0246, Initial Validation Loss: 0.1316, Validation Loss: 0.0359,V Acc: 0.8364, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.6061
Fold [3/5] Epoch [30/100] Initial Loss: 0.1391, Training Loss: 0.0221, Initial Validation Loss: 0.1316, Validation Loss: 0.0349,V Acc: 0.8364, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 36  Rolling back to Epoch (base 0): 31  Top Validation Acc: 0.922077922077922
Fold [4/5] Epoch [0/100] Initial Loss: 0.1408, Training Loss: 0.1408, Initial Validation Loss: 0.1382, Validation Loss: 0.1382,V Acc: 0.2477, Top 70th Acc: 0.2727, Bottom 30th Acc: 0.1875
Fold [4/5] Epoch [10/100] Initial Loss: 0.1408, Training Loss: 0.0460, Initial Validation Loss: 0.1382, Validation Loss: 0.0497,V Acc: 0.7982, Top 70th Acc: 0.8571, Bottom 30th Acc: 0.6562
Fold [4/5] Epoch [20/100] Initial Loss: 0.1408, Training Loss: 0.0253, Initial Validation Loss: 0.1382, Validation Loss: 0.0355,V Acc: 0.8257, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.5938
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.922077922077922
7 3 [array([0.3109704 , 0.07915597, 0.14482117, 0.3079393 , 0.15711321],
      dtype=float32)]
Fold [5/5] Epoch [0/100] Initial Loss: 0.1393, Training Loss: 0.1393, Initial Validation Loss: 0.1323, Validation Loss: 0.1323,V Acc: 0.2593, Top 70th Acc: 0.3158, Bottom 30th Acc: 0.1250
Fold [5/5] Epoch [10/100] Initial Loss: 0.1393, Training Loss: 0.0337, Initial Validation Loss: 0.1323, Validation Loss: 0.0327,V Acc: 0.8611, Top 70th Acc: 0.9211, Bottom 30th Acc: 0.7188
Fold [5/5] Epoch [20/100] Initial Loss: 0.1393, Training Loss: 0.0252, Initial Validation Loss: 0.1323, Validation Loss: 0.0303,V Acc: 0.8519, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.5938
Stopping early at Epoch (base 0): 28  Rolling back to Epoch (base 0): 23  Top Validation Acc: 0.9605263157894737
Running train_nn.py with seed 8
CUDA:False
Training samples count:  550
Training on 20 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1383, Training Loss: 0.1383, Initial Validation Loss: 0.1364, Validation Loss: 0.1364,V Acc: 0.2679, Top 70th Acc: 0.3418, Bottom 30th Acc: 0.0909
Fold [1/5] Epoch [10/100] Initial Loss: 0.1383, Training Loss: 0.0384, Initial Validation Loss: 0.1364, Validation Loss: 0.0462,V Acc: 0.7768, Top 70th Acc: 0.8987, Bottom 30th Acc: 0.4848
Fold [1/5] Epoch [20/100] Initial Loss: 0.1383, Training Loss: 0.0268, Initial Validation Loss: 0.1364, Validation Loss: 0.0334,V Acc: 0.8482, Top 70th Acc: 0.9367, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 29  Rolling back to Epoch (base 0): 24  Top Validation Acc: 0.9367088607594937
Fold [2/5] Epoch [0/100] Initial Loss: 0.1424, Training Loss: 0.1424, Initial Validation Loss: 0.1331, Validation Loss: 0.1331,V Acc: 0.3964, Top 70th Acc: 0.4359, Bottom 30th Acc: 0.3030
Fold [2/5] Epoch [10/100] Initial Loss: 0.1424, Training Loss: 0.0490, Initial Validation Loss: 0.1331, Validation Loss: 0.0515,V Acc: 0.7387, Top 70th Acc: 0.8718, Bottom 30th Acc: 0.4242
Fold [2/5] Epoch [20/100] Initial Loss: 0.1424, Training Loss: 0.0305, Initial Validation Loss: 0.1331, Validation Loss: 0.0342,V Acc: 0.8559, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.6970
Fold [2/5] Epoch [30/100] Initial Loss: 0.1424, Training Loss: 0.0235, Initial Validation Loss: 0.1331, Validation Loss: 0.0313,V Acc: 0.8829, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.7879
Stopping early at Epoch (base 0): 32  Rolling back to Epoch (base 0): 27  Top Validation Acc: 0.9230769230769231
Fold [3/5] Epoch [0/100] Initial Loss: 0.1420, Training Loss: 0.1420, Initial Validation Loss: 0.1380, Validation Loss: 0.1380,V Acc: 0.2545, Top 70th Acc: 0.2857, Bottom 30th Acc: 0.1818
Fold [3/5] Epoch [10/100] Initial Loss: 0.1420, Training Loss: 0.0370, Initial Validation Loss: 0.1380, Validation Loss: 0.0395,V Acc: 0.8182, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.5455
Fold [3/5] Epoch [20/100] Initial Loss: 0.1420, Training Loss: 0.0251, Initial Validation Loss: 0.1380, Validation Loss: 0.0327,V Acc: 0.8364, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.5455
Fold [3/5] Epoch [30/100] Initial Loss: 0.1420, Training Loss: 0.0228, Initial Validation Loss: 0.1380, Validation Loss: 0.0319,V Acc: 0.8545, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 33  Rolling back to Epoch (base 0): 28  Top Validation Acc: 0.961038961038961
8 2 [array([0.43123898, 0.09089972, 0.128668  , 0.28243077, 0.06676256],
      dtype=float32)]
Fold [4/5] Epoch [0/100] Initial Loss: 0.1443, Training Loss: 0.1443, Initial Validation Loss: 0.1338, Validation Loss: 0.1338,V Acc: 0.2477, Top 70th Acc: 0.3247, Bottom 30th Acc: 0.0625
Fold [4/5] Epoch [10/100] Initial Loss: 0.1443, Training Loss: 0.0488, Initial Validation Loss: 0.1338, Validation Loss: 0.0635,V Acc: 0.7064, Top 70th Acc: 0.7792, Bottom 30th Acc: 0.5312
Fold [4/5] Epoch [20/100] Initial Loss: 0.1443, Training Loss: 0.0297, Initial Validation Loss: 0.1338, Validation Loss: 0.0465,V Acc: 0.7615, Top 70th Acc: 0.8571, Bottom 30th Acc: 0.5312
Fold [4/5] Epoch [30/100] Initial Loss: 0.1443, Training Loss: 0.0226, Initial Validation Loss: 0.1338, Validation Loss: 0.0392,V Acc: 0.8073, Top 70th Acc: 0.8831, Bottom 30th Acc: 0.6250
Stopping early at Epoch (base 0): 32  Rolling back to Epoch (base 0): 27  Top Validation Acc: 0.8831168831168831
Fold [5/5] Epoch [0/100] Initial Loss: 0.1407, Training Loss: 0.1407, Initial Validation Loss: 0.1299, Validation Loss: 0.1299,V Acc: 0.2778, Top 70th Acc: 0.3158, Bottom 30th Acc: 0.1875
Fold [5/5] Epoch [10/100] Initial Loss: 0.1407, Training Loss: 0.0428, Initial Validation Loss: 0.1299, Validation Loss: 0.0395,V Acc: 0.7963, Top 70th Acc: 0.9079, Bottom 30th Acc: 0.5312
Fold [5/5] Epoch [20/100] Initial Loss: 0.1407, Training Loss: 0.0314, Initial Validation Loss: 0.1299, Validation Loss: 0.0346,V Acc: 0.8148, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.5000
Fold [5/5] Epoch [30/100] Initial Loss: 0.1407, Training Loss: 0.0249, Initial Validation Loss: 0.1299, Validation Loss: 0.0323,V Acc: 0.8148, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.5312
Stopping early at Epoch (base 0): 32  Rolling back to Epoch (base 0): 27  Top Validation Acc: 0.9342105263157895
Running train_nn.py with seed 9
CUDA:False
Training samples count:  550
Training on 20 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1392, Training Loss: 0.1392, Initial Validation Loss: 0.1364, Validation Loss: 0.1364,V Acc: 0.3482, Top 70th Acc: 0.4051, Bottom 30th Acc: 0.2121
Fold [1/5] Epoch [10/100] Initial Loss: 0.1392, Training Loss: 0.0426, Initial Validation Loss: 0.1364, Validation Loss: 0.0486,V Acc: 0.8036, Top 70th Acc: 0.8861, Bottom 30th Acc: 0.6061
Fold [1/5] Epoch [20/100] Initial Loss: 0.1392, Training Loss: 0.0246, Initial Validation Loss: 0.1364, Validation Loss: 0.0350,V Acc: 0.8304, Top 70th Acc: 0.9241, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 27  Rolling back to Epoch (base 0): 22  Top Validation Acc: 0.9113924050632911
Fold [2/5] Epoch [0/100] Initial Loss: 0.1409, Training Loss: 0.1409, Initial Validation Loss: 0.1361, Validation Loss: 0.1361,V Acc: 0.2703, Top 70th Acc: 0.3077, Bottom 30th Acc: 0.1818
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 46
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 2 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 47
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 2 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 48
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 2 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 49
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 2 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 50
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 2 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 51
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 2 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 52
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 2 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 53
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 2 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 54
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 2 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 55
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 2 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 56
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 2 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 57
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 2 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 58
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 2 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 59
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 2 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 60
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 2 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 61
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 2 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 62
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 2 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 63
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 2 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 64
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 2 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 65
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 2 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 66
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 2 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 67
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 2 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 68
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 2 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 69
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 2 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 70
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 2 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 71
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 2 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 72
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 2 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 73
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 2 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 74
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 2 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 75
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 2 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 76
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 2 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 77
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 2 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 78
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 2 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 79
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 2 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 80
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 2 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 81
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 2 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 82
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 2 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 83
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 2 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 84
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 2 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 85
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 2 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 86
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 2 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 87
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 2 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 88
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 2 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 89
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 2 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 90
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Fold [1/5] Epoch [10/100] Initial Loss: 0.1337, Training Loss: 0.0203, Initial Validation Loss: 0.1238, Validation Loss: 0.0303,V Acc: 0.8661, Top 70th Acc: 0.9367, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 18  Rolling back to Epoch (base 0): 13  Top Validation Acc: 0.9620253164556962
Fold [2/5] Epoch [0/100] Initial Loss: 0.1341, Training Loss: 0.1341, Initial Validation Loss: 0.1194, Validation Loss: 0.1194,V Acc: 0.4685, Top 70th Acc: 0.5897, Bottom 30th Acc: 0.1818
Fold [2/5] Epoch [10/100] Initial Loss: 0.1341, Training Loss: 0.0239, Initial Validation Loss: 0.1194, Validation Loss: 0.0279,V Acc: 0.8288, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.5152
Fold [2/5] Epoch [20/100] Initial Loss: 0.1341, Training Loss: 0.0169, Initial Validation Loss: 0.1194, Validation Loss: 0.0267,V Acc: 0.8559, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.9615384615384616
Fold [3/5] Epoch [0/100] Initial Loss: 0.1344, Training Loss: 0.1344, Initial Validation Loss: 0.1263, Validation Loss: 0.1263,V Acc: 0.4818, Top 70th Acc: 0.5974, Bottom 30th Acc: 0.2121
Fold [3/5] Epoch [10/100] Initial Loss: 0.1344, Training Loss: 0.0216, Initial Validation Loss: 0.1263, Validation Loss: 0.0347,V Acc: 0.8455, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6061
Fold [3/5] Epoch [20/100] Initial Loss: 0.1344, Training Loss: 0.0135, Initial Validation Loss: 0.1263, Validation Loss: 0.0260,V Acc: 0.8818, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 28  Rolling back to Epoch (base 0): 23  Top Validation Acc: 0.948051948051948
Fold [4/5] Epoch [0/100] Initial Loss: 0.1336, Training Loss: 0.1336, Initial Validation Loss: 0.1174, Validation Loss: 0.1174,V Acc: 0.5046, Top 70th Acc: 0.6494, Bottom 30th Acc: 0.1562
Fold [4/5] Epoch [10/100] Initial Loss: 0.1336, Training Loss: 0.0213, Initial Validation Loss: 0.1174, Validation Loss: 0.0261,V Acc: 0.8807, Top 70th Acc: 0.9870, Bottom 30th Acc: 0.6250
Fold [4/5] Epoch [20/100] Initial Loss: 0.1336, Training Loss: 0.0149, Initial Validation Loss: 0.1174, Validation Loss: 0.0206,V Acc: 0.9266, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.8125
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.974025974025974
11 3 [array([0.7294786 , 0.02301491, 0.03232465, 0.11944121, 0.09574059],
      dtype=float32)]
Fold [5/5] Epoch [0/100] Initial Loss: 0.1379, Training Loss: 0.1379, Initial Validation Loss: 0.1283, Validation Loss: 0.1283,V Acc: 0.4167, Top 70th Acc: 0.5263, Bottom 30th Acc: 0.1562
Fold [5/5] Epoch [10/100] Initial Loss: 0.1379, Training Loss: 0.0243, Initial Validation Loss: 0.1283, Validation Loss: 0.0306,V Acc: 0.8611, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.6250
Stopping early at Epoch (base 0): 13  Rolling back to Epoch (base 0): 8  Top Validation Acc: 0.9605263157894737
Running train_nn.py with seed 12
CUDA:False
Training samples count:  550
Training on 21 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1350, Training Loss: 0.1350, Initial Validation Loss: 0.1239, Validation Loss: 0.1239,V Acc: 0.5000, Top 70th Acc: 0.5570, Bottom 30th Acc: 0.3636
Fold [1/5] Epoch [10/100] Initial Loss: 0.1350, Training Loss: 0.0218, Initial Validation Loss: 0.1239, Validation Loss: 0.0289,V Acc: 0.8482, Top 70th Acc: 0.9620, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 15  Rolling back to Epoch (base 0): 10  Top Validation Acc: 0.9873417721518988
Fold [2/5] Epoch [0/100] Initial Loss: 0.1334, Training Loss: 0.1334, Initial Validation Loss: 0.1224, Validation Loss: 0.1224,V Acc: 0.4144, Top 70th Acc: 0.5513, Bottom 30th Acc: 0.0909
Fold [2/5] Epoch [10/100] Initial Loss: 0.1334, Training Loss: 0.0232, Initial Validation Loss: 0.1224, Validation Loss: 0.0227,V Acc: 0.9099, Top 70th Acc: 1.0000, Bottom 30th Acc: 0.6970
Fold [2/5] Epoch [20/100] Initial Loss: 0.1334, Training Loss: 0.0161, Initial Validation Loss: 0.1224, Validation Loss: 0.0221,V Acc: 0.9009, Top 70th Acc: 0.9872, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 21  Rolling back to Epoch (base 0): 16  Top Validation Acc: 0.9871794871794872
Fold [3/5] Epoch [0/100] Initial Loss: 0.1316, Training Loss: 0.1316, Initial Validation Loss: 0.1142, Validation Loss: 0.1142,V Acc: 0.4818, Top 70th Acc: 0.6494, Bottom 30th Acc: 0.0909
Fold [3/5] Epoch [10/100] Initial Loss: 0.1316, Training Loss: 0.0232, Initial Validation Loss: 0.1142, Validation Loss: 0.0373,V Acc: 0.8091, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.5152
Stopping early at Epoch (base 0): 13  Rolling back to Epoch (base 0): 8  Top Validation Acc: 0.9090909090909091
Fold [4/5] Epoch [0/100] Initial Loss: 0.1353, Training Loss: 0.1353, Initial Validation Loss: 0.1254, Validation Loss: 0.1254,V Acc: 0.5596, Top 70th Acc: 0.5844, Bottom 30th Acc: 0.5000
Fold [4/5] Epoch [10/100] Initial Loss: 0.1353, Training Loss: 0.0216, Initial Validation Loss: 0.1254, Validation Loss: 0.0263,V Acc: 0.8624, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6562
Fold [4/5] Epoch [20/100] Initial Loss: 0.1353, Training Loss: 0.0167, Initial Validation Loss: 0.1254, Validation Loss: 0.0233,V Acc: 0.8899, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.7812
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.948051948051948
Fold [5/5] Epoch [0/100] Initial Loss: 0.1366, Training Loss: 0.1366, Initial Validation Loss: 0.1213, Validation Loss: 0.1213,V Acc: 0.5093, Top 70th Acc: 0.5921, Bottom 30th Acc: 0.3125
Fold [5/5] Epoch [10/100] Initial Loss: 0.1366, Training Loss: 0.0231, Initial Validation Loss: 0.1213, Validation Loss: 0.0207,V Acc: 0.9074, Top 70th Acc: 0.9868, Bottom 30th Acc: 0.7188
Fold [5/5] Epoch [20/100] Initial Loss: 0.1366, Training Loss: 0.0155, Initial Validation Loss: 0.1213, Validation Loss: 0.0202,V Acc: 0.8889, Top 70th Acc: 0.9868, Bottom 30th Acc: 0.6562
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.9868421052631579
12 4 [array([0.8074453 , 0.01533855, 0.02448047, 0.0837068 , 0.069029  ],
      dtype=float32)]
Running train_nn.py with seed 13
CUDA:False
Training samples count:  550
Training on 21 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1311, Training Loss: 0.1311, Initial Validation Loss: 0.1158, Validation Loss: 0.1158,V Acc: 0.6161, Top 70th Acc: 0.6962, Bottom 30th Acc: 0.4242
Fold [1/5] Epoch [10/100] Initial Loss: 0.1311, Training Loss: 0.0238, Initial Validation Loss: 0.1158, Validation Loss: 0.0351,V Acc: 0.8304, Top 70th Acc: 0.9620, Bottom 30th Acc: 0.5152
Stopping early at Epoch (base 0): 16  Rolling back to Epoch (base 0): 11  Top Validation Acc: 0.9240506329113924
Fold [2/5] Epoch [0/100] Initial Loss: 0.1390, Training Loss: 0.1390, Initial Validation Loss: 0.1364, Validation Loss: 0.1364,V Acc: 0.2523, Top 70th Acc: 0.3205, Bottom 30th Acc: 0.0909
Fold [2/5] Epoch [10/100] Initial Loss: 0.1390, Training Loss: 0.0227, Initial Validation Loss: 0.1364, Validation Loss: 0.0313,V Acc: 0.8559, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.6667
Fold [2/5] Epoch [20/100] Initial Loss: 0.1390, Training Loss: 0.0166, Initial Validation Loss: 0.1364, Validation Loss: 0.0233,V Acc: 0.8649, Top 70th Acc: 0.9872, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 28  Rolling back to Epoch (base 0): 23  Top Validation Acc: 0.9743589743589743
Fold [3/5] Epoch [0/100] Initial Loss: 0.1365, Training Loss: 0.1365, Initial Validation Loss: 0.1295, Validation Loss: 0.1295,V Acc: 0.2818, Top 70th Acc: 0.3506, Bottom 30th Acc: 0.1212
Fold [3/5] Epoch [10/100] Initial Loss: 0.1365, Training Loss: 0.0223, Initial Validation Loss: 0.1295, Validation Loss: 0.0240,V Acc: 0.8818, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 18  Rolling back to Epoch (base 0): 13  Top Validation Acc: 0.974025974025974
Fold [4/5] Epoch [0/100] Initial Loss: 0.1402, Training Loss: 0.1402, Initial Validation Loss: 0.1279, Validation Loss: 0.1279,V Acc: 0.4404, Top 70th Acc: 0.5714, Bottom 30th Acc: 0.1250
Fold [4/5] Epoch [10/100] Initial Loss: 0.1402, Training Loss: 0.0233, Initial Validation Loss: 0.1279, Validation Loss: 0.0258,V Acc: 0.8991, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.7188
Fold [5/5] Epoch [10/100] Initial Loss: 0.1418, Training Loss: 0.0810, Initial Validation Loss: 0.1275, Validation Loss: 0.0772,V Acc: 0.6389, Top 70th Acc: 0.7368, Bottom 30th Acc: 0.4062
Fold [5/5] Epoch [20/100] Initial Loss: 0.1418, Training Loss: 0.0792, Initial Validation Loss: 0.1275, Validation Loss: 0.0752,V Acc: 0.6204, Top 70th Acc: 0.7368, Bottom 30th Acc: 0.3438
Stopping early at Epoch (base 0): 21  Rolling back to Epoch (base 0): 16  Top Validation Acc: 0.7368421052631579
Running train_nn.py with seed 9
CUDA:False
Training samples count:  550
Training on 2 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1368, Training Loss: 0.1368, Initial Validation Loss: 0.1323, Validation Loss: 0.1323,V Acc: 0.3661, Top 70th Acc: 0.3797, Bottom 30th Acc: 0.3333
Fold [1/5] Epoch [10/100] Initial Loss: 0.1368, Training Loss: 0.0797, Initial Validation Loss: 0.1323, Validation Loss: 0.0861,V Acc: 0.5982, Top 70th Acc: 0.7089, Bottom 30th Acc: 0.3333
Fold [1/5] Epoch [20/100] Initial Loss: 0.1368, Training Loss: 0.0775, Initial Validation Loss: 0.1323, Validation Loss: 0.0846,V Acc: 0.6339, Top 70th Acc: 0.6962, Bottom 30th Acc: 0.4848
Stopping early at Epoch (base 0): 29  Rolling back to Epoch (base 0): 24  Top Validation Acc: 0.7088607594936709
Fold [2/5] Epoch [0/100] Initial Loss: 0.1359, Training Loss: 0.1359, Initial Validation Loss: 0.1279, Validation Loss: 0.1279,V Acc: 0.4234, Top 70th Acc: 0.4359, Bottom 30th Acc: 0.3939
Fold [2/5] Epoch [10/100] Initial Loss: 0.1359, Training Loss: 0.0790, Initial Validation Loss: 0.1279, Validation Loss: 0.0860,V Acc: 0.6036, Top 70th Acc: 0.7436, Bottom 30th Acc: 0.2727
Fold [2/5] Epoch [20/100] Initial Loss: 0.1359, Training Loss: 0.0772, Initial Validation Loss: 0.1279, Validation Loss: 0.0848,V Acc: 0.5946, Top 70th Acc: 0.7308, Bottom 30th Acc: 0.2727
Stopping early at Epoch (base 0): 21  Rolling back to Epoch (base 0): 16  Top Validation Acc: 0.7307692307692307
Fold [3/5] Epoch [0/100] Initial Loss: 0.1387, Training Loss: 0.1387, Initial Validation Loss: 0.1273, Validation Loss: 0.1273,V Acc: 0.3182, Top 70th Acc: 0.3766, Bottom 30th Acc: 0.1818
Fold [3/5] Epoch [10/100] Initial Loss: 0.1387, Training Loss: 0.0809, Initial Validation Loss: 0.1273, Validation Loss: 0.0756,V Acc: 0.6091, Top 70th Acc: 0.7273, Bottom 30th Acc: 0.3333
Fold [3/5] Epoch [20/100] Initial Loss: 0.1387, Training Loss: 0.0785, Initial Validation Loss: 0.1273, Validation Loss: 0.0742,V Acc: 0.6000, Top 70th Acc: 0.7143, Bottom 30th Acc: 0.3333
Fold [3/5] Epoch [30/100] Initial Loss: 0.1387, Training Loss: 0.0776, Initial Validation Loss: 0.1273, Validation Loss: 0.0742,V Acc: 0.6182, Top 70th Acc: 0.7273, Bottom 30th Acc: 0.3636
Stopping early at Epoch (base 0): 33  Rolling back to Epoch (base 0): 28  Top Validation Acc: 0.7272727272727273
Fold [4/5] Epoch [0/100] Initial Loss: 0.1322, Training Loss: 0.1322, Initial Validation Loss: 0.1159, Validation Loss: 0.1159,V Acc: 0.4679, Top 70th Acc: 0.5455, Bottom 30th Acc: 0.2812
Fold [4/5] Epoch [10/100] Initial Loss: 0.1322, Training Loss: 0.0817, Initial Validation Loss: 0.1159, Validation Loss: 0.0743,V Acc: 0.6514, Top 70th Acc: 0.7792, Bottom 30th Acc: 0.3438
Fold [4/5] Epoch [20/100] Initial Loss: 0.1322, Training Loss: 0.0802, Initial Validation Loss: 0.1159, Validation Loss: 0.0732,V Acc: 0.6514, Top 70th Acc: 0.7662, Bottom 30th Acc: 0.3750
Stopping early at Epoch (base 0): 27  Rolling back to Epoch (base 0): 22  Top Validation Acc: 0.7792207792207793
9 3 [array([0.11900634, 0.37992257, 0.1331893 , 0.20476522, 0.16311659],
      dtype=float32)]
Fold [5/5] Epoch [0/100] Initial Loss: 0.1339, Training Loss: 0.1339, Initial Validation Loss: 0.1189, Validation Loss: 0.1189,V Acc: 0.4259, Top 70th Acc: 0.5263, Bottom 30th Acc: 0.1875
Fold [5/5] Epoch [10/100] Initial Loss: 0.1339, Training Loss: 0.0816, Initial Validation Loss: 0.1189, Validation Loss: 0.0727,V Acc: 0.6759, Top 70th Acc: 0.7763, Bottom 30th Acc: 0.4375
Fold [5/5] Epoch [20/100] Initial Loss: 0.1339, Training Loss: 0.0803, Initial Validation Loss: 0.1189, Validation Loss: 0.0726,V Acc: 0.6574, Top 70th Acc: 0.7763, Bottom 30th Acc: 0.3750
Fold [5/5] Epoch [30/100] Initial Loss: 0.1339, Training Loss: 0.0797, Initial Validation Loss: 0.1189, Validation Loss: 0.0714,V Acc: 0.6759, Top 70th Acc: 0.7632, Bottom 30th Acc: 0.4688
Stopping early at Epoch (base 0): 30  Rolling back to Epoch (base 0): 25  Top Validation Acc: 0.7631578947368421
Running train_nn.py with seed 10
CUDA:False
Training samples count:  550
Training on 2 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1367, Training Loss: 0.1367, Initial Validation Loss: 0.1236, Validation Loss: 0.1236,V Acc: 0.5446, Top 70th Acc: 0.5443, Bottom 30th Acc: 0.5455
Fold [1/5] Epoch [10/100] Initial Loss: 0.1367, Training Loss: 0.0840, Initial Validation Loss: 0.1236, Validation Loss: 0.0699,V Acc: 0.6518, Top 70th Acc: 0.7595, Bottom 30th Acc: 0.3939
Fold [1/5] Epoch [20/100] Initial Loss: 0.1367, Training Loss: 0.0819, Initial Validation Loss: 0.1236, Validation Loss: 0.0680,V Acc: 0.6429, Top 70th Acc: 0.7595, Bottom 30th Acc: 0.3636
Stopping early at Epoch (base 0): 29  Rolling back to Epoch (base 0): 24  Top Validation Acc: 0.759493670886076
Fold [2/5] Epoch [0/100] Initial Loss: 0.1361, Training Loss: 0.1361, Initial Validation Loss: 0.1302, Validation Loss: 0.1302,V Acc: 0.3694, Top 70th Acc: 0.5000, Bottom 30th Acc: 0.0606
Fold [2/5] Epoch [10/100] Initial Loss: 0.1361, Training Loss: 0.0782, Initial Validation Loss: 0.1302, Validation Loss: 0.0867,V Acc: 0.5586, Top 70th Acc: 0.6923, Bottom 30th Acc: 0.2424
Fold [2/5] Epoch [20/100] Initial Loss: 0.1361, Training Loss: 0.0763, Initial Validation Loss: 0.1302, Validation Loss: 0.0841,V Acc: 0.5946, Top 70th Acc: 0.6923, Bottom 30th Acc: 0.3636
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.6923076923076923
Fold [3/5] Epoch [0/100] Initial Loss: 0.1321, Training Loss: 0.1321, Initial Validation Loss: 0.1167, Validation Loss: 0.1167,V Acc: 0.4273, Top 70th Acc: 0.4805, Bottom 30th Acc: 0.3030
Fold [3/5] Epoch [10/100] Initial Loss: 0.1321, Training Loss: 0.0791, Initial Validation Loss: 0.1167, Validation Loss: 0.0815,V Acc: 0.5818, Top 70th Acc: 0.6883, Bottom 30th Acc: 0.3333
Stopping early at Epoch (base 0): 17  Rolling back to Epoch (base 0): 12  Top Validation Acc: 0.7142857142857143
10 2 [array([0.11265445, 0.3875654 , 0.15008348, 0.18721816, 0.16247861],
      dtype=float32)]
Fold [4/5] Epoch [0/100] Initial Loss: 0.1324, Training Loss: 0.1324, Initial Validation Loss: 0.1238, Validation Loss: 0.1238,V Acc: 0.4587, Top 70th Acc: 0.5455, Bottom 30th Acc: 0.2500
Fold [4/5] Epoch [10/100] Initial Loss: 0.1324, Training Loss: 0.0787, Initial Validation Loss: 0.1238, Validation Loss: 0.0830,V Acc: 0.6147, Top 70th Acc: 0.7143, Bottom 30th Acc: 0.3750
Fold [4/5] Epoch [20/100] Initial Loss: 0.1324, Training Loss: 0.0770, Initial Validation Loss: 0.1238, Validation Loss: 0.0819,V Acc: 0.6239, Top 70th Acc: 0.7403, Bottom 30th Acc: 0.3438
Stopping early at Epoch (base 0): 21  Rolling back to Epoch (base 0): 16  Top Validation Acc: 0.7532467532467533
Fold [5/5] Epoch [0/100] Initial Loss: 0.1376, Training Loss: 0.1376, Initial Validation Loss: 0.1321, Validation Loss: 0.1321,V Acc: 0.5000, Top 70th Acc: 0.5000, Bottom 30th Acc: 0.5000
Fold [5/5] Epoch [10/100] Initial Loss: 0.1376, Training Loss: 0.0805, Initial Validation Loss: 0.1321, Validation Loss: 0.0758,V Acc: 0.6667, Top 70th Acc: 0.8026, Bottom 30th Acc: 0.3438
Fold [5/5] Epoch [20/100] Initial Loss: 0.1376, Training Loss: 0.0790, Initial Validation Loss: 0.1321, Validation Loss: 0.0741,V Acc: 0.6852, Top 70th Acc: 0.8026, Bottom 30th Acc: 0.4062
Stopping early at Epoch (base 0): 27  Rolling back to Epoch (base 0): 22  Top Validation Acc: 0.7894736842105263
Running train_nn.py with seed 11
CUDA:False
Training samples count:  550
Training on 2 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1377, Training Loss: 0.1377, Initial Validation Loss: 0.1279, Validation Loss: 0.1279,V Acc: 0.5000, Top 70th Acc: 0.6076, Bottom 30th Acc: 0.2424
Fold [1/5] Epoch [10/100] Initial Loss: 0.1377, Training Loss: 0.0804, Initial Validation Loss: 0.1279, Validation Loss: 0.0842,V Acc: 0.5893, Top 70th Acc: 0.7089, Bottom 30th Acc: 0.3030
Fold [5/5] Epoch [40/100] Initial Loss: 0.1392, Training Loss: 0.0039, Initial Validation Loss: 0.1353, Validation Loss: 0.0239,V Acc: 0.8704, Top 70th Acc: 0.9868, Bottom 30th Acc: 0.5938
Stopping early at Epoch (base 0): 43  Rolling back to Epoch (base 0): 38  Top Validation Acc: 0.9736842105263158
Running train_nn.py with seed 6
CUDA:False
Training samples count:  550
Training on 162 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1384, Training Loss: 0.1384, Initial Validation Loss: 0.1368, Validation Loss: 0.1368,V Acc: 0.2589, Top 70th Acc: 0.3544, Bottom 30th Acc: 0.0303
Fold [1/5] Epoch [10/100] Initial Loss: 0.1384, Training Loss: 0.0159, Initial Validation Loss: 0.1368, Validation Loss: 0.0408,V Acc: 0.8393, Top 70th Acc: 0.9241, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 19  Rolling back to Epoch (base 0): 14  Top Validation Acc: 0.9367088607594937
Fold [2/5] Epoch [0/100] Initial Loss: 0.1391, Training Loss: 0.1391, Initial Validation Loss: 0.1361, Validation Loss: 0.1361,V Acc: 0.3063, Top 70th Acc: 0.3590, Bottom 30th Acc: 0.1818
Fold [2/5] Epoch [10/100] Initial Loss: 0.1391, Training Loss: 0.0241, Initial Validation Loss: 0.1361, Validation Loss: 0.0410,V Acc: 0.8018, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.5455
Fold [2/5] Epoch [20/100] Initial Loss: 0.1391, Training Loss: 0.0057, Initial Validation Loss: 0.1361, Validation Loss: 0.0251,V Acc: 0.8919, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.7273
Fold [2/5] Epoch [30/100] Initial Loss: 0.1391, Training Loss: 0.0042, Initial Validation Loss: 0.1361, Validation Loss: 0.0237,V Acc: 0.9009, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.7576
Fold [2/5] Epoch [40/100] Initial Loss: 0.1391, Training Loss: 0.0038, Initial Validation Loss: 0.1361, Validation Loss: 0.0242,V Acc: 0.9099, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.7879
Stopping early at Epoch (base 0): 40  Rolling back to Epoch (base 0): 35  Top Validation Acc: 0.9615384615384616
Fold [3/5] Epoch [0/100] Initial Loss: 0.1387, Training Loss: 0.1387, Initial Validation Loss: 0.1336, Validation Loss: 0.1336,V Acc: 0.3091, Top 70th Acc: 0.3896, Bottom 30th Acc: 0.1212
Fold [3/5] Epoch [10/100] Initial Loss: 0.1387, Training Loss: 0.0132, Initial Validation Loss: 0.1336, Validation Loss: 0.0369,V Acc: 0.8273, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.6061
Fold [3/5] Epoch [20/100] Initial Loss: 0.1387, Training Loss: 0.0046, Initial Validation Loss: 0.1336, Validation Loss: 0.0319,V Acc: 0.9000, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.8182
Fold [3/5] Epoch [30/100] Initial Loss: 0.1387, Training Loss: 0.0037, Initial Validation Loss: 0.1336, Validation Loss: 0.0314,V Acc: 0.9000, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.8485
Stopping early at Epoch (base 0): 31  Rolling back to Epoch (base 0): 26  Top Validation Acc: 0.922077922077922
Fold [4/5] Epoch [0/100] Initial Loss: 0.1394, Training Loss: 0.1394, Initial Validation Loss: 0.1315, Validation Loss: 0.1315,V Acc: 0.2752, Top 70th Acc: 0.3247, Bottom 30th Acc: 0.1562
Fold [4/5] Epoch [10/100] Initial Loss: 0.1394, Training Loss: 0.0165, Initial Validation Loss: 0.1315, Validation Loss: 0.0399,V Acc: 0.7615, Top 70th Acc: 0.8961, Bottom 30th Acc: 0.4375
Fold [4/5] Epoch [20/100] Initial Loss: 0.1394, Training Loss: 0.0050, Initial Validation Loss: 0.1315, Validation Loss: 0.0374,V Acc: 0.7890, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.5000
Stopping early at Epoch (base 0): 22  Rolling back to Epoch (base 0): 17  Top Validation Acc: 0.9090909090909091
Fold [5/5] Epoch [0/100] Initial Loss: 0.1424, Training Loss: 0.1424, Initial Validation Loss: 0.1310, Validation Loss: 0.1310,V Acc: 0.2500, Top 70th Acc: 0.3421, Bottom 30th Acc: 0.0312
Fold [5/5] Epoch [10/100] Initial Loss: 0.1424, Training Loss: 0.0233, Initial Validation Loss: 0.1310, Validation Loss: 0.0413,V Acc: 0.8333, Top 70th Acc: 0.8947, Bottom 30th Acc: 0.6875
Fold [5/5] Epoch [20/100] Initial Loss: 0.1424, Training Loss: 0.0047, Initial Validation Loss: 0.1310, Validation Loss: 0.0317,V Acc: 0.8241, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.5312
Stopping early at Epoch (base 0): 29  Rolling back to Epoch (base 0): 24  Top Validation Acc: 0.9473684210526315
6 4 [array([0.41071984, 0.03758955, 0.11408847, 0.2976649 , 0.13993725],
      dtype=float32)]
Running train_nn.py with seed 7
CUDA:False
Training samples count:  550
Training on 162 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1415, Training Loss: 0.1415, Initial Validation Loss: 0.1349, Validation Loss: 0.1349,V Acc: 0.2768, Top 70th Acc: 0.3544, Bottom 30th Acc: 0.0909
Fold [1/5] Epoch [10/100] Initial Loss: 0.1415, Training Loss: 0.0239, Initial Validation Loss: 0.1349, Validation Loss: 0.0425,V Acc: 0.8393, Top 70th Acc: 0.8987, Bottom 30th Acc: 0.6970
Fold [1/5] Epoch [20/100] Initial Loss: 0.1415, Training Loss: 0.0049, Initial Validation Loss: 0.1349, Validation Loss: 0.0297,V Acc: 0.8661, Top 70th Acc: 0.9367, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 28  Rolling back to Epoch (base 0): 23  Top Validation Acc: 0.9493670886075949
Fold [2/5] Epoch [0/100] Initial Loss: 0.1408, Training Loss: 0.1408, Initial Validation Loss: 0.1313, Validation Loss: 0.1313,V Acc: 0.3423, Top 70th Acc: 0.4103, Bottom 30th Acc: 0.1818
Fold [2/5] Epoch [10/100] Initial Loss: 0.1408, Training Loss: 0.0223, Initial Validation Loss: 0.1313, Validation Loss: 0.0407,V Acc: 0.7928, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.4545
Fold [2/5] Epoch [20/100] Initial Loss: 0.1408, Training Loss: 0.0051, Initial Validation Loss: 0.1313, Validation Loss: 0.0326,V Acc: 0.8108, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.4545
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.9743589743589743
Fold [3/5] Epoch [0/100] Initial Loss: 0.1406, Training Loss: 0.1406, Initial Validation Loss: 0.1343, Validation Loss: 0.1343,V Acc: 0.3273, Top 70th Acc: 0.4156, Bottom 30th Acc: 0.1212
Fold [3/5] Epoch [10/100] Initial Loss: 0.1406, Training Loss: 0.0213, Initial Validation Loss: 0.1343, Validation Loss: 0.0374,V Acc: 0.8455, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6061
Fold [3/5] Epoch [20/100] Initial Loss: 0.1406, Training Loss: 0.0048, Initial Validation Loss: 0.1343, Validation Loss: 0.0314,V Acc: 0.8455, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 28  Rolling back to Epoch (base 0): 23  Top Validation Acc: 0.974025974025974
Fold [4/5] Epoch [0/100] Initial Loss: 0.1380, Training Loss: 0.1380, Initial Validation Loss: 0.1356, Validation Loss: 0.1356,V Acc: 0.3028, Top 70th Acc: 0.3896, Bottom 30th Acc: 0.0938
Fold [4/5] Epoch [10/100] Initial Loss: 0.1380, Training Loss: 0.0163, Initial Validation Loss: 0.1356, Validation Loss: 0.0340,V Acc: 0.8807, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.6562
Fold [4/5] Epoch [20/100] Initial Loss: 0.1380, Training Loss: 0.0048, Initial Validation Loss: 0.1356, Validation Loss: 0.0284,V Acc: 0.8624, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.6250
Fold [4/5] Epoch [30/100] Initial Loss: 0.1380, Training Loss: 0.0037, Initial Validation Loss: 0.1356, Validation Loss: 0.0281,V Acc: 0.8532, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.5625
Stopping early at Epoch (base 0): 33  Rolling back to Epoch (base 0): 28  Top Validation Acc: 0.974025974025974
7 3 [array([0.23720583, 0.10003719, 0.08814431, 0.3139068 , 0.26070583],
      dtype=float32)]
Fold [5/5] Epoch [0/100] Initial Loss: 0.1383, Training Loss: 0.1383, Initial Validation Loss: 0.1335, Validation Loss: 0.1335,V Acc: 0.2500, Top 70th Acc: 0.2895, Bottom 30th Acc: 0.1562
Fold [5/5] Epoch [10/100] Initial Loss: 0.1383, Training Loss: 0.0160, Initial Validation Loss: 0.1335, Validation Loss: 0.0317,V Acc: 0.8241, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.5625
Fold [5/5] Epoch [20/100] Initial Loss: 0.1383, Training Loss: 0.0053, Initial Validation Loss: 0.1335, Validation Loss: 0.0260,V Acc: 0.8611, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.6875
Fold [5/5] Epoch [30/100] Initial Loss: 0.1383, Training Loss: 0.0043, Initial Validation Loss: 0.1335, Validation Loss: 0.0248,V Acc: 0.8796, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.6875
Stopping early at Epoch (base 0): 35  Rolling back to Epoch (base 0): 30  Top Validation Acc: 0.9367088607594937
Fold [2/5] Epoch [0/100] Initial Loss: 0.1383, Training Loss: 0.1383, Initial Validation Loss: 0.1325, Validation Loss: 0.1325,V Acc: 0.3333, Top 70th Acc: 0.3974, Bottom 30th Acc: 0.1818
Fold [2/5] Epoch [10/100] Initial Loss: 0.1383, Training Loss: 0.0320, Initial Validation Loss: 0.1325, Validation Loss: 0.0358,V Acc: 0.8468, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.6364
Fold [2/5] Epoch [20/100] Initial Loss: 0.1383, Training Loss: 0.0151, Initial Validation Loss: 0.1325, Validation Loss: 0.0257,V Acc: 0.8739, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.6364
Fold [2/5] Epoch [30/100] Initial Loss: 0.1383, Training Loss: 0.0124, Initial Validation Loss: 0.1325, Validation Loss: 0.0255,V Acc: 0.8559, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 31  Rolling back to Epoch (base 0): 26  Top Validation Acc: 0.9743589743589743
Fold [3/5] Epoch [0/100] Initial Loss: 0.1385, Training Loss: 0.1385, Initial Validation Loss: 0.1309, Validation Loss: 0.1309,V Acc: 0.2909, Top 70th Acc: 0.3377, Bottom 30th Acc: 0.1818
Fold [3/5] Epoch [10/100] Initial Loss: 0.1385, Training Loss: 0.0259, Initial Validation Loss: 0.1309, Validation Loss: 0.0281,V Acc: 0.8909, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.8182
Fold [3/5] Epoch [20/100] Initial Loss: 0.1385, Training Loss: 0.0139, Initial Validation Loss: 0.1309, Validation Loss: 0.0215,V Acc: 0.8909, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.7879
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.948051948051948
Fold [4/5] Epoch [0/100] Initial Loss: 0.1411, Training Loss: 0.1411, Initial Validation Loss: 0.1350, Validation Loss: 0.1350,V Acc: 0.2661, Top 70th Acc: 0.3117, Bottom 30th Acc: 0.1562
Fold [4/5] Epoch [10/100] Initial Loss: 0.1411, Training Loss: 0.0344, Initial Validation Loss: 0.1350, Validation Loss: 0.0451,V Acc: 0.7798, Top 70th Acc: 0.8961, Bottom 30th Acc: 0.5000
Fold [4/5] Epoch [20/100] Initial Loss: 0.1411, Training Loss: 0.0129, Initial Validation Loss: 0.1350, Validation Loss: 0.0414,V Acc: 0.7798, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.4688
Stopping early at Epoch (base 0): 21  Rolling back to Epoch (base 0): 16  Top Validation Acc: 0.8961038961038961
9 3 [array([0.5856072 , 0.03110767, 0.03839793, 0.18632446, 0.15856273],
      dtype=float32)]
Fold [5/5] Epoch [0/100] Initial Loss: 0.1385, Training Loss: 0.1385, Initial Validation Loss: 0.1319, Validation Loss: 0.1319,V Acc: 0.3241, Top 70th Acc: 0.3421, Bottom 30th Acc: 0.2812
Fold [5/5] Epoch [10/100] Initial Loss: 0.1385, Training Loss: 0.0248, Initial Validation Loss: 0.1319, Validation Loss: 0.0319,V Acc: 0.8519, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.5938
Fold [5/5] Epoch [20/100] Initial Loss: 0.1385, Training Loss: 0.0136, Initial Validation Loss: 0.1319, Validation Loss: 0.0277,V Acc: 0.8611, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.6562
Stopping early at Epoch (base 0): 22  Rolling back to Epoch (base 0): 17  Top Validation Acc: 0.9736842105263158
Running train_nn.py with seed 10
CUDA:False
Training samples count:  550
Training on 40 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1433, Training Loss: 0.1433, Initial Validation Loss: 0.1322, Validation Loss: 0.1322,V Acc: 0.3214, Top 70th Acc: 0.3291, Bottom 30th Acc: 0.3030
Fold [1/5] Epoch [10/100] Initial Loss: 0.1433, Training Loss: 0.0490, Initial Validation Loss: 0.1322, Validation Loss: 0.0374,V Acc: 0.8393, Top 70th Acc: 0.9241, Bottom 30th Acc: 0.6364
Fold [1/5] Epoch [20/100] Initial Loss: 0.1433, Training Loss: 0.0163, Initial Validation Loss: 0.1322, Validation Loss: 0.0216,V Acc: 0.8750, Top 70th Acc: 0.9747, Bottom 30th Acc: 0.6364
Fold [1/5] Epoch [30/100] Initial Loss: 0.1433, Training Loss: 0.0121, Initial Validation Loss: 0.1322, Validation Loss: 0.0209,V Acc: 0.8750, Top 70th Acc: 0.9747, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 34  Rolling back to Epoch (base 0): 29  Top Validation Acc: 0.9746835443037974
Fold [2/5] Epoch [0/100] Initial Loss: 0.1418, Training Loss: 0.1418, Initial Validation Loss: 0.1350, Validation Loss: 0.1350,V Acc: 0.3333, Top 70th Acc: 0.3462, Bottom 30th Acc: 0.3030
Fold [2/5] Epoch [10/100] Initial Loss: 0.1418, Training Loss: 0.0426, Initial Validation Loss: 0.1350, Validation Loss: 0.0591,V Acc: 0.6937, Top 70th Acc: 0.8077, Bottom 30th Acc: 0.4242
Fold [2/5] Epoch [20/100] Initial Loss: 0.1418, Training Loss: 0.0152, Initial Validation Loss: 0.1350, Validation Loss: 0.0349,V Acc: 0.8559, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.6364
Fold [2/5] Epoch [30/100] Initial Loss: 0.1418, Training Loss: 0.0117, Initial Validation Loss: 0.1350, Validation Loss: 0.0332,V Acc: 0.8649, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 38  Rolling back to Epoch (base 0): 33  Top Validation Acc: 0.9358974358974359
Fold [3/5] Epoch [0/100] Initial Loss: 0.1401, Training Loss: 0.1401, Initial Validation Loss: 0.1328, Validation Loss: 0.1328,V Acc: 0.2455, Top 70th Acc: 0.2857, Bottom 30th Acc: 0.1515
Fold [3/5] Epoch [10/100] Initial Loss: 0.1401, Training Loss: 0.0288, Initial Validation Loss: 0.1328, Validation Loss: 0.0412,V Acc: 0.8091, Top 70th Acc: 0.8831, Bottom 30th Acc: 0.6364
Fold [3/5] Epoch [20/100] Initial Loss: 0.1401, Training Loss: 0.0138, Initial Validation Loss: 0.1328, Validation Loss: 0.0333,V Acc: 0.8455, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 29  Rolling back to Epoch (base 0): 24  Top Validation Acc: 0.9090909090909091
10 2 [array([0.18972497, 0.07191661, 0.06166853, 0.12596458, 0.55072534],
      dtype=float32)]
Fold [4/5] Epoch [0/100] Initial Loss: 0.1370, Training Loss: 0.1370, Initial Validation Loss: 0.1320, Validation Loss: 0.1320,V Acc: 0.2569, Top 70th Acc: 0.3506, Bottom 30th Acc: 0.0312
Fold [4/5] Epoch [10/100] Initial Loss: 0.1370, Training Loss: 0.0237, Initial Validation Loss: 0.1320, Validation Loss: 0.0328,V Acc: 0.8165, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.4375
Fold [4/5] Epoch [20/100] Initial Loss: 0.1370, Training Loss: 0.0133, Initial Validation Loss: 0.1320, Validation Loss: 0.0288,V Acc: 0.8440, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.5625
Stopping early at Epoch (base 0): 27  Rolling back to Epoch (base 0): 22  Top Validation Acc: 0.961038961038961
Fold [5/5] Epoch [0/100] Initial Loss: 0.1380, Training Loss: 0.1380, Initial Validation Loss: 0.1361, Validation Loss: 0.1361,V Acc: 0.2500, Top 70th Acc: 0.2500, Bottom 30th Acc: 0.2500
Fold [5/5] Epoch [10/100] Initial Loss: 0.1380, Training Loss: 0.0396, Initial Validation Loss: 0.1361, Validation Loss: 0.0456,V Acc: 0.7778, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.3438
Fold [5/5] Epoch [20/100] Initial Loss: 0.1380, Training Loss: 0.0161, Initial Validation Loss: 0.1361, Validation Loss: 0.0300,V Acc: 0.8519, Top 70th Acc: 0.9737, Bottom 30th Acc: 0.5625
Fold [5/5] Epoch [30/100] Initial Loss: 0.1380, Training Loss: 0.0118, Initial Validation Loss: 0.1361, Validation Loss: 0.0284,V Acc: 0.8519, Top 70th Acc: 0.9737, Bottom 30th Acc: 0.5625
Stopping early at Epoch (base 0): 31  Rolling back to Epoch (base 0): 26  Top Validation Acc: 0.9736842105263158
Running train_nn.py with seed 11
CUDA:False
Training samples count:  550
Training on 40 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1388, Training Loss: 0.1388, Initial Validation Loss: 0.1318, Validation Loss: 0.1318,V Acc: 0.2857, Top 70th Acc: 0.3291, Bottom 30th Acc: 0.1818
Fold [1/5] Epoch [10/100] Initial Loss: 0.1388, Training Loss: 0.0325, Initial Validation Loss: 0.1318, Validation Loss: 0.0405,V Acc: 0.7768, Top 70th Acc: 0.9367, Bottom 30th Acc: 0.3939
Fold [1/5] Epoch [20/100] Initial Loss: 0.1388, Training Loss: 0.0172, Initial Validation Loss: 0.1318, Validation Loss: 0.0338,V Acc: 0.7857, Top 70th Acc: 0.9241, Bottom 30th Acc: 0.4545
Fold [1/5] Epoch [30/100] Initial Loss: 0.1388, Training Loss: 0.0126, Initial Validation Loss: 0.1318, Validation Loss: 0.0305,V Acc: 0.8304, Top 70th Acc: 0.9494, Bottom 30th Acc: 0.5455
Fold [1/5] Epoch [40/100] Initial Loss: 0.1388, Training Loss: 0.0108, Initial Validation Loss: 0.1318, Validation Loss: 0.0287,V Acc: 0.8482, Top 70th Acc: 0.9367, Bottom 30th Acc: 0.6364
Training on 2 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 91
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 2 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 92
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 2 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 93
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 2 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 94
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 2 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 95
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 2 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 96
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 2 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 97
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 2 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 98
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 2 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 99
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 2 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 100
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 2 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5

Fold [3/5] Epoch [20/100] Initial Loss: 0.1385, Training Loss: 0.0196, Initial Validation Loss: 0.1304, Validation Loss: 0.0293,V Acc: 0.8636, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 21  Rolling back to Epoch (base 0): 16  Top Validation Acc: 0.935064935064935
Fold [4/5] Epoch [0/100] Initial Loss: 0.1403, Training Loss: 0.1403, Initial Validation Loss: 0.1357, Validation Loss: 0.1357,V Acc: 0.2477, Top 70th Acc: 0.2338, Bottom 30th Acc: 0.2812
Fold [4/5] Epoch [10/100] Initial Loss: 0.1403, Training Loss: 0.0428, Initial Validation Loss: 0.1357, Validation Loss: 0.0438,V Acc: 0.7798, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.4688
Fold [4/5] Epoch [20/100] Initial Loss: 0.1403, Training Loss: 0.0197, Initial Validation Loss: 0.1357, Validation Loss: 0.0390,V Acc: 0.7798, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.4688
Stopping early at Epoch (base 0): 20  Rolling back to Epoch (base 0): 15  Top Validation Acc: 0.9090909090909091
9 3 [array([0.71472216, 0.04605319, 0.03118906, 0.08904079, 0.11899479],
      dtype=float32)]
Fold [5/5] Epoch [0/100] Initial Loss: 0.1386, Training Loss: 0.1386, Initial Validation Loss: 0.1275, Validation Loss: 0.1275,V Acc: 0.4167, Top 70th Acc: 0.4868, Bottom 30th Acc: 0.2500
Fold [5/5] Epoch [10/100] Initial Loss: 0.1386, Training Loss: 0.0437, Initial Validation Loss: 0.1275, Validation Loss: 0.0497,V Acc: 0.7778, Top 70th Acc: 0.8684, Bottom 30th Acc: 0.5625
Fold [5/5] Epoch [20/100] Initial Loss: 0.1386, Training Loss: 0.0218, Initial Validation Loss: 0.1275, Validation Loss: 0.0379,V Acc: 0.8056, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.5000
Fold [5/5] Epoch [30/100] Initial Loss: 0.1386, Training Loss: 0.0175, Initial Validation Loss: 0.1275, Validation Loss: 0.0378,V Acc: 0.8056, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.4688
Stopping early at Epoch (base 0): 31  Rolling back to Epoch (base 0): 26  Top Validation Acc: 0.9342105263157895
Running train_nn.py with seed 10
CUDA:False
Training samples count:  550
Training on 30 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1429, Training Loss: 0.1429, Initial Validation Loss: 0.1312, Validation Loss: 0.1312,V Acc: 0.2679, Top 70th Acc: 0.2785, Bottom 30th Acc: 0.2424
Fold [1/5] Epoch [10/100] Initial Loss: 0.1429, Training Loss: 0.0360, Initial Validation Loss: 0.1312, Validation Loss: 0.0309,V Acc: 0.8125, Top 70th Acc: 0.9241, Bottom 30th Acc: 0.5455
Fold [1/5] Epoch [20/100] Initial Loss: 0.1429, Training Loss: 0.0198, Initial Validation Loss: 0.1312, Validation Loss: 0.0242,V Acc: 0.8482, Top 70th Acc: 0.9494, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.9367088607594937
Fold [2/5] Epoch [0/100] Initial Loss: 0.1394, Training Loss: 0.1394, Initial Validation Loss: 0.1346, Validation Loss: 0.1346,V Acc: 0.2523, Top 70th Acc: 0.3590, Bottom 30th Acc: 0.0000
Fold [2/5] Epoch [10/100] Initial Loss: 0.1394, Training Loss: 0.0352, Initial Validation Loss: 0.1346, Validation Loss: 0.0479,V Acc: 0.7748, Top 70th Acc: 0.8590, Bottom 30th Acc: 0.5758
Fold [2/5] Epoch [20/100] Initial Loss: 0.1394, Training Loss: 0.0184, Initial Validation Loss: 0.1346, Validation Loss: 0.0346,V Acc: 0.8288, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 28  Rolling back to Epoch (base 0): 23  Top Validation Acc: 0.9230769230769231
Fold [3/5] Epoch [0/100] Initial Loss: 0.1397, Training Loss: 0.1397, Initial Validation Loss: 0.1320, Validation Loss: 0.1320,V Acc: 0.2727, Top 70th Acc: 0.2727, Bottom 30th Acc: 0.2727
Fold [3/5] Epoch [10/100] Initial Loss: 0.1397, Training Loss: 0.0307, Initial Validation Loss: 0.1320, Validation Loss: 0.0443,V Acc: 0.7818, Top 70th Acc: 0.8961, Bottom 30th Acc: 0.5152
Fold [3/5] Epoch [20/100] Initial Loss: 0.1397, Training Loss: 0.0191, Initial Validation Loss: 0.1320, Validation Loss: 0.0367,V Acc: 0.8273, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.6364
Fold [3/5] Epoch [30/100] Initial Loss: 0.1397, Training Loss: 0.0158, Initial Validation Loss: 0.1320, Validation Loss: 0.0351,V Acc: 0.8364, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 34  Rolling back to Epoch (base 0): 29  Top Validation Acc: 0.935064935064935
10 2 [array([0.5392821 , 0.04825457, 0.06761384, 0.1506356 , 0.19421385],
      dtype=float32)]
Fold [4/5] Epoch [0/100] Initial Loss: 0.1358, Training Loss: 0.1358, Initial Validation Loss: 0.1305, Validation Loss: 0.1305,V Acc: 0.2936, Top 70th Acc: 0.3636, Bottom 30th Acc: 0.1250
Fold [4/5] Epoch [10/100] Initial Loss: 0.1358, Training Loss: 0.0312, Initial Validation Loss: 0.1305, Validation Loss: 0.0394,V Acc: 0.8165, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.5000
Fold [4/5] Epoch [20/100] Initial Loss: 0.1358, Training Loss: 0.0181, Initial Validation Loss: 0.1305, Validation Loss: 0.0306,V Acc: 0.8440, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.5625
Fold [4/5] Epoch [30/100] Initial Loss: 0.1358, Training Loss: 0.0156, Initial Validation Loss: 0.1305, Validation Loss: 0.0296,V Acc: 0.8624, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.5938
Stopping early at Epoch (base 0): 32  Rolling back to Epoch (base 0): 27  Top Validation Acc: 0.974025974025974
Fold [5/5] Epoch [0/100] Initial Loss: 0.1374, Training Loss: 0.1374, Initial Validation Loss: 0.1369, Validation Loss: 0.1369,V Acc: 0.2500, Top 70th Acc: 0.3421, Bottom 30th Acc: 0.0312
Fold [5/5] Epoch [10/100] Initial Loss: 0.1374, Training Loss: 0.0374, Initial Validation Loss: 0.1369, Validation Loss: 0.0379,V Acc: 0.8519, Top 70th Acc: 0.9737, Bottom 30th Acc: 0.5625
Fold [5/5] Epoch [20/100] Initial Loss: 0.1374, Training Loss: 0.0195, Initial Validation Loss: 0.1369, Validation Loss: 0.0289,V Acc: 0.8333, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.5312
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.9605263157894737
Running train_nn.py with seed 11
CUDA:False
Training samples count:  550
Training on 30 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1420, Training Loss: 0.1420, Initial Validation Loss: 0.1344, Validation Loss: 0.1344,V Acc: 0.3036, Top 70th Acc: 0.3418, Bottom 30th Acc: 0.2121
Fold [1/5] Epoch [10/100] Initial Loss: 0.1420, Training Loss: 0.0322, Initial Validation Loss: 0.1344, Validation Loss: 0.0381,V Acc: 0.8125, Top 70th Acc: 0.9367, Bottom 30th Acc: 0.5152
Fold [1/5] Epoch [20/100] Initial Loss: 0.1420, Training Loss: 0.0181, Initial Validation Loss: 0.1344, Validation Loss: 0.0328,V Acc: 0.8214, Top 70th Acc: 0.9367, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 27  Rolling back to Epoch (base 0): 22  Top Validation Acc: 0.9367088607594937
Fold [2/5] Epoch [0/100] Initial Loss: 0.1385, Training Loss: 0.1385, Initial Validation Loss: 0.1313, Validation Loss: 0.1313,V Acc: 0.2973, Top 70th Acc: 0.3333, Bottom 30th Acc: 0.2121
Fold [2/5] Epoch [10/100] Initial Loss: 0.1385, Training Loss: 0.0281, Initial Validation Loss: 0.1313, Validation Loss: 0.0317,V Acc: 0.8198, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.5758
Fold [2/5] Epoch [20/100] Initial Loss: 0.1385, Training Loss: 0.0195, Initial Validation Loss: 0.1313, Validation Loss: 0.0303,V Acc: 0.8288, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.9358974358974359
Fold [3/5] Epoch [0/100] Initial Loss: 0.1371, Training Loss: 0.1371, Initial Validation Loss: 0.1378, Validation Loss: 0.1378,V Acc: 0.2545, Top 70th Acc: 0.3247, Bottom 30th Acc: 0.0909
Fold [3/5] Epoch [10/100] Initial Loss: 0.1371, Training Loss: 0.0373, Initial Validation Loss: 0.1378, Validation Loss: 0.0382,V Acc: 0.8091, Top 70th Acc: 0.9870, Bottom 30th Acc: 0.3939
Fold [3/5] Epoch [20/100] Initial Loss: 0.1371, Training Loss: 0.0244, Initial Validation Loss: 0.1378, Validation Loss: 0.0262,V Acc: 0.9000, Top 70th Acc: 0.9870, Bottom 30th Acc: 0.6970
Fold [3/5] Epoch [30/100] Initial Loss: 0.1371, Training Loss: 0.0188, Initial Validation Loss: 0.1378, Validation Loss: 0.0225,V Acc: 0.9000, Top 70th Acc: 0.9870, Bottom 30th Acc: 0.6970
Fold [3/5] Epoch [40/100] Initial Loss: 0.1371, Training Loss: 0.0164, Initial Validation Loss: 0.1378, Validation Loss: 0.0211,V Acc: 0.9000, Top 70th Acc: 0.9870, Bottom 30th Acc: 0.6970
Fold [2/5] Epoch [10/100] Initial Loss: 0.1409, Training Loss: 0.0492, Initial Validation Loss: 0.1361, Validation Loss: 0.0544,V Acc: 0.7568, Top 70th Acc: 0.8846, Bottom 30th Acc: 0.4545
Fold [2/5] Epoch [20/100] Initial Loss: 0.1409, Training Loss: 0.0244, Initial Validation Loss: 0.1361, Validation Loss: 0.0391,V Acc: 0.8018, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.5152
Fold [2/5] Epoch [30/100] Initial Loss: 0.1409, Training Loss: 0.0208, Initial Validation Loss: 0.1361, Validation Loss: 0.0371,V Acc: 0.8018, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.5152
Stopping early at Epoch (base 0): 31  Rolling back to Epoch (base 0): 26  Top Validation Acc: 0.9358974358974359
Fold [3/5] Epoch [0/100] Initial Loss: 0.1402, Training Loss: 0.1402, Initial Validation Loss: 0.1326, Validation Loss: 0.1326,V Acc: 0.2727, Top 70th Acc: 0.2208, Bottom 30th Acc: 0.3939
Fold [3/5] Epoch [10/100] Initial Loss: 0.1402, Training Loss: 0.0329, Initial Validation Loss: 0.1326, Validation Loss: 0.0339,V Acc: 0.8727, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.7273
Fold [3/5] Epoch [20/100] Initial Loss: 0.1402, Training Loss: 0.0230, Initial Validation Loss: 0.1326, Validation Loss: 0.0311,V Acc: 0.8545, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.922077922077922
Fold [4/5] Epoch [0/100] Initial Loss: 0.1404, Training Loss: 0.1404, Initial Validation Loss: 0.1316, Validation Loss: 0.1316,V Acc: 0.3394, Top 70th Acc: 0.4416, Bottom 30th Acc: 0.0938
Fold [4/5] Epoch [10/100] Initial Loss: 0.1404, Training Loss: 0.0299, Initial Validation Loss: 0.1316, Validation Loss: 0.0331,V Acc: 0.8349, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.5938
Fold [4/5] Epoch [20/100] Initial Loss: 0.1404, Training Loss: 0.0228, Initial Validation Loss: 0.1316, Validation Loss: 0.0312,V Acc: 0.8440, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.6250
Stopping early at Epoch (base 0): 21  Rolling back to Epoch (base 0): 16  Top Validation Acc: 0.935064935064935
9 3 [array([0.30807513, 0.08610038, 0.07995595, 0.34117085, 0.18469766],
      dtype=float32)]
Fold [5/5] Epoch [0/100] Initial Loss: 0.1415, Training Loss: 0.1415, Initial Validation Loss: 0.1319, Validation Loss: 0.1319,V Acc: 0.3241, Top 70th Acc: 0.3421, Bottom 30th Acc: 0.2812
Fold [5/5] Epoch [10/100] Initial Loss: 0.1415, Training Loss: 0.0348, Initial Validation Loss: 0.1319, Validation Loss: 0.0367,V Acc: 0.8333, Top 70th Acc: 0.9211, Bottom 30th Acc: 0.6250
Fold [5/5] Epoch [20/100] Initial Loss: 0.1415, Training Loss: 0.0233, Initial Validation Loss: 0.1319, Validation Loss: 0.0349,V Acc: 0.8056, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.5000
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.9210526315789473
Running train_nn.py with seed 10
CUDA:False
Training samples count:  550
Training on 20 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1429, Training Loss: 0.1429, Initial Validation Loss: 0.1313, Validation Loss: 0.1313,V Acc: 0.2500, Top 70th Acc: 0.2405, Bottom 30th Acc: 0.2727
Fold [1/5] Epoch [10/100] Initial Loss: 0.1429, Training Loss: 0.0367, Initial Validation Loss: 0.1313, Validation Loss: 0.0333,V Acc: 0.8214, Top 70th Acc: 0.8987, Bottom 30th Acc: 0.6364
Fold [1/5] Epoch [20/100] Initial Loss: 0.1429, Training Loss: 0.0247, Initial Validation Loss: 0.1313, Validation Loss: 0.0298,V Acc: 0.8125, Top 70th Acc: 0.9367, Bottom 30th Acc: 0.5152
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.9493670886075949
Fold [2/5] Epoch [0/100] Initial Loss: 0.1368, Training Loss: 0.1368, Initial Validation Loss: 0.1334, Validation Loss: 0.1334,V Acc: 0.3243, Top 70th Acc: 0.4231, Bottom 30th Acc: 0.0909
Fold [2/5] Epoch [10/100] Initial Loss: 0.1368, Training Loss: 0.0360, Initial Validation Loss: 0.1334, Validation Loss: 0.0454,V Acc: 0.8108, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.5758
Fold [2/5] Epoch [20/100] Initial Loss: 0.1368, Training Loss: 0.0241, Initial Validation Loss: 0.1334, Validation Loss: 0.0422,V Acc: 0.7928, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.4545
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.9230769230769231
Fold [3/5] Epoch [0/100] Initial Loss: 0.1389, Training Loss: 0.1389, Initial Validation Loss: 0.1314, Validation Loss: 0.1314,V Acc: 0.3545, Top 70th Acc: 0.4156, Bottom 30th Acc: 0.2121
Fold [3/5] Epoch [10/100] Initial Loss: 0.1389, Training Loss: 0.0360, Initial Validation Loss: 0.1314, Validation Loss: 0.0436,V Acc: 0.8273, Top 70th Acc: 0.8831, Bottom 30th Acc: 0.6970
Fold [3/5] Epoch [20/100] Initial Loss: 0.1389, Training Loss: 0.0231, Initial Validation Loss: 0.1314, Validation Loss: 0.0359,V Acc: 0.8455, Top 70th Acc: 0.8961, Bottom 30th Acc: 0.7273
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.8961038961038961
10 2 [array([0.36531007, 0.11951344, 0.12243654, 0.26931378, 0.12342618],
      dtype=float32)]
Fold [4/5] Epoch [0/100] Initial Loss: 0.1373, Training Loss: 0.1373, Initial Validation Loss: 0.1323, Validation Loss: 0.1323,V Acc: 0.3486, Top 70th Acc: 0.3896, Bottom 30th Acc: 0.2500
Fold [4/5] Epoch [10/100] Initial Loss: 0.1373, Training Loss: 0.0291, Initial Validation Loss: 0.1323, Validation Loss: 0.0373,V Acc: 0.8440, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.6562
Stopping early at Epoch (base 0): 19  Rolling back to Epoch (base 0): 14  Top Validation Acc: 0.935064935064935
Fold [5/5] Epoch [0/100] Initial Loss: 0.1390, Training Loss: 0.1390, Initial Validation Loss: 0.1370, Validation Loss: 0.1370,V Acc: 0.2500, Top 70th Acc: 0.3289, Bottom 30th Acc: 0.0625
Fold [5/5] Epoch [10/100] Initial Loss: 0.1390, Training Loss: 0.0379, Initial Validation Loss: 0.1370, Validation Loss: 0.0405,V Acc: 0.8056, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.4375
Fold [5/5] Epoch [20/100] Initial Loss: 0.1390, Training Loss: 0.0254, Initial Validation Loss: 0.1370, Validation Loss: 0.0301,V Acc: 0.8611, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.6562
Stopping early at Epoch (base 0): 29  Rolling back to Epoch (base 0): 24  Top Validation Acc: 0.9473684210526315
Running train_nn.py with seed 11
CUDA:False
Training samples count:  550
Training on 20 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1397, Training Loss: 0.1397, Initial Validation Loss: 0.1331, Validation Loss: 0.1331,V Acc: 0.2857, Top 70th Acc: 0.3165, Bottom 30th Acc: 0.2121
Fold [1/5] Epoch [10/100] Initial Loss: 0.1397, Training Loss: 0.0367, Initial Validation Loss: 0.1331, Validation Loss: 0.0407,V Acc: 0.7946, Top 70th Acc: 0.8734, Bottom 30th Acc: 0.6061
Fold [1/5] Epoch [20/100] Initial Loss: 0.1397, Training Loss: 0.0216, Initial Validation Loss: 0.1331, Validation Loss: 0.0341,V Acc: 0.8036, Top 70th Acc: 0.9114, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.9240506329113924
Fold [2/5] Epoch [0/100] Initial Loss: 0.1387, Training Loss: 0.1387, Initial Validation Loss: 0.1309, Validation Loss: 0.1309,V Acc: 0.3333, Top 70th Acc: 0.3846, Bottom 30th Acc: 0.2121
Fold [2/5] Epoch [10/100] Initial Loss: 0.1387, Training Loss: 0.0394, Initial Validation Loss: 0.1309, Validation Loss: 0.0436,V Acc: 0.7477, Top 70th Acc: 0.8846, Bottom 30th Acc: 0.4242
Fold [2/5] Epoch [20/100] Initial Loss: 0.1387, Training Loss: 0.0261, Initial Validation Loss: 0.1309, Validation Loss: 0.0328,V Acc: 0.8018, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.5152
Fold [2/5] Epoch [30/100] Initial Loss: 0.1387, Training Loss: 0.0230, Initial Validation Loss: 0.1309, Validation Loss: 0.0319,V Acc: 0.8288, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 31  Rolling back to Epoch (base 0): 26  Top Validation Acc: 0.9358974358974359
Fold [3/5] Epoch [0/100] Initial Loss: 0.1369, Training Loss: 0.1369, Initial Validation Loss: 0.1364, Validation Loss: 0.1364,V Acc: 0.4000, Top 70th Acc: 0.4545, Bottom 30th Acc: 0.2727
Fold [3/5] Epoch [10/100] Initial Loss: 0.1369, Training Loss: 0.0348, Initial Validation Loss: 0.1364, Validation Loss: 0.0294,V Acc: 0.8727, Top 70th Acc: 1.0000, Bottom 30th Acc: 0.5758/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)

Stopping early at Epoch (base 0): 17  Rolling back to Epoch (base 0): 12  Top Validation Acc: 0.961038961038961
13 3 [array([0.81737137, 0.02624761, 0.0268631 , 0.08246296, 0.04705485],
      dtype=float32)]
Fold [5/5] Epoch [0/100] Initial Loss: 0.1398, Training Loss: 0.1398, Initial Validation Loss: 0.1263, Validation Loss: 0.1263,V Acc: 0.4074, Top 70th Acc: 0.4474, Bottom 30th Acc: 0.3125
Fold [5/5] Epoch [10/100] Initial Loss: 0.1398, Training Loss: 0.0237, Initial Validation Loss: 0.1263, Validation Loss: 0.0289,V Acc: 0.8704, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.6875
Fold [5/5] Epoch [20/100] Initial Loss: 0.1398, Training Loss: 0.0163, Initial Validation Loss: 0.1263, Validation Loss: 0.0267,V Acc: 0.8981, Top 70th Acc: 0.9737, Bottom 30th Acc: 0.7188
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.9736842105263158
Running train_nn.py with seed 14
CUDA:False
Training samples count:  550
Training on 21 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1397, Training Loss: 0.1397, Initial Validation Loss: 0.1300, Validation Loss: 0.1300,V Acc: 0.4107, Top 70th Acc: 0.4810, Bottom 30th Acc: 0.2424
Fold [1/5] Epoch [10/100] Initial Loss: 0.1397, Training Loss: 0.0241, Initial Validation Loss: 0.1300, Validation Loss: 0.0298,V Acc: 0.8393, Top 70th Acc: 0.9747, Bottom 30th Acc: 0.5152
Stopping early at Epoch (base 0): 19  Rolling back to Epoch (base 0): 14  Top Validation Acc: 0.9620253164556962
Fold [2/5] Epoch [0/100] Initial Loss: 0.1342, Training Loss: 0.1342, Initial Validation Loss: 0.1203, Validation Loss: 0.1203,V Acc: 0.4955, Top 70th Acc: 0.6410, Bottom 30th Acc: 0.1515
Fold [2/5] Epoch [10/100] Initial Loss: 0.1342, Training Loss: 0.0193, Initial Validation Loss: 0.1203, Validation Loss: 0.0297,V Acc: 0.8649, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 19  Rolling back to Epoch (base 0): 14  Top Validation Acc: 0.9102564102564102
14 1 [array([0.8515342 , 0.02418546, 0.01802446, 0.04691147, 0.05934441],
      dtype=float32)]
Fold [3/5] Epoch [0/100] Initial Loss: 0.1332, Training Loss: 0.1332, Initial Validation Loss: 0.1207, Validation Loss: 0.1207,V Acc: 0.4818, Top 70th Acc: 0.5584, Bottom 30th Acc: 0.3030
Fold [3/5] Epoch [10/100] Initial Loss: 0.1332, Training Loss: 0.0221, Initial Validation Loss: 0.1207, Validation Loss: 0.0279,V Acc: 0.8909, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 14  Rolling back to Epoch (base 0): 9  Top Validation Acc: 0.948051948051948
Fold [4/5] Epoch [0/100] Initial Loss: 0.1309, Training Loss: 0.1309, Initial Validation Loss: 0.1102, Validation Loss: 0.1102,V Acc: 0.4771, Top 70th Acc: 0.5714, Bottom 30th Acc: 0.2500
Fold [4/5] Epoch [10/100] Initial Loss: 0.1309, Training Loss: 0.0210, Initial Validation Loss: 0.1102, Validation Loss: 0.0244,V Acc: 0.8807, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.6562
Fold [4/5] Epoch [20/100] Initial Loss: 0.1309, Training Loss: 0.0138, Initial Validation Loss: 0.1102, Validation Loss: 0.0296,V Acc: 0.8257, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.5312
Stopping early at Epoch (base 0): 21  Rolling back to Epoch (base 0): 16  Top Validation Acc: 0.974025974025974
Fold [5/5] Epoch [0/100] Initial Loss: 0.1360, Training Loss: 0.1360, Initial Validation Loss: 0.1233, Validation Loss: 0.1233,V Acc: 0.4630, Top 70th Acc: 0.5263, Bottom 30th Acc: 0.3125
Fold [5/5] Epoch [10/100] Initial Loss: 0.1360, Training Loss: 0.0242, Initial Validation Loss: 0.1233, Validation Loss: 0.0242,V Acc: 0.8796, Top 70th Acc: 0.9868, Bottom 30th Acc: 0.6250
Fold [5/5] Epoch [20/100] Initial Loss: 0.1360, Training Loss: 0.0158, Initial Validation Loss: 0.1233, Validation Loss: 0.0186,V Acc: 0.8889, Top 70th Acc: 0.9868, Bottom 30th Acc: 0.6562
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.9736842105263158
Running train_nn.py with seed 15
CUDA:False
Training samples count:  550
Training on 21 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1367, Training Loss: 0.1367, Initial Validation Loss: 0.1288, Validation Loss: 0.1288,V Acc: 0.4196, Top 70th Acc: 0.4684, Bottom 30th Acc: 0.3030
Fold [1/5] Epoch [10/100] Initial Loss: 0.1367, Training Loss: 0.0227, Initial Validation Loss: 0.1288, Validation Loss: 0.0356,V Acc: 0.8393, Top 70th Acc: 0.9241, Bottom 30th Acc: 0.6364
Fold [1/5] Epoch [20/100] Initial Loss: 0.1367, Training Loss: 0.0151, Initial Validation Loss: 0.1288, Validation Loss: 0.0378,V Acc: 0.8125, Top 70th Acc: 0.9241, Bottom 30th Acc: 0.5455
Fold [1/5] Epoch [30/100] Initial Loss: 0.1367, Training Loss: 0.0130, Initial Validation Loss: 0.1288, Validation Loss: 0.0345,V Acc: 0.7946, Top 70th Acc: 0.9367, Bottom 30th Acc: 0.4545
Fold [1/5] Epoch [40/100] Initial Loss: 0.1367, Training Loss: 0.0109, Initial Validation Loss: 0.1288, Validation Loss: 0.0289,V Acc: 0.8661, Top 70th Acc: 0.9747, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 40  Rolling back to Epoch (base 0): 35  Top Validation Acc: 0.9746835443037974
Fold [2/5] Epoch [0/100] Initial Loss: 0.1358, Training Loss: 0.1358, Initial Validation Loss: 0.1243, Validation Loss: 0.1243,V Acc: 0.5315, Top 70th Acc: 0.6282, Bottom 30th Acc: 0.3030
Fold [2/5] Epoch [10/100] Initial Loss: 0.1358, Training Loss: 0.0251, Initial Validation Loss: 0.1243, Validation Loss: 0.0310,V Acc: 0.8378, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.5152
Fold [2/5] Epoch [20/100] Initial Loss: 0.1358, Training Loss: 0.0165, Initial Validation Loss: 0.1243, Validation Loss: 0.0271,V Acc: 0.8649, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.6667
Fold [2/5] Epoch [30/100] Initial Loss: 0.1358, Training Loss: 0.0144, Initial Validation Loss: 0.1243, Validation Loss: 0.0261,V Acc: 0.8559, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 30  Rolling back to Epoch (base 0): 25  Top Validation Acc: 0.9743589743589743
15 1 [array([0.81399757, 0.03399709, 0.02951413, 0.04804996, 0.07444135],
      dtype=float32)]
Fold [3/5] Epoch [0/100] Initial Loss: 0.1367, Training Loss: 0.1367, Initial Validation Loss: 0.1236, Validation Loss: 0.1236,V Acc: 0.5182, Top 70th Acc: 0.6234, Bottom 30th Acc: 0.2727
Fold [3/5] Epoch [10/100] Initial Loss: 0.1367, Training Loss: 0.0306, Initial Validation Loss: 0.1236, Validation Loss: 0.0304,V Acc: 0.8545, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6364
Fold [3/5] Epoch [20/100] Initial Loss: 0.1367, Training Loss: 0.0181, Initial Validation Loss: 0.1236, Validation Loss: 0.0257,V Acc: 0.8727, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.961038961038961
Fold [4/5] Epoch [0/100] Initial Loss: 0.1275, Training Loss: 0.1275, Initial Validation Loss: 0.1106, Validation Loss: 0.1106,V Acc: 0.5688, Top 70th Acc: 0.6623, Bottom 30th Acc: 0.3438
Fold [4/5] Epoch [10/100] Initial Loss: 0.1275, Training Loss: 0.0223, Initial Validation Loss: 0.1106, Validation Loss: 0.0225,V Acc: 0.9266, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.8125
Fold [4/5] Epoch [20/100] Initial Loss: 0.1275, Training Loss: 0.0168, Initial Validation Loss: 0.1106, Validation Loss: 0.0197,V Acc: 0.9266, Top 70th Acc: 0.9870, Bottom 30th Acc: 0.7812
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.974025974025974
Fold [5/5] Epoch [0/100] Initial Loss: 0.1304, Training Loss: 0.1304, Initial Validation Loss: 0.1092, Validation Loss: 0.1092,V Acc: 0.4907, Top 70th Acc: 0.5526, Bottom 30th Acc: 0.3438
Fold [5/5] Epoch [10/100] Initial Loss: 0.1304, Training Loss: 0.0204, Initial Validation Loss: 0.1092, Validation Loss: 0.0264,V Acc: 0.8796, Top 70th Acc: 0.9868, Bottom 30th Acc: 0.6250
Stopping early at Epoch (base 0): 15  Rolling back to Epoch (base 0): 10  Top Validation Acc: 0.9736842105263158
Running train_nn.py with seed 16
CUDA:False
Training samples count:  550
Training on 21 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1372, Training Loss: 0.1372, Initial Validation Loss: 0.1316, Validation Loss: 0.1316,V Acc: 0.4286, Top 70th Acc: 0.5696, Bottom 30th Acc: 0.0909
Fold [1/5] Epoch [10/100] Initial Loss: 0.1372, Training Loss: 0.0259, Initial Validation Loss: 0.1316, Validation Loss: 0.0330,V Acc: 0.8750, Top 70th Acc: 0.9241, Bottom 30th Acc: 0.7576
Stopping early at Epoch (base 0): 17  Rolling back to Epoch (base 0): 12  Top Validation Acc: 0.7088607594936709
Fold [2/5] Epoch [0/100] Initial Loss: 0.1393, Training Loss: 0.1393, Initial Validation Loss: 0.1326, Validation Loss: 0.1326,V Acc: 0.2703, Top 70th Acc: 0.3590, Bottom 30th Acc: 0.0606
Fold [2/5] Epoch [10/100] Initial Loss: 0.1393, Training Loss: 0.0804, Initial Validation Loss: 0.1326, Validation Loss: 0.0848,V Acc: 0.6396, Top 70th Acc: 0.6795, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 18  Rolling back to Epoch (base 0): 13  Top Validation Acc: 0.6923076923076923
Fold [3/5] Epoch [0/100] Initial Loss: 0.1376, Training Loss: 0.1376, Initial Validation Loss: 0.1358, Validation Loss: 0.1358,V Acc: 0.3455, Top 70th Acc: 0.4416, Bottom 30th Acc: 0.1212
Fold [3/5] Epoch [10/100] Initial Loss: 0.1376, Training Loss: 0.0812, Initial Validation Loss: 0.1358, Validation Loss: 0.0796,V Acc: 0.6545, Top 70th Acc: 0.7662, Bottom 30th Acc: 0.3939
Fold [3/5] Epoch [20/100] Initial Loss: 0.1376, Training Loss: 0.0786, Initial Validation Loss: 0.1358, Validation Loss: 0.0771,V Acc: 0.6636, Top 70th Acc: 0.7662, Bottom 30th Acc: 0.4242
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.7792207792207793
Fold [4/5] Epoch [0/100] Initial Loss: 0.1391, Training Loss: 0.1391, Initial Validation Loss: 0.1296, Validation Loss: 0.1296,V Acc: 0.3028, Top 70th Acc: 0.3506, Bottom 30th Acc: 0.1875
Fold [4/5] Epoch [10/100] Initial Loss: 0.1391, Training Loss: 0.0829, Initial Validation Loss: 0.1296, Validation Loss: 0.0752,V Acc: 0.6514, Top 70th Acc: 0.7532, Bottom 30th Acc: 0.4062
Fold [4/5] Epoch [20/100] Initial Loss: 0.1391, Training Loss: 0.0811, Initial Validation Loss: 0.1296, Validation Loss: 0.0725,V Acc: 0.6789, Top 70th Acc: 0.7532, Bottom 30th Acc: 0.5000
Fold [4/5] Epoch [30/100] Initial Loss: 0.1391, Training Loss: 0.0803, Initial Validation Loss: 0.1296, Validation Loss: 0.0717,V Acc: 0.6697, Top 70th Acc: 0.7532, Bottom 30th Acc: 0.4688
Fold [4/5] Epoch [40/100] Initial Loss: 0.1391, Training Loss: 0.0799, Initial Validation Loss: 0.1296, Validation Loss: 0.0718,V Acc: 0.6697, Top 70th Acc: 0.7662, Bottom 30th Acc: 0.4375
Stopping early at Epoch (base 0): 43  Rolling back to Epoch (base 0): 38  Top Validation Acc: 0.7532467532467533
11 3 [array([0.12398291, 0.33891985, 0.14990589, 0.2165847 , 0.17060664],
      dtype=float32)]
Fold [5/5] Epoch [0/100] Initial Loss: 0.1340, Training Loss: 0.1340, Initial Validation Loss: 0.1242, Validation Loss: 0.1242,V Acc: 0.3611, Top 70th Acc: 0.3816, Bottom 30th Acc: 0.3125
Fold [5/5] Epoch [10/100] Initial Loss: 0.1340, Training Loss: 0.0794, Initial Validation Loss: 0.1242, Validation Loss: 0.0793,V Acc: 0.5741, Top 70th Acc: 0.7500, Bottom 30th Acc: 0.1562
Stopping early at Epoch (base 0): 19  Rolling back to Epoch (base 0): 14  Top Validation Acc: 0.7631578947368421
Running train_nn.py with seed 12
CUDA:False
Training samples count:  550
Training on 2 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1378, Training Loss: 0.1378, Initial Validation Loss: 0.1277, Validation Loss: 0.1277,V Acc: 0.4018, Top 70th Acc: 0.5443, Bottom 30th Acc: 0.0606
Fold [1/5] Epoch [10/100] Initial Loss: 0.1378, Training Loss: 0.0815, Initial Validation Loss: 0.1277, Validation Loss: 0.0771,V Acc: 0.6339, Top 70th Acc: 0.7595, Bottom 30th Acc: 0.3333
Fold [1/5] Epoch [20/100] Initial Loss: 0.1378, Training Loss: 0.0803, Initial Validation Loss: 0.1277, Validation Loss: 0.0745,V Acc: 0.6518, Top 70th Acc: 0.7468, Bottom 30th Acc: 0.4242
Stopping early at Epoch (base 0): 20  Rolling back to Epoch (base 0): 15  Top Validation Acc: 0.7468354430379747
Fold [2/5] Epoch [0/100] Initial Loss: 0.1333, Training Loss: 0.1333, Initial Validation Loss: 0.1272, Validation Loss: 0.1272,V Acc: 0.2793, Top 70th Acc: 0.3462, Bottom 30th Acc: 0.1212
Fold [2/5] Epoch [10/100] Initial Loss: 0.1333, Training Loss: 0.0800, Initial Validation Loss: 0.1272, Validation Loss: 0.0820,V Acc: 0.6216, Top 70th Acc: 0.7564, Bottom 30th Acc: 0.3030
Fold [2/5] Epoch [20/100] Initial Loss: 0.1333, Training Loss: 0.0783, Initial Validation Loss: 0.1272, Validation Loss: 0.0816,V Acc: 0.6036, Top 70th Acc: 0.7564, Bottom 30th Acc: 0.2424
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.7564102564102564
Fold [3/5] Epoch [0/100] Initial Loss: 0.1395, Training Loss: 0.1395, Initial Validation Loss: 0.1278, Validation Loss: 0.1278,V Acc: 0.3727, Top 70th Acc: 0.4156, Bottom 30th Acc: 0.2727
Fold [3/5] Epoch [10/100] Initial Loss: 0.1395, Training Loss: 0.0794, Initial Validation Loss: 0.1278, Validation Loss: 0.0823,V Acc: 0.5909, Top 70th Acc: 0.6753, Bottom 30th Acc: 0.3939
Stopping early at Epoch (base 0): 19  Rolling back to Epoch (base 0): 14  Top Validation Acc: 0.7012987012987013
Fold [4/5] Epoch [0/100] Initial Loss: 0.1309, Training Loss: 0.1309, Initial Validation Loss: 0.1182, Validation Loss: 0.1182,V Acc: 0.5596, Top 70th Acc: 0.5844, Bottom 30th Acc: 0.5000
Fold [4/5] Epoch [10/100] Initial Loss: 0.1309, Training Loss: 0.0819, Initial Validation Loss: 0.1182, Validation Loss: 0.0774,V Acc: 0.6422, Top 70th Acc: 0.7143, Bottom 30th Acc: 0.4688
Fold [4/5] Epoch [20/100] Initial Loss: 0.1309, Training Loss: 0.0794, Initial Validation Loss: 0.1182, Validation Loss: 0.0760,V Acc: 0.6514, Top 70th Acc: 0.7273, Bottom 30th Acc: 0.4688
Fold [4/5] Epoch [30/100] Initial Loss: 0.1309, Training Loss: 0.0790, Initial Validation Loss: 0.1182, Validation Loss: 0.0754,V Acc: 0.6422, Top 70th Acc: 0.7143, Bottom 30th Acc: 0.4688
Fold [4/5] Epoch [40/100] Initial Loss: 0.1309, Training Loss: 0.0782, Initial Validation Loss: 0.1182, Validation Loss: 0.0746,V Acc: 0.6330, Top 70th Acc: 0.7143, Bottom 30th Acc: 0.4375
Fold [4/5] Epoch [50/100] Initial Loss: 0.1309, Training Loss: 0.0776, Initial Validation Loss: 0.1182, Validation Loss: 0.0738,V Acc: 0.6330, Top 70th Acc: 0.7532, Bottom 30th Acc: 0.3438
Fold [4/5] Epoch [60/100] Initial Loss: 0.1309, Training Loss: 0.0773, Initial Validation Loss: 0.1182, Validation Loss: 0.0732,V Acc: 0.6330, Top 70th Acc: 0.7403, Bottom 30th Acc: 0.3750
Stopping early at Epoch (base 0): 65  Rolling back to Epoch (base 0): 60  Top Validation Acc: 0.7272727272727273
Fold [5/5] Epoch [0/100] Initial Loss: 0.1379, Training Loss: 0.1379, Initial Validation Loss: 0.1313, Validation Loss: 0.1313,V Acc: 0.3148, Top 70th Acc: 0.3816, Bottom 30th Acc: 0.1562
Fold [5/5] Epoch [10/100] Initial Loss: 0.1379, Training Loss: 0.0817, Initial Validation Loss: 0.1313, Validation Loss: 0.0800,V Acc: 0.6204, Top 70th Acc: 0.7632, Bottom 30th Acc: 0.2812
Fold [5/5] Epoch [20/100] Initial Loss: 0.1379, Training Loss: 0.0786, Initial Validation Loss: 0.1313, Validation Loss: 0.0780,V Acc: 0.6204, Top 70th Acc: 0.7632, Bottom 30th Acc: 0.2812
Fold [5/5] Epoch [30/100] Initial Loss: 0.1379, Training Loss: 0.0781, Initial Validation Loss: 0.1313, Validation Loss: 0.0775,V Acc: 0.6296, Top 70th Acc: 0.7763, Bottom 30th Acc: 0.2812
Fold [5/5] Epoch [40/100] Initial Loss: 0.1379, Training Loss: 0.0779, Initial Validation Loss: 0.1313, Validation Loss: 0.0769,V Acc: 0.6481, Top 70th Acc: 0.7632, Bottom 30th Acc: 0.3750
Stopping early at Epoch (base 0): 43  Rolling back to Epoch (base 0): 38  Top Validation Acc: 0.7631578947368421
12 4 [array([0.1095094 , 0.34512755, 0.15760703, 0.22638673, 0.1613693 ],
      dtype=float32)]
Running train_nn.py with seed 13
CUDA:False
Training samples count:  550
Training on 2 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1382, Training Loss: 0.1382, Initial Validation Loss: 0.1318, Validation Loss: 0.1318,V Acc: 0.2768, Top 70th Acc: 0.3797, Bottom 30th Acc: 0.0303
Fold [1/5] Epoch [10/100] Initial Loss: 0.1382, Training Loss: 0.0796, Initial Validation Loss: 0.1318, Validation Loss: 0.0833,V Acc: 0.6071, Top 70th Acc: 0.7342, Bottom 30th Acc: 0.3030
Fold [1/5] Epoch [20/100] Initial Loss: 0.1382, Training Loss: 0.0775, Initial Validation Loss: 0.1318, Validation Loss: 0.0812,V Acc: 0.6071, Top 70th Acc: 0.7468, Bottom 30th Acc: 0.2727
Stopping early at Epoch (base 0): 28  Rolling back to Epoch (base 0): 23 
Fold [1/5] Epoch [50/100] Initial Loss: 0.1388, Training Loss: 0.0099, Initial Validation Loss: 0.1318, Validation Loss: 0.0288,V Acc: 0.8393, Top 70th Acc: 0.9494, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 51  Rolling back to Epoch (base 0): 46  Top Validation Acc: 0.9367088607594937
Fold [2/5] Epoch [0/100] Initial Loss: 0.1407, Training Loss: 0.1407, Initial Validation Loss: 0.1342, Validation Loss: 0.1342,V Acc: 0.2703, Top 70th Acc: 0.2692, Bottom 30th Acc: 0.2727
Fold [2/5] Epoch [10/100] Initial Loss: 0.1407, Training Loss: 0.0398, Initial Validation Loss: 0.1342, Validation Loss: 0.0417,V Acc: 0.7928, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.5152
Fold [2/5] Epoch [20/100] Initial Loss: 0.1407, Training Loss: 0.0185, Initial Validation Loss: 0.1342, Validation Loss: 0.0251,V Acc: 0.8739, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.6667
Fold [2/5] Epoch [30/100] Initial Loss: 0.1407, Training Loss: 0.0140, Initial Validation Loss: 0.1342, Validation Loss: 0.0232,V Acc: 0.8739, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 30  Rolling back to Epoch (base 0): 25  Top Validation Acc: 0.9487179487179487
Fold [3/5] Epoch [0/100] Initial Loss: 0.1379, Training Loss: 0.1379, Initial Validation Loss: 0.1369, Validation Loss: 0.1369,V Acc: 0.2727, Top 70th Acc: 0.3506, Bottom 30th Acc: 0.0909
Fold [3/5] Epoch [10/100] Initial Loss: 0.1379, Training Loss: 0.0259, Initial Validation Loss: 0.1369, Validation Loss: 0.0288,V Acc: 0.8909, Top 70th Acc: 1.0000, Bottom 30th Acc: 0.6364
Fold [3/5] Epoch [20/100] Initial Loss: 0.1379, Training Loss: 0.0146, Initial Validation Loss: 0.1369, Validation Loss: 0.0261,V Acc: 0.8727, Top 70th Acc: 0.9870, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 21  Rolling back to Epoch (base 0): 16  Top Validation Acc: 0.987012987012987
Fold [4/5] Epoch [0/100] Initial Loss: 0.1394, Training Loss: 0.1394, Initial Validation Loss: 0.1342, Validation Loss: 0.1342,V Acc: 0.2752, Top 70th Acc: 0.2857, Bottom 30th Acc: 0.2500
Fold [4/5] Epoch [10/100] Initial Loss: 0.1394, Training Loss: 0.0432, Initial Validation Loss: 0.1342, Validation Loss: 0.0567,V Acc: 0.7339, Top 70th Acc: 0.8182, Bottom 30th Acc: 0.5312
Fold [4/5] Epoch [20/100] Initial Loss: 0.1394, Training Loss: 0.0158, Initial Validation Loss: 0.1342, Validation Loss: 0.0376,V Acc: 0.8257, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.5938
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.948051948051948
11 3 [array([0.68644   , 0.059236  , 0.03902074, 0.08625431, 0.12904897],
      dtype=float32)]
Fold [5/5] Epoch [0/100] Initial Loss: 0.1383, Training Loss: 0.1383, Initial Validation Loss: 0.1319, Validation Loss: 0.1319,V Acc: 0.3056, Top 70th Acc: 0.3158, Bottom 30th Acc: 0.2812
Fold [5/5] Epoch [10/100] Initial Loss: 0.1383, Training Loss: 0.0270, Initial Validation Loss: 0.1319, Validation Loss: 0.0426,V Acc: 0.8148, Top 70th Acc: 0.8947, Bottom 30th Acc: 0.6250
Fold [5/5] Epoch [20/100] Initial Loss: 0.1383, Training Loss: 0.0144, Initial Validation Loss: 0.1319, Validation Loss: 0.0370,V Acc: 0.8056, Top 70th Acc: 0.9211, Bottom 30th Acc: 0.5312
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.9342105263157895
Running train_nn.py with seed 12
CUDA:False
Training samples count:  550
Training on 40 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1419, Training Loss: 0.1419, Initial Validation Loss: 0.1348, Validation Loss: 0.1348,V Acc: 0.3304, Top 70th Acc: 0.3797, Bottom 30th Acc: 0.2121
Fold [1/5] Epoch [10/100] Initial Loss: 0.1419, Training Loss: 0.0278, Initial Validation Loss: 0.1348, Validation Loss: 0.0354,V Acc: 0.8393, Top 70th Acc: 0.9367, Bottom 30th Acc: 0.6061
Fold [1/5] Epoch [20/100] Initial Loss: 0.1419, Training Loss: 0.0151, Initial Validation Loss: 0.1348, Validation Loss: 0.0278,V Acc: 0.8482, Top 70th Acc: 0.9620, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.9620253164556962
Fold [2/5] Epoch [0/100] Initial Loss: 0.1386, Training Loss: 0.1386, Initial Validation Loss: 0.1349, Validation Loss: 0.1349,V Acc: 0.2973, Top 70th Acc: 0.3205, Bottom 30th Acc: 0.2424
Fold [2/5] Epoch [10/100] Initial Loss: 0.1386, Training Loss: 0.0306, Initial Validation Loss: 0.1349, Validation Loss: 0.0463,V Acc: 0.7658, Top 70th Acc: 0.8974, Bottom 30th Acc: 0.4545
Fold [2/5] Epoch [20/100] Initial Loss: 0.1386, Training Loss: 0.0175, Initial Validation Loss: 0.1349, Validation Loss: 0.0352,V Acc: 0.8288, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.5758
Fold [2/5] Epoch [30/100] Initial Loss: 0.1386, Training Loss: 0.0132, Initial Validation Loss: 0.1349, Validation Loss: 0.0304,V Acc: 0.8288, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.5152
Fold [2/5] Epoch [40/100] Initial Loss: 0.1386, Training Loss: 0.0112, Initial Validation Loss: 0.1349, Validation Loss: 0.0283,V Acc: 0.8468, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.5455
Fold [2/5] Epoch [50/100] Initial Loss: 0.1386, Training Loss: 0.0102, Initial Validation Loss: 0.1349, Validation Loss: 0.0277,V Acc: 0.8378, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.5152
Stopping early at Epoch (base 0): 54  Rolling back to Epoch (base 0): 49  Top Validation Acc: 0.9743589743589743
Fold [3/5] Epoch [0/100] Initial Loss: 0.1404, Training Loss: 0.1404, Initial Validation Loss: 0.1332, Validation Loss: 0.1332,V Acc: 0.2636, Top 70th Acc: 0.3377, Bottom 30th Acc: 0.0909
Fold [3/5] Epoch [10/100] Initial Loss: 0.1404, Training Loss: 0.0377, Initial Validation Loss: 0.1332, Validation Loss: 0.0413,V Acc: 0.8273, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.5455
Fold [3/5] Epoch [20/100] Initial Loss: 0.1404, Training Loss: 0.0159, Initial Validation Loss: 0.1332, Validation Loss: 0.0360,V Acc: 0.8455, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 20  Rolling back to Epoch (base 0): 15  Top Validation Acc: 0.935064935064935
Fold [4/5] Epoch [0/100] Initial Loss: 0.1387, Training Loss: 0.1387, Initial Validation Loss: 0.1342, Validation Loss: 0.1342,V Acc: 0.2661, Top 70th Acc: 0.3117, Bottom 30th Acc: 0.1562
Fold [4/5] Epoch [10/100] Initial Loss: 0.1387, Training Loss: 0.0338, Initial Validation Loss: 0.1342, Validation Loss: 0.0412,V Acc: 0.7890, Top 70th Acc: 0.8831, Bottom 30th Acc: 0.5625
Fold [4/5] Epoch [20/100] Initial Loss: 0.1387, Training Loss: 0.0145, Initial Validation Loss: 0.1342, Validation Loss: 0.0316,V Acc: 0.8440, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.6250
Stopping early at Epoch (base 0): 22  Rolling back to Epoch (base 0): 17  Top Validation Acc: 0.935064935064935
Fold [5/5] Epoch [0/100] Initial Loss: 0.1390, Training Loss: 0.1390, Initial Validation Loss: 0.1343, Validation Loss: 0.1343,V Acc: 0.2500, Top 70th Acc: 0.2895, Bottom 30th Acc: 0.1562
Fold [5/5] Epoch [10/100] Initial Loss: 0.1390, Training Loss: 0.0434, Initial Validation Loss: 0.1343, Validation Loss: 0.0513,V Acc: 0.7685, Top 70th Acc: 0.8684, Bottom 30th Acc: 0.5312
Fold [5/5] Epoch [20/100] Initial Loss: 0.1390, Training Loss: 0.0182, Initial Validation Loss: 0.1343, Validation Loss: 0.0282,V Acc: 0.8796, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.7188
Fold [5/5] Epoch [30/100] Initial Loss: 0.1390, Training Loss: 0.0136, Initial Validation Loss: 0.1343, Validation Loss: 0.0270,V Acc: 0.8889, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.7500
Stopping early at Epoch (base 0): 30  Rolling back to Epoch (base 0): 25  Top Validation Acc: 0.9473684210526315
12 4 [array([0.6696598 , 0.05990179, 0.03114111, 0.06941321, 0.16988415],
      dtype=float32)]
Running train_nn.py with seed 13
CUDA:False
Training samples count:  550
Training on 40 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1387, Training Loss: 0.1387, Initial Validation Loss: 0.1342, Validation Loss: 0.1342,V Acc: 0.3482, Top 70th Acc: 0.3797, Bottom 30th Acc: 0.2727
Fold [1/5] Epoch [10/100] Initial Loss: 0.1387, Training Loss: 0.0342, Initial Validation Loss: 0.1342, Validation Loss: 0.0448,V Acc: 0.8036, Top 70th Acc: 0.9367, Bottom 30th Acc: 0.4848
Fold [1/5] Epoch [20/100] Initial Loss: 0.1387, Training Loss: 0.0136, Initial Validation Loss: 0.1342, Validation Loss: 0.0393,V Acc: 0.7768, Top 70th Acc: 0.9114, Bottom 30th Acc: 0.4545 0.9605263157894737
Running train_nn.py with seed 8
CUDA:False
Training samples count:  550
Training on 162 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1402, Training Loss: 0.1402, Initial Validation Loss: 0.1371, Validation Loss: 0.1371,V Acc: 0.2500, Top 70th Acc: 0.3418, Bottom 30th Acc: 0.0303
Fold [1/5] Epoch [10/100] Initial Loss: 0.1402, Training Loss: 0.0155, Initial Validation Loss: 0.1371, Validation Loss: 0.0373,V Acc: 0.8125, Top 70th Acc: 0.9747, Bottom 30th Acc: 0.4242
Fold [1/5] Epoch [20/100] Initial Loss: 0.1402, Training Loss: 0.0049, Initial Validation Loss: 0.1371, Validation Loss: 0.0355,V Acc: 0.7857, Top 70th Acc: 0.9494, Bottom 30th Acc: 0.3939
Stopping early at Epoch (base 0): 22  Rolling back to Epoch (base 0): 17  Top Validation Acc: 0.9367088607594937
Fold [2/5] Epoch [0/100] Initial Loss: 0.1413, Training Loss: 0.1413, Initial Validation Loss: 0.1345, Validation Loss: 0.1345,V Acc: 0.2523, Top 70th Acc: 0.2949, Bottom 30th Acc: 0.1515
Fold [2/5] Epoch [10/100] Initial Loss: 0.1413, Training Loss: 0.0208, Initial Validation Loss: 0.1345, Validation Loss: 0.0315,V Acc: 0.8468, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.5455
Fold [2/5] Epoch [20/100] Initial Loss: 0.1413, Training Loss: 0.0050, Initial Validation Loss: 0.1345, Validation Loss: 0.0249,V Acc: 0.8919, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.7576
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.9615384615384616
Fold [3/5] Epoch [0/100] Initial Loss: 0.1389, Training Loss: 0.1389, Initial Validation Loss: 0.1383, Validation Loss: 0.1383,V Acc: 0.3636, Top 70th Acc: 0.3766, Bottom 30th Acc: 0.3333
Fold [3/5] Epoch [10/100] Initial Loss: 0.1389, Training Loss: 0.0190, Initial Validation Loss: 0.1383, Validation Loss: 0.0436,V Acc: 0.8273, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.5758
Fold [3/5] Epoch [20/100] Initial Loss: 0.1389, Training Loss: 0.0056, Initial Validation Loss: 0.1383, Validation Loss: 0.0322,V Acc: 0.8545, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6364
Fold [3/5] Epoch [30/100] Initial Loss: 0.1389, Training Loss: 0.0042, Initial Validation Loss: 0.1383, Validation Loss: 0.0305,V Acc: 0.8727, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.6667
Fold [3/5] Epoch [40/100] Initial Loss: 0.1389, Training Loss: 0.0038, Initial Validation Loss: 0.1383, Validation Loss: 0.0295,V Acc: 0.8818, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 42  Rolling back to Epoch (base 0): 37  Top Validation Acc: 0.987012987012987
8 2 [array([0.2073706 , 0.07740896, 0.08275712, 0.32486808, 0.3075952 ],
      dtype=float32)]
Fold [4/5] Epoch [0/100] Initial Loss: 0.1385, Training Loss: 0.1385, Initial Validation Loss: 0.1292, Validation Loss: 0.1292,V Acc: 0.3119, Top 70th Acc: 0.3506, Bottom 30th Acc: 0.2188
Fold [4/5] Epoch [10/100] Initial Loss: 0.1385, Training Loss: 0.0214, Initial Validation Loss: 0.1292, Validation Loss: 0.0486,V Acc: 0.7615, Top 70th Acc: 0.8701, Bottom 30th Acc: 0.5000
Fold [4/5] Epoch [20/100] Initial Loss: 0.1385, Training Loss: 0.0050, Initial Validation Loss: 0.1292, Validation Loss: 0.0368,V Acc: 0.8165, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.5938
Stopping early at Epoch (base 0): 28  Rolling back to Epoch (base 0): 23  Top Validation Acc: 0.8961038961038961
Fold [5/5] Epoch [0/100] Initial Loss: 0.1421, Training Loss: 0.1421, Initial Validation Loss: 0.1278, Validation Loss: 0.1278,V Acc: 0.2593, Top 70th Acc: 0.3421, Bottom 30th Acc: 0.0625
Fold [5/5] Epoch [10/100] Initial Loss: 0.1421, Training Loss: 0.0161, Initial Validation Loss: 0.1278, Validation Loss: 0.0322,V Acc: 0.8426, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.5625
Fold [5/5] Epoch [20/100] Initial Loss: 0.1421, Training Loss: 0.0048, Initial Validation Loss: 0.1278, Validation Loss: 0.0271,V Acc: 0.8333, Top 70th Acc: 0.9737, Bottom 30th Acc: 0.5000
Stopping early at Epoch (base 0): 29  Rolling back to Epoch (base 0): 24  Top Validation Acc: 0.9736842105263158
Running train_nn.py with seed 9
CUDA:False
Training samples count:  550
Training on 162 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1410, Training Loss: 0.1410, Initial Validation Loss: 0.1385, Validation Loss: 0.1385,V Acc: 0.2679, Top 70th Acc: 0.3038, Bottom 30th Acc: 0.1818
Fold [1/5] Epoch [10/100] Initial Loss: 0.1410, Training Loss: 0.0227, Initial Validation Loss: 0.1385, Validation Loss: 0.0418,V Acc: 0.8036, Top 70th Acc: 0.9241, Bottom 30th Acc: 0.5152
Fold [1/5] Epoch [20/100] Initial Loss: 0.1410, Training Loss: 0.0058, Initial Validation Loss: 0.1385, Validation Loss: 0.0354,V Acc: 0.8214, Top 70th Acc: 0.9241, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 29  Rolling back to Epoch (base 0): 24  Top Validation Acc: 0.9367088607594937
Fold [2/5] Epoch [0/100] Initial Loss: 0.1391, Training Loss: 0.1391, Initial Validation Loss: 0.1356, Validation Loss: 0.1356,V Acc: 0.3243, Top 70th Acc: 0.3846, Bottom 30th Acc: 0.1818
Fold [2/5] Epoch [10/100] Initial Loss: 0.1391, Training Loss: 0.0210, Initial Validation Loss: 0.1356, Validation Loss: 0.0370,V Acc: 0.8198, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.5455
Fold [2/5] Epoch [20/100] Initial Loss: 0.1391, Training Loss: 0.0055, Initial Validation Loss: 0.1356, Validation Loss: 0.0320,V Acc: 0.8468, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.5758
Fold [2/5] Epoch [30/100] Initial Loss: 0.1391, Training Loss: 0.0039, Initial Validation Loss: 0.1356, Validation Loss: 0.0312,V Acc: 0.8468, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 33  Rolling back to Epoch (base 0): 28  Top Validation Acc: 0.9487179487179487
Fold [3/5] Epoch [0/100] Initial Loss: 0.1398, Training Loss: 0.1398, Initial Validation Loss: 0.1303, Validation Loss: 0.1303,V Acc: 0.2545, Top 70th Acc: 0.3636, Bottom 30th Acc: 0.0000
Fold [3/5] Epoch [10/100] Initial Loss: 0.1398, Training Loss: 0.0153, Initial Validation Loss: 0.1303, Validation Loss: 0.0260,V Acc: 0.8818, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.6970
Fold [3/5] Epoch [20/100] Initial Loss: 0.1398, Training Loss: 0.0049, Initial Validation Loss: 0.1303, Validation Loss: 0.0216,V Acc: 0.8909, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.7273
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.961038961038961
Fold [4/5] Epoch [0/100] Initial Loss: 0.1391, Training Loss: 0.1391, Initial Validation Loss: 0.1313, Validation Loss: 0.1313,V Acc: 0.3578, Top 70th Acc: 0.4286, Bottom 30th Acc: 0.1875
Fold [4/5] Epoch [10/100] Initial Loss: 0.1391, Training Loss: 0.0179, Initial Validation Loss: 0.1313, Validation Loss: 0.0455,V Acc: 0.7890, Top 70th Acc: 0.8701, Bottom 30th Acc: 0.5938
Fold [4/5] Epoch [20/100] Initial Loss: 0.1391, Training Loss: 0.0052, Initial Validation Loss: 0.1313, Validation Loss: 0.0391,V Acc: 0.8073, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.5625
Fold [4/5] Epoch [30/100] Initial Loss: 0.1391, Training Loss: 0.0039, Initial Validation Loss: 0.1313, Validation Loss: 0.0375,V Acc: 0.8257, Top 70th Acc: 0.8961, Bottom 30th Acc: 0.6562
Fold [4/5] Epoch [40/100] Initial Loss: 0.1391, Training Loss: 0.0036, Initial Validation Loss: 0.1313, Validation Loss: 0.0363,V Acc: 0.8257, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.6250
Stopping early at Epoch (base 0): 41  Rolling back to Epoch (base 0): 36  Top Validation Acc: 0.9090909090909091
9 3 [array([0.29664707, 0.0226243 , 0.0535282 , 0.26166555, 0.36553484],
      dtype=float32)]
Fold [5/5] Epoch [0/100] Initial Loss: 0.1399, Training Loss: 0.1399, Initial Validation Loss: 0.1318, Validation Loss: 0.1318,V Acc: 0.2593, Top 70th Acc: 0.3553, Bottom 30th Acc: 0.0312
Fold [5/5] Epoch [10/100] Initial Loss: 0.1399, Training Loss: 0.0277, Initial Validation Loss: 0.1318, Validation Loss: 0.0428,V Acc: 0.7778, Top 70th Acc: 0.8947, Bottom 30th Acc: 0.5000
Fold [5/5] Epoch [20/100] Initial Loss: 0.1399, Training Loss: 0.0060, Initial Validation Loss: 0.1318, Validation Loss: 0.0307,V Acc: 0.8241, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.5312
Stopping early at Epoch (base 0): 29  Rolling back to Epoch (base 0): 24  Top Validation Acc: 0.9473684210526315
Running train_nn.py with seed 10
CUDA:False
Training samples count: 
Stopping early at Epoch (base 0): 42  Rolling back to Epoch (base 0): 37  Top Validation Acc: 0.987012987012987
Fold [4/5] Epoch [0/100] Initial Loss: 0.1442, Training Loss: 0.1442, Initial Validation Loss: 0.1358, Validation Loss: 0.1358,V Acc: 0.2385, Top 70th Acc: 0.2727, Bottom 30th Acc: 0.1562
Fold [4/5] Epoch [10/100] Initial Loss: 0.1442, Training Loss: 0.0353, Initial Validation Loss: 0.1358, Validation Loss: 0.0459,V Acc: 0.7890, Top 70th Acc: 0.8961, Bottom 30th Acc: 0.5312
Fold [4/5] Epoch [20/100] Initial Loss: 0.1442, Training Loss: 0.0179, Initial Validation Loss: 0.1358, Validation Loss: 0.0373,V Acc: 0.8165, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.5625
Stopping early at Epoch (base 0): 20  Rolling back to Epoch (base 0): 15  Top Validation Acc: 0.922077922077922
11 3 [array([0.7251047 , 0.05564413, 0.04637615, 0.10740446, 0.06547064],
      dtype=float32)]
Fold [5/5] Epoch [0/100] Initial Loss: 0.1389, Training Loss: 0.1389, Initial Validation Loss: 0.1318, Validation Loss: 0.1318,V Acc: 0.2593, Top 70th Acc: 0.3553, Bottom 30th Acc: 0.0312
Fold [5/5] Epoch [10/100] Initial Loss: 0.1389, Training Loss: 0.0338, Initial Validation Loss: 0.1318, Validation Loss: 0.0461,V Acc: 0.8148, Top 70th Acc: 0.8684, Bottom 30th Acc: 0.6875
Fold [5/5] Epoch [20/100] Initial Loss: 0.1389, Training Loss: 0.0213, Initial Validation Loss: 0.1318, Validation Loss: 0.0391,V Acc: 0.8426, Top 70th Acc: 0.9211, Bottom 30th Acc: 0.6562
Stopping early at Epoch (base 0): 27  Rolling back to Epoch (base 0): 22  Top Validation Acc: 0.9078947368421053
Running train_nn.py with seed 12
CUDA:False
Training samples count:  550
Training on 30 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1391, Training Loss: 0.1391, Initial Validation Loss: 0.1317, Validation Loss: 0.1317,V Acc: 0.4107, Top 70th Acc: 0.5063, Bottom 30th Acc: 0.1818
Fold [1/5] Epoch [10/100] Initial Loss: 0.1391, Training Loss: 0.0317, Initial Validation Loss: 0.1317, Validation Loss: 0.0351,V Acc: 0.8214, Top 70th Acc: 0.9494, Bottom 30th Acc: 0.5152
Fold [1/5] Epoch [20/100] Initial Loss: 0.1391, Training Loss: 0.0189, Initial Validation Loss: 0.1317, Validation Loss: 0.0287,V Acc: 0.8482, Top 70th Acc: 0.9620, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.9493670886075949
Fold [2/5] Epoch [0/100] Initial Loss: 0.1420, Training Loss: 0.1420, Initial Validation Loss: 0.1387, Validation Loss: 0.1387,V Acc: 0.2793, Top 70th Acc: 0.2821, Bottom 30th Acc: 0.2727
Fold [2/5] Epoch [10/100] Initial Loss: 0.1420, Training Loss: 0.0428, Initial Validation Loss: 0.1387, Validation Loss: 0.0456,V Acc: 0.7928, Top 70th Acc: 0.8974, Bottom 30th Acc: 0.5455
Fold [2/5] Epoch [20/100] Initial Loss: 0.1420, Training Loss: 0.0228, Initial Validation Loss: 0.1387, Validation Loss: 0.0308,V Acc: 0.8288, Top 70th Acc: 0.9872, Bottom 30th Acc: 0.4545
Fold [2/5] Epoch [30/100] Initial Loss: 0.1420, Training Loss: 0.0176, Initial Validation Loss: 0.1387, Validation Loss: 0.0307,V Acc: 0.8378, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.5152
Stopping early at Epoch (base 0): 32  Rolling back to Epoch (base 0): 27  Top Validation Acc: 0.9871794871794872
Fold [3/5] Epoch [0/100] Initial Loss: 0.1415, Training Loss: 0.1415, Initial Validation Loss: 0.1331, Validation Loss: 0.1331,V Acc: 0.2636, Top 70th Acc: 0.3506, Bottom 30th Acc: 0.0606
Fold [3/5] Epoch [10/100] Initial Loss: 0.1415, Training Loss: 0.0401, Initial Validation Loss: 0.1331, Validation Loss: 0.0478,V Acc: 0.7818, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.4545
Fold [3/5] Epoch [20/100] Initial Loss: 0.1415, Training Loss: 0.0210, Initial Validation Loss: 0.1331, Validation Loss: 0.0415,V Acc: 0.8091, Top 70th Acc: 0.8961, Bottom 30th Acc: 0.6061
Fold [3/5] Epoch [30/100] Initial Loss: 0.1415, Training Loss: 0.0161, Initial Validation Loss: 0.1331, Validation Loss: 0.0415,V Acc: 0.8182, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 30  Rolling back to Epoch (base 0): 25  Top Validation Acc: 0.9090909090909091
Fold [4/5] Epoch [0/100] Initial Loss: 0.1374, Training Loss: 0.1374, Initial Validation Loss: 0.1318, Validation Loss: 0.1318,V Acc: 0.2661, Top 70th Acc: 0.3377, Bottom 30th Acc: 0.0938
Fold [4/5] Epoch [10/100] Initial Loss: 0.1374, Training Loss: 0.0279, Initial Validation Loss: 0.1318, Validation Loss: 0.0357,V Acc: 0.8440, Top 70th Acc: 0.8961, Bottom 30th Acc: 0.7188
Stopping early at Epoch (base 0): 17  Rolling back to Epoch (base 0): 12  Top Validation Acc: 0.922077922077922
Fold [5/5] Epoch [0/100] Initial Loss: 0.1386, Training Loss: 0.1386, Initial Validation Loss: 0.1311, Validation Loss: 0.1311,V Acc: 0.3241, Top 70th Acc: 0.3684, Bottom 30th Acc: 0.2188
Fold [5/5] Epoch [10/100] Initial Loss: 0.1386, Training Loss: 0.0383, Initial Validation Loss: 0.1311, Validation Loss: 0.0452,V Acc: 0.8056, Top 70th Acc: 0.8816, Bottom 30th Acc: 0.6250
Fold [5/5] Epoch [20/100] Initial Loss: 0.1386, Training Loss: 0.0198, Initial Validation Loss: 0.1311, Validation Loss: 0.0322,V Acc: 0.8611, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.6875
Stopping early at Epoch (base 0): 28  Rolling back to Epoch (base 0): 23  Top Validation Acc: 0.9342105263157895
12 4 [array([0.7152572 , 0.05070673, 0.06815217, 0.07097185, 0.09491204],
      dtype=float32)]
Running train_nn.py with seed 13
CUDA:False
Training samples count:  550
Training on 30 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1398, Training Loss: 0.1398, Initial Validation Loss: 0.1343, Validation Loss: 0.1343,V Acc: 0.3304, Top 70th Acc: 0.3418, Bottom 30th Acc: 0.3030
Fold [1/5] Epoch [10/100] Initial Loss: 0.1398, Training Loss: 0.0268, Initial Validation Loss: 0.1343, Validation Loss: 0.0392,V Acc: 0.8482, Top 70th Acc: 0.9367, Bottom 30th Acc: 0.6364
Fold [1/5] Epoch [20/100] Initial Loss: 0.1398, Training Loss: 0.0163, Initial Validation Loss: 0.1343, Validation Loss: 0.0377,V Acc: 0.8125, Top 70th Acc: 0.9114, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.9113924050632911
Fold [2/5] Epoch [0/100] Initial Loss: 0.1376, Training Loss: 0.1376, Initial Validation Loss: 0.1366, Validation Loss: 0.1366,V Acc: 0.3333, Top 70th Acc: 0.3718, Bottom 30th Acc: 0.2424
Fold [2/5] Epoch [10/100] Initial Loss: 0.1376, Training Loss: 0.0354, Initial Validation Loss: 0.1366, Validation Loss: 0.0421,V Acc: 0.7928, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.5152
Fold [2/5] Epoch [20/100] Initial Loss: 0.1376, Training Loss: 0.0194, Initial Validation Loss: 0.1366, Validation Loss: 0.0300,V Acc: 0.8919, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.7273
Fold [2/5] Epoch [30/100] Initial Loss: 0.1376, Training Loss: 0.0163, Initial Validation Loss: 0.1366, Validation Loss: 0.0279,V Acc: 0.8919, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.7273
Stopping early at Epoch (base 0): 30  Rolling back to Epoch (base 0): 25  Top Validation Acc: 0.9615384615384616
Fold [3/5] Epoch [0/100] Initial Loss: 0.1418, Training Loss: 0.1418, Initial Validation Loss: 0.1334, Validation Loss: 0.1334,V Acc: 0.4545, Top 70th Acc: 0.5584, Bottom 30th Acc: 0.2121
Fold [3/5] Epoch [10/100] Initial Loss: 0.1418, Training Loss: 0.0320, Initial Validation Loss: 0.1334, Validation Loss: 0.0355,V Acc: 0.8636, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.7273
Fold [3/5] Epoch [20/100] Initial Loss: 0.1418, Training Loss: 0.0194, Initial Validation Loss: 0.1334, Validation Loss: 0.0306,V Acc: 0.8364, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.935064935064935
Fold [4/5] Epoch [0/100] Initial Loss: 0.1442, Training Loss: 0.1442, Initial Validation Loss: 0.1342, Validation Loss: 0.1342,V Acc: 0.2569, Top 70th Acc: 0.3247, Bottom 30th Acc: 0.0938
Fold [4/5] Epoch [10/100] Initial Loss: 0.1442, Training Loss: 0.0417, Initial Validation Loss: 0.1342, Validation Loss: 0.0413,V Acc: 0.8165, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.5938
Fold [4/5] Epoch [20/100] Initial Loss: 0.1442, Training Loss: 0.0187, Initial Validation Loss: 0.1342, Validation Loss: 0.0296,V Acc: 0.8532, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.5938
Fold [1/5] Epoch [20/100] Initial Loss: 0.1372, Training Loss: 0.0156, Initial Validation Loss: 0.1316, Validation Loss: 0.0238,V Acc: 0.9196, Top 70th Acc: 0.9747, Bottom 30th Acc: 0.7879
Fold [1/5] Epoch [30/100] Initial Loss: 0.1372, Training Loss: 0.0122, Initial Validation Loss: 0.1316, Validation Loss: 0.0271,V Acc: 0.9018, Top 70th Acc: 0.9367, Bottom 30th Acc: 0.8182
Stopping early at Epoch (base 0): 32  Rolling back to Epoch (base 0): 27  Top Validation Acc: 0.9746835443037974
16 0 [array([0.89672256, 0.01329549, 0.02182682, 0.0381396 , 0.03001562],
      dtype=float32)]
Fold [2/5] Epoch [0/100] Initial Loss: 0.1362, Training Loss: 0.1362, Initial Validation Loss: 0.1268, Validation Loss: 0.1268,V Acc: 0.3784, Top 70th Acc: 0.4615, Bottom 30th Acc: 0.1818
Fold [2/5] Epoch [10/100] Initial Loss: 0.1362, Training Loss: 0.0261, Initial Validation Loss: 0.1268, Validation Loss: 0.0223,V Acc: 0.9009, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.7273
Fold [2/5] Epoch [20/100] Initial Loss: 0.1362, Training Loss: 0.0174, Initial Validation Loss: 0.1268, Validation Loss: 0.0183,V Acc: 0.8919, Top 70th Acc: 0.9872, Bottom 30th Acc: 0.6667
Fold [2/5] Epoch [30/100] Initial Loss: 0.1362, Training Loss: 0.0137, Initial Validation Loss: 0.1268, Validation Loss: 0.0180,V Acc: 0.9189, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.7879
Stopping early at Epoch (base 0): 30  Rolling back to Epoch (base 0): 25  Top Validation Acc: 0.9743589743589743
Fold [3/5] Epoch [0/100] Initial Loss: 0.1290, Training Loss: 0.1290, Initial Validation Loss: 0.1124, Validation Loss: 0.1124,V Acc: 0.5182, Top 70th Acc: 0.6494, Bottom 30th Acc: 0.2121
Fold [3/5] Epoch [10/100] Initial Loss: 0.1290, Training Loss: 0.0234, Initial Validation Loss: 0.1124, Validation Loss: 0.0241,V Acc: 0.8545, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.6061
Fold [3/5] Epoch [20/100] Initial Loss: 0.1290, Training Loss: 0.0135, Initial Validation Loss: 0.1124, Validation Loss: 0.0240,V Acc: 0.8545, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.961038961038961
Fold [4/5] Epoch [0/100] Initial Loss: 0.1368, Training Loss: 0.1368, Initial Validation Loss: 0.1179, Validation Loss: 0.1179,V Acc: 0.5505, Top 70th Acc: 0.5714, Bottom 30th Acc: 0.5000
Fold [4/5] Epoch [10/100] Initial Loss: 0.1368, Training Loss: 0.0233, Initial Validation Loss: 0.1179, Validation Loss: 0.0272,V Acc: 0.8716, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.7188
Stopping early at Epoch (base 0): 18  Rolling back to Epoch (base 0): 13  Top Validation Acc: 0.935064935064935
Fold [5/5] Epoch [0/100] Initial Loss: 0.1399, Training Loss: 0.1399, Initial Validation Loss: 0.1280, Validation Loss: 0.1280,V Acc: 0.2870, Top 70th Acc: 0.3421, Bottom 30th Acc: 0.1562
Fold [5/5] Epoch [10/100] Initial Loss: 0.1399, Training Loss: 0.0214, Initial Validation Loss: 0.1280, Validation Loss: 0.0332,V Acc: 0.8333, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.5938
Fold [5/5] Epoch [20/100] Initial Loss: 0.1399, Training Loss: 0.0157, Initial Validation Loss: 0.1280, Validation Loss: 0.0311,V Acc: 0.8333, Top 70th Acc: 0.9737, Bottom 30th Acc: 0.5000
Fold [5/5] Epoch [30/100] Initial Loss: 0.1399, Training Loss: 0.0150, Initial Validation Loss: 0.1280, Validation Loss: 0.0262,V Acc: 0.8519, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.5938
Fold [5/5] Epoch [40/100] Initial Loss: 0.1399, Training Loss: 0.0126, Initial Validation Loss: 0.1280, Validation Loss: 0.0257,V Acc: 0.8519, Top 70th Acc: 0.9868, Bottom 30th Acc: 0.5312
Stopping early at Epoch (base 0): 41  Rolling back to Epoch (base 0): 36  Top Validation Acc: 0.9473684210526315
Running train_nn.py with seed 17
CUDA:False
Training samples count:  550
Training on 21 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1341, Training Loss: 0.1341, Initial Validation Loss: 0.1278, Validation Loss: 0.1278,V Acc: 0.4018, Top 70th Acc: 0.4177, Bottom 30th Acc: 0.3636
Fold [1/5] Epoch [10/100] Initial Loss: 0.1341, Training Loss: 0.0262, Initial Validation Loss: 0.1278, Validation Loss: 0.0277,V Acc: 0.8839, Top 70th Acc: 0.9620, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 17  Rolling back to Epoch (base 0): 12  Top Validation Acc: 0.9620253164556962
Fold [2/5] Epoch [0/100] Initial Loss: 0.1263, Training Loss: 0.1263, Initial Validation Loss: 0.1113, Validation Loss: 0.1113,V Acc: 0.4414, Top 70th Acc: 0.5513, Bottom 30th Acc: 0.1818
Fold [2/5] Epoch [10/100] Initial Loss: 0.1263, Training Loss: 0.0192, Initial Validation Loss: 0.1113, Validation Loss: 0.0374,V Acc: 0.8198, Top 70th Acc: 0.8974, Bottom 30th Acc: 0.6364
Fold [2/5] Epoch [20/100] Initial Loss: 0.1263, Training Loss: 0.0163, Initial Validation Loss: 0.1113, Validation Loss: 0.0324,V Acc: 0.8108, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 22  Rolling back to Epoch (base 0): 17  Top Validation Acc: 0.9230769230769231
Fold [3/5] Epoch [0/100] Initial Loss: 0.1289, Training Loss: 0.1289, Initial Validation Loss: 0.1187, Validation Loss: 0.1187,V Acc: 0.5182, Top 70th Acc: 0.6104, Bottom 30th Acc: 0.3030
Fold [3/5] Epoch [10/100] Initial Loss: 0.1289, Training Loss: 0.0277, Initial Validation Loss: 0.1187, Validation Loss: 0.0232,V Acc: 0.8909, Top 70th Acc: 1.0000, Bottom 30th Acc: 0.6364
Fold [3/5] Epoch [20/100] Initial Loss: 0.1289, Training Loss: 0.0171, Initial Validation Loss: 0.1187, Validation Loss: 0.0187,V Acc: 0.9182, Top 70th Acc: 1.0000, Bottom 30th Acc: 0.7273
Stopping early at Epoch (base 0): 20  Rolling back to Epoch (base 0): 15  Top Validation Acc: 1.0
Fold [4/5] Epoch [0/100] Initial Loss: 0.1316, Training Loss: 0.1316, Initial Validation Loss: 0.1147, Validation Loss: 0.1147,V Acc: 0.4220, Top 70th Acc: 0.5325, Bottom 30th Acc: 0.1562
Fold [4/5] Epoch [10/100] Initial Loss: 0.1316, Training Loss: 0.0218, Initial Validation Loss: 0.1147, Validation Loss: 0.0277,V Acc: 0.8532, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6250
Stopping early at Epoch (base 0): 19  Rolling back to Epoch (base 0): 14  Top Validation Acc: 0.974025974025974
17 3 [array([0.79771566, 0.01465595, 0.02595994, 0.08899893, 0.07266949],
      dtype=float32)]
Fold [5/5] Epoch [0/100] Initial Loss: 0.1326, Training Loss: 0.1326, Initial Validation Loss: 0.1181, Validation Loss: 0.1181,V Acc: 0.4907, Top 70th Acc: 0.5658, Bottom 30th Acc: 0.3125
Fold [5/5] Epoch [10/100] Initial Loss: 0.1326, Training Loss: 0.0223, Initial Validation Loss: 0.1181, Validation Loss: 0.0319,V Acc: 0.8519, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.6250
Fold [5/5] Epoch [20/100] Initial Loss: 0.1326, Training Loss: 0.0129, Initial Validation Loss: 0.1181, Validation Loss: 0.0307,V Acc: 0.8333, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.5312
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.9605263157894737
Running train_nn.py with seed 18
CUDA:False
Training samples count:  550
Training on 21 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1332, Training Loss: 0.1332, Initial Validation Loss: 0.1219, Validation Loss: 0.1219,V Acc: 0.6250, Top 70th Acc: 0.6582, Bottom 30th Acc: 0.5455
Fold [1/5] Epoch [10/100] Initial Loss: 0.1332, Training Loss: 0.0225, Initial Validation Loss: 0.1219, Validation Loss: 0.0361,V Acc: 0.8214, Top 70th Acc: 0.9620, Bottom 30th Acc: 0.4848
Fold [1/5] Epoch [20/100] Initial Loss: 0.1332, Training Loss: 0.0164, Initial Validation Loss: 0.1219, Validation Loss: 0.0241,V Acc: 0.8929, Top 70th Acc: 0.9873, Bottom 30th Acc: 0.6667
Fold [1/5] Epoch [30/100] Initial Loss: 0.1332, Training Loss: 0.0137, Initial Validation Loss: 0.1219, Validation Loss: 0.0251,V Acc: 0.8929, Top 70th Acc: 0.9873, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 33  Rolling back to Epoch (base 0): 28  Top Validation Acc: 0.9873417721518988
18 0 [array([0.7546501 , 0.03819882, 0.02475269, 0.07405413, 0.10834417],
      dtype=float32)]
Fold [2/5] Epoch [0/100] Initial Loss: 0.1378, Training Loss: 0.1378, Initial Validation Loss: 0.1292, Validation Loss: 0.1292,V Acc: 0.4595, Top 70th Acc: 0.5641, Bottom 30th Acc: 0.2121
Fold [2/5] Epoch [10/100] Initial Loss: 0.1378, Training Loss: 0.0245, Initial Validation Loss: 0.1292, Validation Loss: 0.0250,V Acc: 0.8919, Top 70th Acc: 0.9872, Bottom 30th Acc: 0.6667
Fold [3/5] Epoch [20/100] Initial Loss: 0.1369, Training Loss: 0.0245, Initial Validation Loss: 0.1364, Validation Loss: 0.0217,V Acc: 0.9000, Top 70th Acc: 1.0000, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 28  Rolling back to Epoch (base 0): 23  Top Validation Acc: 1.0
Fold [4/5] Epoch [0/100] Initial Loss: 0.1417, Training Loss: 0.1417, Initial Validation Loss: 0.1350, Validation Loss: 0.1350,V Acc: 0.2385, Top 70th Acc: 0.2468, Bottom 30th Acc: 0.2188
Fold [4/5] Epoch [10/100] Initial Loss: 0.1417, Training Loss: 0.0333, Initial Validation Loss: 0.1350, Validation Loss: 0.0408,V Acc: 0.8257, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.5938
Stopping early at Epoch (base 0): 18  Rolling back to Epoch (base 0): 13  Top Validation Acc: 0.9090909090909091
11 3 [array([0.48589614, 0.05538614, 0.05655689, 0.21896052, 0.18320036],
      dtype=float32)]
Fold [5/5] Epoch [0/100] Initial Loss: 0.1426, Training Loss: 0.1426, Initial Validation Loss: 0.1325, Validation Loss: 0.1325,V Acc: 0.2315, Top 70th Acc: 0.2632, Bottom 30th Acc: 0.1562
Fold [5/5] Epoch [10/100] Initial Loss: 0.1426, Training Loss: 0.0443, Initial Validation Loss: 0.1325, Validation Loss: 0.0537,V Acc: 0.7870, Top 70th Acc: 0.8816, Bottom 30th Acc: 0.5625
Fold [5/5] Epoch [20/100] Initial Loss: 0.1426, Training Loss: 0.0283, Initial Validation Loss: 0.1325, Validation Loss: 0.0462,V Acc: 0.7685, Top 70th Acc: 0.9079, Bottom 30th Acc: 0.4375
Fold [5/5] Epoch [30/100] Initial Loss: 0.1426, Training Loss: 0.0224, Initial Validation Loss: 0.1325, Validation Loss: 0.0379,V Acc: 0.8148, Top 70th Acc: 0.9211, Bottom 30th Acc: 0.5625
Stopping early at Epoch (base 0): 35  Rolling back to Epoch (base 0): 30  Top Validation Acc: 0.9210526315789473
Running train_nn.py with seed 12
CUDA:False
Training samples count:  550
Training on 20 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1471, Training Loss: 0.1471, Initial Validation Loss: 0.1360, Validation Loss: 0.1360,V Acc: 0.3125, Top 70th Acc: 0.3544, Bottom 30th Acc: 0.2121
Fold [1/5] Epoch [10/100] Initial Loss: 0.1471, Training Loss: 0.0338, Initial Validation Loss: 0.1360, Validation Loss: 0.0390,V Acc: 0.8125, Top 70th Acc: 0.9114, Bottom 30th Acc: 0.5758
Fold [1/5] Epoch [20/100] Initial Loss: 0.1471, Training Loss: 0.0242, Initial Validation Loss: 0.1360, Validation Loss: 0.0336,V Acc: 0.8304, Top 70th Acc: 0.9114, Bottom 30th Acc: 0.6364
Fold [1/5] Epoch [30/100] Initial Loss: 0.1471, Training Loss: 0.0218, Initial Validation Loss: 0.1360, Validation Loss: 0.0320,V Acc: 0.8214, Top 70th Acc: 0.9367, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 31  Rolling back to Epoch (base 0): 26  Top Validation Acc: 0.9240506329113924
Fold [2/5] Epoch [0/100] Initial Loss: 0.1390, Training Loss: 0.1390, Initial Validation Loss: 0.1329, Validation Loss: 0.1329,V Acc: 0.4054, Top 70th Acc: 0.4615, Bottom 30th Acc: 0.2727
Fold [2/5] Epoch [10/100] Initial Loss: 0.1390, Training Loss: 0.0392, Initial Validation Loss: 0.1329, Validation Loss: 0.0442,V Acc: 0.8018, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.5152
Fold [2/5] Epoch [20/100] Initial Loss: 0.1390, Training Loss: 0.0238, Initial Validation Loss: 0.1329, Validation Loss: 0.0321,V Acc: 0.8288, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.5152
Fold [2/5] Epoch [30/100] Initial Loss: 0.1390, Training Loss: 0.0213, Initial Validation Loss: 0.1329, Validation Loss: 0.0305,V Acc: 0.8378, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 34  Rolling back to Epoch (base 0): 29  Top Validation Acc: 0.9743589743589743
Fold [3/5] Epoch [0/100] Initial Loss: 0.1454, Training Loss: 0.1454, Initial Validation Loss: 0.1349, Validation Loss: 0.1349,V Acc: 0.2545, Top 70th Acc: 0.2468, Bottom 30th Acc: 0.2727
Fold [3/5] Epoch [10/100] Initial Loss: 0.1454, Training Loss: 0.0373, Initial Validation Loss: 0.1349, Validation Loss: 0.0454,V Acc: 0.7545, Top 70th Acc: 0.8961, Bottom 30th Acc: 0.4242
Fold [3/5] Epoch [20/100] Initial Loss: 0.1454, Training Loss: 0.0236, Initial Validation Loss: 0.1349, Validation Loss: 0.0370,V Acc: 0.8091, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.5758
Fold [3/5] Epoch [30/100] Initial Loss: 0.1454, Training Loss: 0.0211, Initial Validation Loss: 0.1349, Validation Loss: 0.0367,V Acc: 0.8000, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 34  Rolling back to Epoch (base 0): 29  Top Validation Acc: 0.922077922077922
Fold [4/5] Epoch [0/100] Initial Loss: 0.1394, Training Loss: 0.1394, Initial Validation Loss: 0.1332, Validation Loss: 0.1332,V Acc: 0.2477, Top 70th Acc: 0.3377, Bottom 30th Acc: 0.0312
Fold [4/5] Epoch [10/100] Initial Loss: 0.1394, Training Loss: 0.0471, Initial Validation Loss: 0.1332, Validation Loss: 0.0540,V Acc: 0.7431, Top 70th Acc: 0.8442, Bottom 30th Acc: 0.5000
Fold [4/5] Epoch [20/100] Initial Loss: 0.1394, Training Loss: 0.0251, Initial Validation Loss: 0.1332, Validation Loss: 0.0368,V Acc: 0.8165, Top 70th Acc: 0.8961, Bottom 30th Acc: 0.6250
Fold [4/5] Epoch [30/100] Initial Loss: 0.1394, Training Loss: 0.0203, Initial Validation Loss: 0.1332, Validation Loss: 0.0368,V Acc: 0.8073, Top 70th Acc: 0.8831, Bottom 30th Acc: 0.6250
Stopping early at Epoch (base 0): 31  Rolling back to Epoch (base 0): 26  Top Validation Acc: 0.8831168831168831
Fold [5/5] Epoch [0/100] Initial Loss: 0.1408, Training Loss: 0.1408, Initial Validation Loss: 0.1329, Validation Loss: 0.1329,V Acc: 0.3056, Top 70th Acc: 0.3553, Bottom 30th Acc: 0.1875
Fold [5/5] Epoch [10/100] Initial Loss: 0.1408, Training Loss: 0.0370, Initial Validation Loss: 0.1329, Validation Loss: 0.0398,V Acc: 0.8241, Top 70th Acc: 0.9211, Bottom 30th Acc: 0.5938
Fold [5/5] Epoch [20/100] Initial Loss: 0.1408, Training Loss: 0.0241, Initial Validation Loss: 0.1329, Validation Loss: 0.0331,V Acc: 0.8241, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.5000
Stopping early at Epoch (base 0): 22  Rolling back to Epoch (base 0): 17  Top Validation Acc: 0.9605263157894737
12 4 [array([0.2900216 , 0.16317871, 0.13609457, 0.19817585, 0.21252929],
      dtype=float32)]
Running train_nn.py with seed 13
CUDA:False
Training samples count:  550
Training on 20 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1417, Training Loss: 0.1417, Initial Validation Loss: 0.1351, Validation Loss: 0.1351,V Acc: 0.3839, Top 70th Acc: 0.4177, Bottom 30th Acc: 0.3030
Fold [1/5] Epoch [10/100] Initial Loss: 0.1417, Training Loss: 0.0475, Initial Validation Loss: 0.1351, Validation Loss: 0.0523,V Acc: 0.7857, Top 70th Acc: 0.8481, Bottom 30th Acc: 0.6364
Fold [1/5] Epoch [20/100] Initial Loss: 0.1417, Training Loss: 0.0239, Initial Validation Loss: 0.1351, Validation Loss: 0.0403,V Acc: 0.8125, Top 70th Acc: 0.9114, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 28  Rolling back to Epoch (base 0): 23  Top Validation Acc: 0.8987341772151899
Fold [2/5] Epoch [0/100] Initial Loss: 0.1405, Training Loss: 0.1405, Initial Validation Loss: 0.1365, Validation Loss: 0.1365,V Acc: 0.3333, Top 70th Acc: 0.3974, Bottom 30th Acc: 0.1818
Fold [2/5] Epoch [10/100] Initial Loss: 0.1405, Training Loss: 0.0444, Initial Validation Loss: 0.1365, Validation Loss: 0.0488,V Acc: 0.7658, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.4242
Fold [2/5] Epoch [20/100] Initial Loss: 0.1405, Training Loss: 0.0261, Initial Validation Loss: 0.1365, Validation Loss: 0.0328,V Acc: 0.8559, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.6667
Fold [2/5] Epoch [30/100] Initial Loss: 0.1405, Training Loss: 0.0237, Initial Validation Loss: 0.1365, Validation Loss: 0.0319,V Acc: 0.8559, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.6364
Fold [2/5] Epoch [40/100] Initial Loss: 0.1405, Training Loss: 0.0223, Initial Validation Loss: 0.1365, Validation Loss: 0.0311,V Acc: 0.8829, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.7273
Stopping early at Epoch (base 0): 43  Rolling back to Epoch (base 0): 38  Top Validation Acc: 0.9358974358974359
Fold [3/5] Epoch [0/100] Initial Loss: 0.1425, Training Loss: 0.1425, Initial Validation Loss: 0.1354, Validation Loss: 0.1354,V Acc: 0.3000, Top 70th Acc: 0.3247, Bottom 30th Acc: 0.2424
Fold [3/5] Epoch [10/100] Initial Loss: 0.1425, Training Loss: 0.0315, Initial Validation Loss: 0.1354, Validation Loss: 0.0391,V Acc: 0.8091, Top 70th Acc: 0.8961, Bottom 30th Acc: 0.6061 Top Validation Acc: 0.7215189873417721
Fold [2/5] Epoch [0/100] Initial Loss: 0.1419, Training Loss: 0.1419, Initial Validation Loss: 0.1358, Validation Loss: 0.1358,V Acc: 0.2973, Top 70th Acc: 0.3718, Bottom 30th Acc: 0.1212
Fold [2/5] Epoch [10/100] Initial Loss: 0.1419, Training Loss: 0.0818, Initial Validation Loss: 0.1358, Validation Loss: 0.0777,V Acc: 0.6937, Top 70th Acc: 0.7692, Bottom 30th Acc: 0.5152
Fold [2/5] Epoch [20/100] Initial Loss: 0.1419, Training Loss: 0.0800, Initial Validation Loss: 0.1358, Validation Loss: 0.0756,V Acc: 0.6847, Top 70th Acc: 0.7692, Bottom 30th Acc: 0.4848
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.7692307692307693
Fold [3/5] Epoch [0/100] Initial Loss: 0.1380, Training Loss: 0.1380, Initial Validation Loss: 0.1299, Validation Loss: 0.1299,V Acc: 0.4000, Top 70th Acc: 0.5584, Bottom 30th Acc: 0.0303
Fold [3/5] Epoch [10/100] Initial Loss: 0.1380, Training Loss: 0.0829, Initial Validation Loss: 0.1299, Validation Loss: 0.0776,V Acc: 0.6455, Top 70th Acc: 0.7662, Bottom 30th Acc: 0.3636
Fold [3/5] Epoch [20/100] Initial Loss: 0.1380, Training Loss: 0.0804, Initial Validation Loss: 0.1299, Validation Loss: 0.0742,V Acc: 0.6455, Top 70th Acc: 0.7662, Bottom 30th Acc: 0.3636
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.7792207792207793
Fold [4/5] Epoch [0/100] Initial Loss: 0.1376, Training Loss: 0.1376, Initial Validation Loss: 0.1259, Validation Loss: 0.1259,V Acc: 0.5046, Top 70th Acc: 0.5844, Bottom 30th Acc: 0.3125
Fold [4/5] Epoch [10/100] Initial Loss: 0.1376, Training Loss: 0.0824, Initial Validation Loss: 0.1259, Validation Loss: 0.0740,V Acc: 0.6514, Top 70th Acc: 0.7403, Bottom 30th Acc: 0.4375
Fold [4/5] Epoch [20/100] Initial Loss: 0.1376, Training Loss: 0.0804, Initial Validation Loss: 0.1259, Validation Loss: 0.0716,V Acc: 0.6514, Top 70th Acc: 0.7792, Bottom 30th Acc: 0.3438
Fold [4/5] Epoch [30/100] Initial Loss: 0.1376, Training Loss: 0.0794, Initial Validation Loss: 0.1259, Validation Loss: 0.0713,V Acc: 0.6422, Top 70th Acc: 0.7662, Bottom 30th Acc: 0.3438
Fold [4/5] Epoch [40/100] Initial Loss: 0.1376, Training Loss: 0.0789, Initial Validation Loss: 0.1259, Validation Loss: 0.0717,V Acc: 0.6330, Top 70th Acc: 0.7662, Bottom 30th Acc: 0.3125
Stopping early at Epoch (base 0): 41  Rolling back to Epoch (base 0): 36  Top Validation Acc: 0.7662337662337663
13 3 [array([0.10654205, 0.3686916 , 0.15272383, 0.23309632, 0.13894624],
      dtype=float32)]
Fold [5/5] Epoch [0/100] Initial Loss: 0.1387, Training Loss: 0.1387, Initial Validation Loss: 0.1266, Validation Loss: 0.1266,V Acc: 0.4352, Top 70th Acc: 0.5263, Bottom 30th Acc: 0.2188
Fold [5/5] Epoch [10/100] Initial Loss: 0.1387, Training Loss: 0.0774, Initial Validation Loss: 0.1266, Validation Loss: 0.0866,V Acc: 0.5648, Top 70th Acc: 0.6711, Bottom 30th Acc: 0.3125
Fold [5/5] Epoch [20/100] Initial Loss: 0.1387, Training Loss: 0.0753, Initial Validation Loss: 0.1266, Validation Loss: 0.0869,V Acc: 0.5463, Top 70th Acc: 0.6579, Bottom 30th Acc: 0.2812
Stopping early at Epoch (base 0): 29  Rolling back to Epoch (base 0): 24  Top Validation Acc: 0.6710526315789473
Running train_nn.py with seed 14
CUDA:False
Training samples count:  550
Training on 2 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1351, Training Loss: 0.1351, Initial Validation Loss: 0.1226, Validation Loss: 0.1226,V Acc: 0.5446, Top 70th Acc: 0.5696, Bottom 30th Acc: 0.4848
Fold [1/5] Epoch [10/100] Initial Loss: 0.1351, Training Loss: 0.0829, Initial Validation Loss: 0.1226, Validation Loss: 0.0736,V Acc: 0.6786, Top 70th Acc: 0.7975, Bottom 30th Acc: 0.3939
Fold [1/5] Epoch [20/100] Initial Loss: 0.1351, Training Loss: 0.0810, Initial Validation Loss: 0.1226, Validation Loss: 0.0717,V Acc: 0.6607, Top 70th Acc: 0.7848, Bottom 30th Acc: 0.3636
Fold [1/5] Epoch [30/100] Initial Loss: 0.1351, Training Loss: 0.0803, Initial Validation Loss: 0.1226, Validation Loss: 0.0694,V Acc: 0.6786, Top 70th Acc: 0.8101, Bottom 30th Acc: 0.3636
Stopping early at Epoch (base 0): 35  Rolling back to Epoch (base 0): 30  Top Validation Acc: 0.8227848101265823
Fold [2/5] Epoch [0/100] Initial Loss: 0.1433, Training Loss: 0.1433, Initial Validation Loss: 0.1262, Validation Loss: 0.1262,V Acc: 0.4505, Top 70th Acc: 0.4872, Bottom 30th Acc: 0.3636
Fold [2/5] Epoch [10/100] Initial Loss: 0.1433, Training Loss: 0.0803, Initial Validation Loss: 0.1262, Validation Loss: 0.0814,V Acc: 0.6036, Top 70th Acc: 0.7436, Bottom 30th Acc: 0.2727
Fold [2/5] Epoch [20/100] Initial Loss: 0.1433, Training Loss: 0.0785, Initial Validation Loss: 0.1262, Validation Loss: 0.0802,V Acc: 0.6216, Top 70th Acc: 0.7436, Bottom 30th Acc: 0.3333
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.7435897435897436
14 1 [array([0.12154461, 0.33428597, 0.14133038, 0.21286376, 0.1899752 ],
      dtype=float32)]
Fold [3/5] Epoch [0/100] Initial Loss: 0.1320, Training Loss: 0.1320, Initial Validation Loss: 0.1260, Validation Loss: 0.1260,V Acc: 0.4364, Top 70th Acc: 0.5195, Bottom 30th Acc: 0.2424
Fold [3/5] Epoch [10/100] Initial Loss: 0.1320, Training Loss: 0.0776, Initial Validation Loss: 0.1260, Validation Loss: 0.0904,V Acc: 0.6091, Top 70th Acc: 0.6753, Bottom 30th Acc: 0.4545
Fold [3/5] Epoch [20/100] Initial Loss: 0.1320, Training Loss: 0.0753, Initial Validation Loss: 0.1260, Validation Loss: 0.0908,V Acc: 0.5909, Top 70th Acc: 0.6623, Bottom 30th Acc: 0.4242
Stopping early at Epoch (base 0): 21  Rolling back to Epoch (base 0): 16  Top Validation Acc: 0.6623376623376623
Fold [4/5] Epoch [0/100] Initial Loss: 0.1398, Training Loss: 0.1398, Initial Validation Loss: 0.1262, Validation Loss: 0.1262,V Acc: 0.3486, Top 70th Acc: 0.3377, Bottom 30th Acc: 0.3750
Fold [4/5] Epoch [10/100] Initial Loss: 0.1398, Training Loss: 0.0794, Initial Validation Loss: 0.1262, Validation Loss: 0.0821,V Acc: 0.5780, Top 70th Acc: 0.6623, Bottom 30th Acc: 0.3750
Fold [4/5] Epoch [20/100] Initial Loss: 0.1398, Training Loss: 0.0768, Initial Validation Loss: 0.1262, Validation Loss: 0.0816,V Acc: 0.5872, Top 70th Acc: 0.6494, Bottom 30th Acc: 0.4375
Stopping early at Epoch (base 0): 22  Rolling back to Epoch (base 0): 17  Top Validation Acc: 0.6493506493506493
Fold [5/5] Epoch [0/100] Initial Loss: 0.1411, Training Loss: 0.1411, Initial Validation Loss: 0.1314, Validation Loss: 0.1314,V Acc: 0.2037, Top 70th Acc: 0.2105, Bottom 30th Acc: 0.1875
Fold [5/5] Epoch [10/100] Initial Loss: 0.1411, Training Loss: 0.0846, Initial Validation Loss: 0.1314, Validation Loss: 0.0724,V Acc: 0.6574, Top 70th Acc: 0.7632, Bottom 30th Acc: 0.4062
Fold [5/5] Epoch [20/100] Initial Loss: 0.1411, Training Loss: 0.0818, Initial Validation Loss: 0.1314, Validation Loss: 0.0686,V Acc: 0.6759, Top 70th Acc: 0.7895, Bottom 30th Acc: 0.4062
Fold [5/5] Epoch [30/100] Initial Loss: 0.1411, Training Loss: 0.0809, Initial Validation Loss: 0.1314, Validation Loss: 0.0679,V Acc: 0.6944, Top 70th Acc: 0.8026, Bottom 30th Acc: 0.4375
Fold [5/5] Epoch [40/100] Initial Loss: 0.1411, Training Loss: 0.0807, Initial Validation Loss: 0.1314, Validation Loss: 0.0669,V Acc: 0.6667, Top 70th Acc: 0.8026, Bottom 30th Acc: 0.3438
Stopping early at Epoch (base 0): 48  Rolling back to Epoch (base 0): 43  Top Validation Acc: 0.8026315789473685
Running train_nn.py with seed 15
CUDA:False
Training samples count:  550
Training on 2 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1356, Training Loss: 0.1356, Initial Validation Loss: 0.1261, Validation Loss: 0.1261,V Acc: 0.4821, Top 70th Acc: 0.5823, Bottom 30th Acc: 0.2424
Fold [1/5] Epoch [10/100] Initial Loss: 0.1356, Training Loss: 0.0785, Initial Validation Loss: 0.1261, Validation Loss: 0.0863,V Acc: 0.5536, Top 70th Acc: 0.6835, Bottom 30th Acc: 0.2424
Fold [1/5] Epoch [20/100] Initial Loss: 0.1356, Training Loss: 0.0765, Initial Validation Loss: 0.1261, Validation Loss: 0.0855,V Acc: 0.5357, Top 70th Acc: 0.6835, Bottom 30th Acc: 0.1818
Fold [1/5] Epoch [30/100] Initial Loss: 0.1356, Training Loss: 0.0761, Initial Validation Loss: 0.1261, Validation Loss: 0.0856,V Acc: 0.5625, Top 70th Acc: 0.6709, Bottom 30th Acc: 0.3030
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.9113924050632911
Fold [2/5] Epoch [0/100] Initial Loss: 0.1437, Training Loss: 0.1437, Initial Validation Loss: 0.1382, Validation Loss: 0.1382,V Acc: 0.2613, Top 70th Acc: 0.2949, Bottom 30th Acc: 0.1818
Fold [2/5] Epoch [10/100] Initial Loss: 0.1437, Training Loss: 0.0327, Initial Validation Loss: 0.1382, Validation Loss: 0.0412,V Acc: 0.8288, Top 70th Acc: 0.8846, Bottom 30th Acc: 0.6970
Fold [2/5] Epoch [20/100] Initial Loss: 0.1437, Training Loss: 0.0179, Initial Validation Loss: 0.1382, Validation Loss: 0.0330,V Acc: 0.8468, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.6364
Fold [2/5] Epoch [30/100] Initial Loss: 0.1437, Training Loss: 0.0134, Initial Validation Loss: 0.1382, Validation Loss: 0.0301,V Acc: 0.8559, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 38  Rolling back to Epoch (base 0): 33  Top Validation Acc: 0.9615384615384616
Fold [3/5] Epoch [0/100] Initial Loss: 0.1393, Training Loss: 0.1393, Initial Validation Loss: 0.1338, Validation Loss: 0.1338,V Acc: 0.2818, Top 70th Acc: 0.3247, Bottom 30th Acc: 0.1818
Fold [3/5] Epoch [10/100] Initial Loss: 0.1393, Training Loss: 0.0275, Initial Validation Loss: 0.1338, Validation Loss: 0.0340,V Acc: 0.8364, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.5758
Fold [3/5] Epoch [20/100] Initial Loss: 0.1393, Training Loss: 0.0156, Initial Validation Loss: 0.1338, Validation Loss: 0.0269,V Acc: 0.8909, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.7273
Stopping early at Epoch (base 0): 21  Rolling back to Epoch (base 0): 16  Top Validation Acc: 0.961038961038961
Fold [4/5] Epoch [0/100] Initial Loss: 0.1396, Training Loss: 0.1396, Initial Validation Loss: 0.1328, Validation Loss: 0.1328,V Acc: 0.3119, Top 70th Acc: 0.3506, Bottom 30th Acc: 0.2188
Fold [4/5] Epoch [10/100] Initial Loss: 0.1396, Training Loss: 0.0326, Initial Validation Loss: 0.1328, Validation Loss: 0.0394,V Acc: 0.7615, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.3750
Fold [4/5] Epoch [20/100] Initial Loss: 0.1396, Training Loss: 0.0172, Initial Validation Loss: 0.1328, Validation Loss: 0.0357,V Acc: 0.7982, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.5000
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.922077922077922
13 3 [array([0.42331102, 0.02128374, 0.19272262, 0.07992693, 0.28275573],
      dtype=float32)]
Fold [5/5] Epoch [0/100] Initial Loss: 0.1404, Training Loss: 0.1404, Initial Validation Loss: 0.1311, Validation Loss: 0.1311,V Acc: 0.2685, Top 70th Acc: 0.3421, Bottom 30th Acc: 0.0938
Fold [5/5] Epoch [10/100] Initial Loss: 0.1404, Training Loss: 0.0424, Initial Validation Loss: 0.1311, Validation Loss: 0.0467,V Acc: 0.7778, Top 70th Acc: 0.8684, Bottom 30th Acc: 0.5625
Fold [5/5] Epoch [20/100] Initial Loss: 0.1404, Training Loss: 0.0160, Initial Validation Loss: 0.1311, Validation Loss: 0.0304,V Acc: 0.8796, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.7188
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.9473684210526315
Running train_nn.py with seed 14
CUDA:False
Training samples count:  550
Training on 40 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1397, Training Loss: 0.1397, Initial Validation Loss: 0.1379, Validation Loss: 0.1379,V Acc: 0.2500, Top 70th Acc: 0.3165, Bottom 30th Acc: 0.0909
Fold [1/5] Epoch [10/100] Initial Loss: 0.1397, Training Loss: 0.0395, Initial Validation Loss: 0.1379, Validation Loss: 0.0437,V Acc: 0.8036, Top 70th Acc: 0.8987, Bottom 30th Acc: 0.5758
Fold [1/5] Epoch [20/100] Initial Loss: 0.1397, Training Loss: 0.0152, Initial Validation Loss: 0.1379, Validation Loss: 0.0294,V Acc: 0.8661, Top 70th Acc: 0.9620, Bottom 30th Acc: 0.6364
Fold [1/5] Epoch [30/100] Initial Loss: 0.1397, Training Loss: 0.0121, Initial Validation Loss: 0.1379, Validation Loss: 0.0273,V Acc: 0.8750, Top 70th Acc: 0.9747, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 35  Rolling back to Epoch (base 0): 30  Top Validation Acc: 0.9620253164556962
Fold [2/5] Epoch [0/100] Initial Loss: 0.1380, Training Loss: 0.1380, Initial Validation Loss: 0.1312, Validation Loss: 0.1312,V Acc: 0.2973, Top 70th Acc: 0.3718, Bottom 30th Acc: 0.1212
Fold [2/5] Epoch [10/100] Initial Loss: 0.1380, Training Loss: 0.0382, Initial Validation Loss: 0.1312, Validation Loss: 0.0484,V Acc: 0.7748, Top 70th Acc: 0.8462, Bottom 30th Acc: 0.6061
Fold [2/5] Epoch [20/100] Initial Loss: 0.1380, Training Loss: 0.0166, Initial Validation Loss: 0.1312, Validation Loss: 0.0347,V Acc: 0.8018, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.5152
Fold [2/5] Epoch [30/100] Initial Loss: 0.1380, Training Loss: 0.0121, Initial Validation Loss: 0.1312, Validation Loss: 0.0328,V Acc: 0.7928, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.4545
Fold [2/5] Epoch [40/100] Initial Loss: 0.1380, Training Loss: 0.0109, Initial Validation Loss: 0.1312, Validation Loss: 0.0314,V Acc: 0.8108, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.5152
Stopping early at Epoch (base 0): 40  Rolling back to Epoch (base 0): 35  Top Validation Acc: 0.9358974358974359
14 1 [array([0.65641624, 0.06958099, 0.08587375, 0.04910061, 0.13902837],
      dtype=float32)]
Fold [3/5] Epoch [0/100] Initial Loss: 0.1405, Training Loss: 0.1405, Initial Validation Loss: 0.1353, Validation Loss: 0.1353,V Acc: 0.2545, Top 70th Acc: 0.3506, Bottom 30th Acc: 0.0303
Fold [3/5] Epoch [10/100] Initial Loss: 0.1405, Training Loss: 0.0283, Initial Validation Loss: 0.1353, Validation Loss: 0.0352,V Acc: 0.9000, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.7879
Fold [3/5] Epoch [20/100] Initial Loss: 0.1405, Training Loss: 0.0144, Initial Validation Loss: 0.1353, Validation Loss: 0.0312,V Acc: 0.8455, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 21  Rolling back to Epoch (base 0): 16  Top Validation Acc: 0.961038961038961
Fold [4/5] Epoch [0/100] Initial Loss: 0.1392, Training Loss: 0.1392, Initial Validation Loss: 0.1263, Validation Loss: 0.1263,V Acc: 0.3853, Top 70th Acc: 0.4416, Bottom 30th Acc: 0.2500
Fold [4/5] Epoch [10/100] Initial Loss: 0.1392, Training Loss: 0.0344, Initial Validation Loss: 0.1263, Validation Loss: 0.0450,V Acc: 0.7706, Top 70th Acc: 0.8442, Bottom 30th Acc: 0.5938
Fold [4/5] Epoch [20/100] Initial Loss: 0.1392, Training Loss: 0.0140, Initial Validation Loss: 0.1263, Validation Loss: 0.0325,V Acc: 0.8165, Top 70th Acc: 0.8961, Bottom 30th Acc: 0.6250
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.8961038961038961
Fold [5/5] Epoch [0/100] Initial Loss: 0.1418, Training Loss: 0.1418, Initial Validation Loss: 0.1340, Validation Loss: 0.1340,V Acc: 0.2500, Top 70th Acc: 0.2500, Bottom 30th Acc: 0.2500
Fold [5/5] Epoch [10/100] Initial Loss: 0.1418, Training Loss: 0.0336, Initial Validation Loss: 0.1340, Validation Loss: 0.0332,V Acc: 0.8519, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.5938
Fold [5/5] Epoch [20/100] Initial Loss: 0.1418, Training Loss: 0.0154, Initial Validation Loss: 0.1340, Validation Loss: 0.0245,V Acc: 0.8611, Top 70th Acc: 0.9868, Bottom 30th Acc: 0.5625
Stopping early at Epoch (base 0): 22  Rolling back to Epoch (base 0): 17  Top Validation Acc: 0.9868421052631579
Running train_nn.py with seed 15
CUDA:False
Training samples count:  550
Training on 40 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1378, Training Loss: 0.1378, Initial Validation Loss: 0.1325, Validation Loss: 0.1325,V Acc: 0.2589, Top 70th Acc: 0.3544, Bottom 30th Acc: 0.0303
Fold [1/5] Epoch [10/100] Initial Loss: 0.1378, Training Loss: 0.0391, Initial Validation Loss: 0.1325, Validation Loss: 0.0541,V Acc: 0.7232, Top 70th Acc: 0.8861, Bottom 30th Acc: 0.3333
Fold [1/5] Epoch [20/100] Initial Loss: 0.1378, Training Loss: 0.0146, Initial Validation Loss: 0.1325, Validation Loss: 0.0405,V Acc: 0.8036, Top 70th Acc: 0.9114, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 27  Rolling back to Epoch (base 0): 22  Top Validation Acc: 0.8987341772151899
Fold [2/5] Epoch [0/100] Initial Loss: 0.1419, Training Loss: 0.1419, Initial Validation Loss: 0.1359, Validation Loss: 0.1359,V Acc: 0.2613, Top 70th Acc: 0.3077, Bottom 30th Acc: 0.1515 550
Training on 162 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1408, Training Loss: 0.1408, Initial Validation Loss: 0.1312, Validation Loss: 0.1312,V Acc: 0.3214, Top 70th Acc: 0.4051, Bottom 30th Acc: 0.1212
Fold [1/5] Epoch [10/100] Initial Loss: 0.1408, Training Loss: 0.0155, Initial Validation Loss: 0.1312, Validation Loss: 0.0310,V Acc: 0.8125, Top 70th Acc: 0.9367, Bottom 30th Acc: 0.5152
Fold [1/5] Epoch [20/100] Initial Loss: 0.1408, Training Loss: 0.0048, Initial Validation Loss: 0.1312, Validation Loss: 0.0237,V Acc: 0.8393, Top 70th Acc: 0.9367, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.9493670886075949
Fold [2/5] Epoch [0/100] Initial Loss: 0.1387, Training Loss: 0.1387, Initial Validation Loss: 0.1374, Validation Loss: 0.1374,V Acc: 0.2793, Top 70th Acc: 0.2821, Bottom 30th Acc: 0.2727
Fold [2/5] Epoch [10/100] Initial Loss: 0.1387, Training Loss: 0.0169, Initial Validation Loss: 0.1374, Validation Loss: 0.0375,V Acc: 0.8108, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.5152
Fold [2/5] Epoch [20/100] Initial Loss: 0.1387, Training Loss: 0.0048, Initial Validation Loss: 0.1374, Validation Loss: 0.0320,V Acc: 0.8108, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.4848
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.9487179487179487
Fold [3/5] Epoch [0/100] Initial Loss: 0.1413, Training Loss: 0.1413, Initial Validation Loss: 0.1314, Validation Loss: 0.1314,V Acc: 0.3818, Top 70th Acc: 0.3896, Bottom 30th Acc: 0.3636
Fold [3/5] Epoch [10/100] Initial Loss: 0.1413, Training Loss: 0.0170, Initial Validation Loss: 0.1314, Validation Loss: 0.0460,V Acc: 0.7455, Top 70th Acc: 0.8831, Bottom 30th Acc: 0.4242
Fold [3/5] Epoch [20/100] Initial Loss: 0.1413, Training Loss: 0.0057, Initial Validation Loss: 0.1314, Validation Loss: 0.0387,V Acc: 0.7818, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.4848
Fold [3/5] Epoch [30/100] Initial Loss: 0.1413, Training Loss: 0.0046, Initial Validation Loss: 0.1314, Validation Loss: 0.0383,V Acc: 0.8091, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 30  Rolling back to Epoch (base 0): 25  Top Validation Acc: 0.9090909090909091
10 2 [array([0.04811465, 0.01590647, 0.06415775, 0.5226963 , 0.34912488],
      dtype=float32)]
Fold [4/5] Epoch [0/100] Initial Loss: 0.1381, Training Loss: 0.1381, Initial Validation Loss: 0.1340, Validation Loss: 0.1340,V Acc: 0.2477, Top 70th Acc: 0.3377, Bottom 30th Acc: 0.0312
Fold [4/5] Epoch [10/100] Initial Loss: 0.1381, Training Loss: 0.0203, Initial Validation Loss: 0.1340, Validation Loss: 0.0435,V Acc: 0.8349, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.6562
Stopping early at Epoch (base 0): 19  Rolling back to Epoch (base 0): 14  Top Validation Acc: 0.948051948051948
Fold [5/5] Epoch [0/100] Initial Loss: 0.1379, Training Loss: 0.1379, Initial Validation Loss: 0.1377, Validation Loss: 0.1377,V Acc: 0.2500, Top 70th Acc: 0.3421, Bottom 30th Acc: 0.0312
Fold [5/5] Epoch [10/100] Initial Loss: 0.1379, Training Loss: 0.0191, Initial Validation Loss: 0.1377, Validation Loss: 0.0374,V Acc: 0.8704, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.6875
Fold [5/5] Epoch [20/100] Initial Loss: 0.1379, Training Loss: 0.0056, Initial Validation Loss: 0.1377, Validation Loss: 0.0285,V Acc: 0.8889, Top 70th Acc: 0.9737, Bottom 30th Acc: 0.6875
Fold [5/5] Epoch [30/100] Initial Loss: 0.1379, Training Loss: 0.0041, Initial Validation Loss: 0.1377, Validation Loss: 0.0279,V Acc: 0.9074, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.7812
Stopping early at Epoch (base 0): 37  Rolling back to Epoch (base 0): 32  Top Validation Acc: 0.9736842105263158
Running train_nn.py with seed 11
CUDA:False
Training samples count:  550
Training on 162 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1400, Training Loss: 0.1400, Initial Validation Loss: 0.1326, Validation Loss: 0.1326,V Acc: 0.3125, Top 70th Acc: 0.4177, Bottom 30th Acc: 0.0606
Fold [1/5] Epoch [10/100] Initial Loss: 0.1400, Training Loss: 0.0169, Initial Validation Loss: 0.1326, Validation Loss: 0.0285,V Acc: 0.8482, Top 70th Acc: 0.9494, Bottom 30th Acc: 0.6061
Fold [1/5] Epoch [20/100] Initial Loss: 0.1400, Training Loss: 0.0046, Initial Validation Loss: 0.1326, Validation Loss: 0.0237,V Acc: 0.8661, Top 70th Acc: 0.9494, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 21  Rolling back to Epoch (base 0): 16  Top Validation Acc: 0.9493670886075949
Fold [2/5] Epoch [0/100] Initial Loss: 0.1422, Training Loss: 0.1422, Initial Validation Loss: 0.1352, Validation Loss: 0.1352,V Acc: 0.2432, Top 70th Acc: 0.2564, Bottom 30th Acc: 0.2121
Fold [2/5] Epoch [10/100] Initial Loss: 0.1422, Training Loss: 0.0216, Initial Validation Loss: 0.1352, Validation Loss: 0.0372,V Acc: 0.8018, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.5152
Fold [2/5] Epoch [20/100] Initial Loss: 0.1422, Training Loss: 0.0053, Initial Validation Loss: 0.1352, Validation Loss: 0.0272,V Acc: 0.8559, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 27  Rolling back to Epoch (base 0): 22  Top Validation Acc: 0.9615384615384616
Fold [3/5] Epoch [0/100] Initial Loss: 0.1378, Training Loss: 0.1378, Initial Validation Loss: 0.1377, Validation Loss: 0.1377,V Acc: 0.3636, Top 70th Acc: 0.3896, Bottom 30th Acc: 0.3030
Fold [3/5] Epoch [10/100] Initial Loss: 0.1378, Training Loss: 0.0134, Initial Validation Loss: 0.1377, Validation Loss: 0.0306,V Acc: 0.8727, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.6364
Fold [3/5] Epoch [20/100] Initial Loss: 0.1378, Training Loss: 0.0051, Initial Validation Loss: 0.1377, Validation Loss: 0.0267,V Acc: 0.8455, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.5455
Fold [3/5] Epoch [30/100] Initial Loss: 0.1378, Training Loss: 0.0042, Initial Validation Loss: 0.1377, Validation Loss: 0.0259,V Acc: 0.8727, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.6364
Fold [3/5] Epoch [40/100] Initial Loss: 0.1378, Training Loss: 0.0039, Initial Validation Loss: 0.1377, Validation Loss: 0.0256,V Acc: 0.8636, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 47  Rolling back to Epoch (base 0): 42  Top Validation Acc: 0.974025974025974
Fold [4/5] Epoch [0/100] Initial Loss: 0.1427, Training Loss: 0.1427, Initial Validation Loss: 0.1340, Validation Loss: 0.1340,V Acc: 0.2569, Top 70th Acc: 0.3377, Bottom 30th Acc: 0.0625
Fold [4/5] Epoch [10/100] Initial Loss: 0.1427, Training Loss: 0.0210, Initial Validation Loss: 0.1340, Validation Loss: 0.0425,V Acc: 0.7890, Top 70th Acc: 0.8961, Bottom 30th Acc: 0.5312
Fold [4/5] Epoch [20/100] Initial Loss: 0.1427, Training Loss: 0.0044, Initial Validation Loss: 0.1340, Validation Loss: 0.0359,V Acc: 0.8257, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.5312
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.935064935064935
11 3 [array([0.29338187, 0.08266289, 0.06686931, 0.36957243, 0.18751349],
      dtype=float32)]
Fold [5/5] Epoch [0/100] Initial Loss: 0.1407, Training Loss: 0.1407, Initial Validation Loss: 0.1296, Validation Loss: 0.1296,V Acc: 0.4537, Top 70th Acc: 0.5395, Bottom 30th Acc: 0.2500
Fold [5/5] Epoch [10/100] Initial Loss: 0.1407, Training Loss: 0.0117, Initial Validation Loss: 0.1296, Validation Loss: 0.0381,V Acc: 0.8056, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.5000
Fold [5/5] Epoch [20/100] Initial Loss: 0.1407, Training Loss: 0.0046, Initial Validation Loss: 0.1296, Validation Loss: 0.0336,V Acc: 0.8333, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.5312
Stopping early at Epoch (base 0): 28  Rolling back to Epoch (base 0): 23  Top Validation Acc: 0.9473684210526315
Running train_nn.py with seed 12
CUDA:False
Training samples count:  550
Training on 162 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1396, Training Loss: 0.1396, Initial Validation Loss: 0.1346, Validation Loss: 0.1346,V Acc: 0.2500, Top 70th Acc: 0.3544, Bottom 30th Acc: 0.0000
Fold [1/5] Epoch [10/100] Initial Loss: 0.1396, Training Loss: 0.0224, Initial Validation Loss: 0.1346, Validation Loss: 0.0372,V Acc: 0.7857, Top 70th Acc: 0.9620, Bottom 30th Acc: 0.3636
Fold [1/5] Epoch [20/100] Initial Loss: 0.1396, Training Loss: 0.0052, Initial Validation Loss: 0.1346, Validation Loss: 0.0319,V Acc: 0.8304, Top 70th Acc: 0.9494, Bottom 30th Acc: 0.5455
Fold [4/5] Epoch [30/100] Initial Loss: 0.1442, Training Loss: 0.0162, Initial Validation Loss: 0.1342, Validation Loss: 0.0290,V Acc: 0.8349, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.5625
Stopping early at Epoch (base 0): 32  Rolling back to Epoch (base 0): 27  Top Validation Acc: 0.961038961038961
13 3 [array([0.6487943 , 0.08042517, 0.06600987, 0.10180659, 0.10296407],
      dtype=float32)]
Fold [5/5] Epoch [0/100] Initial Loss: 0.1380, Training Loss: 0.1380, Initial Validation Loss: 0.1300, Validation Loss: 0.1300,V Acc: 0.3796, Top 70th Acc: 0.4737, Bottom 30th Acc: 0.1562
Fold [5/5] Epoch [10/100] Initial Loss: 0.1380, Training Loss: 0.0367, Initial Validation Loss: 0.1300, Validation Loss: 0.0372,V Acc: 0.8148, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.5000
Fold [5/5] Epoch [20/100] Initial Loss: 0.1380, Training Loss: 0.0184, Initial Validation Loss: 0.1300, Validation Loss: 0.0290,V Acc: 0.8519, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.5938
Stopping early at Epoch (base 0): 22  Rolling back to Epoch (base 0): 17  Top Validation Acc: 0.9473684210526315
Running train_nn.py with seed 14
CUDA:False
Training samples count:  550
Training on 30 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1385, Training Loss: 0.1385, Initial Validation Loss: 0.1371, Validation Loss: 0.1371,V Acc: 0.2768, Top 70th Acc: 0.2911, Bottom 30th Acc: 0.2424
Fold [1/5] Epoch [10/100] Initial Loss: 0.1385, Training Loss: 0.0446, Initial Validation Loss: 0.1371, Validation Loss: 0.0534,V Acc: 0.7321, Top 70th Acc: 0.8861, Bottom 30th Acc: 0.3636
Fold [1/5] Epoch [20/100] Initial Loss: 0.1385, Training Loss: 0.0214, Initial Validation Loss: 0.1371, Validation Loss: 0.0367,V Acc: 0.8125, Top 70th Acc: 0.9114, Bottom 30th Acc: 0.5758
Fold [1/5] Epoch [30/100] Initial Loss: 0.1385, Training Loss: 0.0173, Initial Validation Loss: 0.1371, Validation Loss: 0.0327,V Acc: 0.8393, Top 70th Acc: 0.9241, Bottom 30th Acc: 0.6364
Fold [1/5] Epoch [40/100] Initial Loss: 0.1385, Training Loss: 0.0155, Initial Validation Loss: 0.1371, Validation Loss: 0.0329,V Acc: 0.8571, Top 70th Acc: 0.9494, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 43  Rolling back to Epoch (base 0): 38  Top Validation Acc: 0.9240506329113924
Fold [2/5] Epoch [0/100] Initial Loss: 0.1394, Training Loss: 0.1394, Initial Validation Loss: 0.1338, Validation Loss: 0.1338,V Acc: 0.3333, Top 70th Acc: 0.3462, Bottom 30th Acc: 0.3030
Fold [2/5] Epoch [10/100] Initial Loss: 0.1394, Training Loss: 0.0276, Initial Validation Loss: 0.1338, Validation Loss: 0.0353,V Acc: 0.8018, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.5152
Fold [2/5] Epoch [20/100] Initial Loss: 0.1394, Training Loss: 0.0175, Initial Validation Loss: 0.1338, Validation Loss: 0.0318,V Acc: 0.8378, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.9230769230769231
14 1 [array([0.7258107 , 0.05521845, 0.04758721, 0.09657791, 0.0748057 ],
      dtype=float32)]
Fold [3/5] Epoch [0/100] Initial Loss: 0.1367, Training Loss: 0.1367, Initial Validation Loss: 0.1354, Validation Loss: 0.1354,V Acc: 0.3182, Top 70th Acc: 0.4026, Bottom 30th Acc: 0.1212
Fold [3/5] Epoch [10/100] Initial Loss: 0.1367, Training Loss: 0.0379, Initial Validation Loss: 0.1354, Validation Loss: 0.0464,V Acc: 0.8091, Top 70th Acc: 0.8961, Bottom 30th Acc: 0.6061
Fold [3/5] Epoch [20/100] Initial Loss: 0.1367, Training Loss: 0.0193, Initial Validation Loss: 0.1354, Validation Loss: 0.0341,V Acc: 0.8364, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 22  Rolling back to Epoch (base 0): 17  Top Validation Acc: 0.948051948051948
Fold [4/5] Epoch [0/100] Initial Loss: 0.1436, Training Loss: 0.1436, Initial Validation Loss: 0.1299, Validation Loss: 0.1299,V Acc: 0.3211, Top 70th Acc: 0.3506, Bottom 30th Acc: 0.2500
Fold [4/5] Epoch [10/100] Initial Loss: 0.1436, Training Loss: 0.0406, Initial Validation Loss: 0.1299, Validation Loss: 0.0466,V Acc: 0.7615, Top 70th Acc: 0.8701, Bottom 30th Acc: 0.5000
Fold [4/5] Epoch [20/100] Initial Loss: 0.1436, Training Loss: 0.0217, Initial Validation Loss: 0.1299, Validation Loss: 0.0353,V Acc: 0.7890, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.4688
Fold [4/5] Epoch [30/100] Initial Loss: 0.1436, Training Loss: 0.0172, Initial Validation Loss: 0.1299, Validation Loss: 0.0346,V Acc: 0.7890, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.4688
Stopping early at Epoch (base 0): 34  Rolling back to Epoch (base 0): 29  Top Validation Acc: 0.8961038961038961
Fold [5/5] Epoch [0/100] Initial Loss: 0.1390, Training Loss: 0.1390, Initial Validation Loss: 0.1318, Validation Loss: 0.1318,V Acc: 0.2778, Top 70th Acc: 0.3421, Bottom 30th Acc: 0.1250
Fold [5/5] Epoch [10/100] Initial Loss: 0.1390, Training Loss: 0.0315, Initial Validation Loss: 0.1318, Validation Loss: 0.0325,V Acc: 0.8611, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.6875
Fold [5/5] Epoch [20/100] Initial Loss: 0.1390, Training Loss: 0.0181, Initial Validation Loss: 0.1318, Validation Loss: 0.0287,V Acc: 0.8333, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.5938
Stopping early at Epoch (base 0): 20  Rolling back to Epoch (base 0): 15  Top Validation Acc: 0.9342105263157895
Running train_nn.py with seed 15
CUDA:False
Training samples count:  550
Training on 30 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1426, Training Loss: 0.1426, Initial Validation Loss: 0.1350, Validation Loss: 0.1350,V Acc: 0.2768, Top 70th Acc: 0.2911, Bottom 30th Acc: 0.2424
Fold [1/5] Epoch [10/100] Initial Loss: 0.1426, Training Loss: 0.0430, Initial Validation Loss: 0.1350, Validation Loss: 0.0520,V Acc: 0.7500, Top 70th Acc: 0.8608, Bottom 30th Acc: 0.4848
Fold [1/5] Epoch [20/100] Initial Loss: 0.1426, Training Loss: 0.0171, Initial Validation Loss: 0.1350, Validation Loss: 0.0404,V Acc: 0.7857, Top 70th Acc: 0.8734, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 22  Rolling back to Epoch (base 0): 17  Top Validation Acc: 0.8860759493670886
Fold [2/5] Epoch [0/100] Initial Loss: 0.1404, Training Loss: 0.1404, Initial Validation Loss: 0.1365, Validation Loss: 0.1365,V Acc: 0.2162, Top 70th Acc: 0.2692, Bottom 30th Acc: 0.0909
Fold [2/5] Epoch [10/100] Initial Loss: 0.1404, Training Loss: 0.0442, Initial Validation Loss: 0.1365, Validation Loss: 0.0490,V Acc: 0.7477, Top 70th Acc: 0.8974, Bottom 30th Acc: 0.3939
Fold [2/5] Epoch [20/100] Initial Loss: 0.1404, Training Loss: 0.0199, Initial Validation Loss: 0.1365, Validation Loss: 0.0357,V Acc: 0.8108, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.5152
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.9487179487179487
15 1 [array([0.35587743, 0.07395816, 0.04668177, 0.15156384, 0.37191883],
      dtype=float32)]
Fold [3/5] Epoch [0/100] Initial Loss: 0.1421, Training Loss: 0.1421, Initial Validation Loss: 0.1366, Validation Loss: 0.1366,V Acc: 0.3091, Top 70th Acc: 0.3117, Bottom 30th Acc: 0.3030
Fold [3/5] Epoch [10/100] Initial Loss: 0.1421, Training Loss: 0.0412, Initial Validation Loss: 0.1366, Validation Loss: 0.0370,V Acc: 0.8545, Top 70th Acc: 0.8961, Bottom 30th Acc: 0.7576
Fold [3/5] Epoch [20/100] Initial Loss: 0.1421, Training Loss: 0.0194, Initial Validation Loss: 0.1366, Validation Loss: 0.0264,V Acc: 0.8727, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6970
Fold [3/5] Epoch [30/100] Initial Loss: 0.1421, Training Loss: 0.0167, Initial Validation Loss: 0.1366, Validation Loss: 0.0267,V Acc: 0.8636, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 31  Rolling back to Epoch (base 0): 26  Top Validation Acc: 0.935064935064935
Fold [4/5] Epoch [0/100] Initial Loss: 0.1387, Training Loss: 0.1387, Initial Validation Loss: 0.1338, Validation Loss: 0.1338,V Acc: 0.2661, Top 70th Acc: 0.3117, Bottom 30th Acc: 0.1562
Fold [4/5] Epoch [10/100] Initial Loss: 0.1387, Training Loss: 0.0328, Initial Validation Loss: 0.1338, Validation Loss: 0.0276,V Acc: 0.8899, Top 70th Acc: 1.0000, Bottom 30th Acc: 0.6250
Fold [4/5] Epoch [20/100] Initial Loss: 0.1387, Training Loss: 0.0196, Initial Validation Loss: 0.1338, Validation Loss: 0.0200,V Acc: 0.8991, Top 70th Acc: 1.0000, Bottom 30th Acc: 0.6562/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)

Stopping early at Epoch (base 0): 19  Rolling back to Epoch (base 0): 14  Top Validation Acc: 0.8831168831168831
Fold [4/5] Epoch [0/100] Initial Loss: 0.1400, Training Loss: 0.1400, Initial Validation Loss: 0.1294, Validation Loss: 0.1294,V Acc: 0.3578, Top 70th Acc: 0.3377, Bottom 30th Acc: 0.4062
Fold [4/5] Epoch [10/100] Initial Loss: 0.1400, Training Loss: 0.0459, Initial Validation Loss: 0.1294, Validation Loss: 0.0418,V Acc: 0.8073, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.5000
Fold [4/5] Epoch [20/100] Initial Loss: 0.1400, Training Loss: 0.0265, Initial Validation Loss: 0.1294, Validation Loss: 0.0279,V Acc: 0.8440, Top 70th Acc: 0.9870, Bottom 30th Acc: 0.5000
Fold [4/5] Epoch [30/100] Initial Loss: 0.1400, Training Loss: 0.0241, Initial Validation Loss: 0.1294, Validation Loss: 0.0265,V Acc: 0.8532, Top 70th Acc: 0.9870, Bottom 30th Acc: 0.5312
Stopping early at Epoch (base 0): 36  Rolling back to Epoch (base 0): 31  Top Validation Acc: 0.987012987012987
13 3 [array([0.44408765, 0.15880272, 0.07540967, 0.23833875, 0.0833612 ],
      dtype=float32)]
Fold [5/5] Epoch [0/100] Initial Loss: 0.1383, Training Loss: 0.1383, Initial Validation Loss: 0.1287, Validation Loss: 0.1287,V Acc: 0.2685, Top 70th Acc: 0.3289, Bottom 30th Acc: 0.1250
Fold [5/5] Epoch [10/100] Initial Loss: 0.1383, Training Loss: 0.0313, Initial Validation Loss: 0.1287, Validation Loss: 0.0400,V Acc: 0.8148, Top 70th Acc: 0.8553, Bottom 30th Acc: 0.7188
Stopping early at Epoch (base 0): 17  Rolling back to Epoch (base 0): 12  Top Validation Acc: 0.8552631578947368
Running train_nn.py with seed 14
CUDA:False
Training samples count:  550
Training on 20 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1379, Training Loss: 0.1379, Initial Validation Loss: 0.1309, Validation Loss: 0.1309,V Acc: 0.3929, Top 70th Acc: 0.4684, Bottom 30th Acc: 0.2121
Fold [1/5] Epoch [10/100] Initial Loss: 0.1379, Training Loss: 0.0410, Initial Validation Loss: 0.1309, Validation Loss: 0.0406,V Acc: 0.7768, Top 70th Acc: 0.9367, Bottom 30th Acc: 0.3939
Fold [1/5] Epoch [20/100] Initial Loss: 0.1379, Training Loss: 0.0240, Initial Validation Loss: 0.1309, Validation Loss: 0.0316,V Acc: 0.8571, Top 70th Acc: 0.9494, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 20  Rolling back to Epoch (base 0): 15  Top Validation Acc: 0.9493670886075949
Fold [2/5] Epoch [0/100] Initial Loss: 0.1417, Training Loss: 0.1417, Initial Validation Loss: 0.1329, Validation Loss: 0.1329,V Acc: 0.2613, Top 70th Acc: 0.3462, Bottom 30th Acc: 0.0606
Fold [2/5] Epoch [10/100] Initial Loss: 0.1417, Training Loss: 0.0314, Initial Validation Loss: 0.1329, Validation Loss: 0.0383,V Acc: 0.8108, Top 70th Acc: 0.8974, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 18  Rolling back to Epoch (base 0): 13  Top Validation Acc: 0.8974358974358975
14 1 [array([0.33155915, 0.0965985 , 0.1119529 , 0.22231065, 0.23757876],
      dtype=float32)]
Fold [3/5] Epoch [0/100] Initial Loss: 0.1380, Training Loss: 0.1380, Initial Validation Loss: 0.1358, Validation Loss: 0.1358,V Acc: 0.2636, Top 70th Acc: 0.3636, Bottom 30th Acc: 0.0303
Fold [3/5] Epoch [10/100] Initial Loss: 0.1380, Training Loss: 0.0320, Initial Validation Loss: 0.1358, Validation Loss: 0.0397,V Acc: 0.8455, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.6970
Fold [3/5] Epoch [20/100] Initial Loss: 0.1380, Training Loss: 0.0241, Initial Validation Loss: 0.1358, Validation Loss: 0.0349,V Acc: 0.8182, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.5152
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.961038961038961
Fold [4/5] Epoch [0/100] Initial Loss: 0.1381, Training Loss: 0.1381, Initial Validation Loss: 0.1261, Validation Loss: 0.1261,V Acc: 0.3394, Top 70th Acc: 0.4156, Bottom 30th Acc: 0.1562
Fold [4/5] Epoch [10/100] Initial Loss: 0.1381, Training Loss: 0.0295, Initial Validation Loss: 0.1261, Validation Loss: 0.0399,V Acc: 0.7798, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.4375
Fold [4/5] Epoch [20/100] Initial Loss: 0.1381, Training Loss: 0.0213, Initial Validation Loss: 0.1261, Validation Loss: 0.0354,V Acc: 0.8073, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.5000
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.922077922077922
Fold [5/5] Epoch [0/100] Initial Loss: 0.1392, Training Loss: 0.1392, Initial Validation Loss: 0.1325, Validation Loss: 0.1325,V Acc: 0.3148, Top 70th Acc: 0.3816, Bottom 30th Acc: 0.1562
Fold [5/5] Epoch [10/100] Initial Loss: 0.1392, Training Loss: 0.0350, Initial Validation Loss: 0.1325, Validation Loss: 0.0362,V Acc: 0.8148, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.4688
Fold [5/5] Epoch [20/100] Initial Loss: 0.1392, Training Loss: 0.0244, Initial Validation Loss: 0.1325, Validation Loss: 0.0336,V Acc: 0.8333, Top 70th Acc: 0.9079, Bottom 30th Acc: 0.6562
Stopping early at Epoch (base 0): 22  Rolling back to Epoch (base 0): 17  Top Validation Acc: 0.9078947368421053
Running train_nn.py with seed 15
CUDA:False
Training samples count:  550
Training on 20 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1390, Training Loss: 0.1390, Initial Validation Loss: 0.1332, Validation Loss: 0.1332,V Acc: 0.2679, Top 70th Acc: 0.3418, Bottom 30th Acc: 0.0909
Fold [1/5] Epoch [10/100] Initial Loss: 0.1390, Training Loss: 0.0426, Initial Validation Loss: 0.1332, Validation Loss: 0.0503,V Acc: 0.7768, Top 70th Acc: 0.8861, Bottom 30th Acc: 0.5152
Fold [1/5] Epoch [20/100] Initial Loss: 0.1390, Training Loss: 0.0275, Initial Validation Loss: 0.1332, Validation Loss: 0.0415,V Acc: 0.7946, Top 70th Acc: 0.9241, Bottom 30th Acc: 0.4848
Fold [1/5] Epoch [30/100] Initial Loss: 0.1390, Training Loss: 0.0230, Initial Validation Loss: 0.1332, Validation Loss: 0.0410,V Acc: 0.7946, Top 70th Acc: 0.9114, Bottom 30th Acc: 0.5152
Stopping early at Epoch (base 0): 34  Rolling back to Epoch (base 0): 29  Top Validation Acc: 0.8860759493670886
Fold [2/5] Epoch [0/100] Initial Loss: 0.1372, Training Loss: 0.1372, Initial Validation Loss: 0.1334, Validation Loss: 0.1334,V Acc: 0.3333, Top 70th Acc: 0.3590, Bottom 30th Acc: 0.2727
Fold [2/5] Epoch [10/100] Initial Loss: 0.1372, Training Loss: 0.0440, Initial Validation Loss: 0.1334, Validation Loss: 0.0489,V Acc: 0.8018, Top 70th Acc: 0.8718, Bottom 30th Acc: 0.6364
Fold [2/5] Epoch [20/100] Initial Loss: 0.1372, Training Loss: 0.0250, Initial Validation Loss: 0.1334, Validation Loss: 0.0391,V Acc: 0.8198, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.9230769230769231
15 1 [array([0.54113895, 0.04581182, 0.06323364, 0.22699685, 0.12281872],
      dtype=float32)]
Fold [3/5] Epoch [0/100] Initial Loss: 0.1380, Training Loss: 0.1380, Initial Validation Loss: 0.1338, Validation Loss: 0.1338,V Acc: 0.3909, Top 70th Acc: 0.3766, Bottom 30th Acc: 0.4242
Fold [3/5] Epoch [10/100] Initial Loss: 0.1380, Training Loss: 0.0390, Initial Validation Loss: 0.1338, Validation Loss: 0.0328,V Acc: 0.8545, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.6667
Fold [3/5] Epoch [20/100] Initial Loss: 0.1380, Training Loss: 0.0265, Initial Validation Loss: 0.1338, Validation Loss: 0.0254,V Acc: 0.8818, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.6970
Fold [3/5] Epoch [30/100] Initial Loss: 0.1380, Training Loss: 0.0237, Initial Validation Loss: 0.1338, Validation Loss: 0.0250,V Acc: 0.8727, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 36  Rolling back to Epoch (base 0): 31  Top Validation Acc: 0.961038961038961
Fold [4/5] Epoch [0/100] Initial Loss: 0.1387, Training Loss: 0.1387, Initial Validation Loss: 0.1337, Validation Loss: 0.1337,V Acc: 0.2569, Top 70th Acc: 0.3247, Bottom 30th Acc: 0.0938
Fold [4/5] Epoch [10/100] Initial Loss: 0.1387, Training Loss: 0.0371, Initial Validation Loss: 0.1337, Validation Loss: 0.0321,V Acc: 0.8716, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.6250
Fold [4/5] Epoch [20/100] Initial Loss: 0.1387, Training Loss: 0.0253, Initial Validation Loss: 0.1337, Validation Loss: 0.0291,V Acc: 0.8532, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6250
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0):
Fold [2/5] Epoch [20/100] Initial Loss: 0.1378, Training Loss: 0.0173, Initial Validation Loss: 0.1292, Validation Loss: 0.0197,V Acc: 0.9279, Top 70th Acc: 1.0000, Bottom 30th Acc: 0.7576
Stopping early at Epoch (base 0): 22  Rolling back to Epoch (base 0): 17  Top Validation Acc: 0.9743589743589743
Fold [3/5] Epoch [0/100] Initial Loss: 0.1332, Training Loss: 0.1332, Initial Validation Loss: 0.1187, Validation Loss: 0.1187,V Acc: 0.4909, Top 70th Acc: 0.6104, Bottom 30th Acc: 0.2121
Fold [3/5] Epoch [10/100] Initial Loss: 0.1332, Training Loss: 0.0215, Initial Validation Loss: 0.1187, Validation Loss: 0.0418,V Acc: 0.8000, Top 70th Acc: 0.8961, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 16  Rolling back to Epoch (base 0): 11  Top Validation Acc: 0.948051948051948
Fold [4/5] Epoch [0/100] Initial Loss: 0.1376, Training Loss: 0.1376, Initial Validation Loss: 0.1241, Validation Loss: 0.1241,V Acc: 0.4862, Top 70th Acc: 0.5844, Bottom 30th Acc: 0.2500
Fold [4/5] Epoch [10/100] Initial Loss: 0.1376, Training Loss: 0.0259, Initial Validation Loss: 0.1241, Validation Loss: 0.0293,V Acc: 0.8624, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.5938
Fold [4/5] Epoch [20/100] Initial Loss: 0.1376, Training Loss: 0.0152, Initial Validation Loss: 0.1241, Validation Loss: 0.0257,V Acc: 0.8624, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.5938
Fold [4/5] Epoch [30/100] Initial Loss: 0.1376, Training Loss: 0.0129, Initial Validation Loss: 0.1241, Validation Loss: 0.0250,V Acc: 0.8807, Top 70th Acc: 0.9870, Bottom 30th Acc: 0.6250
Stopping early at Epoch (base 0): 33  Rolling back to Epoch (base 0): 28  Top Validation Acc: 0.961038961038961
Fold [5/5] Epoch [0/100] Initial Loss: 0.1247, Training Loss: 0.1247, Initial Validation Loss: 0.1040, Validation Loss: 0.1040,V Acc: 0.5185, Top 70th Acc: 0.6053, Bottom 30th Acc: 0.3125
Fold [5/5] Epoch [10/100] Initial Loss: 0.1247, Training Loss: 0.0237, Initial Validation Loss: 0.1040, Validation Loss: 0.0212,V Acc: 0.8981, Top 70th Acc: 0.9737, Bottom 30th Acc: 0.7188
Stopping early at Epoch (base 0): 17  Rolling back to Epoch (base 0): 12  Top Validation Acc: 0.9868421052631579
Running train_nn.py with seed 19
CUDA:False
Training samples count:  550
Training on 21 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1324, Training Loss: 0.1324, Initial Validation Loss: 0.1273, Validation Loss: 0.1273,V Acc: 0.4018, Top 70th Acc: 0.4051, Bottom 30th Acc: 0.3939
Fold [1/5] Epoch [10/100] Initial Loss: 0.1324, Training Loss: 0.0244, Initial Validation Loss: 0.1273, Validation Loss: 0.0276,V Acc: 0.8929, Top 70th Acc: 0.9367, Bottom 30th Acc: 0.7879
Stopping early at Epoch (base 0): 19  Rolling back to Epoch (base 0): 14  Top Validation Acc: 0.9746835443037974
Fold [2/5] Epoch [0/100] Initial Loss: 0.1372, Training Loss: 0.1372, Initial Validation Loss: 0.1227, Validation Loss: 0.1227,V Acc: 0.4234, Top 70th Acc: 0.4744, Bottom 30th Acc: 0.3030
Fold [2/5] Epoch [10/100] Initial Loss: 0.1372, Training Loss: 0.0219, Initial Validation Loss: 0.1227, Validation Loss: 0.0330,V Acc: 0.8198, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 18  Rolling back to Epoch (base 0): 13  Top Validation Acc: 0.8589743589743589
19 1 [array([0.8450979 , 0.03396547, 0.02026496, 0.0451136 , 0.05555809],
      dtype=float32)]
Fold [3/5] Epoch [0/100] Initial Loss: 0.1320, Training Loss: 0.1320, Initial Validation Loss: 0.1170, Validation Loss: 0.1170,V Acc: 0.5636, Top 70th Acc: 0.6623, Bottom 30th Acc: 0.3333
Fold [3/5] Epoch [10/100] Initial Loss: 0.1320, Training Loss: 0.0187, Initial Validation Loss: 0.1170, Validation Loss: 0.0282,V Acc: 0.8636, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.6364
Fold [3/5] Epoch [20/100] Initial Loss: 0.1320, Training Loss: 0.0136, Initial Validation Loss: 0.1170, Validation Loss: 0.0225,V Acc: 0.9182, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.8485
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.922077922077922
Fold [4/5] Epoch [0/100] Initial Loss: 0.1307, Training Loss: 0.1307, Initial Validation Loss: 0.1181, Validation Loss: 0.1181,V Acc: 0.4771, Top 70th Acc: 0.5714, Bottom 30th Acc: 0.2500
Fold [4/5] Epoch [10/100] Initial Loss: 0.1307, Training Loss: 0.0219, Initial Validation Loss: 0.1181, Validation Loss: 0.0297,V Acc: 0.8440, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.5625
Stopping early at Epoch (base 0): 14  Rolling back to Epoch (base 0): 9  Top Validation Acc: 0.974025974025974
Fold [5/5] Epoch [0/100] Initial Loss: 0.1363, Training Loss: 0.1363, Initial Validation Loss: 0.1219, Validation Loss: 0.1219,V Acc: 0.5370, Top 70th Acc: 0.6579, Bottom 30th Acc: 0.2500
Fold [5/5] Epoch [10/100] Initial Loss: 0.1363, Training Loss: 0.0280, Initial Validation Loss: 0.1219, Validation Loss: 0.0189,V Acc: 0.9259, Top 70th Acc: 0.9868, Bottom 30th Acc: 0.7812
Fold [5/5] Epoch [20/100] Initial Loss: 0.1363, Training Loss: 0.0202, Initial Validation Loss: 0.1219, Validation Loss: 0.0154,V Acc: 0.9352, Top 70th Acc: 0.9868, Bottom 30th Acc: 0.8125
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 1.0
Running train_nn.py with seed 20
CUDA:False
Training samples count:  550
Training on 21 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1428, Training Loss: 0.1428, Initial Validation Loss: 0.1327, Validation Loss: 0.1327,V Acc: 0.2857, Top 70th Acc: 0.3418, Bottom 30th Acc: 0.1515
Fold [1/5] Epoch [10/100] Initial Loss: 0.1428, Training Loss: 0.0227, Initial Validation Loss: 0.1327, Validation Loss: 0.0286,V Acc: 0.8304, Top 70th Acc: 0.9620, Bottom 30th Acc: 0.5152
Stopping early at Epoch (base 0): 17  Rolling back to Epoch (base 0): 12  Top Validation Acc: 0.9873417721518988
20 0 [array([0.6771979 , 0.01952696, 0.02563265, 0.13219078, 0.14545172],
      dtype=float32)]
Fold [2/5] Epoch [0/100] Initial Loss: 0.1403, Training Loss: 0.1403, Initial Validation Loss: 0.1349, Validation Loss: 0.1349,V Acc: 0.2793, Top 70th Acc: 0.3462, Bottom 30th Acc: 0.1212
Fold [2/5] Epoch [10/100] Initial Loss: 0.1403, Training Loss: 0.0236, Initial Validation Loss: 0.1349, Validation Loss: 0.0192,V Acc: 0.9550, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.9394
Fold [2/5] Epoch [20/100] Initial Loss: 0.1403, Training Loss: 0.0141, Initial Validation Loss: 0.1349, Validation Loss: 0.0234,V Acc: 0.8829, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 20  Rolling back to Epoch (base 0): 15  Top Validation Acc: 0.9743589743589743
Fold [3/5] Epoch [0/100] Initial Loss: 0.1402, Training Loss: 0.1402, Initial Validation Loss: 0.1261, Validation Loss: 0.1261,V Acc: 0.4091, Top 70th Acc: 0.4545, Bottom 30th Acc: 0.3030
Fold [3/5] Epoch [10/100] Initial Loss: 0.1402, Training Loss: 0.0201, Initial Validation Loss: 0.1261, Validation Loss: 0.0394,V Acc: 0.8091, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.5152
Stopping early at Epoch (base 0): 16  Rolling back to Epoch (base 0): 11  Top Validation Acc: 0.948051948051948
Fold [4/5] Epoch [0/100] Initial Loss: 0.1379, Training Loss: 0.1379, Initial Validation Loss: 0.1267, Validation Loss: 0.1267,V Acc: 0.4220, Top 70th Acc: 0.4675, Bottom 30th Acc: 0.3125
Fold [4/5] Epoch [10/100] Initial Loss: 0.1379, Training Loss: 0.0244, Initial Validation Loss: 0.1267, Validation Loss: 0.0297,V Acc: 0.8624, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6562
Stopping early at Epoch (base 0): 19  Rolling back to Epoch (base 0): 14  Top Validation Acc: 0.974025974025974
Fold [5/5] Epoch [0/100] Initial Loss: 0.1376, Training Loss: 0.1376, Initial Validation Loss: 0.1276, Validation Loss: 0.1276,V Acc: 0.5185, Top 70th Acc: 0.5132, Bottom 30th Acc: 0.5312
Fold [5/5] Epoch [10/100] Initial Loss: 0.1376, Training Loss: 0.0275, Initial Validation Loss: 0.1276, Validation Loss: 0.0292,V Acc: 0.8611, Top 70th Acc: 0.9737, Bottom 30th Acc: 0.5938
Fold [5/5] Epoch [20/100] Initial Loss: 0.1376, Training Loss: 0.0180, Initial Validation Loss: 0.1276, Validation Loss: 0.0249,V Acc: 0.8704, Top 70th Acc: 0.9737, Bottom 30th Acc: 0.6250
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.9736842105263158
Running train_nn.py with seed 21/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)

Fold [2/5] Epoch [10/100] Initial Loss: 0.1419, Training Loss: 0.0322, Initial Validation Loss: 0.1359, Validation Loss: 0.0469,V Acc: 0.7207, Top 70th Acc: 0.8718, Bottom 30th Acc: 0.3636
Fold [2/5] Epoch [20/100] Initial Loss: 0.1419, Training Loss: 0.0138, Initial Validation Loss: 0.1359, Validation Loss: 0.0353,V Acc: 0.8108, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.5455
Fold [2/5] Epoch [30/100] Initial Loss: 0.1419, Training Loss: 0.0111, Initial Validation Loss: 0.1359, Validation Loss: 0.0343,V Acc: 0.8288, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 32  Rolling back to Epoch (base 0): 27  Top Validation Acc: 0.9487179487179487
15 1 [array([0.31069255, 0.04926214, 0.04671655, 0.10599464, 0.48733413],
      dtype=float32)]
Fold [3/5] Epoch [0/100] Initial Loss: 0.1403, Training Loss: 0.1403, Initial Validation Loss: 0.1354, Validation Loss: 0.1354,V Acc: 0.3455, Top 70th Acc: 0.3896, Bottom 30th Acc: 0.2424
Fold [3/5] Epoch [10/100] Initial Loss: 0.1403, Training Loss: 0.0372, Initial Validation Loss: 0.1354, Validation Loss: 0.0367,V Acc: 0.8545, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.6667
Fold [3/5] Epoch [20/100] Initial Loss: 0.1403, Training Loss: 0.0188, Initial Validation Loss: 0.1354, Validation Loss: 0.0280,V Acc: 0.8818, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.7879
Fold [3/5] Epoch [30/100] Initial Loss: 0.1403, Training Loss: 0.0133, Initial Validation Loss: 0.1354, Validation Loss: 0.0276,V Acc: 0.8273, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.5152
Fold [3/5] Epoch [40/100] Initial Loss: 0.1403, Training Loss: 0.0117, Initial Validation Loss: 0.1354, Validation Loss: 0.0257,V Acc: 0.8545, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 45  Rolling back to Epoch (base 0): 40  Top Validation Acc: 0.948051948051948
Fold [4/5] Epoch [0/100] Initial Loss: 0.1396, Training Loss: 0.1396, Initial Validation Loss: 0.1356, Validation Loss: 0.1356,V Acc: 0.2661, Top 70th Acc: 0.3117, Bottom 30th Acc: 0.1562
Fold [4/5] Epoch [10/100] Initial Loss: 0.1396, Training Loss: 0.0377, Initial Validation Loss: 0.1356, Validation Loss: 0.0332,V Acc: 0.8440, Top 70th Acc: 0.9870, Bottom 30th Acc: 0.5000
Fold [4/5] Epoch [20/100] Initial Loss: 0.1396, Training Loss: 0.0163, Initial Validation Loss: 0.1356, Validation Loss: 0.0209,V Acc: 0.8532, Top 70th Acc: 1.0000, Bottom 30th Acc: 0.5000
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.987012987012987
Fold [5/5] Epoch [0/100] Initial Loss: 0.1393, Training Loss: 0.1393, Initial Validation Loss: 0.1274, Validation Loss: 0.1274,V Acc: 0.3148, Top 70th Acc: 0.3553, Bottom 30th Acc: 0.2188
Fold [5/5] Epoch [10/100] Initial Loss: 0.1393, Training Loss: 0.0269, Initial Validation Loss: 0.1274, Validation Loss: 0.0451,V Acc: 0.7593, Top 70th Acc: 0.8684, Bottom 30th Acc: 0.5000
Fold [5/5] Epoch [20/100] Initial Loss: 0.1393, Training Loss: 0.0129, Initial Validation Loss: 0.1274, Validation Loss: 0.0373,V Acc: 0.8148, Top 70th Acc: 0.9079, Bottom 30th Acc: 0.5938
Stopping early at Epoch (base 0): 27  Rolling back to Epoch (base 0): 22  Top Validation Acc: 0.9210526315789473
Running train_nn.py with seed 16
CUDA:False
Training samples count:  550
Training on 40 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1386, Training Loss: 0.1386, Initial Validation Loss: 0.1375, Validation Loss: 0.1375,V Acc: 0.3214, Top 70th Acc: 0.3544, Bottom 30th Acc: 0.2424
Fold [1/5] Epoch [10/100] Initial Loss: 0.1386, Training Loss: 0.0355, Initial Validation Loss: 0.1375, Validation Loss: 0.0487,V Acc: 0.7946, Top 70th Acc: 0.8734, Bottom 30th Acc: 0.6061
Fold [1/5] Epoch [20/100] Initial Loss: 0.1386, Training Loss: 0.0155, Initial Validation Loss: 0.1375, Validation Loss: 0.0311,V Acc: 0.8839, Top 70th Acc: 0.9620, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 28  Rolling back to Epoch (base 0): 23  Top Validation Acc: 0.9620253164556962
16 0 [array([0.57011205, 0.03779288, 0.02191502, 0.11286943, 0.25731066],
      dtype=float32)]
Fold [2/5] Epoch [0/100] Initial Loss: 0.1399, Training Loss: 0.1399, Initial Validation Loss: 0.1338, Validation Loss: 0.1338,V Acc: 0.3243, Top 70th Acc: 0.3590, Bottom 30th Acc: 0.2424
Fold [2/5] Epoch [10/100] Initial Loss: 0.1399, Training Loss: 0.0322, Initial Validation Loss: 0.1338, Validation Loss: 0.0372,V Acc: 0.8018, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.5152
Fold [2/5] Epoch [20/100] Initial Loss: 0.1399, Training Loss: 0.0172, Initial Validation Loss: 0.1338, Validation Loss: 0.0317,V Acc: 0.8108, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.4848
Fold [2/5] Epoch [30/100] Initial Loss: 0.1399, Training Loss: 0.0128, Initial Validation Loss: 0.1338, Validation Loss: 0.0302,V Acc: 0.8288, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.5152
Stopping early at Epoch (base 0): 34  Rolling back to Epoch (base 0): 29  Top Validation Acc: 0.9615384615384616
Fold [3/5] Epoch [0/100] Initial Loss: 0.1389, Training Loss: 0.1389, Initial Validation Loss: 0.1349, Validation Loss: 0.1349,V Acc: 0.2545, Top 70th Acc: 0.3117, Bottom 30th Acc: 0.1212
Fold [3/5] Epoch [10/100] Initial Loss: 0.1389, Training Loss: 0.0381, Initial Validation Loss: 0.1349, Validation Loss: 0.0425,V Acc: 0.8091, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.5455
Fold [3/5] Epoch [20/100] Initial Loss: 0.1389, Training Loss: 0.0165, Initial Validation Loss: 0.1349, Validation Loss: 0.0287,V Acc: 0.8273, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.5455
Fold [3/5] Epoch [30/100] Initial Loss: 0.1389, Training Loss: 0.0134, Initial Validation Loss: 0.1349, Validation Loss: 0.0279,V Acc: 0.8182, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.5152
Stopping early at Epoch (base 0): 39  Rolling back to Epoch (base 0): 34  Top Validation Acc: 0.948051948051948
Fold [4/5] Epoch [0/100] Initial Loss: 0.1402, Training Loss: 0.1402, Initial Validation Loss: 0.1328, Validation Loss: 0.1328,V Acc: 0.2844, Top 70th Acc: 0.3377, Bottom 30th Acc: 0.1562
Fold [4/5] Epoch [10/100] Initial Loss: 0.1402, Training Loss: 0.0390, Initial Validation Loss: 0.1328, Validation Loss: 0.0447,V Acc: 0.7615, Top 70th Acc: 0.8961, Bottom 30th Acc: 0.4375
Fold [4/5] Epoch [20/100] Initial Loss: 0.1402, Training Loss: 0.0212, Initial Validation Loss: 0.1328, Validation Loss: 0.0390,V Acc: 0.7798, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.4375
Fold [4/5] Epoch [30/100] Initial Loss: 0.1402, Training Loss: 0.0140, Initial Validation Loss: 0.1328, Validation Loss: 0.0335,V Acc: 0.8165, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.5000
Fold [4/5] Epoch [40/100] Initial Loss: 0.1402, Training Loss: 0.0119, Initial Validation Loss: 0.1328, Validation Loss: 0.0307,V Acc: 0.8440, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.5938
Fold [4/5] Epoch [50/100] Initial Loss: 0.1402, Training Loss: 0.0111, Initial Validation Loss: 0.1328, Validation Loss: 0.0281,V Acc: 0.8624, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.6875
Stopping early at Epoch (base 0): 55  Rolling back to Epoch (base 0): 50  Top Validation Acc: 0.935064935064935
Fold [5/5] Epoch [0/100] Initial Loss: 0.1401, Training Loss: 0.1401, Initial Validation Loss: 0.1289, Validation Loss: 0.1289,V Acc: 0.3148, Top 70th Acc: 0.3684, Bottom 30th Acc: 0.1875
Fold [5/5] Epoch [10/100] Initial Loss: 0.1401, Training Loss: 0.0262, Initial Validation Loss: 0.1289, Validation Loss: 0.0400,V Acc: 0.8056, Top 70th Acc: 0.9079, Bottom 30th Acc: 0.5625
Fold [5/5] Epoch [20/100] Initial Loss: 0.1401, Training Loss: 0.0134, Initial Validation Loss: 0.1289, Validation Loss: 0.0373,V Acc: 0.8148, Top 70th Acc: 0.9211, Bottom 30th Acc: 0.5625
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.9210526315789473
Running train_nn.py with seed 17
CUDA:False
Training samples count:  550
Training on 40 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1419, Training Loss: 0.1419, Initial Validation Loss: 0.1382, Validation Loss: 0.1382,V Acc: 0.3214, Top 70th Acc: 0.3797, Bottom 30th Acc: 0.1818
Fold [1/5] Epoch [10/100] Initial Loss: 0.1419, Training Loss: 0.0391, Initial Validation Loss: 0.1382, Validation Loss: 0.0487,V Acc: 0.7768, Top 70th Acc: 0.8481, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 34  Rolling back to Epoch (base 0): 29  Top Validation Acc: 0.6582278481012658
Fold [2/5] Epoch [0/100] Initial Loss: 0.1382, Training Loss: 0.1382, Initial Validation Loss: 0.1317, Validation Loss: 0.1317,V Acc: 0.2613, Top 70th Acc: 0.3590, Bottom 30th Acc: 0.0303
Fold [2/5] Epoch [10/100] Initial Loss: 0.1382, Training Loss: 0.0831, Initial Validation Loss: 0.1317, Validation Loss: 0.0757,V Acc: 0.6757, Top 70th Acc: 0.7308, Bottom 30th Acc: 0.5455
Fold [2/5] Epoch [20/100] Initial Loss: 0.1382, Training Loss: 0.0811, Initial Validation Loss: 0.1317, Validation Loss: 0.0728,V Acc: 0.6847, Top 70th Acc: 0.7436, Bottom 30th Acc: 0.5455
Fold [2/5] Epoch [30/100] Initial Loss: 0.1382, Training Loss: 0.0806, Initial Validation Loss: 0.1317, Validation Loss: 0.0727,V Acc: 0.6937, Top 70th Acc: 0.7436, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 32  Rolling back to Epoch (base 0): 27  Top Validation Acc: 0.7307692307692307
15 1 [array([0.11278436, 0.36821684, 0.16118532, 0.2092838 , 0.14852962],
      dtype=float32)]
Fold [3/5] Epoch [0/100] Initial Loss: 0.1377, Training Loss: 0.1377, Initial Validation Loss: 0.1323, Validation Loss: 0.1323,V Acc: 0.3909, Top 70th Acc: 0.4805, Bottom 30th Acc: 0.1818
Fold [3/5] Epoch [10/100] Initial Loss: 0.1377, Training Loss: 0.0809, Initial Validation Loss: 0.1323, Validation Loss: 0.0763,V Acc: 0.6727, Top 70th Acc: 0.7792, Bottom 30th Acc: 0.4242
Fold [3/5] Epoch [20/100] Initial Loss: 0.1377, Training Loss: 0.0785, Initial Validation Loss: 0.1323, Validation Loss: 0.0754,V Acc: 0.6545, Top 70th Acc: 0.8052, Bottom 30th Acc: 0.3030
Fold [3/5] Epoch [30/100] Initial Loss: 0.1377, Training Loss: 0.0780, Initial Validation Loss: 0.1323, Validation Loss: 0.0751,V Acc: 0.6545, Top 70th Acc: 0.7922, Bottom 30th Acc: 0.3333
Fold [3/5] Epoch [40/100] Initial Loss: 0.1377, Training Loss: 0.0776, Initial Validation Loss: 0.1323, Validation Loss: 0.0747,V Acc: 0.6727, Top 70th Acc: 0.7792, Bottom 30th Acc: 0.4242
Stopping early at Epoch (base 0): 47  Rolling back to Epoch (base 0): 42  Top Validation Acc: 0.7662337662337663
Fold [4/5] Epoch [0/100] Initial Loss: 0.1333, Training Loss: 0.1333, Initial Validation Loss: 0.1244, Validation Loss: 0.1244,V Acc: 0.4037, Top 70th Acc: 0.4416, Bottom 30th Acc: 0.3125
Fold [4/5] Epoch [10/100] Initial Loss: 0.1333, Training Loss: 0.0819, Initial Validation Loss: 0.1244, Validation Loss: 0.0744,V Acc: 0.6697, Top 70th Acc: 0.8312, Bottom 30th Acc: 0.2812
Fold [4/5] Epoch [20/100] Initial Loss: 0.1333, Training Loss: 0.0808, Initial Validation Loss: 0.1244, Validation Loss: 0.0728,V Acc: 0.6881, Top 70th Acc: 0.8312, Bottom 30th Acc: 0.3438
Fold [4/5] Epoch [30/100] Initial Loss: 0.1333, Training Loss: 0.0803, Initial Validation Loss: 0.1244, Validation Loss: 0.0729,V Acc: 0.6789, Top 70th Acc: 0.8312, Bottom 30th Acc: 0.3125
Fold [4/5] Epoch [40/100] Initial Loss: 0.1333, Training Loss: 0.0801, Initial Validation Loss: 0.1244, Validation Loss: 0.0725,V Acc: 0.6697, Top 70th Acc: 0.8052, Bottom 30th Acc: 0.3438
Stopping early at Epoch (base 0): 49  Rolling back to Epoch (base 0): 44  Top Validation Acc: 0.8311688311688312
Fold [5/5] Epoch [0/100] Initial Loss: 0.1365, Training Loss: 0.1365, Initial Validation Loss: 0.1258, Validation Loss: 0.1258,V Acc: 0.2685, Top 70th Acc: 0.3553, Bottom 30th Acc: 0.0625
Fold [5/5] Epoch [10/100] Initial Loss: 0.1365, Training Loss: 0.0791, Initial Validation Loss: 0.1258, Validation Loss: 0.0854,V Acc: 0.5833, Top 70th Acc: 0.6711, Bottom 30th Acc: 0.3750
Fold [5/5] Epoch [20/100] Initial Loss: 0.1365, Training Loss: 0.0769, Initial Validation Loss: 0.1258, Validation Loss: 0.0850,V Acc: 0.5833, Top 70th Acc: 0.6711, Bottom 30th Acc: 0.3750
Stopping early at Epoch (base 0): 21  Rolling back to Epoch (base 0): 16  Top Validation Acc: 0.6710526315789473
Running train_nn.py with seed 16
CUDA:False
Training samples count:  550
Training on 2 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1398, Training Loss: 0.1398, Initial Validation Loss: 0.1368, Validation Loss: 0.1368,V Acc: 0.3482, Top 70th Acc: 0.4051, Bottom 30th Acc: 0.2121
Fold [1/5] Epoch [10/100] Initial Loss: 0.1398, Training Loss: 0.0796, Initial Validation Loss: 0.1368, Validation Loss: 0.0883,V Acc: 0.5982, Top 70th Acc: 0.6962, Bottom 30th Acc: 0.3636
Fold [1/5] Epoch [20/100] Initial Loss: 0.1398, Training Loss: 0.0772, Initial Validation Loss: 0.1368, Validation Loss: 0.0864,V Acc: 0.5893, Top 70th Acc: 0.7089, Bottom 30th Acc: 0.3030
Stopping early at Epoch (base 0): 22  Rolling back to Epoch (base 0): 17  Top Validation Acc: 0.6962025316455697
16 0 [array([0.10991989, 0.37436473, 0.14351079, 0.20032698, 0.1718775 ],
      dtype=float32)]
Fold [2/5] Epoch [0/100] Initial Loss: 0.1409, Training Loss: 0.1409, Initial Validation Loss: 0.1341, Validation Loss: 0.1341,V Acc: 0.3874, Top 70th Acc: 0.3205, Bottom 30th Acc: 0.5455
Fold [2/5] Epoch [10/100] Initial Loss: 0.1409, Training Loss: 0.0839, Initial Validation Loss: 0.1341, Validation Loss: 0.0763,V Acc: 0.6667, Top 70th Acc: 0.7692, Bottom 30th Acc: 0.4242
Fold [2/5] Epoch [20/100] Initial Loss: 0.1409, Training Loss: 0.0809, Initial Validation Loss: 0.1341, Validation Loss: 0.0727,V Acc: 0.6577, Top 70th Acc: 0.7821, Bottom 30th Acc: 0.3636
Fold [2/5] Epoch [30/100] Initial Loss: 0.1409, Training Loss: 0.0802, Initial Validation Loss: 0.1341, Validation Loss: 0.0715,V Acc: 0.6577, Top 70th Acc: 0.7821, Bottom 30th Acc: 0.3636
Stopping early at Epoch (base 0): 39  Rolling back to Epoch (base 0): 34  Top Validation Acc: 0.782051282051282
Fold [3/5] Epoch [0/100] Initial Loss: 0.1370, Training Loss: 0.1370, Initial Validation Loss: 0.1302, Validation Loss: 0.1302,V Acc: 0.3818, Top 70th Acc: 0.5065, Bottom 30th Acc: 0.0909
Fold [3/5] Epoch [10/100] Initial Loss: 0.1370, Training Loss: 0.0793, Initial Validation Loss: 0.1302, Validation Loss: 0.0847,V Acc: 0.5818, Top 70th Acc: 0.6883, Bottom 30th Acc: 0.3333
Fold [3/5] Epoch [20/100] Initial Loss: 0.1370, Training Loss: 0.0769, Initial Validation Loss: 0.1302, Validation Loss: 0.0840,V Acc: 0.5727, Top 70th Acc: 0.6883, Bottom 30th Acc: 0.3030
Stopping early at Epoch (base 0): 27  Rolling back to Epoch (base 0): 22  Top Validation Acc: 0.6883116883116883
Fold [4/5] Epoch [0/100] Initial Loss: 0.1335, Training Loss: 0.1335, Initial Validation Loss: 0.1178, Validation Loss: 0.1178,V Acc: 0.5688, Top 70th Acc: 0.6364, Bottom 30th Acc: 0.4062
Fold [4/5] Epoch [10/100] Initial Loss: 0.1335, Training Loss: 0.0831, Initial Validation Loss: 0.1178, Validation Loss: 0.0716,V Acc: 0.6697, Top 70th Acc: 0.7403, Bottom 30th Acc: 0.5000
Fold [4/5] Epoch [20/100] Initial Loss: 0.1335, Training Loss: 0.0812, Initial Validation Loss: 0.1178, Validation Loss: 0.0683,V Acc: 0.6606, Top 70th Acc: 0.7792, Bottom 30th Acc: 0.3750
Fold [4/5] Epoch [30/100] Initial Loss: 0.1335, Training Loss: 0.0802, Initial Validation Loss: 0.1178, Validation Loss: 0.0683,V Acc: 0.6697, Top 70th Acc: 0.7792, Bottom 30th Acc: 0.4062
Stopping early at Epoch (base 0): 34  Rolling back to Epoch (base 0): 29  Top Validation Acc: 0.7792207792207793
Fold [5/5] Epoch [0/100] Initial Loss: 0.1401, Training Loss: 0.1401, Initial Validation Loss: 0.1268, Validation Loss: 0.1268,V Acc: 0.3241, Top 70th Acc: 0.3816, Bottom 30th Acc: 0.1875
Fold [5/5] Epoch [10/100] Initial Loss: 0.1401, Training Loss: 0.0794, Initial Validation Loss: 0.1268, Validation Loss: 0.0819,V Acc: 0.6111, Top 70th Acc: 0.7500, Bottom 30th Acc: 0.2812
Fold [5/5] Epoch [20/100] Initial Loss: 0.1401, Training Loss: 0.0772, Initial Validation Loss: 0.1268, Validation Loss: 0.0816,V Acc: 0.6111, Top 70th Acc: 0.7105, Bottom 30th Acc: 0.3750
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.75
Running train_nn.py with seed 17
CUDA:False
Training samples count:  550
Training on 2 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1331, Training Loss: 0.1331, Initial Validation Loss: 0.1260, Validation Loss: 0.1260,V Acc: 0.3661, Top 70th Acc: 0.5190, Bottom 30th Acc: 0.0000
Fold [1/5] Epoch [10/100] Initial Loss: 0.1331, Training Loss: 0.0788, Initial Validation Loss: 0.1260, Validation Loss: 0.0861,V Acc: 0.6161, Top 70th Acc: 0.7089, Bottom 30th Acc: 0.3939
Fold [4/5] Epoch [30/100] Initial Loss: 0.1387, Training Loss: 0.0174, Initial Validation Loss: 0.1338, Validation Loss: 0.0198,V Acc: 0.8991, Top 70th Acc: 1.0000, Bottom 30th Acc: 0.6562
Stopping early at Epoch (base 0): 33  Rolling back to Epoch (base 0): 28  Top Validation Acc: 1.0
Fold [5/5] Epoch [0/100] Initial Loss: 0.1361, Training Loss: 0.1361, Initial Validation Loss: 0.1276, Validation Loss: 0.1276,V Acc: 0.3611, Top 70th Acc: 0.4474, Bottom 30th Acc: 0.1562
Fold [5/5] Epoch [10/100] Initial Loss: 0.1361, Training Loss: 0.0311, Initial Validation Loss: 0.1276, Validation Loss: 0.0463,V Acc: 0.7685, Top 70th Acc: 0.8684, Bottom 30th Acc: 0.5312
Fold [5/5] Epoch [20/100] Initial Loss: 0.1361, Training Loss: 0.0170, Initial Validation Loss: 0.1276, Validation Loss: 0.0388,V Acc: 0.8148, Top 70th Acc: 0.8684, Bottom 30th Acc: 0.6875
Stopping early at Epoch (base 0): 29  Rolling back to Epoch (base 0): 24  Top Validation Acc: 0.881578947368421
Running train_nn.py with seed 16
CUDA:False
Training samples count:  550
Training on 30 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1365, Training Loss: 0.1365, Initial Validation Loss: 0.1361, Validation Loss: 0.1361,V Acc: 0.3839, Top 70th Acc: 0.4557, Bottom 30th Acc: 0.2121
Fold [1/5] Epoch [10/100] Initial Loss: 0.1365, Training Loss: 0.0542, Initial Validation Loss: 0.1361, Validation Loss: 0.0584,V Acc: 0.7768, Top 70th Acc: 0.8481, Bottom 30th Acc: 0.6061
Fold [1/5] Epoch [20/100] Initial Loss: 0.1365, Training Loss: 0.0243, Initial Validation Loss: 0.1361, Validation Loss: 0.0391,V Acc: 0.8661, Top 70th Acc: 0.9241, Bottom 30th Acc: 0.7273
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.9240506329113924
16 0 [array([0.49670574, 0.02737061, 0.06336609, 0.17072369, 0.24183387],
      dtype=float32)]
Fold [2/5] Epoch [0/100] Initial Loss: 0.1355, Training Loss: 0.1355, Initial Validation Loss: 0.1277, Validation Loss: 0.1277,V Acc: 0.4595, Top 70th Acc: 0.5000, Bottom 30th Acc: 0.3636
Fold [2/5] Epoch [10/100] Initial Loss: 0.1355, Training Loss: 0.0380, Initial Validation Loss: 0.1277, Validation Loss: 0.0433,V Acc: 0.7658, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.4242
Fold [2/5] Epoch [20/100] Initial Loss: 0.1355, Training Loss: 0.0194, Initial Validation Loss: 0.1277, Validation Loss: 0.0353,V Acc: 0.8018, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.5152
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.9230769230769231
Fold [3/5] Epoch [0/100] Initial Loss: 0.1408, Training Loss: 0.1408, Initial Validation Loss: 0.1352, Validation Loss: 0.1352,V Acc: 0.2909, Top 70th Acc: 0.3506, Bottom 30th Acc: 0.1515
Fold [3/5] Epoch [10/100] Initial Loss: 0.1408, Training Loss: 0.0323, Initial Validation Loss: 0.1352, Validation Loss: 0.0372,V Acc: 0.8273, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.6061
Fold [3/5] Epoch [20/100] Initial Loss: 0.1408, Training Loss: 0.0208, Initial Validation Loss: 0.1352, Validation Loss: 0.0320,V Acc: 0.8182, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.935064935064935
Fold [4/5] Epoch [0/100] Initial Loss: 0.1360, Training Loss: 0.1360, Initial Validation Loss: 0.1273, Validation Loss: 0.1273,V Acc: 0.3578, Top 70th Acc: 0.4675, Bottom 30th Acc: 0.0938
Fold [4/5] Epoch [10/100] Initial Loss: 0.1360, Training Loss: 0.0372, Initial Validation Loss: 0.1273, Validation Loss: 0.0438,V Acc: 0.7798, Top 70th Acc: 0.8961, Bottom 30th Acc: 0.5000
Fold [4/5] Epoch [20/100] Initial Loss: 0.1360, Training Loss: 0.0270, Initial Validation Loss: 0.1273, Validation Loss: 0.0405,V Acc: 0.7890, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.5000
Fold [4/5] Epoch [30/100] Initial Loss: 0.1360, Training Loss: 0.0210, Initial Validation Loss: 0.1273, Validation Loss: 0.0394,V Acc: 0.7982, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.5312
Fold [4/5] Epoch [40/100] Initial Loss: 0.1360, Training Loss: 0.0181, Initial Validation Loss: 0.1273, Validation Loss: 0.0340,V Acc: 0.8165, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.5000
Stopping early at Epoch (base 0): 45  Rolling back to Epoch (base 0): 40  Top Validation Acc: 0.922077922077922
Fold [5/5] Epoch [0/100] Initial Loss: 0.1406, Training Loss: 0.1406, Initial Validation Loss: 0.1314, Validation Loss: 0.1314,V Acc: 0.2593, Top 70th Acc: 0.2500, Bottom 30th Acc: 0.2812
Fold [5/5] Epoch [10/100] Initial Loss: 0.1406, Training Loss: 0.0285, Initial Validation Loss: 0.1314, Validation Loss: 0.0410,V Acc: 0.7963, Top 70th Acc: 0.8816, Bottom 30th Acc: 0.5938
Fold [5/5] Epoch [20/100] Initial Loss: 0.1406, Training Loss: 0.0187, Initial Validation Loss: 0.1314, Validation Loss: 0.0388,V Acc: 0.7685, Top 70th Acc: 0.9079, Bottom 30th Acc: 0.4375
Stopping early at Epoch (base 0): 20  Rolling back to Epoch (base 0): 15  Top Validation Acc: 0.9078947368421053
Running train_nn.py with seed 17
CUDA:False
Training samples count:  550
Training on 30 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1438, Training Loss: 0.1438, Initial Validation Loss: 0.1362, Validation Loss: 0.1362,V Acc: 0.3750, Top 70th Acc: 0.4430, Bottom 30th Acc: 0.2121
Fold [1/5] Epoch [10/100] Initial Loss: 0.1438, Training Loss: 0.0348, Initial Validation Loss: 0.1362, Validation Loss: 0.0401,V Acc: 0.8214, Top 70th Acc: 0.8987, Bottom 30th Acc: 0.6364
Fold [1/5] Epoch [20/100] Initial Loss: 0.1438, Training Loss: 0.0177, Initial Validation Loss: 0.1362, Validation Loss: 0.0335,V Acc: 0.8482, Top 70th Acc: 0.9241, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 20  Rolling back to Epoch (base 0): 15  Top Validation Acc: 0.9240506329113924
Fold [2/5] Epoch [0/100] Initial Loss: 0.1397, Training Loss: 0.1397, Initial Validation Loss: 0.1339, Validation Loss: 0.1339,V Acc: 0.2523, Top 70th Acc: 0.3590, Bottom 30th Acc: 0.0000
Fold [2/5] Epoch [10/100] Initial Loss: 0.1397, Training Loss: 0.0285, Initial Validation Loss: 0.1339, Validation Loss: 0.0421,V Acc: 0.8288, Top 70th Acc: 0.8718, Bottom 30th Acc: 0.7273
Fold [2/5] Epoch [20/100] Initial Loss: 0.1397, Training Loss: 0.0170, Initial Validation Loss: 0.1339, Validation Loss: 0.0382,V Acc: 0.8198, Top 70th Acc: 0.8718, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.8846153846153846
Fold [3/5] Epoch [0/100] Initial Loss: 0.1399, Training Loss: 0.1399, Initial Validation Loss: 0.1344, Validation Loss: 0.1344,V Acc: 0.3273, Top 70th Acc: 0.3766, Bottom 30th Acc: 0.2121
Fold [3/5] Epoch [10/100] Initial Loss: 0.1399, Training Loss: 0.0288, Initial Validation Loss: 0.1344, Validation Loss: 0.0351,V Acc: 0.8545, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.6061
Fold [3/5] Epoch [20/100] Initial Loss: 0.1399, Training Loss: 0.0185, Initial Validation Loss: 0.1344, Validation Loss: 0.0326,V Acc: 0.8364, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 27  Rolling back to Epoch (base 0): 22  Top Validation Acc: 0.961038961038961
Fold [4/5] Epoch [0/100] Initial Loss: 0.1388, Training Loss: 0.1388, Initial Validation Loss: 0.1291, Validation Loss: 0.1291,V Acc: 0.3211, Top 70th Acc: 0.4026, Bottom 30th Acc: 0.1250
Fold [4/5] Epoch [10/100] Initial Loss: 0.1388, Training Loss: 0.0334, Initial Validation Loss: 0.1291, Validation Loss: 0.0355,V Acc: 0.8165, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.5000
Fold [4/5] Epoch [20/100] Initial Loss: 0.1388, Training Loss: 0.0190, Initial Validation Loss: 0.1291, Validation Loss: 0.0273,V Acc: 0.8349, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.5000
Stopping early at Epoch (base 0): 29  Rolling back to Epoch (base 0): 24  Top Validation Acc: 0.974025974025974
17 3 [array([0.7047472 , 0.06866498, 0.05318258, 0.09334211, 0.08006322],
      dtype=float32)]
Fold [5/5] Epoch [0/100] Initial Loss: 0.1360, Training Loss: 0.1360, Initial Validation Loss: 0.1294, Validation Loss: 0.1294,V Acc: 0.2963, Top 70th Acc: 0.3684, Bottom 30th Acc: 0.1250
Fold [5/5] Epoch [10/100] Initial Loss: 0.1360, Training Loss: 0.0341, Initial Validation Loss: 0.1294, Validation Loss: 0.0399,V Acc: 0.8148, Top 70th Acc: 0.8947, Bottom 30th Acc: 0.6250
CUDA:False
Training samples count:  550
Training on 21 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1397, Training Loss: 0.1397, Initial Validation Loss: 0.1302, Validation Loss: 0.1302,V Acc: 0.3571, Top 70th Acc: 0.4051, Bottom 30th Acc: 0.2424
Fold [1/5] Epoch [10/100] Initial Loss: 0.1397, Training Loss: 0.0279, Initial Validation Loss: 0.1302, Validation Loss: 0.0380,V Acc: 0.8304, Top 70th Acc: 0.9367, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 18  Rolling back to Epoch (base 0): 13  Top Validation Acc: 0.9620253164556962
21 0 [array([0.6579132 , 0.03316824, 0.04944583, 0.15206493, 0.10740774],
      dtype=float32)]
Fold [2/5] Epoch [0/100] Initial Loss: 0.1364, Training Loss: 0.1364, Initial Validation Loss: 0.1258, Validation Loss: 0.1258,V Acc: 0.4955, Top 70th Acc: 0.6410, Bottom 30th Acc: 0.1515
Fold [2/5] Epoch [10/100] Initial Loss: 0.1364, Training Loss: 0.0245, Initial Validation Loss: 0.1258, Validation Loss: 0.0307,V Acc: 0.8919, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.6970
Fold [2/5] Epoch [20/100] Initial Loss: 0.1364, Training Loss: 0.0196, Initial Validation Loss: 0.1258, Validation Loss: 0.0220,V Acc: 0.9099, Top 70th Acc: 0.9872, Bottom 30th Acc: 0.7273
Stopping early at Epoch (base 0): 22  Rolling back to Epoch (base 0): 17  Top Validation Acc: 0.9871794871794872
Fold [3/5] Epoch [0/100] Initial Loss: 0.1322, Training Loss: 0.1322, Initial Validation Loss: 0.1218, Validation Loss: 0.1218,V Acc: 0.4727, Top 70th Acc: 0.5584, Bottom 30th Acc: 0.2727
Fold [3/5] Epoch [10/100] Initial Loss: 0.1322, Training Loss: 0.0197, Initial Validation Loss: 0.1218, Validation Loss: 0.0296,V Acc: 0.8636, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6667
Fold [3/5] Epoch [20/100] Initial Loss: 0.1322, Training Loss: 0.0148, Initial Validation Loss: 0.1218, Validation Loss: 0.0307,V Acc: 0.8727, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.7273
Stopping early at Epoch (base 0): 27  Rolling back to Epoch (base 0): 22  Top Validation Acc: 0.961038961038961
Fold [4/5] Epoch [0/100] Initial Loss: 0.1300, Training Loss: 0.1300, Initial Validation Loss: 0.1204, Validation Loss: 0.1204,V Acc: 0.4404, Top 70th Acc: 0.5455, Bottom 30th Acc: 0.1875
Fold [4/5] Epoch [10/100] Initial Loss: 0.1300, Training Loss: 0.0234, Initial Validation Loss: 0.1204, Validation Loss: 0.0265,V Acc: 0.8991, Top 70th Acc: 0.9870, Bottom 30th Acc: 0.6875
Fold [4/5] Epoch [20/100] Initial Loss: 0.1300, Training Loss: 0.0135, Initial Validation Loss: 0.1204, Validation Loss: 0.0216,V Acc: 0.8807, Top 70th Acc: 0.9870, Bottom 30th Acc: 0.6250
Stopping early at Epoch (base 0): 22  Rolling back to Epoch (base 0): 17  Top Validation Acc: 0.987012987012987
Fold [5/5] Epoch [0/100] Initial Loss: 0.1390, Training Loss: 0.1390, Initial Validation Loss: 0.1166, Validation Loss: 0.1166,V Acc: 0.4444, Top 70th Acc: 0.5395, Bottom 30th Acc: 0.2188
Fold [5/5] Epoch [10/100] Initial Loss: 0.1390, Training Loss: 0.0258, Initial Validation Loss: 0.1166, Validation Loss: 0.0276,V Acc: 0.8519, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.5938
Fold [5/5] Epoch [20/100] Initial Loss: 0.1390, Training Loss: 0.0160, Initial Validation Loss: 0.1166, Validation Loss: 0.0229,V Acc: 0.8519, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.5938
Stopping early at Epoch (base 0): 20  Rolling back to Epoch (base 0): 15  Top Validation Acc: 0.9605263157894737
Running train_nn.py with seed 22
CUDA:False
Training samples count:  550
Training on 21 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1376, Training Loss: 0.1376, Initial Validation Loss: 0.1203, Validation Loss: 0.1203,V Acc: 0.5268, Top 70th Acc: 0.5063, Bottom 30th Acc: 0.5758
Fold [1/5] Epoch [10/100] Initial Loss: 0.1376, Training Loss: 0.0219, Initial Validation Loss: 0.1203, Validation Loss: 0.0324,V Acc: 0.8482, Top 70th Acc: 0.9241, Bottom 30th Acc: 0.6667
Fold [1/5] Epoch [20/100] Initial Loss: 0.1376, Training Loss: 0.0171, Initial Validation Loss: 0.1203, Validation Loss: 0.0264,V Acc: 0.8482, Top 70th Acc: 0.9620, Bottom 30th Acc: 0.5758
Fold [1/5] Epoch [30/100] Initial Loss: 0.1376, Training Loss: 0.0142, Initial Validation Loss: 0.1203, Validation Loss: 0.0261,V Acc: 0.8571, Top 70th Acc: 0.9367, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 34  Rolling back to Epoch (base 0): 29  Top Validation Acc: 0.9493670886075949
22 0 [array([0.7886207 , 0.01436795, 0.01837296, 0.06259328, 0.1160451 ],
      dtype=float32)]
Fold [2/5] Epoch [0/100] Initial Loss: 0.1333, Training Loss: 0.1333, Initial Validation Loss: 0.1211, Validation Loss: 0.1211,V Acc: 0.4414, Top 70th Acc: 0.5769, Bottom 30th Acc: 0.1212
Fold [2/5] Epoch [10/100] Initial Loss: 0.1333, Training Loss: 0.0197, Initial Validation Loss: 0.1211, Validation Loss: 0.0279,V Acc: 0.8829, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 15  Rolling back to Epoch (base 0): 10  Top Validation Acc: 0.9871794871794872
Fold [3/5] Epoch [0/100] Initial Loss: 0.1358, Training Loss: 0.1358, Initial Validation Loss: 0.1239, Validation Loss: 0.1239,V Acc: 0.5091, Top 70th Acc: 0.5584, Bottom 30th Acc: 0.3939
Fold [3/5] Epoch [10/100] Initial Loss: 0.1358, Training Loss: 0.0226, Initial Validation Loss: 0.1239, Validation Loss: 0.0218,V Acc: 0.9091, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.7576
Stopping early at Epoch (base 0): 19  Rolling back to Epoch (base 0): 14  Top Validation Acc: 0.961038961038961
Fold [4/5] Epoch [0/100] Initial Loss: 0.1300, Training Loss: 0.1300, Initial Validation Loss: 0.1114, Validation Loss: 0.1114,V Acc: 0.5596, Top 70th Acc: 0.6753, Bottom 30th Acc: 0.2812
Fold [4/5] Epoch [10/100] Initial Loss: 0.1300, Training Loss: 0.0215, Initial Validation Loss: 0.1114, Validation Loss: 0.0271,V Acc: 0.8807, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.7500
Fold [4/5] Epoch [20/100] Initial Loss: 0.1300, Training Loss: 0.0160, Initial Validation Loss: 0.1114, Validation Loss: 0.0212,V Acc: 0.9266, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.8125
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.948051948051948
Fold [5/5] Epoch [0/100] Initial Loss: 0.1299, Training Loss: 0.1299, Initial Validation Loss: 0.1220, Validation Loss: 0.1220,V Acc: 0.4444, Top 70th Acc: 0.5789, Bottom 30th Acc: 0.1250
Fold [5/5] Epoch [10/100] Initial Loss: 0.1299, Training Loss: 0.0213, Initial Validation Loss: 0.1220, Validation Loss: 0.0356,V Acc: 0.8241, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.5312
Stopping early at Epoch (base 0): 17  Rolling back to Epoch (base 0): 12  Top Validation Acc: 0.9605263157894737
Running train_nn.py with seed 23
CUDA:False
Training samples count:  550
Training on 21 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1277, Training Loss: 0.1277, Initial Validation Loss: 0.1032, Validation Loss: 0.1032,V Acc: 0.6339, Top 70th Acc: 0.7595, Bottom 30th Acc: 0.3333
Fold [1/5] Epoch [10/100] Initial Loss: 0.1277, Training Loss: 0.0246, Initial Validation Loss: 0.1032, Validation Loss: 0.0262,V Acc: 0.8571, Top 70th Acc: 0.9620, Bottom 30th Acc: 0.6061
Fold [1/5] Epoch [20/100] Initial Loss: 0.1277, Training Loss: 0.0164, Initial Validation Loss: 0.1032, Validation Loss: 0.0231,V Acc: 0.8750, Top 70th Acc: 0.9620, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 20  Rolling back to Epoch (base 0): 15  Top Validation Acc: 0.9620253164556962
Fold [2/5] Epoch [0/100] Initial Loss: 0.1368, Training Loss: 0.1368, Initial Validation Loss: 0.1328, Validation Loss: 0.1328,V Acc: 0.3153, Top 70th Acc: 0.3846, Bottom 30th Acc: 0.1515
Fold [2/5] Epoch [10/100] Initial Loss: 0.1368, Training Loss: 0.0214, Initial Validation Loss: 0.1328, Validation Loss: 0.0258,V Acc: 0.8829, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.6667
Fold [2/5] Epoch [20/100] Initial Loss: 0.1368, Training Loss: 0.0162, Initial Validation Loss: 0.1328, Validation Loss: 0.0236,V Acc: 0.8829, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 21  Rolling back to Epoch (base 0): 16  Top Validation Acc: 0.9743589743589743
23 1 [array([0.7485432 , 0.02425132, 0.020239  , 0.10835503, 0.09861142],
      dtype=float32)]
Fold [3/5] Epoch [0/100] Initial Loss: 0.1332, Training Loss: 0.1332, Initial Validation Loss: 0.1186, Validation Loss: 0.1186,V Acc: 0.4091, Top 70th Acc: 0.4805, Bottom 30th Acc: 0.2424training rf with seed 1
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 20 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 2
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 20 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 3
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 20 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 4
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 20 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 5
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 20 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 6
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 20 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 7
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 20 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 8
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 20 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 9
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 20 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 10
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 20 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 11
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 20 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 12
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 20 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 13
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 20 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 14
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 20 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 15
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 20 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 16
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 20 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 17
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 20 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 18
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 20 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 19
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 20 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 20
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 20 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 21
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 20 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 22
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 20 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 23
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 20 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 24
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 20 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 25
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 20 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 26
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 20 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 27
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 20 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 28
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 20 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 29
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 20 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 30
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 20 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 31
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 20 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 32
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 20 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 33
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 20 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 34
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 20 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 35
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 20 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 36
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 20 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 37
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 20 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 38
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 20 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 39
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 20 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 40
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 20 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 41
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 20 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 42
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 20 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 43
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 20 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 44
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 20 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 45
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Stopping early at Epoch (base 0): 27  Rolling back to Epoch (base 0): 22  Top Validation Acc: 0.9493670886075949
Fold [2/5] Epoch [0/100] Initial Loss: 0.1352, Training Loss: 0.1352, Initial Validation Loss: 0.1312, Validation Loss: 0.1312,V Acc: 0.4685, Top 70th Acc: 0.5641, Bottom 30th Acc: 0.2424
Fold [2/5] Epoch [10/100] Initial Loss: 0.1352, Training Loss: 0.0140, Initial Validation Loss: 0.1312, Validation Loss: 0.0349,V Acc: 0.8378, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.5758
Fold [2/5] Epoch [20/100] Initial Loss: 0.1352, Training Loss: 0.0049, Initial Validation Loss: 0.1312, Validation Loss: 0.0281,V Acc: 0.8378, Top 70th Acc: 0.9872, Bottom 30th Acc: 0.4848
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.9743589743589743
Fold [3/5] Epoch [0/100] Initial Loss: 0.1400, Training Loss: 0.1400, Initial Validation Loss: 0.1324, Validation Loss: 0.1324,V Acc: 0.3455, Top 70th Acc: 0.4156, Bottom 30th Acc: 0.1818
Fold [3/5] Epoch [10/100] Initial Loss: 0.1400, Training Loss: 0.0129, Initial Validation Loss: 0.1324, Validation Loss: 0.0343,V Acc: 0.8364, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.5758
Fold [3/5] Epoch [20/100] Initial Loss: 0.1400, Training Loss: 0.0048, Initial Validation Loss: 0.1324, Validation Loss: 0.0332,V Acc: 0.8455, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6061
Fold [3/5] Epoch [30/100] Initial Loss: 0.1400, Training Loss: 0.0039, Initial Validation Loss: 0.1324, Validation Loss: 0.0336,V Acc: 0.8091, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.4848
Stopping early at Epoch (base 0): 30  Rolling back to Epoch (base 0): 25  Top Validation Acc: 0.948051948051948
Fold [4/5] Epoch [0/100] Initial Loss: 0.1394, Training Loss: 0.1394, Initial Validation Loss: 0.1336, Validation Loss: 0.1336,V Acc: 0.3486, Top 70th Acc: 0.4156, Bottom 30th Acc: 0.1875
Fold [4/5] Epoch [10/100] Initial Loss: 0.1394, Training Loss: 0.0316, Initial Validation Loss: 0.1336, Validation Loss: 0.0484,V Acc: 0.7523, Top 70th Acc: 0.8701, Bottom 30th Acc: 0.4688
Fold [4/5] Epoch [20/100] Initial Loss: 0.1394, Training Loss: 0.0073, Initial Validation Loss: 0.1336, Validation Loss: 0.0369,V Acc: 0.7798, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.3438
Fold [4/5] Epoch [30/100] Initial Loss: 0.1394, Training Loss: 0.0051, Initial Validation Loss: 0.1336, Validation Loss: 0.0334,V Acc: 0.8349, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.5625
Fold [4/5] Epoch [40/100] Initial Loss: 0.1394, Training Loss: 0.0043, Initial Validation Loss: 0.1336, Validation Loss: 0.0315,V Acc: 0.8440, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.5625
Fold [4/5] Epoch [50/100] Initial Loss: 0.1394, Training Loss: 0.0040, Initial Validation Loss: 0.1336, Validation Loss: 0.0300,V Acc: 0.8624, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.5938
Fold [4/5] Epoch [60/100] Initial Loss: 0.1394, Training Loss: 0.0039, Initial Validation Loss: 0.1336, Validation Loss: 0.0289,V Acc: 0.8624, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.5938
Stopping early at Epoch (base 0): 67  Rolling back to Epoch (base 0): 62  Top Validation Acc: 0.961038961038961
Fold [5/5] Epoch [0/100] Initial Loss: 0.1386, Training Loss: 0.1386, Initial Validation Loss: 0.1330, Validation Loss: 0.1330,V Acc: 0.2870, Top 70th Acc: 0.3816, Bottom 30th Acc: 0.0625
Fold [5/5] Epoch [10/100] Initial Loss: 0.1386, Training Loss: 0.0234, Initial Validation Loss: 0.1330, Validation Loss: 0.0371,V Acc: 0.8611, Top 70th Acc: 0.9211, Bottom 30th Acc: 0.7188
Fold [5/5] Epoch [20/100] Initial Loss: 0.1386, Training Loss: 0.0054, Initial Validation Loss: 0.1330, Validation Loss: 0.0232,V Acc: 0.8796, Top 70th Acc: 0.9868, Bottom 30th Acc: 0.6250
Fold [5/5] Epoch [30/100] Initial Loss: 0.1386, Training Loss: 0.0043, Initial Validation Loss: 0.1330, Validation Loss: 0.0226,V Acc: 0.8796, Top 70th Acc: 0.9868, Bottom 30th Acc: 0.6250
Stopping early at Epoch (base 0): 33  Rolling back to Epoch (base 0): 28  Top Validation Acc: 0.9868421052631579
12 4 [array([0.36799827, 0.04992726, 0.04918166, 0.28752393, 0.24536888],
      dtype=float32)]
Running train_nn.py with seed 13
CUDA:False
Training samples count:  550
Training on 162 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1397, Training Loss: 0.1397, Initial Validation Loss: 0.1329, Validation Loss: 0.1329,V Acc: 0.3661, Top 70th Acc: 0.4304, Bottom 30th Acc: 0.2121
Fold [1/5] Epoch [10/100] Initial Loss: 0.1397, Training Loss: 0.0135, Initial Validation Loss: 0.1329, Validation Loss: 0.0396,V Acc: 0.8036, Top 70th Acc: 0.9241, Bottom 30th Acc: 0.5152
Fold [1/5] Epoch [20/100] Initial Loss: 0.1397, Training Loss: 0.0043, Initial Validation Loss: 0.1329, Validation Loss: 0.0355,V Acc: 0.8125, Top 70th Acc: 0.9494, Bottom 30th Acc: 0.4848
Stopping early at Epoch (base 0): 28  Rolling back to Epoch (base 0): 23  Top Validation Acc: 0.9493670886075949
Fold [2/5] Epoch [0/100] Initial Loss: 0.1389, Training Loss: 0.1389, Initial Validation Loss: 0.1365, Validation Loss: 0.1365,V Acc: 0.3423, Top 70th Acc: 0.3974, Bottom 30th Acc: 0.2121
Fold [2/5] Epoch [10/100] Initial Loss: 0.1389, Training Loss: 0.0176, Initial Validation Loss: 0.1365, Validation Loss: 0.0384,V Acc: 0.8288, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.6061
Fold [2/5] Epoch [20/100] Initial Loss: 0.1389, Training Loss: 0.0063, Initial Validation Loss: 0.1365, Validation Loss: 0.0338,V Acc: 0.8198, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.4848
Fold [2/5] Epoch [30/100] Initial Loss: 0.1389, Training Loss: 0.0044, Initial Validation Loss: 0.1365, Validation Loss: 0.0316,V Acc: 0.8559, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.5758
Fold [2/5] Epoch [40/100] Initial Loss: 0.1389, Training Loss: 0.0039, Initial Validation Loss: 0.1365, Validation Loss: 0.0303,V Acc: 0.8559, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.6364
Fold [2/5] Epoch [50/100] Initial Loss: 0.1389, Training Loss: 0.0036, Initial Validation Loss: 0.1365, Validation Loss: 0.0283,V Acc: 0.8649, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.6364
Fold [2/5] Epoch [60/100] Initial Loss: 0.1389, Training Loss: 0.0035, Initial Validation Loss: 0.1365, Validation Loss: 0.0280,V Acc: 0.8739, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 69  Rolling back to Epoch (base 0): 64  Top Validation Acc: 0.9615384615384616
Fold [3/5] Epoch [0/100] Initial Loss: 0.1398, Training Loss: 0.1398, Initial Validation Loss: 0.1350, Validation Loss: 0.1350,V Acc: 0.3545, Top 70th Acc: 0.3766, Bottom 30th Acc: 0.3030
Fold [3/5] Epoch [10/100] Initial Loss: 0.1398, Training Loss: 0.0228, Initial Validation Loss: 0.1350, Validation Loss: 0.0372,V Acc: 0.8273, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.6061
Fold [3/5] Epoch [20/100] Initial Loss: 0.1398, Training Loss: 0.0056, Initial Validation Loss: 0.1350, Validation Loss: 0.0267,V Acc: 0.8455, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6061
Fold [3/5] Epoch [30/100] Initial Loss: 0.1398, Training Loss: 0.0042, Initial Validation Loss: 0.1350, Validation Loss: 0.0260,V Acc: 0.8636, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 33  Rolling back to Epoch (base 0): 28  Top Validation Acc: 0.948051948051948
Fold [4/5] Epoch [0/100] Initial Loss: 0.1406, Training Loss: 0.1406, Initial Validation Loss: 0.1327, Validation Loss: 0.1327,V Acc: 0.2477, Top 70th Acc: 0.3377, Bottom 30th Acc: 0.0312
Fold [4/5] Epoch [10/100] Initial Loss: 0.1406, Training Loss: 0.0273, Initial Validation Loss: 0.1327, Validation Loss: 0.0377,V Acc: 0.8165, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.5625
Fold [4/5] Epoch [20/100] Initial Loss: 0.1406, Training Loss: 0.0055, Initial Validation Loss: 0.1327, Validation Loss: 0.0258,V Acc: 0.8532, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6250
Stopping early at Epoch (base 0): 27  Rolling back to Epoch (base 0): 22  Top Validation Acc: 0.948051948051948
13 3 [array([0.36156029, 0.04159102, 0.04133674, 0.16193788, 0.3935741 ],
      dtype=float32)]
Fold [5/5] Epoch [0/100] Initial Loss: 0.1420, Training Loss: 0.1420, Initial Validation Loss: 0.1321, Validation Loss: 0.1321,V Acc: 0.2500, Top 70th Acc: 0.3158, Bottom 30th Acc: 0.0938
Fold [5/5] Epoch [10/100] Initial Loss: 0.1420, Training Loss: 0.0160, Initial Validation Loss: 0.1321, Validation Loss: 0.0354,V Acc: 0.8333, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.5625
Training on 21 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 46
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 21 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 47
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 21 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 48
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 21 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 49
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 21 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 50
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 21 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 51
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 21 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 52
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 21 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 53
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 21 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 54
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 21 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 55
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 21 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 56
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 21 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 57
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 21 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 58
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 21 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 59
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 21 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 60
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 21 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 61
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 21 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 62
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 21 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 63
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 21 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 64
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 21 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 65
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 21 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 66
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 21 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 67
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 21 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 68
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 21 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 69
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 21 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 70
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 21 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 71
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 21 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 72
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 21 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 73
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 21 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 74
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 21 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 75
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 21 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 76
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 21 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 77
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 21 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 78
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 21 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 79
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 21 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 80
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 21 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 81
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 21 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 82
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 21 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 83
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 21 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 84
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 21 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 85
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 21 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 86
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 21 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 87
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 21 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 88
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 21 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 89
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 21 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 90
Training size: 438 18  Top Validation Acc: 0.961038961038961
Fold [5/5] Epoch [0/100] Initial Loss: 0.1429, Training Loss: 0.1429, Initial Validation Loss: 0.1328, Validation Loss: 0.1328,V Acc: 0.3333, Top 70th Acc: 0.3158, Bottom 30th Acc: 0.3750
Fold [5/5] Epoch [10/100] Initial Loss: 0.1429, Training Loss: 0.0371, Initial Validation Loss: 0.1328, Validation Loss: 0.0524,V Acc: 0.7130, Top 70th Acc: 0.8684, Bottom 30th Acc: 0.3438
Fold [5/5] Epoch [20/100] Initial Loss: 0.1429, Training Loss: 0.0240, Initial Validation Loss: 0.1328, Validation Loss: 0.0464,V Acc: 0.7593, Top 70th Acc: 0.8684, Bottom 30th Acc: 0.5000
Fold [5/5] Epoch [30/100] Initial Loss: 0.1429, Training Loss: 0.0210, Initial Validation Loss: 0.1328, Validation Loss: 0.0437,V Acc: 0.7685, Top 70th Acc: 0.9079, Bottom 30th Acc: 0.4375
Fold [5/5] Epoch [40/100] Initial Loss: 0.1429, Training Loss: 0.0199, Initial Validation Loss: 0.1328, Validation Loss: 0.0429,V Acc: 0.7963, Top 70th Acc: 0.8816, Bottom 30th Acc: 0.5938
Stopping early at Epoch (base 0): 41  Rolling back to Epoch (base 0): 36  Top Validation Acc: 0.881578947368421
Running train_nn.py with seed 16
CUDA:False
Training samples count:  550
Training on 20 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1389, Training Loss: 0.1389, Initial Validation Loss: 0.1396, Validation Loss: 0.1396,V Acc: 0.3125, Top 70th Acc: 0.3165, Bottom 30th Acc: 0.3030
Fold [1/5] Epoch [10/100] Initial Loss: 0.1389, Training Loss: 0.0444, Initial Validation Loss: 0.1396, Validation Loss: 0.0504,V Acc: 0.8214, Top 70th Acc: 0.8734, Bottom 30th Acc: 0.6970
Fold [1/5] Epoch [20/100] Initial Loss: 0.1389, Training Loss: 0.0262, Initial Validation Loss: 0.1396, Validation Loss: 0.0358,V Acc: 0.8482, Top 70th Acc: 0.9367, Bottom 30th Acc: 0.6364
Fold [1/5] Epoch [30/100] Initial Loss: 0.1389, Training Loss: 0.0229, Initial Validation Loss: 0.1396, Validation Loss: 0.0347,V Acc: 0.8661, Top 70th Acc: 0.9367, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 35  Rolling back to Epoch (base 0): 30  Top Validation Acc: 0.9367088607594937
16 0 [array([0.40931347, 0.0653566 , 0.11511607, 0.273732  , 0.13648182],
      dtype=float32)]
Fold [2/5] Epoch [0/100] Initial Loss: 0.1391, Training Loss: 0.1391, Initial Validation Loss: 0.1332, Validation Loss: 0.1332,V Acc: 0.2703, Top 70th Acc: 0.3718, Bottom 30th Acc: 0.0303
Fold [2/5] Epoch [10/100] Initial Loss: 0.1391, Training Loss: 0.0446, Initial Validation Loss: 0.1332, Validation Loss: 0.0435,V Acc: 0.7658, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.4242
Fold [2/5] Epoch [20/100] Initial Loss: 0.1391, Training Loss: 0.0249, Initial Validation Loss: 0.1332, Validation Loss: 0.0310,V Acc: 0.8468, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.9358974358974359
Fold [3/5] Epoch [0/100] Initial Loss: 0.1403, Training Loss: 0.1403, Initial Validation Loss: 0.1340, Validation Loss: 0.1340,V Acc: 0.3091, Top 70th Acc: 0.3636, Bottom 30th Acc: 0.1818
Fold [3/5] Epoch [10/100] Initial Loss: 0.1403, Training Loss: 0.0352, Initial Validation Loss: 0.1340, Validation Loss: 0.0445,V Acc: 0.8000, Top 70th Acc: 0.8701, Bottom 30th Acc: 0.6364
Fold [3/5] Epoch [20/100] Initial Loss: 0.1403, Training Loss: 0.0235, Initial Validation Loss: 0.1340, Validation Loss: 0.0351,V Acc: 0.8455, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.6970
Fold [3/5] Epoch [30/100] Initial Loss: 0.1403, Training Loss: 0.0215, Initial Validation Loss: 0.1340, Validation Loss: 0.0348,V Acc: 0.8455, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 32  Rolling back to Epoch (base 0): 27  Top Validation Acc: 0.9090909090909091
Fold [4/5] Epoch [0/100] Initial Loss: 0.1433, Training Loss: 0.1433, Initial Validation Loss: 0.1337, Validation Loss: 0.1337,V Acc: 0.2385, Top 70th Acc: 0.2597, Bottom 30th Acc: 0.1875
Fold [4/5] Epoch [10/100] Initial Loss: 0.1433, Training Loss: 0.0397, Initial Validation Loss: 0.1337, Validation Loss: 0.0400,V Acc: 0.8073, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.5625
Fold [4/5] Epoch [20/100] Initial Loss: 0.1433, Training Loss: 0.0247, Initial Validation Loss: 0.1337, Validation Loss: 0.0323,V Acc: 0.8257, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.5625
Stopping early at Epoch (base 0): 28  Rolling back to Epoch (base 0): 23  Top Validation Acc: 0.961038961038961
Fold [5/5] Epoch [0/100] Initial Loss: 0.1363, Training Loss: 0.1363, Initial Validation Loss: 0.1280, Validation Loss: 0.1280,V Acc: 0.3056, Top 70th Acc: 0.3026, Bottom 30th Acc: 0.3125
Fold [5/5] Epoch [10/100] Initial Loss: 0.1363, Training Loss: 0.0379, Initial Validation Loss: 0.1280, Validation Loss: 0.0453,V Acc: 0.7685, Top 70th Acc: 0.8816, Bottom 30th Acc: 0.5000
Fold [5/5] Epoch [20/100] Initial Loss: 0.1363, Training Loss: 0.0232, Initial Validation Loss: 0.1280, Validation Loss: 0.0380,V Acc: 0.8241, Top 70th Acc: 0.8947, Bottom 30th Acc: 0.6562
Fold [5/5] Epoch [30/100] Initial Loss: 0.1363, Training Loss: 0.0208, Initial Validation Loss: 0.1280, Validation Loss: 0.0384,V Acc: 0.7870, Top 70th Acc: 0.8816, Bottom 30th Acc: 0.5625
Stopping early at Epoch (base 0): 30  Rolling back to Epoch (base 0): 25  Top Validation Acc: 0.881578947368421
Running train_nn.py with seed 17
CUDA:False
Training samples count:  550
Training on 20 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1379, Training Loss: 0.1379, Initial Validation Loss: 0.1328, Validation Loss: 0.1328,V Acc: 0.3482, Top 70th Acc: 0.4051, Bottom 30th Acc: 0.2121
Fold [1/5] Epoch [10/100] Initial Loss: 0.1379, Training Loss: 0.0348, Initial Validation Loss: 0.1328, Validation Loss: 0.0411,V Acc: 0.8125, Top 70th Acc: 0.8987, Bottom 30th Acc: 0.6061
Fold [1/5] Epoch [20/100] Initial Loss: 0.1379, Training Loss: 0.0221, Initial Validation Loss: 0.1328, Validation Loss: 0.0350,V Acc: 0.8393, Top 70th Acc: 0.8987, Bottom 30th Acc: 0.6970
Fold [1/5] Epoch [30/100] Initial Loss: 0.1379, Training Loss: 0.0201, Initial Validation Loss: 0.1328, Validation Loss: 0.0360,V Acc: 0.8393, Top 70th Acc: 0.8987, Bottom 30th Acc: 0.6970
Fold [1/5] Epoch [40/100] Initial Loss: 0.1379, Training Loss: 0.0191, Initial Validation Loss: 0.1328, Validation Loss: 0.0348,V Acc: 0.8482, Top 70th Acc: 0.9114, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 42  Rolling back to Epoch (base 0): 37  Top Validation Acc: 0.9240506329113924
Fold [2/5] Epoch [0/100] Initial Loss: 0.1443, Training Loss: 0.1443, Initial Validation Loss: 0.1362, Validation Loss: 0.1362,V Acc: 0.3694, Top 70th Acc: 0.4744, Bottom 30th Acc: 0.1212
Fold [2/5] Epoch [10/100] Initial Loss: 0.1443, Training Loss: 0.0364, Initial Validation Loss: 0.1362, Validation Loss: 0.0511,V Acc: 0.7658, Top 70th Acc: 0.8333, Bottom 30th Acc: 0.6061
Fold [2/5] Epoch [20/100] Initial Loss: 0.1443, Training Loss: 0.0230, Initial Validation Loss: 0.1362, Validation Loss: 0.0459,V Acc: 0.7748, Top 70th Acc: 0.8718, Bottom 30th Acc: 0.5455
Fold [2/5] Epoch [30/100] Initial Loss: 0.1443, Training Loss: 0.0191, Initial Validation Loss: 0.1362, Validation Loss: 0.0419,V Acc: 0.7838, Top 70th Acc: 0.8846, Bottom 30th Acc: 0.5455
Fold [2/5] Epoch [40/100] Initial Loss: 0.1443, Training Loss: 0.0180, Initial Validation Loss: 0.1362, Validation Loss: 0.0410,V Acc: 0.7658, Top 70th Acc: 0.8974, Bottom 30th Acc: 0.4545
Stopping early at Epoch (base 0): 43  Rolling back to Epoch (base 0): 38  Top Validation Acc: 0.8974358974358975
Fold [3/5] Epoch [0/100] Initial Loss: 0.1375, Training Loss: 0.1375, Initial Validation Loss: 0.1358, Validation Loss: 0.1358,V Acc: 0.4000, Top 70th Acc: 0.4935, Bottom 30th Acc: 0.1818
Fold [3/5] Epoch [10/100] Initial Loss: 0.1375, Training Loss: 0.0338, Initial Validation Loss: 0.1358, Validation Loss: 0.0358,V Acc: 0.8636, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.6970
Fold [3/5] Epoch [20/100] Initial Loss: 0.1375, Training Loss: 0.0242, Initial Validation Loss: 0.1358, Validation Loss: 0.0282,V Acc: 0.8909, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.961038961038961
Fold [4/5] Epoch [0/100] Initial Loss: 0.1409, Training Loss: 0.1409, Initial Validation Loss: 0.1301, Validation Loss: 0.1301,V Acc: 0.2477, Top 70th Acc: 0.3506, Bottom 30th Acc: 0.0000
Fold [1/5] Epoch [20/100] Initial Loss: 0.1419, Training Loss: 0.0236, Initial Validation Loss: 0.1382, Validation Loss: 0.0440,V Acc: 0.7679, Top 70th Acc: 0.8734, Bottom 30th Acc: 0.5152
Fold [1/5] Epoch [30/100] Initial Loss: 0.1419, Training Loss: 0.0161, Initial Validation Loss: 0.1382, Validation Loss: 0.0396,V Acc: 0.8125, Top 70th Acc: 0.8987, Bottom 30th Acc: 0.6061
Fold [1/5] Epoch [40/100] Initial Loss: 0.1419, Training Loss: 0.0124, Initial Validation Loss: 0.1382, Validation Loss: 0.0349,V Acc: 0.8393, Top 70th Acc: 0.9241, Bottom 30th Acc: 0.6364
Fold [1/5] Epoch [50/100] Initial Loss: 0.1419, Training Loss: 0.0112, Initial Validation Loss: 0.1382, Validation Loss: 0.0333,V Acc: 0.8393, Top 70th Acc: 0.9241, Bottom 30th Acc: 0.6364
Fold [1/5] Epoch [60/100] Initial Loss: 0.1419, Training Loss: 0.0103, Initial Validation Loss: 0.1382, Validation Loss: 0.0323,V Acc: 0.8571, Top 70th Acc: 0.9241, Bottom 30th Acc: 0.6970
Fold [1/5] Epoch [70/100] Initial Loss: 0.1419, Training Loss: 0.0101, Initial Validation Loss: 0.1382, Validation Loss: 0.0315,V Acc: 0.8482, Top 70th Acc: 0.9367, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 71  Rolling back to Epoch (base 0): 66  Top Validation Acc: 0.9367088607594937
Fold [2/5] Epoch [0/100] Initial Loss: 0.1377, Training Loss: 0.1377, Initial Validation Loss: 0.1290, Validation Loss: 0.1290,V Acc: 0.4054, Top 70th Acc: 0.4487, Bottom 30th Acc: 0.3030
Fold [2/5] Epoch [10/100] Initial Loss: 0.1377, Training Loss: 0.0274, Initial Validation Loss: 0.1290, Validation Loss: 0.0419,V Acc: 0.8018, Top 70th Acc: 0.8718, Bottom 30th Acc: 0.6364
Fold [2/5] Epoch [20/100] Initial Loss: 0.1377, Training Loss: 0.0145, Initial Validation Loss: 0.1290, Validation Loss: 0.0360,V Acc: 0.8018, Top 70th Acc: 0.8846, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.8717948717948718
Fold [3/5] Epoch [0/100] Initial Loss: 0.1441, Training Loss: 0.1441, Initial Validation Loss: 0.1387, Validation Loss: 0.1387,V Acc: 0.3091, Top 70th Acc: 0.3377, Bottom 30th Acc: 0.2424
Fold [3/5] Epoch [10/100] Initial Loss: 0.1441, Training Loss: 0.0328, Initial Validation Loss: 0.1387, Validation Loss: 0.0437,V Acc: 0.7909, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.4848
Fold [3/5] Epoch [20/100] Initial Loss: 0.1441, Training Loss: 0.0155, Initial Validation Loss: 0.1387, Validation Loss: 0.0289,V Acc: 0.8818, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.6970
Fold [3/5] Epoch [30/100] Initial Loss: 0.1441, Training Loss: 0.0131, Initial Validation Loss: 0.1387, Validation Loss: 0.0285,V Acc: 0.8818, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.7273
Stopping early at Epoch (base 0): 32  Rolling back to Epoch (base 0): 27  Top Validation Acc: 0.961038961038961
Fold [4/5] Epoch [0/100] Initial Loss: 0.1394, Training Loss: 0.1394, Initial Validation Loss: 0.1277, Validation Loss: 0.1277,V Acc: 0.3119, Top 70th Acc: 0.3506, Bottom 30th Acc: 0.2188
Fold [4/5] Epoch [10/100] Initial Loss: 0.1394, Training Loss: 0.0410, Initial Validation Loss: 0.1277, Validation Loss: 0.0406,V Acc: 0.8073, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.5625
Fold [4/5] Epoch [20/100] Initial Loss: 0.1394, Training Loss: 0.0164, Initial Validation Loss: 0.1277, Validation Loss: 0.0267,V Acc: 0.8349, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.5000
Stopping early at Epoch (base 0): 29  Rolling back to Epoch (base 0): 24  Top Validation Acc: 0.987012987012987
17 3 [array([0.8206507 , 0.02704771, 0.02089201, 0.05897133, 0.07243825],
      dtype=float32)]
Fold [5/5] Epoch [0/100] Initial Loss: 0.1395, Training Loss: 0.1395, Initial Validation Loss: 0.1332, Validation Loss: 0.1332,V Acc: 0.2685, Top 70th Acc: 0.2763, Bottom 30th Acc: 0.2500
Fold [5/5] Epoch [10/100] Initial Loss: 0.1395, Training Loss: 0.0274, Initial Validation Loss: 0.1332, Validation Loss: 0.0391,V Acc: 0.8148, Top 70th Acc: 0.8947, Bottom 30th Acc: 0.6250
Fold [5/5] Epoch [20/100] Initial Loss: 0.1395, Training Loss: 0.0132, Initial Validation Loss: 0.1332, Validation Loss: 0.0351,V Acc: 0.8148, Top 70th Acc: 0.9211, Bottom 30th Acc: 0.5625
Stopping early at Epoch (base 0): 21  Rolling back to Epoch (base 0): 16  Top Validation Acc: 0.9210526315789473
Running train_nn.py with seed 18
CUDA:False
Training samples count:  550
Training on 40 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1391, Training Loss: 0.1391, Initial Validation Loss: 0.1368, Validation Loss: 0.1368,V Acc: 0.2768, Top 70th Acc: 0.2785, Bottom 30th Acc: 0.2727
Fold [1/5] Epoch [10/100] Initial Loss: 0.1391, Training Loss: 0.0242, Initial Validation Loss: 0.1368, Validation Loss: 0.0323,V Acc: 0.8571, Top 70th Acc: 0.9494, Bottom 30th Acc: 0.6364
Fold [1/5] Epoch [20/100] Initial Loss: 0.1391, Training Loss: 0.0150, Initial Validation Loss: 0.1368, Validation Loss: 0.0286,V Acc: 0.8482, Top 70th Acc: 0.9620, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.9620253164556962
18 0 [array([0.6670208 , 0.05279471, 0.05563306, 0.04812486, 0.17642663],
      dtype=float32)]
Fold [2/5] Epoch [0/100] Initial Loss: 0.1408, Training Loss: 0.1408, Initial Validation Loss: 0.1356, Validation Loss: 0.1356,V Acc: 0.2162, Top 70th Acc: 0.2821, Bottom 30th Acc: 0.0606
Fold [2/5] Epoch [10/100] Initial Loss: 0.1408, Training Loss: 0.0445, Initial Validation Loss: 0.1356, Validation Loss: 0.0516,V Acc: 0.7477, Top 70th Acc: 0.8846, Bottom 30th Acc: 0.4242
Fold [2/5] Epoch [20/100] Initial Loss: 0.1408, Training Loss: 0.0187, Initial Validation Loss: 0.1356, Validation Loss: 0.0305,V Acc: 0.8829, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.7576
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.9615384615384616
Fold [3/5] Epoch [0/100] Initial Loss: 0.1384, Training Loss: 0.1384, Initial Validation Loss: 0.1302, Validation Loss: 0.1302,V Acc: 0.2636, Top 70th Acc: 0.3636, Bottom 30th Acc: 0.0303
Fold [3/5] Epoch [10/100] Initial Loss: 0.1384, Training Loss: 0.0293, Initial Validation Loss: 0.1302, Validation Loss: 0.0355,V Acc: 0.8636, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.7273
Fold [3/5] Epoch [20/100] Initial Loss: 0.1384, Training Loss: 0.0145, Initial Validation Loss: 0.1302, Validation Loss: 0.0293,V Acc: 0.8636, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.935064935064935
Fold [4/5] Epoch [0/100] Initial Loss: 0.1393, Training Loss: 0.1393, Initial Validation Loss: 0.1314, Validation Loss: 0.1314,V Acc: 0.3853, Top 70th Acc: 0.3766, Bottom 30th Acc: 0.4062
Fold [4/5] Epoch [10/100] Initial Loss: 0.1393, Training Loss: 0.0266, Initial Validation Loss: 0.1314, Validation Loss: 0.0346,V Acc: 0.8624, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.6875
Fold [4/5] Epoch [20/100] Initial Loss: 0.1393, Training Loss: 0.0140, Initial Validation Loss: 0.1314, Validation Loss: 0.0293,V Acc: 0.8532, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.6562
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.948051948051948
Fold [5/5] Epoch [0/100] Initial Loss: 0.1367, Training Loss: 0.1367, Initial Validation Loss: 0.1278, Validation Loss: 0.1278,V Acc: 0.3333, Top 70th Acc: 0.4211, Bottom 30th Acc: 0.1250
Fold [5/5] Epoch [10/100] Initial Loss: 0.1367, Training Loss: 0.0353, Initial Validation Loss: 0.1278, Validation Loss: 0.0367,V Acc: 0.8056, Top 70th Acc: 0.9211, Bottom 30th Acc: 0.5312
Fold [5/5] Epoch [20/100] Initial Loss: 0.1367, Training Loss: 0.0156, Initial Validation Loss: 0.1278, Validation Loss: 0.0297,V Acc: 0.8241, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.5312
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.9473684210526315
Running train_nn.py with seed 19
CUDA:False
Training samples count:  550
Training on 40 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1377, Training Loss: 0.1377, Initial Validation Loss: 0.1417, Validation Loss: 0.1417,V Acc: 0.2500, Top 70th Acc: 0.2911, Bottom 30th Acc: 0.1515
Fold [1/5] Epoch [10/100] Initial Loss: 0.1377, Training Loss: 0.0304, Initial Validation Loss: 0.1417, Validation Loss: 0.0349,V Acc: 0.8750, Top 70th Acc: 0.9747, Bottom 30th Acc: 0.6364
Fold [3/5] Epoch [10/100] Initial Loss: 0.1332, Training Loss: 0.0258, Initial Validation Loss: 0.1186, Validation Loss: 0.0318,V Acc: 0.8636, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.6364
Fold [3/5] Epoch [20/100] Initial Loss: 0.1332, Training Loss: 0.0146, Initial Validation Loss: 0.1186, Validation Loss: 0.0332,V Acc: 0.8364, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.948051948051948
Fold [4/5] Epoch [0/100] Initial Loss: 0.1308, Training Loss: 0.1308, Initial Validation Loss: 0.1188, Validation Loss: 0.1188,V Acc: 0.5321, Top 70th Acc: 0.6494, Bottom 30th Acc: 0.2500
Fold [4/5] Epoch [10/100] Initial Loss: 0.1308, Training Loss: 0.0240, Initial Validation Loss: 0.1188, Validation Loss: 0.0223,V Acc: 0.9266, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.8750
Fold [4/5] Epoch [20/100] Initial Loss: 0.1308, Training Loss: 0.0158, Initial Validation Loss: 0.1188, Validation Loss: 0.0181,V Acc: 0.9174, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.7812
Stopping early at Epoch (base 0): 22  Rolling back to Epoch (base 0): 17  Top Validation Acc: 0.961038961038961
Fold [5/5] Epoch [0/100] Initial Loss: 0.1394, Training Loss: 0.1394, Initial Validation Loss: 0.1257, Validation Loss: 0.1257,V Acc: 0.3611, Top 70th Acc: 0.3684, Bottom 30th Acc: 0.3438
Fold [5/5] Epoch [10/100] Initial Loss: 0.1394, Training Loss: 0.0201, Initial Validation Loss: 0.1257, Validation Loss: 0.0391,V Acc: 0.8333, Top 70th Acc: 0.9079, Bottom 30th Acc: 0.6562
Stopping early at Epoch (base 0): 18  Rolling back to Epoch (base 0): 13  Top Validation Acc: 0.9473684210526315
Running train_nn.py with seed 24
CUDA:False
Training samples count:  550
Training on 21 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1338, Training Loss: 0.1338, Initial Validation Loss: 0.1244, Validation Loss: 0.1244,V Acc: 0.4196, Top 70th Acc: 0.5063, Bottom 30th Acc: 0.2121
Fold [1/5] Epoch [10/100] Initial Loss: 0.1338, Training Loss: 0.0230, Initial Validation Loss: 0.1244, Validation Loss: 0.0263,V Acc: 0.8661, Top 70th Acc: 0.9241, Bottom 30th Acc: 0.7273
Fold [1/5] Epoch [20/100] Initial Loss: 0.1338, Training Loss: 0.0158, Initial Validation Loss: 0.1244, Validation Loss: 0.0248,V Acc: 0.8839, Top 70th Acc: 0.9241, Bottom 30th Acc: 0.7879
Stopping early at Epoch (base 0): 22  Rolling back to Epoch (base 0): 17  Top Validation Acc: 0.9367088607594937
Fold [2/5] Epoch [0/100] Initial Loss: 0.1374, Training Loss: 0.1374, Initial Validation Loss: 0.1236, Validation Loss: 0.1236,V Acc: 0.4144, Top 70th Acc: 0.5128, Bottom 30th Acc: 0.1818
Fold [2/5] Epoch [10/100] Initial Loss: 0.1374, Training Loss: 0.0224, Initial Validation Loss: 0.1236, Validation Loss: 0.0288,V Acc: 0.8468, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 17  Rolling back to Epoch (base 0): 12  Top Validation Acc: 0.9487179487179487
Fold [3/5] Epoch [0/100] Initial Loss: 0.1281, Training Loss: 0.1281, Initial Validation Loss: 0.1173, Validation Loss: 0.1173,V Acc: 0.4818, Top 70th Acc: 0.6234, Bottom 30th Acc: 0.1515
Fold [3/5] Epoch [10/100] Initial Loss: 0.1281, Training Loss: 0.0209, Initial Validation Loss: 0.1173, Validation Loss: 0.0225,V Acc: 0.9091, Top 70th Acc: 0.9870, Bottom 30th Acc: 0.7273
Stopping early at Epoch (base 0): 16  Rolling back to Epoch (base 0): 11  Top Validation Acc: 0.987012987012987
24 2 [array([0.7079126 , 0.0292318 , 0.05871096, 0.14927556, 0.05486916],
      dtype=float32)]
Fold [4/5] Epoch [0/100] Initial Loss: 0.1343, Training Loss: 0.1343, Initial Validation Loss: 0.1256, Validation Loss: 0.1256,V Acc: 0.4404, Top 70th Acc: 0.5325, Bottom 30th Acc: 0.2188
Fold [4/5] Epoch [10/100] Initial Loss: 0.1343, Training Loss: 0.0252, Initial Validation Loss: 0.1256, Validation Loss: 0.0315,V Acc: 0.8716, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.6562
Fold [4/5] Epoch [20/100] Initial Loss: 0.1343, Training Loss: 0.0155, Initial Validation Loss: 0.1256, Validation Loss: 0.0241,V Acc: 0.8899, Top 70th Acc: 0.9870, Bottom 30th Acc: 0.6562
Fold [4/5] Epoch [30/100] Initial Loss: 0.1343, Training Loss: 0.0155, Initial Validation Loss: 0.1256, Validation Loss: 0.0238,V Acc: 0.8807, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.6562
Stopping early at Epoch (base 0): 30  Rolling back to Epoch (base 0): 25  Top Validation Acc: 0.974025974025974
Fold [5/5] Epoch [0/100] Initial Loss: 0.1352, Training Loss: 0.1352, Initial Validation Loss: 0.1183, Validation Loss: 0.1183,V Acc: 0.3889, Top 70th Acc: 0.4737, Bottom 30th Acc: 0.1875
Fold [5/5] Epoch [10/100] Initial Loss: 0.1352, Training Loss: 0.0227, Initial Validation Loss: 0.1183, Validation Loss: 0.0343,V Acc: 0.8148, Top 70th Acc: 0.9211, Bottom 30th Acc: 0.5625
Fold [5/5] Epoch [20/100] Initial Loss: 0.1352, Training Loss: 0.0157, Initial Validation Loss: 0.1183, Validation Loss: 0.0274,V Acc: 0.8704, Top 70th Acc: 0.9737, Bottom 30th Acc: 0.6250
Stopping early at Epoch (base 0): 20  Rolling back to Epoch (base 0): 15  Top Validation Acc: 0.9736842105263158
Running train_nn.py with seed 25
CUDA:False
Training samples count:  550
Training on 21 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1328, Training Loss: 0.1328, Initial Validation Loss: 0.1226, Validation Loss: 0.1226,V Acc: 0.4911, Top 70th Acc: 0.6329, Bottom 30th Acc: 0.1515
Fold [1/5] Epoch [10/100] Initial Loss: 0.1328, Training Loss: 0.0272, Initial Validation Loss: 0.1226, Validation Loss: 0.0399,V Acc: 0.8125, Top 70th Acc: 0.8734, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 19  Rolling back to Epoch (base 0): 14  Top Validation Acc: 0.9367088607594937
Fold [2/5] Epoch [0/100] Initial Loss: 0.1380, Training Loss: 0.1380, Initial Validation Loss: 0.1301, Validation Loss: 0.1301,V Acc: 0.5405, Top 70th Acc: 0.6667, Bottom 30th Acc: 0.2424
Fold [2/5] Epoch [10/100] Initial Loss: 0.1380, Training Loss: 0.0266, Initial Validation Loss: 0.1301, Validation Loss: 0.0290,V Acc: 0.8829, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.6970
Fold [2/5] Epoch [20/100] Initial Loss: 0.1380, Training Loss: 0.0164, Initial Validation Loss: 0.1301, Validation Loss: 0.0251,V Acc: 0.8919, Top 70th Acc: 0.9872, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 28  Rolling back to Epoch (base 0): 23  Top Validation Acc: 0.9487179487179487
Fold [3/5] Epoch [0/100] Initial Loss: 0.1385, Training Loss: 0.1385, Initial Validation Loss: 0.1304, Validation Loss: 0.1304,V Acc: 0.4727, Top 70th Acc: 0.5844, Bottom 30th Acc: 0.2121
Fold [3/5] Epoch [10/100] Initial Loss: 0.1385, Training Loss: 0.0230, Initial Validation Loss: 0.1304, Validation Loss: 0.0344,V Acc: 0.8182, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.4545
Stopping early at Epoch (base 0): 19  Rolling back to Epoch (base 0): 14  Top Validation Acc: 0.974025974025974
25 2 [array([0.82313466, 0.01848397, 0.02870582, 0.0757153 , 0.05396029],
      dtype=float32)]
Fold [4/5] Epoch [0/100] Initial Loss: 0.1315, Training Loss: 0.1315, Initial Validation Loss: 0.1155, Validation Loss: 0.1155,V Acc: 0.4679, Top 70th Acc: 0.6104, Bottom 30th Acc: 0.1250
Fold [4/5] Epoch [10/100] Initial Loss: 0.1315, Training Loss: 0.0210, Initial Validation Loss: 0.1155, Validation Loss: 0.0325,V Acc: 0.8532, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.6875
Fold [4/5] Epoch [20/100] Initial Loss: 0.1315, Training Loss: 0.0163, Initial Validation Loss: 0.1155, Validation Loss: 0.0319,V Acc: 0.8349, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.5938
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.987012987012987
Fold [5/5] Epoch [0/100] Initial Loss: 0.1338, Training Loss: 0.1338, Initial Validation Loss: 0.1157, Validation Loss: 0.1157,V Acc: 0.3981, Top 70th Acc: 0.5132, Bottom 30th Acc: 0.1250
Fold [5/5] Epoch [10/100] Initial Loss: 0.1338, Training Loss: 0.0206, Initial Validation Loss: 0.1157, Validation Loss: 0.0315,V Acc: 0.8611, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.6250
Fold [5/5] Epoch [20/100] Initial Loss: 0.1338, Training Loss: 0.0156, Initial Validation Loss: 0.1157, Validation Loss: 0.0321,V Acc: 0.8519, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.6562
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0):
Fold [5/5] Epoch [20/100] Initial Loss: 0.1360, Training Loss: 0.0177, Initial Validation Loss: 0.1294, Validation Loss: 0.0304,V Acc: 0.8241, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.5312
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.9473684210526315
Running train_nn.py with seed 18
CUDA:False
Training samples count:  550
Training on 30 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1403, Training Loss: 0.1403, Initial Validation Loss: 0.1345, Validation Loss: 0.1345,V Acc: 0.3393, Top 70th Acc: 0.4430, Bottom 30th Acc: 0.0909
Fold [1/5] Epoch [10/100] Initial Loss: 0.1403, Training Loss: 0.0359, Initial Validation Loss: 0.1345, Validation Loss: 0.0456,V Acc: 0.7857, Top 70th Acc: 0.8987, Bottom 30th Acc: 0.5152
Fold [1/5] Epoch [20/100] Initial Loss: 0.1403, Training Loss: 0.0198, Initial Validation Loss: 0.1345, Validation Loss: 0.0344,V Acc: 0.8304, Top 70th Acc: 0.9620, Bottom 30th Acc: 0.5152
Stopping early at Epoch (base 0): 28  Rolling back to Epoch (base 0): 23  Top Validation Acc: 0.9620253164556962
18 0 [array([0.67671597, 0.08792505, 0.04761519, 0.1206407 , 0.06710301],
      dtype=float32)]
Fold [2/5] Epoch [0/100] Initial Loss: 0.1377, Training Loss: 0.1377, Initial Validation Loss: 0.1335, Validation Loss: 0.1335,V Acc: 0.3514, Top 70th Acc: 0.4359, Bottom 30th Acc: 0.1515
Fold [2/5] Epoch [10/100] Initial Loss: 0.1377, Training Loss: 0.0390, Initial Validation Loss: 0.1335, Validation Loss: 0.0442,V Acc: 0.7658, Top 70th Acc: 0.8846, Bottom 30th Acc: 0.4848
Fold [2/5] Epoch [20/100] Initial Loss: 0.1377, Training Loss: 0.0201, Initial Validation Loss: 0.1335, Validation Loss: 0.0285,V Acc: 0.8378, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.9615384615384616
Fold [3/5] Epoch [0/100] Initial Loss: 0.1422, Training Loss: 0.1422, Initial Validation Loss: 0.1355, Validation Loss: 0.1355,V Acc: 0.3273, Top 70th Acc: 0.2987, Bottom 30th Acc: 0.3939
Fold [3/5] Epoch [10/100] Initial Loss: 0.1422, Training Loss: 0.0528, Initial Validation Loss: 0.1355, Validation Loss: 0.0565,V Acc: 0.7182, Top 70th Acc: 0.8312, Bottom 30th Acc: 0.4545
Fold [3/5] Epoch [20/100] Initial Loss: 0.1422, Training Loss: 0.0208, Initial Validation Loss: 0.1355, Validation Loss: 0.0329,V Acc: 0.8364, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.935064935064935
Fold [4/5] Epoch [0/100] Initial Loss: 0.1417, Training Loss: 0.1417, Initial Validation Loss: 0.1318, Validation Loss: 0.1318,V Acc: 0.3670, Top 70th Acc: 0.3896, Bottom 30th Acc: 0.3125
Fold [4/5] Epoch [10/100] Initial Loss: 0.1417, Training Loss: 0.0446, Initial Validation Loss: 0.1318, Validation Loss: 0.0505,V Acc: 0.7890, Top 70th Acc: 0.8831, Bottom 30th Acc: 0.5625
Fold [4/5] Epoch [20/100] Initial Loss: 0.1417, Training Loss: 0.0217, Initial Validation Loss: 0.1318, Validation Loss: 0.0338,V Acc: 0.8440, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.5938
Fold [4/5] Epoch [30/100] Initial Loss: 0.1417, Training Loss: 0.0175, Initial Validation Loss: 0.1318, Validation Loss: 0.0314,V Acc: 0.8716, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.7500
Stopping early at Epoch (base 0): 33  Rolling back to Epoch (base 0): 28  Top Validation Acc: 0.935064935064935
Fold [5/5] Epoch [0/100] Initial Loss: 0.1420, Training Loss: 0.1420, Initial Validation Loss: 0.1323, Validation Loss: 0.1323,V Acc: 0.2685, Top 70th Acc: 0.2763, Bottom 30th Acc: 0.2500
Fold [5/5] Epoch [10/100] Initial Loss: 0.1420, Training Loss: 0.0361, Initial Validation Loss: 0.1323, Validation Loss: 0.0340,V Acc: 0.8333, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.5625
Fold [5/5] Epoch [20/100] Initial Loss: 0.1420, Training Loss: 0.0201, Initial Validation Loss: 0.1323, Validation Loss: 0.0296,V Acc: 0.8056, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.4688
Stopping early at Epoch (base 0): 20  Rolling back to Epoch (base 0): 15  Top Validation Acc: 0.9473684210526315
Running train_nn.py with seed 19
CUDA:False
Training samples count:  550
Training on 30 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1367, Training Loss: 0.1367, Initial Validation Loss: 0.1417, Validation Loss: 0.1417,V Acc: 0.2500, Top 70th Acc: 0.3038, Bottom 30th Acc: 0.1212
Fold [1/5] Epoch [10/100] Initial Loss: 0.1367, Training Loss: 0.0415, Initial Validation Loss: 0.1417, Validation Loss: 0.0417,V Acc: 0.8571, Top 70th Acc: 0.9241, Bottom 30th Acc: 0.6970
Fold [1/5] Epoch [20/100] Initial Loss: 0.1367, Training Loss: 0.0201, Initial Validation Loss: 0.1417, Validation Loss: 0.0282,V Acc: 0.8839, Top 70th Acc: 0.9494, Bottom 30th Acc: 0.7273
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.9620253164556962
Fold [2/5] Epoch [0/100] Initial Loss: 0.1398, Training Loss: 0.1398, Initial Validation Loss: 0.1292, Validation Loss: 0.1292,V Acc: 0.3063, Top 70th Acc: 0.2821, Bottom 30th Acc: 0.3636
Fold [2/5] Epoch [10/100] Initial Loss: 0.1398, Training Loss: 0.0286, Initial Validation Loss: 0.1292, Validation Loss: 0.0365,V Acc: 0.8108, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.5455
Fold [2/5] Epoch [20/100] Initial Loss: 0.1398, Training Loss: 0.0195, Initial Validation Loss: 0.1292, Validation Loss: 0.0306,V Acc: 0.7838, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.3939
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.9615384615384616
19 1 [array([0.64359283, 0.06550216, 0.04943953, 0.06681349, 0.17465201],
      dtype=float32)]
Fold [3/5] Epoch [0/100] Initial Loss: 0.1412, Training Loss: 0.1412, Initial Validation Loss: 0.1340, Validation Loss: 0.1340,V Acc: 0.2545, Top 70th Acc: 0.2468, Bottom 30th Acc: 0.2727
Fold [3/5] Epoch [10/100] Initial Loss: 0.1412, Training Loss: 0.0300, Initial Validation Loss: 0.1340, Validation Loss: 0.0398,V Acc: 0.7909, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.4242
Fold [3/5] Epoch [20/100] Initial Loss: 0.1412, Training Loss: 0.0183, Initial Validation Loss: 0.1340, Validation Loss: 0.0399,V Acc: 0.8000, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 20  Rolling back to Epoch (base 0): 15  Top Validation Acc: 0.9090909090909091
Fold [4/5] Epoch [0/100] Initial Loss: 0.1399, Training Loss: 0.1399, Initial Validation Loss: 0.1345, Validation Loss: 0.1345,V Acc: 0.2661, Top 70th Acc: 0.2857, Bottom 30th Acc: 0.2188
Fold [4/5] Epoch [10/100] Initial Loss: 0.1399, Training Loss: 0.0312, Initial Validation Loss: 0.1345, Validation Loss: 0.0383,V Acc: 0.8349, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.5938
Fold [4/5] Epoch [20/100] Initial Loss: 0.1399, Training Loss: 0.0176, Initial Validation Loss: 0.1345, Validation Loss: 0.0334,V Acc: 0.8532, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.7188
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.9090909090909091
Fold [5/5] Epoch [0/100] Initial Loss: 0.1378, Training Loss: 0.1378, Initial Validation Loss: 0.1299, Validation Loss: 0.1299,V Acc: 0.3241, Top 70th Acc: 0.3158, Bottom 30th Acc: 0.3438
Fold [5/5] Epoch [10/100] Initial Loss: 0.1378, Training Loss: 0.0307, Initial Validation Loss: 0.1299, Validation Loss: 0.0350,V Acc: 0.8333, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.5938
Fold [5/5] Epoch [20/100] Initial Loss: 0.1378, Training Loss: 0.0186, Initial Validation Loss: 0.1299, Validation Loss: 0.0289,V Acc: 0.8148, Top 70th Acc: 0.9737, Bottom 30th Acc: 0.4375
Stopping early at Epoch (base 0): 29  Rolling back to Epoch (base 0): 24  Top Validation Acc: 0.9605263157894737
Running train_nn.py with seed 20
CUDA:False
Training samples count:  550
Training on 30 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1434, Training Loss: 0.1434, Initial Validation Loss: 0.1362, Validation Loss: 0.1362,V Acc: 0.2411, Top 70th Acc: 0.2278, Bottom 30th Acc: 0.2727
Fold [1/5] Epoch [10/100] Initial Loss: 0.1434, Training Loss: 0.0404, Initial Validation Loss: 0.1362, Validation Loss: 0.0484,V Acc: 0.7500, Top 70th Acc: 0.8481, Bottom 30th Acc: 0.5152
Fold [1/5] Epoch [20/100] Initial Loss: 0.1434, Training Loss: 0.0195, Initial Validation Loss: 0.1362, Validation Loss: 0.0339,V Acc: 0.8214, Top 70th Acc: 0.9241, Bottom 30th Acc: 0.5758
Fold [1/5] Epoch [20/100] Initial Loss: 0.1331, Training Loss: 0.0766, Initial Validation Loss: 0.1260, Validation Loss: 0.0856,V Acc: 0.5893, Top 70th Acc: 0.7089, Bottom 30th Acc: 0.3030
Stopping early at Epoch (base 0): 20  Rolling back to Epoch (base 0): 15  Top Validation Acc: 0.7088607594936709
Fold [2/5] Epoch [0/100] Initial Loss: 0.1369, Training Loss: 0.1369, Initial Validation Loss: 0.1274, Validation Loss: 0.1274,V Acc: 0.3784, Top 70th Acc: 0.4615, Bottom 30th Acc: 0.1818
Fold [2/5] Epoch [10/100] Initial Loss: 0.1369, Training Loss: 0.0824, Initial Validation Loss: 0.1274, Validation Loss: 0.0791,V Acc: 0.6847, Top 70th Acc: 0.7692, Bottom 30th Acc: 0.4848
Fold [2/5] Epoch [20/100] Initial Loss: 0.1369, Training Loss: 0.0796, Initial Validation Loss: 0.1274, Validation Loss: 0.0755,V Acc: 0.6667, Top 70th Acc: 0.7821, Bottom 30th Acc: 0.3939
Fold [2/5] Epoch [30/100] Initial Loss: 0.1369, Training Loss: 0.0785, Initial Validation Loss: 0.1274, Validation Loss: 0.0756,V Acc: 0.6847, Top 70th Acc: 0.7821, Bottom 30th Acc: 0.4545
Stopping early at Epoch (base 0): 32  Rolling back to Epoch (base 0): 27  Top Validation Acc: 0.7692307692307693
Fold [3/5] Epoch [0/100] Initial Loss: 0.1357, Training Loss: 0.1357, Initial Validation Loss: 0.1267, Validation Loss: 0.1267,V Acc: 0.5273, Top 70th Acc: 0.5455, Bottom 30th Acc: 0.4848
Fold [3/5] Epoch [10/100] Initial Loss: 0.1357, Training Loss: 0.0797, Initial Validation Loss: 0.1267, Validation Loss: 0.0805,V Acc: 0.6455, Top 70th Acc: 0.7662, Bottom 30th Acc: 0.3636
Fold [3/5] Epoch [20/100] Initial Loss: 0.1357, Training Loss: 0.0784, Initial Validation Loss: 0.1267, Validation Loss: 0.0779,V Acc: 0.6455, Top 70th Acc: 0.7792, Bottom 30th Acc: 0.3333
Fold [3/5] Epoch [30/100] Initial Loss: 0.1357, Training Loss: 0.0778, Initial Validation Loss: 0.1267, Validation Loss: 0.0777,V Acc: 0.6727, Top 70th Acc: 0.7662, Bottom 30th Acc: 0.4545
Stopping early at Epoch (base 0): 39  Rolling back to Epoch (base 0): 34  Top Validation Acc: 0.7532467532467533
Fold [4/5] Epoch [0/100] Initial Loss: 0.1411, Training Loss: 0.1411, Initial Validation Loss: 0.1281, Validation Loss: 0.1281,V Acc: 0.2844, Top 70th Acc: 0.3636, Bottom 30th Acc: 0.0938
Fold [4/5] Epoch [10/100] Initial Loss: 0.1411, Training Loss: 0.0812, Initial Validation Loss: 0.1281, Validation Loss: 0.0790,V Acc: 0.5780, Top 70th Acc: 0.7013, Bottom 30th Acc: 0.2812
Stopping early at Epoch (base 0): 19  Rolling back to Epoch (base 0): 14  Top Validation Acc: 0.7142857142857143
17 3 [array([0.12401973, 0.40622133, 0.11839497, 0.16958259, 0.1817813 ],
      dtype=float32)]
Fold [5/5] Epoch [0/100] Initial Loss: 0.1424, Training Loss: 0.1424, Initial Validation Loss: 0.1326, Validation Loss: 0.1326,V Acc: 0.3704, Top 70th Acc: 0.3421, Bottom 30th Acc: 0.4375
Fold [5/5] Epoch [10/100] Initial Loss: 0.1424, Training Loss: 0.0813, Initial Validation Loss: 0.1326, Validation Loss: 0.0762,V Acc: 0.6296, Top 70th Acc: 0.7500, Bottom 30th Acc: 0.3438
Fold [5/5] Epoch [20/100] Initial Loss: 0.1424, Training Loss: 0.0793, Initial Validation Loss: 0.1326, Validation Loss: 0.0750,V Acc: 0.6481, Top 70th Acc: 0.7368, Bottom 30th Acc: 0.4375
Fold [5/5] Epoch [30/100] Initial Loss: 0.1424, Training Loss: 0.0787, Initial Validation Loss: 0.1326, Validation Loss: 0.0745,V Acc: 0.6481, Top 70th Acc: 0.7368, Bottom 30th Acc: 0.4375
Stopping early at Epoch (base 0): 37  Rolling back to Epoch (base 0): 32  Top Validation Acc: 0.7368421052631579
Running train_nn.py with seed 18
CUDA:False
Training samples count:  550
Training on 2 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1453, Training Loss: 0.1453, Initial Validation Loss: 0.1396, Validation Loss: 0.1396,V Acc: 0.2946, Top 70th Acc: 0.3924, Bottom 30th Acc: 0.0606
Fold [1/5] Epoch [10/100] Initial Loss: 0.1453, Training Loss: 0.0817, Initial Validation Loss: 0.1396, Validation Loss: 0.0779,V Acc: 0.6339, Top 70th Acc: 0.7342, Bottom 30th Acc: 0.3939
Fold [1/5] Epoch [20/100] Initial Loss: 0.1453, Training Loss: 0.0792, Initial Validation Loss: 0.1396, Validation Loss: 0.0763,V Acc: 0.6071, Top 70th Acc: 0.7342, Bottom 30th Acc: 0.3030
Stopping early at Epoch (base 0): 22  Rolling back to Epoch (base 0): 17  Top Validation Acc: 0.7215189873417721
18 0 [array([0.13255164, 0.35469118, 0.15094274, 0.20144637, 0.16036803],
      dtype=float32)]
Fold [2/5] Epoch [0/100] Initial Loss: 0.1360, Training Loss: 0.1360, Initial Validation Loss: 0.1294, Validation Loss: 0.1294,V Acc: 0.3333, Top 70th Acc: 0.4231, Bottom 30th Acc: 0.1212
Fold [2/5] Epoch [10/100] Initial Loss: 0.1360, Training Loss: 0.0791, Initial Validation Loss: 0.1294, Validation Loss: 0.0848,V Acc: 0.6126, Top 70th Acc: 0.7436, Bottom 30th Acc: 0.3030
Fold [2/5] Epoch [20/100] Initial Loss: 0.1360, Training Loss: 0.0774, Initial Validation Loss: 0.1294, Validation Loss: 0.0826,V Acc: 0.6216, Top 70th Acc: 0.7308, Bottom 30th Acc: 0.3636
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.7307692307692307
Fold [3/5] Epoch [0/100] Initial Loss: 0.1380, Training Loss: 0.1380, Initial Validation Loss: 0.1293, Validation Loss: 0.1293,V Acc: 0.2818, Top 70th Acc: 0.3766, Bottom 30th Acc: 0.0606
Fold [3/5] Epoch [10/100] Initial Loss: 0.1380, Training Loss: 0.0809, Initial Validation Loss: 0.1293, Validation Loss: 0.0800,V Acc: 0.6455, Top 70th Acc: 0.7273, Bottom 30th Acc: 0.4545
Fold [3/5] Epoch [20/100] Initial Loss: 0.1380, Training Loss: 0.0789, Initial Validation Loss: 0.1293, Validation Loss: 0.0784,V Acc: 0.6273, Top 70th Acc: 0.7532, Bottom 30th Acc: 0.3333
Fold [3/5] Epoch [30/100] Initial Loss: 0.1380, Training Loss: 0.0781, Initial Validation Loss: 0.1293, Validation Loss: 0.0773,V Acc: 0.6455, Top 70th Acc: 0.7532, Bottom 30th Acc: 0.3939
Fold [3/5] Epoch [40/100] Initial Loss: 0.1380, Training Loss: 0.0778, Initial Validation Loss: 0.1293, Validation Loss: 0.0776,V Acc: 0.6182, Top 70th Acc: 0.7532, Bottom 30th Acc: 0.3030
Fold [3/5] Epoch [50/100] Initial Loss: 0.1380, Training Loss: 0.0775, Initial Validation Loss: 0.1293, Validation Loss: 0.0767,V Acc: 0.6545, Top 70th Acc: 0.7662, Bottom 30th Acc: 0.3939
Stopping early at Epoch (base 0): 58  Rolling back to Epoch (base 0): 53  Top Validation Acc: 0.7662337662337663
Fold [4/5] Epoch [0/100] Initial Loss: 0.1344, Training Loss: 0.1344, Initial Validation Loss: 0.1191, Validation Loss: 0.1191,V Acc: 0.4037, Top 70th Acc: 0.4935, Bottom 30th Acc: 0.1875
Fold [4/5] Epoch [10/100] Initial Loss: 0.1344, Training Loss: 0.0816, Initial Validation Loss: 0.1191, Validation Loss: 0.0755,V Acc: 0.6697, Top 70th Acc: 0.7662, Bottom 30th Acc: 0.4375
Fold [4/5] Epoch [20/100] Initial Loss: 0.1344, Training Loss: 0.0796, Initial Validation Loss: 0.1191, Validation Loss: 0.0757,V Acc: 0.6606, Top 70th Acc: 0.7532, Bottom 30th Acc: 0.4375
Fold [4/5] Epoch [30/100] Initial Loss: 0.1344, Training Loss: 0.0793, Initial Validation Loss: 0.1191, Validation Loss: 0.0735,V Acc: 0.6697, Top 70th Acc: 0.7532, Bottom 30th Acc: 0.4688
Stopping early at Epoch (base 0): 33  Rolling back to Epoch (base 0): 28  Top Validation Acc: 0.7532467532467533
Fold [5/5] Epoch [0/100] Initial Loss: 0.1364, Training Loss: 0.1364, Initial Validation Loss: 0.1254, Validation Loss: 0.1254,V Acc: 0.3889, Top 70th Acc: 0.5000, Bottom 30th Acc: 0.1250
Fold [5/5] Epoch [10/100] Initial Loss: 0.1364, Training Loss: 0.0809, Initial Validation Loss: 0.1254, Validation Loss: 0.0787,V Acc: 0.6019, Top 70th Acc: 0.7368, Bottom 30th Acc: 0.2812
Fold [5/5] Epoch [20/100] Initial Loss: 0.1364, Training Loss: 0.0790, Initial Validation Loss: 0.1254, Validation Loss: 0.0766,V Acc: 0.6019, Top 70th Acc: 0.7632, Bottom 30th Acc: 0.2188
Fold [5/5] Epoch [30/100] Initial Loss: 0.1364, Training Loss: 0.0784, Initial Validation Loss: 0.1254, Validation Loss: 0.0756,V Acc: 0.6111, Top 70th Acc: 0.7500, Bottom 30th Acc: 0.2812
Fold [5/5] Epoch [40/100] Initial Loss: 0.1364, Training Loss: 0.0782, Initial Validation Loss: 0.1254, Validation Loss: 0.0754,V Acc: 0.6296, Top 70th Acc: 0.7500, Bottom 30th Acc: 0.3438
Fold [5/5] Epoch [50/100] Initial Loss: 0.1364, Training Loss: 0.0778, Initial Validation Loss: 0.1254, Validation Loss: 0.0747,V Acc: 0.6389, Top 70th Acc: 0.7632, Bottom 30th Acc: 0.3438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 21 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 91
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 21 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 92
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 21 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 93
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 21 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 94
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 21 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 95
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 21 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 96
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 21 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 97
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 21 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 98
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 21 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 99
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 21 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 100
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 21 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5

Fold [4/5] Epoch [10/100] Initial Loss: 0.1409, Training Loss: 0.0398, Initial Validation Loss: 0.1301, Validation Loss: 0.0448,V Acc: 0.7706, Top 70th Acc: 0.8831, Bottom 30th Acc: 0.5000
Fold [4/5] Epoch [20/100] Initial Loss: 0.1409, Training Loss: 0.0244, Initial Validation Loss: 0.1301, Validation Loss: 0.0328,V Acc: 0.8257, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.5938
Fold [4/5] Epoch [30/100] Initial Loss: 0.1409, Training Loss: 0.0204, Initial Validation Loss: 0.1301, Validation Loss: 0.0310,V Acc: 0.8349, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.5938
Stopping early at Epoch (base 0): 37  Rolling back to Epoch (base 0): 32  Top Validation Acc: 0.922077922077922
17 3 [array([0.51822454, 0.05044913, 0.06256609, 0.23809657, 0.13066381],
      dtype=float32)]
Fold [5/5] Epoch [0/100] Initial Loss: 0.1384, Training Loss: 0.1384, Initial Validation Loss: 0.1280, Validation Loss: 0.1280,V Acc: 0.3611, Top 70th Acc: 0.3947, Bottom 30th Acc: 0.2812
Fold [5/5] Epoch [10/100] Initial Loss: 0.1384, Training Loss: 0.0404, Initial Validation Loss: 0.1280, Validation Loss: 0.0395,V Acc: 0.8148, Top 70th Acc: 0.9079, Bottom 30th Acc: 0.5938
Fold [5/5] Epoch [20/100] Initial Loss: 0.1384, Training Loss: 0.0283, Initial Validation Loss: 0.1280, Validation Loss: 0.0333,V Acc: 0.8241, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.5312
Stopping early at Epoch (base 0): 29  Rolling back to Epoch (base 0): 24  Top Validation Acc: 0.9210526315789473
Running train_nn.py with seed 18
CUDA:False
Training samples count:  550
Training on 20 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1372, Training Loss: 0.1372, Initial Validation Loss: 0.1332, Validation Loss: 0.1332,V Acc: 0.2500, Top 70th Acc: 0.3165, Bottom 30th Acc: 0.0909
Fold [1/5] Epoch [10/100] Initial Loss: 0.1372, Training Loss: 0.0361, Initial Validation Loss: 0.1332, Validation Loss: 0.0453,V Acc: 0.7768, Top 70th Acc: 0.9367, Bottom 30th Acc: 0.3939
Fold [1/5] Epoch [20/100] Initial Loss: 0.1372, Training Loss: 0.0240, Initial Validation Loss: 0.1332, Validation Loss: 0.0372,V Acc: 0.8304, Top 70th Acc: 0.8987, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 28  Rolling back to Epoch (base 0): 23  Top Validation Acc: 0.8987341772151899
18 0 [array([0.2637965 , 0.0744041 , 0.17175104, 0.2556656 , 0.23438275],
      dtype=float32)]
Fold [2/5] Epoch [0/100] Initial Loss: 0.1401, Training Loss: 0.1401, Initial Validation Loss: 0.1360, Validation Loss: 0.1360,V Acc: 0.3964, Top 70th Acc: 0.3974, Bottom 30th Acc: 0.3939
Fold [2/5] Epoch [10/100] Initial Loss: 0.1401, Training Loss: 0.0414, Initial Validation Loss: 0.1360, Validation Loss: 0.0420,V Acc: 0.8378, Top 70th Acc: 0.8974, Bottom 30th Acc: 0.6970
Fold [2/5] Epoch [20/100] Initial Loss: 0.1401, Training Loss: 0.0244, Initial Validation Loss: 0.1360, Validation Loss: 0.0290,V Acc: 0.9009, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.7879
Fold [2/5] Epoch [30/100] Initial Loss: 0.1401, Training Loss: 0.0216, Initial Validation Loss: 0.1360, Validation Loss: 0.0298,V Acc: 0.8649, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 32  Rolling back to Epoch (base 0): 27  Top Validation Acc: 0.9487179487179487
Fold [3/5] Epoch [0/100] Initial Loss: 0.1364, Training Loss: 0.1364, Initial Validation Loss: 0.1309, Validation Loss: 0.1309,V Acc: 0.3727, Top 70th Acc: 0.4156, Bottom 30th Acc: 0.2727
Fold [3/5] Epoch [10/100] Initial Loss: 0.1364, Training Loss: 0.0431, Initial Validation Loss: 0.1309, Validation Loss: 0.0500,V Acc: 0.7364, Top 70th Acc: 0.8442, Bottom 30th Acc: 0.4848
Fold [3/5] Epoch [20/100] Initial Loss: 0.1364, Training Loss: 0.0229, Initial Validation Loss: 0.1309, Validation Loss: 0.0357,V Acc: 0.8273, Top 70th Acc: 0.8961, Bottom 30th Acc: 0.6667
Fold [3/5] Epoch [30/100] Initial Loss: 0.1364, Training Loss: 0.0204, Initial Validation Loss: 0.1309, Validation Loss: 0.0351,V Acc: 0.8182, Top 70th Acc: 0.8961, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 30  Rolling back to Epoch (base 0): 25  Top Validation Acc: 0.8961038961038961
Fold [4/5] Epoch [0/100] Initial Loss: 0.1404, Training Loss: 0.1404, Initial Validation Loss: 0.1291, Validation Loss: 0.1291,V Acc: 0.5138, Top 70th Acc: 0.5584, Bottom 30th Acc: 0.4062
Fold [4/5] Epoch [10/100] Initial Loss: 0.1404, Training Loss: 0.0336, Initial Validation Loss: 0.1291, Validation Loss: 0.0360,V Acc: 0.8532, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6250
Fold [4/5] Epoch [20/100] Initial Loss: 0.1404, Training Loss: 0.0231, Initial Validation Loss: 0.1291, Validation Loss: 0.0315,V Acc: 0.8532, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6250
Stopping early at Epoch (base 0): 22  Rolling back to Epoch (base 0): 17  Top Validation Acc: 0.961038961038961
Fold [5/5] Epoch [0/100] Initial Loss: 0.1393, Training Loss: 0.1393, Initial Validation Loss: 0.1299, Validation Loss: 0.1299,V Acc: 0.3519, Top 70th Acc: 0.4474, Bottom 30th Acc: 0.1250
Fold [5/5] Epoch [10/100] Initial Loss: 0.1393, Training Loss: 0.0371, Initial Validation Loss: 0.1299, Validation Loss: 0.0406,V Acc: 0.8056, Top 70th Acc: 0.9079, Bottom 30th Acc: 0.5625
Fold [5/5] Epoch [20/100] Initial Loss: 0.1393, Training Loss: 0.0249, Initial Validation Loss: 0.1299, Validation Loss: 0.0304,V Acc: 0.8519, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.6250
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.9210526315789473
Running train_nn.py with seed 19
CUDA:False
Training samples count:  550
Training on 20 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1394, Training Loss: 0.1394, Initial Validation Loss: 0.1420, Validation Loss: 0.1420,V Acc: 0.2589, Top 70th Acc: 0.2911, Bottom 30th Acc: 0.1818
Fold [1/5] Epoch [10/100] Initial Loss: 0.1394, Training Loss: 0.0400, Initial Validation Loss: 0.1420, Validation Loss: 0.0426,V Acc: 0.8571, Top 70th Acc: 0.9114, Bottom 30th Acc: 0.7273
Fold [1/5] Epoch [20/100] Initial Loss: 0.1394, Training Loss: 0.0259, Initial Validation Loss: 0.1420, Validation Loss: 0.0275,V Acc: 0.9107, Top 70th Acc: 0.9620, Bottom 30th Acc: 0.7879
Fold [1/5] Epoch [30/100] Initial Loss: 0.1394, Training Loss: 0.0231, Initial Validation Loss: 0.1420, Validation Loss: 0.0261,V Acc: 0.9196, Top 70th Acc: 0.9620, Bottom 30th Acc: 0.8182
Stopping early at Epoch (base 0): 38  Rolling back to Epoch (base 0): 33  Top Validation Acc: 0.9493670886075949
Fold [2/5] Epoch [0/100] Initial Loss: 0.1405, Training Loss: 0.1405, Initial Validation Loss: 0.1272, Validation Loss: 0.1272,V Acc: 0.4054, Top 70th Acc: 0.4744, Bottom 30th Acc: 0.2424
Fold [2/5] Epoch [10/100] Initial Loss: 0.1405, Training Loss: 0.0367, Initial Validation Loss: 0.1272, Validation Loss: 0.0401,V Acc: 0.7928, Top 70th Acc: 0.8718, Bottom 30th Acc: 0.6061
Fold [2/5] Epoch [20/100] Initial Loss: 0.1405, Training Loss: 0.0235, Initial Validation Loss: 0.1272, Validation Loss: 0.0316,V Acc: 0.8288, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.6061
Fold [2/5] Epoch [30/100] Initial Loss: 0.1405, Training Loss: 0.0208, Initial Validation Loss: 0.1272, Validation Loss: 0.0330,V Acc: 0.8018, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.5152
Stopping early at Epoch (base 0): 30  Rolling back to Epoch (base 0): 25  Top Validation Acc: 0.9230769230769231
19 1 [array([0.17542164, 0.06430994, 0.09947643, 0.33839402, 0.32239792],
      dtype=float32)]
Fold [3/5] Epoch [0/100] Initial Loss: 0.1398, Training Loss: 0.1398, Initial Validation Loss: 0.1319, Validation Loss: 0.1319,V Acc: 0.2909, Top 70th Acc: 0.3117, Bottom 30th Acc: 0.2424
Fold [3/5] Epoch [10/100] Initial Loss: 0.1398, Training Loss: 0.0333, Initial Validation Loss: 0.1319, Validation Loss: 0.0489,V Acc: 0.7636, Top 70th Acc: 0.8442, Bottom 30th Acc: 0.5758
Fold [3/5] Epoch [20/100] Initial Loss: 0.1398, Training Loss: 0.0242, Initial Validation Loss: 0.1319, Validation Loss: 0.0416,V Acc: 0.7909, Top 70th Acc: 0.8571, Bottom 30th Acc: 0.6364
Fold [3/5] Epoch [30/100] Initial Loss: 0.1398, Training Loss: 0.0217, Initial Validation Loss: 0.1319, Validation Loss: 0.0405,V Acc: 0.8273, Top 70th Acc: 0.8701, Bottom 30th Acc: 0.7273
Stopping early at Epoch (base 0): 31  Rolling back to Epoch (base 0): 26  Top Validation Acc:training rf with seed 1
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 162 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 2
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 162 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 3
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 162 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 4
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 162 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 5
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 162 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 6
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 162 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 7
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 162 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 8
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 162 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 9
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 162 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 10
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 162 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 11
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 162 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 12
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 162 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 13
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 162 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 14
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 162 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 15
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 162 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 16
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 162 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 17
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 162 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 18
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 162 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 19
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 162 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 20
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 162 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 21
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 162 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 22
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 162 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 23
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 162 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 24
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 162 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 25
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 162 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 26
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 162 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 27
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 162 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 28
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 162 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 29
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 162 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 30
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 162 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 31
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 162 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 32
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 162 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 33
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 162 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 34
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 162 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 35
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 162 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 36
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 162 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 37
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 162 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 38
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 162 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 39
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 162 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 40
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 162 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 41
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 162 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 42
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 162 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 43
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 162 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 44
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 162 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 45
Training size: 438
Training size: 439
Fold [5/5] Epoch [20/100] Initial Loss: 0.1420, Training Loss: 0.0067, Initial Validation Loss: 0.1321, Validation Loss: 0.0301,V Acc: 0.8796, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.6875
Fold [5/5] Epoch [30/100] Initial Loss: 0.1420, Training Loss: 0.0052, Initial Validation Loss: 0.1321, Validation Loss: 0.0287,V Acc: 0.8704, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.6875
Fold [5/5] Epoch [40/100] Initial Loss: 0.1420, Training Loss: 0.0046, Initial Validation Loss: 0.1321, Validation Loss: 0.0272,V Acc: 0.8796, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.6875
Fold [5/5] Epoch [50/100] Initial Loss: 0.1420, Training Loss: 0.0043, Initial Validation Loss: 0.1321, Validation Loss: 0.0257,V Acc: 0.8796, Top 70th Acc: 0.9737, Bottom 30th Acc: 0.6562
Fold [5/5] Epoch [60/100] Initial Loss: 0.1420, Training Loss: 0.0040, Initial Validation Loss: 0.1321, Validation Loss: 0.0251,V Acc: 0.8889, Top 70th Acc: 0.9737, Bottom 30th Acc: 0.6875
Fold [5/5] Epoch [70/100] Initial Loss: 0.1420, Training Loss: 0.0039, Initial Validation Loss: 0.1321, Validation Loss: 0.0247,V Acc: 0.8611, Top 70th Acc: 0.9737, Bottom 30th Acc: 0.5938
Stopping early at Epoch (base 0): 76  Rolling back to Epoch (base 0): 71  Top Validation Acc: 0.9736842105263158
Running train_nn.py with seed 14
CUDA:False
Training samples count:  550
Training on 162 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1355, Training Loss: 0.1355, Initial Validation Loss: 0.1305, Validation Loss: 0.1305,V Acc: 0.2946, Top 70th Acc: 0.3924, Bottom 30th Acc: 0.0606
Fold [1/5] Epoch [10/100] Initial Loss: 0.1355, Training Loss: 0.0215, Initial Validation Loss: 0.1305, Validation Loss: 0.0410,V Acc: 0.7946, Top 70th Acc: 0.9114, Bottom 30th Acc: 0.5152
Fold [1/5] Epoch [20/100] Initial Loss: 0.1355, Training Loss: 0.0052, Initial Validation Loss: 0.1305, Validation Loss: 0.0298,V Acc: 0.8393, Top 70th Acc: 0.9494, Bottom 30th Acc: 0.5758
Fold [1/5] Epoch [30/100] Initial Loss: 0.1355, Training Loss: 0.0041, Initial Validation Loss: 0.1305, Validation Loss: 0.0290,V Acc: 0.8571, Top 70th Acc: 0.9494, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 36  Rolling back to Epoch (base 0): 31  Top Validation Acc: 0.9493670886075949
Fold [2/5] Epoch [0/100] Initial Loss: 0.1408, Training Loss: 0.1408, Initial Validation Loss: 0.1333, Validation Loss: 0.1333,V Acc: 0.2973, Top 70th Acc: 0.3462, Bottom 30th Acc: 0.1818
Fold [2/5] Epoch [10/100] Initial Loss: 0.1408, Training Loss: 0.0146, Initial Validation Loss: 0.1333, Validation Loss: 0.0337,V Acc: 0.7928, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.4242
Fold [2/5] Epoch [20/100] Initial Loss: 0.1408, Training Loss: 0.0046, Initial Validation Loss: 0.1333, Validation Loss: 0.0302,V Acc: 0.8018, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.4545
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.9358974358974359
14 1 [array([0.24555017, 0.04058848, 0.07862034, 0.18895404, 0.44628692],
      dtype=float32)]
Fold [3/5] Epoch [0/100] Initial Loss: 0.1404, Training Loss: 0.1404, Initial Validation Loss: 0.1384, Validation Loss: 0.1384,V Acc: 0.2545, Top 70th Acc: 0.3117, Bottom 30th Acc: 0.1212
Fold [3/5] Epoch [10/100] Initial Loss: 0.1404, Training Loss: 0.0189, Initial Validation Loss: 0.1384, Validation Loss: 0.0361,V Acc: 0.8455, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.5758
Fold [3/5] Epoch [20/100] Initial Loss: 0.1404, Training Loss: 0.0059, Initial Validation Loss: 0.1384, Validation Loss: 0.0300,V Acc: 0.8545, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.6061
Fold [3/5] Epoch [30/100] Initial Loss: 0.1404, Training Loss: 0.0043, Initial Validation Loss: 0.1384, Validation Loss: 0.0303,V Acc: 0.8727, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 31  Rolling back to Epoch (base 0): 26  Top Validation Acc: 0.948051948051948
Fold [4/5] Epoch [0/100] Initial Loss: 0.1406, Training Loss: 0.1406, Initial Validation Loss: 0.1304, Validation Loss: 0.1304,V Acc: 0.2844, Top 70th Acc: 0.3117, Bottom 30th Acc: 0.2188
Fold [4/5] Epoch [10/100] Initial Loss: 0.1406, Training Loss: 0.0243, Initial Validation Loss: 0.1304, Validation Loss: 0.0476,V Acc: 0.7798, Top 70th Acc: 0.8571, Bottom 30th Acc: 0.5938
Fold [4/5] Epoch [20/100] Initial Loss: 0.1406, Training Loss: 0.0048, Initial Validation Loss: 0.1304, Validation Loss: 0.0396,V Acc: 0.7890, Top 70th Acc: 0.8701, Bottom 30th Acc: 0.5938
Fold [4/5] Epoch [30/100] Initial Loss: 0.1406, Training Loss: 0.0037, Initial Validation Loss: 0.1304, Validation Loss: 0.0380,V Acc: 0.7982, Top 70th Acc: 0.8961, Bottom 30th Acc: 0.5625
Fold [4/5] Epoch [40/100] Initial Loss: 0.1406, Training Loss: 0.0035, Initial Validation Loss: 0.1304, Validation Loss: 0.0373,V Acc: 0.7982, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.5312
Stopping early at Epoch (base 0): 48  Rolling back to Epoch (base 0): 43  Top Validation Acc: 0.8961038961038961
Fold [5/5] Epoch [0/100] Initial Loss: 0.1379, Training Loss: 0.1379, Initial Validation Loss: 0.1299, Validation Loss: 0.1299,V Acc: 0.3611, Top 70th Acc: 0.4474, Bottom 30th Acc: 0.1562
Fold [5/5] Epoch [10/100] Initial Loss: 0.1379, Training Loss: 0.0229, Initial Validation Loss: 0.1299, Validation Loss: 0.0340,V Acc: 0.8426, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.5625
Fold [5/5] Epoch [20/100] Initial Loss: 0.1379, Training Loss: 0.0054, Initial Validation Loss: 0.1299, Validation Loss: 0.0245,V Acc: 0.8796, Top 70th Acc: 0.9868, Bottom 30th Acc: 0.6250
Fold [5/5] Epoch [30/100] Initial Loss: 0.1379, Training Loss: 0.0041, Initial Validation Loss: 0.1299, Validation Loss: 0.0237,V Acc: 0.8704, Top 70th Acc: 0.9868, Bottom 30th Acc: 0.5938
Stopping early at Epoch (base 0): 38  Rolling back to Epoch (base 0): 33  Top Validation Acc: 0.9736842105263158
Running train_nn.py with seed 15
CUDA:False
Training samples count:  550
Training on 162 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1414, Training Loss: 0.1414, Initial Validation Loss: 0.1326, Validation Loss: 0.1326,V Acc: 0.2500, Top 70th Acc: 0.3291, Bottom 30th Acc: 0.0606
Fold [1/5] Epoch [10/100] Initial Loss: 0.1414, Training Loss: 0.0163, Initial Validation Loss: 0.1326, Validation Loss: 0.0508,V Acc: 0.7411, Top 70th Acc: 0.8481, Bottom 30th Acc: 0.4848
Stopping early at Epoch (base 0): 16  Rolling back to Epoch (base 0): 11  Top Validation Acc: 0.8354430379746836
Fold [2/5] Epoch [0/100] Initial Loss: 0.1389, Training Loss: 0.1389, Initial Validation Loss: 0.1353, Validation Loss: 0.1353,V Acc: 0.2613, Top 70th Acc: 0.2821, Bottom 30th Acc: 0.2121
Fold [2/5] Epoch [10/100] Initial Loss: 0.1389, Training Loss: 0.0175, Initial Validation Loss: 0.1353, Validation Loss: 0.0440,V Acc: 0.7748, Top 70th Acc: 0.8974, Bottom 30th Acc: 0.4848
Fold [2/5] Epoch [20/100] Initial Loss: 0.1389, Training Loss: 0.0045, Initial Validation Loss: 0.1353, Validation Loss: 0.0391,V Acc: 0.7838, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.4242
Fold [2/5] Epoch [30/100] Initial Loss: 0.1389, Training Loss: 0.0037, Initial Validation Loss: 0.1353, Validation Loss: 0.0379,V Acc: 0.8018, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.5152
Fold [2/5] Epoch [40/100] Initial Loss: 0.1389, Training Loss: 0.0036, Initial Validation Loss: 0.1353, Validation Loss: 0.0370,V Acc: 0.8018, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.4848
Stopping early at Epoch (base 0): 42  Rolling back to Epoch (base 0): 37  Top Validation Acc: 0.9487179487179487
15 1 [array([0.20089348, 0.10302512, 0.03206076, 0.13292563, 0.53109497],
      dtype=float32)]
Fold [3/5] Epoch [0/100] Initial Loss: 0.1393, Training Loss: 0.1393, Initial Validation Loss: 0.1354, Validation Loss: 0.1354,V Acc: 0.2545, Top 70th Acc: 0.3506, Bottom 30th Acc: 0.0303
Fold [3/5] Epoch [10/100] Initial Loss: 0.1393, Training Loss: 0.0174, Initial Validation Loss: 0.1354, Validation Loss: 0.0282,V Acc: 0.8818, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.6667
Fold [3/5] Epoch [20/100] Initial Loss: 0.1393, Training Loss: 0.0052, Initial Validation Loss: 0.1354, Validation Loss: 0.0243,V Acc: 0.8636, Top 70th Acc: 0.9870, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.987012987012987 19  Top Validation Acc: 0.9605263157894737
Running train_nn.py with seed 26
CUDA:False
Training samples count:  550
Training on 21 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1337, Training Loss: 0.1337, Initial Validation Loss: 0.1194, Validation Loss: 0.1194,V Acc: 0.5179, Top 70th Acc: 0.5949, Bottom 30th Acc: 0.3333
Fold [1/5] Epoch [10/100] Initial Loss: 0.1337, Training Loss: 0.0174, Initial Validation Loss: 0.1194, Validation Loss: 0.0232,V Acc: 0.8839, Top 70th Acc: 0.9620, Bottom 30th Acc: 0.6970
Fold [1/5] Epoch [20/100] Initial Loss: 0.1337, Training Loss: 0.0135, Initial Validation Loss: 0.1194, Validation Loss: 0.0232,V Acc: 0.9107, Top 70th Acc: 0.9494, Bottom 30th Acc: 0.8182
Stopping early at Epoch (base 0): 20  Rolling back to Epoch (base 0): 15  Top Validation Acc: 0.9493670886075949
Fold [2/5] Epoch [0/100] Initial Loss: 0.1387, Training Loss: 0.1387, Initial Validation Loss: 0.1342, Validation Loss: 0.1342,V Acc: 0.3604, Top 70th Acc: 0.3974, Bottom 30th Acc: 0.2727
Fold [2/5] Epoch [10/100] Initial Loss: 0.1387, Training Loss: 0.0254, Initial Validation Loss: 0.1342, Validation Loss: 0.0276,V Acc: 0.8919, Top 70th Acc: 0.9872, Bottom 30th Acc: 0.6667
Fold [2/5] Epoch [20/100] Initial Loss: 0.1387, Training Loss: 0.0187, Initial Validation Loss: 0.1342, Validation Loss: 0.0184,V Acc: 0.9099, Top 70th Acc: 1.0000, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 21  Rolling back to Epoch (base 0): 16  Top Validation Acc: 1.0
26 1 [array([0.78878695, 0.02406551, 0.03426525, 0.08993221, 0.0629501 ],
      dtype=float32)]
Fold [3/5] Epoch [0/100] Initial Loss: 0.1377, Training Loss: 0.1377, Initial Validation Loss: 0.1254, Validation Loss: 0.1254,V Acc: 0.4364, Top 70th Acc: 0.4545, Bottom 30th Acc: 0.3939
Fold [3/5] Epoch [10/100] Initial Loss: 0.1377, Training Loss: 0.0201, Initial Validation Loss: 0.1254, Validation Loss: 0.0331,V Acc: 0.8364, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 13  Rolling back to Epoch (base 0): 8  Top Validation Acc: 0.9090909090909091
Fold [4/5] Epoch [0/100] Initial Loss: 0.1380, Training Loss: 0.1380, Initial Validation Loss: 0.1273, Validation Loss: 0.1273,V Acc: 0.3028, Top 70th Acc: 0.3896, Bottom 30th Acc: 0.0938
Fold [4/5] Epoch [10/100] Initial Loss: 0.1380, Training Loss: 0.0220, Initial Validation Loss: 0.1273, Validation Loss: 0.0247,V Acc: 0.8624, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.5938
Fold [4/5] Epoch [20/100] Initial Loss: 0.1380, Training Loss: 0.0159, Initial Validation Loss: 0.1273, Validation Loss: 0.0225,V Acc: 0.8716, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.6250
Stopping early at Epoch (base 0): 21  Rolling back to Epoch (base 0): 16  Top Validation Acc: 0.961038961038961
Fold [5/5] Epoch [0/100] Initial Loss: 0.1202, Training Loss: 0.1202, Initial Validation Loss: 0.1010, Validation Loss: 0.1010,V Acc: 0.6019, Top 70th Acc: 0.6711, Bottom 30th Acc: 0.4375
Fold [5/5] Epoch [10/100] Initial Loss: 0.1202, Training Loss: 0.0192, Initial Validation Loss: 0.1010, Validation Loss: 0.0301,V Acc: 0.8519, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.6562
Stopping early at Epoch (base 0): 14  Rolling back to Epoch (base 0): 9  Top Validation Acc: 0.9473684210526315
Running train_nn.py with seed 27
CUDA:False
Training samples count:  550
Training on 21 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1364, Training Loss: 0.1364, Initial Validation Loss: 0.1256, Validation Loss: 0.1256,V Acc: 0.4375, Top 70th Acc: 0.4937, Bottom 30th Acc: 0.3030
Fold [1/5] Epoch [10/100] Initial Loss: 0.1364, Training Loss: 0.0261, Initial Validation Loss: 0.1256, Validation Loss: 0.0341,V Acc: 0.8304, Top 70th Acc: 0.9494, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 18  Rolling back to Epoch (base 0): 13  Top Validation Acc: 0.9493670886075949
Fold [2/5] Epoch [0/100] Initial Loss: 0.1360, Training Loss: 0.1360, Initial Validation Loss: 0.1184, Validation Loss: 0.1184,V Acc: 0.4595, Top 70th Acc: 0.6026, Bottom 30th Acc: 0.1212
Fold [2/5] Epoch [10/100] Initial Loss: 0.1360, Training Loss: 0.0228, Initial Validation Loss: 0.1184, Validation Loss: 0.0290,V Acc: 0.8559, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 16  Rolling back to Epoch (base 0): 11  Top Validation Acc: 0.9487179487179487
27 1 [array([0.7732729 , 0.02018551, 0.03741518, 0.09501529, 0.07411105],
      dtype=float32)]
Fold [3/5] Epoch [0/100] Initial Loss: 0.1386, Training Loss: 0.1386, Initial Validation Loss: 0.1314, Validation Loss: 0.1314,V Acc: 0.3364, Top 70th Acc: 0.3636, Bottom 30th Acc: 0.2727
Fold [3/5] Epoch [10/100] Initial Loss: 0.1386, Training Loss: 0.0274, Initial Validation Loss: 0.1314, Validation Loss: 0.0265,V Acc: 0.8727, Top 70th Acc: 1.0000, Bottom 30th Acc: 0.5758
Fold [3/5] Epoch [20/100] Initial Loss: 0.1386, Training Loss: 0.0175, Initial Validation Loss: 0.1314, Validation Loss: 0.0211,V Acc: 0.9091, Top 70th Acc: 0.9870, Bottom 30th Acc: 0.7273
Fold [3/5] Epoch [30/100] Initial Loss: 0.1386, Training Loss: 0.0146, Initial Validation Loss: 0.1314, Validation Loss: 0.0171,V Acc: 0.9091, Top 70th Acc: 1.0000, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 30  Rolling back to Epoch (base 0): 25  Top Validation Acc: 1.0
Fold [4/5] Epoch [0/100] Initial Loss: 0.1306, Training Loss: 0.1306, Initial Validation Loss: 0.1155, Validation Loss: 0.1155,V Acc: 0.4404, Top 70th Acc: 0.5714, Bottom 30th Acc: 0.1250
Fold [4/5] Epoch [10/100] Initial Loss: 0.1306, Training Loss: 0.0204, Initial Validation Loss: 0.1155, Validation Loss: 0.0234,V Acc: 0.8807, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.6875
Stopping early at Epoch (base 0): 14  Rolling back to Epoch (base 0): 9  Top Validation Acc: 0.961038961038961
Fold [5/5] Epoch [0/100] Initial Loss: 0.1276, Training Loss: 0.1276, Initial Validation Loss: 0.1138, Validation Loss: 0.1138,V Acc: 0.5463, Top 70th Acc: 0.6053, Bottom 30th Acc: 0.4062
Fold [5/5] Epoch [10/100] Initial Loss: 0.1276, Training Loss: 0.0204, Initial Validation Loss: 0.1138, Validation Loss: 0.0320,V Acc: 0.8241, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.5000
Stopping early at Epoch (base 0): 18  Rolling back to Epoch (base 0): 13  Top Validation Acc: 0.9473684210526315
Running train_nn.py with seed 28
CUDA:False
Training samples count:  550
Training on 21 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1345, Training Loss: 0.1345, Initial Validation Loss: 0.1262, Validation Loss: 0.1262,V Acc: 0.4464, Top 70th Acc: 0.5443, Bottom 30th Acc: 0.2121
Fold [1/5] Epoch [10/100] Initial Loss: 0.1345, Training Loss: 0.0234, Initial Validation Loss: 0.1262, Validation Loss: 0.0335,V Acc: 0.8304, Top 70th Acc: 0.9747, Bottom 30th Acc: 0.4848
Fold [1/5] Epoch [20/100] Initial Loss: 0.1345, Training Loss: 0.0170, Initial Validation Loss: 0.1262, Validation Loss: 0.0308,V Acc: 0.8661, Top 70th Acc: 0.9620, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 21  Rolling back to Epoch (base 0): 16  Top Validation Acc: 0.9620253164556962
Fold [2/5] Epoch [0/100] Initial Loss: 0.1352, Training Loss: 0.1352, Initial Validation Loss: 0.1178, Validation Loss: 0.1178,V Acc: 0.4865, Top 70th Acc: 0.5641, Bottom 30th Acc: 0.3030
Fold [2/5] Epoch [10/100] Initial Loss: 0.1352, Training Loss: 0.0194, Initial Validation Loss: 0.1178, Validation Loss: 0.0275,V Acc: 0.8649, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.6970
Fold [2/5] Epoch [20/100] Initial Loss: 0.1352, Training Loss: 0.0158, Initial Validation Loss: 0.1178, Validation Loss: 0.0247,V Acc: 0.8739, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.7273
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.9230769230769231
28 1 [array([0.85318846, 0.01380589, 0.00902273, 0.06761288, 0.05637016],
      dtype=float32)]
Fold [3/5] Epoch [0/100] Initial Loss: 0.1360, Training Loss: 0.1360, Initial Validation Loss: 0.1274, Validation Loss: 0.1274,V Acc: 0.4909, Top 70th Acc: 0.6234, Bottom 30th Acc: 0.1818
Fold [3/5] Epoch [10/100] Initial Loss: 0.1360, Training Loss: 0.0237, Initial Validation Loss: 0.1274, Validation Loss: 0.0283,V Acc: 0.8636, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.6364
Fold [3/5] Epoch [20/100] Initial Loss: 0.1360, Training Loss: 0.0168, Initial Validation Loss: 0.1274, Validation Loss: 0.0210,V Acc: 0.8818, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.6667/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)

Fold [1/5] Epoch [20/100] Initial Loss: 0.1377, Training Loss: 0.0170, Initial Validation Loss: 0.1417, Validation Loss: 0.0242,V Acc: 0.8839, Top 70th Acc: 0.9747, Bottom 30th Acc: 0.6667
Fold [1/5] Epoch [30/100] Initial Loss: 0.1377, Training Loss: 0.0140, Initial Validation Loss: 0.1417, Validation Loss: 0.0229,V Acc: 0.8839, Top 70th Acc: 0.9747, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 39  Rolling back to Epoch (base 0): 34  Top Validation Acc: 0.9746835443037974
Fold [2/5] Epoch [0/100] Initial Loss: 0.1437, Training Loss: 0.1437, Initial Validation Loss: 0.1301, Validation Loss: 0.1301,V Acc: 0.3964, Top 70th Acc: 0.4615, Bottom 30th Acc: 0.2424
Fold [2/5] Epoch [10/100] Initial Loss: 0.1437, Training Loss: 0.0348, Initial Validation Loss: 0.1301, Validation Loss: 0.0437,V Acc: 0.7477, Top 70th Acc: 0.8718, Bottom 30th Acc: 0.4545
Fold [2/5] Epoch [20/100] Initial Loss: 0.1437, Training Loss: 0.0164, Initial Validation Loss: 0.1301, Validation Loss: 0.0353,V Acc: 0.7928, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.5152
Fold [2/5] Epoch [30/100] Initial Loss: 0.1437, Training Loss: 0.0118, Initial Validation Loss: 0.1301, Validation Loss: 0.0314,V Acc: 0.8198, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.5758
Fold [2/5] Epoch [40/100] Initial Loss: 0.1437, Training Loss: 0.0103, Initial Validation Loss: 0.1301, Validation Loss: 0.0311,V Acc: 0.8288, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 48  Rolling back to Epoch (base 0): 43  Top Validation Acc: 0.9230769230769231
19 1 [array([0.41036493, 0.08264866, 0.03475245, 0.04529976, 0.42693424],
      dtype=float32)]
Fold [3/5] Epoch [0/100] Initial Loss: 0.1417, Training Loss: 0.1417, Initial Validation Loss: 0.1337, Validation Loss: 0.1337,V Acc: 0.2636, Top 70th Acc: 0.2597, Bottom 30th Acc: 0.2727
Fold [3/5] Epoch [10/100] Initial Loss: 0.1417, Training Loss: 0.0418, Initial Validation Loss: 0.1337, Validation Loss: 0.0477,V Acc: 0.7636, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.4242
Fold [3/5] Epoch [20/100] Initial Loss: 0.1417, Training Loss: 0.0201, Initial Validation Loss: 0.1337, Validation Loss: 0.0405,V Acc: 0.8000, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.5455
Fold [3/5] Epoch [30/100] Initial Loss: 0.1417, Training Loss: 0.0150, Initial Validation Loss: 0.1337, Validation Loss: 0.0368,V Acc: 0.8364, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.6364
Fold [3/5] Epoch [40/100] Initial Loss: 0.1417, Training Loss: 0.0124, Initial Validation Loss: 0.1337, Validation Loss: 0.0349,V Acc: 0.8455, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.6667
Fold [3/5] Epoch [50/100] Initial Loss: 0.1417, Training Loss: 0.0108, Initial Validation Loss: 0.1337, Validation Loss: 0.0326,V Acc: 0.8636, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 58  Rolling back to Epoch (base 0): 53  Top Validation Acc: 0.935064935064935
Fold [4/5] Epoch [0/100] Initial Loss: 0.1402, Training Loss: 0.1402, Initial Validation Loss: 0.1341, Validation Loss: 0.1341,V Acc: 0.3028, Top 70th Acc: 0.3247, Bottom 30th Acc: 0.2500
Fold [4/5] Epoch [10/100] Initial Loss: 0.1402, Training Loss: 0.0335, Initial Validation Loss: 0.1341, Validation Loss: 0.0471,V Acc: 0.7523, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.3750
Fold [4/5] Epoch [20/100] Initial Loss: 0.1402, Training Loss: 0.0182, Initial Validation Loss: 0.1341, Validation Loss: 0.0395,V Acc: 0.7890, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.4688
Fold [4/5] Epoch [30/100] Initial Loss: 0.1402, Training Loss: 0.0126, Initial Validation Loss: 0.1341, Validation Loss: 0.0349,V Acc: 0.8257, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.5312
Fold [4/5] Epoch [40/100] Initial Loss: 0.1402, Training Loss: 0.0108, Initial Validation Loss: 0.1341, Validation Loss: 0.0342,V Acc: 0.8165, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.5000
Stopping early at Epoch (base 0): 41  Rolling back to Epoch (base 0): 36  Top Validation Acc: 0.948051948051948
Fold [5/5] Epoch [0/100] Initial Loss: 0.1393, Training Loss: 0.1393, Initial Validation Loss: 0.1312, Validation Loss: 0.1312,V Acc: 0.2593, Top 70th Acc: 0.3553, Bottom 30th Acc: 0.0312
Fold [5/5] Epoch [10/100] Initial Loss: 0.1393, Training Loss: 0.0385, Initial Validation Loss: 0.1312, Validation Loss: 0.0445,V Acc: 0.7593, Top 70th Acc: 0.9079, Bottom 30th Acc: 0.4062
Fold [5/5] Epoch [20/100] Initial Loss: 0.1393, Training Loss: 0.0212, Initial Validation Loss: 0.1312, Validation Loss: 0.0401,V Acc: 0.7870, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.4375
Fold [5/5] Epoch [30/100] Initial Loss: 0.1393, Training Loss: 0.0129, Initial Validation Loss: 0.1312, Validation Loss: 0.0343,V Acc: 0.8241, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.5312
Fold [5/5] Epoch [40/100] Initial Loss: 0.1393, Training Loss: 0.0103, Initial Validation Loss: 0.1312, Validation Loss: 0.0347,V Acc: 0.8148, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.5000
Stopping early at Epoch (base 0): 41  Rolling back to Epoch (base 0): 36  Top Validation Acc: 0.9473684210526315
Running train_nn.py with seed 20
CUDA:False
Training samples count:  550
Training on 40 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1397, Training Loss: 0.1397, Initial Validation Loss: 0.1312, Validation Loss: 0.1312,V Acc: 0.4554, Top 70th Acc: 0.5190, Bottom 30th Acc: 0.3030
Fold [1/5] Epoch [10/100] Initial Loss: 0.1397, Training Loss: 0.0287, Initial Validation Loss: 0.1312, Validation Loss: 0.0372,V Acc: 0.7857, Top 70th Acc: 0.8987, Bottom 30th Acc: 0.5152
Fold [1/5] Epoch [20/100] Initial Loss: 0.1397, Training Loss: 0.0147, Initial Validation Loss: 0.1312, Validation Loss: 0.0281,V Acc: 0.8304, Top 70th Acc: 0.9620, Bottom 30th Acc: 0.5152
Stopping early at Epoch (base 0): 29  Rolling back to Epoch (base 0): 24  Top Validation Acc: 0.9493670886075949
20 0 [array([0.4994583 , 0.08917123, 0.02808148, 0.07485869, 0.30843034],
      dtype=float32)]
Fold [2/5] Epoch [0/100] Initial Loss: 0.1382, Training Loss: 0.1382, Initial Validation Loss: 0.1359, Validation Loss: 0.1359,V Acc: 0.2973, Top 70th Acc: 0.3846, Bottom 30th Acc: 0.0909
Fold [2/5] Epoch [10/100] Initial Loss: 0.1382, Training Loss: 0.0271, Initial Validation Loss: 0.1359, Validation Loss: 0.0383,V Acc: 0.8378, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.6061
Fold [2/5] Epoch [20/100] Initial Loss: 0.1382, Training Loss: 0.0135, Initial Validation Loss: 0.1359, Validation Loss: 0.0325,V Acc: 0.8468, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.6364
Fold [2/5] Epoch [30/100] Initial Loss: 0.1382, Training Loss: 0.0110, Initial Validation Loss: 0.1359, Validation Loss: 0.0323,V Acc: 0.8468, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 32  Rolling back to Epoch (base 0): 27  Top Validation Acc: 0.9487179487179487
Fold [3/5] Epoch [0/100] Initial Loss: 0.1388, Training Loss: 0.1388, Initial Validation Loss: 0.1309, Validation Loss: 0.1309,V Acc: 0.2818, Top 70th Acc: 0.3506, Bottom 30th Acc: 0.1212
Fold [3/5] Epoch [10/100] Initial Loss: 0.1388, Training Loss: 0.0394, Initial Validation Loss: 0.1309, Validation Loss: 0.0395,V Acc: 0.8091, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.4848
Fold [3/5] Epoch [20/100] Initial Loss: 0.1388, Training Loss: 0.0163, Initial Validation Loss: 0.1309, Validation Loss: 0.0264,V Acc: 0.8727, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.6667
Fold [3/5] Epoch [30/100] Initial Loss: 0.1388, Training Loss: 0.0127, Initial Validation Loss: 0.1309, Validation Loss: 0.0242,V Acc: 0.8636, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.6364
Fold [3/5] Epoch [40/100] Initial Loss: 0.1388, Training Loss: 0.0115, Initial Validation Loss: 0.1309, Validation Loss: 0.0240,V Acc: 0.8727, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 43  Rolling back to Epoch (base 0): 38  Top Validation Acc: 0.961038961038961
Fold [4/5] Epoch [0/100] Initial Loss: 0.1372, Training Loss: 0.1372, Initial Validation Loss: 0.1299, Validation Loss: 0.1299,V Acc: 0.3119, Top 70th Acc: 0.3506, Bottom 30th Acc: 0.2188
Fold [4/5] Epoch [10/100] Initial Loss: 0.1372, Training Loss: 0.0213, Initial Validation Loss: 0.1299, Validation Loss: 0.0359,V Acc: 0.8440, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.5938
Fold [4/5] Epoch [20/100] Initial Loss: 0.1372, Training Loss: 0.0126, Initial Validation Loss: 0.1299, Validation Loss: 0.0327,V Acc: 0.8165, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.5000
Stopping early at Epoch (base 0): 29  Rolling back to Epoch (base 0): 24  Top Validation Acc: 0.9113924050632911
20 0 [array([0.55990756, 0.17270915, 0.03571488, 0.05685401, 0.17481448],
      dtype=float32)]
Fold [2/5] Epoch [0/100] Initial Loss: 0.1386, Training Loss: 0.1386, Initial Validation Loss: 0.1379, Validation Loss: 0.1379,V Acc: 0.2523, Top 70th Acc: 0.2949, Bottom 30th Acc: 0.1515
Fold [2/5] Epoch [10/100] Initial Loss: 0.1386, Training Loss: 0.0407, Initial Validation Loss: 0.1379, Validation Loss: 0.0461,V Acc: 0.7928, Top 70th Acc: 0.8974, Bottom 30th Acc: 0.5455
Fold [2/5] Epoch [20/100] Initial Loss: 0.1386, Training Loss: 0.0186, Initial Validation Loss: 0.1379, Validation Loss: 0.0340,V Acc: 0.8108, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.4242
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.9743589743589743
Fold [3/5] Epoch [0/100] Initial Loss: 0.1409, Training Loss: 0.1409, Initial Validation Loss: 0.1329, Validation Loss: 0.1329,V Acc: 0.4273, Top 70th Acc: 0.4545, Bottom 30th Acc: 0.3636
Fold [3/5] Epoch [10/100] Initial Loss: 0.1409, Training Loss: 0.0280, Initial Validation Loss: 0.1329, Validation Loss: 0.0329,V Acc: 0.8455, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.6667
Fold [3/5] Epoch [20/100] Initial Loss: 0.1409, Training Loss: 0.0185, Initial Validation Loss: 0.1329, Validation Loss: 0.0302,V Acc: 0.8545, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 22  Rolling back to Epoch (base 0): 17  Top Validation Acc: 0.948051948051948
Fold [4/5] Epoch [0/100] Initial Loss: 0.1402, Training Loss: 0.1402, Initial Validation Loss: 0.1326, Validation Loss: 0.1326,V Acc: 0.2844, Top 70th Acc: 0.2987, Bottom 30th Acc: 0.2500
Fold [4/5] Epoch [10/100] Initial Loss: 0.1402, Training Loss: 0.0349, Initial Validation Loss: 0.1326, Validation Loss: 0.0391,V Acc: 0.8440, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.6562
Fold [4/5] Epoch [20/100] Initial Loss: 0.1402, Training Loss: 0.0176, Initial Validation Loss: 0.1326, Validation Loss: 0.0326,V Acc: 0.8532, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.6875
Stopping early at Epoch (base 0): 21  Rolling back to Epoch (base 0): 16  Top Validation Acc: 0.935064935064935
Fold [5/5] Epoch [0/100] Initial Loss: 0.1396, Training Loss: 0.1396, Initial Validation Loss: 0.1336, Validation Loss: 0.1336,V Acc: 0.3981, Top 70th Acc: 0.4474, Bottom 30th Acc: 0.2812
Fold [5/5] Epoch [10/100] Initial Loss: 0.1396, Training Loss: 0.0406, Initial Validation Loss: 0.1336, Validation Loss: 0.0489,V Acc: 0.7500, Top 70th Acc: 0.9079, Bottom 30th Acc: 0.3750
Fold [5/5] Epoch [20/100] Initial Loss: 0.1396, Training Loss: 0.0208, Initial Validation Loss: 0.1336, Validation Loss: 0.0305,V Acc: 0.8426, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.6250
Fold [5/5] Epoch [30/100] Initial Loss: 0.1396, Training Loss: 0.0169, Initial Validation Loss: 0.1336, Validation Loss: 0.0294,V Acc: 0.8519, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.5938
Stopping early at Epoch (base 0): 34  Rolling back to Epoch (base 0): 29  Top Validation Acc: 0.9210526315789473
Running train_nn.py with seed 21
CUDA:False
Training samples count:  550
Training on 30 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1415, Training Loss: 0.1415, Initial Validation Loss: 0.1344, Validation Loss: 0.1344,V Acc: 0.2411, Top 70th Acc: 0.2911, Bottom 30th Acc: 0.1212
Fold [1/5] Epoch [10/100] Initial Loss: 0.1415, Training Loss: 0.0381, Initial Validation Loss: 0.1344, Validation Loss: 0.0461,V Acc: 0.7768, Top 70th Acc: 0.8861, Bottom 30th Acc: 0.5152
Fold [1/5] Epoch [20/100] Initial Loss: 0.1415, Training Loss: 0.0173, Initial Validation Loss: 0.1344, Validation Loss: 0.0354,V Acc: 0.8393, Top 70th Acc: 0.9367, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 27  Rolling back to Epoch (base 0): 22  Top Validation Acc: 0.9240506329113924
21 0 [array([0.64123213, 0.06636993, 0.01595701, 0.05819192, 0.218249  ],
      dtype=float32)]
Fold [2/5] Epoch [0/100] Initial Loss: 0.1397, Training Loss: 0.1397, Initial Validation Loss: 0.1367, Validation Loss: 0.1367,V Acc: 0.2523, Top 70th Acc: 0.3333, Bottom 30th Acc: 0.0606
Fold [2/5] Epoch [10/100] Initial Loss: 0.1397, Training Loss: 0.0307, Initial Validation Loss: 0.1367, Validation Loss: 0.0367,V Acc: 0.8468, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.5758
Fold [2/5] Epoch [20/100] Initial Loss: 0.1397, Training Loss: 0.0190, Initial Validation Loss: 0.1367, Validation Loss: 0.0270,V Acc: 0.9009, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.7576
Fold [2/5] Epoch [30/100] Initial Loss: 0.1397, Training Loss: 0.0160, Initial Validation Loss: 0.1367, Validation Loss: 0.0263,V Acc: 0.8739, Top 70th Acc: 0.9872, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 33  Rolling back to Epoch (base 0): 28  Top Validation Acc: 0.9743589743589743
Fold [3/5] Epoch [0/100] Initial Loss: 0.1366, Training Loss: 0.1366, Initial Validation Loss: 0.1314, Validation Loss: 0.1314,V Acc: 0.4727, Top 70th Acc: 0.5325, Bottom 30th Acc: 0.3333
Fold [3/5] Epoch [10/100] Initial Loss: 0.1366, Training Loss: 0.0442, Initial Validation Loss: 0.1314, Validation Loss: 0.0499,V Acc: 0.7273, Top 70th Acc: 0.8831, Bottom 30th Acc: 0.3636
Fold [3/5] Epoch [20/100] Initial Loss: 0.1366, Training Loss: 0.0205, Initial Validation Loss: 0.1314, Validation Loss: 0.0307,V Acc: 0.8636, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.6364
Fold [3/5] Epoch [30/100] Initial Loss: 0.1366, Training Loss: 0.0166, Initial Validation Loss: 0.1314, Validation Loss: 0.0293,V Acc: 0.8818, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.7273
Stopping early at Epoch (base 0): 32  Rolling back to Epoch (base 0): 27  Top Validation Acc: 0.961038961038961
Fold [4/5] Epoch [0/100] Initial Loss: 0.1381, Training Loss: 0.1381, Initial Validation Loss: 0.1336, Validation Loss: 0.1336,V Acc: 0.2477, Top 70th Acc: 0.3506, Bottom 30th Acc: 0.0000
Fold [4/5] Epoch [10/100] Initial Loss: 0.1381, Training Loss: 0.0258, Initial Validation Loss: 0.1336, Validation Loss: 0.0324,V Acc: 0.8532, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.5938
Fold [4/5] Epoch [20/100] Initial Loss: 0.1381, Training Loss: 0.0169, Initial Validation Loss: 0.1336, Validation Loss: 0.0298,V Acc: 0.8624, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.5938
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.961038961038961
Fold [5/5] Epoch [0/100] Initial Loss: 0.1397, Training Loss: 0.1397, Initial Validation Loss: 0.1274, Validation Loss: 0.1274,V Acc: 0.3333, Top 70th Acc: 0.4211, Bottom 30th Acc: 0.1250
Fold [5/5] Epoch [10/100] Initial Loss: 0.1397, Training Loss: 0.0299, Initial Validation Loss: 0.1274, Validation Loss: 0.0277,V Acc: 0.8241, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.5312
Fold [5/5] Epoch [20/100] Initial Loss: 0.1397, Training Loss: 0.0184, Initial Validation Loss: 0.1274, Validation Loss: 0.0254,V Acc: 0.8519, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.6562
Fold [5/5] Epoch [30/100] Initial Loss: 0.1397, Training Loss: 0.0157, Initial Validation Loss: 0.1274, Validation Loss: 0.0256,V Acc: 0.8519, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.6562
Stopping early at Epoch (base 0): 30  Rolling back to Epoch (base 0): 25  Top Validation Acc: 0.9342105263157895
Running train_nn.py with seed 22
CUDA:False
Training samples count:  550
Training on 30 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1391, Training Loss: 0.1391, Initial Validation Loss: 0.1316, Validation Loss: 0.1316,V Acc: 0.2768, Top 70th Acc: 0.3418, Bottom 30th Acc: 0.1212
Fold [1/5] Epoch [10/100] Initial Loss: 0.1391, Training Loss: 0.0332, Initial Validation Loss: 0.1316, Validation Loss: 0.0411,V Acc: 0.8304, Top 70th Acc: 0.9114, Bottom 30th Acc: 0.6364
Fold [1/5] Epoch [20/100] Initial Loss: 0.1391, Training Loss: 0.0204, Initial Validation Loss: 0.1316, Validation Loss: 0.0341,V Acc: 0.7946, Top 70th Acc: 0.9367, Bottom 30th Acc: 0.4545
Fold [1/5] Epoch [30/100] Initial Loss: 0.1391, Training Loss: 0.0167, Initial Validation Loss: 0.1316, Validation Loss: 0.0332,V Acc: 0.8304, Top 70th Acc: 0.9367, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 35  Rolling back to Epoch (base 0): 30  Top Validation Acc:
Fold [5/5] Epoch [60/100] Initial Loss: 0.1364, Training Loss: 0.0773, Initial Validation Loss: 0.1254, Validation Loss: 0.0745,V Acc: 0.6389, Top 70th Acc: 0.7632, Bottom 30th Acc: 0.3438
Fold [5/5] Epoch [70/100] Initial Loss: 0.1364, Training Loss: 0.0773, Initial Validation Loss: 0.1254, Validation Loss: 0.0741,V Acc: 0.6389, Top 70th Acc: 0.7632, Bottom 30th Acc: 0.3438
Fold [5/5] Epoch [80/100] Initial Loss: 0.1364, Training Loss: 0.0769, Initial Validation Loss: 0.1254, Validation Loss: 0.0737,V Acc: 0.6389, Top 70th Acc: 0.7763, Bottom 30th Acc: 0.3125
Stopping early at Epoch (base 0): 87  Rolling back to Epoch (base 0): 82  Top Validation Acc: 0.7631578947368421
Running train_nn.py with seed 19
CUDA:False
Training samples count:  550
Training on 2 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1342, Training Loss: 0.1342, Initial Validation Loss: 0.1329, Validation Loss: 0.1329,V Acc: 0.5000, Top 70th Acc: 0.4937, Bottom 30th Acc: 0.5152
Fold [1/5] Epoch [10/100] Initial Loss: 0.1342, Training Loss: 0.0817, Initial Validation Loss: 0.1329, Validation Loss: 0.0817,V Acc: 0.6607, Top 70th Acc: 0.7595, Bottom 30th Acc: 0.4242
Fold [1/5] Epoch [20/100] Initial Loss: 0.1342, Training Loss: 0.0794, Initial Validation Loss: 0.1329, Validation Loss: 0.0776,V Acc: 0.6696, Top 70th Acc: 0.7722, Bottom 30th Acc: 0.4242
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.7468354430379747
Fold [2/5] Epoch [0/100] Initial Loss: 0.1383, Training Loss: 0.1383, Initial Validation Loss: 0.1230, Validation Loss: 0.1230,V Acc: 0.2793, Top 70th Acc: 0.3462, Bottom 30th Acc: 0.1212
Fold [2/5] Epoch [10/100] Initial Loss: 0.1383, Training Loss: 0.0811, Initial Validation Loss: 0.1230, Validation Loss: 0.0799,V Acc: 0.5766, Top 70th Acc: 0.7179, Bottom 30th Acc: 0.2424
Fold [2/5] Epoch [20/100] Initial Loss: 0.1383, Training Loss: 0.0788, Initial Validation Loss: 0.1230, Validation Loss: 0.0805,V Acc: 0.5676, Top 70th Acc: 0.6923, Bottom 30th Acc: 0.2727
Stopping early at Epoch (base 0): 29  Rolling back to Epoch (base 0): 24  Top Validation Acc: 0.717948717948718
19 1 [array([0.12612031, 0.36322257, 0.12441082, 0.230004  , 0.15624225],
      dtype=float32)]
Fold [3/5] Epoch [0/100] Initial Loss: 0.1383, Training Loss: 0.1383, Initial Validation Loss: 0.1251, Validation Loss: 0.1251,V Acc: 0.4273, Top 70th Acc: 0.4675, Bottom 30th Acc: 0.3333
Fold [3/5] Epoch [10/100] Initial Loss: 0.1383, Training Loss: 0.0806, Initial Validation Loss: 0.1251, Validation Loss: 0.0769,V Acc: 0.6455, Top 70th Acc: 0.7662, Bottom 30th Acc: 0.3636
Fold [3/5] Epoch [20/100] Initial Loss: 0.1383, Training Loss: 0.0794, Initial Validation Loss: 0.1251, Validation Loss: 0.0759,V Acc: 0.6273, Top 70th Acc: 0.7662, Bottom 30th Acc: 0.3030
Stopping early at Epoch (base 0): 22  Rolling back to Epoch (base 0): 17  Top Validation Acc: 0.7792207792207793
Fold [4/5] Epoch [0/100] Initial Loss: 0.1373, Training Loss: 0.1373, Initial Validation Loss: 0.1275, Validation Loss: 0.1275,V Acc: 0.4954, Top 70th Acc: 0.6364, Bottom 30th Acc: 0.1562
Fold [4/5] Epoch [10/100] Initial Loss: 0.1373, Training Loss: 0.0786, Initial Validation Loss: 0.1275, Validation Loss: 0.0859,V Acc: 0.5780, Top 70th Acc: 0.7143, Bottom 30th Acc: 0.2500
Stopping early at Epoch (base 0): 19  Rolling back to Epoch (base 0): 14  Top Validation Acc: 0.6753246753246753
Fold [5/5] Epoch [0/100] Initial Loss: 0.1344, Training Loss: 0.1344, Initial Validation Loss: 0.1260, Validation Loss: 0.1260,V Acc: 0.3519, Top 70th Acc: 0.3553, Bottom 30th Acc: 0.3438
Fold [5/5] Epoch [10/100] Initial Loss: 0.1344, Training Loss: 0.0817, Initial Validation Loss: 0.1260, Validation Loss: 0.0752,V Acc: 0.6852, Top 70th Acc: 0.7500, Bottom 30th Acc: 0.5312
Fold [5/5] Epoch [20/100] Initial Loss: 0.1344, Training Loss: 0.0801, Initial Validation Loss: 0.1260, Validation Loss: 0.0731,V Acc: 0.6667, Top 70th Acc: 0.7500, Bottom 30th Acc: 0.4688
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.7368421052631579
Running train_nn.py with seed 20
CUDA:False
Training samples count:  550
Training on 2 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1415, Training Loss: 0.1415, Initial Validation Loss: 0.1332, Validation Loss: 0.1332,V Acc: 0.3304, Top 70th Acc: 0.3544, Bottom 30th Acc: 0.2727
Fold [1/5] Epoch [10/100] Initial Loss: 0.1415, Training Loss: 0.0823, Initial Validation Loss: 0.1332, Validation Loss: 0.0796,V Acc: 0.6250, Top 70th Acc: 0.7342, Bottom 30th Acc: 0.3636
Fold [1/5] Epoch [20/100] Initial Loss: 0.1415, Training Loss: 0.0797, Initial Validation Loss: 0.1332, Validation Loss: 0.0778,V Acc: 0.6339, Top 70th Acc: 0.7595, Bottom 30th Acc: 0.3333
Stopping early at Epoch (base 0): 27  Rolling back to Epoch (base 0): 22  Top Validation Acc: 0.7341772151898734
20 0 [array([0.10600249, 0.3973459 , 0.13596961, 0.20903276, 0.15164924],
      dtype=float32)]
Fold [2/5] Epoch [0/100] Initial Loss: 0.1306, Training Loss: 0.1306, Initial Validation Loss: 0.1165, Validation Loss: 0.1165,V Acc: 0.4955, Top 70th Acc: 0.6026, Bottom 30th Acc: 0.2424
Fold [2/5] Epoch [10/100] Initial Loss: 0.1306, Training Loss: 0.0795, Initial Validation Loss: 0.1165, Validation Loss: 0.0843,V Acc: 0.6396, Top 70th Acc: 0.7692, Bottom 30th Acc: 0.3333
Stopping early at Epoch (base 0): 19  Rolling back to Epoch (base 0): 14  Top Validation Acc: 0.7307692307692307
Fold [3/5] Epoch [0/100] Initial Loss: 0.1380, Training Loss: 0.1380, Initial Validation Loss: 0.1285, Validation Loss: 0.1285,V Acc: 0.3455, Top 70th Acc: 0.4416, Bottom 30th Acc: 0.1212
Fold [3/5] Epoch [10/100] Initial Loss: 0.1380, Training Loss: 0.0844, Initial Validation Loss: 0.1285, Validation Loss: 0.0671,V Acc: 0.6818, Top 70th Acc: 0.8182, Bottom 30th Acc: 0.3636
Fold [3/5] Epoch [20/100] Initial Loss: 0.1380, Training Loss: 0.0827, Initial Validation Loss: 0.1285, Validation Loss: 0.0639,V Acc: 0.7091, Top 70th Acc: 0.8052, Bottom 30th Acc: 0.4848
Fold [3/5] Epoch [30/100] Initial Loss: 0.1380, Training Loss: 0.0826, Initial Validation Loss: 0.1285, Validation Loss: 0.0629,V Acc: 0.7000, Top 70th Acc: 0.8182, Bottom 30th Acc: 0.4242
Stopping early at Epoch (base 0): 33  Rolling back to Epoch (base 0): 28  Top Validation Acc: 0.8311688311688312
Fold [4/5] Epoch [0/100] Initial Loss: 0.1417, Training Loss: 0.1417, Initial Validation Loss: 0.1334, Validation Loss: 0.1334,V Acc: 0.2477, Top 70th Acc: 0.1039, Bottom 30th Acc: 0.5938
Fold [4/5] Epoch [10/100] Initial Loss: 0.1417, Training Loss: 0.0800, Initial Validation Loss: 0.1334, Validation Loss: 0.0850,V Acc: 0.5780, Top 70th Acc: 0.7013, Bottom 30th Acc: 0.2812
Fold [4/5] Epoch [20/100] Initial Loss: 0.1417, Training Loss: 0.0774, Initial Validation Loss: 0.1334, Validation Loss: 0.0828,V Acc: 0.5872, Top 70th Acc: 0.6753, Bottom 30th Acc: 0.3750
Fold [4/5] Epoch [30/100] Initial Loss: 0.1417, Training Loss: 0.0769, Initial Validation Loss: 0.1334, Validation Loss: 0.0819,V Acc: 0.5872, Top 70th Acc: 0.7013, Bottom 30th Acc: 0.3125
Stopping early at Epoch (base 0): 30  Rolling back to Epoch (base 0): 25  Top Validation Acc: 0.7012987012987013
Fold [5/5] Epoch [0/100] Initial Loss: 0.1311, Training Loss: 0.1311, Initial Validation Loss: 0.1207, Validation Loss: 0.1207,V Acc: 0.4537, Top 70th Acc: 0.5789, Bottom 30th Acc: 0.1562
Fold [5/5] Epoch [10/100] Initial Loss: 0.1311, Training Loss: 0.0790, Initial Validation Loss: 0.1207, Validation Loss: 0.0846,V Acc: 0.5833, Top 70th Acc: 0.6842, Bottom 30th Acc: 0.3438
Fold [5/5] Epoch [20/100] Initial Loss: 0.1311, Training Loss: 0.0773, Initial Validation Loss: 0.1207, Validation Loss: 0.0836,V Acc: 0.5926, Top 70th Acc: 0.6842, Bottom 30th Acc: 0.3750
Fold [5/5] Epoch [30/100] Initial Loss: 0.1311, Training Loss: 0.0768, Initial Validation Loss: 0.1207, Validation Loss: 0.0831,V Acc: 0.5926, Top 70th Acc: 0.6842, Bottom 30th Acc: 0.3750
Fold [5/5] Epoch [40/100] Initial Loss: 0.1311, Training Loss: 0.0763, Initial Validation Loss: 0.1207, Validation Loss: 0.0832,V Acc: 0.5833, Top 70th Acc: 0.6711, Bottom 30th Acc: 0.3750
Stopping early at Epoch (base 0): 41  Rolling back to Epoch (base 0): 36  Top Validation Acc: 0.8701298701298701
Fold [4/5] Epoch [0/100] Initial Loss: 0.1399, Training Loss: 0.1399, Initial Validation Loss: 0.1345, Validation Loss: 0.1345,V Acc: 0.2752, Top 70th Acc: 0.3117, Bottom 30th Acc: 0.1875
Fold [4/5] Epoch [10/100] Initial Loss: 0.1399, Training Loss: 0.0377, Initial Validation Loss: 0.1345, Validation Loss: 0.0402,V Acc: 0.7982, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.4375
Fold [4/5] Epoch [20/100] Initial Loss: 0.1399, Training Loss: 0.0229, Initial Validation Loss: 0.1345, Validation Loss: 0.0309,V Acc: 0.8532, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6250
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.935064935064935
Fold [5/5] Epoch [0/100] Initial Loss: 0.1383, Training Loss: 0.1383, Initial Validation Loss: 0.1318, Validation Loss: 0.1318,V Acc: 0.2685, Top 70th Acc: 0.3553, Bottom 30th Acc: 0.0625
Fold [5/5] Epoch [10/100] Initial Loss: 0.1383, Training Loss: 0.0325, Initial Validation Loss: 0.1318, Validation Loss: 0.0371,V Acc: 0.8056, Top 70th Acc: 0.9211, Bottom 30th Acc: 0.5312
Fold [5/5] Epoch [20/100] Initial Loss: 0.1383, Training Loss: 0.0230, Initial Validation Loss: 0.1318, Validation Loss: 0.0333,V Acc: 0.8519, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.6562
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.9342105263157895
Running train_nn.py with seed 20
CUDA:False
Training samples count:  550
Training on 20 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1382, Training Loss: 0.1382, Initial Validation Loss: 0.1300, Validation Loss: 0.1300,V Acc: 0.3750, Top 70th Acc: 0.3797, Bottom 30th Acc: 0.3636
Fold [1/5] Epoch [10/100] Initial Loss: 0.1382, Training Loss: 0.0368, Initial Validation Loss: 0.1300, Validation Loss: 0.0538,V Acc: 0.7411, Top 70th Acc: 0.8354, Bottom 30th Acc: 0.5152
Fold [1/5] Epoch [20/100] Initial Loss: 0.1382, Training Loss: 0.0244, Initial Validation Loss: 0.1300, Validation Loss: 0.0404,V Acc: 0.8036, Top 70th Acc: 0.8734, Bottom 30th Acc: 0.6364
Fold [1/5] Epoch [30/100] Initial Loss: 0.1382, Training Loss: 0.0220, Initial Validation Loss: 0.1300, Validation Loss: 0.0381,V Acc: 0.8125, Top 70th Acc: 0.8987, Bottom 30th Acc: 0.6061
Fold [1/5] Epoch [40/100] Initial Loss: 0.1382, Training Loss: 0.0209, Initial Validation Loss: 0.1300, Validation Loss: 0.0369,V Acc: 0.8125, Top 70th Acc: 0.9114, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 45  Rolling back to Epoch (base 0): 40  Top Validation Acc: 0.9240506329113924
20 0 [array([0.27826014, 0.07509185, 0.08718504, 0.19366005, 0.3658029 ],
      dtype=float32)]
Fold [2/5] Epoch [0/100] Initial Loss: 0.1371, Training Loss: 0.1371, Initial Validation Loss: 0.1361, Validation Loss: 0.1361,V Acc: 0.3153, Top 70th Acc: 0.3077, Bottom 30th Acc: 0.3333
Fold [2/5] Epoch [10/100] Initial Loss: 0.1371, Training Loss: 0.0382, Initial Validation Loss: 0.1361, Validation Loss: 0.0452,V Acc: 0.7928, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.4848
Fold [2/5] Epoch [20/100] Initial Loss: 0.1371, Training Loss: 0.0229, Initial Validation Loss: 0.1361, Validation Loss: 0.0352,V Acc: 0.8108, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.4848
Stopping early at Epoch (base 0): 29  Rolling back to Epoch (base 0): 24  Top Validation Acc: 0.9487179487179487
Fold [3/5] Epoch [0/100] Initial Loss: 0.1394, Training Loss: 0.1394, Initial Validation Loss: 0.1337, Validation Loss: 0.1337,V Acc: 0.2545, Top 70th Acc: 0.2987, Bottom 30th Acc: 0.1515
Fold [3/5] Epoch [10/100] Initial Loss: 0.1394, Training Loss: 0.0326, Initial Validation Loss: 0.1337, Validation Loss: 0.0341,V Acc: 0.8455, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.6364
Fold [3/5] Epoch [20/100] Initial Loss: 0.1394, Training Loss: 0.0235, Initial Validation Loss: 0.1337, Validation Loss: 0.0316,V Acc: 0.8455, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 20  Rolling back to Epoch (base 0): 15  Top Validation Acc: 0.922077922077922
Fold [4/5] Epoch [0/100] Initial Loss: 0.1353, Training Loss: 0.1353, Initial Validation Loss: 0.1249, Validation Loss: 0.1249,V Acc: 0.4128, Top 70th Acc: 0.4156, Bottom 30th Acc: 0.4062
Fold [4/5] Epoch [10/100] Initial Loss: 0.1353, Training Loss: 0.0315, Initial Validation Loss: 0.1249, Validation Loss: 0.0371,V Acc: 0.8624, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.7188
Fold [4/5] Epoch [20/100] Initial Loss: 0.1353, Training Loss: 0.0218, Initial Validation Loss: 0.1249, Validation Loss: 0.0358,V Acc: 0.8440, Top 70th Acc: 0.8961, Bottom 30th Acc: 0.7188
Stopping early at Epoch (base 0): 22  Rolling back to Epoch (base 0): 17  Top Validation Acc: 0.922077922077922
Fold [5/5] Epoch [0/100] Initial Loss: 0.1380, Training Loss: 0.1380, Initial Validation Loss: 0.1314, Validation Loss: 0.1314,V Acc: 0.3148, Top 70th Acc: 0.3553, Bottom 30th Acc: 0.2188
Fold [5/5] Epoch [10/100] Initial Loss: 0.1380, Training Loss: 0.0405, Initial Validation Loss: 0.1314, Validation Loss: 0.0450,V Acc: 0.8241, Top 70th Acc: 0.8947, Bottom 30th Acc: 0.6562
Fold [5/5] Epoch [20/100] Initial Loss: 0.1380, Training Loss: 0.0255, Initial Validation Loss: 0.1314, Validation Loss: 0.0317,V Acc: 0.8426, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.6250
Fold [5/5] Epoch [30/100] Initial Loss: 0.1380, Training Loss: 0.0224, Initial Validation Loss: 0.1314, Validation Loss: 0.0305,V Acc: 0.8519, Top 70th Acc: 0.9211, Bottom 30th Acc: 0.6875
Stopping early at Epoch (base 0): 35  Rolling back to Epoch (base 0): 30  Top Validation Acc: 0.9210526315789473
Running train_nn.py with seed 21
CUDA:False
Training samples count:  550
Training on 20 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1424, Training Loss: 0.1424, Initial Validation Loss: 0.1335, Validation Loss: 0.1335,V Acc: 0.3214, Top 70th Acc: 0.3671, Bottom 30th Acc: 0.2121
Fold [1/5] Epoch [10/100] Initial Loss: 0.1424, Training Loss: 0.0508, Initial Validation Loss: 0.1335, Validation Loss: 0.0529,V Acc: 0.7232, Top 70th Acc: 0.8734, Bottom 30th Acc: 0.3636
Fold [1/5] Epoch [20/100] Initial Loss: 0.1424, Training Loss: 0.0244, Initial Validation Loss: 0.1335, Validation Loss: 0.0388,V Acc: 0.8125, Top 70th Acc: 0.8861, Bottom 30th Acc: 0.6364
Fold [1/5] Epoch [30/100] Initial Loss: 0.1424, Training Loss: 0.0194, Initial Validation Loss: 0.1335, Validation Loss: 0.0384,V Acc: 0.8393, Top 70th Acc: 0.8987, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 32  Rolling back to Epoch (base 0): 27  Top Validation Acc: 0.8987341772151899
21 0 [array([0.6159744 , 0.09007151, 0.08433075, 0.11956917, 0.0900541 ],
      dtype=float32)]
Fold [2/5] Epoch [0/100] Initial Loss: 0.1385, Training Loss: 0.1385, Initial Validation Loss: 0.1356, Validation Loss: 0.1356,V Acc: 0.2973, Top 70th Acc: 0.3590, Bottom 30th Acc: 0.1515
Fold [2/5] Epoch [10/100] Initial Loss: 0.1385, Training Loss: 0.0290, Initial Validation Loss: 0.1356, Validation Loss: 0.0367,V Acc: 0.8739, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.7273
Fold [2/5] Epoch [20/100] Initial Loss: 0.1385, Training Loss: 0.0229, Initial Validation Loss: 0.1356, Validation Loss: 0.0332,V Acc: 0.8559, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.9487179487179487
Fold [3/5] Epoch [0/100] Initial Loss: 0.1384, Training Loss: 0.1384, Initial Validation Loss: 0.1334, Validation Loss: 0.1334,V Acc: 0.3000, Top 70th Acc: 0.3506, Bottom 30th Acc: 0.1818
Fold [3/5] Epoch [10/100] Initial Loss: 0.1384, Training Loss: 0.0437, Initial Validation Loss: 0.1334, Validation Loss: 0.0460,V Acc: 0.7909, Top 70th Acc: 0.8831, Bottom 30th Acc: 0.5758
Fold [3/5] Epoch [20/100] Initial Loss: 0.1384, Training Loss: 0.0257, Initial Validation Loss: 0.1334, Validation Loss: 0.0347,V Acc: 0.8273, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 27  Rolling back to Epoch (base 0): 22  Top Validation Acc: 0.948051948051948
Fold [4/5] Epoch [0/100] Initial Loss: 0.1386, Training Loss: 0.1386, Initial Validation Loss: 0.1348, Validation Loss: 0.1348,V Acc: 0.3211, Top 70th Acc: 0.3506, Bottom 30th Acc: 0.2500
Fold [4/5] Epoch [10/100] Initial Loss: 0.1386, Training Loss: 0.0435, Initial Validation Loss: 0.1348, Validation Loss: 0.0492,V Acc: 0.7890, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.5000/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)

Stopping early at Epoch (base 0): 29  Rolling back to Epoch (base 0): 24  Top Validation Acc: 0.987012987012987
Fold [4/5] Epoch [0/100] Initial Loss: 0.1367, Training Loss: 0.1367, Initial Validation Loss: 0.1276, Validation Loss: 0.1276,V Acc: 0.4404, Top 70th Acc: 0.5325, Bottom 30th Acc: 0.2188
Fold [4/5] Epoch [10/100] Initial Loss: 0.1367, Training Loss: 0.0256, Initial Validation Loss: 0.1276, Validation Loss: 0.0264,V Acc: 0.8899, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.6875
Fold [4/5] Epoch [20/100] Initial Loss: 0.1367, Training Loss: 0.0152, Initial Validation Loss: 0.1276, Validation Loss: 0.0255,V Acc: 0.8624, Top 70th Acc: 0.9870, Bottom 30th Acc: 0.5625
Stopping early at Epoch (base 0): 21  Rolling back to Epoch (base 0): 16  Top Validation Acc: 0.987012987012987
Fold [5/5] Epoch [0/100] Initial Loss: 0.1300, Training Loss: 0.1300, Initial Validation Loss: 0.1150, Validation Loss: 0.1150,V Acc: 0.4907, Top 70th Acc: 0.5921, Bottom 30th Acc: 0.2500
Fold [5/5] Epoch [10/100] Initial Loss: 0.1300, Training Loss: 0.0234, Initial Validation Loss: 0.1150, Validation Loss: 0.0260,V Acc: 0.8981, Top 70th Acc: 0.9737, Bottom 30th Acc: 0.7188
Fold [5/5] Epoch [20/100] Initial Loss: 0.1300, Training Loss: 0.0159, Initial Validation Loss: 0.1150, Validation Loss: 0.0279,V Acc: 0.8611, Top 70th Acc: 0.9737, Bottom 30th Acc: 0.5938
Stopping early at Epoch (base 0): 20  Rolling back to Epoch (base 0): 15  Top Validation Acc: 0.9736842105263158
Running train_nn.py with seed 29
CUDA:False
Training samples count:  550
Training on 21 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1330, Training Loss: 0.1330, Initial Validation Loss: 0.1229, Validation Loss: 0.1229,V Acc: 0.5446, Top 70th Acc: 0.6962, Bottom 30th Acc: 0.1818
Fold [1/5] Epoch [10/100] Initial Loss: 0.1330, Training Loss: 0.0271, Initial Validation Loss: 0.1229, Validation Loss: 0.0175,V Acc: 0.9107, Top 70th Acc: 1.0000, Bottom 30th Acc: 0.6970
Fold [1/5] Epoch [20/100] Initial Loss: 0.1330, Training Loss: 0.0182, Initial Validation Loss: 0.1229, Validation Loss: 0.0157,V Acc: 0.9196, Top 70th Acc: 1.0000, Bottom 30th Acc: 0.7273
Stopping early at Epoch (base 0): 21  Rolling back to Epoch (base 0): 16  Top Validation Acc: 1.0
Fold [2/5] Epoch [0/100] Initial Loss: 0.1297, Training Loss: 0.1297, Initial Validation Loss: 0.1200, Validation Loss: 0.1200,V Acc: 0.4775, Top 70th Acc: 0.5385, Bottom 30th Acc: 0.3333
Fold [2/5] Epoch [10/100] Initial Loss: 0.1297, Training Loss: 0.0379, Initial Validation Loss: 0.1200, Validation Loss: 0.0385,V Acc: 0.8378, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.5758
Fold [2/5] Epoch [20/100] Initial Loss: 0.1297, Training Loss: 0.0190, Initial Validation Loss: 0.1200, Validation Loss: 0.0226,V Acc: 0.8829, Top 70th Acc: 0.9872, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 28  Rolling back to Epoch (base 0): 23  Top Validation Acc: 0.9743589743589743
29 1 [array([0.7672891 , 0.01547844, 0.02921269, 0.1308733 , 0.05714656],
      dtype=float32)]
Fold [3/5] Epoch [0/100] Initial Loss: 0.1398, Training Loss: 0.1398, Initial Validation Loss: 0.1290, Validation Loss: 0.1290,V Acc: 0.3727, Top 70th Acc: 0.5195, Bottom 30th Acc: 0.0303
Fold [3/5] Epoch [10/100] Initial Loss: 0.1398, Training Loss: 0.0219, Initial Validation Loss: 0.1290, Validation Loss: 0.0299,V Acc: 0.8727, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 18  Rolling back to Epoch (base 0): 13  Top Validation Acc: 0.961038961038961
Fold [4/5] Epoch [0/100] Initial Loss: 0.1366, Training Loss: 0.1366, Initial Validation Loss: 0.1218, Validation Loss: 0.1218,V Acc: 0.4220, Top 70th Acc: 0.4935, Bottom 30th Acc: 0.2500
Fold [4/5] Epoch [10/100] Initial Loss: 0.1366, Training Loss: 0.0221, Initial Validation Loss: 0.1218, Validation Loss: 0.0295,V Acc: 0.8440, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.5938
Stopping early at Epoch (base 0): 17  Rolling back to Epoch (base 0): 12  Top Validation Acc: 0.974025974025974
Fold [5/5] Epoch [0/100] Initial Loss: 0.1349, Training Loss: 0.1349, Initial Validation Loss: 0.1233, Validation Loss: 0.1233,V Acc: 0.4167, Top 70th Acc: 0.5000, Bottom 30th Acc: 0.2188
Fold [5/5] Epoch [10/100] Initial Loss: 0.1349, Training Loss: 0.0209, Initial Validation Loss: 0.1233, Validation Loss: 0.0249,V Acc: 0.8889, Top 70th Acc: 0.9737, Bottom 30th Acc: 0.6875
Fold [5/5] Epoch [20/100] Initial Loss: 0.1349, Training Loss: 0.0151, Initial Validation Loss: 0.1233, Validation Loss: 0.0228,V Acc: 0.8889, Top 70th Acc: 0.9737, Bottom 30th Acc: 0.6875
Fold [5/5] Epoch [30/100] Initial Loss: 0.1349, Training Loss: 0.0136, Initial Validation Loss: 0.1233, Validation Loss: 0.0239,V Acc: 0.8611, Top 70th Acc: 0.9737, Bottom 30th Acc: 0.5938
Stopping early at Epoch (base 0): 30  Rolling back to Epoch (base 0): 25  Top Validation Acc: 0.9736842105263158
Running train_nn.py with seed 30
CUDA:False
Training samples count:  550
Training on 21 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1369, Training Loss: 0.1369, Initial Validation Loss: 0.1247, Validation Loss: 0.1247,V Acc: 0.3482, Top 70th Acc: 0.4304, Bottom 30th Acc: 0.1515
Fold [1/5] Epoch [10/100] Initial Loss: 0.1369, Training Loss: 0.0222, Initial Validation Loss: 0.1247, Validation Loss: 0.0343,V Acc: 0.8036, Top 70th Acc: 0.9494, Bottom 30th Acc: 0.4545
Stopping early at Epoch (base 0): 18  Rolling back to Epoch (base 0): 13  Top Validation Acc: 0.9620253164556962
Fold [2/5] Epoch [0/100] Initial Loss: 0.1310, Training Loss: 0.1310, Initial Validation Loss: 0.1188, Validation Loss: 0.1188,V Acc: 0.4685, Top 70th Acc: 0.5513, Bottom 30th Acc: 0.2727
Fold [2/5] Epoch [10/100] Initial Loss: 0.1310, Training Loss: 0.0205, Initial Validation Loss: 0.1188, Validation Loss: 0.0413,V Acc: 0.8108, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.5758
Fold [2/5] Epoch [20/100] Initial Loss: 0.1310, Training Loss: 0.0150, Initial Validation Loss: 0.1188, Validation Loss: 0.0299,V Acc: 0.8378, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.5152
Stopping early at Epoch (base 0): 21  Rolling back to Epoch (base 0): 16  Top Validation Acc: 0.9487179487179487
30 1 [array([0.7750405 , 0.01820557, 0.01629916, 0.09820817, 0.09224664],
      dtype=float32)]
Fold [3/5] Epoch [0/100] Initial Loss: 0.1375, Training Loss: 0.1375, Initial Validation Loss: 0.1259, Validation Loss: 0.1259,V Acc: 0.4364, Top 70th Acc: 0.5584, Bottom 30th Acc: 0.1515
Fold [3/5] Epoch [10/100] Initial Loss: 0.1375, Training Loss: 0.0223, Initial Validation Loss: 0.1259, Validation Loss: 0.0245,V Acc: 0.9000, Top 70th Acc: 1.0000, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 19  Rolling back to Epoch (base 0): 14  Top Validation Acc: 1.0
Fold [4/5] Epoch [0/100] Initial Loss: 0.1397, Training Loss: 0.1397, Initial Validation Loss: 0.1298, Validation Loss: 0.1298,V Acc: 0.3578, Top 70th Acc: 0.4545, Bottom 30th Acc: 0.1250
Fold [4/5] Epoch [10/100] Initial Loss: 0.1397, Training Loss: 0.0253, Initial Validation Loss: 0.1298, Validation Loss: 0.0304,V Acc: 0.8532, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.6562
Fold [4/5] Epoch [20/100] Initial Loss: 0.1397, Training Loss: 0.0159, Initial Validation Loss: 0.1298, Validation Loss: 0.0210,V Acc: 0.9174, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.8125
Stopping early at Epoch (base 0): 22  Rolling back to Epoch (base 0): 17  Top Validation Acc: 0.961038961038961
Fold [5/5] Epoch [0/100] Initial Loss: 0.1320, Training Loss: 0.1320, Initial Validation Loss: 0.1136, Validation Loss: 0.1136,V Acc: 0.5463, Top 70th Acc: 0.6447, Bottom 30th Acc: 0.3125
Fold [5/5] Epoch [10/100] Initial Loss: 0.1320, Training Loss: 0.0213, Initial Validation Loss: 0.1136, Validation Loss: 0.0265,V Acc: 0.9074, Top 70th Acc: 0.9737, Bottom 30th Acc: 0.7500
Stopping early at Epoch (base 0): 15  Rolling back to Epoch (base 0): 10  Top Validation Acc: 0.9605263157894737
Running train_nn.py with seed 31
CUDA:False
Training samples count:  550
Training on 21 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1305, Training Loss: 0.1305, Initial Validation Loss: 0.1256, Validation Loss: 0.1256,V Acc: 0.3571, Top 70th Acc: 0.4684, Bottom 30th Acc: 0.0909
Fold [1/5] Epoch [10/100] Initial Loss: 0.1305, Training Loss: 0.0224, Initial Validation Loss: 0.1256, Validation Loss: 0.0426,V Acc: 0.8036, Top 70th Acc: 0.8987, Bottom 30th Acc: 0.5758
Fold [4/5] Epoch [0/100] Initial Loss: 0.1390, Training Loss: 0.1390, Initial Validation Loss: 0.1352, Validation Loss: 0.1352,V Acc: 0.2569, Top 70th Acc: 0.3506, Bottom 30th Acc: 0.0312
Fold [4/5] Epoch [10/100] Initial Loss: 0.1390, Training Loss: 0.0165, Initial Validation Loss: 0.1352, Validation Loss: 0.0243,V Acc: 0.8991, Top 70th Acc: 0.9870, Bottom 30th Acc: 0.6875
Fold [4/5] Epoch [20/100] Initial Loss: 0.1390, Training Loss: 0.0051, Initial Validation Loss: 0.1352, Validation Loss: 0.0181,V Acc: 0.8991, Top 70th Acc: 0.9870, Bottom 30th Acc: 0.6875
Stopping early at Epoch (base 0): 27  Rolling back to Epoch (base 0): 22  Top Validation Acc: 0.987012987012987
Fold [5/5] Epoch [0/100] Initial Loss: 0.1397, Training Loss: 0.1397, Initial Validation Loss: 0.1319, Validation Loss: 0.1319,V Acc: 0.3333, Top 70th Acc: 0.3947, Bottom 30th Acc: 0.1875
Fold [5/5] Epoch [10/100] Initial Loss: 0.1397, Training Loss: 0.0202, Initial Validation Loss: 0.1319, Validation Loss: 0.0417,V Acc: 0.8056, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.5000
Fold [5/5] Epoch [20/100] Initial Loss: 0.1397, Training Loss: 0.0053, Initial Validation Loss: 0.1319, Validation Loss: 0.0334,V Acc: 0.8241, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.5000
Fold [5/5] Epoch [30/100] Initial Loss: 0.1397, Training Loss: 0.0038, Initial Validation Loss: 0.1319, Validation Loss: 0.0316,V Acc: 0.8426, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.5625
Fold [5/5] Epoch [40/100] Initial Loss: 0.1397, Training Loss: 0.0035, Initial Validation Loss: 0.1319, Validation Loss: 0.0309,V Acc: 0.8611, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.6562
Fold [5/5] Epoch [50/100] Initial Loss: 0.1397, Training Loss: 0.0034, Initial Validation Loss: 0.1319, Validation Loss: 0.0308,V Acc: 0.8704, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.6875
Stopping early at Epoch (base 0): 57  Rolling back to Epoch (base 0): 52  Top Validation Acc: 0.9342105263157895
Running train_nn.py with seed 16
CUDA:False
Training samples count:  550
Training on 162 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1383, Training Loss: 0.1383, Initial Validation Loss: 0.1377, Validation Loss: 0.1377,V Acc: 0.3929, Top 70th Acc: 0.5063, Bottom 30th Acc: 0.1212
Fold [1/5] Epoch [10/100] Initial Loss: 0.1383, Training Loss: 0.0129, Initial Validation Loss: 0.1377, Validation Loss: 0.0352,V Acc: 0.8750, Top 70th Acc: 0.9241, Bottom 30th Acc: 0.7576
Fold [1/5] Epoch [20/100] Initial Loss: 0.1383, Training Loss: 0.0042, Initial Validation Loss: 0.1377, Validation Loss: 0.0315,V Acc: 0.8661, Top 70th Acc: 0.9620, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 22  Rolling back to Epoch (base 0): 17  Top Validation Acc: 0.9493670886075949
16 0 [array([0.22374491, 0.09136874, 0.06661555, 0.27081573, 0.34745505],
      dtype=float32)]
Fold [2/5] Epoch [0/100] Initial Loss: 0.1408, Training Loss: 0.1408, Initial Validation Loss: 0.1330, Validation Loss: 0.1330,V Acc: 0.2703, Top 70th Acc: 0.3462, Bottom 30th Acc: 0.0909
Fold [2/5] Epoch [10/100] Initial Loss: 0.1408, Training Loss: 0.0204, Initial Validation Loss: 0.1330, Validation Loss: 0.0340,V Acc: 0.8378, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.6061
Fold [2/5] Epoch [20/100] Initial Loss: 0.1408, Training Loss: 0.0050, Initial Validation Loss: 0.1330, Validation Loss: 0.0245,V Acc: 0.8649, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.6667
Fold [2/5] Epoch [30/100] Initial Loss: 0.1408, Training Loss: 0.0039, Initial Validation Loss: 0.1330, Validation Loss: 0.0234,V Acc: 0.8829, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.7273
Fold [2/5] Epoch [40/100] Initial Loss: 0.1408, Training Loss: 0.0036, Initial Validation Loss: 0.1330, Validation Loss: 0.0229,V Acc: 0.8919, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.7576
Stopping early at Epoch (base 0): 42  Rolling back to Epoch (base 0): 37  Top Validation Acc: 0.9615384615384616
Fold [3/5] Epoch [0/100] Initial Loss: 0.1390, Training Loss: 0.1390, Initial Validation Loss: 0.1328, Validation Loss: 0.1328,V Acc: 0.4091, Top 70th Acc: 0.4545, Bottom 30th Acc: 0.3030
Fold [3/5] Epoch [10/100] Initial Loss: 0.1390, Training Loss: 0.0173, Initial Validation Loss: 0.1328, Validation Loss: 0.0333,V Acc: 0.8455, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.6364
Fold [3/5] Epoch [20/100] Initial Loss: 0.1390, Training Loss: 0.0062, Initial Validation Loss: 0.1328, Validation Loss: 0.0299,V Acc: 0.8455, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6061
Fold [3/5] Epoch [30/100] Initial Loss: 0.1390, Training Loss: 0.0048, Initial Validation Loss: 0.1328, Validation Loss: 0.0286,V Acc: 0.8455, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 33  Rolling back to Epoch (base 0): 28  Top Validation Acc: 0.948051948051948
Fold [4/5] Epoch [0/100] Initial Loss: 0.1400, Training Loss: 0.1400, Initial Validation Loss: 0.1319, Validation Loss: 0.1319,V Acc: 0.3670, Top 70th Acc: 0.4026, Bottom 30th Acc: 0.2812
Fold [4/5] Epoch [10/100] Initial Loss: 0.1400, Training Loss: 0.0170, Initial Validation Loss: 0.1319, Validation Loss: 0.0399,V Acc: 0.7982, Top 70th Acc: 0.8961, Bottom 30th Acc: 0.5625
Fold [4/5] Epoch [20/100] Initial Loss: 0.1400, Training Loss: 0.0063, Initial Validation Loss: 0.1319, Validation Loss: 0.0355,V Acc: 0.7890, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.4688
Fold [4/5] Epoch [30/100] Initial Loss: 0.1400, Training Loss: 0.0044, Initial Validation Loss: 0.1319, Validation Loss: 0.0329,V Acc: 0.8165, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.5312
Fold [4/5] Epoch [40/100] Initial Loss: 0.1400, Training Loss: 0.0039, Initial Validation Loss: 0.1319, Validation Loss: 0.0317,V Acc: 0.8165, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.5312
Stopping early at Epoch (base 0): 48  Rolling back to Epoch (base 0): 43  Top Validation Acc: 0.948051948051948
Fold [5/5] Epoch [0/100] Initial Loss: 0.1390, Training Loss: 0.1390, Initial Validation Loss: 0.1308, Validation Loss: 0.1308,V Acc: 0.2500, Top 70th Acc: 0.3421, Bottom 30th Acc: 0.0312
Fold [5/5] Epoch [10/100] Initial Loss: 0.1390, Training Loss: 0.0184, Initial Validation Loss: 0.1308, Validation Loss: 0.0351,V Acc: 0.8056, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.5000
Fold [5/5] Epoch [20/100] Initial Loss: 0.1390, Training Loss: 0.0064, Initial Validation Loss: 0.1308, Validation Loss: 0.0305,V Acc: 0.8519, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.6562
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.9342105263157895
Running train_nn.py with seed 17
CUDA:False
Training samples count:  550
Training on 162 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1401, Training Loss: 0.1401, Initial Validation Loss: 0.1383, Validation Loss: 0.1383,V Acc: 0.2411, Top 70th Acc: 0.3038, Bottom 30th Acc: 0.0909
Fold [1/5] Epoch [10/100] Initial Loss: 0.1401, Training Loss: 0.0211, Initial Validation Loss: 0.1383, Validation Loss: 0.0331,V Acc: 0.8571, Top 70th Acc: 0.9494, Bottom 30th Acc: 0.6364
Fold [1/5] Epoch [20/100] Initial Loss: 0.1401, Training Loss: 0.0049, Initial Validation Loss: 0.1383, Validation Loss: 0.0234,V Acc: 0.8839, Top 70th Acc: 0.9747, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 29  Rolling back to Epoch (base 0): 24  Top Validation Acc: 0.9746835443037974
Fold [2/5] Epoch [0/100] Initial Loss: 0.1394, Training Loss: 0.1394, Initial Validation Loss: 0.1331, Validation Loss: 0.1331,V Acc: 0.2613, Top 70th Acc: 0.2949, Bottom 30th Acc: 0.1818
Fold [2/5] Epoch [10/100] Initial Loss: 0.1394, Training Loss: 0.0100, Initial Validation Loss: 0.1331, Validation Loss: 0.0353,V Acc: 0.8288, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 17  Rolling back to Epoch (base 0): 12  Top Validation Acc: 0.9230769230769231
Fold [3/5] Epoch [0/100] Initial Loss: 0.1373, Training Loss: 0.1373, Initial Validation Loss: 0.1367, Validation Loss: 0.1367,V Acc: 0.3000, Top 70th Acc: 0.3766, Bottom 30th Acc: 0.1212
Fold [3/5] Epoch [10/100] Initial Loss: 0.1373, Training Loss: 0.0202, Initial Validation Loss: 0.1367, Validation Loss: 0.0367,V Acc: 0.8091, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.4545
Fold [3/5] Epoch [20/100] Initial Loss: 0.1373, Training Loss: 0.0054, Initial Validation Loss: 0.1367, Validation Loss: 0.0308,V Acc: 0.8455, Top 70th Acc: 0.9870, Bottom 30th Acc: 0.5152
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.922077922077922
Fold [5/5] Epoch [0/100] Initial Loss: 0.1394, Training Loss: 0.1394, Initial Validation Loss: 0.1349, Validation Loss: 0.1349,V Acc: 0.2500, Top 70th Acc: 0.2895, Bottom 30th Acc: 0.1562
Fold [5/5] Epoch [10/100] Initial Loss: 0.1394, Training Loss: 0.0387, Initial Validation Loss: 0.1349, Validation Loss: 0.0498,V Acc: 0.7778, Top 70th Acc: 0.8816, Bottom 30th Acc: 0.5312
Fold [5/5] Epoch [20/100] Initial Loss: 0.1394, Training Loss: 0.0208, Initial Validation Loss: 0.1349, Validation Loss: 0.0380,V Acc: 0.8241, Top 70th Acc: 0.8947, Bottom 30th Acc: 0.6562
Fold [5/5] Epoch [30/100] Initial Loss: 0.1394, Training Loss: 0.0153, Initial Validation Loss: 0.1349, Validation Loss: 0.0344,V Acc: 0.8426, Top 70th Acc: 0.8947, Bottom 30th Acc: 0.7188
Stopping early at Epoch (base 0): 35  Rolling back to Epoch (base 0): 30  Top Validation Acc: 0.9078947368421053
Running train_nn.py with seed 21
CUDA:False
Training samples count:  550
Training on 40 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1401, Training Loss: 0.1401, Initial Validation Loss: 0.1341, Validation Loss: 0.1341,V Acc: 0.3571, Top 70th Acc: 0.3797, Bottom 30th Acc: 0.3030
Fold [1/5] Epoch [10/100] Initial Loss: 0.1401, Training Loss: 0.0306, Initial Validation Loss: 0.1341, Validation Loss: 0.0345,V Acc: 0.8482, Top 70th Acc: 0.9494, Bottom 30th Acc: 0.6061
Fold [1/5] Epoch [20/100] Initial Loss: 0.1401, Training Loss: 0.0146, Initial Validation Loss: 0.1341, Validation Loss: 0.0311,V Acc: 0.8304, Top 70th Acc: 0.9494, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 20  Rolling back to Epoch (base 0): 15  Top Validation Acc: 0.9493670886075949
21 0 [array([0.41089067, 0.05198533, 0.10481822, 0.12251104, 0.3097948 ],
      dtype=float32)]
Fold [2/5] Epoch [0/100] Initial Loss: 0.1419, Training Loss: 0.1419, Initial Validation Loss: 0.1378, Validation Loss: 0.1378,V Acc: 0.2523, Top 70th Acc: 0.3333, Bottom 30th Acc: 0.0606
Fold [2/5] Epoch [10/100] Initial Loss: 0.1419, Training Loss: 0.0367, Initial Validation Loss: 0.1378, Validation Loss: 0.0444,V Acc: 0.8288, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.6364
Fold [2/5] Epoch [20/100] Initial Loss: 0.1419, Training Loss: 0.0170, Initial Validation Loss: 0.1378, Validation Loss: 0.0305,V Acc: 0.8739, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.9615384615384616
Fold [3/5] Epoch [0/100] Initial Loss: 0.1414, Training Loss: 0.1414, Initial Validation Loss: 0.1359, Validation Loss: 0.1359,V Acc: 0.2545, Top 70th Acc: 0.2597, Bottom 30th Acc: 0.2424
Fold [3/5] Epoch [10/100] Initial Loss: 0.1414, Training Loss: 0.0348, Initial Validation Loss: 0.1359, Validation Loss: 0.0498,V Acc: 0.7545, Top 70th Acc: 0.8701, Bottom 30th Acc: 0.4848
Fold [3/5] Epoch [20/100] Initial Loss: 0.1414, Training Loss: 0.0191, Initial Validation Loss: 0.1359, Validation Loss: 0.0403,V Acc: 0.7909, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.4545
Fold [3/5] Epoch [30/100] Initial Loss: 0.1414, Training Loss: 0.0128, Initial Validation Loss: 0.1359, Validation Loss: 0.0353,V Acc: 0.8455, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 39  Rolling back to Epoch (base 0): 34  Top Validation Acc: 0.948051948051948
Fold [4/5] Epoch [0/100] Initial Loss: 0.1390, Training Loss: 0.1390, Initial Validation Loss: 0.1362, Validation Loss: 0.1362,V Acc: 0.2661, Top 70th Acc: 0.3377, Bottom 30th Acc: 0.0938
Fold [4/5] Epoch [10/100] Initial Loss: 0.1390, Training Loss: 0.0305, Initial Validation Loss: 0.1362, Validation Loss: 0.0382,V Acc: 0.8440, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.5938
Fold [4/5] Epoch [20/100] Initial Loss: 0.1390, Training Loss: 0.0140, Initial Validation Loss: 0.1362, Validation Loss: 0.0294,V Acc: 0.8716, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6875
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.961038961038961
Fold [5/5] Epoch [0/100] Initial Loss: 0.1450, Training Loss: 0.1450, Initial Validation Loss: 0.1297, Validation Loss: 0.1297,V Acc: 0.3148, Top 70th Acc: 0.3553, Bottom 30th Acc: 0.2188
Fold [5/5] Epoch [10/100] Initial Loss: 0.1450, Training Loss: 0.0304, Initial Validation Loss: 0.1297, Validation Loss: 0.0318,V Acc: 0.8241, Top 70th Acc: 0.9079, Bottom 30th Acc: 0.6250
Fold [5/5] Epoch [20/100] Initial Loss: 0.1450, Training Loss: 0.0145, Initial Validation Loss: 0.1297, Validation Loss: 0.0266,V Acc: 0.8241, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.5312
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.9342105263157895
Running train_nn.py with seed 22
CUDA:False
Training samples count:  550
Training on 40 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1413, Training Loss: 0.1413, Initial Validation Loss: 0.1338, Validation Loss: 0.1338,V Acc: 0.2946, Top 70th Acc: 0.3797, Bottom 30th Acc: 0.0909
Fold [1/5] Epoch [10/100] Initial Loss: 0.1413, Training Loss: 0.0376, Initial Validation Loss: 0.1338, Validation Loss: 0.0508,V Acc: 0.7321, Top 70th Acc: 0.8354, Bottom 30th Acc: 0.4848
Fold [1/5] Epoch [20/100] Initial Loss: 0.1413, Training Loss: 0.0152, Initial Validation Loss: 0.1338, Validation Loss: 0.0364,V Acc: 0.8214, Top 70th Acc: 0.8987, Bottom 30th Acc: 0.6364
Fold [1/5] Epoch [30/100] Initial Loss: 0.1413, Training Loss: 0.0113, Initial Validation Loss: 0.1338, Validation Loss: 0.0347,V Acc: 0.8304, Top 70th Acc: 0.9114, Bottom 30th Acc: 0.6364
Fold [1/5] Epoch [40/100] Initial Loss: 0.1413, Training Loss: 0.0099, Initial Validation Loss: 0.1338, Validation Loss: 0.0332,V Acc: 0.8214, Top 70th Acc: 0.9620, Bottom 30th Acc: 0.4848
Fold [1/5] Epoch [50/100] Initial Loss: 0.1413, Training Loss: 0.0093, Initial Validation Loss: 0.1338, Validation Loss: 0.0327,V Acc: 0.8214, Top 70th Acc: 0.9620, Bottom 30th Acc: 0.4848
Fold [1/5] Epoch [60/100] Initial Loss: 0.1413, Training Loss: 0.0089, Initial Validation Loss: 0.1338, Validation Loss: 0.0318,V Acc: 0.8304, Top 70th Acc: 0.9620, Bottom 30th Acc: 0.5152
Stopping early at Epoch (base 0): 67  Rolling back to Epoch (base 0): 62  Top Validation Acc: 0.9620253164556962
22 0 [array([0.7917691 , 0.02575235, 0.01917454, 0.0846933 , 0.07861066],
      dtype=float32)]
Fold [2/5] Epoch [0/100] Initial Loss: 0.1374, Training Loss: 0.1374, Initial Validation Loss: 0.1365, Validation Loss: 0.1365,V Acc: 0.3694, Top 70th Acc: 0.3974, Bottom 30th Acc: 0.3030
Fold [2/5] Epoch [10/100] Initial Loss: 0.1374, Training Loss: 0.0318, Initial Validation Loss: 0.1365, Validation Loss: 0.0378,V Acc: 0.8288, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.5758
Fold [2/5] Epoch [20/100] Initial Loss: 0.1374, Training Loss: 0.0152, Initial Validation Loss: 0.1365, Validation Loss: 0.0275,V Acc: 0.8739, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.9615384615384616
Fold [3/5] Epoch [0/100] Initial Loss: 0.1380, Training Loss: 0.1380, Initial Validation Loss: 0.1305, Validation Loss: 0.1305,V Acc: 0.2455, Top 70th Acc: 0.3377, Bottom 30th Acc: 0.0303
Fold [3/5] Epoch [10/100] Initial Loss: 0.1380, Training Loss: 0.0327, Initial Validation Loss: 0.1305, Validation Loss: 0.0344,V Acc: 0.8091, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.4848
Fold [3/5] Epoch [20/100] Initial Loss: 0.1380, Training Loss: 0.0162, Initial Validation Loss: 0.1305, Validation Loss: 0.0253,V Acc: 0.9000, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.7879
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.948051948051948
Fold [4/5] Epoch [0/100] Initial Loss: 0.1420, Training Loss: 0.1420, Initial Validation Loss: 0.1320, Validation Loss: 0.1320,V Acc: 0.2844, Top 70th Acc: 0.2857, Bottom 30th Acc: 0.2812
Fold [4/5] Epoch [10/100] Initial Loss: 0.1420, Training Loss: 0.0296, Initial Validation Loss: 0.1320, Validation Loss: 0.0458,V Acc: 0.7982, Top 70th Acc: 0.8571, Bottom 30th Acc: 0.6562
Fold [4/5] Epoch [20/100] Initial Loss: 0.1420, Training Loss: 0.0142, Initial Validation Loss: 0.1320, Validation Loss: 0.0355,V Acc: 0.8257, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.6250 0.9113924050632911
22 0 [array([0.8030676 , 0.05347661, 0.02272256, 0.02813782, 0.09259545],
      dtype=float32)]
Fold [2/5] Epoch [0/100] Initial Loss: 0.1394, Training Loss: 0.1394, Initial Validation Loss: 0.1357, Validation Loss: 0.1357,V Acc: 0.3153, Top 70th Acc: 0.3333, Bottom 30th Acc: 0.2727
Fold [2/5] Epoch [10/100] Initial Loss: 0.1394, Training Loss: 0.0313, Initial Validation Loss: 0.1357, Validation Loss: 0.0365,V Acc: 0.8468, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.6667
Fold [2/5] Epoch [20/100] Initial Loss: 0.1394, Training Loss: 0.0199, Initial Validation Loss: 0.1357, Validation Loss: 0.0330,V Acc: 0.8288, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.5152
Stopping early at Epoch (base 0): 21  Rolling back to Epoch (base 0): 16  Top Validation Acc: 0.9615384615384616
Fold [3/5] Epoch [0/100] Initial Loss: 0.1406, Training Loss: 0.1406, Initial Validation Loss: 0.1340, Validation Loss: 0.1340,V Acc: 0.1727, Top 70th Acc: 0.1429, Bottom 30th Acc: 0.2424
Fold [3/5] Epoch [10/100] Initial Loss: 0.1406, Training Loss: 0.0437, Initial Validation Loss: 0.1340, Validation Loss: 0.0413,V Acc: 0.8091, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.5758
Fold [3/5] Epoch [20/100] Initial Loss: 0.1406, Training Loss: 0.0241, Initial Validation Loss: 0.1340, Validation Loss: 0.0283,V Acc: 0.8636, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.6970
Fold [3/5] Epoch [30/100] Initial Loss: 0.1406, Training Loss: 0.0187, Initial Validation Loss: 0.1340, Validation Loss: 0.0243,V Acc: 0.8909, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.7273
Stopping early at Epoch (base 0): 35  Rolling back to Epoch (base 0): 30  Top Validation Acc: 0.974025974025974
Fold [4/5] Epoch [0/100] Initial Loss: 0.1414, Training Loss: 0.1414, Initial Validation Loss: 0.1311, Validation Loss: 0.1311,V Acc: 0.2477, Top 70th Acc: 0.3117, Bottom 30th Acc: 0.0938
Fold [4/5] Epoch [10/100] Initial Loss: 0.1414, Training Loss: 0.0323, Initial Validation Loss: 0.1311, Validation Loss: 0.0426,V Acc: 0.8165, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.5938
Fold [4/5] Epoch [20/100] Initial Loss: 0.1414, Training Loss: 0.0175, Initial Validation Loss: 0.1311, Validation Loss: 0.0373,V Acc: 0.8349, Top 70th Acc: 0.8831, Bottom 30th Acc: 0.7188
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.9090909090909091
Fold [5/5] Epoch [0/100] Initial Loss: 0.1379, Training Loss: 0.1379, Initial Validation Loss: 0.1364, Validation Loss: 0.1364,V Acc: 0.2500, Top 70th Acc: 0.3026, Bottom 30th Acc: 0.1250
Fold [5/5] Epoch [10/100] Initial Loss: 0.1379, Training Loss: 0.0335, Initial Validation Loss: 0.1364, Validation Loss: 0.0417,V Acc: 0.8056, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.5000
Fold [5/5] Epoch [20/100] Initial Loss: 0.1379, Training Loss: 0.0194, Initial Validation Loss: 0.1364, Validation Loss: 0.0323,V Acc: 0.8704, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.6875
Fold [5/5] Epoch [30/100] Initial Loss: 0.1379, Training Loss: 0.0168, Initial Validation Loss: 0.1364, Validation Loss: 0.0308,V Acc: 0.8704, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.6562
Fold [5/5] Epoch [40/100] Initial Loss: 0.1379, Training Loss: 0.0156, Initial Validation Loss: 0.1364, Validation Loss: 0.0303,V Acc: 0.8611, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.6250
Stopping early at Epoch (base 0): 43  Rolling back to Epoch (base 0): 38  Top Validation Acc: 0.9605263157894737
Running train_nn.py with seed 23
CUDA:False
Training samples count:  550
Training on 30 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1388, Training Loss: 0.1388, Initial Validation Loss: 0.1303, Validation Loss: 0.1303,V Acc: 0.3929, Top 70th Acc: 0.5443, Bottom 30th Acc: 0.0303
Fold [1/5] Epoch [10/100] Initial Loss: 0.1388, Training Loss: 0.0325, Initial Validation Loss: 0.1303, Validation Loss: 0.0300,V Acc: 0.8304, Top 70th Acc: 0.9620, Bottom 30th Acc: 0.5152
Fold [1/5] Epoch [20/100] Initial Loss: 0.1388, Training Loss: 0.0202, Initial Validation Loss: 0.1303, Validation Loss: 0.0243,V Acc: 0.8482, Top 70th Acc: 0.9747, Bottom 30th Acc: 0.5455
Fold [1/5] Epoch [30/100] Initial Loss: 0.1388, Training Loss: 0.0174, Initial Validation Loss: 0.1303, Validation Loss: 0.0244,V Acc: 0.8571, Top 70th Acc: 0.9620, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 34  Rolling back to Epoch (base 0): 29  Top Validation Acc: 0.9620253164556962
Fold [2/5] Epoch [0/100] Initial Loss: 0.1376, Training Loss: 0.1376, Initial Validation Loss: 0.1356, Validation Loss: 0.1356,V Acc: 0.3694, Top 70th Acc: 0.4487, Bottom 30th Acc: 0.1818
Fold [2/5] Epoch [10/100] Initial Loss: 0.1376, Training Loss: 0.0405, Initial Validation Loss: 0.1356, Validation Loss: 0.0551,V Acc: 0.7568, Top 70th Acc: 0.8462, Bottom 30th Acc: 0.5455
Fold [2/5] Epoch [20/100] Initial Loss: 0.1376, Training Loss: 0.0245, Initial Validation Loss: 0.1356, Validation Loss: 0.0350,V Acc: 0.8198, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.4848
Fold [2/5] Epoch [30/100] Initial Loss: 0.1376, Training Loss: 0.0182, Initial Validation Loss: 0.1356, Validation Loss: 0.0303,V Acc: 0.8378, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 38  Rolling back to Epoch (base 0): 33  Top Validation Acc: 0.9743589743589743
23 1 [array([0.59573877, 0.03116968, 0.07035445, 0.19586347, 0.10687365],
      dtype=float32)]
Fold [3/5] Epoch [0/100] Initial Loss: 0.1398, Training Loss: 0.1398, Initial Validation Loss: 0.1325, Validation Loss: 0.1325,V Acc: 0.3636, Top 70th Acc: 0.3766, Bottom 30th Acc: 0.3333
Fold [3/5] Epoch [10/100] Initial Loss: 0.1398, Training Loss: 0.0310, Initial Validation Loss: 0.1325, Validation Loss: 0.0437,V Acc: 0.7636, Top 70th Acc: 0.8831, Bottom 30th Acc: 0.4848
Fold [3/5] Epoch [20/100] Initial Loss: 0.1398, Training Loss: 0.0164, Initial Validation Loss: 0.1325, Validation Loss: 0.0371,V Acc: 0.8000, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.9090909090909091
Fold [4/5] Epoch [0/100] Initial Loss: 0.1381, Training Loss: 0.1381, Initial Validation Loss: 0.1320, Validation Loss: 0.1320,V Acc: 0.3945, Top 70th Acc: 0.4545, Bottom 30th Acc: 0.2500
Fold [4/5] Epoch [10/100] Initial Loss: 0.1381, Training Loss: 0.0351, Initial Validation Loss: 0.1320, Validation Loss: 0.0434,V Acc: 0.7798, Top 70th Acc: 0.8961, Bottom 30th Acc: 0.5000
Fold [4/5] Epoch [20/100] Initial Loss: 0.1381, Training Loss: 0.0176, Initial Validation Loss: 0.1320, Validation Loss: 0.0358,V Acc: 0.7982, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.4375
Stopping early at Epoch (base 0): 22  Rolling back to Epoch (base 0): 17  Top Validation Acc: 0.935064935064935
Fold [5/5] Epoch [0/100] Initial Loss: 0.1378, Training Loss: 0.1378, Initial Validation Loss: 0.1291, Validation Loss: 0.1291,V Acc: 0.3981, Top 70th Acc: 0.4737, Bottom 30th Acc: 0.2188
Fold [5/5] Epoch [10/100] Initial Loss: 0.1378, Training Loss: 0.0285, Initial Validation Loss: 0.1291, Validation Loss: 0.0345,V Acc: 0.8611, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.6562
Fold [5/5] Epoch [20/100] Initial Loss: 0.1378, Training Loss: 0.0175, Initial Validation Loss: 0.1291, Validation Loss: 0.0319,V Acc: 0.8426, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.5938
Stopping early at Epoch (base 0): 20  Rolling back to Epoch (base 0): 15  Top Validation Acc: 0.9473684210526315
Running train_nn.py with seed 24
CUDA:False
Training samples count:  550
Training on 30 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1417, Training Loss: 0.1417, Initial Validation Loss: 0.1372, Validation Loss: 0.1372,V Acc: 0.3393, Top 70th Acc: 0.3671, Bottom 30th Acc: 0.2727
Fold [1/5] Epoch [10/100] Initial Loss: 0.1417, Training Loss: 0.0394, Initial Validation Loss: 0.1372, Validation Loss: 0.0476,V Acc: 0.7679, Top 70th Acc: 0.8734, Bottom 30th Acc: 0.5152
Fold [1/5] Epoch [20/100] Initial Loss: 0.1417, Training Loss: 0.0205, Initial Validation Loss: 0.1372, Validation Loss: 0.0359,V Acc: 0.8125, Top 70th Acc: 0.9241, Bottom 30th Acc: 0.5455
Fold [1/5] Epoch [30/100] Initial Loss: 0.1417, Training Loss: 0.0167, Initial Validation Loss: 0.1372, Validation Loss: 0.0336,V Acc: 0.8214, Top 70th Acc: 0.9367, Bottom 30th Acc: 0.5455 0.7105263157894737
Running train_nn.py with seed 21
CUDA:False
Training samples count:  550
Training on 2 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1393, Training Loss: 0.1393, Initial Validation Loss: 0.1329, Validation Loss: 0.1329,V Acc: 0.4196, Top 70th Acc: 0.4810, Bottom 30th Acc: 0.2727
Fold [1/5] Epoch [10/100] Initial Loss: 0.1393, Training Loss: 0.0816, Initial Validation Loss: 0.1329, Validation Loss: 0.0787,V Acc: 0.6518, Top 70th Acc: 0.7595, Bottom 30th Acc: 0.3939
Fold [1/5] Epoch [20/100] Initial Loss: 0.1393, Training Loss: 0.0791, Initial Validation Loss: 0.1329, Validation Loss: 0.0766,V Acc: 0.6696, Top 70th Acc: 0.7722, Bottom 30th Acc: 0.4242
Fold [1/5] Epoch [30/100] Initial Loss: 0.1393, Training Loss: 0.0782, Initial Validation Loss: 0.1329, Validation Loss: 0.0761,V Acc: 0.6607, Top 70th Acc: 0.7722, Bottom 30th Acc: 0.3939
Stopping early at Epoch (base 0): 36  Rolling back to Epoch (base 0): 31  Top Validation Acc: 0.7721518987341772
21 0 [array([0.1352401 , 0.35608342, 0.1448603 , 0.20969847, 0.15411778],
      dtype=float32)]
Fold [2/5] Epoch [0/100] Initial Loss: 0.1331, Training Loss: 0.1331, Initial Validation Loss: 0.1249, Validation Loss: 0.1249,V Acc: 0.3964, Top 70th Acc: 0.5000, Bottom 30th Acc: 0.1515
Fold [2/5] Epoch [10/100] Initial Loss: 0.1331, Training Loss: 0.0803, Initial Validation Loss: 0.1249, Validation Loss: 0.0825,V Acc: 0.6396, Top 70th Acc: 0.7821, Bottom 30th Acc: 0.3030
Fold [2/5] Epoch [20/100] Initial Loss: 0.1331, Training Loss: 0.0788, Initial Validation Loss: 0.1249, Validation Loss: 0.0811,V Acc: 0.6486, Top 70th Acc: 0.7692, Bottom 30th Acc: 0.3636
Stopping early at Epoch (base 0): 27  Rolling back to Epoch (base 0): 22  Top Validation Acc: 0.7692307692307693
Fold [3/5] Epoch [0/100] Initial Loss: 0.1346, Training Loss: 0.1346, Initial Validation Loss: 0.1240, Validation Loss: 0.1240,V Acc: 0.5091, Top 70th Acc: 0.6104, Bottom 30th Acc: 0.2727
Fold [3/5] Epoch [10/100] Initial Loss: 0.1346, Training Loss: 0.0800, Initial Validation Loss: 0.1240, Validation Loss: 0.0785,V Acc: 0.6091, Top 70th Acc: 0.7403, Bottom 30th Acc: 0.3030
Fold [3/5] Epoch [20/100] Initial Loss: 0.1346, Training Loss: 0.0780, Initial Validation Loss: 0.1240, Validation Loss: 0.0778,V Acc: 0.6364, Top 70th Acc: 0.7013, Bottom 30th Acc: 0.4848
Stopping early at Epoch (base 0): 20  Rolling back to Epoch (base 0): 15  Top Validation Acc: 0.7012987012987013
Fold [4/5] Epoch [0/100] Initial Loss: 0.1351, Training Loss: 0.1351, Initial Validation Loss: 0.1264, Validation Loss: 0.1264,V Acc: 0.3394, Top 70th Acc: 0.3896, Bottom 30th Acc: 0.2188
Fold [4/5] Epoch [10/100] Initial Loss: 0.1351, Training Loss: 0.0771, Initial Validation Loss: 0.1264, Validation Loss: 0.0878,V Acc: 0.5963, Top 70th Acc: 0.6883, Bottom 30th Acc: 0.3750
Fold [4/5] Epoch [20/100] Initial Loss: 0.1351, Training Loss: 0.0757, Initial Validation Loss: 0.1264, Validation Loss: 0.0861,V Acc: 0.5963, Top 70th Acc: 0.7143, Bottom 30th Acc: 0.3125
Stopping early at Epoch (base 0): 22  Rolling back to Epoch (base 0): 17  Top Validation Acc: 0.7142857142857143
Fold [5/5] Epoch [0/100] Initial Loss: 0.1362, Training Loss: 0.1362, Initial Validation Loss: 0.1200, Validation Loss: 0.1200,V Acc: 0.3889, Top 70th Acc: 0.4079, Bottom 30th Acc: 0.3438
Fold [5/5] Epoch [10/100] Initial Loss: 0.1362, Training Loss: 0.0830, Initial Validation Loss: 0.1200, Validation Loss: 0.0715,V Acc: 0.6389, Top 70th Acc: 0.7632, Bottom 30th Acc: 0.3438
Stopping early at Epoch (base 0): 18  Rolling back to Epoch (base 0): 13  Top Validation Acc: 0.7631578947368421
Running train_nn.py with seed 22
CUDA:False
Training samples count:  550
Training on 2 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1418, Training Loss: 0.1418, Initial Validation Loss: 0.1348, Validation Loss: 0.1348,V Acc: 0.2500, Top 70th Acc: 0.1899, Bottom 30th Acc: 0.3939
Fold [1/5] Epoch [10/100] Initial Loss: 0.1418, Training Loss: 0.0800, Initial Validation Loss: 0.1348, Validation Loss: 0.0841,V Acc: 0.6250, Top 70th Acc: 0.6582, Bottom 30th Acc: 0.5455
Fold [1/5] Epoch [20/100] Initial Loss: 0.1418, Training Loss: 0.0781, Initial Validation Loss: 0.1348, Validation Loss: 0.0831,V Acc: 0.6071, Top 70th Acc: 0.6582, Bottom 30th Acc: 0.4848
Fold [1/5] Epoch [30/100] Initial Loss: 0.1418, Training Loss: 0.0774, Initial Validation Loss: 0.1348, Validation Loss: 0.0827,V Acc: 0.5982, Top 70th Acc: 0.6709, Bottom 30th Acc: 0.4242
Stopping early at Epoch (base 0): 37  Rolling back to Epoch (base 0): 32  Top Validation Acc: 0.6708860759493671
22 0 [array([0.10781152, 0.34906313, 0.1420997 , 0.22372285, 0.17730291],
      dtype=float32)]
Fold [2/5] Epoch [0/100] Initial Loss: 0.1310, Training Loss: 0.1310, Initial Validation Loss: 0.1230, Validation Loss: 0.1230,V Acc: 0.5045, Top 70th Acc: 0.5897, Bottom 30th Acc: 0.3030
Fold [2/5] Epoch [10/100] Initial Loss: 0.1310, Training Loss: 0.0805, Initial Validation Loss: 0.1230, Validation Loss: 0.0802,V Acc: 0.6396, Top 70th Acc: 0.7436, Bottom 30th Acc: 0.3939
Fold [2/5] Epoch [20/100] Initial Loss: 0.1310, Training Loss: 0.0783, Initial Validation Loss: 0.1230, Validation Loss: 0.0792,V Acc: 0.6486, Top 70th Acc: 0.7436, Bottom 30th Acc: 0.4242
Fold [2/5] Epoch [30/100] Initial Loss: 0.1310, Training Loss: 0.0777, Initial Validation Loss: 0.1230, Validation Loss: 0.0787,V Acc: 0.6396, Top 70th Acc: 0.7564, Bottom 30th Acc: 0.3636
Stopping early at Epoch (base 0): 37  Rolling back to Epoch (base 0): 32  Top Validation Acc: 0.7435897435897436
Fold [3/5] Epoch [0/100] Initial Loss: 0.1436, Training Loss: 0.1436, Initial Validation Loss: 0.1326, Validation Loss: 0.1326,V Acc: 0.3545, Top 70th Acc: 0.3247, Bottom 30th Acc: 0.4242
Fold [3/5] Epoch [10/100] Initial Loss: 0.1436, Training Loss: 0.0843, Initial Validation Loss: 0.1326, Validation Loss: 0.0707,V Acc: 0.6727, Top 70th Acc: 0.8052, Bottom 30th Acc: 0.3636
Fold [3/5] Epoch [20/100] Initial Loss: 0.1436, Training Loss: 0.0819, Initial Validation Loss: 0.1326, Validation Loss: 0.0689,V Acc: 0.6727, Top 70th Acc: 0.8052, Bottom 30th Acc: 0.3636
Fold [3/5] Epoch [30/100] Initial Loss: 0.1436, Training Loss: 0.0813, Initial Validation Loss: 0.1326, Validation Loss: 0.0674,V Acc: 0.7000, Top 70th Acc: 0.7922, Bottom 30th Acc: 0.4848
Stopping early at Epoch (base 0): 34  Rolling back to Epoch (base 0): 29  Top Validation Acc: 0.7792207792207793
Fold [4/5] Epoch [0/100] Initial Loss: 0.1348, Training Loss: 0.1348, Initial Validation Loss: 0.1226, Validation Loss: 0.1226,V Acc: 0.4128, Top 70th Acc: 0.4805, Bottom 30th Acc: 0.2500
Fold [4/5] Epoch [10/100] Initial Loss: 0.1348, Training Loss: 0.0817, Initial Validation Loss: 0.1226, Validation Loss: 0.0813,V Acc: 0.6055, Top 70th Acc: 0.7273, Bottom 30th Acc: 0.3125
Fold [4/5] Epoch [20/100] Initial Loss: 0.1348, Training Loss: 0.0788, Initial Validation Loss: 0.1226, Validation Loss: 0.0787,V Acc: 0.5872, Top 70th Acc: 0.7532, Bottom 30th Acc: 0.1875
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.7662337662337663
Fold [5/5] Epoch [0/100] Initial Loss: 0.1352, Training Loss: 0.1352, Initial Validation Loss: 0.1316, Validation Loss: 0.1316,V Acc: 0.2963, Top 70th Acc: 0.3553, Bottom 30th Acc: 0.1562
Fold [5/5] Epoch [10/100] Initial Loss: 0.1352, Training Loss: 0.0789, Initial Validation Loss: 0.1316, Validation Loss: 0.0864,V Acc: 0.5833, Top 70th Acc: 0.7237, Bottom 30th Acc: 0.2500
Fold [5/5] Epoch [20/100] Initial Loss: 0.1352, Training Loss: 0.0770, Initial Validation Loss: 0.1316, Validation Loss: 0.0847,V Acc: 0.5833, Top 70th Acc: 0.7237, Bottom 30th Acc: 0.2500
Fold [5/5] Epoch [30/100] Initial Loss: 0.1352, Training Loss: 0.0761, Initial Validation Loss: 0.1316, Validation Loss: 0.0825,V Acc: 0.6111, Top 70th Acc: 0.7632, Bottom 30th Acc: 0.2500
Stopping early at Epoch (base 0): 35  Rolling back to Epoch (base 0): 30  Top Validation Acc: 0.7236842105263158
Running train_nn.py with seed 23
CUDA:False
Training samples count:  550
Training on 2 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1453, Training Loss: 0.1453, Initial Validation Loss: 0.1350, Validation Loss: 0.1350,V Acc: 0.2500, Top 70th Acc: 0.2785, Bottom 30th Acc: 0.1818
Stopping early at Epoch (base 0): 18  Rolling back to Epoch (base 0): 13  Top Validation Acc: 0.9240506329113924
Fold [2/5] Epoch [0/100] Initial Loss: 0.1322, Training Loss: 0.1322, Initial Validation Loss: 0.1142, Validation Loss: 0.1142,V Acc: 0.4955, Top 70th Acc: 0.5513, Bottom 30th Acc: 0.3636
Fold [2/5] Epoch [10/100] Initial Loss: 0.1322, Training Loss: 0.0197, Initial Validation Loss: 0.1142, Validation Loss: 0.0317,V Acc: 0.8378, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 17  Rolling back to Epoch (base 0): 12  Top Validation Acc: 0.9615384615384616
Fold [3/5] Epoch [0/100] Initial Loss: 0.1305, Training Loss: 0.1305, Initial Validation Loss: 0.1094, Validation Loss: 0.1094,V Acc: 0.5364, Top 70th Acc: 0.6883, Bottom 30th Acc: 0.1818
Fold [3/5] Epoch [10/100] Initial Loss: 0.1305, Training Loss: 0.0231, Initial Validation Loss: 0.1094, Validation Loss: 0.0326,V Acc: 0.8455, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 13  Rolling back to Epoch (base 0): 8  Top Validation Acc: 0.935064935064935
31 2 [array([0.72283185, 0.03386446, 0.03198465, 0.14867723, 0.0626418 ],
      dtype=float32)]
Fold [4/5] Epoch [0/100] Initial Loss: 0.1355, Training Loss: 0.1355, Initial Validation Loss: 0.1281, Validation Loss: 0.1281,V Acc: 0.4312, Top 70th Acc: 0.5584, Bottom 30th Acc: 0.1250
Fold [4/5] Epoch [10/100] Initial Loss: 0.1355, Training Loss: 0.0229, Initial Validation Loss: 0.1281, Validation Loss: 0.0274,V Acc: 0.8899, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.7500
Fold [4/5] Epoch [20/100] Initial Loss: 0.1355, Training Loss: 0.0176, Initial Validation Loss: 0.1281, Validation Loss: 0.0234,V Acc: 0.9083, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.7500
Fold [4/5] Epoch [30/100] Initial Loss: 0.1355, Training Loss: 0.0141, Initial Validation Loss: 0.1281, Validation Loss: 0.0226,V Acc: 0.9174, Top 70th Acc: 0.9870, Bottom 30th Acc: 0.7500
Stopping early at Epoch (base 0): 30  Rolling back to Epoch (base 0): 25  Top Validation Acc: 0.987012987012987
Fold [5/5] Epoch [0/100] Initial Loss: 0.1286, Training Loss: 0.1286, Initial Validation Loss: 0.1119, Validation Loss: 0.1119,V Acc: 0.5556, Top 70th Acc: 0.6711, Bottom 30th Acc: 0.2812
Fold [5/5] Epoch [10/100] Initial Loss: 0.1286, Training Loss: 0.0261, Initial Validation Loss: 0.1119, Validation Loss: 0.0281,V Acc: 0.8796, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.7188
Fold [5/5] Epoch [20/100] Initial Loss: 0.1286, Training Loss: 0.0175, Initial Validation Loss: 0.1119, Validation Loss: 0.0194,V Acc: 0.8889, Top 70th Acc: 0.9868, Bottom 30th Acc: 0.6562
Fold [5/5] Epoch [30/100] Initial Loss: 0.1286, Training Loss: 0.0142, Initial Validation Loss: 0.1119, Validation Loss: 0.0273,V Acc: 0.8611, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.6875
Stopping early at Epoch (base 0): 31  Rolling back to Epoch (base 0): 26  Top Validation Acc: 0.9605263157894737
Running train_nn.py with seed 32
CUDA:False
Training samples count:  550
Training on 21 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1329, Training Loss: 0.1329, Initial Validation Loss: 0.1158, Validation Loss: 0.1158,V Acc: 0.4732, Top 70th Acc: 0.5696, Bottom 30th Acc: 0.2424
Fold [1/5] Epoch [10/100] Initial Loss: 0.1329, Training Loss: 0.0209, Initial Validation Loss: 0.1158, Validation Loss: 0.0308,V Acc: 0.8393, Top 70th Acc: 0.9494, Bottom 30th Acc: 0.5758
Fold [1/5] Epoch [20/100] Initial Loss: 0.1329, Training Loss: 0.0136, Initial Validation Loss: 0.1158, Validation Loss: 0.0324,V Acc: 0.8393, Top 70th Acc: 0.9241, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 20  Rolling back to Epoch (base 0): 15  Top Validation Acc: 0.9240506329113924
Fold [2/5] Epoch [0/100] Initial Loss: 0.1300, Training Loss: 0.1300, Initial Validation Loss: 0.1156, Validation Loss: 0.1156,V Acc: 0.5676, Top 70th Acc: 0.6538, Bottom 30th Acc: 0.3636
Fold [2/5] Epoch [10/100] Initial Loss: 0.1300, Training Loss: 0.0231, Initial Validation Loss: 0.1156, Validation Loss: 0.0248,V Acc: 0.9099, Top 70th Acc: 0.9872, Bottom 30th Acc: 0.7273
Fold [2/5] Epoch [20/100] Initial Loss: 0.1300, Training Loss: 0.0145, Initial Validation Loss: 0.1156, Validation Loss: 0.0221,V Acc: 0.9009, Top 70th Acc: 0.9872, Bottom 30th Acc: 0.6970
Fold [2/5] Epoch [30/100] Initial Loss: 0.1300, Training Loss: 0.0130, Initial Validation Loss: 0.1156, Validation Loss: 0.0215,V Acc: 0.9189, Top 70th Acc: 0.9872, Bottom 30th Acc: 0.7576
Stopping early at Epoch (base 0): 34  Rolling back to Epoch (base 0): 29  Top Validation Acc: 0.9871794871794872
Fold [3/5] Epoch [0/100] Initial Loss: 0.1372, Training Loss: 0.1372, Initial Validation Loss: 0.1222, Validation Loss: 0.1222,V Acc: 0.4455, Top 70th Acc: 0.5455, Bottom 30th Acc: 0.2121
Fold [3/5] Epoch [10/100] Initial Loss: 0.1372, Training Loss: 0.0223, Initial Validation Loss: 0.1222, Validation Loss: 0.0308,V Acc: 0.7909, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.4242
Fold [3/5] Epoch [20/100] Initial Loss: 0.1372, Training Loss: 0.0158, Initial Validation Loss: 0.1222, Validation Loss: 0.0307,V Acc: 0.8364, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.5455
Fold [3/5] Epoch [30/100] Initial Loss: 0.1372, Training Loss: 0.0132, Initial Validation Loss: 0.1222, Validation Loss: 0.0304,V Acc: 0.8455, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 31  Rolling back to Epoch (base 0): 26  Top Validation Acc: 0.961038961038961
32 2 [array([0.63702995, 0.02325264, 0.03952911, 0.11216537, 0.18802293],
      dtype=float32)]
Fold [4/5] Epoch [0/100] Initial Loss: 0.1362, Training Loss: 0.1362, Initial Validation Loss: 0.1267, Validation Loss: 0.1267,V Acc: 0.4220, Top 70th Acc: 0.5455, Bottom 30th Acc: 0.1250
Fold [4/5] Epoch [10/100] Initial Loss: 0.1362, Training Loss: 0.0245, Initial Validation Loss: 0.1267, Validation Loss: 0.0258,V Acc: 0.8899, Top 70th Acc: 0.9870, Bottom 30th Acc: 0.6562
Fold [4/5] Epoch [20/100] Initial Loss: 0.1362, Training Loss: 0.0173, Initial Validation Loss: 0.1267, Validation Loss: 0.0201,V Acc: 0.9174, Top 70th Acc: 0.9870, Bottom 30th Acc: 0.7500
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.987012987012987
Fold [5/5] Epoch [0/100] Initial Loss: 0.1386, Training Loss: 0.1386, Initial Validation Loss: 0.1304, Validation Loss: 0.1304,V Acc: 0.3519, Top 70th Acc: 0.3553, Bottom 30th Acc: 0.3438
Fold [5/5] Epoch [10/100] Initial Loss: 0.1386, Training Loss: 0.0253, Initial Validation Loss: 0.1304, Validation Loss: 0.0238,V Acc: 0.8981, Top 70th Acc: 0.9868, Bottom 30th Acc: 0.6875
Stopping early at Epoch (base 0): 18  Rolling back to Epoch (base 0): 13  Top Validation Acc: 0.9736842105263158
Running train_nn.py with seed 33
CUDA:False
Training samples count:  550
Training on 21 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1369, Training Loss: 0.1369, Initial Validation Loss: 0.1343, Validation Loss: 0.1343,V Acc: 0.3839, Top 70th Acc: 0.4177, Bottom 30th Acc: 0.3030
Fold [1/5] Epoch [10/100] Initial Loss: 0.1369, Training Loss: 0.0285, Initial Validation Loss: 0.1343, Validation Loss: 0.0339,V Acc: 0.8482, Top 70th Acc: 0.9367, Bottom 30th Acc: 0.6364
Fold [1/5] Epoch [20/100] Initial Loss: 0.1369, Training Loss: 0.0187, Initial Validation Loss: 0.1343, Validation Loss: 0.0275,V Acc: 0.8750, Top 70th Acc: 0.9620, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 20  Rolling back to Epoch (base 0): 15  Top Validation Acc: 0.9620253164556962
Fold [2/5] Epoch [0/100] Initial Loss: 0.1387, Training Loss: 0.1387, Initial Validation Loss: 0.1325, Validation Loss: 0.1325,V Acc: 0.4234, Top 70th Acc: 0.5513, Bottom 30th Acc: 0.1212
Fold [2/5] Epoch [10/100] Initial Loss: 0.1387, Training Loss: 0.0270, Initial Validation Loss: 0.1325, Validation Loss: 0.0301,V Acc: 0.8649, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.6667
Fold [2/5] Epoch [20/100] Initial Loss: 0.1387, Training Loss: 0.0151, Initial Validation Loss: 0.1325, Validation Loss: 0.0256,V Acc: 0.8919, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.7273
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.9487179487179487
Fold [3/5] Epoch [0/100] Initial Loss: 0.1271, Training Loss: 0.1271, Initial Validation Loss: 0.1141, Validation Loss: 0.1141,V Acc: 0.5000, Top 70th Acc: 0.6104, Bottom 30th Acc: 0.2424
Fold [4/5] Epoch [20/100] Initial Loss: 0.1386, Training Loss: 0.0245, Initial Validation Loss: 0.1348, Validation Loss: 0.0352,V Acc: 0.8624, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.6250
Fold [4/5] Epoch [30/100] Initial Loss: 0.1386, Training Loss: 0.0216, Initial Validation Loss: 0.1348, Validation Loss: 0.0336,V Acc: 0.8532, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6250
Stopping early at Epoch (base 0): 39  Rolling back to Epoch (base 0): 34  Top Validation Acc: 0.948051948051948
Fold [5/5] Epoch [0/100] Initial Loss: 0.1409, Training Loss: 0.1409, Initial Validation Loss: 0.1276, Validation Loss: 0.1276,V Acc: 0.2963, Top 70th Acc: 0.3553, Bottom 30th Acc: 0.1562
Fold [5/5] Epoch [10/100] Initial Loss: 0.1409, Training Loss: 0.0481, Initial Validation Loss: 0.1276, Validation Loss: 0.0403,V Acc: 0.7685, Top 70th Acc: 0.9079, Bottom 30th Acc: 0.4375
Fold [5/5] Epoch [20/100] Initial Loss: 0.1409, Training Loss: 0.0287, Initial Validation Loss: 0.1276, Validation Loss: 0.0262,V Acc: 0.8426, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.5938
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.9342105263157895
Running train_nn.py with seed 22
CUDA:False
Training samples count:  550
Training on 20 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1460, Training Loss: 0.1460, Initial Validation Loss: 0.1354, Validation Loss: 0.1354,V Acc: 0.2054, Top 70th Acc: 0.2152, Bottom 30th Acc: 0.1818
Fold [1/5] Epoch [10/100] Initial Loss: 0.1460, Training Loss: 0.0369, Initial Validation Loss: 0.1354, Validation Loss: 0.0469,V Acc: 0.8036, Top 70th Acc: 0.8861, Bottom 30th Acc: 0.6061
Fold [1/5] Epoch [20/100] Initial Loss: 0.1460, Training Loss: 0.0235, Initial Validation Loss: 0.1354, Validation Loss: 0.0396,V Acc: 0.7857, Top 70th Acc: 0.9114, Bottom 30th Acc: 0.4848
Stopping early at Epoch (base 0): 22  Rolling back to Epoch (base 0): 17  Top Validation Acc: 0.8607594936708861
22 0 [array([0.43646505, 0.07400778, 0.10105941, 0.23697276, 0.15149495],
      dtype=float32)]
Fold [2/5] Epoch [0/100] Initial Loss: 0.1387, Training Loss: 0.1387, Initial Validation Loss: 0.1320, Validation Loss: 0.1320,V Acc: 0.4144, Top 70th Acc: 0.5385, Bottom 30th Acc: 0.1212
Fold [2/5] Epoch [10/100] Initial Loss: 0.1387, Training Loss: 0.0423, Initial Validation Loss: 0.1320, Validation Loss: 0.0463,V Acc: 0.7928, Top 70th Acc: 0.8718, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 15  Rolling back to Epoch (base 0): 10  Top Validation Acc: 0.8589743589743589
Fold [3/5] Epoch [0/100] Initial Loss: 0.1422, Training Loss: 0.1422, Initial Validation Loss: 0.1340, Validation Loss: 0.1340,V Acc: 0.2909, Top 70th Acc: 0.2727, Bottom 30th Acc: 0.3333
Fold [3/5] Epoch [10/100] Initial Loss: 0.1422, Training Loss: 0.0443, Initial Validation Loss: 0.1340, Validation Loss: 0.0393,V Acc: 0.8364, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.6667
Fold [3/5] Epoch [20/100] Initial Loss: 0.1422, Training Loss: 0.0260, Initial Validation Loss: 0.1340, Validation Loss: 0.0263,V Acc: 0.8818, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.6970
Fold [3/5] Epoch [30/100] Initial Loss: 0.1422, Training Loss: 0.0234, Initial Validation Loss: 0.1340, Validation Loss: 0.0264,V Acc: 0.8818, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 31  Rolling back to Epoch (base 0): 26  Top Validation Acc: 0.961038961038961
Fold [4/5] Epoch [0/100] Initial Loss: 0.1407, Training Loss: 0.1407, Initial Validation Loss: 0.1315, Validation Loss: 0.1315,V Acc: 0.3119, Top 70th Acc: 0.2987, Bottom 30th Acc: 0.3438
Fold [4/5] Epoch [10/100] Initial Loss: 0.1407, Training Loss: 0.0347, Initial Validation Loss: 0.1315, Validation Loss: 0.0485,V Acc: 0.7982, Top 70th Acc: 0.8312, Bottom 30th Acc: 0.7188
Fold [4/5] Epoch [20/100] Initial Loss: 0.1407, Training Loss: 0.0209, Initial Validation Loss: 0.1315, Validation Loss: 0.0441,V Acc: 0.7798, Top 70th Acc: 0.8571, Bottom 30th Acc: 0.5938
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.8701298701298701
Fold [5/5] Epoch [0/100] Initial Loss: 0.1396, Training Loss: 0.1396, Initial Validation Loss: 0.1361, Validation Loss: 0.1361,V Acc: 0.2500, Top 70th Acc: 0.3026, Bottom 30th Acc: 0.1250
Fold [5/5] Epoch [10/100] Initial Loss: 0.1396, Training Loss: 0.0415, Initial Validation Loss: 0.1361, Validation Loss: 0.0470,V Acc: 0.8148, Top 70th Acc: 0.8947, Bottom 30th Acc: 0.6250
Fold [5/5] Epoch [20/100] Initial Loss: 0.1396, Training Loss: 0.0264, Initial Validation Loss: 0.1361, Validation Loss: 0.0363,V Acc: 0.8333, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.5625
Fold [5/5] Epoch [30/100] Initial Loss: 0.1396, Training Loss: 0.0227, Initial Validation Loss: 0.1361, Validation Loss: 0.0340,V Acc: 0.8519, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.6250
Stopping early at Epoch (base 0): 33  Rolling back to Epoch (base 0): 28  Top Validation Acc: 0.9605263157894737
Running train_nn.py with seed 23
CUDA:False
Training samples count:  550
Training on 20 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1392, Training Loss: 0.1392, Initial Validation Loss: 0.1309, Validation Loss: 0.1309,V Acc: 0.5000, Top 70th Acc: 0.5823, Bottom 30th Acc: 0.3030
Fold [1/5] Epoch [10/100] Initial Loss: 0.1392, Training Loss: 0.0369, Initial Validation Loss: 0.1309, Validation Loss: 0.0300,V Acc: 0.8839, Top 70th Acc: 0.9241, Bottom 30th Acc: 0.7879
Fold [1/5] Epoch [20/100] Initial Loss: 0.1392, Training Loss: 0.0262, Initial Validation Loss: 0.1309, Validation Loss: 0.0275,V Acc: 0.8661, Top 70th Acc: 0.9367, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 21  Rolling back to Epoch (base 0): 16  Top Validation Acc: 0.9240506329113924
Fold [2/5] Epoch [0/100] Initial Loss: 0.1351, Training Loss: 0.1351, Initial Validation Loss: 0.1343, Validation Loss: 0.1343,V Acc: 0.3784, Top 70th Acc: 0.4615, Bottom 30th Acc: 0.1818
Fold [2/5] Epoch [10/100] Initial Loss: 0.1351, Training Loss: 0.0440, Initial Validation Loss: 0.1343, Validation Loss: 0.0619,V Acc: 0.7297, Top 70th Acc: 0.7949, Bottom 30th Acc: 0.5758
Fold [2/5] Epoch [20/100] Initial Loss: 0.1351, Training Loss: 0.0247, Initial Validation Loss: 0.1343, Validation Loss: 0.0381,V Acc: 0.8018, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.5152
Stopping early at Epoch (base 0): 28  Rolling back to Epoch (base 0): 23  Top Validation Acc: 0.9102564102564102
23 1 [array([0.30530155, 0.06268327, 0.12746242, 0.27273008, 0.23182264],
      dtype=float32)]
Fold [3/5] Epoch [0/100] Initial Loss: 0.1376, Training Loss: 0.1376, Initial Validation Loss: 0.1314, Validation Loss: 0.1314,V Acc: 0.3091, Top 70th Acc: 0.3636, Bottom 30th Acc: 0.1818
Fold [3/5] Epoch [10/100] Initial Loss: 0.1376, Training Loss: 0.0332, Initial Validation Loss: 0.1314, Validation Loss: 0.0450,V Acc: 0.7727, Top 70th Acc: 0.8961, Bottom 30th Acc: 0.4848
Fold [3/5] Epoch [20/100] Initial Loss: 0.1376, Training Loss: 0.0236, Initial Validation Loss: 0.1314, Validation Loss: 0.0399,V Acc: 0.8000, Top 70th Acc: 0.8831, Bottom 30th Acc: 0.6061
Fold [3/5] Epoch [30/100] Initial Loss: 0.1376, Training Loss: 0.0215, Initial Validation Loss: 0.1314, Validation Loss: 0.0393,V Acc: 0.8091, Top 70th Acc: 0.8961, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 30  Rolling back to Epoch (base 0): 25  Top Validation Acc: 0.8961038961038961
Fold [4/5] Epoch [0/100] Initial Loss: 0.1385, Training Loss: 0.1385, Initial Validation Loss: 0.1341, Validation Loss: 0.1341,V Acc: 0.2477, Top 70th Acc: 0.2987, Bottom 30th Acc: 0.1250
Fold [4/5] Epoch [10/100] Initial Loss: 0.1385, Training Loss: 0.0362, Initial Validation Loss: 0.1341, Validation Loss: 0.0469,V Acc: 0.7706, Top 70th Acc: 0.8831, Bottom 30th Acc: 0.5000
Fold [4/5] Epoch [20/100] Initial Loss: 0.1385, Training Loss: 0.0224, Initial Validation Loss: 0.1341, Validation Loss: 0.0388,V Acc: 0.7982, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.5312
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.8961038961038961
Fold [5/5] Epoch [0/100] Initial Loss: 0.1382, Training Loss: 0.1382, Initial Validation Loss: 0.1312, Validation Loss: 0.1312,V Acc: 0.2500, Top 70th Acc: 0.3421, Bottom 30th Acc: 0.0312
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.9090909090909091
Fold [5/5] Epoch [0/100] Initial Loss: 0.1390, Training Loss: 0.1390, Initial Validation Loss: 0.1355, Validation Loss: 0.1355,V Acc: 0.3148, Top 70th Acc: 0.3553, Bottom 30th Acc: 0.2188
Fold [5/5] Epoch [10/100] Initial Loss: 0.1390, Training Loss: 0.0291, Initial Validation Loss: 0.1355, Validation Loss: 0.0380,V Acc: 0.8519, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.6250
Fold [5/5] Epoch [20/100] Initial Loss: 0.1390, Training Loss: 0.0143, Initial Validation Loss: 0.1355, Validation Loss: 0.0277,V Acc: 0.8704, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.6875
Stopping early at Epoch (base 0): 29  Rolling back to Epoch (base 0): 24  Top Validation Acc: 0.9473684210526315
Running train_nn.py with seed 23
CUDA:False
Training samples count:  550
Training on 40 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1414, Training Loss: 0.1414, Initial Validation Loss: 0.1341, Validation Loss: 0.1341,V Acc: 0.3125, Top 70th Acc: 0.3291, Bottom 30th Acc: 0.2727
Fold [1/5] Epoch [10/100] Initial Loss: 0.1414, Training Loss: 0.0412, Initial Validation Loss: 0.1341, Validation Loss: 0.0355,V Acc: 0.8482, Top 70th Acc: 0.9620, Bottom 30th Acc: 0.5758
Fold [1/5] Epoch [20/100] Initial Loss: 0.1414, Training Loss: 0.0156, Initial Validation Loss: 0.1341, Validation Loss: 0.0244,V Acc: 0.8482, Top 70th Acc: 0.9494, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.9493670886075949
Fold [2/5] Epoch [0/100] Initial Loss: 0.1378, Training Loss: 0.1378, Initial Validation Loss: 0.1357, Validation Loss: 0.1357,V Acc: 0.3514, Top 70th Acc: 0.3718, Bottom 30th Acc: 0.3030
Fold [2/5] Epoch [10/100] Initial Loss: 0.1378, Training Loss: 0.0365, Initial Validation Loss: 0.1357, Validation Loss: 0.0517,V Acc: 0.7387, Top 70th Acc: 0.8333, Bottom 30th Acc: 0.5152
Fold [2/5] Epoch [20/100] Initial Loss: 0.1378, Training Loss: 0.0169, Initial Validation Loss: 0.1357, Validation Loss: 0.0383,V Acc: 0.8018, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.5152
Fold [2/5] Epoch [30/100] Initial Loss: 0.1378, Training Loss: 0.0131, Initial Validation Loss: 0.1357, Validation Loss: 0.0367,V Acc: 0.8108, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 30  Rolling back to Epoch (base 0): 25  Top Validation Acc: 0.9102564102564102
23 1 [array([0.7815689 , 0.01671465, 0.05255063, 0.06833915, 0.0808266 ],
      dtype=float32)]
Fold [3/5] Epoch [0/100] Initial Loss: 0.1388, Training Loss: 0.1388, Initial Validation Loss: 0.1329, Validation Loss: 0.1329,V Acc: 0.3455, Top 70th Acc: 0.3636, Bottom 30th Acc: 0.3030
Fold [3/5] Epoch [10/100] Initial Loss: 0.1388, Training Loss: 0.0312, Initial Validation Loss: 0.1329, Validation Loss: 0.0441,V Acc: 0.7727, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.4545
Fold [3/5] Epoch [20/100] Initial Loss: 0.1388, Training Loss: 0.0146, Initial Validation Loss: 0.1329, Validation Loss: 0.0351,V Acc: 0.8000, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.4545
Stopping early at Epoch (base 0): 29  Rolling back to Epoch (base 0): 24  Top Validation Acc: 0.948051948051948
Fold [4/5] Epoch [0/100] Initial Loss: 0.1400, Training Loss: 0.1400, Initial Validation Loss: 0.1343, Validation Loss: 0.1343,V Acc: 0.3394, Top 70th Acc: 0.4026, Bottom 30th Acc: 0.1875
Fold [4/5] Epoch [10/100] Initial Loss: 0.1400, Training Loss: 0.0310, Initial Validation Loss: 0.1343, Validation Loss: 0.0458,V Acc: 0.7523, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.3750
Fold [4/5] Epoch [20/100] Initial Loss: 0.1400, Training Loss: 0.0140, Initial Validation Loss: 0.1343, Validation Loss: 0.0345,V Acc: 0.8257, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.5938
Fold [4/5] Epoch [30/100] Initial Loss: 0.1400, Training Loss: 0.0113, Initial Validation Loss: 0.1343, Validation Loss: 0.0335,V Acc: 0.8257, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.5938
Stopping early at Epoch (base 0): 33  Rolling back to Epoch (base 0): 28  Top Validation Acc: 0.922077922077922
Fold [5/5] Epoch [0/100] Initial Loss: 0.1418, Training Loss: 0.1418, Initial Validation Loss: 0.1336, Validation Loss: 0.1336,V Acc: 0.2500, Top 70th Acc: 0.2500, Bottom 30th Acc: 0.2500
Fold [5/5] Epoch [10/100] Initial Loss: 0.1418, Training Loss: 0.0271, Initial Validation Loss: 0.1336, Validation Loss: 0.0350,V Acc: 0.8611, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.6562
Fold [5/5] Epoch [20/100] Initial Loss: 0.1418, Training Loss: 0.0135, Initial Validation Loss: 0.1336, Validation Loss: 0.0294,V Acc: 0.8519, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.5938
Fold [5/5] Epoch [30/100] Initial Loss: 0.1418, Training Loss: 0.0112, Initial Validation Loss: 0.1336, Validation Loss: 0.0293,V Acc: 0.8426, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.5625
Stopping early at Epoch (base 0): 30  Rolling back to Epoch (base 0): 25  Top Validation Acc: 0.9605263157894737
Running train_nn.py with seed 24
CUDA:False
Training samples count:  550
Training on 40 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1420, Training Loss: 0.1420, Initial Validation Loss: 0.1380, Validation Loss: 0.1380,V Acc: 0.2857, Top 70th Acc: 0.3671, Bottom 30th Acc: 0.0909
Fold [1/5] Epoch [10/100] Initial Loss: 0.1420, Training Loss: 0.0347, Initial Validation Loss: 0.1380, Validation Loss: 0.0453,V Acc: 0.7946, Top 70th Acc: 0.8861, Bottom 30th Acc: 0.5758
Fold [1/5] Epoch [20/100] Initial Loss: 0.1420, Training Loss: 0.0158, Initial Validation Loss: 0.1380, Validation Loss: 0.0341,V Acc: 0.8304, Top 70th Acc: 0.9241, Bottom 30th Acc: 0.6061
Fold [1/5] Epoch [30/100] Initial Loss: 0.1420, Training Loss: 0.0130, Initial Validation Loss: 0.1380, Validation Loss: 0.0344,V Acc: 0.8036, Top 70th Acc: 0.9367, Bottom 30th Acc: 0.4848
Stopping early at Epoch (base 0): 31  Rolling back to Epoch (base 0): 26  Top Validation Acc: 0.9240506329113924
Fold [2/5] Epoch [0/100] Initial Loss: 0.1396, Training Loss: 0.1396, Initial Validation Loss: 0.1351, Validation Loss: 0.1351,V Acc: 0.2613, Top 70th Acc: 0.3077, Bottom 30th Acc: 0.1515
Fold [2/5] Epoch [10/100] Initial Loss: 0.1396, Training Loss: 0.0334, Initial Validation Loss: 0.1351, Validation Loss: 0.0396,V Acc: 0.8378, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.6364
Fold [2/5] Epoch [20/100] Initial Loss: 0.1396, Training Loss: 0.0144, Initial Validation Loss: 0.1351, Validation Loss: 0.0300,V Acc: 0.8378, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.9487179487179487
Fold [3/5] Epoch [0/100] Initial Loss: 0.1370, Training Loss: 0.1370, Initial Validation Loss: 0.1314, Validation Loss: 0.1314,V Acc: 0.3000, Top 70th Acc: 0.3506, Bottom 30th Acc: 0.1818
Fold [3/5] Epoch [10/100] Initial Loss: 0.1370, Training Loss: 0.0218, Initial Validation Loss: 0.1314, Validation Loss: 0.0301,V Acc: 0.8727, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 16  Rolling back to Epoch (base 0): 11  Top Validation Acc: 0.961038961038961
24 2 [array([0.3768693 , 0.15882435, 0.12637115, 0.08943578, 0.24849942],
      dtype=float32)]
Fold [4/5] Epoch [0/100] Initial Loss: 0.1368, Training Loss: 0.1368, Initial Validation Loss: 0.1356, Validation Loss: 0.1356,V Acc: 0.3761, Top 70th Acc: 0.4416, Bottom 30th Acc: 0.2188
Fold [4/5] Epoch [10/100] Initial Loss: 0.1368, Training Loss: 0.0305, Initial Validation Loss: 0.1356, Validation Loss: 0.0389,V Acc: 0.8624, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6562
Fold [4/5] Epoch [20/100] Initial Loss: 0.1368, Training Loss: 0.0160, Initial Validation Loss: 0.1356, Validation Loss: 0.0317,V Acc: 0.8624, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.5938
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.961038961038961
Fold [5/5] Epoch [0/100] Initial Loss: 0.1424, Training Loss: 0.1424, Initial Validation Loss: 0.1267, Validation Loss: 0.1267,V Acc: 0.3519, Top 70th Acc: 0.4211, Bottom 30th Acc: 0.1875
Fold [5/5] Epoch [10/100] Initial Loss: 0.1424, Training Loss: 0.0255, Initial Validation Loss: 0.1267, Validation Loss: 0.0303,V Acc: 0.8426, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.6250
Fold [3/5] Epoch [30/100] Initial Loss: 0.1373, Training Loss: 0.0043, Initial Validation Loss: 0.1367, Validation Loss: 0.0292,V Acc: 0.8636, Top 70th Acc: 0.9870, Bottom 30th Acc: 0.5758
Fold [3/5] Epoch [40/100] Initial Loss: 0.1373, Training Loss: 0.0040, Initial Validation Loss: 0.1367, Validation Loss: 0.0298,V Acc: 0.8455, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 44  Rolling back to Epoch (base 0): 39  Top Validation Acc: 0.974025974025974
Fold [4/5] Epoch [0/100] Initial Loss: 0.1388, Training Loss: 0.1388, Initial Validation Loss: 0.1252, Validation Loss: 0.1252,V Acc: 0.4220, Top 70th Acc: 0.4416, Bottom 30th Acc: 0.3750
Fold [4/5] Epoch [10/100] Initial Loss: 0.1388, Training Loss: 0.0110, Initial Validation Loss: 0.1252, Validation Loss: 0.0310,V Acc: 0.8165, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.4688
Fold [4/5] Epoch [20/100] Initial Loss: 0.1388, Training Loss: 0.0051, Initial Validation Loss: 0.1252, Validation Loss: 0.0288,V Acc: 0.7982, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.4375
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.948051948051948
17 3 [array([0.29117104, 0.04448755, 0.0633311 , 0.12628426, 0.47472602],
      dtype=float32)]
Fold [5/5] Epoch [0/100] Initial Loss: 0.1389, Training Loss: 0.1389, Initial Validation Loss: 0.1332, Validation Loss: 0.1332,V Acc: 0.3241, Top 70th Acc: 0.3684, Bottom 30th Acc: 0.2188
Fold [5/5] Epoch [10/100] Initial Loss: 0.1389, Training Loss: 0.0242, Initial Validation Loss: 0.1332, Validation Loss: 0.0427,V Acc: 0.8056, Top 70th Acc: 0.9211, Bottom 30th Acc: 0.5312
Fold [5/5] Epoch [20/100] Initial Loss: 0.1389, Training Loss: 0.0060, Initial Validation Loss: 0.1332, Validation Loss: 0.0338,V Acc: 0.8241, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.5312
Fold [5/5] Epoch [30/100] Initial Loss: 0.1389, Training Loss: 0.0042, Initial Validation Loss: 0.1332, Validation Loss: 0.0299,V Acc: 0.8519, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.6562
Fold [5/5] Epoch [40/100] Initial Loss: 0.1389, Training Loss: 0.0038, Initial Validation Loss: 0.1332, Validation Loss: 0.0281,V Acc: 0.8704, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.6562
Stopping early at Epoch (base 0): 45  Rolling back to Epoch (base 0): 40  Top Validation Acc: 0.9605263157894737
Running train_nn.py with seed 18
CUDA:False
Training samples count:  550
Training on 162 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1388, Training Loss: 0.1388, Initial Validation Loss: 0.1373, Validation Loss: 0.1373,V Acc: 0.2500, Top 70th Acc: 0.3291, Bottom 30th Acc: 0.0606
Fold [1/5] Epoch [10/100] Initial Loss: 0.1388, Training Loss: 0.0275, Initial Validation Loss: 0.1373, Validation Loss: 0.0422,V Acc: 0.7768, Top 70th Acc: 0.9367, Bottom 30th Acc: 0.3939
Fold [1/5] Epoch [20/100] Initial Loss: 0.1388, Training Loss: 0.0059, Initial Validation Loss: 0.1373, Validation Loss: 0.0300,V Acc: 0.8482, Top 70th Acc: 0.9620, Bottom 30th Acc: 0.5758
Fold [1/5] Epoch [30/100] Initial Loss: 0.1388, Training Loss: 0.0043, Initial Validation Loss: 0.1373, Validation Loss: 0.0264,V Acc: 0.8661, Top 70th Acc: 1.0000, Bottom 30th Acc: 0.5455
Fold [1/5] Epoch [40/100] Initial Loss: 0.1388, Training Loss: 0.0039, Initial Validation Loss: 0.1373, Validation Loss: 0.0255,V Acc: 0.8571, Top 70th Acc: 1.0000, Bottom 30th Acc: 0.5152
Fold [1/5] Epoch [50/100] Initial Loss: 0.1388, Training Loss: 0.0038, Initial Validation Loss: 0.1373, Validation Loss: 0.0252,V Acc: 0.8661, Top 70th Acc: 1.0000, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 59  Rolling back to Epoch (base 0): 54  Top Validation Acc: 1.0
18 0 [array([0.17616922, 0.08994007, 0.07443325, 0.13475633, 0.5247011 ],
      dtype=float32)]
Fold [2/5] Epoch [0/100] Initial Loss: 0.1434, Training Loss: 0.1434, Initial Validation Loss: 0.1378, Validation Loss: 0.1378,V Acc: 0.2252, Top 70th Acc: 0.2692, Bottom 30th Acc: 0.1212
Fold [2/5] Epoch [10/100] Initial Loss: 0.1434, Training Loss: 0.0175, Initial Validation Loss: 0.1378, Validation Loss: 0.0339,V Acc: 0.8468, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.6061
Fold [2/5] Epoch [20/100] Initial Loss: 0.1434, Training Loss: 0.0043, Initial Validation Loss: 0.1378, Validation Loss: 0.0252,V Acc: 0.8559, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.5758
Fold [2/5] Epoch [30/100] Initial Loss: 0.1434, Training Loss: 0.0034, Initial Validation Loss: 0.1378, Validation Loss: 0.0243,V Acc: 0.8649, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 34  Rolling back to Epoch (base 0): 29  Top Validation Acc: 0.9743589743589743
Fold [3/5] Epoch [0/100] Initial Loss: 0.1393, Training Loss: 0.1393, Initial Validation Loss: 0.1330, Validation Loss: 0.1330,V Acc: 0.3455, Top 70th Acc: 0.3896, Bottom 30th Acc: 0.2424
Fold [3/5] Epoch [10/100] Initial Loss: 0.1393, Training Loss: 0.0330, Initial Validation Loss: 0.1330, Validation Loss: 0.0531,V Acc: 0.7273, Top 70th Acc: 0.8442, Bottom 30th Acc: 0.4545
Fold [3/5] Epoch [20/100] Initial Loss: 0.1393, Training Loss: 0.0060, Initial Validation Loss: 0.1330, Validation Loss: 0.0374,V Acc: 0.7909, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.5152
Fold [3/5] Epoch [30/100] Initial Loss: 0.1393, Training Loss: 0.0041, Initial Validation Loss: 0.1330, Validation Loss: 0.0349,V Acc: 0.8091, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.5455
Fold [3/5] Epoch [40/100] Initial Loss: 0.1393, Training Loss: 0.0038, Initial Validation Loss: 0.1330, Validation Loss: 0.0342,V Acc: 0.8091, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.5455
Fold [3/5] Epoch [50/100] Initial Loss: 0.1393, Training Loss: 0.0037, Initial Validation Loss: 0.1330, Validation Loss: 0.0338,V Acc: 0.8182, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 53  Rolling back to Epoch (base 0): 48  Top Validation Acc: 0.922077922077922
Fold [4/5] Epoch [0/100] Initial Loss: 0.1394, Training Loss: 0.1394, Initial Validation Loss: 0.1333, Validation Loss: 0.1333,V Acc: 0.2477, Top 70th Acc: 0.2857, Bottom 30th Acc: 0.1562
Fold [4/5] Epoch [10/100] Initial Loss: 0.1394, Training Loss: 0.0177, Initial Validation Loss: 0.1333, Validation Loss: 0.0371,V Acc: 0.8349, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.6250
Fold [4/5] Epoch [20/100] Initial Loss: 0.1394, Training Loss: 0.0052, Initial Validation Loss: 0.1333, Validation Loss: 0.0311,V Acc: 0.8349, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.5938
Fold [4/5] Epoch [30/100] Initial Loss: 0.1394, Training Loss: 0.0042, Initial Validation Loss: 0.1333, Validation Loss: 0.0306,V Acc: 0.8440, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.6562
Stopping early at Epoch (base 0): 36  Rolling back to Epoch (base 0): 31  Top Validation Acc: 0.922077922077922
Fold [5/5] Epoch [0/100] Initial Loss: 0.1382, Training Loss: 0.1382, Initial Validation Loss: 0.1303, Validation Loss: 0.1303,V Acc: 0.3241, Top 70th Acc: 0.3947, Bottom 30th Acc: 0.1562
Fold [5/5] Epoch [10/100] Initial Loss: 0.1382, Training Loss: 0.0134, Initial Validation Loss: 0.1303, Validation Loss: 0.0241,V Acc: 0.8611, Top 70th Acc: 0.9737, Bottom 30th Acc: 0.5938
Fold [5/5] Epoch [20/100] Initial Loss: 0.1382, Training Loss: 0.0050, Initial Validation Loss: 0.1303, Validation Loss: 0.0215,V Acc: 0.8611, Top 70th Acc: 0.9868, Bottom 30th Acc: 0.5625
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.9736842105263158
Running train_nn.py with seed 19
CUDA:False
Training samples count:  550
Training on 162 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1379, Training Loss: 0.1379, Initial Validation Loss: 0.1420, Validation Loss: 0.1420,V Acc: 0.2500, Top 70th Acc: 0.3165, Bottom 30th Acc: 0.0909
Fold [1/5] Epoch [10/100] Initial Loss: 0.1379, Training Loss: 0.0245, Initial Validation Loss: 0.1420, Validation Loss: 0.0371,V Acc: 0.8482, Top 70th Acc: 0.9620, Bottom 30th Acc: 0.5758
Fold [1/5] Epoch [20/100] Initial Loss: 0.1379, Training Loss: 0.0059, Initial Validation Loss: 0.1420, Validation Loss: 0.0276,V Acc: 0.8661, Top 70th Acc: 0.9747, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 27  Rolling back to Epoch (base 0): 22  Top Validation Acc: 0.9620253164556962
Fold [2/5] Epoch [0/100] Initial Loss: 0.1404, Training Loss: 0.1404, Initial Validation Loss: 0.1296, Validation Loss: 0.1296,V Acc: 0.4324, Top 70th Acc: 0.4872, Bottom 30th Acc: 0.3030training rf with seed 1
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 30 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 2
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 30 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 3
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 30 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 4
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 30 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 5
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 30 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 6
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 30 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 7
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 30 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 8
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 30 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 9
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 30 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 10
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 30 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 11
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 30 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 12
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 30 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 13
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 30 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 14
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 30 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 15
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 30 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 16
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 30 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 17
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 30 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 18
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 30 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 19
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 30 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 20
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 30 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 21
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 30 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 22
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 30 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 23
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 30 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 24
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 30 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 25
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 30 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 26
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 30 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 27
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 30 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 28
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 30 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 29
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 30 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 30
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 30 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 31
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 30 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 32
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 30 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 33
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 30 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 34
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 30 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 35
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 30 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 36
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 30 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 37
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 30 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 38
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 30 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 39
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 30 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 40
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 30 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 41
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 30 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 42
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 30 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 43
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 30 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 44
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 30 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 45
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Stopping early at Epoch (base 0): 34  Rolling back to Epoch (base 0): 29  Top Validation Acc: 0.9367088607594937
Fold [2/5] Epoch [0/100] Initial Loss: 0.1404, Training Loss: 0.1404, Initial Validation Loss: 0.1317, Validation Loss: 0.1317,V Acc: 0.2523, Top 70th Acc: 0.3590, Bottom 30th Acc: 0.0000
Fold [2/5] Epoch [10/100] Initial Loss: 0.1404, Training Loss: 0.0290, Initial Validation Loss: 0.1317, Validation Loss: 0.0355,V Acc: 0.8468, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.6364
Fold [2/5] Epoch [20/100] Initial Loss: 0.1404, Training Loss: 0.0167, Initial Validation Loss: 0.1317, Validation Loss: 0.0339,V Acc: 0.8468, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 22  Rolling back to Epoch (base 0): 17  Top Validation Acc: 0.9230769230769231
Fold [3/5] Epoch [0/100] Initial Loss: 0.1380, Training Loss: 0.1380, Initial Validation Loss: 0.1347, Validation Loss: 0.1347,V Acc: 0.3818, Top 70th Acc: 0.4156, Bottom 30th Acc: 0.3030
Fold [3/5] Epoch [10/100] Initial Loss: 0.1380, Training Loss: 0.0445, Initial Validation Loss: 0.1347, Validation Loss: 0.0531,V Acc: 0.7455, Top 70th Acc: 0.8701, Bottom 30th Acc: 0.4545
Fold [3/5] Epoch [20/100] Initial Loss: 0.1380, Training Loss: 0.0215, Initial Validation Loss: 0.1347, Validation Loss: 0.0302,V Acc: 0.8545, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.6061
Fold [3/5] Epoch [30/100] Initial Loss: 0.1380, Training Loss: 0.0168, Initial Validation Loss: 0.1347, Validation Loss: 0.0298,V Acc: 0.8545, Top 70th Acc: 0.9870, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 32  Rolling back to Epoch (base 0): 27  Top Validation Acc: 0.974025974025974
24 2 [array([0.6995326 , 0.0538002 , 0.03089171, 0.10697318, 0.10880224],
      dtype=float32)]
Fold [4/5] Epoch [0/100] Initial Loss: 0.1372, Training Loss: 0.1372, Initial Validation Loss: 0.1365, Validation Loss: 0.1365,V Acc: 0.2752, Top 70th Acc: 0.3506, Bottom 30th Acc: 0.0938
Fold [4/5] Epoch [10/100] Initial Loss: 0.1372, Training Loss: 0.0287, Initial Validation Loss: 0.1365, Validation Loss: 0.0358,V Acc: 0.8440, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.5625
Fold [4/5] Epoch [20/100] Initial Loss: 0.1372, Training Loss: 0.0190, Initial Validation Loss: 0.1365, Validation Loss: 0.0313,V Acc: 0.8624, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.6250
Stopping early at Epoch (base 0): 27  Rolling back to Epoch (base 0): 22  Top Validation Acc: 0.948051948051948
Fold [5/5] Epoch [0/100] Initial Loss: 0.1412, Training Loss: 0.1412, Initial Validation Loss: 0.1277, Validation Loss: 0.1277,V Acc: 0.2685, Top 70th Acc: 0.3684, Bottom 30th Acc: 0.0312
Fold [5/5] Epoch [10/100] Initial Loss: 0.1412, Training Loss: 0.0362, Initial Validation Loss: 0.1277, Validation Loss: 0.0349,V Acc: 0.7963, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.4375
Fold [5/5] Epoch [20/100] Initial Loss: 0.1412, Training Loss: 0.0197, Initial Validation Loss: 0.1277, Validation Loss: 0.0269,V Acc: 0.8333, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.5625
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.9342105263157895
Running train_nn.py with seed 25
CUDA:False
Training samples count:  550
Training on 30 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1425, Training Loss: 0.1425, Initial Validation Loss: 0.1376, Validation Loss: 0.1376,V Acc: 0.2679, Top 70th Acc: 0.2911, Bottom 30th Acc: 0.2121
Fold [1/5] Epoch [10/100] Initial Loss: 0.1425, Training Loss: 0.0359, Initial Validation Loss: 0.1376, Validation Loss: 0.0459,V Acc: 0.7500, Top 70th Acc: 0.8734, Bottom 30th Acc: 0.4545
Fold [1/5] Epoch [20/100] Initial Loss: 0.1425, Training Loss: 0.0208, Initial Validation Loss: 0.1376, Validation Loss: 0.0333,V Acc: 0.8304, Top 70th Acc: 0.9114, Bottom 30th Acc: 0.6364
Fold [1/5] Epoch [30/100] Initial Loss: 0.1425, Training Loss: 0.0179, Initial Validation Loss: 0.1376, Validation Loss: 0.0305,V Acc: 0.8571, Top 70th Acc: 0.9114, Bottom 30th Acc: 0.7273
Stopping early at Epoch (base 0): 37  Rolling back to Epoch (base 0): 32  Top Validation Acc: 0.9113924050632911
Fold [2/5] Epoch [0/100] Initial Loss: 0.1398, Training Loss: 0.1398, Initial Validation Loss: 0.1396, Validation Loss: 0.1396,V Acc: 0.2613, Top 70th Acc: 0.3462, Bottom 30th Acc: 0.0606
Fold [2/5] Epoch [10/100] Initial Loss: 0.1398, Training Loss: 0.0343, Initial Validation Loss: 0.1396, Validation Loss: 0.0369,V Acc: 0.8559, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.6061
Fold [2/5] Epoch [20/100] Initial Loss: 0.1398, Training Loss: 0.0188, Initial Validation Loss: 0.1396, Validation Loss: 0.0288,V Acc: 0.8739, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.9743589743589743
Fold [3/5] Epoch [0/100] Initial Loss: 0.1387, Training Loss: 0.1387, Initial Validation Loss: 0.1319, Validation Loss: 0.1319,V Acc: 0.3636, Top 70th Acc: 0.4156, Bottom 30th Acc: 0.2424
Fold [3/5] Epoch [10/100] Initial Loss: 0.1387, Training Loss: 0.0353, Initial Validation Loss: 0.1319, Validation Loss: 0.0325,V Acc: 0.8273, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.5152
Fold [3/5] Epoch [20/100] Initial Loss: 0.1387, Training Loss: 0.0199, Initial Validation Loss: 0.1319, Validation Loss: 0.0287,V Acc: 0.8455, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 20  Rolling back to Epoch (base 0): 15  Top Validation Acc: 0.974025974025974
25 2 [array([0.6459501 , 0.15528108, 0.03883922, 0.08427503, 0.07565463],
      dtype=float32)]
Fold [4/5] Epoch [0/100] Initial Loss: 0.1395, Training Loss: 0.1395, Initial Validation Loss: 0.1311, Validation Loss: 0.1311,V Acc: 0.3028, Top 70th Acc: 0.2987, Bottom 30th Acc: 0.3125
Fold [4/5] Epoch [10/100] Initial Loss: 0.1395, Training Loss: 0.0347, Initial Validation Loss: 0.1311, Validation Loss: 0.0415,V Acc: 0.7890, Top 70th Acc: 0.8961, Bottom 30th Acc: 0.5312
Fold [4/5] Epoch [20/100] Initial Loss: 0.1395, Training Loss: 0.0192, Initial Validation Loss: 0.1311, Validation Loss: 0.0325,V Acc: 0.8073, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.4688
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.935064935064935
Fold [5/5] Epoch [0/100] Initial Loss: 0.1395, Training Loss: 0.1395, Initial Validation Loss: 0.1257, Validation Loss: 0.1257,V Acc: 0.3056, Top 70th Acc: 0.3684, Bottom 30th Acc: 0.1562
Fold [5/5] Epoch [10/100] Initial Loss: 0.1395, Training Loss: 0.0274, Initial Validation Loss: 0.1257, Validation Loss: 0.0487,V Acc: 0.7593, Top 70th Acc: 0.8816, Bottom 30th Acc: 0.4688
Fold [5/5] Epoch [20/100] Initial Loss: 0.1395, Training Loss: 0.0165, Initial Validation Loss: 0.1257, Validation Loss: 0.0433,V Acc: 0.7593, Top 70th Acc: 0.9079, Bottom 30th Acc: 0.4062
Fold [5/5] Epoch [30/100] Initial Loss: 0.1395, Training Loss: 0.0140, Initial Validation Loss: 0.1257, Validation Loss: 0.0423,V Acc: 0.7593, Top 70th Acc: 0.8947, Bottom 30th Acc: 0.4375
Stopping early at Epoch (base 0): 37  Rolling back to Epoch (base 0): 32  Top Validation Acc: 0.8947368421052632
Running train_nn.py with seed 26
CUDA:False
Training samples count:  550
Training on 30 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1419, Training Loss: 0.1419, Initial Validation Loss: 0.1340, Validation Loss: 0.1340,V Acc: 0.3393, Top 70th Acc: 0.3797, Bottom 30th Acc: 0.2424
Fold [1/5] Epoch [10/100] Initial Loss: 0.1419, Training Loss: 0.0332, Initial Validation Loss: 0.1340, Validation Loss: 0.0371,V Acc: 0.8304, Top 70th Acc: 0.9494, Bottom 30th Acc: 0.5455
Fold [1/5] Epoch [20/100] Initial Loss: 0.1419, Training Loss: 0.0179, Initial Validation Loss: 0.1340, Validation Loss: 0.0317,V Acc: 0.8125, Top 70th Acc: 0.9620, Bottom 30th Acc: 0.4545
Stopping early at Epoch (base 0): 22  Rolling back to Epoch (base 0): 17  Top Validation Acc: 0.9620253164556962
Fold [2/5] Epoch [0/100] Initial Loss: 0.1387, Training Loss: 0.1387, Initial Validation Loss: 0.1380, Validation Loss: 0.1380,V Acc: 0.2703, Top 70th Acc: 0.3205, Bottom 30th Acc: 0.1515
Fold [2/5] Epoch [10/100] Initial Loss: 0.1387, Training Loss: 0.0298, Initial Validation Loss: 0.1380, Validation Loss: 0.0279,V Acc: 0.8649, Top 70th Acc: 0.9872, Bottom 30th Acc: 0.5758
Fold [1/5] Epoch [10/100] Initial Loss: 0.1453, Training Loss: 0.0839, Initial Validation Loss: 0.1350, Validation Loss: 0.0761,V Acc: 0.6518, Top 70th Acc: 0.7722, Bottom 30th Acc: 0.3636
Fold [1/5] Epoch [20/100] Initial Loss: 0.1453, Training Loss: 0.0806, Initial Validation Loss: 0.1350, Validation Loss: 0.0738,V Acc: 0.6607, Top 70th Acc: 0.7848, Bottom 30th Acc: 0.3636
Stopping early at Epoch (base 0): 28  Rolling back to Epoch (base 0): 23  Top Validation Acc: 0.7848101265822784
Fold [2/5] Epoch [0/100] Initial Loss: 0.1396, Training Loss: 0.1396, Initial Validation Loss: 0.1367, Validation Loss: 0.1367,V Acc: 0.2973, Top 70th Acc: 0.3590, Bottom 30th Acc: 0.1515
Fold [2/5] Epoch [10/100] Initial Loss: 0.1396, Training Loss: 0.0809, Initial Validation Loss: 0.1367, Validation Loss: 0.0833,V Acc: 0.6306, Top 70th Acc: 0.7179, Bottom 30th Acc: 0.4242
Fold [2/5] Epoch [20/100] Initial Loss: 0.1396, Training Loss: 0.0787, Initial Validation Loss: 0.1367, Validation Loss: 0.0808,V Acc: 0.6306, Top 70th Acc: 0.7179, Bottom 30th Acc: 0.4242
Fold [2/5] Epoch [30/100] Initial Loss: 0.1396, Training Loss: 0.0780, Initial Validation Loss: 0.1367, Validation Loss: 0.0809,V Acc: 0.6486, Top 70th Acc: 0.7051, Bottom 30th Acc: 0.5152
Stopping early at Epoch (base 0): 33  Rolling back to Epoch (base 0): 28  Top Validation Acc: 0.7051282051282052
23 1 [array([0.12121762, 0.38637304, 0.15050784, 0.19607389, 0.14582756],
      dtype=float32)]
Fold [3/5] Epoch [0/100] Initial Loss: 0.1336, Training Loss: 0.1336, Initial Validation Loss: 0.1230, Validation Loss: 0.1230,V Acc: 0.5000, Top 70th Acc: 0.5584, Bottom 30th Acc: 0.3636
Fold [3/5] Epoch [10/100] Initial Loss: 0.1336, Training Loss: 0.0809, Initial Validation Loss: 0.1230, Validation Loss: 0.0787,V Acc: 0.6000, Top 70th Acc: 0.7273, Bottom 30th Acc: 0.3030
Fold [3/5] Epoch [20/100] Initial Loss: 0.1336, Training Loss: 0.0790, Initial Validation Loss: 0.1230, Validation Loss: 0.0779,V Acc: 0.6000, Top 70th Acc: 0.7403, Bottom 30th Acc: 0.2727
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.7402597402597403
Fold [4/5] Epoch [0/100] Initial Loss: 0.1379, Training Loss: 0.1379, Initial Validation Loss: 0.1312, Validation Loss: 0.1312,V Acc: 0.2661, Top 70th Acc: 0.3247, Bottom 30th Acc: 0.1250
Fold [4/5] Epoch [10/100] Initial Loss: 0.1379, Training Loss: 0.0803, Initial Validation Loss: 0.1312, Validation Loss: 0.0797,V Acc: 0.6422, Top 70th Acc: 0.7273, Bottom 30th Acc: 0.4375
Fold [4/5] Epoch [20/100] Initial Loss: 0.1379, Training Loss: 0.0784, Initial Validation Loss: 0.1312, Validation Loss: 0.0775,V Acc: 0.6422, Top 70th Acc: 0.7403, Bottom 30th Acc: 0.4062
Fold [4/5] Epoch [30/100] Initial Loss: 0.1379, Training Loss: 0.0777, Initial Validation Loss: 0.1312, Validation Loss: 0.0777,V Acc: 0.6422, Top 70th Acc: 0.7273, Bottom 30th Acc: 0.4375
Stopping early at Epoch (base 0): 31  Rolling back to Epoch (base 0): 26  Top Validation Acc: 0.7272727272727273
Fold [5/5] Epoch [0/100] Initial Loss: 0.1398, Training Loss: 0.1398, Initial Validation Loss: 0.1316, Validation Loss: 0.1316,V Acc: 0.4259, Top 70th Acc: 0.3947, Bottom 30th Acc: 0.5000
Fold [5/5] Epoch [10/100] Initial Loss: 0.1398, Training Loss: 0.0804, Initial Validation Loss: 0.1316, Validation Loss: 0.0793,V Acc: 0.6389, Top 70th Acc: 0.7500, Bottom 30th Acc: 0.3750
Fold [5/5] Epoch [20/100] Initial Loss: 0.1398, Training Loss: 0.0785, Initial Validation Loss: 0.1316, Validation Loss: 0.0781,V Acc: 0.6389, Top 70th Acc: 0.7500, Bottom 30th Acc: 0.3750
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.7236842105263158
Running train_nn.py with seed 24
CUDA:False
Training samples count:  550
Training on 2 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1394, Training Loss: 0.1394, Initial Validation Loss: 0.1319, Validation Loss: 0.1319,V Acc: 0.4375, Top 70th Acc: 0.5443, Bottom 30th Acc: 0.1818
Fold [1/5] Epoch [10/100] Initial Loss: 0.1394, Training Loss: 0.0794, Initial Validation Loss: 0.1319, Validation Loss: 0.0838,V Acc: 0.6071, Top 70th Acc: 0.7215, Bottom 30th Acc: 0.3333
Fold [1/5] Epoch [20/100] Initial Loss: 0.1394, Training Loss: 0.0773, Initial Validation Loss: 0.1319, Validation Loss: 0.0833,V Acc: 0.6250, Top 70th Acc: 0.7468, Bottom 30th Acc: 0.3333
Fold [1/5] Epoch [30/100] Initial Loss: 0.1394, Training Loss: 0.0769, Initial Validation Loss: 0.1319, Validation Loss: 0.0825,V Acc: 0.6161, Top 70th Acc: 0.7215, Bottom 30th Acc: 0.3636
Stopping early at Epoch (base 0): 35  Rolling back to Epoch (base 0): 30  Top Validation Acc: 0.7215189873417721
Fold [2/5] Epoch [0/100] Initial Loss: 0.1402, Training Loss: 0.1402, Initial Validation Loss: 0.1281, Validation Loss: 0.1281,V Acc: 0.3604, Top 70th Acc: 0.4103, Bottom 30th Acc: 0.2424
Fold [2/5] Epoch [10/100] Initial Loss: 0.1402, Training Loss: 0.0810, Initial Validation Loss: 0.1281, Validation Loss: 0.0771,V Acc: 0.6396, Top 70th Acc: 0.7308, Bottom 30th Acc: 0.4242
Stopping early at Epoch (base 0): 19  Rolling back to Epoch (base 0): 14  Top Validation Acc: 0.717948717948718
Fold [3/5] Epoch [0/100] Initial Loss: 0.1362, Training Loss: 0.1362, Initial Validation Loss: 0.1282, Validation Loss: 0.1282,V Acc: 0.4182, Top 70th Acc: 0.5065, Bottom 30th Acc: 0.2121
Fold [3/5] Epoch [10/100] Initial Loss: 0.1362, Training Loss: 0.0786, Initial Validation Loss: 0.1282, Validation Loss: 0.0861,V Acc: 0.5727, Top 70th Acc: 0.7143, Bottom 30th Acc: 0.2424
Fold [3/5] Epoch [20/100] Initial Loss: 0.1362, Training Loss: 0.0770, Initial Validation Loss: 0.1282, Validation Loss: 0.0846,V Acc: 0.5818, Top 70th Acc: 0.7273, Bottom 30th Acc: 0.2424
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.7272727272727273
24 2 [array([0.11376449, 0.3917927 , 0.15137646, 0.199932  , 0.14313433],
      dtype=float32)]
Fold [4/5] Epoch [0/100] Initial Loss: 0.1311, Training Loss: 0.1311, Initial Validation Loss: 0.1221, Validation Loss: 0.1221,V Acc: 0.4128, Top 70th Acc: 0.5714, Bottom 30th Acc: 0.0312
Fold [4/5] Epoch [10/100] Initial Loss: 0.1311, Training Loss: 0.0811, Initial Validation Loss: 0.1221, Validation Loss: 0.0768,V Acc: 0.6697, Top 70th Acc: 0.7662, Bottom 30th Acc: 0.4375
Fold [4/5] Epoch [20/100] Initial Loss: 0.1311, Training Loss: 0.0792, Initial Validation Loss: 0.1221, Validation Loss: 0.0754,V Acc: 0.6881, Top 70th Acc: 0.7792, Bottom 30th Acc: 0.4688
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.7792207792207793
Fold [5/5] Epoch [0/100] Initial Loss: 0.1355, Training Loss: 0.1355, Initial Validation Loss: 0.1185, Validation Loss: 0.1185,V Acc: 0.4074, Top 70th Acc: 0.4342, Bottom 30th Acc: 0.3438
Fold [5/5] Epoch [10/100] Initial Loss: 0.1355, Training Loss: 0.0826, Initial Validation Loss: 0.1185, Validation Loss: 0.0710,V Acc: 0.6481, Top 70th Acc: 0.7895, Bottom 30th Acc: 0.3125
Fold [5/5] Epoch [20/100] Initial Loss: 0.1355, Training Loss: 0.0811, Initial Validation Loss: 0.1185, Validation Loss: 0.0685,V Acc: 0.6481, Top 70th Acc: 0.7763, Bottom 30th Acc: 0.3438
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.8026315789473685
Running train_nn.py with seed 25
CUDA:False
Training samples count:  550
Training on 2 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1357, Training Loss: 0.1357, Initial Validation Loss: 0.1272, Validation Loss: 0.1272,V Acc: 0.4911, Top 70th Acc: 0.5443, Bottom 30th Acc: 0.3636
Fold [1/5] Epoch [10/100] Initial Loss: 0.1357, Training Loss: 0.0812, Initial Validation Loss: 0.1272, Validation Loss: 0.0798,V Acc: 0.6429, Top 70th Acc: 0.7468, Bottom 30th Acc: 0.3939
Fold [1/5] Epoch [20/100] Initial Loss: 0.1357, Training Loss: 0.0791, Initial Validation Loss: 0.1272, Validation Loss: 0.0780,V Acc: 0.6250, Top 70th Acc: 0.7342, Bottom 30th Acc: 0.3636
Stopping early at Epoch (base 0): 21  Rolling back to Epoch (base 0): 16  Top Validation Acc: 0.7341772151898734
Fold [2/5] Epoch [0/100] Initial Loss: 0.1363, Training Loss: 0.1363, Initial Validation Loss: 0.1354, Validation Loss: 0.1354,V Acc: 0.3694, Top 70th Acc: 0.4615, Bottom 30th Acc: 0.1515
Fold [3/5] Epoch [10/100] Initial Loss: 0.1271, Training Loss: 0.0293, Initial Validation Loss: 0.1141, Validation Loss: 0.0294,V Acc: 0.8455, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.5455
Fold [3/5] Epoch [20/100] Initial Loss: 0.1271, Training Loss: 0.0182, Initial Validation Loss: 0.1141, Validation Loss: 0.0221,V Acc: 0.8727, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 29  Rolling back to Epoch (base 0): 24  Top Validation Acc: 0.974025974025974
Fold [4/5] Epoch [0/100] Initial Loss: 0.1312, Training Loss: 0.1312, Initial Validation Loss: 0.1109, Validation Loss: 0.1109,V Acc: 0.5688, Top 70th Acc: 0.6753, Bottom 30th Acc: 0.3125
Fold [4/5] Epoch [10/100] Initial Loss: 0.1312, Training Loss: 0.0218, Initial Validation Loss: 0.1109, Validation Loss: 0.0287,V Acc: 0.8807, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.6875
Fold [4/5] Epoch [20/100] Initial Loss: 0.1312, Training Loss: 0.0157, Initial Validation Loss: 0.1109, Validation Loss: 0.0235,V Acc: 0.9083, Top 70th Acc: 0.9870, Bottom 30th Acc: 0.7188
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.974025974025974
Fold [5/5] Epoch [0/100] Initial Loss: 0.1375, Training Loss: 0.1375, Initial Validation Loss: 0.1240, Validation Loss: 0.1240,V Acc: 0.4074, Top 70th Acc: 0.5000, Bottom 30th Acc: 0.1875
Fold [5/5] Epoch [10/100] Initial Loss: 0.1375, Training Loss: 0.0221, Initial Validation Loss: 0.1240, Validation Loss: 0.0337,V Acc: 0.8333, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.5938
Stopping early at Epoch (base 0): 19  Rolling back to Epoch (base 0): 14  Top Validation Acc: 0.9605263157894737
33 4 [array([0.69892955, 0.03057565, 0.03326428, 0.13503264, 0.10219789],
      dtype=float32)]
Running train_nn.py with seed 34
CUDA:False
Training samples count:  550
Training on 21 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1336, Training Loss: 0.1336, Initial Validation Loss: 0.1236, Validation Loss: 0.1236,V Acc: 0.4375, Top 70th Acc: 0.5570, Bottom 30th Acc: 0.1515
Fold [1/5] Epoch [10/100] Initial Loss: 0.1336, Training Loss: 0.0235, Initial Validation Loss: 0.1236, Validation Loss: 0.0356,V Acc: 0.8304, Top 70th Acc: 0.9494, Bottom 30th Acc: 0.5455
Fold [1/5] Epoch [20/100] Initial Loss: 0.1336, Training Loss: 0.0147, Initial Validation Loss: 0.1236, Validation Loss: 0.0267,V Acc: 0.8661, Top 70th Acc: 0.9620, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 28  Rolling back to Epoch (base 0): 23  Top Validation Acc: 0.9367088607594937
34 0 [array([0.8477873 , 0.0137498 , 0.01343971, 0.04293675, 0.08208644],
      dtype=float32)]
Fold [2/5] Epoch [0/100] Initial Loss: 0.1317, Training Loss: 0.1317, Initial Validation Loss: 0.1176, Validation Loss: 0.1176,V Acc: 0.5676, Top 70th Acc: 0.6923, Bottom 30th Acc: 0.2727
Fold [2/5] Epoch [10/100] Initial Loss: 0.1317, Training Loss: 0.0303, Initial Validation Loss: 0.1176, Validation Loss: 0.0281,V Acc: 0.8829, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 19  Rolling back to Epoch (base 0): 14  Top Validation Acc: 0.9615384615384616
Fold [3/5] Epoch [0/100] Initial Loss: 0.1377, Training Loss: 0.1377, Initial Validation Loss: 0.1321, Validation Loss: 0.1321,V Acc: 0.4364, Top 70th Acc: 0.5065, Bottom 30th Acc: 0.2727
Fold [3/5] Epoch [10/100] Initial Loss: 0.1377, Training Loss: 0.0227, Initial Validation Loss: 0.1321, Validation Loss: 0.0316,V Acc: 0.8545, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 19  Rolling back to Epoch (base 0): 14  Top Validation Acc: 0.961038961038961
Fold [4/5] Epoch [0/100] Initial Loss: 0.1340, Training Loss: 0.1340, Initial Validation Loss: 0.1167, Validation Loss: 0.1167,V Acc: 0.4495, Top 70th Acc: 0.5455, Bottom 30th Acc: 0.2188
Fold [4/5] Epoch [10/100] Initial Loss: 0.1340, Training Loss: 0.0211, Initial Validation Loss: 0.1167, Validation Loss: 0.0271,V Acc: 0.8807, Top 70th Acc: 0.9870, Bottom 30th Acc: 0.6250
Fold [4/5] Epoch [20/100] Initial Loss: 0.1340, Training Loss: 0.0155, Initial Validation Loss: 0.1167, Validation Loss: 0.0320,V Acc: 0.8073, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.4062
Stopping early at Epoch (base 0): 20  Rolling back to Epoch (base 0): 15  Top Validation Acc: 0.974025974025974
Fold [5/5] Epoch [0/100] Initial Loss: 0.1364, Training Loss: 0.1364, Initial Validation Loss: 0.1206, Validation Loss: 0.1206,V Acc: 0.4815, Top 70th Acc: 0.5789, Bottom 30th Acc: 0.2500
Fold [5/5] Epoch [10/100] Initial Loss: 0.1364, Training Loss: 0.0233, Initial Validation Loss: 0.1206, Validation Loss: 0.0281,V Acc: 0.8704, Top 70th Acc: 0.9737, Bottom 30th Acc: 0.6250
Stopping early at Epoch (base 0): 17  Rolling back to Epoch (base 0): 12  Top Validation Acc: 0.9473684210526315
Running train_nn.py with seed 35
CUDA:False
Training samples count:  550
Training on 21 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1283, Training Loss: 0.1283, Initial Validation Loss: 0.1109, Validation Loss: 0.1109,V Acc: 0.5982, Top 70th Acc: 0.7342, Bottom 30th Acc: 0.2727
Fold [1/5] Epoch [10/100] Initial Loss: 0.1283, Training Loss: 0.0190, Initial Validation Loss: 0.1109, Validation Loss: 0.0308,V Acc: 0.8750, Top 70th Acc: 0.9620, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 17  Rolling back to Epoch (base 0): 12  Top Validation Acc: 0.9746835443037974
Fold [2/5] Epoch [0/100] Initial Loss: 0.1376, Training Loss: 0.1376, Initial Validation Loss: 0.1288, Validation Loss: 0.1288,V Acc: 0.5946, Top 70th Acc: 0.6923, Bottom 30th Acc: 0.3636
Fold [2/5] Epoch [10/100] Initial Loss: 0.1376, Training Loss: 0.0258, Initial Validation Loss: 0.1288, Validation Loss: 0.0278,V Acc: 0.8739, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 15  Rolling back to Epoch (base 0): 10  Top Validation Acc: 0.9743589743589743
Fold [3/5] Epoch [0/100] Initial Loss: 0.1402, Training Loss: 0.1402, Initial Validation Loss: 0.1280, Validation Loss: 0.1280,V Acc: 0.4182, Top 70th Acc: 0.4286, Bottom 30th Acc: 0.3939
Fold [3/5] Epoch [10/100] Initial Loss: 0.1402, Training Loss: 0.0241, Initial Validation Loss: 0.1280, Validation Loss: 0.0334,V Acc: 0.8273, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.5455
Fold [3/5] Epoch [20/100] Initial Loss: 0.1402, Training Loss: 0.0158, Initial Validation Loss: 0.1280, Validation Loss: 0.0322,V Acc: 0.8273, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 29  Rolling back to Epoch (base 0): 24  Top Validation Acc: 0.948051948051948
35 2 [array([0.8439157 , 0.01769505, 0.01579132, 0.06380267, 0.05879528],
      dtype=float32)]
Fold [4/5] Epoch [0/100] Initial Loss: 0.1296, Training Loss: 0.1296, Initial Validation Loss: 0.1134, Validation Loss: 0.1134,V Acc: 0.4862, Top 70th Acc: 0.5065, Bottom 30th Acc: 0.4375
Fold [4/5] Epoch [10/100] Initial Loss: 0.1296, Training Loss: 0.0292, Initial Validation Loss: 0.1134, Validation Loss: 0.0340,V Acc: 0.7982, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.4688
Fold [4/5] Epoch [20/100] Initial Loss: 0.1296, Training Loss: 0.0190, Initial Validation Loss: 0.1134, Validation Loss: 0.0240,V Acc: 0.8899, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.7500
Stopping early at Epoch (base 0): 28  Rolling back to Epoch (base 0): 23  Top Validation Acc: 0.922077922077922
Fold [5/5] Epoch [0/100] Initial Loss: 0.1273, Training Loss: 0.1273, Initial Validation Loss: 0.1201, Validation Loss: 0.1201,V Acc: 0.4074, Top 70th Acc: 0.5132, Bottom 30th Acc: 0.1562
Fold [5/5] Epoch [10/100] Initial Loss: 0.1273, Training Loss: 0.0268, Initial Validation Loss: 0.1201, Validation Loss: 0.0287,V Acc: 0.9259, Top 70th Acc: 0.9737, Bottom 30th Acc: 0.8125
Fold [5/5] Epoch [20/100] Initial Loss: 0.1273, Training Loss: 0.0174, Initial Validation Loss: 0.1201, Validation Loss: 0.0222,V Acc: 0.9167, Top 70th Acc: 1.0000, Bottom 30th Acc: 0.7188
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.9605263157894737
Running train_nn.py with seed 36
CUDA:False
Training samples count:  550
Training on 21 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1373, Training Loss: 0.1373, Initial Validation Loss: 0.1232, Validation Loss: 0.1232,V Acc: 0.4643, Top 70th Acc: 0.4810, Bottom 30th Acc: 0.4242
Fold [5/5] Epoch [20/100] Initial Loss: 0.1424, Training Loss: 0.0147, Initial Validation Loss: 0.1267, Validation Loss: 0.0261,V Acc: 0.8333, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.5312
Stopping early at Epoch (base 0): 21  Rolling back to Epoch (base 0): 16  Top Validation Acc: 0.9473684210526315
Running train_nn.py with seed 25
CUDA:False
Training samples count:  550
Training on 40 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1382, Training Loss: 0.1382, Initial Validation Loss: 0.1343, Validation Loss: 0.1343,V Acc: 0.2500, Top 70th Acc: 0.2911, Bottom 30th Acc: 0.1515
Fold [1/5] Epoch [10/100] Initial Loss: 0.1382, Training Loss: 0.0278, Initial Validation Loss: 0.1343, Validation Loss: 0.0402,V Acc: 0.8125, Top 70th Acc: 0.9114, Bottom 30th Acc: 0.5758
Fold [1/5] Epoch [20/100] Initial Loss: 0.1382, Training Loss: 0.0155, Initial Validation Loss: 0.1343, Validation Loss: 0.0320,V Acc: 0.8393, Top 70th Acc: 0.9367, Bottom 30th Acc: 0.6061
Fold [1/5] Epoch [30/100] Initial Loss: 0.1382, Training Loss: 0.0124, Initial Validation Loss: 0.1343, Validation Loss: 0.0313,V Acc: 0.8214, Top 70th Acc: 0.9367, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 37  Rolling back to Epoch (base 0): 32  Top Validation Acc: 0.9620253164556962
Fold [2/5] Epoch [0/100] Initial Loss: 0.1380, Training Loss: 0.1380, Initial Validation Loss: 0.1402, Validation Loss: 0.1402,V Acc: 0.2793, Top 70th Acc: 0.3333, Bottom 30th Acc: 0.1515
Fold [2/5] Epoch [10/100] Initial Loss: 0.1380, Training Loss: 0.0387, Initial Validation Loss: 0.1402, Validation Loss: 0.0420,V Acc: 0.8378, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.6061
Fold [2/5] Epoch [20/100] Initial Loss: 0.1380, Training Loss: 0.0169, Initial Validation Loss: 0.1402, Validation Loss: 0.0234,V Acc: 0.9369, Top 70th Acc: 0.9872, Bottom 30th Acc: 0.8182
Fold [2/5] Epoch [30/100] Initial Loss: 0.1380, Training Loss: 0.0140, Initial Validation Loss: 0.1402, Validation Loss: 0.0223,V Acc: 0.9099, Top 70th Acc: 1.0000, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 30  Rolling back to Epoch (base 0): 25  Top Validation Acc: 1.0
Fold [3/5] Epoch [0/100] Initial Loss: 0.1388, Training Loss: 0.1388, Initial Validation Loss: 0.1334, Validation Loss: 0.1334,V Acc: 0.3000, Top 70th Acc: 0.3636, Bottom 30th Acc: 0.1515
Fold [3/5] Epoch [10/100] Initial Loss: 0.1388, Training Loss: 0.0374, Initial Validation Loss: 0.1334, Validation Loss: 0.0349,V Acc: 0.8273, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.5455
Fold [3/5] Epoch [20/100] Initial Loss: 0.1388, Training Loss: 0.0184, Initial Validation Loss: 0.1334, Validation Loss: 0.0254,V Acc: 0.8364, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.5152
Fold [3/5] Epoch [30/100] Initial Loss: 0.1388, Training Loss: 0.0142, Initial Validation Loss: 0.1334, Validation Loss: 0.0247,V Acc: 0.8636, Top 70th Acc: 0.9870, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 35  Rolling back to Epoch (base 0): 30  Top Validation Acc: 0.987012987012987
25 2 [array([0.6870366 , 0.0931382 , 0.03348203, 0.04523285, 0.1411103 ],
      dtype=float32)]
Fold [4/5] Epoch [0/100] Initial Loss: 0.1367, Training Loss: 0.1367, Initial Validation Loss: 0.1272, Validation Loss: 0.1272,V Acc: 0.3853, Top 70th Acc: 0.4545, Bottom 30th Acc: 0.2188
Fold [4/5] Epoch [10/100] Initial Loss: 0.1367, Training Loss: 0.0332, Initial Validation Loss: 0.1272, Validation Loss: 0.0449,V Acc: 0.7615, Top 70th Acc: 0.8961, Bottom 30th Acc: 0.4375
Fold [4/5] Epoch [20/100] Initial Loss: 0.1367, Training Loss: 0.0197, Initial Validation Loss: 0.1272, Validation Loss: 0.0338,V Acc: 0.8257, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.5938
Fold [4/5] Epoch [30/100] Initial Loss: 0.1367, Training Loss: 0.0134, Initial Validation Loss: 0.1272, Validation Loss: 0.0304,V Acc: 0.8532, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6250
Stopping early at Epoch (base 0): 31  Rolling back to Epoch (base 0): 26  Top Validation Acc: 0.948051948051948
Fold [5/5] Epoch [0/100] Initial Loss: 0.1402, Training Loss: 0.1402, Initial Validation Loss: 0.1297, Validation Loss: 0.1297,V Acc: 0.2870, Top 70th Acc: 0.3026, Bottom 30th Acc: 0.2500
Fold [5/5] Epoch [10/100] Initial Loss: 0.1402, Training Loss: 0.0296, Initial Validation Loss: 0.1297, Validation Loss: 0.0504,V Acc: 0.7407, Top 70th Acc: 0.8553, Bottom 30th Acc: 0.4688
Fold [5/5] Epoch [20/100] Initial Loss: 0.1402, Training Loss: 0.0137, Initial Validation Loss: 0.1297, Validation Loss: 0.0421,V Acc: 0.8056, Top 70th Acc: 0.9079, Bottom 30th Acc: 0.5625
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.8947368421052632
Running train_nn.py with seed 26
CUDA:False
Training samples count:  550
Training on 40 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1399, Training Loss: 0.1399, Initial Validation Loss: 0.1340, Validation Loss: 0.1340,V Acc: 0.3393, Top 70th Acc: 0.3797, Bottom 30th Acc: 0.2424
Fold [1/5] Epoch [10/100] Initial Loss: 0.1399, Training Loss: 0.0344, Initial Validation Loss: 0.1340, Validation Loss: 0.0375,V Acc: 0.8125, Top 70th Acc: 0.9620, Bottom 30th Acc: 0.4545
Fold [1/5] Epoch [20/100] Initial Loss: 0.1399, Training Loss: 0.0151, Initial Validation Loss: 0.1340, Validation Loss: 0.0285,V Acc: 0.8393, Top 70th Acc: 0.9873, Bottom 30th Acc: 0.4848
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.9746835443037974
Fold [2/5] Epoch [0/100] Initial Loss: 0.1399, Training Loss: 0.1399, Initial Validation Loss: 0.1376, Validation Loss: 0.1376,V Acc: 0.3423, Top 70th Acc: 0.3718, Bottom 30th Acc: 0.2727
Fold [2/5] Epoch [10/100] Initial Loss: 0.1399, Training Loss: 0.0289, Initial Validation Loss: 0.1376, Validation Loss: 0.0296,V Acc: 0.9009, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.7273
Fold [2/5] Epoch [20/100] Initial Loss: 0.1399, Training Loss: 0.0165, Initial Validation Loss: 0.1376, Validation Loss: 0.0230,V Acc: 0.9009, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.7273
Fold [2/5] Epoch [30/100] Initial Loss: 0.1399, Training Loss: 0.0136, Initial Validation Loss: 0.1376, Validation Loss: 0.0219,V Acc: 0.9189, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.7879
Stopping early at Epoch (base 0): 31  Rolling back to Epoch (base 0): 26  Top Validation Acc: 0.9743589743589743
26 1 [array([0.6367445 , 0.03180495, 0.09383529, 0.09209065, 0.14552458],
      dtype=float32)]
Fold [3/5] Epoch [0/100] Initial Loss: 0.1417, Training Loss: 0.1417, Initial Validation Loss: 0.1335, Validation Loss: 0.1335,V Acc: 0.2727, Top 70th Acc: 0.2987, Bottom 30th Acc: 0.2121
Fold [3/5] Epoch [10/100] Initial Loss: 0.1417, Training Loss: 0.0277, Initial Validation Loss: 0.1335, Validation Loss: 0.0482,V Acc: 0.7455, Top 70th Acc: 0.8571, Bottom 30th Acc: 0.4848
Fold [3/5] Epoch [20/100] Initial Loss: 0.1417, Training Loss: 0.0135, Initial Validation Loss: 0.1335, Validation Loss: 0.0436,V Acc: 0.7727, Top 70th Acc: 0.8831, Bottom 30th Acc: 0.5152
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.8961038961038961
Fold [4/5] Epoch [0/100] Initial Loss: 0.1410, Training Loss: 0.1410, Initial Validation Loss: 0.1316, Validation Loss: 0.1316,V Acc: 0.4312, Top 70th Acc: 0.5195, Bottom 30th Acc: 0.2188
Fold [4/5] Epoch [10/100] Initial Loss: 0.1410, Training Loss: 0.0314, Initial Validation Loss: 0.1316, Validation Loss: 0.0384,V Acc: 0.8257, Top 70th Acc: 0.8961, Bottom 30th Acc: 0.6562
Fold [4/5] Epoch [20/100] Initial Loss: 0.1410, Training Loss: 0.0148, Initial Validation Loss: 0.1316, Validation Loss: 0.0304,V Acc: 0.8257, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.5000
Fold [4/5] Epoch [30/100] Initial Loss: 0.1410, Training Loss: 0.0117, Initial Validation Loss: 0.1316, Validation Loss: 0.0306,V Acc: 0.8257, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.5312
Stopping early at Epoch (base 0): 32  Rolling back to Epoch (base 0): 27  Top Validation Acc: 0.961038961038961
Fold [5/5] Epoch [0/100] Initial Loss: 0.1383, Training Loss: 0.1383, Initial Validation Loss: 0.1303, Validation Loss: 0.1303,V Acc: 0.3333, Top 70th Acc: 0.4079, Bottom 30th Acc: 0.1562
Fold [5/5] Epoch [10/100] Initial Loss: 0.1383, Training Loss: 0.0230, Initial Validation Loss: 0.1303, Validation Loss: 0.0361,V Acc: 0.8148, Top 70th Acc: 0.9211, Bottom 30th Acc: 0.5625
Fold [5/5] Epoch [10/100] Initial Loss: 0.1382, Training Loss: 0.0393, Initial Validation Loss: 0.1312, Validation Loss: 0.0351,V Acc: 0.8981, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.7500
Fold [5/5] Epoch [20/100] Initial Loss: 0.1382, Training Loss: 0.0258, Initial Validation Loss: 0.1312, Validation Loss: 0.0301,V Acc: 0.8519, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.5938
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.9605263157894737
Running train_nn.py with seed 24
CUDA:False
Training samples count:  550
Training on 20 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1366, Training Loss: 0.1366, Initial Validation Loss: 0.1337, Validation Loss: 0.1337,V Acc: 0.4107, Top 70th Acc: 0.5063, Bottom 30th Acc: 0.1818
Fold [1/5] Epoch [10/100] Initial Loss: 0.1366, Training Loss: 0.0436, Initial Validation Loss: 0.1337, Validation Loss: 0.0495,V Acc: 0.7768, Top 70th Acc: 0.8354, Bottom 30th Acc: 0.6364
Fold [1/5] Epoch [20/100] Initial Loss: 0.1366, Training Loss: 0.0253, Initial Validation Loss: 0.1337, Validation Loss: 0.0410,V Acc: 0.8036, Top 70th Acc: 0.8987, Bottom 30th Acc: 0.5758
Fold [1/5] Epoch [30/100] Initial Loss: 0.1366, Training Loss: 0.0224, Initial Validation Loss: 0.1337, Validation Loss: 0.0406,V Acc: 0.8036, Top 70th Acc: 0.8987, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 31  Rolling back to Epoch (base 0): 26  Top Validation Acc: 0.9113924050632911
Fold [2/5] Epoch [0/100] Initial Loss: 0.1429, Training Loss: 0.1429, Initial Validation Loss: 0.1360, Validation Loss: 0.1360,V Acc: 0.2523, Top 70th Acc: 0.2821, Bottom 30th Acc: 0.1818
Fold [2/5] Epoch [10/100] Initial Loss: 0.1429, Training Loss: 0.0423, Initial Validation Loss: 0.1360, Validation Loss: 0.0441,V Acc: 0.8198, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.6061
Fold [2/5] Epoch [20/100] Initial Loss: 0.1429, Training Loss: 0.0258, Initial Validation Loss: 0.1360, Validation Loss: 0.0331,V Acc: 0.8198, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.9102564102564102
Fold [3/5] Epoch [0/100] Initial Loss: 0.1374, Training Loss: 0.1374, Initial Validation Loss: 0.1297, Validation Loss: 0.1297,V Acc: 0.3727, Top 70th Acc: 0.4416, Bottom 30th Acc: 0.2121
Fold [3/5] Epoch [10/100] Initial Loss: 0.1374, Training Loss: 0.0344, Initial Validation Loss: 0.1297, Validation Loss: 0.0385,V Acc: 0.8545, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.6970
Fold [3/5] Epoch [20/100] Initial Loss: 0.1374, Training Loss: 0.0238, Initial Validation Loss: 0.1297, Validation Loss: 0.0328,V Acc: 0.8727, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.922077922077922
24 2 [array([0.44763476, 0.11870125, 0.10042644, 0.1357115 , 0.19752608],
      dtype=float32)]
Fold [4/5] Epoch [0/100] Initial Loss: 0.1377, Training Loss: 0.1377, Initial Validation Loss: 0.1354, Validation Loss: 0.1354,V Acc: 0.2844, Top 70th Acc: 0.3377, Bottom 30th Acc: 0.1562
Fold [4/5] Epoch [10/100] Initial Loss: 0.1377, Training Loss: 0.0369, Initial Validation Loss: 0.1354, Validation Loss: 0.0438,V Acc: 0.8165, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.5938
Fold [4/5] Epoch [20/100] Initial Loss: 0.1377, Training Loss: 0.0251, Initial Validation Loss: 0.1354, Validation Loss: 0.0370,V Acc: 0.8073, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.5000
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.948051948051948
Fold [5/5] Epoch [0/100] Initial Loss: 0.1397, Training Loss: 0.1397, Initial Validation Loss: 0.1285, Validation Loss: 0.1285,V Acc: 0.2685, Top 70th Acc: 0.3421, Bottom 30th Acc: 0.0938
Fold [5/5] Epoch [10/100] Initial Loss: 0.1397, Training Loss: 0.0521, Initial Validation Loss: 0.1285, Validation Loss: 0.0461,V Acc: 0.7685, Top 70th Acc: 0.8684, Bottom 30th Acc: 0.5312
Fold [5/5] Epoch [20/100] Initial Loss: 0.1397, Training Loss: 0.0276, Initial Validation Loss: 0.1285, Validation Loss: 0.0268,V Acc: 0.8611, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.6875
Stopping early at Epoch (base 0): 27  Rolling back to Epoch (base 0): 22  Top Validation Acc: 0.9342105263157895
Running train_nn.py with seed 25
CUDA:False
Training samples count:  550
Training on 20 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1432, Training Loss: 0.1432, Initial Validation Loss: 0.1379, Validation Loss: 0.1379,V Acc: 0.2411, Top 70th Acc: 0.2785, Bottom 30th Acc: 0.1515
Fold [1/5] Epoch [10/100] Initial Loss: 0.1432, Training Loss: 0.0389, Initial Validation Loss: 0.1379, Validation Loss: 0.0469,V Acc: 0.7857, Top 70th Acc: 0.8608, Bottom 30th Acc: 0.6061
Fold [1/5] Epoch [20/100] Initial Loss: 0.1432, Training Loss: 0.0242, Initial Validation Loss: 0.1379, Validation Loss: 0.0350,V Acc: 0.8125, Top 70th Acc: 0.9241, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.9367088607594937
Fold [2/5] Epoch [0/100] Initial Loss: 0.1355, Training Loss: 0.1355, Initial Validation Loss: 0.1372, Validation Loss: 0.1372,V Acc: 0.2883, Top 70th Acc: 0.3462, Bottom 30th Acc: 0.1515
Fold [2/5] Epoch [10/100] Initial Loss: 0.1355, Training Loss: 0.0338, Initial Validation Loss: 0.1372, Validation Loss: 0.0345,V Acc: 0.9099, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.7879
Fold [2/5] Epoch [20/100] Initial Loss: 0.1355, Training Loss: 0.0255, Initial Validation Loss: 0.1372, Validation Loss: 0.0283,V Acc: 0.9099, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.7879
Stopping early at Epoch (base 0): 29  Rolling back to Epoch (base 0): 24  Top Validation Acc: 0.9615384615384616
Fold [3/5] Epoch [0/100] Initial Loss: 0.1390, Training Loss: 0.1390, Initial Validation Loss: 0.1335, Validation Loss: 0.1335,V Acc: 0.3364, Top 70th Acc: 0.4026, Bottom 30th Acc: 0.1818
Fold [3/5] Epoch [10/100] Initial Loss: 0.1390, Training Loss: 0.0356, Initial Validation Loss: 0.1335, Validation Loss: 0.0338,V Acc: 0.8455, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 18  Rolling back to Epoch (base 0): 13  Top Validation Acc: 0.948051948051948
25 2 [array([0.30492803, 0.13594893, 0.10643531, 0.2216215 , 0.23106617],
      dtype=float32)]
Fold [4/5] Epoch [0/100] Initial Loss: 0.1417, Training Loss: 0.1417, Initial Validation Loss: 0.1312, Validation Loss: 0.1312,V Acc: 0.3028, Top 70th Acc: 0.3247, Bottom 30th Acc: 0.2500
Fold [4/5] Epoch [10/100] Initial Loss: 0.1417, Training Loss: 0.0312, Initial Validation Loss: 0.1312, Validation Loss: 0.0384,V Acc: 0.8165, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.5625
Fold [4/5] Epoch [20/100] Initial Loss: 0.1417, Training Loss: 0.0237, Initial Validation Loss: 0.1312, Validation Loss: 0.0345,V Acc: 0.8073, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.5000
Fold [4/5] Epoch [30/100] Initial Loss: 0.1417, Training Loss: 0.0218, Initial Validation Loss: 0.1312, Validation Loss: 0.0347,V Acc: 0.8165, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.5625
Stopping early at Epoch (base 0): 30  Rolling back to Epoch (base 0): 25  Top Validation Acc: 0.922077922077922
Fold [5/5] Epoch [0/100] Initial Loss: 0.1415, Training Loss: 0.1415, Initial Validation Loss: 0.1290, Validation Loss: 0.1290,V Acc: 0.2963, Top 70th Acc: 0.3289, Bottom 30th Acc: 0.2188
Fold [5/5] Epoch [10/100] Initial Loss: 0.1415, Training Loss: 0.0449, Initial Validation Loss: 0.1290, Validation Loss: 0.0556,V Acc: 0.7407, Top 70th Acc: 0.8553, Bottom 30th Acc: 0.4688
Fold [5/5] Epoch [20/100] Initial Loss: 0.1415, Training Loss: 0.0235, Initial Validation Loss: 0.1290, Validation Loss: 0.0420,V Acc: 0.7778, Top 70th Acc: 0.8947, Bottom 30th Acc: 0.5000
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.8947368421052632
Running train_nn.py with seed 26
CUDA:False
Training samples count:  550
Training on 20 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1417, Training Loss: 0.1417, Initial Validation Loss: 0.1360, Validation Loss: 0.1360,V Acc: 0.2500, Top 70th Acc: 0.2911, Bottom 30th Acc: 0.1515
Fold [1/5] Epoch [10/100] Initial Loss: 0.1417, Training Loss: 0.0364, Initial Validation Loss: 0.1360, Validation Loss: 0.0369,V Acc: 0.8036, Top 70th Acc: 0.9241, Bottom 30th Acc: 0.5152
Fold [2/5] Epoch [10/100] Initial Loss: 0.1404, Training Loss: 0.0130, Initial Validation Loss: 0.1296, Validation Loss: 0.0313,V Acc: 0.8018, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.4848
Fold [2/5] Epoch [20/100] Initial Loss: 0.1404, Training Loss: 0.0046, Initial Validation Loss: 0.1296, Validation Loss: 0.0283,V Acc: 0.8288, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.5758
Fold [2/5] Epoch [30/100] Initial Loss: 0.1404, Training Loss: 0.0038, Initial Validation Loss: 0.1296, Validation Loss: 0.0282,V Acc: 0.8378, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 34  Rolling back to Epoch (base 0): 29  Top Validation Acc: 0.9487179487179487
19 1 [array([0.27423868, 0.0691435 , 0.04901369, 0.18281342, 0.42479074],
      dtype=float32)]
Fold [3/5] Epoch [0/100] Initial Loss: 0.1440, Training Loss: 0.1440, Initial Validation Loss: 0.1334, Validation Loss: 0.1334,V Acc: 0.2818, Top 70th Acc: 0.3247, Bottom 30th Acc: 0.1818
Fold [3/5] Epoch [10/100] Initial Loss: 0.1440, Training Loss: 0.0132, Initial Validation Loss: 0.1334, Validation Loss: 0.0336,V Acc: 0.8364, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.5758
Fold [3/5] Epoch [20/100] Initial Loss: 0.1440, Training Loss: 0.0052, Initial Validation Loss: 0.1334, Validation Loss: 0.0304,V Acc: 0.8273, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.5152
Stopping early at Epoch (base 0): 29  Rolling back to Epoch (base 0): 24  Top Validation Acc: 0.987012987012987
Fold [4/5] Epoch [0/100] Initial Loss: 0.1409, Training Loss: 0.1409, Initial Validation Loss: 0.1351, Validation Loss: 0.1351,V Acc: 0.2477, Top 70th Acc: 0.3117, Bottom 30th Acc: 0.0938
Fold [4/5] Epoch [10/100] Initial Loss: 0.1409, Training Loss: 0.0256, Initial Validation Loss: 0.1351, Validation Loss: 0.0428,V Acc: 0.8073, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.5625
Fold [4/5] Epoch [20/100] Initial Loss: 0.1409, Training Loss: 0.0054, Initial Validation Loss: 0.1351, Validation Loss: 0.0300,V Acc: 0.8807, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.7500
Fold [4/5] Epoch [30/100] Initial Loss: 0.1409, Training Loss: 0.0039, Initial Validation Loss: 0.1351, Validation Loss: 0.0291,V Acc: 0.8716, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.7188
Stopping early at Epoch (base 0): 34  Rolling back to Epoch (base 0): 29  Top Validation Acc: 0.948051948051948
Fold [5/5] Epoch [0/100] Initial Loss: 0.1400, Training Loss: 0.1400, Initial Validation Loss: 0.1337, Validation Loss: 0.1337,V Acc: 0.2685, Top 70th Acc: 0.3158, Bottom 30th Acc: 0.1562
Fold [5/5] Epoch [10/100] Initial Loss: 0.1400, Training Loss: 0.0167, Initial Validation Loss: 0.1337, Validation Loss: 0.0342,V Acc: 0.8056, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.5000
Fold [5/5] Epoch [20/100] Initial Loss: 0.1400, Training Loss: 0.0048, Initial Validation Loss: 0.1337, Validation Loss: 0.0322,V Acc: 0.8333, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.5938
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.9342105263157895
Running train_nn.py with seed 20
CUDA:False
Training samples count:  550
Training on 162 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1393, Training Loss: 0.1393, Initial Validation Loss: 0.1331, Validation Loss: 0.1331,V Acc: 0.3304, Top 70th Acc: 0.3671, Bottom 30th Acc: 0.2424
Fold [1/5] Epoch [10/100] Initial Loss: 0.1393, Training Loss: 0.0241, Initial Validation Loss: 0.1331, Validation Loss: 0.0402,V Acc: 0.8036, Top 70th Acc: 0.8734, Bottom 30th Acc: 0.6364
Fold [1/5] Epoch [20/100] Initial Loss: 0.1393, Training Loss: 0.0061, Initial Validation Loss: 0.1331, Validation Loss: 0.0288,V Acc: 0.8482, Top 70th Acc: 0.9494, Bottom 30th Acc: 0.6061
Fold [1/5] Epoch [30/100] Initial Loss: 0.1393, Training Loss: 0.0044, Initial Validation Loss: 0.1331, Validation Loss: 0.0294,V Acc: 0.8393, Top 70th Acc: 0.9241, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 33  Rolling back to Epoch (base 0): 28  Top Validation Acc: 0.9367088607594937
20 0 [array([0.36093643, 0.07927075, 0.05377019, 0.1531707 , 0.3528519 ],
      dtype=float32)]
Fold [2/5] Epoch [0/100] Initial Loss: 0.1393, Training Loss: 0.1393, Initial Validation Loss: 0.1361, Validation Loss: 0.1361,V Acc: 0.3604, Top 70th Acc: 0.3590, Bottom 30th Acc: 0.3636
Fold [2/5] Epoch [10/100] Initial Loss: 0.1393, Training Loss: 0.0198, Initial Validation Loss: 0.1361, Validation Loss: 0.0363,V Acc: 0.8559, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.6970
Fold [2/5] Epoch [20/100] Initial Loss: 0.1393, Training Loss: 0.0049, Initial Validation Loss: 0.1361, Validation Loss: 0.0279,V Acc: 0.9009, Top 70th Acc: 0.9872, Bottom 30th Acc: 0.6970
Fold [2/5] Epoch [30/100] Initial Loss: 0.1393, Training Loss: 0.0035, Initial Validation Loss: 0.1361, Validation Loss: 0.0264,V Acc: 0.9099, Top 70th Acc: 0.9872, Bottom 30th Acc: 0.7273
Stopping early at Epoch (base 0): 35  Rolling back to Epoch (base 0): 30  Top Validation Acc: 0.9743589743589743
Fold [3/5] Epoch [0/100] Initial Loss: 0.1398, Training Loss: 0.1398, Initial Validation Loss: 0.1318, Validation Loss: 0.1318,V Acc: 0.2545, Top 70th Acc: 0.3636, Bottom 30th Acc: 0.0000
Fold [3/5] Epoch [10/100] Initial Loss: 0.1398, Training Loss: 0.0234, Initial Validation Loss: 0.1318, Validation Loss: 0.0358,V Acc: 0.8636, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6667
Fold [3/5] Epoch [20/100] Initial Loss: 0.1398, Training Loss: 0.0062, Initial Validation Loss: 0.1318, Validation Loss: 0.0311,V Acc: 0.8273, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.5152
Fold [3/5] Epoch [30/100] Initial Loss: 0.1398, Training Loss: 0.0046, Initial Validation Loss: 0.1318, Validation Loss: 0.0301,V Acc: 0.8364, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.5152
Stopping early at Epoch (base 0): 35  Rolling back to Epoch (base 0): 30  Top Validation Acc: 0.961038961038961
Fold [4/5] Epoch [0/100] Initial Loss: 0.1398, Training Loss: 0.1398, Initial Validation Loss: 0.1299, Validation Loss: 0.1299,V Acc: 0.2477, Top 70th Acc: 0.3506, Bottom 30th Acc: 0.0000
Fold [4/5] Epoch [10/100] Initial Loss: 0.1398, Training Loss: 0.0150, Initial Validation Loss: 0.1299, Validation Loss: 0.0399,V Acc: 0.7890, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.4375
Fold [4/5] Epoch [20/100] Initial Loss: 0.1398, Training Loss: 0.0051, Initial Validation Loss: 0.1299, Validation Loss: 0.0332,V Acc: 0.8349, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.5938
Fold [4/5] Epoch [30/100] Initial Loss: 0.1398, Training Loss: 0.0041, Initial Validation Loss: 0.1299, Validation Loss: 0.0328,V Acc: 0.8257, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.5625
Stopping early at Epoch (base 0): 32  Rolling back to Epoch (base 0): 27  Top Validation Acc: 0.935064935064935
Fold [5/5] Epoch [0/100] Initial Loss: 0.1397, Training Loss: 0.1397, Initial Validation Loss: 0.1349, Validation Loss: 0.1349,V Acc: 0.2500, Top 70th Acc: 0.2895, Bottom 30th Acc: 0.1562
Fold [5/5] Epoch [10/100] Initial Loss: 0.1397, Training Loss: 0.0191, Initial Validation Loss: 0.1349, Validation Loss: 0.0365,V Acc: 0.8241, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.5000
Fold [5/5] Epoch [20/100] Initial Loss: 0.1397, Training Loss: 0.0054, Initial Validation Loss: 0.1349, Validation Loss: 0.0316,V Acc: 0.8426, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.6250
Stopping early at Epoch (base 0): 22  Rolling back to Epoch (base 0): 17  Top Validation Acc: 0.9473684210526315
Running train_nn.py with seed 21
CUDA:False
Training samples count:  550
Training on 162 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1392, Training Loss: 0.1392, Initial Validation Loss: 0.1336, Validation Loss: 0.1336,V Acc: 0.3661, Top 70th Acc: 0.4304, Bottom 30th Acc: 0.2121
Fold [1/5] Epoch [10/100] Initial Loss: 0.1392, Training Loss: 0.0207, Initial Validation Loss: 0.1336, Validation Loss: 0.0413,V Acc: 0.8036, Top 70th Acc: 0.9114, Bottom 30th Acc: 0.5455
Fold [1/5] Epoch [20/100] Initial Loss: 0.1392, Training Loss: 0.0049, Initial Validation Loss: 0.1336, Validation Loss: 0.0338,V Acc: 0.8393, Top 70th Acc: 0.9494, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 27  Rolling back to Epoch (base 0): 22  Top Validation Acc: 0.9367088607594937
21 0 [array([0.1870093 , 0.02745715, 0.02977708, 0.1506118 , 0.6051447 ],
      dtype=float32)]
Fold [2/5] Epoch [10/100] Initial Loss: 0.1363, Training Loss: 0.0799, Initial Validation Loss: 0.1354, Validation Loss: 0.0812,V Acc: 0.6126, Top 70th Acc: 0.7436, Bottom 30th Acc: 0.3030
Fold [2/5] Epoch [20/100] Initial Loss: 0.1363, Training Loss: 0.0776, Initial Validation Loss: 0.1354, Validation Loss: 0.0792,V Acc: 0.6036, Top 70th Acc: 0.7436, Bottom 30th Acc: 0.2727
Fold [2/5] Epoch [30/100] Initial Loss: 0.1363, Training Loss: 0.0765, Initial Validation Loss: 0.1354, Validation Loss: 0.0786,V Acc: 0.6126, Top 70th Acc: 0.7436, Bottom 30th Acc: 0.3030
Fold [2/5] Epoch [40/100] Initial Loss: 0.1363, Training Loss: 0.0760, Initial Validation Loss: 0.1354, Validation Loss: 0.0782,V Acc: 0.6216, Top 70th Acc: 0.7436, Bottom 30th Acc: 0.3333
Fold [2/5] Epoch [50/100] Initial Loss: 0.1363, Training Loss: 0.0758, Initial Validation Loss: 0.1354, Validation Loss: 0.0780,V Acc: 0.6216, Top 70th Acc: 0.7436, Bottom 30th Acc: 0.3333
Stopping early at Epoch (base 0): 50  Rolling back to Epoch (base 0): 45  Top Validation Acc: 0.7435897435897436
Fold [3/5] Epoch [0/100] Initial Loss: 0.1409, Training Loss: 0.1409, Initial Validation Loss: 0.1290, Validation Loss: 0.1290,V Acc: 0.4545, Top 70th Acc: 0.5195, Bottom 30th Acc: 0.3030
Fold [3/5] Epoch [10/100] Initial Loss: 0.1409, Training Loss: 0.0817, Initial Validation Loss: 0.1290, Validation Loss: 0.0756,V Acc: 0.6636, Top 70th Acc: 0.7662, Bottom 30th Acc: 0.4242
Fold [3/5] Epoch [20/100] Initial Loss: 0.1409, Training Loss: 0.0802, Initial Validation Loss: 0.1290, Validation Loss: 0.0736,V Acc: 0.6727, Top 70th Acc: 0.7792, Bottom 30th Acc: 0.4242
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.7792207792207793
25 2 [array([0.11957145, 0.38675582, 0.13202983, 0.20841053, 0.15323232],
      dtype=float32)]
Fold [4/5] Epoch [0/100] Initial Loss: 0.1379, Training Loss: 0.1379, Initial Validation Loss: 0.1222, Validation Loss: 0.1222,V Acc: 0.3945, Top 70th Acc: 0.4805, Bottom 30th Acc: 0.1875
Fold [4/5] Epoch [10/100] Initial Loss: 0.1379, Training Loss: 0.0810, Initial Validation Loss: 0.1222, Validation Loss: 0.0772,V Acc: 0.6147, Top 70th Acc: 0.7273, Bottom 30th Acc: 0.3438
Fold [4/5] Epoch [20/100] Initial Loss: 0.1379, Training Loss: 0.0785, Initial Validation Loss: 0.1222, Validation Loss: 0.0737,V Acc: 0.6330, Top 70th Acc: 0.7662, Bottom 30th Acc: 0.3125
Fold [4/5] Epoch [30/100] Initial Loss: 0.1379, Training Loss: 0.0777, Initial Validation Loss: 0.1222, Validation Loss: 0.0733,V Acc: 0.6330, Top 70th Acc: 0.7532, Bottom 30th Acc: 0.3438
Stopping early at Epoch (base 0): 30  Rolling back to Epoch (base 0): 25  Top Validation Acc: 0.7532467532467533
Fold [5/5] Epoch [0/100] Initial Loss: 0.1334, Training Loss: 0.1334, Initial Validation Loss: 0.1196, Validation Loss: 0.1196,V Acc: 0.5463, Top 70th Acc: 0.6184, Bottom 30th Acc: 0.3750
Fold [5/5] Epoch [10/100] Initial Loss: 0.1334, Training Loss: 0.0786, Initial Validation Loss: 0.1196, Validation Loss: 0.0852,V Acc: 0.5648, Top 70th Acc: 0.6842, Bottom 30th Acc: 0.2812
Fold [5/5] Epoch [20/100] Initial Loss: 0.1334, Training Loss: 0.0765, Initial Validation Loss: 0.1196, Validation Loss: 0.0844,V Acc: 0.5741, Top 70th Acc: 0.6842, Bottom 30th Acc: 0.3125
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.6842105263157895
Running train_nn.py with seed 26
CUDA:False
Training samples count:  550
Training on 2 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1383, Training Loss: 0.1383, Initial Validation Loss: 0.1275, Validation Loss: 0.1275,V Acc: 0.3125, Top 70th Acc: 0.3797, Bottom 30th Acc: 0.1515
Fold [1/5] Epoch [10/100] Initial Loss: 0.1383, Training Loss: 0.0810, Initial Validation Loss: 0.1275, Validation Loss: 0.0833,V Acc: 0.5804, Top 70th Acc: 0.7215, Bottom 30th Acc: 0.2424
Fold [1/5] Epoch [20/100] Initial Loss: 0.1383, Training Loss: 0.0792, Initial Validation Loss: 0.1275, Validation Loss: 0.0817,V Acc: 0.5804, Top 70th Acc: 0.7089, Bottom 30th Acc: 0.2727
Fold [1/5] Epoch [30/100] Initial Loss: 0.1383, Training Loss: 0.0787, Initial Validation Loss: 0.1275, Validation Loss: 0.0808,V Acc: 0.5804, Top 70th Acc: 0.7215, Bottom 30th Acc: 0.2424
Fold [1/5] Epoch [40/100] Initial Loss: 0.1383, Training Loss: 0.0781, Initial Validation Loss: 0.1275, Validation Loss: 0.0829,V Acc: 0.5893, Top 70th Acc: 0.7089, Bottom 30th Acc: 0.3030
Stopping early at Epoch (base 0): 40  Rolling back to Epoch (base 0): 35  Top Validation Acc: 0.7088607594936709
Fold [2/5] Epoch [0/100] Initial Loss: 0.1303, Training Loss: 0.1303, Initial Validation Loss: 0.1208, Validation Loss: 0.1208,V Acc: 0.4414, Top 70th Acc: 0.5769, Bottom 30th Acc: 0.1212
Fold [2/5] Epoch [10/100] Initial Loss: 0.1303, Training Loss: 0.0823, Initial Validation Loss: 0.1208, Validation Loss: 0.0734,V Acc: 0.6847, Top 70th Acc: 0.8462, Bottom 30th Acc: 0.3030
Fold [2/5] Epoch [20/100] Initial Loss: 0.1303, Training Loss: 0.0812, Initial Validation Loss: 0.1208, Validation Loss: 0.0705,V Acc: 0.7117, Top 70th Acc: 0.8718, Bottom 30th Acc: 0.3333
Fold [2/5] Epoch [30/100] Initial Loss: 0.1303, Training Loss: 0.0808, Initial Validation Loss: 0.1208, Validation Loss: 0.0689,V Acc: 0.7117, Top 70th Acc: 0.8590, Bottom 30th Acc: 0.3636
Stopping early at Epoch (base 0): 38  Rolling back to Epoch (base 0): 33  Top Validation Acc: 0.8717948717948718
26 1 [array([0.11538699, 0.37027168, 0.16397016, 0.19260958, 0.15776159],
      dtype=float32)]
Fold [3/5] Epoch [0/100] Initial Loss: 0.1369, Training Loss: 0.1369, Initial Validation Loss: 0.1305, Validation Loss: 0.1305,V Acc: 0.3273, Top 70th Acc: 0.4156, Bottom 30th Acc: 0.1212
Fold [3/5] Epoch [10/100] Initial Loss: 0.1369, Training Loss: 0.0770, Initial Validation Loss: 0.1305, Validation Loss: 0.0937,V Acc: 0.5091, Top 70th Acc: 0.6234, Bottom 30th Acc: 0.2424
Stopping early at Epoch (base 0): 16  Rolling back to Epoch (base 0): 11  Top Validation Acc: 0.6493506493506493
Fold [4/5] Epoch [0/100] Initial Loss: 0.1368, Training Loss: 0.1368, Initial Validation Loss: 0.1280, Validation Loss: 0.1280,V Acc: 0.3486, Top 70th Acc: 0.3766, Bottom 30th Acc: 0.2812
Fold [4/5] Epoch [10/100] Initial Loss: 0.1368, Training Loss: 0.0808, Initial Validation Loss: 0.1280, Validation Loss: 0.0759,V Acc: 0.6514, Top 70th Acc: 0.7403, Bottom 30th Acc: 0.4375
Fold [4/5] Epoch [20/100] Initial Loss: 0.1368, Training Loss: 0.0794, Initial Validation Loss: 0.1280, Validation Loss: 0.0748,V Acc: 0.6514, Top 70th Acc: 0.7662, Bottom 30th Acc: 0.3750
Fold [4/5] Epoch [30/100] Initial Loss: 0.1368, Training Loss: 0.0792, Initial Validation Loss: 0.1280, Validation Loss: 0.0743,V Acc: 0.6514, Top 70th Acc: 0.7662, Bottom 30th Acc: 0.3750
Stopping early at Epoch (base 0): 38  Rolling back to Epoch (base 0): 33  Top Validation Acc: 0.7532467532467533
Fold [5/5] Epoch [0/100] Initial Loss: 0.1343, Training Loss: 0.1343, Initial Validation Loss: 0.1225, Validation Loss: 0.1225,V Acc: 0.5093, Top 70th Acc: 0.5263, Bottom 30th Acc: 0.4688
Fold [5/5] Epoch [10/100] Initial Loss: 0.1343, Training Loss: 0.0804, Initial Validation Loss: 0.1225, Validation Loss: 0.0732,V Acc: 0.6667, Top 70th Acc: 0.7368, Bottom 30th Acc: 0.5000
Stopping early at Epoch (base 0): 14  Rolling back to Epoch (base 0): 9  Top Validation Acc: 0.7368421052631579
Running train_nn.py with seed 27
CUDA:False
Training samples count:  550
Training on 2 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1387, Training Loss: 0.1387, Initial Validation Loss: 0.1279, Validation Loss: 0.1279,V Acc: 0.3929, Top 70th Acc: 0.5443, Bottom 30th Acc: 0.0303
Fold [1/5] Epoch [10/100] Initial Loss: 0.1387, Training Loss: 0.0800, Initial Validation Loss: 0.1279, Validation Loss: 0.0833,V Acc: 0.6071, Top 70th Acc: 0.6962, Bottom 30th Acc: 0.3939
Fold [1/5] Epoch [20/100] Initial Loss: 0.1387, Training Loss: 0.0777, Initial Validation Loss: 0.1279, Validation Loss: 0.0812,V Acc: 0.5982, Top 70th Acc: 0.6962, Bottom 30th Acc: 0.3636
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.6962025316455697
Fold [2/5] Epoch [0/100] Initial Loss: 0.1376, Training Loss: 0.1376, Initial Validation Loss: 0.1303, Validation Loss: 0.1303,V Acc: 0.4414, Top 70th Acc: 0.5385, Bottom 30th Acc: 0.2121
Fold [5/5] Epoch [20/100] Initial Loss: 0.1383, Training Loss: 0.0128, Initial Validation Loss: 0.1303, Validation Loss: 0.0356,V Acc: 0.8056, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.5000
Stopping early at Epoch (base 0): 21  Rolling back to Epoch (base 0): 16  Top Validation Acc: 0.9078947368421053
Running train_nn.py with seed 27
CUDA:False
Training samples count:  550
Training on 40 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1394, Training Loss: 0.1394, Initial Validation Loss: 0.1342, Validation Loss: 0.1342,V Acc: 0.3929, Top 70th Acc: 0.4557, Bottom 30th Acc: 0.2424
Fold [1/5] Epoch [10/100] Initial Loss: 0.1394, Training Loss: 0.0347, Initial Validation Loss: 0.1342, Validation Loss: 0.0528,V Acc: 0.7143, Top 70th Acc: 0.8354, Bottom 30th Acc: 0.4242
Fold [1/5] Epoch [20/100] Initial Loss: 0.1394, Training Loss: 0.0142, Initial Validation Loss: 0.1342, Validation Loss: 0.0364,V Acc: 0.7946, Top 70th Acc: 0.9494, Bottom 30th Acc: 0.4242
Stopping early at Epoch (base 0): 27  Rolling back to Epoch (base 0): 22  Top Validation Acc: 0.9493670886075949
Fold [2/5] Epoch [0/100] Initial Loss: 0.1405, Training Loss: 0.1405, Initial Validation Loss: 0.1331, Validation Loss: 0.1331,V Acc: 0.3153, Top 70th Acc: 0.3718, Bottom 30th Acc: 0.1818
Fold [2/5] Epoch [10/100] Initial Loss: 0.1405, Training Loss: 0.0355, Initial Validation Loss: 0.1331, Validation Loss: 0.0376,V Acc: 0.8288, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.6061
Fold [2/5] Epoch [20/100] Initial Loss: 0.1405, Training Loss: 0.0162, Initial Validation Loss: 0.1331, Validation Loss: 0.0238,V Acc: 0.8739, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.6364
Fold [2/5] Epoch [30/100] Initial Loss: 0.1405, Training Loss: 0.0130, Initial Validation Loss: 0.1331, Validation Loss: 0.0222,V Acc: 0.9099, Top 70th Acc: 0.9872, Bottom 30th Acc: 0.7273
Fold [2/5] Epoch [40/100] Initial Loss: 0.1405, Training Loss: 0.0115, Initial Validation Loss: 0.1331, Validation Loss: 0.0219,V Acc: 0.9009, Top 70th Acc: 0.9872, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 44  Rolling back to Epoch (base 0): 39  Top Validation Acc: 0.9871794871794872
27 1 [array([0.7435421 , 0.03487903, 0.02568683, 0.08974699, 0.10614511],
      dtype=float32)]
Fold [3/5] Epoch [0/100] Initial Loss: 0.1406, Training Loss: 0.1406, Initial Validation Loss: 0.1372, Validation Loss: 0.1372,V Acc: 0.2636, Top 70th Acc: 0.2987, Bottom 30th Acc: 0.1818
Fold [3/5] Epoch [10/100] Initial Loss: 0.1406, Training Loss: 0.0333, Initial Validation Loss: 0.1372, Validation Loss: 0.0396,V Acc: 0.8273, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.6061
Fold [3/5] Epoch [20/100] Initial Loss: 0.1406, Training Loss: 0.0178, Initial Validation Loss: 0.1372, Validation Loss: 0.0299,V Acc: 0.8455, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.5758
Fold [3/5] Epoch [30/100] Initial Loss: 0.1406, Training Loss: 0.0143, Initial Validation Loss: 0.1372, Validation Loss: 0.0299,V Acc: 0.8455, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 32  Rolling back to Epoch (base 0): 27  Top Validation Acc: 0.935064935064935
Fold [4/5] Epoch [0/100] Initial Loss: 0.1385, Training Loss: 0.1385, Initial Validation Loss: 0.1343, Validation Loss: 0.1343,V Acc: 0.2477, Top 70th Acc: 0.3377, Bottom 30th Acc: 0.0312
Fold [4/5] Epoch [10/100] Initial Loss: 0.1385, Training Loss: 0.0375, Initial Validation Loss: 0.1343, Validation Loss: 0.0411,V Acc: 0.8440, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.6250
Fold [4/5] Epoch [20/100] Initial Loss: 0.1385, Training Loss: 0.0159, Initial Validation Loss: 0.1343, Validation Loss: 0.0302,V Acc: 0.8349, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.5625
Fold [4/5] Epoch [30/100] Initial Loss: 0.1385, Training Loss: 0.0129, Initial Validation Loss: 0.1343, Validation Loss: 0.0305,V Acc: 0.8257, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.5312
Stopping early at Epoch (base 0): 33  Rolling back to Epoch (base 0): 28  Top Validation Acc: 0.948051948051948
Fold [5/5] Epoch [0/100] Initial Loss: 0.1404, Training Loss: 0.1404, Initial Validation Loss: 0.1318, Validation Loss: 0.1318,V Acc: 0.3148, Top 70th Acc: 0.3684, Bottom 30th Acc: 0.1875
Fold [5/5] Epoch [10/100] Initial Loss: 0.1404, Training Loss: 0.0353, Initial Validation Loss: 0.1318, Validation Loss: 0.0478,V Acc: 0.7500, Top 70th Acc: 0.9079, Bottom 30th Acc: 0.3750
Fold [5/5] Epoch [20/100] Initial Loss: 0.1404, Training Loss: 0.0137, Initial Validation Loss: 0.1318, Validation Loss: 0.0397,V Acc: 0.7778, Top 70th Acc: 0.8947, Bottom 30th Acc: 0.5000
Fold [5/5] Epoch [30/100] Initial Loss: 0.1404, Training Loss: 0.0105, Initial Validation Loss: 0.1318, Validation Loss: 0.0380,V Acc: 0.8148, Top 70th Acc: 0.9079, Bottom 30th Acc: 0.5938
Stopping early at Epoch (base 0): 35  Rolling back to Epoch (base 0): 30  Top Validation Acc: 0.8947368421052632
Running train_nn.py with seed 28
CUDA:False
Training samples count:  550
Training on 40 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1377, Training Loss: 0.1377, Initial Validation Loss: 0.1364, Validation Loss: 0.1364,V Acc: 0.2679, Top 70th Acc: 0.3291, Bottom 30th Acc: 0.1212
Fold [1/5] Epoch [10/100] Initial Loss: 0.1377, Training Loss: 0.0294, Initial Validation Loss: 0.1364, Validation Loss: 0.0470,V Acc: 0.7768, Top 70th Acc: 0.8861, Bottom 30th Acc: 0.5152
Fold [1/5] Epoch [20/100] Initial Loss: 0.1377, Training Loss: 0.0140, Initial Validation Loss: 0.1364, Validation Loss: 0.0382,V Acc: 0.8214, Top 70th Acc: 0.9241, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.9367088607594937
Fold [2/5] Epoch [0/100] Initial Loss: 0.1386, Training Loss: 0.1386, Initial Validation Loss: 0.1260, Validation Loss: 0.1260,V Acc: 0.2793, Top 70th Acc: 0.3590, Bottom 30th Acc: 0.0909
Fold [2/5] Epoch [10/100] Initial Loss: 0.1386, Training Loss: 0.0385, Initial Validation Loss: 0.1260, Validation Loss: 0.0474,V Acc: 0.7568, Top 70th Acc: 0.8333, Bottom 30th Acc: 0.5758
Fold [2/5] Epoch [20/100] Initial Loss: 0.1386, Training Loss: 0.0138, Initial Validation Loss: 0.1260, Validation Loss: 0.0336,V Acc: 0.8018, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.9230769230769231
28 1 [array([0.7257637 , 0.02135475, 0.0350128 , 0.10953935, 0.10832941],
      dtype=float32)]
Fold [3/5] Epoch [0/100] Initial Loss: 0.1392, Training Loss: 0.1392, Initial Validation Loss: 0.1349, Validation Loss: 0.1349,V Acc: 0.3545, Top 70th Acc: 0.4026, Bottom 30th Acc: 0.2424
Fold [3/5] Epoch [10/100] Initial Loss: 0.1392, Training Loss: 0.0293, Initial Validation Loss: 0.1349, Validation Loss: 0.0382,V Acc: 0.8273, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.5758
Fold [3/5] Epoch [20/100] Initial Loss: 0.1392, Training Loss: 0.0162, Initial Validation Loss: 0.1349, Validation Loss: 0.0323,V Acc: 0.8273, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.5152
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.961038961038961
Fold [4/5] Epoch [0/100] Initial Loss: 0.1408, Training Loss: 0.1408, Initial Validation Loss: 0.1380, Validation Loss: 0.1380,V Acc: 0.2477, Top 70th Acc: 0.3117, Bottom 30th Acc: 0.0938
Fold [4/5] Epoch [10/100] Initial Loss: 0.1408, Training Loss: 0.0328, Initial Validation Loss: 0.1380, Validation Loss: 0.0339,V Acc: 0.8532, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.6562
Fold [4/5] Epoch [20/100] Initial Loss: 0.1408, Training Loss: 0.0152, Initial Validation Loss: 0.1380, Validation Loss: 0.0262,V Acc: 0.8807, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.7188
Stopping early at Epoch (base 0): 21  Rolling back to Epoch (base 0): 16  Top Validation Acc: 0.948051948051948
Fold [5/5] Epoch [0/100] Initial Loss: 0.1389, Training Loss: 0.1389, Initial Validation Loss: 0.1287, Validation Loss: 0.1287,V Acc: 0.4074, Top 70th Acc: 0.4737, Bottom 30th Acc: 0.2500
Fold [5/5] Epoch [10/100] Initial Loss: 0.1389, Training Loss: 0.0240, Initial Validation Loss: 0.1287, Validation Loss: 0.0317,V Acc: 0.8241, Top 70th Acc: 0.9737, Bottom 30th Acc: 0.4688
Fold [5/5] Epoch [20/100] Initial Loss: 0.1389, Training Loss: 0.0147, Initial Validation Loss: 0.1287, Validation Loss: 0.0282,V Acc: 0.8426, Top 70th Acc: 0.9737, Bottom 30th Acc: 0.5312
Fold [2/5] Epoch [20/100] Initial Loss: 0.1387, Training Loss: 0.0205, Initial Validation Loss: 0.1380, Validation Loss: 0.0240,V Acc: 0.8829, Top 70th Acc: 0.9872, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.9743589743589743
26 1 [array([0.6690246 , 0.06095321, 0.0443867 , 0.09411047, 0.13152511],
      dtype=float32)]
Fold [3/5] Epoch [0/100] Initial Loss: 0.1396, Training Loss: 0.1396, Initial Validation Loss: 0.1346, Validation Loss: 0.1346,V Acc: 0.2545, Top 70th Acc: 0.3247, Bottom 30th Acc: 0.0909
Fold [3/5] Epoch [10/100] Initial Loss: 0.1396, Training Loss: 0.0365, Initial Validation Loss: 0.1346, Validation Loss: 0.0543,V Acc: 0.7545, Top 70th Acc: 0.8312, Bottom 30th Acc: 0.5758
Fold [3/5] Epoch [20/100] Initial Loss: 0.1396, Training Loss: 0.0191, Initial Validation Loss: 0.1346, Validation Loss: 0.0418,V Acc: 0.8091, Top 70th Acc: 0.8701, Bottom 30th Acc: 0.6667
Fold [3/5] Epoch [30/100] Initial Loss: 0.1396, Training Loss: 0.0159, Initial Validation Loss: 0.1346, Validation Loss: 0.0418,V Acc: 0.8091, Top 70th Acc: 0.8571, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 33  Rolling back to Epoch (base 0): 28  Top Validation Acc: 0.8701298701298701
Fold [4/5] Epoch [0/100] Initial Loss: 0.1388, Training Loss: 0.1388, Initial Validation Loss: 0.1324, Validation Loss: 0.1324,V Acc: 0.2844, Top 70th Acc: 0.2987, Bottom 30th Acc: 0.2500
Fold [4/5] Epoch [10/100] Initial Loss: 0.1388, Training Loss: 0.0264, Initial Validation Loss: 0.1324, Validation Loss: 0.0365,V Acc: 0.8165, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.5625
Fold [4/5] Epoch [20/100] Initial Loss: 0.1388, Training Loss: 0.0182, Initial Validation Loss: 0.1324, Validation Loss: 0.0346,V Acc: 0.8165, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.5312
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.948051948051948
Fold [5/5] Epoch [0/100] Initial Loss: 0.1401, Training Loss: 0.1401, Initial Validation Loss: 0.1319, Validation Loss: 0.1319,V Acc: 0.2500, Top 70th Acc: 0.3289, Bottom 30th Acc: 0.0625
Fold [5/5] Epoch [10/100] Initial Loss: 0.1401, Training Loss: 0.0329, Initial Validation Loss: 0.1319, Validation Loss: 0.0420,V Acc: 0.8056, Top 70th Acc: 0.9079, Bottom 30th Acc: 0.5625
Fold [5/5] Epoch [20/100] Initial Loss: 0.1401, Training Loss: 0.0184, Initial Validation Loss: 0.1319, Validation Loss: 0.0337,V Acc: 0.8333, Top 70th Acc: 0.9211, Bottom 30th Acc: 0.6250
Fold [5/5] Epoch [30/100] Initial Loss: 0.1401, Training Loss: 0.0155, Initial Validation Loss: 0.1319, Validation Loss: 0.0342,V Acc: 0.8056, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.5000
Stopping early at Epoch (base 0): 30  Rolling back to Epoch (base 0): 25  Top Validation Acc: 0.9342105263157895
Running train_nn.py with seed 27
CUDA:False
Training samples count:  550
Training on 30 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1383, Training Loss: 0.1383, Initial Validation Loss: 0.1330, Validation Loss: 0.1330,V Acc: 0.4018, Top 70th Acc: 0.5063, Bottom 30th Acc: 0.1515
Fold [1/5] Epoch [10/100] Initial Loss: 0.1383, Training Loss: 0.0252, Initial Validation Loss: 0.1330, Validation Loss: 0.0414,V Acc: 0.7946, Top 70th Acc: 0.8861, Bottom 30th Acc: 0.5758
Fold [1/5] Epoch [20/100] Initial Loss: 0.1383, Training Loss: 0.0151, Initial Validation Loss: 0.1330, Validation Loss: 0.0397,V Acc: 0.8036, Top 70th Acc: 0.8861, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 28  Rolling back to Epoch (base 0): 23  Top Validation Acc: 0.8860759493670886
Fold [2/5] Epoch [0/100] Initial Loss: 0.1386, Training Loss: 0.1386, Initial Validation Loss: 0.1319, Validation Loss: 0.1319,V Acc: 0.4054, Top 70th Acc: 0.5128, Bottom 30th Acc: 0.1515
Fold [2/5] Epoch [10/100] Initial Loss: 0.1386, Training Loss: 0.0291, Initial Validation Loss: 0.1319, Validation Loss: 0.0284,V Acc: 0.8739, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.6667
Fold [2/5] Epoch [20/100] Initial Loss: 0.1386, Training Loss: 0.0193, Initial Validation Loss: 0.1319, Validation Loss: 0.0224,V Acc: 0.8919, Top 70th Acc: 0.9872, Bottom 30th Acc: 0.6667
Fold [2/5] Epoch [30/100] Initial Loss: 0.1386, Training Loss: 0.0161, Initial Validation Loss: 0.1319, Validation Loss: 0.0213,V Acc: 0.8739, Top 70th Acc: 1.0000, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 39  Rolling back to Epoch (base 0): 34  Top Validation Acc: 1.0
27 1 [array([0.78592545, 0.06247454, 0.01547795, 0.04734578, 0.08877621],
      dtype=float32)]
Fold [3/5] Epoch [0/100] Initial Loss: 0.1394, Training Loss: 0.1394, Initial Validation Loss: 0.1365, Validation Loss: 0.1365,V Acc: 0.2818, Top 70th Acc: 0.4026, Bottom 30th Acc: 0.0000
Fold [3/5] Epoch [10/100] Initial Loss: 0.1394, Training Loss: 0.0395, Initial Validation Loss: 0.1365, Validation Loss: 0.0366,V Acc: 0.8636, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6667
Fold [3/5] Epoch [20/100] Initial Loss: 0.1394, Training Loss: 0.0209, Initial Validation Loss: 0.1365, Validation Loss: 0.0250,V Acc: 0.8818, Top 70th Acc: 0.9870, Bottom 30th Acc: 0.6364
Fold [3/5] Epoch [30/100] Initial Loss: 0.1394, Training Loss: 0.0180, Initial Validation Loss: 0.1365, Validation Loss: 0.0218,V Acc: 0.8727, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 33  Rolling back to Epoch (base 0): 28  Top Validation Acc: 0.974025974025974
Fold [4/5] Epoch [0/100] Initial Loss: 0.1351, Training Loss: 0.1351, Initial Validation Loss: 0.1270, Validation Loss: 0.1270,V Acc: 0.3945, Top 70th Acc: 0.4805, Bottom 30th Acc: 0.1875
Fold [4/5] Epoch [10/100] Initial Loss: 0.1351, Training Loss: 0.0307, Initial Validation Loss: 0.1270, Validation Loss: 0.0286,V Acc: 0.8716, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.6250
Fold [4/5] Epoch [20/100] Initial Loss: 0.1351, Training Loss: 0.0192, Initial Validation Loss: 0.1270, Validation Loss: 0.0267,V Acc: 0.8440, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.5938
Stopping early at Epoch (base 0): 21  Rolling back to Epoch (base 0): 16  Top Validation Acc: 0.948051948051948
Fold [5/5] Epoch [0/100] Initial Loss: 0.1404, Training Loss: 0.1404, Initial Validation Loss: 0.1322, Validation Loss: 0.1322,V Acc: 0.2963, Top 70th Acc: 0.2895, Bottom 30th Acc: 0.3125
Fold [5/5] Epoch [10/100] Initial Loss: 0.1404, Training Loss: 0.0392, Initial Validation Loss: 0.1322, Validation Loss: 0.0503,V Acc: 0.7407, Top 70th Acc: 0.8421, Bottom 30th Acc: 0.5000
Fold [5/5] Epoch [20/100] Initial Loss: 0.1404, Training Loss: 0.0166, Initial Validation Loss: 0.1322, Validation Loss: 0.0385,V Acc: 0.7963, Top 70th Acc: 0.9079, Bottom 30th Acc: 0.5312
Fold [5/5] Epoch [30/100] Initial Loss: 0.1404, Training Loss: 0.0134, Initial Validation Loss: 0.1322, Validation Loss: 0.0388,V Acc: 0.8056, Top 70th Acc: 0.9079, Bottom 30th Acc: 0.5625
Stopping early at Epoch (base 0): 31  Rolling back to Epoch (base 0): 26  Top Validation Acc: 0.9210526315789473
Running train_nn.py with seed 28
CUDA:False
Training samples count:  550
Training on 30 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1381, Training Loss: 0.1381, Initial Validation Loss: 0.1373, Validation Loss: 0.1373,V Acc: 0.3036, Top 70th Acc: 0.3291, Bottom 30th Acc: 0.2424
Fold [1/5] Epoch [10/100] Initial Loss: 0.1381, Training Loss: 0.0325, Initial Validation Loss: 0.1373, Validation Loss: 0.0470,V Acc: 0.8036, Top 70th Acc: 0.8987, Bottom 30th Acc: 0.5758
Fold [1/5] Epoch [20/100] Initial Loss: 0.1381, Training Loss: 0.0167, Initial Validation Loss: 0.1373, Validation Loss: 0.0416,V Acc: 0.7946, Top 70th Acc: 0.9241, Bottom 30th Acc: 0.4848
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.8860759493670886
Fold [2/5] Epoch [0/100] Initial Loss: 0.1406, Training Loss: 0.1406, Initial Validation Loss: 0.1293, Validation Loss: 0.1293,V Acc: 0.2883, Top 70th Acc: 0.3205, Bottom 30th Acc: 0.2121
Fold [2/5] Epoch [10/100] Initial Loss: 0.1406, Training Loss: 0.0441, Initial Validation Loss: 0.1293, Validation Loss: 0.0522,V Acc: 0.7387, Top 70th Acc: 0.8205, Bottom 30th Acc: 0.5455
Fold [2/5] Epoch [20/100] Initial Loss: 0.1406, Training Loss: 0.0188, Initial Validation Loss: 0.1293, Validation Loss: 0.0331,V Acc: 0.8288, Top 70th Acc: 0.8974, Bottom 30th Acc: 0.6667
Fold [1/5] Epoch [20/100] Initial Loss: 0.1417, Training Loss: 0.0250, Initial Validation Loss: 0.1360, Validation Loss: 0.0327,V Acc: 0.8125, Top 70th Acc: 0.9367, Bottom 30th Acc: 0.5152
Stopping early at Epoch (base 0): 22  Rolling back to Epoch (base 0): 17  Top Validation Acc: 0.9367088607594937
Fold [2/5] Epoch [0/100] Initial Loss: 0.1354, Training Loss: 0.1354, Initial Validation Loss: 0.1334, Validation Loss: 0.1334,V Acc: 0.3333, Top 70th Acc: 0.3590, Bottom 30th Acc: 0.2727
Fold [2/5] Epoch [10/100] Initial Loss: 0.1354, Training Loss: 0.0415, Initial Validation Loss: 0.1334, Validation Loss: 0.0404,V Acc: 0.8378, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.6364
Fold [2/5] Epoch [20/100] Initial Loss: 0.1354, Training Loss: 0.0274, Initial Validation Loss: 0.1334, Validation Loss: 0.0294,V Acc: 0.8829, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.6970
Fold [2/5] Epoch [30/100] Initial Loss: 0.1354, Training Loss: 0.0243, Initial Validation Loss: 0.1334, Validation Loss: 0.0288,V Acc: 0.8739, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 32  Rolling back to Epoch (base 0): 27  Top Validation Acc: 0.9487179487179487
26 1 [array([0.37714776, 0.12156032, 0.13941802, 0.09754413, 0.26432982],
      dtype=float32)]
Fold [3/5] Epoch [0/100] Initial Loss: 0.1375, Training Loss: 0.1375, Initial Validation Loss: 0.1310, Validation Loss: 0.1310,V Acc: 0.3182, Top 70th Acc: 0.3896, Bottom 30th Acc: 0.1515
Fold [3/5] Epoch [10/100] Initial Loss: 0.1375, Training Loss: 0.0314, Initial Validation Loss: 0.1310, Validation Loss: 0.0495,V Acc: 0.7455, Top 70th Acc: 0.8831, Bottom 30th Acc: 0.4242
Fold [3/5] Epoch [20/100] Initial Loss: 0.1375, Training Loss: 0.0221, Initial Validation Loss: 0.1310, Validation Loss: 0.0404,V Acc: 0.8182, Top 70th Acc: 0.8831, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 28  Rolling back to Epoch (base 0): 23  Top Validation Acc: 0.8831168831168831
Fold [4/5] Epoch [0/100] Initial Loss: 0.1398, Training Loss: 0.1398, Initial Validation Loss: 0.1331, Validation Loss: 0.1331,V Acc: 0.3394, Top 70th Acc: 0.3247, Bottom 30th Acc: 0.3750
Fold [4/5] Epoch [10/100] Initial Loss: 0.1398, Training Loss: 0.0360, Initial Validation Loss: 0.1331, Validation Loss: 0.0405,V Acc: 0.7890, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.5000
Fold [4/5] Epoch [20/100] Initial Loss: 0.1398, Training Loss: 0.0238, Initial Validation Loss: 0.1331, Validation Loss: 0.0350,V Acc: 0.8165, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.5625
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.948051948051948
Fold [5/5] Epoch [0/100] Initial Loss: 0.1410, Training Loss: 0.1410, Initial Validation Loss: 0.1284, Validation Loss: 0.1284,V Acc: 0.3704, Top 70th Acc: 0.4079, Bottom 30th Acc: 0.2812
Fold [5/5] Epoch [10/100] Initial Loss: 0.1410, Training Loss: 0.0314, Initial Validation Loss: 0.1284, Validation Loss: 0.0380,V Acc: 0.8148, Top 70th Acc: 0.8947, Bottom 30th Acc: 0.6250
Fold [5/5] Epoch [20/100] Initial Loss: 0.1410, Training Loss: 0.0240, Initial Validation Loss: 0.1284, Validation Loss: 0.0359,V Acc: 0.8241, Top 70th Acc: 0.8947, Bottom 30th Acc: 0.6562
Stopping early at Epoch (base 0): 21  Rolling back to Epoch (base 0): 16  Top Validation Acc: 0.9078947368421053
Running train_nn.py with seed 27
CUDA:False
Training samples count:  550
Training on 20 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1379, Training Loss: 0.1379, Initial Validation Loss: 0.1325, Validation Loss: 0.1325,V Acc: 0.4732, Top 70th Acc: 0.5190, Bottom 30th Acc: 0.3636
Fold [1/5] Epoch [10/100] Initial Loss: 0.1379, Training Loss: 0.0314, Initial Validation Loss: 0.1325, Validation Loss: 0.0454,V Acc: 0.7768, Top 70th Acc: 0.8734, Bottom 30th Acc: 0.5455
Fold [1/5] Epoch [20/100] Initial Loss: 0.1379, Training Loss: 0.0211, Initial Validation Loss: 0.1325, Validation Loss: 0.0420,V Acc: 0.8036, Top 70th Acc: 0.8734, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 21  Rolling back to Epoch (base 0): 16  Top Validation Acc: 0.8734177215189873
Fold [2/5] Epoch [0/100] Initial Loss: 0.1407, Training Loss: 0.1407, Initial Validation Loss: 0.1340, Validation Loss: 0.1340,V Acc: 0.1982, Top 70th Acc: 0.2564, Bottom 30th Acc: 0.0606
Fold [2/5] Epoch [10/100] Initial Loss: 0.1407, Training Loss: 0.0357, Initial Validation Loss: 0.1340, Validation Loss: 0.0288,V Acc: 0.9009, Top 70th Acc: 1.0000, Bottom 30th Acc: 0.6667
Fold [2/5] Epoch [20/100] Initial Loss: 0.1407, Training Loss: 0.0255, Initial Validation Loss: 0.1340, Validation Loss: 0.0247,V Acc: 0.8829, Top 70th Acc: 0.9872, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.9743589743589743
27 1 [array([0.2482638 , 0.13465524, 0.10697481, 0.316436  , 0.19367018],
      dtype=float32)]
Fold [3/5] Epoch [0/100] Initial Loss: 0.1378, Training Loss: 0.1378, Initial Validation Loss: 0.1341, Validation Loss: 0.1341,V Acc: 0.3727, Top 70th Acc: 0.4675, Bottom 30th Acc: 0.1515
Fold [3/5] Epoch [10/100] Initial Loss: 0.1378, Training Loss: 0.0334, Initial Validation Loss: 0.1341, Validation Loss: 0.0289,V Acc: 0.9000, Top 70th Acc: 0.9870, Bottom 30th Acc: 0.6970
Fold [3/5] Epoch [20/100] Initial Loss: 0.1378, Training Loss: 0.0253, Initial Validation Loss: 0.1341, Validation Loss: 0.0259,V Acc: 0.9000, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.7273
Stopping early at Epoch (base 0): 22  Rolling back to Epoch (base 0): 17  Top Validation Acc: 0.961038961038961
Fold [4/5] Epoch [0/100] Initial Loss: 0.1389, Training Loss: 0.1389, Initial Validation Loss: 0.1352, Validation Loss: 0.1352,V Acc: 0.2477, Top 70th Acc: 0.3247, Bottom 30th Acc: 0.0625
Fold [4/5] Epoch [10/100] Initial Loss: 0.1389, Training Loss: 0.0369, Initial Validation Loss: 0.1352, Validation Loss: 0.0387,V Acc: 0.8257, Top 70th Acc: 0.8961, Bottom 30th Acc: 0.6562
Fold [4/5] Epoch [20/100] Initial Loss: 0.1389, Training Loss: 0.0237, Initial Validation Loss: 0.1352, Validation Loss: 0.0341,V Acc: 0.8073, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.5625
Stopping early at Epoch (base 0): 28  Rolling back to Epoch (base 0): 23  Top Validation Acc: 0.9090909090909091
Fold [5/5] Epoch [0/100] Initial Loss: 0.1387, Training Loss: 0.1387, Initial Validation Loss: 0.1321, Validation Loss: 0.1321,V Acc: 0.2593, Top 70th Acc: 0.3553, Bottom 30th Acc: 0.0312
Fold [5/5] Epoch [10/100] Initial Loss: 0.1387, Training Loss: 0.0320, Initial Validation Loss: 0.1321, Validation Loss: 0.0421,V Acc: 0.7963, Top 70th Acc: 0.8947, Bottom 30th Acc: 0.5625
Fold [5/5] Epoch [20/100] Initial Loss: 0.1387, Training Loss: 0.0217, Initial Validation Loss: 0.1321, Validation Loss: 0.0397,V Acc: 0.8241, Top 70th Acc: 0.9079, Bottom 30th Acc: 0.6250
Stopping early at Epoch (base 0): 20  Rolling back to Epoch (base 0): 15  Top Validation Acc: 0.9078947368421053
Running train_nn.py with seed 28
CUDA:False
Training samples count:  550
Training on 20 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1392, Training Loss: 0.1392, Initial Validation Loss: 0.1357, Validation Loss: 0.1357,V Acc: 0.3750, Top 70th Acc: 0.4177, Bottom 30th Acc: 0.2727
Fold [1/5] Epoch [10/100] Initial Loss: 0.1392, Training Loss: 0.0315, Initial Validation Loss: 0.1357, Validation Loss: 0.0489,V Acc: 0.7411, Top 70th Acc: 0.8987, Bottom 30th Acc: 0.3636
Fold [1/5] Epoch [20/100] Initial Loss: 0.1392, Training Loss: 0.0212, Initial Validation Loss: 0.1357, Validation Loss: 0.0459,V Acc: 0.7768, Top 70th Acc: 0.8734, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 21  Rolling back to Epoch (base 0): 16  Top Validation Acc: 0.8860759493670886
Fold [2/5] Epoch [0/100] Initial Loss: 0.1415, Training Loss: 0.1415, Initial Validation Loss: 0.1296, Validation Loss: 0.1296,V Acc: 0.2793, Top 70th Acc: 0.3077, Bottom 30th Acc: 0.2121
Fold [2/5] Epoch [10/100] Initial Loss: 0.1415, Training Loss: 0.0395, Initial Validation Loss: 0.1296, Validation Loss: 0.0404,V Acc: 0.7568, Top 70th Acc: 0.8462, Bottom 30th Acc: 0.5455
Fold [2/5] Epoch [20/100] Initial Loss: 0.1415, Training Loss: 0.0239, Initial Validation Loss: 0.1296, Validation Loss: 0.0316,V Acc: 0.8468, Top 70th Acc: 0.8974, Bottom 30th Acc: 0.7273
Fold [1/5] Epoch [10/100] Initial Loss: 0.1373, Training Loss: 0.0208, Initial Validation Loss: 0.1232, Validation Loss: 0.0377,V Acc: 0.8304, Top 70th Acc: 0.9114, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 14  Rolling back to Epoch (base 0): 9  Top Validation Acc: 0.8987341772151899
Fold [2/5] Epoch [0/100] Initial Loss: 0.1389, Training Loss: 0.1389, Initial Validation Loss: 0.1361, Validation Loss: 0.1361,V Acc: 0.3243, Top 70th Acc: 0.3974, Bottom 30th Acc: 0.1515
Fold [2/5] Epoch [10/100] Initial Loss: 0.1389, Training Loss: 0.0216, Initial Validation Loss: 0.1361, Validation Loss: 0.0290,V Acc: 0.8739, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.6364
Fold [2/5] Epoch [20/100] Initial Loss: 0.1389, Training Loss: 0.0155, Initial Validation Loss: 0.1361, Validation Loss: 0.0284,V Acc: 0.8468, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 22  Rolling back to Epoch (base 0): 17  Top Validation Acc: 0.9743589743589743
Fold [3/5] Epoch [0/100] Initial Loss: 0.1388, Training Loss: 0.1388, Initial Validation Loss: 0.1257, Validation Loss: 0.1257,V Acc: 0.3909, Top 70th Acc: 0.4675, Bottom 30th Acc: 0.2121
Fold [3/5] Epoch [10/100] Initial Loss: 0.1388, Training Loss: 0.0275, Initial Validation Loss: 0.1257, Validation Loss: 0.0169,V Acc: 0.9273, Top 70th Acc: 1.0000, Bottom 30th Acc: 0.7576
Stopping early at Epoch (base 0): 17  Rolling back to Epoch (base 0): 12  Top Validation Acc: 1.0
Fold [4/5] Epoch [0/100] Initial Loss: 0.1289, Training Loss: 0.1289, Initial Validation Loss: 0.1167, Validation Loss: 0.1167,V Acc: 0.4312, Top 70th Acc: 0.5584, Bottom 30th Acc: 0.1250
Fold [4/5] Epoch [10/100] Initial Loss: 0.1289, Training Loss: 0.0234, Initial Validation Loss: 0.1167, Validation Loss: 0.0301,V Acc: 0.8807, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.6562
Stopping early at Epoch (base 0): 19  Rolling back to Epoch (base 0): 14  Top Validation Acc: 0.961038961038961
Fold [5/5] Epoch [0/100] Initial Loss: 0.1339, Training Loss: 0.1339, Initial Validation Loss: 0.1128, Validation Loss: 0.1128,V Acc: 0.4537, Top 70th Acc: 0.5658, Bottom 30th Acc: 0.1875
Fold [5/5] Epoch [10/100] Initial Loss: 0.1339, Training Loss: 0.0198, Initial Validation Loss: 0.1128, Validation Loss: 0.0321,V Acc: 0.8333, Top 70th Acc: 0.9211, Bottom 30th Acc: 0.6250
Stopping early at Epoch (base 0): 17  Rolling back to Epoch (base 0): 12  Top Validation Acc: 0.9473684210526315
36 4 [array([0.83170986, 0.02252331, 0.01951941, 0.06188766, 0.06435972],
      dtype=float32)]
Running train_nn.py with seed 37
CUDA:False
Training samples count:  550
Training on 21 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1298, Training Loss: 0.1298, Initial Validation Loss: 0.1239, Validation Loss: 0.1239,V Acc: 0.4732, Top 70th Acc: 0.6076, Bottom 30th Acc: 0.1515
Fold [1/5] Epoch [10/100] Initial Loss: 0.1298, Training Loss: 0.0250, Initial Validation Loss: 0.1239, Validation Loss: 0.0306,V Acc: 0.8571, Top 70th Acc: 0.9620, Bottom 30th Acc: 0.6061
Fold [1/5] Epoch [20/100] Initial Loss: 0.1298, Training Loss: 0.0171, Initial Validation Loss: 0.1239, Validation Loss: 0.0251,V Acc: 0.8929, Top 70th Acc: 0.9873, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 27  Rolling back to Epoch (base 0): 22  Top Validation Acc: 0.9620253164556962
Fold [2/5] Epoch [0/100] Initial Loss: 0.1326, Training Loss: 0.1326, Initial Validation Loss: 0.1215, Validation Loss: 0.1215,V Acc: 0.4324, Top 70th Acc: 0.5641, Bottom 30th Acc: 0.1212
Fold [2/5] Epoch [10/100] Initial Loss: 0.1326, Training Loss: 0.0232, Initial Validation Loss: 0.1215, Validation Loss: 0.0330,V Acc: 0.8559, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.6364
Fold [2/5] Epoch [20/100] Initial Loss: 0.1326, Training Loss: 0.0158, Initial Validation Loss: 0.1215, Validation Loss: 0.0320,V Acc: 0.8559, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 28  Rolling back to Epoch (base 0): 23  Top Validation Acc: 0.9743589743589743
37 1 [array([0.86297244, 0.02263226, 0.01506312, 0.05729889, 0.04203327],
      dtype=float32)]
Fold [3/5] Epoch [0/100] Initial Loss: 0.1416, Training Loss: 0.1416, Initial Validation Loss: 0.1268, Validation Loss: 0.1268,V Acc: 0.4909, Top 70th Acc: 0.6104, Bottom 30th Acc: 0.2121
Fold [3/5] Epoch [10/100] Initial Loss: 0.1416, Training Loss: 0.0226, Initial Validation Loss: 0.1268, Validation Loss: 0.0293,V Acc: 0.8455, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6061
Fold [3/5] Epoch [20/100] Initial Loss: 0.1416, Training Loss: 0.0149, Initial Validation Loss: 0.1268, Validation Loss: 0.0300,V Acc: 0.8455, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 20  Rolling back to Epoch (base 0): 15  Top Validation Acc: 0.961038961038961
Fold [4/5] Epoch [0/100] Initial Loss: 0.1217, Training Loss: 0.1217, Initial Validation Loss: 0.1054, Validation Loss: 0.1054,V Acc: 0.5321, Top 70th Acc: 0.5974, Bottom 30th Acc: 0.3750
Fold [4/5] Epoch [10/100] Initial Loss: 0.1217, Training Loss: 0.0220, Initial Validation Loss: 0.1054, Validation Loss: 0.0289,V Acc: 0.8716, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6875
Fold [4/5] Epoch [20/100] Initial Loss: 0.1217, Training Loss: 0.0160, Initial Validation Loss: 0.1054, Validation Loss: 0.0226,V Acc: 0.8991, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.7188
Fold [4/5] Epoch [30/100] Initial Loss: 0.1217, Training Loss: 0.0141, Initial Validation Loss: 0.1054, Validation Loss: 0.0198,V Acc: 0.8899, Top 70th Acc: 1.0000, Bottom 30th Acc: 0.6250
Stopping early at Epoch (base 0): 30  Rolling back to Epoch (base 0): 25  Top Validation Acc: 1.0
Fold [5/5] Epoch [0/100] Initial Loss: 0.1381, Training Loss: 0.1381, Initial Validation Loss: 0.1147, Validation Loss: 0.1147,V Acc: 0.5185, Top 70th Acc: 0.5921, Bottom 30th Acc: 0.3438
Fold [5/5] Epoch [10/100] Initial Loss: 0.1381, Training Loss: 0.0190, Initial Validation Loss: 0.1147, Validation Loss: 0.0218,V Acc: 0.8981, Top 70th Acc: 0.9737, Bottom 30th Acc: 0.7188
Stopping early at Epoch (base 0): 17  Rolling back to Epoch (base 0): 12  Top Validation Acc: 0.9605263157894737
Running train_nn.py with seed 38
CUDA:False
Training samples count:  550
Training on 21 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1215, Training Loss: 0.1215, Initial Validation Loss: 0.1127, Validation Loss: 0.1127,V Acc: 0.4464, Top 70th Acc: 0.5570, Bottom 30th Acc: 0.1818
Fold [1/5] Epoch [10/100] Initial Loss: 0.1215, Training Loss: 0.0197, Initial Validation Loss: 0.1127, Validation Loss: 0.0237,V Acc: 0.9018, Top 70th Acc: 0.9873, Bottom 30th Acc: 0.6970
Fold [1/5] Epoch [20/100] Initial Loss: 0.1215, Training Loss: 0.0148, Initial Validation Loss: 0.1127, Validation Loss: 0.0246,V Acc: 0.9107, Top 70th Acc: 0.9494, Bottom 30th Acc: 0.8182
Stopping early at Epoch (base 0): 22  Rolling back to Epoch (base 0): 17  Top Validation Acc: 0.9873417721518988
Fold [2/5] Epoch [0/100] Initial Loss: 0.1361, Training Loss: 0.1361, Initial Validation Loss: 0.1218, Validation Loss: 0.1218,V Acc: 0.4414, Top 70th Acc: 0.4872, Bottom 30th Acc: 0.3333
Fold [2/5] Epoch [10/100] Initial Loss: 0.1361, Training Loss: 0.0262, Initial Validation Loss: 0.1218, Validation Loss: 0.0331,V Acc: 0.8468, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.6061
Fold [2/5] Epoch [20/100] Initial Loss: 0.1361, Training Loss: 0.0147, Initial Validation Loss: 0.1218, Validation Loss: 0.0314,V Acc: 0.8559, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 27  Rolling back to Epoch (base 0): 22  Top Validation Acc: 0.9230769230769231
38 1 [array([0.7320439 , 0.01574985, 0.03001393, 0.08109996, 0.14109235],
      dtype=float32)]
Fold [3/5] Epoch [0/100] Initial Loss: 0.1395, Training Loss: 0.1395, Initial Validation Loss: 0.1265, Validation Loss: 0.1265,V Acc: 0.4455, Top 70th Acc: 0.5195, Bottom 30th Acc: 0.2727
Fold [3/5] Epoch [10/100] Initial Loss: 0.1395, Training Loss: 0.0245, Initial Validation Loss: 0.1265, Validation Loss: 0.0309,V Acc: 0.8455, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 19  Rolling back to Epoch (base 0): 14  Top Validation Acc: 0.987012987012987
Fold [4/5] Epoch [0/100] Initial Loss: 0.1344, Training Loss: 0.1344, Initial Validation Loss: 0.1248, Validation Loss: 0.1248,V Acc: 0.4220, Top 70th Acc: 0.5065, Bottom 30th Acc: 0.2188
Fold [2/5] Epoch [10/100] Initial Loss: 0.1376, Training Loss: 0.0818, Initial Validation Loss: 0.1303, Validation Loss: 0.0792,V Acc: 0.5946, Top 70th Acc: 0.7436, Bottom 30th Acc: 0.2424
Fold [2/5] Epoch [20/100] Initial Loss: 0.1376, Training Loss: 0.0798, Initial Validation Loss: 0.1303, Validation Loss: 0.0766,V Acc: 0.6306, Top 70th Acc: 0.7436, Bottom 30th Acc: 0.3636
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.7435897435897436
27 1 [array([0.12070376, 0.40252605, 0.12251795, 0.19486895, 0.15938327],
      dtype=float32)]
Fold [3/5] Epoch [0/100] Initial Loss: 0.1381, Training Loss: 0.1381, Initial Validation Loss: 0.1334, Validation Loss: 0.1334,V Acc: 0.2636, Top 70th Acc: 0.3506, Bottom 30th Acc: 0.0606
Fold [3/5] Epoch [10/100] Initial Loss: 0.1381, Training Loss: 0.0820, Initial Validation Loss: 0.1334, Validation Loss: 0.0773,V Acc: 0.6636, Top 70th Acc: 0.7792, Bottom 30th Acc: 0.3939
Fold [3/5] Epoch [20/100] Initial Loss: 0.1381, Training Loss: 0.0792, Initial Validation Loss: 0.1334, Validation Loss: 0.0739,V Acc: 0.6727, Top 70th Acc: 0.7792, Bottom 30th Acc: 0.4242
Fold [3/5] Epoch [30/100] Initial Loss: 0.1381, Training Loss: 0.0781, Initial Validation Loss: 0.1334, Validation Loss: 0.0734,V Acc: 0.6818, Top 70th Acc: 0.7922, Bottom 30th Acc: 0.4242
Stopping early at Epoch (base 0): 38  Rolling back to Epoch (base 0): 33  Top Validation Acc: 0.8051948051948052
Fold [4/5] Epoch [0/100] Initial Loss: 0.1315, Training Loss: 0.1315, Initial Validation Loss: 0.1210, Validation Loss: 0.1210,V Acc: 0.4312, Top 70th Acc: 0.5455, Bottom 30th Acc: 0.1562
Fold [4/5] Epoch [10/100] Initial Loss: 0.1315, Training Loss: 0.0807, Initial Validation Loss: 0.1210, Validation Loss: 0.0799,V Acc: 0.6239, Top 70th Acc: 0.7403, Bottom 30th Acc: 0.3438
Fold [4/5] Epoch [20/100] Initial Loss: 0.1315, Training Loss: 0.0790, Initial Validation Loss: 0.1210, Validation Loss: 0.0786,V Acc: 0.6330, Top 70th Acc: 0.7403, Bottom 30th Acc: 0.3750
Stopping early at Epoch (base 0): 27  Rolling back to Epoch (base 0): 22  Top Validation Acc: 0.7532467532467533
Fold [5/5] Epoch [0/100] Initial Loss: 0.1407, Training Loss: 0.1407, Initial Validation Loss: 0.1308, Validation Loss: 0.1308,V Acc: 0.2222, Top 70th Acc: 0.2895, Bottom 30th Acc: 0.0625
Fold [5/5] Epoch [10/100] Initial Loss: 0.1407, Training Loss: 0.0802, Initial Validation Loss: 0.1308, Validation Loss: 0.0808,V Acc: 0.6204, Top 70th Acc: 0.7237, Bottom 30th Acc: 0.3750
Fold [5/5] Epoch [20/100] Initial Loss: 0.1407, Training Loss: 0.0780, Initial Validation Loss: 0.1308, Validation Loss: 0.0791,V Acc: 0.6019, Top 70th Acc: 0.7237, Bottom 30th Acc: 0.3125
Fold [5/5] Epoch [30/100] Initial Loss: 0.1407, Training Loss: 0.0775, Initial Validation Loss: 0.1308, Validation Loss: 0.0796,V Acc: 0.6019, Top 70th Acc: 0.7368, Bottom 30th Acc: 0.2812
Stopping early at Epoch (base 0): 31  Rolling back to Epoch (base 0): 26  Top Validation Acc: 0.7368421052631579
Running train_nn.py with seed 28
CUDA:False
Training samples count:  550
Training on 2 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1234, Training Loss: 0.1234, Initial Validation Loss: 0.1117, Validation Loss: 0.1117,V Acc: 0.5536, Top 70th Acc: 0.7089, Bottom 30th Acc: 0.1818
Fold [1/5] Epoch [10/100] Initial Loss: 0.1234, Training Loss: 0.0781, Initial Validation Loss: 0.1117, Validation Loss: 0.0855,V Acc: 0.6250, Top 70th Acc: 0.6962, Bottom 30th Acc: 0.4545
Stopping early at Epoch (base 0): 10  Rolling back to Epoch (base 0): 5  Top Validation Acc: 0.6962025316455697
Fold [2/5] Epoch [0/100] Initial Loss: 0.1377, Training Loss: 0.1377, Initial Validation Loss: 0.1218, Validation Loss: 0.1218,V Acc: 0.4505, Top 70th Acc: 0.5385, Bottom 30th Acc: 0.2424
Fold [2/5] Epoch [10/100] Initial Loss: 0.1377, Training Loss: 0.0818, Initial Validation Loss: 0.1218, Validation Loss: 0.0750,V Acc: 0.6577, Top 70th Acc: 0.7436, Bottom 30th Acc: 0.4545
Fold [2/5] Epoch [20/100] Initial Loss: 0.1377, Training Loss: 0.0794, Initial Validation Loss: 0.1218, Validation Loss: 0.0747,V Acc: 0.6396, Top 70th Acc: 0.7179, Bottom 30th Acc: 0.4545
Stopping early at Epoch (base 0): 22  Rolling back to Epoch (base 0): 17  Top Validation Acc: 0.7435897435897436
28 1 [array([0.11898178, 0.3554839 , 0.1332206 , 0.21777   , 0.1745438 ],
      dtype=float32)]
Fold [3/5] Epoch [0/100] Initial Loss: 0.1367, Training Loss: 0.1367, Initial Validation Loss: 0.1277, Validation Loss: 0.1277,V Acc: 0.4636, Top 70th Acc: 0.4156, Bottom 30th Acc: 0.5758
Fold [3/5] Epoch [10/100] Initial Loss: 0.1367, Training Loss: 0.0795, Initial Validation Loss: 0.1277, Validation Loss: 0.0825,V Acc: 0.5909, Top 70th Acc: 0.7532, Bottom 30th Acc: 0.2121
Fold [3/5] Epoch [20/100] Initial Loss: 0.1367, Training Loss: 0.0777, Initial Validation Loss: 0.1277, Validation Loss: 0.0804,V Acc: 0.6273, Top 70th Acc: 0.7532, Bottom 30th Acc: 0.3333
Fold [3/5] Epoch [30/100] Initial Loss: 0.1367, Training Loss: 0.0772, Initial Validation Loss: 0.1277, Validation Loss: 0.0793,V Acc: 0.6273, Top 70th Acc: 0.7532, Bottom 30th Acc: 0.3333
Fold [3/5] Epoch [40/100] Initial Loss: 0.1367, Training Loss: 0.0765, Initial Validation Loss: 0.1277, Validation Loss: 0.0791,V Acc: 0.6364, Top 70th Acc: 0.7532, Bottom 30th Acc: 0.3636
Fold [3/5] Epoch [50/100] Initial Loss: 0.1367, Training Loss: 0.0765, Initial Validation Loss: 0.1277, Validation Loss: 0.0793,V Acc: 0.6364, Top 70th Acc: 0.7532, Bottom 30th Acc: 0.3636
Stopping early at Epoch (base 0): 50  Rolling back to Epoch (base 0): 45  Top Validation Acc: 0.7532467532467533
Fold [4/5] Epoch [0/100] Initial Loss: 0.1326, Training Loss: 0.1326, Initial Validation Loss: 0.1279, Validation Loss: 0.1279,V Acc: 0.3761, Top 70th Acc: 0.3506, Bottom 30th Acc: 0.4375
Fold [4/5] Epoch [10/100] Initial Loss: 0.1326, Training Loss: 0.0805, Initial Validation Loss: 0.1279, Validation Loss: 0.0779,V Acc: 0.6422, Top 70th Acc: 0.7662, Bottom 30th Acc: 0.3438
Fold [4/5] Epoch [20/100] Initial Loss: 0.1326, Training Loss: 0.0787, Initial Validation Loss: 0.1279, Validation Loss: 0.0774,V Acc: 0.6514, Top 70th Acc: 0.7792, Bottom 30th Acc: 0.3438
Fold [4/5] Epoch [30/100] Initial Loss: 0.1326, Training Loss: 0.0785, Initial Validation Loss: 0.1279, Validation Loss: 0.0757,V Acc: 0.6514, Top 70th Acc: 0.7792, Bottom 30th Acc: 0.3438
Fold [4/5] Epoch [40/100] Initial Loss: 0.1326, Training Loss: 0.0782, Initial Validation Loss: 0.1279, Validation Loss: 0.0755,V Acc: 0.6514, Top 70th Acc: 0.7922, Bottom 30th Acc: 0.3125
Stopping early at Epoch (base 0): 40  Rolling back to Epoch (base 0): 35  Top Validation Acc: 0.7922077922077922
Fold [5/5] Epoch [0/100] Initial Loss: 0.1358, Training Loss: 0.1358, Initial Validation Loss: 0.1253, Validation Loss: 0.1253,V Acc: 0.5185, Top 70th Acc: 0.6711, Bottom 30th Acc: 0.1562
Fold [5/5] Epoch [10/100] Initial Loss: 0.1358, Training Loss: 0.0812, Initial Validation Loss: 0.1253, Validation Loss: 0.0762,V Acc: 0.6204, Top 70th Acc: 0.7632, Bottom 30th Acc: 0.2812
Fold [5/5] Epoch [20/100] Initial Loss: 0.1358, Training Loss: 0.0797, Initial Validation Loss: 0.1253, Validation Loss: 0.0736,V Acc: 0.6019, Top 70th Acc: 0.7632, Bottom 30th Acc: 0.2188
Fold [5/5] Epoch [30/100] Initial Loss: 0.1358, Training Loss: 0.0789, Initial Validation Loss: 0.1253, Validation Loss: 0.0723,V Acc: 0.6111, Top 70th Acc: 0.7632, Bottom 30th Acc: 0.2500
Stopping early at Epoch (base 0): 35  Rolling back to Epoch (base 0): 30  Top Validation Acc: 0.7631578947368421
Running train_nn.py with seed 29
CUDA:False
Training samples count:  550
Training on 2 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1401, Training Loss: 0.1401, Initial Validation Loss: 0.1380, Validation Loss: 0.1380,V Acc: 0.3839, Top 70th Acc: 0.5063, Bottom 30th Acc: 0.0909
Fold [1/5] Epoch [10/100] Initial Loss: 0.1401, Training Loss: 0.0841, Initial Validation Loss: 0.1380, Validation Loss: 0.0750,V Acc: 0.6875, Top 70th Acc: 0.7975, Bottom 30th Acc: 0.4242
Fold [1/5] Epoch [20/100] Initial Loss: 0.1401, Training Loss: 0.0820, Initial Validation Loss: 0.1380, Validation Loss: 0.0714,V Acc: 0.7054, Top 70th Acc: 0.7975, Bottom 30th Acc: 0.4848/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)

Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.9605263157894737
Running train_nn.py with seed 29
CUDA:False
Training samples count:  550
Training on 40 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1404, Training Loss: 0.1404, Initial Validation Loss: 0.1400, Validation Loss: 0.1400,V Acc: 0.2946, Top 70th Acc: 0.3165, Bottom 30th Acc: 0.2424
Fold [1/5] Epoch [10/100] Initial Loss: 0.1404, Training Loss: 0.0319, Initial Validation Loss: 0.1400, Validation Loss: 0.0369,V Acc: 0.8393, Top 70th Acc: 0.9620, Bottom 30th Acc: 0.5455
Fold [1/5] Epoch [20/100] Initial Loss: 0.1404, Training Loss: 0.0158, Initial Validation Loss: 0.1400, Validation Loss: 0.0319,V Acc: 0.8482, Top 70th Acc: 0.9494, Bottom 30th Acc: 0.6061
Fold [1/5] Epoch [30/100] Initial Loss: 0.1404, Training Loss: 0.0126, Initial Validation Loss: 0.1400, Validation Loss: 0.0308,V Acc: 0.8482, Top 70th Acc: 0.9494, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 34  Rolling back to Epoch (base 0): 29  Top Validation Acc: 0.9493670886075949
Fold [2/5] Epoch [0/100] Initial Loss: 0.1397, Training Loss: 0.1397, Initial Validation Loss: 0.1418, Validation Loss: 0.1418,V Acc: 0.2523, Top 70th Acc: 0.3077, Bottom 30th Acc: 0.1212
Fold [2/5] Epoch [10/100] Initial Loss: 0.1397, Training Loss: 0.0489, Initial Validation Loss: 0.1418, Validation Loss: 0.0573,V Acc: 0.7568, Top 70th Acc: 0.8462, Bottom 30th Acc: 0.5455
Fold [2/5] Epoch [20/100] Initial Loss: 0.1397, Training Loss: 0.0231, Initial Validation Loss: 0.1418, Validation Loss: 0.0340,V Acc: 0.8559, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.6061
Fold [2/5] Epoch [30/100] Initial Loss: 0.1397, Training Loss: 0.0150, Initial Validation Loss: 0.1418, Validation Loss: 0.0278,V Acc: 0.8739, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 35  Rolling back to Epoch (base 0): 30  Top Validation Acc: 0.9871794871794872
29 1 [array([0.5995114 , 0.02841705, 0.09782572, 0.11092333, 0.16332248],
      dtype=float32)]
Fold [3/5] Epoch [0/100] Initial Loss: 0.1407, Training Loss: 0.1407, Initial Validation Loss: 0.1341, Validation Loss: 0.1341,V Acc: 0.2455, Top 70th Acc: 0.2468, Bottom 30th Acc: 0.2424
Fold [3/5] Epoch [10/100] Initial Loss: 0.1407, Training Loss: 0.0395, Initial Validation Loss: 0.1341, Validation Loss: 0.0445,V Acc: 0.7636, Top 70th Acc: 0.8831, Bottom 30th Acc: 0.4848
Fold [3/5] Epoch [20/100] Initial Loss: 0.1407, Training Loss: 0.0164, Initial Validation Loss: 0.1341, Validation Loss: 0.0287,V Acc: 0.8364, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 29  Rolling back to Epoch (base 0): 24  Top Validation Acc: 0.935064935064935
Fold [4/5] Epoch [0/100] Initial Loss: 0.1385, Training Loss: 0.1385, Initial Validation Loss: 0.1270, Validation Loss: 0.1270,V Acc: 0.2844, Top 70th Acc: 0.3247, Bottom 30th Acc: 0.1875
Fold [4/5] Epoch [10/100] Initial Loss: 0.1385, Training Loss: 0.0280, Initial Validation Loss: 0.1270, Validation Loss: 0.0350,V Acc: 0.7982, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.5312
Stopping early at Epoch (base 0): 18  Rolling back to Epoch (base 0): 13  Top Validation Acc: 0.8961038961038961
Fold [5/5] Epoch [0/100] Initial Loss: 0.1404, Training Loss: 0.1404, Initial Validation Loss: 0.1320, Validation Loss: 0.1320,V Acc: 0.3241, Top 70th Acc: 0.3816, Bottom 30th Acc: 0.1875
Fold [5/5] Epoch [10/100] Initial Loss: 0.1404, Training Loss: 0.0318, Initial Validation Loss: 0.1320, Validation Loss: 0.0473,V Acc: 0.7130, Top 70th Acc: 0.8553, Bottom 30th Acc: 0.3750
Fold [5/5] Epoch [20/100] Initial Loss: 0.1404, Training Loss: 0.0156, Initial Validation Loss: 0.1320, Validation Loss: 0.0360,V Acc: 0.7870, Top 70th Acc: 0.8947, Bottom 30th Acc: 0.5312
Fold [5/5] Epoch [30/100] Initial Loss: 0.1404, Training Loss: 0.0116, Initial Validation Loss: 0.1320, Validation Loss: 0.0348,V Acc: 0.8056, Top 70th Acc: 0.9079, Bottom 30th Acc: 0.5625
Stopping early at Epoch (base 0): 31  Rolling back to Epoch (base 0): 26  Top Validation Acc: 0.9210526315789473
Running train_nn.py with seed 30
CUDA:False
Training samples count:  550
Training on 40 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1407, Training Loss: 0.1407, Initial Validation Loss: 0.1358, Validation Loss: 0.1358,V Acc: 0.2500, Top 70th Acc: 0.3038, Bottom 30th Acc: 0.1212
Fold [1/5] Epoch [10/100] Initial Loss: 0.1407, Training Loss: 0.0314, Initial Validation Loss: 0.1358, Validation Loss: 0.0412,V Acc: 0.8036, Top 70th Acc: 0.8987, Bottom 30th Acc: 0.5758
Fold [1/5] Epoch [20/100] Initial Loss: 0.1407, Training Loss: 0.0158, Initial Validation Loss: 0.1358, Validation Loss: 0.0327,V Acc: 0.8393, Top 70th Acc: 0.9367, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.9113924050632911
Fold [2/5] Epoch [0/100] Initial Loss: 0.1408, Training Loss: 0.1408, Initial Validation Loss: 0.1337, Validation Loss: 0.1337,V Acc: 0.3694, Top 70th Acc: 0.4744, Bottom 30th Acc: 0.1212
Fold [2/5] Epoch [10/100] Initial Loss: 0.1408, Training Loss: 0.0238, Initial Validation Loss: 0.1337, Validation Loss: 0.0388,V Acc: 0.7748, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.3939
Fold [2/5] Epoch [20/100] Initial Loss: 0.1408, Training Loss: 0.0129, Initial Validation Loss: 0.1337, Validation Loss: 0.0366,V Acc: 0.7838, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.4848
Stopping early at Epoch (base 0): 20  Rolling back to Epoch (base 0): 15  Top Validation Acc: 0.9102564102564102
30 1 [array([0.5732416 , 0.05677663, 0.0220412 , 0.08084737, 0.2670932 ],
      dtype=float32)]
Fold [3/5] Epoch [0/100] Initial Loss: 0.1380, Training Loss: 0.1380, Initial Validation Loss: 0.1347, Validation Loss: 0.1347,V Acc: 0.3455, Top 70th Acc: 0.3636, Bottom 30th Acc: 0.3030
Fold [3/5] Epoch [10/100] Initial Loss: 0.1380, Training Loss: 0.0329, Initial Validation Loss: 0.1347, Validation Loss: 0.0388,V Acc: 0.8091, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.5152
Fold [3/5] Epoch [20/100] Initial Loss: 0.1380, Training Loss: 0.0158, Initial Validation Loss: 0.1347, Validation Loss: 0.0335,V Acc: 0.8455, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 22  Rolling back to Epoch (base 0): 17  Top Validation Acc: 0.922077922077922
Fold [4/5] Epoch [0/100] Initial Loss: 0.1412, Training Loss: 0.1412, Initial Validation Loss: 0.1352, Validation Loss: 0.1352,V Acc: 0.2477, Top 70th Acc: 0.3377, Bottom 30th Acc: 0.0312
Fold [4/5] Epoch [10/100] Initial Loss: 0.1412, Training Loss: 0.0351, Initial Validation Loss: 0.1352, Validation Loss: 0.0352,V Acc: 0.8716, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6875
Fold [4/5] Epoch [20/100] Initial Loss: 0.1412, Training Loss: 0.0162, Initial Validation Loss: 0.1352, Validation Loss: 0.0256,V Acc: 0.8807, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.6875
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.974025974025974
Fold [5/5] Epoch [0/100] Initial Loss: 0.1399, Training Loss: 0.1399, Initial Validation Loss: 0.1328, Validation Loss: 0.1328,V Acc: 0.2315, Top 70th Acc: 0.2895, Bottom 30th Acc: 0.0938
Fold [5/5] Epoch [10/100] Initial Loss: 0.1399, Training Loss: 0.0342, Initial Validation Loss: 0.1328, Validation Loss: 0.0381,V Acc: 0.8241, Top 70th Acc: 0.9211, Bottom 30th Acc: 0.5938
Fold [5/5] Epoch [20/100] Initial Loss: 0.1399, Training Loss: 0.0155, Initial Validation Loss: 0.1328, Validation Loss: 0.0289,V Acc: 0.8519, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.6250
Fold [5/5] Epoch [30/100] Initial Loss: 0.1399, Training Loss: 0.0123, Initial Validation Loss: 0.1328, Validation Loss: 0.0288,V Acc: 0.8426, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.6250
Stopping early at Epoch (base 0): 30  Rolling back to Epoch (base 0): 25  Top Validation Acc: 0.9342105263157895
Running train_nn.py with seed 31
CUDA:False
Training samples count:  550
Training on 40 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1398, Training Loss: 0.1398, Initial Validation Loss: 0.1398, Validation Loss: 0.1398,V Acc: 0.2321, Top 70th Acc: 0.2532, Bottom 30th Acc: 0.1818
Fold [1/5] Epoch [10/100] Initial Loss: 0.1398, Training Loss: 0.0440, Initial Validation Loss: 0.1398, Validation Loss: 0.0554,V Acc: 0.7411, Top 70th Acc: 0.8354, Bottom 30th Acc: 0.5152
Fold [2/5] Epoch [30/100] Initial Loss: 0.1415, Training Loss: 0.0211, Initial Validation Loss: 0.1296, Validation Loss: 0.0319,V Acc: 0.8378, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 33  Rolling back to Epoch (base 0): 28  Top Validation Acc: 0.9102564102564102
28 1 [array([0.4507404 , 0.04869821, 0.08408616, 0.24339566, 0.17307955],
      dtype=float32)]
Fold [3/5] Epoch [0/100] Initial Loss: 0.1393, Training Loss: 0.1393, Initial Validation Loss: 0.1304, Validation Loss: 0.1304,V Acc: 0.3727, Top 70th Acc: 0.4675, Bottom 30th Acc: 0.1515
Fold [3/5] Epoch [10/100] Initial Loss: 0.1393, Training Loss: 0.0386, Initial Validation Loss: 0.1304, Validation Loss: 0.0451,V Acc: 0.7818, Top 70th Acc: 0.8831, Bottom 30th Acc: 0.5455
Fold [3/5] Epoch [20/100] Initial Loss: 0.1393, Training Loss: 0.0258, Initial Validation Loss: 0.1304, Validation Loss: 0.0337,V Acc: 0.8636, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.7576
Stopping early at Epoch (base 0): 28  Rolling back to Epoch (base 0): 23  Top Validation Acc: 0.8961038961038961
Fold [4/5] Epoch [0/100] Initial Loss: 0.1389, Training Loss: 0.1389, Initial Validation Loss: 0.1369, Validation Loss: 0.1369,V Acc: 0.2661, Top 70th Acc: 0.3117, Bottom 30th Acc: 0.1562
Fold [4/5] Epoch [10/100] Initial Loss: 0.1389, Training Loss: 0.0412, Initial Validation Loss: 0.1369, Validation Loss: 0.0400,V Acc: 0.8440, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.5938
Fold [4/5] Epoch [20/100] Initial Loss: 0.1389, Training Loss: 0.0260, Initial Validation Loss: 0.1369, Validation Loss: 0.0276,V Acc: 0.9174, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.8125
Fold [4/5] Epoch [30/100] Initial Loss: 0.1389, Training Loss: 0.0235, Initial Validation Loss: 0.1369, Validation Loss: 0.0267,V Acc: 0.8991, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.7500
Stopping early at Epoch (base 0): 35  Rolling back to Epoch (base 0): 30  Top Validation Acc: 0.961038961038961
Fold [5/5] Epoch [0/100] Initial Loss: 0.1393, Training Loss: 0.1393, Initial Validation Loss: 0.1334, Validation Loss: 0.1334,V Acc: 0.2500, Top 70th Acc: 0.2895, Bottom 30th Acc: 0.1562
Fold [5/5] Epoch [10/100] Initial Loss: 0.1393, Training Loss: 0.0459, Initial Validation Loss: 0.1334, Validation Loss: 0.0450,V Acc: 0.7963, Top 70th Acc: 0.8816, Bottom 30th Acc: 0.5938
Fold [5/5] Epoch [20/100] Initial Loss: 0.1393, Training Loss: 0.0255, Initial Validation Loss: 0.1334, Validation Loss: 0.0321,V Acc: 0.8611, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.6562
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.9473684210526315
Running train_nn.py with seed 29
CUDA:False
Training samples count:  550
Training on 20 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1369, Training Loss: 0.1369, Initial Validation Loss: 0.1353, Validation Loss: 0.1353,V Acc: 0.3125, Top 70th Acc: 0.3797, Bottom 30th Acc: 0.1515
Fold [1/5] Epoch [10/100] Initial Loss: 0.1369, Training Loss: 0.0462, Initial Validation Loss: 0.1353, Validation Loss: 0.0514,V Acc: 0.7500, Top 70th Acc: 0.8987, Bottom 30th Acc: 0.3939
Fold [1/5] Epoch [20/100] Initial Loss: 0.1369, Training Loss: 0.0276, Initial Validation Loss: 0.1353, Validation Loss: 0.0323,V Acc: 0.8661, Top 70th Acc: 0.9620, Bottom 30th Acc: 0.6364
Fold [1/5] Epoch [30/100] Initial Loss: 0.1369, Training Loss: 0.0236, Initial Validation Loss: 0.1353, Validation Loss: 0.0297,V Acc: 0.8393, Top 70th Acc: 0.9747, Bottom 30th Acc: 0.5152
Stopping early at Epoch (base 0): 38  Rolling back to Epoch (base 0): 33  Top Validation Acc: 0.9620253164556962
Fold [2/5] Epoch [0/100] Initial Loss: 0.1373, Training Loss: 0.1373, Initial Validation Loss: 0.1367, Validation Loss: 0.1367,V Acc: 0.2703, Top 70th Acc: 0.3205, Bottom 30th Acc: 0.1515
Fold [2/5] Epoch [10/100] Initial Loss: 0.1373, Training Loss: 0.0358, Initial Validation Loss: 0.1367, Validation Loss: 0.0455,V Acc: 0.8018, Top 70th Acc: 0.8974, Bottom 30th Acc: 0.5758
Fold [2/5] Epoch [20/100] Initial Loss: 0.1373, Training Loss: 0.0246, Initial Validation Loss: 0.1367, Validation Loss: 0.0343,V Acc: 0.8198, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.5152
Fold [2/5] Epoch [30/100] Initial Loss: 0.1373, Training Loss: 0.0224, Initial Validation Loss: 0.1367, Validation Loss: 0.0338,V Acc: 0.8378, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 32  Rolling back to Epoch (base 0): 27  Top Validation Acc: 0.9487179487179487
29 1 [array([0.39789113, 0.07291968, 0.07238349, 0.27432916, 0.18247664],
      dtype=float32)]
Fold [3/5] Epoch [0/100] Initial Loss: 0.1419, Training Loss: 0.1419, Initial Validation Loss: 0.1314, Validation Loss: 0.1314,V Acc: 0.2636, Top 70th Acc: 0.3117, Bottom 30th Acc: 0.1515
Fold [3/5] Epoch [10/100] Initial Loss: 0.1419, Training Loss: 0.0303, Initial Validation Loss: 0.1314, Validation Loss: 0.0326,V Acc: 0.8273, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.6061
Fold [3/5] Epoch [20/100] Initial Loss: 0.1419, Training Loss: 0.0229, Initial Validation Loss: 0.1314, Validation Loss: 0.0324,V Acc: 0.8364, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 21  Rolling back to Epoch (base 0): 16  Top Validation Acc: 0.9090909090909091
Fold [4/5] Epoch [0/100] Initial Loss: 0.1403, Training Loss: 0.1403, Initial Validation Loss: 0.1261, Validation Loss: 0.1261,V Acc: 0.3394, Top 70th Acc: 0.4026, Bottom 30th Acc: 0.1875
Fold [4/5] Epoch [10/100] Initial Loss: 0.1403, Training Loss: 0.0384, Initial Validation Loss: 0.1261, Validation Loss: 0.0430,V Acc: 0.7431, Top 70th Acc: 0.8831, Bottom 30th Acc: 0.4062
Fold [4/5] Epoch [20/100] Initial Loss: 0.1403, Training Loss: 0.0238, Initial Validation Loss: 0.1261, Validation Loss: 0.0379,V Acc: 0.7523, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.3750
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.9090909090909091
Fold [5/5] Epoch [0/100] Initial Loss: 0.1423, Training Loss: 0.1423, Initial Validation Loss: 0.1336, Validation Loss: 0.1336,V Acc: 0.2500, Top 70th Acc: 0.3026, Bottom 30th Acc: 0.1250
Fold [5/5] Epoch [10/100] Initial Loss: 0.1423, Training Loss: 0.0373, Initial Validation Loss: 0.1336, Validation Loss: 0.0416,V Acc: 0.8056, Top 70th Acc: 0.8816, Bottom 30th Acc: 0.6250
Fold [5/5] Epoch [20/100] Initial Loss: 0.1423, Training Loss: 0.0239, Initial Validation Loss: 0.1336, Validation Loss: 0.0343,V Acc: 0.8241, Top 70th Acc: 0.9079, Bottom 30th Acc: 0.6250
Fold [5/5] Epoch [30/100] Initial Loss: 0.1423, Training Loss: 0.0208, Initial Validation Loss: 0.1336, Validation Loss: 0.0338,V Acc: 0.8241, Top 70th Acc: 0.9079, Bottom 30th Acc: 0.6250
Fold [5/5] Epoch [40/100] Initial Loss: 0.1423, Training Loss: 0.0196, Initial Validation Loss: 0.1336, Validation Loss: 0.0334,V Acc: 0.8333, Top 70th Acc: 0.9079, Bottom 30th Acc: 0.6562
Fold [5/5] Epoch [50/100] Initial Loss: 0.1423, Training Loss: 0.0188, Initial Validation Loss: 0.1336, Validation Loss: 0.0331,V Acc: 0.8333, Top 70th Acc: 0.9079, Bottom 30th Acc: 0.6562
Stopping early at Epoch (base 0): 55  Rolling back to Epoch (base 0): 50  Top Validation Acc: 0.9078947368421053
Running train_nn.py with seed 30
CUDA:False
Training samples count:  550
Training on 20 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1399, Training Loss: 0.1399, Initial Validation Loss: 0.1327, Validation Loss: 0.1327,V Acc: 0.3304, Top 70th Acc: 0.3671, Bottom 30th Acc: 0.2424
Fold [1/5] Epoch [10/100] Initial Loss: 0.1399, Training Loss: 0.0329, Initial Validation Loss: 0.1327, Validation Loss: 0.0371,V Acc: 0.8482, Top 70th Acc: 0.9241, Bottom 30th Acc: 0.6667
Fold [1/5] Epoch [20/100] Initial Loss: 0.1399, Training Loss: 0.0240, Initial Validation Loss: 0.1327, Validation Loss: 0.0342,V Acc: 0.8393, Top 70th Acc: 0.9114, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.9240506329113924
Fold [2/5] Epoch [0/100] Initial Loss: 0.1356, Training Loss: 0.1356, Initial Validation Loss: 0.1286, Validation Loss: 0.1286,V Acc: 0.4144, Top 70th Acc: 0.4744, Bottom 30th Acc: 0.2727
Fold [2/5] Epoch [10/100] Initial Loss: 0.1356, Training Loss: 0.0310, Initial Validation Loss: 0.1286, Validation Loss: 0.0416,V Acc: 0.8198, Top 70th Acc: 0.8846, Bottom 30th Acc: 0.6667
Fold [4/5] Epoch [10/100] Initial Loss: 0.1344, Training Loss: 0.0247, Initial Validation Loss: 0.1248, Validation Loss: 0.0354,V Acc: 0.8165, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.4375
Stopping early at Epoch (base 0): 19  Rolling back to Epoch (base 0): 14  Top Validation Acc: 0.922077922077922
Fold [5/5] Epoch [0/100] Initial Loss: 0.1348, Training Loss: 0.1348, Initial Validation Loss: 0.1164, Validation Loss: 0.1164,V Acc: 0.5000, Top 70th Acc: 0.5789, Bottom 30th Acc: 0.3125
Fold [5/5] Epoch [10/100] Initial Loss: 0.1348, Training Loss: 0.0200, Initial Validation Loss: 0.1164, Validation Loss: 0.0236,V Acc: 0.8796, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.6875
Stopping early at Epoch (base 0): 14  Rolling back to Epoch (base 0): 9  Top Validation Acc: 0.9342105263157895
Running train_nn.py with seed 39
CUDA:False
Training samples count:  550
Training on 21 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1281, Training Loss: 0.1281, Initial Validation Loss: 0.1115, Validation Loss: 0.1115,V Acc: 0.5000, Top 70th Acc: 0.6203, Bottom 30th Acc: 0.2121
Fold [1/5] Epoch [10/100] Initial Loss: 0.1281, Training Loss: 0.0222, Initial Validation Loss: 0.1115, Validation Loss: 0.0284,V Acc: 0.8750, Top 70th Acc: 0.9620, Bottom 30th Acc: 0.6667
Fold [1/5] Epoch [20/100] Initial Loss: 0.1281, Training Loss: 0.0147, Initial Validation Loss: 0.1115, Validation Loss: 0.0293,V Acc: 0.8750, Top 70th Acc: 0.9367, Bottom 30th Acc: 0.7273
Stopping early at Epoch (base 0): 28  Rolling back to Epoch (base 0): 23  Top Validation Acc: 0.9746835443037974
Fold [2/5] Epoch [0/100] Initial Loss: 0.1379, Training Loss: 0.1379, Initial Validation Loss: 0.1306, Validation Loss: 0.1306,V Acc: 0.4865, Top 70th Acc: 0.5385, Bottom 30th Acc: 0.3636
Fold [2/5] Epoch [10/100] Initial Loss: 0.1379, Training Loss: 0.0266, Initial Validation Loss: 0.1306, Validation Loss: 0.0218,V Acc: 0.9099, Top 70th Acc: 0.9872, Bottom 30th Acc: 0.7273
Fold [2/5] Epoch [20/100] Initial Loss: 0.1379, Training Loss: 0.0171, Initial Validation Loss: 0.1306, Validation Loss: 0.0186,V Acc: 0.9099, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.7576
Stopping early at Epoch (base 0): 28  Rolling back to Epoch (base 0): 23  Top Validation Acc: 0.9743589743589743
Fold [3/5] Epoch [0/100] Initial Loss: 0.1343, Training Loss: 0.1343, Initial Validation Loss: 0.1183, Validation Loss: 0.1183,V Acc: 0.5455, Top 70th Acc: 0.6364, Bottom 30th Acc: 0.3333
Fold [3/5] Epoch [10/100] Initial Loss: 0.1343, Training Loss: 0.0211, Initial Validation Loss: 0.1183, Validation Loss: 0.0259,V Acc: 0.8545, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 16  Rolling back to Epoch (base 0): 11  Top Validation Acc: 0.974025974025974
Fold [4/5] Epoch [0/100] Initial Loss: 0.1312, Training Loss: 0.1312, Initial Validation Loss: 0.1174, Validation Loss: 0.1174,V Acc: 0.4587, Top 70th Acc: 0.4935, Bottom 30th Acc: 0.3750
Fold [4/5] Epoch [10/100] Initial Loss: 0.1312, Training Loss: 0.0199, Initial Validation Loss: 0.1174, Validation Loss: 0.0339,V Acc: 0.8165, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.4375
Fold [4/5] Epoch [20/100] Initial Loss: 0.1312, Training Loss: 0.0127, Initial Validation Loss: 0.1174, Validation Loss: 0.0321,V Acc: 0.8349, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.5625
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.974025974025974
39 3 [array([0.81451875, 0.01118661, 0.03224415, 0.07322875, 0.0688217 ],
      dtype=float32)]
Fold [5/5] Epoch [0/100] Initial Loss: 0.1334, Training Loss: 0.1334, Initial Validation Loss: 0.1113, Validation Loss: 0.1113,V Acc: 0.5648, Top 70th Acc: 0.6316, Bottom 30th Acc: 0.4062
Fold [5/5] Epoch [10/100] Initial Loss: 0.1334, Training Loss: 0.0220, Initial Validation Loss: 0.1113, Validation Loss: 0.0316,V Acc: 0.8426, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.6250
Stopping early at Epoch (base 0): 17  Rolling back to Epoch (base 0): 12  Top Validation Acc: 0.9868421052631579
Running train_nn.py with seed 40
CUDA:False
Training samples count:  550
Training on 21 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1358, Training Loss: 0.1358, Initial Validation Loss: 0.1272, Validation Loss: 0.1272,V Acc: 0.4018, Top 70th Acc: 0.4810, Bottom 30th Acc: 0.2121
Fold [1/5] Epoch [10/100] Initial Loss: 0.1358, Training Loss: 0.0291, Initial Validation Loss: 0.1272, Validation Loss: 0.0270,V Acc: 0.8839, Top 70th Acc: 1.0000, Bottom 30th Acc: 0.6061
Fold [1/5] Epoch [20/100] Initial Loss: 0.1358, Training Loss: 0.0168, Initial Validation Loss: 0.1272, Validation Loss: 0.0227,V Acc: 0.9107, Top 70th Acc: 0.9873, Bottom 30th Acc: 0.7273
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.9746835443037974
Fold [2/5] Epoch [0/100] Initial Loss: 0.1386, Training Loss: 0.1386, Initial Validation Loss: 0.1259, Validation Loss: 0.1259,V Acc: 0.5045, Top 70th Acc: 0.6154, Bottom 30th Acc: 0.2424
Fold [2/5] Epoch [10/100] Initial Loss: 0.1386, Training Loss: 0.0225, Initial Validation Loss: 0.1259, Validation Loss: 0.0269,V Acc: 0.8559, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.6061
Fold [2/5] Epoch [20/100] Initial Loss: 0.1386, Training Loss: 0.0162, Initial Validation Loss: 0.1259, Validation Loss: 0.0269,V Acc: 0.8649, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 21  Rolling back to Epoch (base 0): 16  Top Validation Acc: 0.9743589743589743
40 1 [array([0.81619024, 0.03070707, 0.0245676 , 0.08287811, 0.04565699],
      dtype=float32)]
Fold [3/5] Epoch [0/100] Initial Loss: 0.1322, Training Loss: 0.1322, Initial Validation Loss: 0.1258, Validation Loss: 0.1258,V Acc: 0.4909, Top 70th Acc: 0.5195, Bottom 30th Acc: 0.4242
Fold [3/5] Epoch [10/100] Initial Loss: 0.1322, Training Loss: 0.0201, Initial Validation Loss: 0.1258, Validation Loss: 0.0293,V Acc: 0.8545, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 19  Rolling back to Epoch (base 0): 14  Top Validation Acc: 0.961038961038961
Fold [4/5] Epoch [0/100] Initial Loss: 0.1344, Training Loss: 0.1344, Initial Validation Loss: 0.1140, Validation Loss: 0.1140,V Acc: 0.4404, Top 70th Acc: 0.4286, Bottom 30th Acc: 0.4688
Fold [4/5] Epoch [10/100] Initial Loss: 0.1344, Training Loss: 0.0283, Initial Validation Loss: 0.1140, Validation Loss: 0.0321,V Acc: 0.8440, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.5625
Fold [4/5] Epoch [20/100] Initial Loss: 0.1344, Training Loss: 0.0159, Initial Validation Loss: 0.1140, Validation Loss: 0.0270,V Acc: 0.8349, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.5312
Stopping early at Epoch (base 0): 21  Rolling back to Epoch (base 0): 16  Top Validation Acc: 0.961038961038961
Fold [5/5] Epoch [0/100] Initial Loss: 0.1350, Training Loss: 0.1350, Initial Validation Loss: 0.1262, Validation Loss: 0.1262,V Acc: 0.5556, Top 70th Acc: 0.6053, Bottom 30th Acc: 0.4375
Fold [5/5] Epoch [10/100] Initial Loss: 0.1350, Training Loss: 0.0233, Initial Validation Loss: 0.1262, Validation Loss: 0.0254,V Acc: 0.8796, Top 70th Acc: 0.9868, Bottom 30th Acc: 0.6250
Stopping early at Epoch (base 0): 18  Rolling back to Epoch (base 0): 13  Top Validation Acc: 0.9868421052631579
Running train_nn.py with seed 41
CUDA:False
Training samples count:  550
Training on 21 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1337, Training Loss: 0.1337, Initial Validation Loss: 0.1260, Validation Loss: 0.1260,V Acc: 0.4732, Top 70th Acc: 0.5443, Bottom 30th Acc: 0.3030
Fold [1/5] Epoch [10/100] Initial Loss: 0.1337, Training Loss: 0.0185, Initial Validation Loss: 0.1260, Validation Loss: 0.0242,V Acc: 0.9286, Top 70th Acc: 0.9747, Bottom 30th Acc: 0.8182
Stopping early at Epoch (base 0): 18  Rolling back to Epoch (base 0): 13  Top Validation Acc: 0.9873417721518988
Fold [2/5] Epoch [0/100] Initial Loss: 0.1415, Training Loss: 0.1415, Initial Validation Loss: 0.1290, Validation Loss: 0.1290,V Acc: 0.3964, Top 70th Acc: 0.3974, Bottom 30th Acc: 0.3939
Fold [2/5] Epoch [10/100] Initial Loss: 0.1415, Training Loss: 0.0172, Initial Validation Loss: 0.1290, Validation Loss: 0.0322,V Acc: 0.8378, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0):/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)

Fold [2/5] Epoch [0/100] Initial Loss: 0.1365, Training Loss: 0.1365, Initial Validation Loss: 0.1334, Validation Loss: 0.1334,V Acc: 0.3243, Top 70th Acc: 0.3462, Bottom 30th Acc: 0.2727
Fold [2/5] Epoch [10/100] Initial Loss: 0.1365, Training Loss: 0.0146, Initial Validation Loss: 0.1334, Validation Loss: 0.0355,V Acc: 0.8649, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.7273
Fold [2/5] Epoch [20/100] Initial Loss: 0.1365, Training Loss: 0.0052, Initial Validation Loss: 0.1334, Validation Loss: 0.0317,V Acc: 0.8649, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.7273
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.9358974358974359
Fold [3/5] Epoch [0/100] Initial Loss: 0.1387, Training Loss: 0.1387, Initial Validation Loss: 0.1344, Validation Loss: 0.1344,V Acc: 0.2545, Top 70th Acc: 0.3636, Bottom 30th Acc: 0.0000
Fold [3/5] Epoch [10/100] Initial Loss: 0.1387, Training Loss: 0.0123, Initial Validation Loss: 0.1344, Validation Loss: 0.0300,V Acc: 0.9000, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.8182
Fold [3/5] Epoch [20/100] Initial Loss: 0.1387, Training Loss: 0.0049, Initial Validation Loss: 0.1344, Validation Loss: 0.0282,V Acc: 0.8818, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.961038961038961
Fold [4/5] Epoch [0/100] Initial Loss: 0.1383, Training Loss: 0.1383, Initial Validation Loss: 0.1344, Validation Loss: 0.1344,V Acc: 0.2936, Top 70th Acc: 0.3377, Bottom 30th Acc: 0.1875
Fold [4/5] Epoch [10/100] Initial Loss: 0.1383, Training Loss: 0.0320, Initial Validation Loss: 0.1344, Validation Loss: 0.0489,V Acc: 0.8073, Top 70th Acc: 0.8961, Bottom 30th Acc: 0.5938
Fold [4/5] Epoch [20/100] Initial Loss: 0.1383, Training Loss: 0.0065, Initial Validation Loss: 0.1344, Validation Loss: 0.0345,V Acc: 0.8440, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.5938
Fold [4/5] Epoch [30/100] Initial Loss: 0.1383, Training Loss: 0.0046, Initial Validation Loss: 0.1344, Validation Loss: 0.0324,V Acc: 0.8716, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.6562
Fold [4/5] Epoch [40/100] Initial Loss: 0.1383, Training Loss: 0.0041, Initial Validation Loss: 0.1344, Validation Loss: 0.0309,V Acc: 0.8899, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.7188
Fold [4/5] Epoch [50/100] Initial Loss: 0.1383, Training Loss: 0.0039, Initial Validation Loss: 0.1344, Validation Loss: 0.0292,V Acc: 0.8991, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.7500
Fold [4/5] Epoch [60/100] Initial Loss: 0.1383, Training Loss: 0.0038, Initial Validation Loss: 0.1344, Validation Loss: 0.0288,V Acc: 0.8899, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.7188
Stopping early at Epoch (base 0): 62  Rolling back to Epoch (base 0): 57  Top Validation Acc: 0.961038961038961
Fold [5/5] Epoch [0/100] Initial Loss: 0.1438, Training Loss: 0.1438, Initial Validation Loss: 0.1298, Validation Loss: 0.1298,V Acc: 0.2593, Top 70th Acc: 0.2895, Bottom 30th Acc: 0.1875
Fold [5/5] Epoch [10/100] Initial Loss: 0.1438, Training Loss: 0.0296, Initial Validation Loss: 0.1298, Validation Loss: 0.0374,V Acc: 0.7870, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.4375
Fold [5/5] Epoch [20/100] Initial Loss: 0.1438, Training Loss: 0.0066, Initial Validation Loss: 0.1298, Validation Loss: 0.0259,V Acc: 0.8241, Top 70th Acc: 0.9868, Bottom 30th Acc: 0.4375
Fold [5/5] Epoch [30/100] Initial Loss: 0.1438, Training Loss: 0.0044, Initial Validation Loss: 0.1298, Validation Loss: 0.0226,V Acc: 0.8704, Top 70th Acc: 0.9868, Bottom 30th Acc: 0.5938
Fold [5/5] Epoch [40/100] Initial Loss: 0.1438, Training Loss: 0.0039, Initial Validation Loss: 0.1298, Validation Loss: 0.0212,V Acc: 0.8796, Top 70th Acc: 0.9868, Bottom 30th Acc: 0.6250
Fold [5/5] Epoch [50/100] Initial Loss: 0.1438, Training Loss: 0.0038, Initial Validation Loss: 0.1298, Validation Loss: 0.0203,V Acc: 0.8889, Top 70th Acc: 0.9737, Bottom 30th Acc: 0.6875
Fold [5/5] Epoch [60/100] Initial Loss: 0.1438, Training Loss: 0.0037, Initial Validation Loss: 0.1298, Validation Loss: 0.0196,V Acc: 0.8981, Top 70th Acc: 0.9737, Bottom 30th Acc: 0.7188
Stopping early at Epoch (base 0): 67  Rolling back to Epoch (base 0): 62  Top Validation Acc: 0.9736842105263158
Running train_nn.py with seed 22
CUDA:False
Training samples count:  550
Training on 162 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1415, Training Loss: 0.1415, Initial Validation Loss: 0.1351, Validation Loss: 0.1351,V Acc: 0.2500, Top 70th Acc: 0.2911, Bottom 30th Acc: 0.1515
Fold [1/5] Epoch [10/100] Initial Loss: 0.1415, Training Loss: 0.0359, Initial Validation Loss: 0.1351, Validation Loss: 0.0567,V Acc: 0.7232, Top 70th Acc: 0.8608, Bottom 30th Acc: 0.3939
Fold [1/5] Epoch [20/100] Initial Loss: 0.1415, Training Loss: 0.0058, Initial Validation Loss: 0.1351, Validation Loss: 0.0362,V Acc: 0.8214, Top 70th Acc: 0.9367, Bottom 30th Acc: 0.5455
Fold [1/5] Epoch [30/100] Initial Loss: 0.1415, Training Loss: 0.0035, Initial Validation Loss: 0.1351, Validation Loss: 0.0345,V Acc: 0.8125, Top 70th Acc: 0.9620, Bottom 30th Acc: 0.4545
Fold [1/5] Epoch [40/100] Initial Loss: 0.1415, Training Loss: 0.0032, Initial Validation Loss: 0.1351, Validation Loss: 0.0336,V Acc: 0.8125, Top 70th Acc: 0.9620, Bottom 30th Acc: 0.4545
Fold [1/5] Epoch [50/100] Initial Loss: 0.1415, Training Loss: 0.0031, Initial Validation Loss: 0.1351, Validation Loss: 0.0328,V Acc: 0.8036, Top 70th Acc: 0.9620, Bottom 30th Acc: 0.4242
Stopping early at Epoch (base 0): 57  Rolling back to Epoch (base 0): 52  Top Validation Acc: 0.9620253164556962
22 0 [array([0.2396705 , 0.05095509, 0.08346181, 0.33455566, 0.29135695],
      dtype=float32)]
Fold [2/5] Epoch [0/100] Initial Loss: 0.1401, Training Loss: 0.1401, Initial Validation Loss: 0.1359, Validation Loss: 0.1359,V Acc: 0.3964, Top 70th Acc: 0.4359, Bottom 30th Acc: 0.3030
Fold [2/5] Epoch [10/100] Initial Loss: 0.1401, Training Loss: 0.0177, Initial Validation Loss: 0.1359, Validation Loss: 0.0374,V Acc: 0.8108, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.5152
Fold [2/5] Epoch [20/100] Initial Loss: 0.1401, Training Loss: 0.0048, Initial Validation Loss: 0.1359, Validation Loss: 0.0311,V Acc: 0.8649, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.9230769230769231
Fold [3/5] Epoch [0/100] Initial Loss: 0.1409, Training Loss: 0.1409, Initial Validation Loss: 0.1334, Validation Loss: 0.1334,V Acc: 0.2727, Top 70th Acc: 0.2857, Bottom 30th Acc: 0.2424
Fold [3/5] Epoch [10/100] Initial Loss: 0.1409, Training Loss: 0.0243, Initial Validation Loss: 0.1334, Validation Loss: 0.0364,V Acc: 0.8455, Top 70th Acc: 0.8831, Bottom 30th Acc: 0.7576
Fold [3/5] Epoch [20/100] Initial Loss: 0.1409, Training Loss: 0.0056, Initial Validation Loss: 0.1334, Validation Loss: 0.0269,V Acc: 0.8727, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.6667
Fold [3/5] Epoch [30/100] Initial Loss: 0.1409, Training Loss: 0.0041, Initial Validation Loss: 0.1334, Validation Loss: 0.0260,V Acc: 0.8636, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 32  Rolling back to Epoch (base 0): 27  Top Validation Acc: 0.974025974025974
Fold [4/5] Epoch [0/100] Initial Loss: 0.1425, Training Loss: 0.1425, Initial Validation Loss: 0.1320, Validation Loss: 0.1320,V Acc: 0.2477, Top 70th Acc: 0.3117, Bottom 30th Acc: 0.0938
Fold [4/5] Epoch [10/100] Initial Loss: 0.1425, Training Loss: 0.0132, Initial Validation Loss: 0.1320, Validation Loss: 0.0349,V Acc: 0.8165, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.5625
Fold [4/5] Epoch [20/100] Initial Loss: 0.1425, Training Loss: 0.0046, Initial Validation Loss: 0.1320, Validation Loss: 0.0334,V Acc: 0.8073, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.5312
Stopping early at Epoch (base 0): 21  Rolling back to Epoch (base 0): 16  Top Validation Acc: 0.922077922077922
Fold [5/5] Epoch [0/100] Initial Loss: 0.1383, Training Loss: 0.1383, Initial Validation Loss: 0.1367, Validation Loss: 0.1367,V Acc: 0.2500, Top 70th Acc: 0.3158, Bottom 30th Acc: 0.0938
Fold [5/5] Epoch [10/100] Initial Loss: 0.1383, Training Loss: 0.0220, Initial Validation Loss: 0.1367, Validation Loss: 0.0378,V Acc: 0.8519, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.5938
Stopping early at Epoch (base 0): 29  Rolling back to Epoch (base 0): 24  Top Validation Acc: 0.9102564102564102
28 1 [array([0.5939234 , 0.09208169, 0.02071665, 0.1436232 , 0.14965507],
      dtype=float32)]
Fold [3/5] Epoch [0/100] Initial Loss: 0.1407, Training Loss: 0.1407, Initial Validation Loss: 0.1365, Validation Loss: 0.1365,V Acc: 0.2545, Top 70th Acc: 0.2727, Bottom 30th Acc: 0.2121
Fold [3/5] Epoch [10/100] Initial Loss: 0.1407, Training Loss: 0.0355, Initial Validation Loss: 0.1365, Validation Loss: 0.0442,V Acc: 0.7818, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.4848
Fold [3/5] Epoch [20/100] Initial Loss: 0.1407, Training Loss: 0.0192, Initial Validation Loss: 0.1365, Validation Loss: 0.0295,V Acc: 0.8727, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 27  Rolling back to Epoch (base 0): 22  Top Validation Acc: 0.948051948051948
Fold [4/5] Epoch [0/100] Initial Loss: 0.1419, Training Loss: 0.1419, Initial Validation Loss: 0.1356, Validation Loss: 0.1356,V Acc: 0.3945, Top 70th Acc: 0.4805, Bottom 30th Acc: 0.1875
Fold [4/5] Epoch [10/100] Initial Loss: 0.1419, Training Loss: 0.0346, Initial Validation Loss: 0.1356, Validation Loss: 0.0348,V Acc: 0.8440, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.6250
Fold [4/5] Epoch [20/100] Initial Loss: 0.1419, Training Loss: 0.0195, Initial Validation Loss: 0.1356, Validation Loss: 0.0269,V Acc: 0.8624, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.6250
Fold [4/5] Epoch [30/100] Initial Loss: 0.1419, Training Loss: 0.0163, Initial Validation Loss: 0.1356, Validation Loss: 0.0267,V Acc: 0.8716, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.6562
Stopping early at Epoch (base 0): 31  Rolling back to Epoch (base 0): 26  Top Validation Acc: 0.961038961038961
Fold [5/5] Epoch [0/100] Initial Loss: 0.1385, Training Loss: 0.1385, Initial Validation Loss: 0.1315, Validation Loss: 0.1315,V Acc: 0.3056, Top 70th Acc: 0.4211, Bottom 30th Acc: 0.0312
Fold [5/5] Epoch [10/100] Initial Loss: 0.1385, Training Loss: 0.0339, Initial Validation Loss: 0.1315, Validation Loss: 0.0335,V Acc: 0.8426, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.5625
Fold [5/5] Epoch [20/100] Initial Loss: 0.1385, Training Loss: 0.0184, Initial Validation Loss: 0.1315, Validation Loss: 0.0295,V Acc: 0.8704, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.6562
Stopping early at Epoch (base 0): 22  Rolling back to Epoch (base 0): 17  Top Validation Acc: 0.9342105263157895
Running train_nn.py with seed 29
CUDA:False
Training samples count:  550
Training on 30 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1367, Training Loss: 0.1367, Initial Validation Loss: 0.1365, Validation Loss: 0.1365,V Acc: 0.2857, Top 70th Acc: 0.3797, Bottom 30th Acc: 0.0606
Fold [1/5] Epoch [10/100] Initial Loss: 0.1367, Training Loss: 0.0330, Initial Validation Loss: 0.1365, Validation Loss: 0.0356,V Acc: 0.8482, Top 70th Acc: 0.9620, Bottom 30th Acc: 0.5758
Fold [1/5] Epoch [20/100] Initial Loss: 0.1367, Training Loss: 0.0186, Initial Validation Loss: 0.1365, Validation Loss: 0.0290,V Acc: 0.8571, Top 70th Acc: 0.9747, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.9873417721518988
Fold [2/5] Epoch [0/100] Initial Loss: 0.1388, Training Loss: 0.1388, Initial Validation Loss: 0.1382, Validation Loss: 0.1382,V Acc: 0.3333, Top 70th Acc: 0.4103, Bottom 30th Acc: 0.1515
Fold [2/5] Epoch [10/100] Initial Loss: 0.1388, Training Loss: 0.0354, Initial Validation Loss: 0.1382, Validation Loss: 0.0446,V Acc: 0.8018, Top 70th Acc: 0.8974, Bottom 30th Acc: 0.5758
Fold [2/5] Epoch [20/100] Initial Loss: 0.1388, Training Loss: 0.0207, Initial Validation Loss: 0.1382, Validation Loss: 0.0306,V Acc: 0.8739, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.6667
Fold [2/5] Epoch [30/100] Initial Loss: 0.1388, Training Loss: 0.0174, Initial Validation Loss: 0.1382, Validation Loss: 0.0293,V Acc: 0.8739, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 38  Rolling back to Epoch (base 0): 33  Top Validation Acc: 0.9615384615384616
29 1 [array([0.75002444, 0.07791991, 0.0257633 , 0.06567662, 0.08061573],
      dtype=float32)]
Fold [3/5] Epoch [0/100] Initial Loss: 0.1395, Training Loss: 0.1395, Initial Validation Loss: 0.1292, Validation Loss: 0.1292,V Acc: 0.3182, Top 70th Acc: 0.3636, Bottom 30th Acc: 0.2121
Fold [3/5] Epoch [10/100] Initial Loss: 0.1395, Training Loss: 0.0368, Initial Validation Loss: 0.1292, Validation Loss: 0.0432,V Acc: 0.7727, Top 70th Acc: 0.8961, Bottom 30th Acc: 0.4848
Fold [3/5] Epoch [20/100] Initial Loss: 0.1395, Training Loss: 0.0181, Initial Validation Loss: 0.1292, Validation Loss: 0.0300,V Acc: 0.8636, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.7273
Fold [3/5] Epoch [30/100] Initial Loss: 0.1395, Training Loss: 0.0148, Initial Validation Loss: 0.1292, Validation Loss: 0.0288,V Acc: 0.8545, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 30  Rolling back to Epoch (base 0): 25  Top Validation Acc: 0.961038961038961
Fold [4/5] Epoch [0/100] Initial Loss: 0.1431, Training Loss: 0.1431, Initial Validation Loss: 0.1301, Validation Loss: 0.1301,V Acc: 0.2477, Top 70th Acc: 0.3377, Bottom 30th Acc: 0.0312
Fold [4/5] Epoch [10/100] Initial Loss: 0.1431, Training Loss: 0.0331, Initial Validation Loss: 0.1301, Validation Loss: 0.0401,V Acc: 0.7706, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.4375
Stopping early at Epoch (base 0): 17  Rolling back to Epoch (base 0): 12  Top Validation Acc: 0.9090909090909091
Fold [5/5] Epoch [0/100] Initial Loss: 0.1431, Training Loss: 0.1431, Initial Validation Loss: 0.1345, Validation Loss: 0.1345,V Acc: 0.2593, Top 70th Acc: 0.2895, Bottom 30th Acc: 0.1875
Fold [5/5] Epoch [10/100] Initial Loss: 0.1431, Training Loss: 0.0417, Initial Validation Loss: 0.1345, Validation Loss: 0.0464,V Acc: 0.8056, Top 70th Acc: 0.8684, Bottom 30th Acc: 0.6562
Fold [5/5] Epoch [20/100] Initial Loss: 0.1431, Training Loss: 0.0180, Initial Validation Loss: 0.1345, Validation Loss: 0.0371,V Acc: 0.8241, Top 70th Acc: 0.9079, Bottom 30th Acc: 0.6250
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.8947368421052632
Running train_nn.py with seed 30
CUDA:False
Training samples count:  550
Training on 30 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1386, Training Loss: 0.1386, Initial Validation Loss: 0.1342, Validation Loss: 0.1342,V Acc: 0.2589, Top 70th Acc: 0.3291, Bottom 30th Acc: 0.0909
Fold [1/5] Epoch [10/100] Initial Loss: 0.1386, Training Loss: 0.0358, Initial Validation Loss: 0.1342, Validation Loss: 0.0446,V Acc: 0.7946, Top 70th Acc: 0.8987, Bottom 30th Acc: 0.5455
Fold [1/5] Epoch [20/100] Initial Loss: 0.1386, Training Loss: 0.0223, Initial Validation Loss: 0.1342, Validation Loss: 0.0409,V Acc: 0.7857, Top 70th Acc: 0.8861, Bottom 30th Acc: 0.5455
Fold [1/5] Epoch [30/100] Initial Loss: 0.1386, Training Loss: 0.0168, Initial Validation Loss: 0.1342, Validation Loss: 0.0368,V Acc: 0.8304, Top 70th Acc: 0.9114, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 38  Rolling back to Epoch (base 0): 33  Top Validation Acc: 0.8987341772151899
Fold [2/5] Epoch [0/100] Initial Loss: 0.1382, Training Loss: 0.1382, Initial Validation Loss: 0.1345, Validation Loss: 0.1345,V Acc: 0.3423, Top 70th Acc: 0.4103, Bottom 30th Acc: 0.1818
Fold [2/5] Epoch [10/100] Initial Loss: 0.1382, Training Loss: 0.0302, Initial Validation Loss: 0.1345, Validation Loss: 0.0508,V Acc: 0.7297, Top 70th Acc: 0.8590, Bottom 30th Acc: 0.4242
Fold [2/5] Epoch [20/100] Initial Loss: 0.1382, Training Loss: 0.0190, Initial Validation Loss: 0.1345, Validation Loss: 0.0421,V Acc: 0.7928, Top 70th Acc: 0.8974, Bottom 30th Acc: 0.5455
Fold [2/5] Epoch [30/100] Initial Loss: 0.1382, Training Loss: 0.0156, Initial Validation Loss: 0.1345, Validation Loss: 0.0409,V Acc: 0.8018, Top 70th Acc: 0.8846, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 36  Rolling back to Epoch (base 0): 31  Top Validation Acc: 0.8717948717948718
30 1 [array([0.6124874 , 0.07126011, 0.0781588 , 0.06754888, 0.17054492],
      dtype=float32)]
Fold [3/5] Epoch [0/100] Initial Loss: 0.1412, Training Loss: 0.1412, Initial Validation Loss: 0.1350, Validation Loss: 0.1350,V Acc: 0.3727, Top 70th Acc: 0.3766, Bottom 30th Acc: 0.3636training rf with seed 1
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 40 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 2
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 40 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 3
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 40 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 4
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 40 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 5
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 40 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 6
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 40 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 7
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 40 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 8
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 40 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 9
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 40 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 10
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 40 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 11
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 40 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 12
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 40 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 13
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 40 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 14
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 40 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 15
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 40 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 16
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 40 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 17
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 40 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 18
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 40 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 19
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 40 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 20
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 40 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 21
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 40 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 22
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 40 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 23
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 40 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 24
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 40 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 25
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 40 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 26
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 40 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 27
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 40 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 28
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 40 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 29
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 40 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 30
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 40 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 31
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 40 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 32
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 40 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 33
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 40 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 34
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 40 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 35
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 40 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 36
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 40 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 37
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 40 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 38
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 40 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 39
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 40 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 40
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 40 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 41
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 40 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 42
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 40 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 43
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 40 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 44
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 40 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 45
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)

Fold [1/5] Epoch [30/100] Initial Loss: 0.1401, Training Loss: 0.0813, Initial Validation Loss: 0.1380, Validation Loss: 0.0698,V Acc: 0.7054, Top 70th Acc: 0.8101, Bottom 30th Acc: 0.4545
Stopping early at Epoch (base 0): 36  Rolling back to Epoch (base 0): 31  Top Validation Acc: 0.810126582278481
Fold [2/5] Epoch [0/100] Initial Loss: 0.1368, Training Loss: 0.1368, Initial Validation Loss: 0.1348, Validation Loss: 0.1348,V Acc: 0.3604, Top 70th Acc: 0.3846, Bottom 30th Acc: 0.3030
Fold [2/5] Epoch [10/100] Initial Loss: 0.1368, Training Loss: 0.0756, Initial Validation Loss: 0.1348, Validation Loss: 0.0978,V Acc: 0.5586, Top 70th Acc: 0.6923, Bottom 30th Acc: 0.2424
Stopping early at Epoch (base 0): 19  Rolling back to Epoch (base 0): 14  Top Validation Acc: 0.6794871794871795
29 1 [array([0.10900486, 0.36988032, 0.15946358, 0.19962023, 0.16203105],
      dtype=float32)]
Fold [3/5] Epoch [0/100] Initial Loss: 0.1339, Training Loss: 0.1339, Initial Validation Loss: 0.1167, Validation Loss: 0.1167,V Acc: 0.6182, Top 70th Acc: 0.7403, Bottom 30th Acc: 0.3333
Fold [3/5] Epoch [10/100] Initial Loss: 0.1339, Training Loss: 0.0809, Initial Validation Loss: 0.1167, Validation Loss: 0.0760,V Acc: 0.6455, Top 70th Acc: 0.7532, Bottom 30th Acc: 0.3939
Fold [3/5] Epoch [20/100] Initial Loss: 0.1339, Training Loss: 0.0795, Initial Validation Loss: 0.1167, Validation Loss: 0.0741,V Acc: 0.6636, Top 70th Acc: 0.7662, Bottom 30th Acc: 0.4242
Fold [3/5] Epoch [30/100] Initial Loss: 0.1339, Training Loss: 0.0791, Initial Validation Loss: 0.1167, Validation Loss: 0.0741,V Acc: 0.6545, Top 70th Acc: 0.7662, Bottom 30th Acc: 0.3939
Stopping early at Epoch (base 0): 31  Rolling back to Epoch (base 0): 26  Top Validation Acc: 0.7532467532467533
Fold [4/5] Epoch [0/100] Initial Loss: 0.1423, Training Loss: 0.1423, Initial Validation Loss: 0.1253, Validation Loss: 0.1253,V Acc: 0.3119, Top 70th Acc: 0.2727, Bottom 30th Acc: 0.4062
Fold [4/5] Epoch [10/100] Initial Loss: 0.1423, Training Loss: 0.0836, Initial Validation Loss: 0.1253, Validation Loss: 0.0725,V Acc: 0.6330, Top 70th Acc: 0.7662, Bottom 30th Acc: 0.3125
Fold [4/5] Epoch [20/100] Initial Loss: 0.1423, Training Loss: 0.0814, Initial Validation Loss: 0.1253, Validation Loss: 0.0704,V Acc: 0.6514, Top 70th Acc: 0.7662, Bottom 30th Acc: 0.3750
Fold [4/5] Epoch [30/100] Initial Loss: 0.1423, Training Loss: 0.0809, Initial Validation Loss: 0.1253, Validation Loss: 0.0694,V Acc: 0.6606, Top 70th Acc: 0.7662, Bottom 30th Acc: 0.4062
Fold [4/5] Epoch [40/100] Initial Loss: 0.1423, Training Loss: 0.0803, Initial Validation Loss: 0.1253, Validation Loss: 0.0699,V Acc: 0.6422, Top 70th Acc: 0.7662, Bottom 30th Acc: 0.3438
Stopping early at Epoch (base 0): 46  Rolling back to Epoch (base 0): 41  Top Validation Acc: 0.7792207792207793
Fold [5/5] Epoch [0/100] Initial Loss: 0.1383, Training Loss: 0.1383, Initial Validation Loss: 0.1269, Validation Loss: 0.1269,V Acc: 0.4259, Top 70th Acc: 0.4474, Bottom 30th Acc: 0.3750
Fold [5/5] Epoch [10/100] Initial Loss: 0.1383, Training Loss: 0.0798, Initial Validation Loss: 0.1269, Validation Loss: 0.0802,V Acc: 0.6019, Top 70th Acc: 0.6711, Bottom 30th Acc: 0.4375
Stopping early at Epoch (base 0): 19  Rolling back to Epoch (base 0): 14  Top Validation Acc: 0.6447368421052632
Running train_nn.py with seed 30
CUDA:False
Training samples count:  550
Training on 2 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1319, Training Loss: 0.1319, Initial Validation Loss: 0.1208, Validation Loss: 0.1208,V Acc: 0.4821, Top 70th Acc: 0.4557, Bottom 30th Acc: 0.5455
Fold [1/5] Epoch [10/100] Initial Loss: 0.1319, Training Loss: 0.0819, Initial Validation Loss: 0.1208, Validation Loss: 0.0820,V Acc: 0.6339, Top 70th Acc: 0.6835, Bottom 30th Acc: 0.5152
Fold [1/5] Epoch [20/100] Initial Loss: 0.1319, Training Loss: 0.0793, Initial Validation Loss: 0.1208, Validation Loss: 0.0795,V Acc: 0.6339, Top 70th Acc: 0.6962, Bottom 30th Acc: 0.4848
Fold [1/5] Epoch [30/100] Initial Loss: 0.1319, Training Loss: 0.0782, Initial Validation Loss: 0.1208, Validation Loss: 0.0790,V Acc: 0.6161, Top 70th Acc: 0.7468, Bottom 30th Acc: 0.3030
Fold [1/5] Epoch [40/100] Initial Loss: 0.1319, Training Loss: 0.0778, Initial Validation Loss: 0.1208, Validation Loss: 0.0784,V Acc: 0.6339, Top 70th Acc: 0.6962, Bottom 30th Acc: 0.4848
Fold [1/5] Epoch [50/100] Initial Loss: 0.1319, Training Loss: 0.0774, Initial Validation Loss: 0.1208, Validation Loss: 0.0782,V Acc: 0.6161, Top 70th Acc: 0.7089, Bottom 30th Acc: 0.3939
Fold [1/5] Epoch [60/100] Initial Loss: 0.1319, Training Loss: 0.0766, Initial Validation Loss: 0.1208, Validation Loss: 0.0781,V Acc: 0.6161, Top 70th Acc: 0.7089, Bottom 30th Acc: 0.3939
Fold [1/5] Epoch [70/100] Initial Loss: 0.1319, Training Loss: 0.0767, Initial Validation Loss: 0.1208, Validation Loss: 0.0771,V Acc: 0.6161, Top 70th Acc: 0.7089, Bottom 30th Acc: 0.3939
Fold [1/5] Epoch [80/100] Initial Loss: 0.1319, Training Loss: 0.0762, Initial Validation Loss: 0.1208, Validation Loss: 0.0769,V Acc: 0.6161, Top 70th Acc: 0.7342, Bottom 30th Acc: 0.3333
Fold [1/5] Epoch [90/100] Initial Loss: 0.1319, Training Loss: 0.0759, Initial Validation Loss: 0.1208, Validation Loss: 0.0770,V Acc: 0.6250, Top 70th Acc: 0.7089, Bottom 30th Acc: 0.4242
Stopping early at Epoch (base 0): 94  Rolling back to Epoch (base 0): 89  Top Validation Acc: 0.7341772151898734
Fold [2/5] Epoch [0/100] Initial Loss: 0.1407, Training Loss: 0.1407, Initial Validation Loss: 0.1344, Validation Loss: 0.1344,V Acc: 0.3604, Top 70th Acc: 0.4103, Bottom 30th Acc: 0.2424
Fold [2/5] Epoch [10/100] Initial Loss: 0.1407, Training Loss: 0.0782, Initial Validation Loss: 0.1344, Validation Loss: 0.0900,V Acc: 0.5586, Top 70th Acc: 0.6667, Bottom 30th Acc: 0.3030
Fold [2/5] Epoch [20/100] Initial Loss: 0.1407, Training Loss: 0.0760, Initial Validation Loss: 0.1344, Validation Loss: 0.0887,V Acc: 0.5676, Top 70th Acc: 0.6795, Bottom 30th Acc: 0.3030
Fold [2/5] Epoch [30/100] Initial Loss: 0.1407, Training Loss: 0.0754, Initial Validation Loss: 0.1344, Validation Loss: 0.0883,V Acc: 0.5586, Top 70th Acc: 0.6923, Bottom 30th Acc: 0.2424
Stopping early at Epoch (base 0): 31  Rolling back to Epoch (base 0): 26  Top Validation Acc: 0.6666666666666666
30 1 [array([0.12285847, 0.39699212, 0.14491394, 0.19474739, 0.14048801],
      dtype=float32)]
Fold [3/5] Epoch [0/100] Initial Loss: 0.1281, Training Loss: 0.1281, Initial Validation Loss: 0.1189, Validation Loss: 0.1189,V Acc: 0.5091, Top 70th Acc: 0.5714, Bottom 30th Acc: 0.3636
Fold [3/5] Epoch [10/100] Initial Loss: 0.1281, Training Loss: 0.0783, Initial Validation Loss: 0.1189, Validation Loss: 0.0844,V Acc: 0.6364, Top 70th Acc: 0.7273, Bottom 30th Acc: 0.4242
Fold [3/5] Epoch [20/100] Initial Loss: 0.1281, Training Loss: 0.0763, Initial Validation Loss: 0.1189, Validation Loss: 0.0842,V Acc: 0.6091, Top 70th Acc: 0.7273, Bottom 30th Acc: 0.3333
Fold [3/5] Epoch [30/100] Initial Loss: 0.1281, Training Loss: 0.0756, Initial Validation Loss: 0.1189, Validation Loss: 0.0845,V Acc: 0.5909, Top 70th Acc: 0.7273, Bottom 30th Acc: 0.2727
Stopping early at Epoch (base 0): 30  Rolling back to Epoch (base 0): 25  Top Validation Acc: 0.7272727272727273
Fold [4/5] Epoch [0/100] Initial Loss: 0.1324, Training Loss: 0.1324, Initial Validation Loss: 0.1211, Validation Loss: 0.1211,V Acc: 0.4128, Top 70th Acc: 0.4935, Bottom 30th Acc: 0.2188
Fold [4/5] Epoch [10/100] Initial Loss: 0.1324, Training Loss: 0.0829, Initial Validation Loss: 0.1211, Validation Loss: 0.0695,V Acc: 0.6789, Top 70th Acc: 0.8312, Bottom 30th Acc: 0.3125
Fold [4/5] Epoch [20/100] Initial Loss: 0.1324, Training Loss: 0.0812, Initial Validation Loss: 0.1211, Validation Loss: 0.0675,V Acc: 0.6881, Top 70th Acc: 0.8312, Bottom 30th Acc: 0.3438
Fold [4/5] Epoch [30/100] Initial Loss: 0.1324, Training Loss: 0.0807, Initial Validation Loss: 0.1211, Validation Loss: 0.0662,V Acc: 0.6881, Top 70th Acc: 0.8182, Bottom 30th Acc: 0.3750
Stopping early at Epoch (base 0): 38  Rolling back to Epoch (base 0): 33  Top Validation Acc: 0.8441558441558441
Fold [5/5] Epoch [0/100] Initial Loss: 0.1375, Training Loss: 0.1375, Initial Validation Loss: 0.1287, Validation Loss: 0.1287,V Acc: 0.2870, Top 70th Acc: 0.3553, Bottom 30th Acc: 0.1250
Fold [1/5] Epoch [20/100] Initial Loss: 0.1398, Training Loss: 0.0163, Initial Validation Loss: 0.1398, Validation Loss: 0.0308,V Acc: 0.8929, Top 70th Acc: 0.9494, Bottom 30th Acc: 0.7576
Fold [1/5] Epoch [30/100] Initial Loss: 0.1398, Training Loss: 0.0126, Initial Validation Loss: 0.1398, Validation Loss: 0.0300,V Acc: 0.8929, Top 70th Acc: 0.9620, Bottom 30th Acc: 0.7273
Stopping early at Epoch (base 0): 32  Rolling back to Epoch (base 0): 27  Top Validation Acc: 0.9620253164556962
Fold [2/5] Epoch [0/100] Initial Loss: 0.1379, Training Loss: 0.1379, Initial Validation Loss: 0.1255, Validation Loss: 0.1255,V Acc: 0.4414, Top 70th Acc: 0.4872, Bottom 30th Acc: 0.3333
Fold [2/5] Epoch [10/100] Initial Loss: 0.1379, Training Loss: 0.0220, Initial Validation Loss: 0.1255, Validation Loss: 0.0357,V Acc: 0.8649, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 19  Rolling back to Epoch (base 0): 14  Top Validation Acc: 0.9230769230769231
Fold [3/5] Epoch [0/100] Initial Loss: 0.1401, Training Loss: 0.1401, Initial Validation Loss: 0.1334, Validation Loss: 0.1334,V Acc: 0.2909, Top 70th Acc: 0.3377, Bottom 30th Acc: 0.1818
Fold [3/5] Epoch [10/100] Initial Loss: 0.1401, Training Loss: 0.0307, Initial Validation Loss: 0.1334, Validation Loss: 0.0370,V Acc: 0.8545, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.7273
Fold [3/5] Epoch [20/100] Initial Loss: 0.1401, Training Loss: 0.0147, Initial Validation Loss: 0.1334, Validation Loss: 0.0316,V Acc: 0.8364, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.6667
Fold [3/5] Epoch [30/100] Initial Loss: 0.1401, Training Loss: 0.0122, Initial Validation Loss: 0.1334, Validation Loss: 0.0315,V Acc: 0.8273, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.6364
Fold [3/5] Epoch [40/100] Initial Loss: 0.1401, Training Loss: 0.0109, Initial Validation Loss: 0.1334, Validation Loss: 0.0317,V Acc: 0.8182, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 49  Rolling back to Epoch (base 0): 44  Top Validation Acc: 0.9090909090909091
31 2 [array([0.54596496, 0.06741163, 0.06080153, 0.10354526, 0.22227657],
      dtype=float32)]
Fold [4/5] Epoch [0/100] Initial Loss: 0.1384, Training Loss: 0.1384, Initial Validation Loss: 0.1365, Validation Loss: 0.1365,V Acc: 0.2752, Top 70th Acc: 0.2338, Bottom 30th Acc: 0.3750
Fold [4/5] Epoch [10/100] Initial Loss: 0.1384, Training Loss: 0.0301, Initial Validation Loss: 0.1365, Validation Loss: 0.0385,V Acc: 0.8165, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.5625
Fold [4/5] Epoch [20/100] Initial Loss: 0.1384, Training Loss: 0.0176, Initial Validation Loss: 0.1365, Validation Loss: 0.0340,V Acc: 0.8349, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.5625
Fold [4/5] Epoch [30/100] Initial Loss: 0.1384, Training Loss: 0.0132, Initial Validation Loss: 0.1365, Validation Loss: 0.0346,V Acc: 0.8073, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.4375
Stopping early at Epoch (base 0): 30  Rolling back to Epoch (base 0): 25  Top Validation Acc: 0.961038961038961
Fold [5/5] Epoch [0/100] Initial Loss: 0.1363, Training Loss: 0.1363, Initial Validation Loss: 0.1267, Validation Loss: 0.1267,V Acc: 0.3981, Top 70th Acc: 0.4079, Bottom 30th Acc: 0.3750
Fold [5/5] Epoch [10/100] Initial Loss: 0.1363, Training Loss: 0.0342, Initial Validation Loss: 0.1267, Validation Loss: 0.0400,V Acc: 0.8333, Top 70th Acc: 0.9211, Bottom 30th Acc: 0.6250
Fold [5/5] Epoch [20/100] Initial Loss: 0.1363, Training Loss: 0.0201, Initial Validation Loss: 0.1267, Validation Loss: 0.0302,V Acc: 0.8611, Top 70th Acc: 0.9737, Bottom 30th Acc: 0.5938
Fold [5/5] Epoch [30/100] Initial Loss: 0.1363, Training Loss: 0.0147, Initial Validation Loss: 0.1267, Validation Loss: 0.0253,V Acc: 0.8611, Top 70th Acc: 0.9737, Bottom 30th Acc: 0.5938
Fold [5/5] Epoch [40/100] Initial Loss: 0.1363, Training Loss: 0.0129, Initial Validation Loss: 0.1267, Validation Loss: 0.0256,V Acc: 0.8611, Top 70th Acc: 0.9737, Bottom 30th Acc: 0.5938
Stopping early at Epoch (base 0): 44  Rolling back to Epoch (base 0): 39  Top Validation Acc: 0.9736842105263158
Running train_nn.py with seed 32
CUDA:False
Training samples count:  550
Training on 40 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1467, Training Loss: 0.1467, Initial Validation Loss: 0.1369, Validation Loss: 0.1369,V Acc: 0.2946, Top 70th Acc: 0.2658, Bottom 30th Acc: 0.3636
Fold [1/5] Epoch [10/100] Initial Loss: 0.1467, Training Loss: 0.0357, Initial Validation Loss: 0.1369, Validation Loss: 0.0360,V Acc: 0.8482, Top 70th Acc: 0.9367, Bottom 30th Acc: 0.6364
Fold [1/5] Epoch [20/100] Initial Loss: 0.1467, Training Loss: 0.0184, Initial Validation Loss: 0.1369, Validation Loss: 0.0314,V Acc: 0.8304, Top 70th Acc: 0.9367, Bottom 30th Acc: 0.5758
Fold [1/5] Epoch [30/100] Initial Loss: 0.1467, Training Loss: 0.0133, Initial Validation Loss: 0.1369, Validation Loss: 0.0283,V Acc: 0.8661, Top 70th Acc: 0.9241, Bottom 30th Acc: 0.7273
Fold [1/5] Epoch [40/100] Initial Loss: 0.1467, Training Loss: 0.0117, Initial Validation Loss: 0.1369, Validation Loss: 0.0281,V Acc: 0.8393, Top 70th Acc: 0.9367, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 42  Rolling back to Epoch (base 0): 37  Top Validation Acc: 0.9367088607594937
Fold [2/5] Epoch [0/100] Initial Loss: 0.1398, Training Loss: 0.1398, Initial Validation Loss: 0.1383, Validation Loss: 0.1383,V Acc: 0.3964, Top 70th Acc: 0.4103, Bottom 30th Acc: 0.3636
Fold [2/5] Epoch [10/100] Initial Loss: 0.1398, Training Loss: 0.0346, Initial Validation Loss: 0.1383, Validation Loss: 0.0442,V Acc: 0.8288, Top 70th Acc: 0.8974, Bottom 30th Acc: 0.6667
Fold [2/5] Epoch [20/100] Initial Loss: 0.1398, Training Loss: 0.0147, Initial Validation Loss: 0.1383, Validation Loss: 0.0325,V Acc: 0.8468, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.6364
Fold [2/5] Epoch [30/100] Initial Loss: 0.1398, Training Loss: 0.0115, Initial Validation Loss: 0.1383, Validation Loss: 0.0312,V Acc: 0.8468, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.6667
Fold [2/5] Epoch [40/100] Initial Loss: 0.1398, Training Loss: 0.0105, Initial Validation Loss: 0.1383, Validation Loss: 0.0315,V Acc: 0.8468, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 42  Rolling back to Epoch (base 0): 37  Top Validation Acc: 0.9358974358974359
Fold [3/5] Epoch [0/100] Initial Loss: 0.1404, Training Loss: 0.1404, Initial Validation Loss: 0.1323, Validation Loss: 0.1323,V Acc: 0.3727, Top 70th Acc: 0.4416, Bottom 30th Acc: 0.2121
Fold [3/5] Epoch [10/100] Initial Loss: 0.1404, Training Loss: 0.0336, Initial Validation Loss: 0.1323, Validation Loss: 0.0419,V Acc: 0.8091, Top 70th Acc: 0.8831, Bottom 30th Acc: 0.6364
Fold [3/5] Epoch [20/100] Initial Loss: 0.1404, Training Loss: 0.0151, Initial Validation Loss: 0.1323, Validation Loss: 0.0319,V Acc: 0.8364, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.6061
Fold [3/5] Epoch [30/100] Initial Loss: 0.1404, Training Loss: 0.0123, Initial Validation Loss: 0.1323, Validation Loss: 0.0319,V Acc: 0.8182, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.5152
Stopping early at Epoch (base 0): 32  Rolling back to Epoch (base 0): 27  Top Validation Acc: 0.948051948051948
32 2 [array([0.25684083, 0.11022792, 0.04278785, 0.10729343, 0.48285   ],
      dtype=float32)]
Fold [4/5] Epoch [0/100] Initial Loss: 0.1386, Training Loss: 0.1386, Initial Validation Loss: 0.1344, Validation Loss: 0.1344,V Acc: 0.2477, Top 70th Acc: 0.3117, Bottom 30th Acc: 0.0938
Fold [4/5] Epoch [10/100] Initial Loss: 0.1386, Training Loss: 0.0303, Initial Validation Loss: 0.1344, Validation Loss: 0.0371,V Acc: 0.8165, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.5625
Fold [4/5] Epoch [20/100] Initial Loss: 0.1386, Training Loss: 0.0162, Initial Validation Loss: 0.1344, Validation Loss: 0.0255,V Acc: 0.8716, Top 70th Acc: 0.9870, Bottom 30th Acc: 0.5938
Fold [4/5] Epoch [30/100] Initial Loss: 0.1386, Training Loss: 0.0130, Initial Validation Loss: 0.1344, Validation Loss: 0.0253,V Acc: 0.8807, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.6562
Stopping early at Epoch (base 0): 34  Rolling back to Epoch (base 0): 29  Top Validation Acc: 0.974025974025974
Fold [5/5] Epoch [0/100] Initial Loss: 0.1400, Training Loss: 0.1400, Initial Validation Loss: 0.1316, Validation Loss: 0.1316,V Acc: 0.3056, Top 70th Acc: 0.3289, Bottom 30th Acc: 0.2500/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)

Fold [2/5] Epoch [20/100] Initial Loss: 0.1356, Training Loss: 0.0232, Initial Validation Loss: 0.1286, Validation Loss: 0.0395,V Acc: 0.7928, Top 70th Acc: 0.8846, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 22  Rolling back to Epoch (base 0): 17  Top Validation Acc: 0.8846153846153846
30 1 [array([0.17164873, 0.13165131, 0.32048956, 0.14840886, 0.22780159],
      dtype=float32)]
Fold [3/5] Epoch [0/100] Initial Loss: 0.1371, Training Loss: 0.1371, Initial Validation Loss: 0.1317, Validation Loss: 0.1317,V Acc: 0.4000, Top 70th Acc: 0.4675, Bottom 30th Acc: 0.2424
Fold [3/5] Epoch [10/100] Initial Loss: 0.1371, Training Loss: 0.0324, Initial Validation Loss: 0.1317, Validation Loss: 0.0399,V Acc: 0.8091, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.5758
Fold [3/5] Epoch [20/100] Initial Loss: 0.1371, Training Loss: 0.0242, Initial Validation Loss: 0.1317, Validation Loss: 0.0356,V Acc: 0.8273, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 22  Rolling back to Epoch (base 0): 17  Top Validation Acc: 0.935064935064935
Fold [4/5] Epoch [0/100] Initial Loss: 0.1387, Training Loss: 0.1387, Initial Validation Loss: 0.1337, Validation Loss: 0.1337,V Acc: 0.3119, Top 70th Acc: 0.3636, Bottom 30th Acc: 0.1875
Fold [4/5] Epoch [10/100] Initial Loss: 0.1387, Training Loss: 0.0442, Initial Validation Loss: 0.1337, Validation Loss: 0.0431,V Acc: 0.8165, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.5938
Fold [4/5] Epoch [20/100] Initial Loss: 0.1387, Training Loss: 0.0257, Initial Validation Loss: 0.1337, Validation Loss: 0.0316,V Acc: 0.8624, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.7188
Fold [4/5] Epoch [30/100] Initial Loss: 0.1387, Training Loss: 0.0238, Initial Validation Loss: 0.1337, Validation Loss: 0.0287,V Acc: 0.8624, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.6250
Stopping early at Epoch (base 0): 32  Rolling back to Epoch (base 0): 27  Top Validation Acc: 0.961038961038961
Fold [5/5] Epoch [0/100] Initial Loss: 0.1361, Training Loss: 0.1361, Initial Validation Loss: 0.1283, Validation Loss: 0.1283,V Acc: 0.3796, Top 70th Acc: 0.4079, Bottom 30th Acc: 0.3125
Fold [5/5] Epoch [10/100] Initial Loss: 0.1361, Training Loss: 0.0446, Initial Validation Loss: 0.1283, Validation Loss: 0.0445,V Acc: 0.7778, Top 70th Acc: 0.8947, Bottom 30th Acc: 0.5000
Fold [5/5] Epoch [20/100] Initial Loss: 0.1361, Training Loss: 0.0248, Initial Validation Loss: 0.1283, Validation Loss: 0.0317,V Acc: 0.8611, Top 70th Acc: 0.9211, Bottom 30th Acc: 0.7188
Fold [5/5] Epoch [30/100] Initial Loss: 0.1361, Training Loss: 0.0219, Initial Validation Loss: 0.1283, Validation Loss: 0.0304,V Acc: 0.8611, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.6875
Stopping early at Epoch (base 0): 35  Rolling back to Epoch (base 0): 30  Top Validation Acc: 0.9078947368421053
Running train_nn.py with seed 31
CUDA:False
Training samples count:  550
Training on 20 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1385, Training Loss: 0.1385, Initial Validation Loss: 0.1392, Validation Loss: 0.1392,V Acc: 0.2321, Top 70th Acc: 0.2785, Bottom 30th Acc: 0.1212
Fold [1/5] Epoch [10/100] Initial Loss: 0.1385, Training Loss: 0.0405, Initial Validation Loss: 0.1392, Validation Loss: 0.0462,V Acc: 0.7679, Top 70th Acc: 0.8987, Bottom 30th Acc: 0.4545
Fold [1/5] Epoch [20/100] Initial Loss: 0.1385, Training Loss: 0.0228, Initial Validation Loss: 0.1392, Validation Loss: 0.0321,V Acc: 0.8393, Top 70th Acc: 0.9367, Bottom 30th Acc: 0.6061
Fold [1/5] Epoch [30/100] Initial Loss: 0.1385, Training Loss: 0.0200, Initial Validation Loss: 0.1392, Validation Loss: 0.0329,V Acc: 0.8482, Top 70th Acc: 0.9241, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 32  Rolling back to Epoch (base 0): 27  Top Validation Acc: 0.9113924050632911
Fold [2/5] Epoch [0/100] Initial Loss: 0.1354, Training Loss: 0.1354, Initial Validation Loss: 0.1236, Validation Loss: 0.1236,V Acc: 0.3694, Top 70th Acc: 0.4615, Bottom 30th Acc: 0.1515
Fold [2/5] Epoch [10/100] Initial Loss: 0.1354, Training Loss: 0.0299, Initial Validation Loss: 0.1236, Validation Loss: 0.0385,V Acc: 0.8559, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.7273
Fold [2/5] Epoch [20/100] Initial Loss: 0.1354, Training Loss: 0.0223, Initial Validation Loss: 0.1236, Validation Loss: 0.0360,V Acc: 0.8288, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 28  Rolling back to Epoch (base 0): 23  Top Validation Acc: 0.9102564102564102
Fold [3/5] Epoch [0/100] Initial Loss: 0.1377, Training Loss: 0.1377, Initial Validation Loss: 0.1270, Validation Loss: 0.1270,V Acc: 0.2818, Top 70th Acc: 0.3636, Bottom 30th Acc: 0.0909
Fold [3/5] Epoch [10/100] Initial Loss: 0.1377, Training Loss: 0.0287, Initial Validation Loss: 0.1270, Validation Loss: 0.0338,V Acc: 0.8455, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.6970
Fold [3/5] Epoch [20/100] Initial Loss: 0.1377, Training Loss: 0.0217, Initial Validation Loss: 0.1270, Validation Loss: 0.0324,V Acc: 0.8273, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.922077922077922
31 2 [array([0.46785414, 0.10480983, 0.1422304 , 0.19419292, 0.09091273],
      dtype=float32)]
Fold [4/5] Epoch [0/100] Initial Loss: 0.1376, Training Loss: 0.1376, Initial Validation Loss: 0.1355, Validation Loss: 0.1355,V Acc: 0.2477, Top 70th Acc: 0.3506, Bottom 30th Acc: 0.0000
Fold [4/5] Epoch [10/100] Initial Loss: 0.1376, Training Loss: 0.0418, Initial Validation Loss: 0.1355, Validation Loss: 0.0466,V Acc: 0.7982, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.5312
Fold [4/5] Epoch [20/100] Initial Loss: 0.1376, Training Loss: 0.0260, Initial Validation Loss: 0.1355, Validation Loss: 0.0324,V Acc: 0.8624, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6562
Stopping early at Epoch (base 0): 27  Rolling back to Epoch (base 0): 22  Top Validation Acc: 0.961038961038961
Fold [5/5] Epoch [0/100] Initial Loss: 0.1463, Training Loss: 0.1463, Initial Validation Loss: 0.1328, Validation Loss: 0.1328,V Acc: 0.3241, Top 70th Acc: 0.3684, Bottom 30th Acc: 0.2188
Fold [5/5] Epoch [10/100] Initial Loss: 0.1463, Training Loss: 0.0471, Initial Validation Loss: 0.1328, Validation Loss: 0.0531,V Acc: 0.7500, Top 70th Acc: 0.8553, Bottom 30th Acc: 0.5000
Fold [5/5] Epoch [20/100] Initial Loss: 0.1463, Training Loss: 0.0271, Initial Validation Loss: 0.1328, Validation Loss: 0.0307,V Acc: 0.8796, Top 70th Acc: 0.9211, Bottom 30th Acc: 0.7812
Fold [5/5] Epoch [30/100] Initial Loss: 0.1463, Training Loss: 0.0223, Initial Validation Loss: 0.1328, Validation Loss: 0.0281,V Acc: 0.8704, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.6875
Stopping early at Epoch (base 0): 35  Rolling back to Epoch (base 0): 30  Top Validation Acc: 0.9342105263157895
Running train_nn.py with seed 32
CUDA:False
Training samples count:  550
Training on 20 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1423, Training Loss: 0.1423, Initial Validation Loss: 0.1340, Validation Loss: 0.1340,V Acc: 0.2768, Top 70th Acc: 0.2658, Bottom 30th Acc: 0.3030
Fold [1/5] Epoch [10/100] Initial Loss: 0.1423, Training Loss: 0.0434, Initial Validation Loss: 0.1340, Validation Loss: 0.0444,V Acc: 0.7679, Top 70th Acc: 0.8987, Bottom 30th Acc: 0.4545
Fold [1/5] Epoch [20/100] Initial Loss: 0.1423, Training Loss: 0.0233, Initial Validation Loss: 0.1340, Validation Loss: 0.0347,V Acc: 0.8214, Top 70th Acc: 0.9114, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 29  Rolling back to Epoch (base 0): 24  Top Validation Acc: 0.9240506329113924
Fold [2/5] Epoch [0/100] Initial Loss: 0.1387, Training Loss: 0.1387, Initial Validation Loss: 0.1355, Validation Loss: 0.1355,V Acc: 0.3243, Top 70th Acc: 0.4359, Bottom 30th Acc: 0.0606
Fold [2/5] Epoch [10/100] Initial Loss: 0.1387, Training Loss: 0.0414, Initial Validation Loss: 0.1355, Validation Loss: 0.0455,V Acc: 0.8108, Top 70th Acc: 0.8718, Bottom 30th Acc: 0.6667
Fold [2/5] Epoch [20/100] Initial Loss: 0.1387, Training Loss: 0.0252, Initial Validation Loss: 0.1355, Validation Loss: 0.0355,V Acc: 0.8468, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 29  Rolling back to Epoch (base 0): 24  Top Validation Acc: 18  Rolling back to Epoch (base 0): 13  Top Validation Acc: 0.8846153846153846
Fold [3/5] Epoch [0/100] Initial Loss: 0.1374, Training Loss: 0.1374, Initial Validation Loss: 0.1225, Validation Loss: 0.1225,V Acc: 0.4636, Top 70th Acc: 0.5974, Bottom 30th Acc: 0.1515
Fold [3/5] Epoch [10/100] Initial Loss: 0.1374, Training Loss: 0.0237, Initial Validation Loss: 0.1225, Validation Loss: 0.0230,V Acc: 0.8545, Top 70th Acc: 1.0000, Bottom 30th Acc: 0.5152
Fold [3/5] Epoch [20/100] Initial Loss: 0.1374, Training Loss: 0.0166, Initial Validation Loss: 0.1225, Validation Loss: 0.0176,V Acc: 0.9182, Top 70th Acc: 1.0000, Bottom 30th Acc: 0.7273
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.987012987012987
41 2 [array([0.7634141 , 0.01445535, 0.03040183, 0.09008924, 0.10163949],
      dtype=float32)]
Fold [4/5] Epoch [0/100] Initial Loss: 0.1309, Training Loss: 0.1309, Initial Validation Loss: 0.1086, Validation Loss: 0.1086,V Acc: 0.5505, Top 70th Acc: 0.6364, Bottom 30th Acc: 0.3438
Fold [4/5] Epoch [10/100] Initial Loss: 0.1309, Training Loss: 0.0215, Initial Validation Loss: 0.1086, Validation Loss: 0.0282,V Acc: 0.8807, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.7188
Fold [4/5] Epoch [20/100] Initial Loss: 0.1309, Training Loss: 0.0161, Initial Validation Loss: 0.1086, Validation Loss: 0.0238,V Acc: 0.8716, Top 70th Acc: 0.9870, Bottom 30th Acc: 0.5938
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.961038961038961
Fold [5/5] Epoch [0/100] Initial Loss: 0.1295, Training Loss: 0.1295, Initial Validation Loss: 0.1177, Validation Loss: 0.1177,V Acc: 0.4907, Top 70th Acc: 0.5526, Bottom 30th Acc: 0.3438
Fold [5/5] Epoch [10/100] Initial Loss: 0.1295, Training Loss: 0.0241, Initial Validation Loss: 0.1177, Validation Loss: 0.0283,V Acc: 0.8981, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.7500
Fold [5/5] Epoch [20/100] Initial Loss: 0.1295, Training Loss: 0.0160, Initial Validation Loss: 0.1177, Validation Loss: 0.0220,V Acc: 0.8981, Top 70th Acc: 1.0000, Bottom 30th Acc: 0.6562
Stopping early at Epoch (base 0): 22  Rolling back to Epoch (base 0): 17  Top Validation Acc: 1.0
Running train_nn.py with seed 42
CUDA:False
Training samples count:  550
Training on 21 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1364, Training Loss: 0.1364, Initial Validation Loss: 0.1285, Validation Loss: 0.1285,V Acc: 0.4107, Top 70th Acc: 0.5316, Bottom 30th Acc: 0.1212
Fold [1/5] Epoch [10/100] Initial Loss: 0.1364, Training Loss: 0.0256, Initial Validation Loss: 0.1285, Validation Loss: 0.0260,V Acc: 0.9107, Top 70th Acc: 0.9620, Bottom 30th Acc: 0.7879
Fold [1/5] Epoch [20/100] Initial Loss: 0.1364, Training Loss: 0.0157, Initial Validation Loss: 0.1285, Validation Loss: 0.0226,V Acc: 0.8839, Top 70th Acc: 0.9747, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.9746835443037974
Fold [2/5] Epoch [0/100] Initial Loss: 0.1344, Training Loss: 0.1344, Initial Validation Loss: 0.1249, Validation Loss: 0.1249,V Acc: 0.3243, Top 70th Acc: 0.3974, Bottom 30th Acc: 0.1515
Fold [2/5] Epoch [10/100] Initial Loss: 0.1344, Training Loss: 0.0240, Initial Validation Loss: 0.1249, Validation Loss: 0.0282,V Acc: 0.8739, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.6970
Fold [2/5] Epoch [20/100] Initial Loss: 0.1344, Training Loss: 0.0182, Initial Validation Loss: 0.1249, Validation Loss: 0.0240,V Acc: 0.8829, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.9615384615384616
Fold [3/5] Epoch [0/100] Initial Loss: 0.1376, Training Loss: 0.1376, Initial Validation Loss: 0.1293, Validation Loss: 0.1293,V Acc: 0.3636, Top 70th Acc: 0.4805, Bottom 30th Acc: 0.0909
Fold [3/5] Epoch [10/100] Initial Loss: 0.1376, Training Loss: 0.0216, Initial Validation Loss: 0.1293, Validation Loss: 0.0354,V Acc: 0.8545, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 16  Rolling back to Epoch (base 0): 11  Top Validation Acc: 0.961038961038961
Fold [4/5] Epoch [0/100] Initial Loss: 0.1364, Training Loss: 0.1364, Initial Validation Loss: 0.1176, Validation Loss: 0.1176,V Acc: 0.4679, Top 70th Acc: 0.5844, Bottom 30th Acc: 0.1875
Fold [4/5] Epoch [10/100] Initial Loss: 0.1364, Training Loss: 0.0220, Initial Validation Loss: 0.1176, Validation Loss: 0.0220,V Acc: 0.8624, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.6250
Stopping early at Epoch (base 0): 19  Rolling back to Epoch (base 0): 14  Top Validation Acc: 0.987012987012987
Fold [5/5] Epoch [0/100] Initial Loss: 0.1292, Training Loss: 0.1292, Initial Validation Loss: 0.1087, Validation Loss: 0.1087,V Acc: 0.5833, Top 70th Acc: 0.6842, Bottom 30th Acc: 0.3438
Fold [5/5] Epoch [10/100] Initial Loss: 0.1292, Training Loss: 0.0209, Initial Validation Loss: 0.1087, Validation Loss: 0.0318,V Acc: 0.8704, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.7188
Fold [5/5] Epoch [20/100] Initial Loss: 0.1292, Training Loss: 0.0148, Initial Validation Loss: 0.1087, Validation Loss: 0.0275,V Acc: 0.8704, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.6562
Stopping early at Epoch (base 0): 22  Rolling back to Epoch (base 0): 17  Top Validation Acc: 0.9868421052631579
42 4 [array([0.82820815, 0.01373675, 0.03974397, 0.08899967, 0.02931153],
      dtype=float32)]
Running train_nn.py with seed 43
CUDA:False
Training samples count:  550
Training on 21 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1376, Training Loss: 0.1376, Initial Validation Loss: 0.1313, Validation Loss: 0.1313,V Acc: 0.3304, Top 70th Acc: 0.3924, Bottom 30th Acc: 0.1818
Fold [1/5] Epoch [10/100] Initial Loss: 0.1376, Training Loss: 0.0240, Initial Validation Loss: 0.1313, Validation Loss: 0.0292,V Acc: 0.8661, Top 70th Acc: 0.9367, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 18  Rolling back to Epoch (base 0): 13  Top Validation Acc: 0.9746835443037974
Fold [2/5] Epoch [0/100] Initial Loss: 0.1409, Training Loss: 0.1409, Initial Validation Loss: 0.1301, Validation Loss: 0.1301,V Acc: 0.4144, Top 70th Acc: 0.4487, Bottom 30th Acc: 0.3333
Fold [2/5] Epoch [10/100] Initial Loss: 0.1409, Training Loss: 0.0221, Initial Validation Loss: 0.1301, Validation Loss: 0.0260,V Acc: 0.8919, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.6970
Fold [2/5] Epoch [20/100] Initial Loss: 0.1409, Training Loss: 0.0154, Initial Validation Loss: 0.1301, Validation Loss: 0.0241,V Acc: 0.8739, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 21  Rolling back to Epoch (base 0): 16  Top Validation Acc: 0.9615384615384616
43 1 [array([0.78921354, 0.01408789, 0.04334777, 0.07141304, 0.08193779],
      dtype=float32)]
Fold [3/5] Epoch [0/100] Initial Loss: 0.1365, Training Loss: 0.1365, Initial Validation Loss: 0.1284, Validation Loss: 0.1284,V Acc: 0.3636, Top 70th Acc: 0.4935, Bottom 30th Acc: 0.0606
Fold [3/5] Epoch [10/100] Initial Loss: 0.1365, Training Loss: 0.0230, Initial Validation Loss: 0.1284, Validation Loss: 0.0279,V Acc: 0.8909, Top 70th Acc: 1.0000, Bottom 30th Acc: 0.6364
Fold [3/5] Epoch [20/100] Initial Loss: 0.1365, Training Loss: 0.0150, Initial Validation Loss: 0.1284, Validation Loss: 0.0234,V Acc: 0.8909, Top 70th Acc: 0.9870, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 27  Rolling back to Epoch (base 0): 22  Top Validation Acc: 0.974025974025974
Fold [4/5] Epoch [0/100] Initial Loss: 0.1473, Training Loss: 0.1473, Initial Validation Loss: 0.1356, Validation Loss: 0.1356,V Acc: 0.4037, Top 70th Acc: 0.4935, Bottom 30th Acc: 0.1875
Fold [4/5] Epoch [10/100] Initial Loss: 0.1473, Training Loss: 0.0268, Initial Validation Loss: 0.1356, Validation Loss: 0.0264,V Acc: 0.8807, Top 70th Acc: 0.9870, Bottom 30th Acc: 0.6250
Fold [4/5] Epoch [20/100] Initial Loss: 0.1473, Training Loss: 0.0172, Initial Validation Loss: 0.1356, Validation Loss: 0.0217,V Acc: 0.9083, Top 70th Acc: 0.9870, Bottom 30th Acc: 0.7188
Stopping early at Epoch (base 0): 20  Rolling back to Epoch (base 0): 15  Top Validation Acc: 0.987012987012987
Fold [5/5] Epoch [0/100] Initial Loss: 0.1319, Training Loss: 0.1319, Initial Validation Loss: 0.1118, Validation Loss: 0.1118,V Acc: 0.5093, Top 70th Acc: 0.6447, Bottom 30th Acc: 0.1875
Fold [5/5] Epoch [20/100] Initial Loss: 0.1383, Training Loss: 0.0052, Initial Validation Loss: 0.1367, Validation Loss: 0.0261,V Acc: 0.9167, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.8125
Fold [5/5] Epoch [30/100] Initial Loss: 0.1383, Training Loss: 0.0039, Initial Validation Loss: 0.1367, Validation Loss: 0.0238,V Acc: 0.9259, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.8438
Fold [5/5] Epoch [40/100] Initial Loss: 0.1383, Training Loss: 0.0036, Initial Validation Loss: 0.1367, Validation Loss: 0.0234,V Acc: 0.9259, Top 70th Acc: 0.9737, Bottom 30th Acc: 0.8125
Stopping early at Epoch (base 0): 45  Rolling back to Epoch (base 0): 40  Top Validation Acc: 0.9605263157894737
Running train_nn.py with seed 23
CUDA:False
Training samples count:  550
Training on 162 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1435, Training Loss: 0.1435, Initial Validation Loss: 0.1317, Validation Loss: 0.1317,V Acc: 0.4196, Top 70th Acc: 0.4937, Bottom 30th Acc: 0.2424
Fold [1/5] Epoch [10/100] Initial Loss: 0.1435, Training Loss: 0.0169, Initial Validation Loss: 0.1317, Validation Loss: 0.0221,V Acc: 0.8929, Top 70th Acc: 0.9873, Bottom 30th Acc: 0.6667
Fold [1/5] Epoch [20/100] Initial Loss: 0.1435, Training Loss: 0.0045, Initial Validation Loss: 0.1317, Validation Loss: 0.0206,V Acc: 0.8750, Top 70th Acc: 0.9747, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 21  Rolling back to Epoch (base 0): 16  Top Validation Acc: 0.9620253164556962
Fold [2/5] Epoch [0/100] Initial Loss: 0.1390, Training Loss: 0.1390, Initial Validation Loss: 0.1390, Validation Loss: 0.1390,V Acc: 0.2252, Top 70th Acc: 0.2308, Bottom 30th Acc: 0.2121
Fold [2/5] Epoch [10/100] Initial Loss: 0.1390, Training Loss: 0.0157, Initial Validation Loss: 0.1390, Validation Loss: 0.0408,V Acc: 0.7928, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.4848
Fold [2/5] Epoch [20/100] Initial Loss: 0.1390, Training Loss: 0.0048, Initial Validation Loss: 0.1390, Validation Loss: 0.0347,V Acc: 0.8559, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 20  Rolling back to Epoch (base 0): 15  Top Validation Acc: 0.9358974358974359
23 1 [array([0.3693187 , 0.0435842 , 0.09690032, 0.28436905, 0.20582777],
      dtype=float32)]
Fold [3/5] Epoch [0/100] Initial Loss: 0.1443, Training Loss: 0.1443, Initial Validation Loss: 0.1322, Validation Loss: 0.1322,V Acc: 0.4091, Top 70th Acc: 0.4675, Bottom 30th Acc: 0.2727
Fold [3/5] Epoch [10/100] Initial Loss: 0.1443, Training Loss: 0.0194, Initial Validation Loss: 0.1322, Validation Loss: 0.0346,V Acc: 0.8364, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.5455
Fold [3/5] Epoch [20/100] Initial Loss: 0.1443, Training Loss: 0.0058, Initial Validation Loss: 0.1322, Validation Loss: 0.0305,V Acc: 0.8455, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.948051948051948
Fold [4/5] Epoch [0/100] Initial Loss: 0.1415, Training Loss: 0.1415, Initial Validation Loss: 0.1354, Validation Loss: 0.1354,V Acc: 0.2477, Top 70th Acc: 0.3247, Bottom 30th Acc: 0.0625
Fold [4/5] Epoch [10/100] Initial Loss: 0.1415, Training Loss: 0.0224, Initial Validation Loss: 0.1354, Validation Loss: 0.0411,V Acc: 0.7982, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.5312
Fold [4/5] Epoch [20/100] Initial Loss: 0.1415, Training Loss: 0.0053, Initial Validation Loss: 0.1354, Validation Loss: 0.0324,V Acc: 0.8257, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.5312
Stopping early at Epoch (base 0): 29  Rolling back to Epoch (base 0): 24  Top Validation Acc: 0.948051948051948
Fold [5/5] Epoch [0/100] Initial Loss: 0.1388, Training Loss: 0.1388, Initial Validation Loss: 0.1320, Validation Loss: 0.1320,V Acc: 0.2685, Top 70th Acc: 0.2895, Bottom 30th Acc: 0.2188
Fold [5/5] Epoch [10/100] Initial Loss: 0.1388, Training Loss: 0.0182, Initial Validation Loss: 0.1320, Validation Loss: 0.0387,V Acc: 0.8241, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.5000
Fold [5/5] Epoch [20/100] Initial Loss: 0.1388, Training Loss: 0.0052, Initial Validation Loss: 0.1320, Validation Loss: 0.0325,V Acc: 0.8333, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.5312
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.9605263157894737
Running train_nn.py with seed 24
CUDA:False
Training samples count:  550
Training on 162 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1406, Training Loss: 0.1406, Initial Validation Loss: 0.1368, Validation Loss: 0.1368,V Acc: 0.3571, Top 70th Acc: 0.3544, Bottom 30th Acc: 0.3636
Fold [1/5] Epoch [10/100] Initial Loss: 0.1406, Training Loss: 0.0150, Initial Validation Loss: 0.1368, Validation Loss: 0.0400,V Acc: 0.7946, Top 70th Acc: 0.8861, Bottom 30th Acc: 0.5758
Fold [1/5] Epoch [20/100] Initial Loss: 0.1406, Training Loss: 0.0048, Initial Validation Loss: 0.1368, Validation Loss: 0.0386,V Acc: 0.8036, Top 70th Acc: 0.8861, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.9113924050632911
Fold [2/5] Epoch [0/100] Initial Loss: 0.1411, Training Loss: 0.1411, Initial Validation Loss: 0.1338, Validation Loss: 0.1338,V Acc: 0.2793, Top 70th Acc: 0.3333, Bottom 30th Acc: 0.1515
Fold [2/5] Epoch [10/100] Initial Loss: 0.1411, Training Loss: 0.0198, Initial Validation Loss: 0.1338, Validation Loss: 0.0370,V Acc: 0.8378, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.5758
Fold [2/5] Epoch [20/100] Initial Loss: 0.1411, Training Loss: 0.0047, Initial Validation Loss: 0.1338, Validation Loss: 0.0294,V Acc: 0.8378, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.5758
Fold [2/5] Epoch [30/100] Initial Loss: 0.1411, Training Loss: 0.0036, Initial Validation Loss: 0.1338, Validation Loss: 0.0290,V Acc: 0.8378, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.5152
Stopping early at Epoch (base 0): 30  Rolling back to Epoch (base 0): 25  Top Validation Acc: 0.9743589743589743
Fold [3/5] Epoch [0/100] Initial Loss: 0.1381, Training Loss: 0.1381, Initial Validation Loss: 0.1348, Validation Loss: 0.1348,V Acc: 0.3636, Top 70th Acc: 0.4156, Bottom 30th Acc: 0.2424
Fold [3/5] Epoch [10/100] Initial Loss: 0.1381, Training Loss: 0.0155, Initial Validation Loss: 0.1348, Validation Loss: 0.0301,V Acc: 0.8727, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.6364
Fold [3/5] Epoch [20/100] Initial Loss: 0.1381, Training Loss: 0.0054, Initial Validation Loss: 0.1348, Validation Loss: 0.0242,V Acc: 0.8818, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.6667
Fold [3/5] Epoch [30/100] Initial Loss: 0.1381, Training Loss: 0.0042, Initial Validation Loss: 0.1348, Validation Loss: 0.0234,V Acc: 0.8818, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.6667
Fold [3/5] Epoch [40/100] Initial Loss: 0.1381, Training Loss: 0.0039, Initial Validation Loss: 0.1348, Validation Loss: 0.0230,V Acc: 0.8909, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 42  Rolling back to Epoch (base 0): 37  Top Validation Acc: 0.974025974025974
24 2 [array([0.13308068, 0.05852667, 0.05984988, 0.25071698, 0.49782583],
      dtype=float32)]
Fold [4/5] Epoch [0/100] Initial Loss: 0.1387, Training Loss: 0.1387, Initial Validation Loss: 0.1370, Validation Loss: 0.1370,V Acc: 0.2569, Top 70th Acc: 0.3247, Bottom 30th Acc: 0.0938
Fold [4/5] Epoch [10/100] Initial Loss: 0.1387, Training Loss: 0.0193, Initial Validation Loss: 0.1370, Validation Loss: 0.0388,V Acc: 0.8532, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.6875
Fold [4/5] Epoch [20/100] Initial Loss: 0.1387, Training Loss: 0.0049, Initial Validation Loss: 0.1370, Validation Loss: 0.0338,V Acc: 0.8440, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.6562
Fold [4/5] Epoch [30/100] Initial Loss: 0.1387, Training Loss: 0.0038, Initial Validation Loss: 0.1370, Validation Loss: 0.0328,V Acc: 0.8532, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6250
Stopping early at Epoch (base 0): 36  Rolling back to Epoch (base 0): 31  Top Validation Acc: 0.974025974025974
Fold [5/5] Epoch [0/100] Initial Loss: 0.1390, Training Loss: 0.1390, Initial Validation Loss: 0.1273, Validation Loss: 0.1273,V Acc: 0.3704, Top 70th Acc: 0.3684, Bottom 30th Acc: 0.3750
Fold [5/5] Epoch [10/100] Initial Loss: 0.1390, Training Loss: 0.0146, Initial Validation Loss: 0.1273, Validation Loss: 0.0287,V Acc: 0.8704, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.7188
Fold [3/5] Epoch [10/100] Initial Loss: 0.1412, Training Loss: 0.0285, Initial Validation Loss: 0.1350, Validation Loss: 0.0348,V Acc: 0.8455, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 19  Rolling back to Epoch (base 0): 14  Top Validation Acc: 0.961038961038961
Fold [4/5] Epoch [0/100] Initial Loss: 0.1415, Training Loss: 0.1415, Initial Validation Loss: 0.1344, Validation Loss: 0.1344,V Acc: 0.2752, Top 70th Acc: 0.3247, Bottom 30th Acc: 0.1562
Fold [4/5] Epoch [10/100] Initial Loss: 0.1415, Training Loss: 0.0306, Initial Validation Loss: 0.1344, Validation Loss: 0.0294,V Acc: 0.8991, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.7500
Fold [4/5] Epoch [20/100] Initial Loss: 0.1415, Training Loss: 0.0198, Initial Validation Loss: 0.1344, Validation Loss: 0.0248,V Acc: 0.8807, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.7188
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.948051948051948
Fold [5/5] Epoch [0/100] Initial Loss: 0.1371, Training Loss: 0.1371, Initial Validation Loss: 0.1279, Validation Loss: 0.1279,V Acc: 0.3796, Top 70th Acc: 0.3947, Bottom 30th Acc: 0.3438
Fold [5/5] Epoch [10/100] Initial Loss: 0.1371, Training Loss: 0.0407, Initial Validation Loss: 0.1279, Validation Loss: 0.0422,V Acc: 0.7685, Top 70th Acc: 0.9079, Bottom 30th Acc: 0.4375
Fold [5/5] Epoch [20/100] Initial Loss: 0.1371, Training Loss: 0.0279, Initial Validation Loss: 0.1279, Validation Loss: 0.0387,V Acc: 0.7963, Top 70th Acc: 0.9079, Bottom 30th Acc: 0.5312
Fold [5/5] Epoch [30/100] Initial Loss: 0.1371, Training Loss: 0.0216, Initial Validation Loss: 0.1279, Validation Loss: 0.0332,V Acc: 0.7870, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.4375
Fold [5/5] Epoch [40/100] Initial Loss: 0.1371, Training Loss: 0.0173, Initial Validation Loss: 0.1279, Validation Loss: 0.0288,V Acc: 0.8519, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.6250
Fold [5/5] Epoch [50/100] Initial Loss: 0.1371, Training Loss: 0.0160, Initial Validation Loss: 0.1279, Validation Loss: 0.0273,V Acc: 0.8611, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.6562
Stopping early at Epoch (base 0): 59  Rolling back to Epoch (base 0): 54  Top Validation Acc: 0.9342105263157895
Running train_nn.py with seed 31
CUDA:False
Training samples count:  550
Training on 30 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1405, Training Loss: 0.1405, Initial Validation Loss: 0.1409, Validation Loss: 0.1409,V Acc: 0.2232, Top 70th Acc: 0.2785, Bottom 30th Acc: 0.0909
Fold [1/5] Epoch [10/100] Initial Loss: 0.1405, Training Loss: 0.0324, Initial Validation Loss: 0.1409, Validation Loss: 0.0388,V Acc: 0.8661, Top 70th Acc: 0.9494, Bottom 30th Acc: 0.6667
Fold [1/5] Epoch [20/100] Initial Loss: 0.1405, Training Loss: 0.0178, Initial Validation Loss: 0.1409, Validation Loss: 0.0308,V Acc: 0.8482, Top 70th Acc: 0.9494, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 22  Rolling back to Epoch (base 0): 17  Top Validation Acc: 0.9493670886075949
Fold [2/5] Epoch [0/100] Initial Loss: 0.1430, Training Loss: 0.1430, Initial Validation Loss: 0.1312, Validation Loss: 0.1312,V Acc: 0.3604, Top 70th Acc: 0.4487, Bottom 30th Acc: 0.1515
Fold [2/5] Epoch [10/100] Initial Loss: 0.1430, Training Loss: 0.0297, Initial Validation Loss: 0.1312, Validation Loss: 0.0404,V Acc: 0.8198, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.5455
Fold [2/5] Epoch [20/100] Initial Loss: 0.1430, Training Loss: 0.0172, Initial Validation Loss: 0.1312, Validation Loss: 0.0360,V Acc: 0.8198, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 28  Rolling back to Epoch (base 0): 23  Top Validation Acc: 0.9358974358974359
Fold [3/5] Epoch [0/100] Initial Loss: 0.1378, Training Loss: 0.1378, Initial Validation Loss: 0.1308, Validation Loss: 0.1308,V Acc: 0.4182, Top 70th Acc: 0.4416, Bottom 30th Acc: 0.3636
Fold [3/5] Epoch [10/100] Initial Loss: 0.1378, Training Loss: 0.0279, Initial Validation Loss: 0.1308, Validation Loss: 0.0357,V Acc: 0.8182, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.5758
Fold [3/5] Epoch [20/100] Initial Loss: 0.1378, Training Loss: 0.0174, Initial Validation Loss: 0.1308, Validation Loss: 0.0346,V Acc: 0.8091, Top 70th Acc: 0.8961, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 20  Rolling back to Epoch (base 0): 15  Top Validation Acc: 0.8961038961038961
31 2 [array([0.6279662 , 0.09936967, 0.09477849, 0.08932689, 0.08855879],
      dtype=float32)]
Fold [4/5] Epoch [0/100] Initial Loss: 0.1367, Training Loss: 0.1367, Initial Validation Loss: 0.1349, Validation Loss: 0.1349,V Acc: 0.3119, Top 70th Acc: 0.3636, Bottom 30th Acc: 0.1875
Fold [4/5] Epoch [10/100] Initial Loss: 0.1367, Training Loss: 0.0344, Initial Validation Loss: 0.1349, Validation Loss: 0.0388,V Acc: 0.8532, Top 70th Acc: 0.8961, Bottom 30th Acc: 0.7500
Fold [4/5] Epoch [20/100] Initial Loss: 0.1367, Training Loss: 0.0187, Initial Validation Loss: 0.1349, Validation Loss: 0.0279,V Acc: 0.8624, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.6250
Stopping early at Epoch (base 0): 27  Rolling back to Epoch (base 0): 22  Top Validation Acc: 0.974025974025974
Fold [5/5] Epoch [0/100] Initial Loss: 0.1417, Training Loss: 0.1417, Initial Validation Loss: 0.1332, Validation Loss: 0.1332,V Acc: 0.2685, Top 70th Acc: 0.2763, Bottom 30th Acc: 0.2500
Fold [5/5] Epoch [10/100] Initial Loss: 0.1417, Training Loss: 0.0313, Initial Validation Loss: 0.1332, Validation Loss: 0.0330,V Acc: 0.8704, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.6875
Fold [5/5] Epoch [20/100] Initial Loss: 0.1417, Training Loss: 0.0191, Initial Validation Loss: 0.1332, Validation Loss: 0.0263,V Acc: 0.8333, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.5312
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.9605263157894737
Running train_nn.py with seed 32
CUDA:False
Training samples count:  550
Training on 30 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1415, Training Loss: 0.1415, Initial Validation Loss: 0.1347, Validation Loss: 0.1347,V Acc: 0.2321, Top 70th Acc: 0.2785, Bottom 30th Acc: 0.1212
Fold [1/5] Epoch [10/100] Initial Loss: 0.1415, Training Loss: 0.0347, Initial Validation Loss: 0.1347, Validation Loss: 0.0352,V Acc: 0.8214, Top 70th Acc: 0.9367, Bottom 30th Acc: 0.5455
Fold [1/5] Epoch [20/100] Initial Loss: 0.1415, Training Loss: 0.0184, Initial Validation Loss: 0.1347, Validation Loss: 0.0298,V Acc: 0.8571, Top 70th Acc: 0.9241, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.9367088607594937
Fold [2/5] Epoch [0/100] Initial Loss: 0.1377, Training Loss: 0.1377, Initial Validation Loss: 0.1354, Validation Loss: 0.1354,V Acc: 0.2432, Top 70th Acc: 0.3077, Bottom 30th Acc: 0.0909
Fold [2/5] Epoch [10/100] Initial Loss: 0.1377, Training Loss: 0.0391, Initial Validation Loss: 0.1354, Validation Loss: 0.0524,V Acc: 0.7928, Top 70th Acc: 0.8846, Bottom 30th Acc: 0.5758
Fold [2/5] Epoch [20/100] Initial Loss: 0.1377, Training Loss: 0.0174, Initial Validation Loss: 0.1354, Validation Loss: 0.0408,V Acc: 0.8108, Top 70th Acc: 0.8974, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.8717948717948718
Fold [3/5] Epoch [0/100] Initial Loss: 0.1398, Training Loss: 0.1398, Initial Validation Loss: 0.1321, Validation Loss: 0.1321,V Acc: 0.3000, Top 70th Acc: 0.3636, Bottom 30th Acc: 0.1515
Fold [3/5] Epoch [10/100] Initial Loss: 0.1398, Training Loss: 0.0330, Initial Validation Loss: 0.1321, Validation Loss: 0.0385,V Acc: 0.8455, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.6970
Fold [3/5] Epoch [20/100] Initial Loss: 0.1398, Training Loss: 0.0182, Initial Validation Loss: 0.1321, Validation Loss: 0.0309,V Acc: 0.8636, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.6970
Fold [3/5] Epoch [30/100] Initial Loss: 0.1398, Training Loss: 0.0158, Initial Validation Loss: 0.1321, Validation Loss: 0.0313,V Acc: 0.8636, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 30  Rolling back to Epoch (base 0): 25  Top Validation Acc: 0.935064935064935
32 2 [array([0.4107854 , 0.18142423, 0.07414361, 0.15006143, 0.18358539],
      dtype=float32)]
Fold [5/5] Epoch [10/100] Initial Loss: 0.1375, Training Loss: 0.0822, Initial Validation Loss: 0.1287, Validation Loss: 0.0728,V Acc: 0.6574, Top 70th Acc: 0.8026, Bottom 30th Acc: 0.3125
Fold [5/5] Epoch [20/100] Initial Loss: 0.1375, Training Loss: 0.0804, Initial Validation Loss: 0.1287, Validation Loss: 0.0716,V Acc: 0.6574, Top 70th Acc: 0.7500, Bottom 30th Acc: 0.4375
Fold [5/5] Epoch [30/100] Initial Loss: 0.1375, Training Loss: 0.0802, Initial Validation Loss: 0.1287, Validation Loss: 0.0705,V Acc: 0.6667, Top 70th Acc: 0.7763, Bottom 30th Acc: 0.4062
Stopping early at Epoch (base 0): 39  Rolling back to Epoch (base 0): 34  Top Validation Acc: 0.7631578947368421
Running train_nn.py with seed 31
CUDA:False
Training samples count:  550
Training on 2 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1362, Training Loss: 0.1362, Initial Validation Loss: 0.1320, Validation Loss: 0.1320,V Acc: 0.5446, Top 70th Acc: 0.5823, Bottom 30th Acc: 0.4545
Fold [1/5] Epoch [10/100] Initial Loss: 0.1362, Training Loss: 0.0807, Initial Validation Loss: 0.1320, Validation Loss: 0.0814,V Acc: 0.6250, Top 70th Acc: 0.7468, Bottom 30th Acc: 0.3333
Fold [1/5] Epoch [20/100] Initial Loss: 0.1362, Training Loss: 0.0788, Initial Validation Loss: 0.1320, Validation Loss: 0.0787,V Acc: 0.6339, Top 70th Acc: 0.7468, Bottom 30th Acc: 0.3636
Fold [1/5] Epoch [30/100] Initial Loss: 0.1362, Training Loss: 0.0781, Initial Validation Loss: 0.1320, Validation Loss: 0.0786,V Acc: 0.6339, Top 70th Acc: 0.7468, Bottom 30th Acc: 0.3636
Stopping early at Epoch (base 0): 32  Rolling back to Epoch (base 0): 27  Top Validation Acc: 0.7341772151898734
Fold [2/5] Epoch [0/100] Initial Loss: 0.1404, Training Loss: 0.1404, Initial Validation Loss: 0.1304, Validation Loss: 0.1304,V Acc: 0.2973, Top 70th Acc: 0.3462, Bottom 30th Acc: 0.1818
Fold [2/5] Epoch [10/100] Initial Loss: 0.1404, Training Loss: 0.0790, Initial Validation Loss: 0.1304, Validation Loss: 0.0829,V Acc: 0.6126, Top 70th Acc: 0.7179, Bottom 30th Acc: 0.3636
Fold [2/5] Epoch [20/100] Initial Loss: 0.1404, Training Loss: 0.0767, Initial Validation Loss: 0.1304, Validation Loss: 0.0822,V Acc: 0.5856, Top 70th Acc: 0.7179, Bottom 30th Acc: 0.2727
Stopping early at Epoch (base 0): 29  Rolling back to Epoch (base 0): 24  Top Validation Acc: 0.7307692307692307
Fold [3/5] Epoch [0/100] Initial Loss: 0.1371, Training Loss: 0.1371, Initial Validation Loss: 0.1244, Validation Loss: 0.1244,V Acc: 0.3909, Top 70th Acc: 0.4545, Bottom 30th Acc: 0.2424
Fold [3/5] Epoch [10/100] Initial Loss: 0.1371, Training Loss: 0.0811, Initial Validation Loss: 0.1244, Validation Loss: 0.0776,V Acc: 0.6364, Top 70th Acc: 0.7532, Bottom 30th Acc: 0.3636
Fold [3/5] Epoch [20/100] Initial Loss: 0.1371, Training Loss: 0.0791, Initial Validation Loss: 0.1244, Validation Loss: 0.0766,V Acc: 0.6091, Top 70th Acc: 0.7403, Bottom 30th Acc: 0.3030
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.7532467532467533
31 2 [array([0.12973629, 0.37364736, 0.13358855, 0.20872734, 0.15430048],
      dtype=float32)]
Fold [4/5] Epoch [0/100] Initial Loss: 0.1320, Training Loss: 0.1320, Initial Validation Loss: 0.1237, Validation Loss: 0.1237,V Acc: 0.3945, Top 70th Acc: 0.4805, Bottom 30th Acc: 0.1875
Fold [4/5] Epoch [10/100] Initial Loss: 0.1320, Training Loss: 0.0797, Initial Validation Loss: 0.1237, Validation Loss: 0.0832,V Acc: 0.6147, Top 70th Acc: 0.7273, Bottom 30th Acc: 0.3438
Fold [4/5] Epoch [20/100] Initial Loss: 0.1320, Training Loss: 0.0774, Initial Validation Loss: 0.1237, Validation Loss: 0.0818,V Acc: 0.6055, Top 70th Acc: 0.7403, Bottom 30th Acc: 0.2812
Stopping early at Epoch (base 0): 21  Rolling back to Epoch (base 0): 16  Top Validation Acc: 0.7402597402597403
Fold [5/5] Epoch [0/100] Initial Loss: 0.1395, Training Loss: 0.1395, Initial Validation Loss: 0.1290, Validation Loss: 0.1290,V Acc: 0.3148, Top 70th Acc: 0.3947, Bottom 30th Acc: 0.1250
Fold [5/5] Epoch [10/100] Initial Loss: 0.1395, Training Loss: 0.0827, Initial Validation Loss: 0.1290, Validation Loss: 0.0705,V Acc: 0.6574, Top 70th Acc: 0.7895, Bottom 30th Acc: 0.3438
Fold [5/5] Epoch [20/100] Initial Loss: 0.1395, Training Loss: 0.0806, Initial Validation Loss: 0.1290, Validation Loss: 0.0685,V Acc: 0.6667, Top 70th Acc: 0.7895, Bottom 30th Acc: 0.3750
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.7894736842105263
Running train_nn.py with seed 32
CUDA:False
Training samples count:  550
Training on 2 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1358, Training Loss: 0.1358, Initial Validation Loss: 0.1211, Validation Loss: 0.1211,V Acc: 0.4286, Top 70th Acc: 0.5570, Bottom 30th Acc: 0.1212
Fold [1/5] Epoch [10/100] Initial Loss: 0.1358, Training Loss: 0.0816, Initial Validation Loss: 0.1211, Validation Loss: 0.0771,V Acc: 0.6250, Top 70th Acc: 0.7089, Bottom 30th Acc: 0.4242
Fold [1/5] Epoch [20/100] Initial Loss: 0.1358, Training Loss: 0.0801, Initial Validation Loss: 0.1211, Validation Loss: 0.0762,V Acc: 0.6161, Top 70th Acc: 0.7215, Bottom 30th Acc: 0.3636
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.7215189873417721
Fold [2/5] Epoch [0/100] Initial Loss: 0.1310, Training Loss: 0.1310, Initial Validation Loss: 0.1218, Validation Loss: 0.1218,V Acc: 0.5135, Top 70th Acc: 0.5769, Bottom 30th Acc: 0.3636
Fold [2/5] Epoch [10/100] Initial Loss: 0.1310, Training Loss: 0.0790, Initial Validation Loss: 0.1218, Validation Loss: 0.0833,V Acc: 0.6486, Top 70th Acc: 0.7179, Bottom 30th Acc: 0.4848
Fold [2/5] Epoch [20/100] Initial Loss: 0.1310, Training Loss: 0.0771, Initial Validation Loss: 0.1218, Validation Loss: 0.0834,V Acc: 0.6306, Top 70th Acc: 0.7051, Bottom 30th Acc: 0.4545
Stopping early at Epoch (base 0): 22  Rolling back to Epoch (base 0): 17  Top Validation Acc: 0.717948717948718
Fold [3/5] Epoch [0/100] Initial Loss: 0.1398, Training Loss: 0.1398, Initial Validation Loss: 0.1297, Validation Loss: 0.1297,V Acc: 0.3182, Top 70th Acc: 0.3896, Bottom 30th Acc: 0.1515
Fold [3/5] Epoch [10/100] Initial Loss: 0.1398, Training Loss: 0.0813, Initial Validation Loss: 0.1297, Validation Loss: 0.0822,V Acc: 0.6091, Top 70th Acc: 0.7403, Bottom 30th Acc: 0.3030
Fold [3/5] Epoch [20/100] Initial Loss: 0.1398, Training Loss: 0.0791, Initial Validation Loss: 0.1297, Validation Loss: 0.0798,V Acc: 0.6091, Top 70th Acc: 0.7403, Bottom 30th Acc: 0.3030
Fold [3/5] Epoch [30/100] Initial Loss: 0.1398, Training Loss: 0.0783, Initial Validation Loss: 0.1297, Validation Loss: 0.0796,V Acc: 0.5909, Top 70th Acc: 0.7273, Bottom 30th Acc: 0.2727
Stopping early at Epoch (base 0): 30  Rolling back to Epoch (base 0): 25  Top Validation Acc: 0.7272727272727273
32 2 [array([0.09837837, 0.37323424, 0.14423417, 0.2139557 , 0.17019758],
      dtype=float32)]
Fold [4/5] Epoch [0/100] Initial Loss: 0.1236, Training Loss: 0.1236, Initial Validation Loss: 0.1125, Validation Loss: 0.1125,V Acc: 0.5872, Top 70th Acc: 0.6883, Bottom 30th Acc: 0.3438
Fold [4/5] Epoch [10/100] Initial Loss: 0.1236, Training Loss: 0.0811, Initial Validation Loss: 0.1125, Validation Loss: 0.0753,V Acc: 0.6422, Top 70th Acc: 0.7662, Bottom 30th Acc: 0.3438
Fold [4/5] Epoch [20/100] Initial Loss: 0.1236, Training Loss: 0.0791, Initial Validation Loss: 0.1125, Validation Loss: 0.0738,V Acc: 0.6789, Top 70th Acc: 0.7662, Bottom 30th Acc: 0.4688
Fold [4/5] Epoch [30/100] Initial Loss: 0.1236, Training Loss: 0.0781, Initial Validation Loss: 0.1125, Validation Loss: 0.0731,V Acc: 0.6972, Top 70th Acc: 0.7922, Bottom 30th Acc: 0.4688
Stopping early at Epoch (base 0): 39  Rolling back to Epoch (base 0): 34  Top Validation Acc: 0.7922077922077922
Fold [5/5] Epoch [0/100] Initial Loss: 0.1336, Training Loss: 0.1336, Initial Validation Loss: 0.1190, Validation Loss: 0.1190,V Acc: 0.4815, Top 70th Acc: 0.5658, Bottom 30th Acc: 0.2812
Fold [5/5] Epoch [10/100] Initial Loss: 0.1336, Training Loss: 0.0810, Initial Validation Loss: 0.1190, Validation Loss: 0.0794,V Acc: 0.6111, Top 70th Acc: 0.7105, Bottom 30th Acc: 0.3750
Fold [5/5] Epoch [20/100] Initial Loss: 0.1336, Training Loss: 0.0782, Initial Validation Loss: 0.1190, Validation Loss: 0.0783,V Acc: 0.6296, Top 70th Acc: 0.7500, Bottom 30th Acc: 0.3438
Fold [5/5] Epoch [10/100] Initial Loss: 0.1400, Training Loss: 0.0325, Initial Validation Loss: 0.1316, Validation Loss: 0.0370,V Acc: 0.8056, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.5000
Fold [5/5] Epoch [20/100] Initial Loss: 0.1400, Training Loss: 0.0161, Initial Validation Loss: 0.1316, Validation Loss: 0.0312,V Acc: 0.8519, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.5938
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.9605263157894737
Running train_nn.py with seed 33
CUDA:False
Training samples count:  550
Training on 40 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1390, Training Loss: 0.1390, Initial Validation Loss: 0.1348, Validation Loss: 0.1348,V Acc: 0.3839, Top 70th Acc: 0.4684, Bottom 30th Acc: 0.1818
Fold [1/5] Epoch [10/100] Initial Loss: 0.1390, Training Loss: 0.0319, Initial Validation Loss: 0.1348, Validation Loss: 0.0350,V Acc: 0.8304, Top 70th Acc: 0.9367, Bottom 30th Acc: 0.5758
Fold [1/5] Epoch [20/100] Initial Loss: 0.1390, Training Loss: 0.0158, Initial Validation Loss: 0.1348, Validation Loss: 0.0269,V Acc: 0.8482, Top 70th Acc: 0.9620, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 22  Rolling back to Epoch (base 0): 17  Top Validation Acc: 0.9493670886075949
Fold [2/5] Epoch [0/100] Initial Loss: 0.1387, Training Loss: 0.1387, Initial Validation Loss: 0.1338, Validation Loss: 0.1338,V Acc: 0.3423, Top 70th Acc: 0.3846, Bottom 30th Acc: 0.2424
Fold [2/5] Epoch [10/100] Initial Loss: 0.1387, Training Loss: 0.0268, Initial Validation Loss: 0.1338, Validation Loss: 0.0364,V Acc: 0.8018, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.4545
Fold [2/5] Epoch [20/100] Initial Loss: 0.1387, Training Loss: 0.0147, Initial Validation Loss: 0.1338, Validation Loss: 0.0307,V Acc: 0.8468, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.9615384615384616
Fold [3/5] Epoch [0/100] Initial Loss: 0.1385, Training Loss: 0.1385, Initial Validation Loss: 0.1345, Validation Loss: 0.1345,V Acc: 0.2455, Top 70th Acc: 0.2857, Bottom 30th Acc: 0.1515
Fold [3/5] Epoch [10/100] Initial Loss: 0.1385, Training Loss: 0.0274, Initial Validation Loss: 0.1345, Validation Loss: 0.0436,V Acc: 0.8000, Top 70th Acc: 0.8831, Bottom 30th Acc: 0.6061
Fold [3/5] Epoch [20/100] Initial Loss: 0.1385, Training Loss: 0.0141, Initial Validation Loss: 0.1345, Validation Loss: 0.0333,V Acc: 0.8455, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.6667
Fold [3/5] Epoch [30/100] Initial Loss: 0.1385, Training Loss: 0.0119, Initial Validation Loss: 0.1345, Validation Loss: 0.0338,V Acc: 0.8364, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 31  Rolling back to Epoch (base 0): 26  Top Validation Acc: 0.922077922077922
Fold [4/5] Epoch [0/100] Initial Loss: 0.1396, Training Loss: 0.1396, Initial Validation Loss: 0.1337, Validation Loss: 0.1337,V Acc: 0.3303, Top 70th Acc: 0.3506, Bottom 30th Acc: 0.2812
Fold [4/5] Epoch [10/100] Initial Loss: 0.1396, Training Loss: 0.0299, Initial Validation Loss: 0.1337, Validation Loss: 0.0313,V Acc: 0.8807, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.6875
Fold [4/5] Epoch [20/100] Initial Loss: 0.1396, Training Loss: 0.0149, Initial Validation Loss: 0.1337, Validation Loss: 0.0251,V Acc: 0.8807, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.6562
Stopping early at Epoch (base 0): 21  Rolling back to Epoch (base 0): 16  Top Validation Acc: 0.961038961038961
Fold [5/5] Epoch [0/100] Initial Loss: 0.1414, Training Loss: 0.1414, Initial Validation Loss: 0.1306, Validation Loss: 0.1306,V Acc: 0.3333, Top 70th Acc: 0.3553, Bottom 30th Acc: 0.2812
Fold [5/5] Epoch [10/100] Initial Loss: 0.1414, Training Loss: 0.0317, Initial Validation Loss: 0.1306, Validation Loss: 0.0407,V Acc: 0.7870, Top 70th Acc: 0.9079, Bottom 30th Acc: 0.5000
Fold [5/5] Epoch [20/100] Initial Loss: 0.1414, Training Loss: 0.0133, Initial Validation Loss: 0.1306, Validation Loss: 0.0316,V Acc: 0.8333, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.5938
Stopping early at Epoch (base 0): 28  Rolling back to Epoch (base 0): 23  Top Validation Acc: 0.9473684210526315
33 4 [array([0.5639335 , 0.035653  , 0.10840876, 0.13023177, 0.16177304],
      dtype=float32)]
Running train_nn.py with seed 34
CUDA:False
Training samples count:  550
Training on 40 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1402, Training Loss: 0.1402, Initial Validation Loss: 0.1362, Validation Loss: 0.1362,V Acc: 0.2589, Top 70th Acc: 0.3165, Bottom 30th Acc: 0.1212
Fold [1/5] Epoch [10/100] Initial Loss: 0.1402, Training Loss: 0.0238, Initial Validation Loss: 0.1362, Validation Loss: 0.0326,V Acc: 0.8571, Top 70th Acc: 0.9114, Bottom 30th Acc: 0.7273
Fold [1/5] Epoch [20/100] Initial Loss: 0.1402, Training Loss: 0.0143, Initial Validation Loss: 0.1362, Validation Loss: 0.0291,V Acc: 0.8482, Top 70th Acc: 0.9494, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.9493670886075949
34 0 [array([0.5988913 , 0.07049383, 0.10944542, 0.07578952, 0.14537984],
      dtype=float32)]
Fold [2/5] Epoch [0/100] Initial Loss: 0.1407, Training Loss: 0.1407, Initial Validation Loss: 0.1349, Validation Loss: 0.1349,V Acc: 0.3243, Top 70th Acc: 0.4231, Bottom 30th Acc: 0.0909
Fold [2/5] Epoch [10/100] Initial Loss: 0.1407, Training Loss: 0.0368, Initial Validation Loss: 0.1349, Validation Loss: 0.0436,V Acc: 0.8018, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.5152
Fold [2/5] Epoch [20/100] Initial Loss: 0.1407, Training Loss: 0.0147, Initial Validation Loss: 0.1349, Validation Loss: 0.0309,V Acc: 0.8198, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.4848
Stopping early at Epoch (base 0): 28  Rolling back to Epoch (base 0): 23  Top Validation Acc: 0.9615384615384616
Fold [3/5] Epoch [0/100] Initial Loss: 0.1371, Training Loss: 0.1371, Initial Validation Loss: 0.1364, Validation Loss: 0.1364,V Acc: 0.3182, Top 70th Acc: 0.2987, Bottom 30th Acc: 0.3636
Fold [3/5] Epoch [10/100] Initial Loss: 0.1371, Training Loss: 0.0285, Initial Validation Loss: 0.1364, Validation Loss: 0.0412,V Acc: 0.8818, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.7273
Fold [3/5] Epoch [20/100] Initial Loss: 0.1371, Training Loss: 0.0156, Initial Validation Loss: 0.1364, Validation Loss: 0.0338,V Acc: 0.8727, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.7273
Fold [3/5] Epoch [30/100] Initial Loss: 0.1371, Training Loss: 0.0118, Initial Validation Loss: 0.1364, Validation Loss: 0.0322,V Acc: 0.8636, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.6970
Fold [3/5] Epoch [40/100] Initial Loss: 0.1371, Training Loss: 0.0105, Initial Validation Loss: 0.1364, Validation Loss: 0.0306,V Acc: 0.8636, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 45  Rolling back to Epoch (base 0): 40  Top Validation Acc: 0.948051948051948
Fold [4/5] Epoch [0/100] Initial Loss: 0.1387, Training Loss: 0.1387, Initial Validation Loss: 0.1309, Validation Loss: 0.1309,V Acc: 0.3486, Top 70th Acc: 0.3766, Bottom 30th Acc: 0.2812
Fold [4/5] Epoch [10/100] Initial Loss: 0.1387, Training Loss: 0.0316, Initial Validation Loss: 0.1309, Validation Loss: 0.0358,V Acc: 0.8073, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.4375
Fold [4/5] Epoch [20/100] Initial Loss: 0.1387, Training Loss: 0.0148, Initial Validation Loss: 0.1309, Validation Loss: 0.0283,V Acc: 0.8532, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.6562
Stopping early at Epoch (base 0): 28  Rolling back to Epoch (base 0): 23  Top Validation Acc: 0.935064935064935
Fold [5/5] Epoch [0/100] Initial Loss: 0.1406, Training Loss: 0.1406, Initial Validation Loss: 0.1286, Validation Loss: 0.1286,V Acc: 0.3241, Top 70th Acc: 0.3421, Bottom 30th Acc: 0.2812
Fold [5/5] Epoch [10/100] Initial Loss: 0.1406, Training Loss: 0.0338, Initial Validation Loss: 0.1286, Validation Loss: 0.0436,V Acc: 0.7685, Top 70th Acc: 0.9079, Bottom 30th Acc: 0.4375
Fold [5/5] Epoch [20/100] Initial Loss: 0.1406, Training Loss: 0.0154, Initial Validation Loss: 0.1286, Validation Loss: 0.0340,V Acc: 0.8148, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.5000
Fold [5/5] Epoch [30/100] Initial Loss: 0.1406, Training Loss: 0.0119, Initial Validation Loss: 0.1286, Validation Loss: 0.0319,V Acc: 0.8426, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.5625
Fold [5/5] Epoch [10/100] Initial Loss: 0.1319, Training Loss: 0.0211, Initial Validation Loss: 0.1118, Validation Loss: 0.0289,V Acc: 0.8611, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.6562
Fold [5/5] Epoch [20/100] Initial Loss: 0.1319, Training Loss: 0.0151, Initial Validation Loss: 0.1118, Validation Loss: 0.0278,V Acc: 0.8611, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.6250
Stopping early at Epoch (base 0): 21  Rolling back to Epoch (base 0): 16  Top Validation Acc: 0.9342105263157895
Running train_nn.py with seed 44
CUDA:False
Training samples count:  550
Training on 21 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1324, Training Loss: 0.1324, Initial Validation Loss: 0.1208, Validation Loss: 0.1208,V Acc: 0.5268, Top 70th Acc: 0.6456, Bottom 30th Acc: 0.2424
Fold [1/5] Epoch [10/100] Initial Loss: 0.1324, Training Loss: 0.0290, Initial Validation Loss: 0.1208, Validation Loss: 0.0330,V Acc: 0.8393, Top 70th Acc: 0.9241, Bottom 30th Acc: 0.6364
Fold [1/5] Epoch [20/100] Initial Loss: 0.1324, Training Loss: 0.0174, Initial Validation Loss: 0.1208, Validation Loss: 0.0267,V Acc: 0.8482, Top 70th Acc: 0.9747, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 27  Rolling back to Epoch (base 0): 22  Top Validation Acc: 0.9493670886075949
44 0 [array([0.6411604 , 0.03580393, 0.01260407, 0.20019217, 0.11023936],
      dtype=float32)]
Fold [2/5] Epoch [0/100] Initial Loss: 0.1310, Training Loss: 0.1310, Initial Validation Loss: 0.1224, Validation Loss: 0.1224,V Acc: 0.5405, Top 70th Acc: 0.6667, Bottom 30th Acc: 0.2424
Fold [2/5] Epoch [10/100] Initial Loss: 0.1310, Training Loss: 0.0348, Initial Validation Loss: 0.1224, Validation Loss: 0.0301,V Acc: 0.9009, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.7879
Fold [2/5] Epoch [20/100] Initial Loss: 0.1310, Training Loss: 0.0201, Initial Validation Loss: 0.1224, Validation Loss: 0.0210,V Acc: 0.9099, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.7576
Fold [2/5] Epoch [30/100] Initial Loss: 0.1310, Training Loss: 0.0153, Initial Validation Loss: 0.1224, Validation Loss: 0.0192,V Acc: 0.8919, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.6970
Fold [2/5] Epoch [40/100] Initial Loss: 0.1310, Training Loss: 0.0134, Initial Validation Loss: 0.1224, Validation Loss: 0.0180,V Acc: 0.9189, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.7879
Fold [2/5] Epoch [50/100] Initial Loss: 0.1310, Training Loss: 0.0125, Initial Validation Loss: 0.1224, Validation Loss: 0.0174,V Acc: 0.9189, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.7879
Stopping early at Epoch (base 0): 51  Rolling back to Epoch (base 0): 46  Top Validation Acc: 0.9615384615384616
Fold [3/5] Epoch [0/100] Initial Loss: 0.1328, Training Loss: 0.1328, Initial Validation Loss: 0.1152, Validation Loss: 0.1152,V Acc: 0.4364, Top 70th Acc: 0.5844, Bottom 30th Acc: 0.0909
Fold [3/5] Epoch [10/100] Initial Loss: 0.1328, Training Loss: 0.0273, Initial Validation Loss: 0.1152, Validation Loss: 0.0290,V Acc: 0.8909, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.7273
Fold [3/5] Epoch [20/100] Initial Loss: 0.1328, Training Loss: 0.0159, Initial Validation Loss: 0.1152, Validation Loss: 0.0223,V Acc: 0.9000, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.7273
Fold [3/5] Epoch [30/100] Initial Loss: 0.1328, Training Loss: 0.0116, Initial Validation Loss: 0.1152, Validation Loss: 0.0229,V Acc: 0.8636, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 30  Rolling back to Epoch (base 0): 25  Top Validation Acc: 0.961038961038961
Fold [4/5] Epoch [0/100] Initial Loss: 0.1379, Training Loss: 0.1379, Initial Validation Loss: 0.1261, Validation Loss: 0.1261,V Acc: 0.4128, Top 70th Acc: 0.5065, Bottom 30th Acc: 0.1875
Fold [4/5] Epoch [10/100] Initial Loss: 0.1379, Training Loss: 0.0250, Initial Validation Loss: 0.1261, Validation Loss: 0.0297,V Acc: 0.8440, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.5938
Stopping early at Epoch (base 0): 19  Rolling back to Epoch (base 0): 14  Top Validation Acc: 0.935064935064935
Fold [5/5] Epoch [0/100] Initial Loss: 0.1385, Training Loss: 0.1385, Initial Validation Loss: 0.1285, Validation Loss: 0.1285,V Acc: 0.3704, Top 70th Acc: 0.3684, Bottom 30th Acc: 0.3750
Fold [5/5] Epoch [10/100] Initial Loss: 0.1385, Training Loss: 0.0244, Initial Validation Loss: 0.1285, Validation Loss: 0.0289,V Acc: 0.8611, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.6250
Fold [5/5] Epoch [20/100] Initial Loss: 0.1385, Training Loss: 0.0177, Initial Validation Loss: 0.1285, Validation Loss: 0.0256,V Acc: 0.8426, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.5938
Stopping early at Epoch (base 0): 28  Rolling back to Epoch (base 0): 23  Top Validation Acc: 0.9605263157894737
Running train_nn.py with seed 45
CUDA:False
Training samples count:  550
Training on 21 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1369, Training Loss: 0.1369, Initial Validation Loss: 0.1258, Validation Loss: 0.1258,V Acc: 0.5268, Top 70th Acc: 0.6456, Bottom 30th Acc: 0.2424
Fold [1/5] Epoch [10/100] Initial Loss: 0.1369, Training Loss: 0.0225, Initial Validation Loss: 0.1258, Validation Loss: 0.0291,V Acc: 0.8929, Top 70th Acc: 0.9367, Bottom 30th Acc: 0.7879
Fold [1/5] Epoch [20/100] Initial Loss: 0.1369, Training Loss: 0.0154, Initial Validation Loss: 0.1258, Validation Loss: 0.0307,V Acc: 0.8661, Top 70th Acc: 0.9367, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 21  Rolling back to Epoch (base 0): 16  Top Validation Acc: 0.9367088607594937
Fold [2/5] Epoch [0/100] Initial Loss: 0.1348, Training Loss: 0.1348, Initial Validation Loss: 0.1200, Validation Loss: 0.1200,V Acc: 0.4144, Top 70th Acc: 0.5385, Bottom 30th Acc: 0.1212
Fold [2/5] Epoch [10/100] Initial Loss: 0.1348, Training Loss: 0.0271, Initial Validation Loss: 0.1200, Validation Loss: 0.0200,V Acc: 0.9099, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.7879
Fold [2/5] Epoch [20/100] Initial Loss: 0.1348, Training Loss: 0.0184, Initial Validation Loss: 0.1200, Validation Loss: 0.0199,V Acc: 0.8829, Top 70th Acc: 0.9872, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 22  Rolling back to Epoch (base 0): 17  Top Validation Acc: 0.9743589743589743
Fold [3/5] Epoch [0/100] Initial Loss: 0.1355, Training Loss: 0.1355, Initial Validation Loss: 0.1235, Validation Loss: 0.1235,V Acc: 0.4545, Top 70th Acc: 0.6104, Bottom 30th Acc: 0.0909
Fold [3/5] Epoch [10/100] Initial Loss: 0.1355, Training Loss: 0.0232, Initial Validation Loss: 0.1235, Validation Loss: 0.0264,V Acc: 0.8727, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.6364
Fold [3/5] Epoch [20/100] Initial Loss: 0.1355, Training Loss: 0.0164, Initial Validation Loss: 0.1235, Validation Loss: 0.0267,V Acc: 0.8364, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.5152
Stopping early at Epoch (base 0): 27  Rolling back to Epoch (base 0): 22  Top Validation Acc: 0.974025974025974
45 2 [array([0.83829343, 0.0108333 , 0.03126414, 0.05888889, 0.06072033],
      dtype=float32)]
Fold [4/5] Epoch [0/100] Initial Loss: 0.1305, Training Loss: 0.1305, Initial Validation Loss: 0.1169, Validation Loss: 0.1169,V Acc: 0.5321, Top 70th Acc: 0.6623, Bottom 30th Acc: 0.2188
Fold [4/5] Epoch [10/100] Initial Loss: 0.1305, Training Loss: 0.0228, Initial Validation Loss: 0.1169, Validation Loss: 0.0225,V Acc: 0.9266, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.8438
Fold [4/5] Epoch [20/100] Initial Loss: 0.1305, Training Loss: 0.0143, Initial Validation Loss: 0.1169, Validation Loss: 0.0239,V Acc: 0.9174, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.8125
Stopping early at Epoch (base 0): 21  Rolling back to Epoch (base 0): 16  Top Validation Acc: 0.961038961038961
Fold [5/5] Epoch [0/100] Initial Loss: 0.1400, Training Loss: 0.1400, Initial Validation Loss: 0.1257, Validation Loss: 0.1257,V Acc: 0.4259, Top 70th Acc: 0.5000, Bottom 30th Acc: 0.2500
Fold [5/5] Epoch [10/100] Initial Loss: 0.1400, Training Loss: 0.0217, Initial Validation Loss: 0.1257, Validation Loss: 0.0343,V Acc: 0.8148, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.4688
Stopping early at Epoch (base 0): 19  Rolling back to Epoch (base 0): 14  Top Validation Acc: 0.9605263157894737
Running train_nn.py with seed 46
CUDA:False
Training samples count:  550
Training on 21 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1253, Training Loss: 0.1253, Initial Validation Loss: 0.1081, Validation Loss: 0.1081,V Acc: 0.5714, Top 70th Acc: 0.6582, Bottom 30th Acc: 0.3636 0.9358974358974359
Fold [3/5] Epoch [0/100] Initial Loss: 0.1388, Training Loss: 0.1388, Initial Validation Loss: 0.1297, Validation Loss: 0.1297,V Acc: 0.3545, Top 70th Acc: 0.4026, Bottom 30th Acc: 0.2424
Fold [3/5] Epoch [10/100] Initial Loss: 0.1388, Training Loss: 0.0325, Initial Validation Loss: 0.1297, Validation Loss: 0.0366,V Acc: 0.8364, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.6364
Fold [3/5] Epoch [20/100] Initial Loss: 0.1388, Training Loss: 0.0240, Initial Validation Loss: 0.1297, Validation Loss: 0.0344,V Acc: 0.8455, Top 70th Acc: 0.8831, Bottom 30th Acc: 0.7576
Stopping early at Epoch (base 0): 22  Rolling back to Epoch (base 0): 17  Top Validation Acc: 0.8701298701298701
32 2 [array([0.24787833, 0.14215817, 0.10929673, 0.20688425, 0.29378247],
      dtype=float32)]
Fold [4/5] Epoch [0/100] Initial Loss: 0.1395, Training Loss: 0.1395, Initial Validation Loss: 0.1342, Validation Loss: 0.1342,V Acc: 0.2936, Top 70th Acc: 0.3377, Bottom 30th Acc: 0.1875
Fold [4/5] Epoch [10/100] Initial Loss: 0.1395, Training Loss: 0.0432, Initial Validation Loss: 0.1342, Validation Loss: 0.0442,V Acc: 0.7982, Top 70th Acc: 0.8961, Bottom 30th Acc: 0.5625
Fold [4/5] Epoch [20/100] Initial Loss: 0.1395, Training Loss: 0.0281, Initial Validation Loss: 0.1342, Validation Loss: 0.0340,V Acc: 0.8257, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.5938
Fold [4/5] Epoch [30/100] Initial Loss: 0.1395, Training Loss: 0.0236, Initial Validation Loss: 0.1342, Validation Loss: 0.0297,V Acc: 0.8532, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6250
Fold [4/5] Epoch [40/100] Initial Loss: 0.1395, Training Loss: 0.0218, Initial Validation Loss: 0.1342, Validation Loss: 0.0286,V Acc: 0.8532, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6250
Fold [4/5] Epoch [50/100] Initial Loss: 0.1395, Training Loss: 0.0210, Initial Validation Loss: 0.1342, Validation Loss: 0.0290,V Acc: 0.8624, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.6875
Stopping early at Epoch (base 0): 50  Rolling back to Epoch (base 0): 45  Top Validation Acc: 0.935064935064935
Fold [5/5] Epoch [0/100] Initial Loss: 0.1362, Training Loss: 0.1362, Initial Validation Loss: 0.1291, Validation Loss: 0.1291,V Acc: 0.2685, Top 70th Acc: 0.3684, Bottom 30th Acc: 0.0312
Fold [5/5] Epoch [10/100] Initial Loss: 0.1362, Training Loss: 0.0331, Initial Validation Loss: 0.1291, Validation Loss: 0.0359,V Acc: 0.8148, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.5312
Fold [5/5] Epoch [20/100] Initial Loss: 0.1362, Training Loss: 0.0238, Initial Validation Loss: 0.1291, Validation Loss: 0.0327,V Acc: 0.8611, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.6875
Stopping early at Epoch (base 0): 20  Rolling back to Epoch (base 0): 15  Top Validation Acc: 0.9342105263157895
Running train_nn.py with seed 33
CUDA:False
Training samples count:  550
Training on 20 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1379, Training Loss: 0.1379, Initial Validation Loss: 0.1348, Validation Loss: 0.1348,V Acc: 0.3750, Top 70th Acc: 0.4430, Bottom 30th Acc: 0.2121
Fold [1/5] Epoch [10/100] Initial Loss: 0.1379, Training Loss: 0.0439, Initial Validation Loss: 0.1348, Validation Loss: 0.0437,V Acc: 0.7857, Top 70th Acc: 0.9241, Bottom 30th Acc: 0.4545
Fold [1/5] Epoch [20/100] Initial Loss: 0.1379, Training Loss: 0.0305, Initial Validation Loss: 0.1348, Validation Loss: 0.0317,V Acc: 0.8482, Top 70th Acc: 0.9620, Bottom 30th Acc: 0.5758
Fold [1/5] Epoch [30/100] Initial Loss: 0.1379, Training Loss: 0.0236, Initial Validation Loss: 0.1348, Validation Loss: 0.0294,V Acc: 0.8482, Top 70th Acc: 0.9494, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 30  Rolling back to Epoch (base 0): 25  Top Validation Acc: 0.9493670886075949
Fold [2/5] Epoch [0/100] Initial Loss: 0.1419, Training Loss: 0.1419, Initial Validation Loss: 0.1377, Validation Loss: 0.1377,V Acc: 0.2523, Top 70th Acc: 0.3590, Bottom 30th Acc: 0.0000
Fold [2/5] Epoch [10/100] Initial Loss: 0.1419, Training Loss: 0.0433, Initial Validation Loss: 0.1377, Validation Loss: 0.0468,V Acc: 0.8198, Top 70th Acc: 0.8974, Bottom 30th Acc: 0.6364
Fold [2/5] Epoch [20/100] Initial Loss: 0.1419, Training Loss: 0.0260, Initial Validation Loss: 0.1377, Validation Loss: 0.0363,V Acc: 0.8198, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.6061
Fold [2/5] Epoch [30/100] Initial Loss: 0.1419, Training Loss: 0.0232, Initial Validation Loss: 0.1377, Validation Loss: 0.0343,V Acc: 0.8018, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.4848
Stopping early at Epoch (base 0): 36  Rolling back to Epoch (base 0): 31  Top Validation Acc: 0.9358974358974359
Fold [3/5] Epoch [0/100] Initial Loss: 0.1403, Training Loss: 0.1403, Initial Validation Loss: 0.1329, Validation Loss: 0.1329,V Acc: 0.4000, Top 70th Acc: 0.4156, Bottom 30th Acc: 0.3636
Fold [3/5] Epoch [10/100] Initial Loss: 0.1403, Training Loss: 0.0407, Initial Validation Loss: 0.1329, Validation Loss: 0.0493,V Acc: 0.7909, Top 70th Acc: 0.8571, Bottom 30th Acc: 0.6364
Fold [3/5] Epoch [20/100] Initial Loss: 0.1403, Training Loss: 0.0237, Initial Validation Loss: 0.1329, Validation Loss: 0.0352,V Acc: 0.8727, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.7879
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.9090909090909091
Fold [4/5] Epoch [0/100] Initial Loss: 0.1403, Training Loss: 0.1403, Initial Validation Loss: 0.1345, Validation Loss: 0.1345,V Acc: 0.2844, Top 70th Acc: 0.2857, Bottom 30th Acc: 0.2812
Fold [4/5] Epoch [10/100] Initial Loss: 0.1403, Training Loss: 0.0410, Initial Validation Loss: 0.1345, Validation Loss: 0.0402,V Acc: 0.7982, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.4688
Fold [4/5] Epoch [20/100] Initial Loss: 0.1403, Training Loss: 0.0257, Initial Validation Loss: 0.1345, Validation Loss: 0.0304,V Acc: 0.8440, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.5312
Stopping early at Epoch (base 0): 27  Rolling back to Epoch (base 0): 22  Top Validation Acc: 0.961038961038961
Fold [5/5] Epoch [0/100] Initial Loss: 0.1408, Training Loss: 0.1408, Initial Validation Loss: 0.1312, Validation Loss: 0.1312,V Acc: 0.2778, Top 70th Acc: 0.2895, Bottom 30th Acc: 0.2500
Fold [5/5] Epoch [10/100] Initial Loss: 0.1408, Training Loss: 0.0480, Initial Validation Loss: 0.1312, Validation Loss: 0.0532,V Acc: 0.7130, Top 70th Acc: 0.8553, Bottom 30th Acc: 0.3750
Fold [5/5] Epoch [20/100] Initial Loss: 0.1408, Training Loss: 0.0255, Initial Validation Loss: 0.1312, Validation Loss: 0.0380,V Acc: 0.7593, Top 70th Acc: 0.9079, Bottom 30th Acc: 0.4062
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.9210526315789473
33 4 [array([0.28124234, 0.10286638, 0.18049447, 0.2880445 , 0.14735234],
      dtype=float32)]
Running train_nn.py with seed 34
CUDA:False
Training samples count:  550
Training on 20 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1390, Training Loss: 0.1390, Initial Validation Loss: 0.1360, Validation Loss: 0.1360,V Acc: 0.3393, Top 70th Acc: 0.3924, Bottom 30th Acc: 0.2121
Fold [1/5] Epoch [10/100] Initial Loss: 0.1390, Training Loss: 0.0460, Initial Validation Loss: 0.1360, Validation Loss: 0.0530,V Acc: 0.7232, Top 70th Acc: 0.8228, Bottom 30th Acc: 0.4848
Fold [1/5] Epoch [20/100] Initial Loss: 0.1390, Training Loss: 0.0318, Initial Validation Loss: 0.1360, Validation Loss: 0.0377,V Acc: 0.8125, Top 70th Acc: 0.8987, Bottom 30th Acc: 0.6061
Fold [1/5] Epoch [30/100] Initial Loss: 0.1390, Training Loss: 0.0235, Initial Validation Loss: 0.1360, Validation Loss: 0.0320,V Acc: 0.8393, Top 70th Acc: 0.9114, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 34  Rolling back to Epoch (base 0): 29  Top Validation Acc: 0.9113924050632911
34 0 [array([0.38842425, 0.11315597, 0.1360505 , 0.2661254 , 0.09624392],
      dtype=float32)]
Fold [2/5] Epoch [0/100] Initial Loss: 0.1382, Training Loss: 0.1382, Initial Validation Loss: 0.1343, Validation Loss: 0.1343,V Acc: 0.3333, Top 70th Acc: 0.3846, Bottom 30th Acc: 0.2121
Fold [2/5] Epoch [10/100] Initial Loss: 0.1382, Training Loss: 0.0424, Initial Validation Loss: 0.1343, Validation Loss: 0.0505,V Acc: 0.7658, Top 70th Acc: 0.8974, Bottom 30th Acc: 0.4545
Fold [2/5] Epoch [20/100] Initial Loss: 0.1382, Training Loss: 0.0285, Initial Validation Loss: 0.1343, Validation Loss: 0.0436,V Acc: 0.7838, Top 70th Acc: 0.8846, Bottom 30th Acc: 0.5455/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)

Fold [5/5] Epoch [20/100] Initial Loss: 0.1390, Training Loss: 0.0047, Initial Validation Loss: 0.1273, Validation Loss: 0.0267,V Acc: 0.8611, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.6250
Stopping early at Epoch (base 0): 22  Rolling back to Epoch (base 0): 17  Top Validation Acc: 0.9473684210526315
Running train_nn.py with seed 25
CUDA:False
Training samples count:  550
Training on 162 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1425, Training Loss: 0.1425, Initial Validation Loss: 0.1377, Validation Loss: 0.1377,V Acc: 0.2500, Top 70th Acc: 0.3165, Bottom 30th Acc: 0.0909
Fold [1/5] Epoch [10/100] Initial Loss: 0.1425, Training Loss: 0.0133, Initial Validation Loss: 0.1377, Validation Loss: 0.0289,V Acc: 0.8661, Top 70th Acc: 0.9494, Bottom 30th Acc: 0.6667
Fold [1/5] Epoch [20/100] Initial Loss: 0.1425, Training Loss: 0.0050, Initial Validation Loss: 0.1377, Validation Loss: 0.0259,V Acc: 0.8661, Top 70th Acc: 0.9494, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.9493670886075949
Fold [2/5] Epoch [0/100] Initial Loss: 0.1393, Training Loss: 0.1393, Initial Validation Loss: 0.1406, Validation Loss: 0.1406,V Acc: 0.2613, Top 70th Acc: 0.2949, Bottom 30th Acc: 0.1818
Fold [2/5] Epoch [10/100] Initial Loss: 0.1393, Training Loss: 0.0334, Initial Validation Loss: 0.1406, Validation Loss: 0.0471,V Acc: 0.7658, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.3939
Fold [2/5] Epoch [20/100] Initial Loss: 0.1393, Training Loss: 0.0069, Initial Validation Loss: 0.1406, Validation Loss: 0.0290,V Acc: 0.8919, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.7273
Fold [2/5] Epoch [30/100] Initial Loss: 0.1393, Training Loss: 0.0042, Initial Validation Loss: 0.1406, Validation Loss: 0.0278,V Acc: 0.8739, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 31  Rolling back to Epoch (base 0): 26  Top Validation Acc: 0.9743589743589743
Fold [3/5] Epoch [0/100] Initial Loss: 0.1387, Training Loss: 0.1387, Initial Validation Loss: 0.1327, Validation Loss: 0.1327,V Acc: 0.2909, Top 70th Acc: 0.3506, Bottom 30th Acc: 0.1515
Fold [3/5] Epoch [10/100] Initial Loss: 0.1387, Training Loss: 0.0158, Initial Validation Loss: 0.1327, Validation Loss: 0.0338,V Acc: 0.8364, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.5455
Fold [3/5] Epoch [20/100] Initial Loss: 0.1387, Training Loss: 0.0050, Initial Validation Loss: 0.1327, Validation Loss: 0.0290,V Acc: 0.8364, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.5152
Fold [3/5] Epoch [30/100] Initial Loss: 0.1387, Training Loss: 0.0040, Initial Validation Loss: 0.1327, Validation Loss: 0.0292,V Acc: 0.8273, Top 70th Acc: 0.9870, Bottom 30th Acc: 0.4545
Stopping early at Epoch (base 0): 32  Rolling back to Epoch (base 0): 27  Top Validation Acc: 0.987012987012987
25 2 [array([0.35835734, 0.02466763, 0.06337005, 0.2608281 , 0.29277685],
      dtype=float32)]
Fold [4/5] Epoch [0/100] Initial Loss: 0.1399, Training Loss: 0.1399, Initial Validation Loss: 0.1314, Validation Loss: 0.1314,V Acc: 0.2477, Top 70th Acc: 0.2987, Bottom 30th Acc: 0.1250
Fold [4/5] Epoch [10/100] Initial Loss: 0.1399, Training Loss: 0.0208, Initial Validation Loss: 0.1314, Validation Loss: 0.0368,V Acc: 0.8349, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.6250
Fold [4/5] Epoch [20/100] Initial Loss: 0.1399, Training Loss: 0.0050, Initial Validation Loss: 0.1314, Validation Loss: 0.0269,V Acc: 0.8899, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.6875
Stopping early at Epoch (base 0): 28  Rolling back to Epoch (base 0): 23  Top Validation Acc: 0.974025974025974
Fold [5/5] Epoch [0/100] Initial Loss: 0.1395, Training Loss: 0.1395, Initial Validation Loss: 0.1293, Validation Loss: 0.1293,V Acc: 0.3426, Top 70th Acc: 0.4079, Bottom 30th Acc: 0.1875
Fold [5/5] Epoch [10/100] Initial Loss: 0.1395, Training Loss: 0.0124, Initial Validation Loss: 0.1293, Validation Loss: 0.0438,V Acc: 0.7685, Top 70th Acc: 0.8947, Bottom 30th Acc: 0.4688
Fold [5/5] Epoch [20/100] Initial Loss: 0.1395, Training Loss: 0.0045, Initial Validation Loss: 0.1293, Validation Loss: 0.0394,V Acc: 0.8241, Top 70th Acc: 0.8816, Bottom 30th Acc: 0.6875
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.881578947368421
Running train_nn.py with seed 26
CUDA:False
Training samples count:  550
Training on 162 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1388, Training Loss: 0.1388, Initial Validation Loss: 0.1314, Validation Loss: 0.1314,V Acc: 0.4107, Top 70th Acc: 0.4937, Bottom 30th Acc: 0.2121
Fold [1/5] Epoch [10/100] Initial Loss: 0.1388, Training Loss: 0.0160, Initial Validation Loss: 0.1314, Validation Loss: 0.0293,V Acc: 0.8929, Top 70th Acc: 0.9620, Bottom 30th Acc: 0.7273
Fold [1/5] Epoch [20/100] Initial Loss: 0.1388, Training Loss: 0.0051, Initial Validation Loss: 0.1314, Validation Loss: 0.0241,V Acc: 0.8929, Top 70th Acc: 0.9620, Bottom 30th Acc: 0.7273
Fold [1/5] Epoch [30/100] Initial Loss: 0.1388, Training Loss: 0.0039, Initial Validation Loss: 0.1314, Validation Loss: 0.0239,V Acc: 0.8839, Top 70th Acc: 0.9620, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 32  Rolling back to Epoch (base 0): 27  Top Validation Acc: 0.9493670886075949
Fold [2/5] Epoch [0/100] Initial Loss: 0.1372, Training Loss: 0.1372, Initial Validation Loss: 0.1349, Validation Loss: 0.1349,V Acc: 0.3514, Top 70th Acc: 0.4103, Bottom 30th Acc: 0.2121
Fold [2/5] Epoch [10/100] Initial Loss: 0.1372, Training Loss: 0.0170, Initial Validation Loss: 0.1349, Validation Loss: 0.0319,V Acc: 0.8559, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.6364
Fold [2/5] Epoch [20/100] Initial Loss: 0.1372, Training Loss: 0.0060, Initial Validation Loss: 0.1349, Validation Loss: 0.0268,V Acc: 0.8649, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.6364
Fold [2/5] Epoch [30/100] Initial Loss: 0.1372, Training Loss: 0.0046, Initial Validation Loss: 0.1349, Validation Loss: 0.0260,V Acc: 0.8739, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.6667
Fold [2/5] Epoch [40/100] Initial Loss: 0.1372, Training Loss: 0.0042, Initial Validation Loss: 0.1349, Validation Loss: 0.0250,V Acc: 0.8649, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.6364
Fold [2/5] Epoch [50/100] Initial Loss: 0.1372, Training Loss: 0.0040, Initial Validation Loss: 0.1349, Validation Loss: 0.0247,V Acc: 0.8739, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 52  Rolling back to Epoch (base 0): 47  Top Validation Acc: 0.9743589743589743
26 1 [array([0.29092315, 0.05817661, 0.05436913, 0.29174557, 0.30478552],
      dtype=float32)]
Fold [3/5] Epoch [0/100] Initial Loss: 0.1386, Training Loss: 0.1386, Initial Validation Loss: 0.1337, Validation Loss: 0.1337,V Acc: 0.2636, Top 70th Acc: 0.3247, Bottom 30th Acc: 0.1212
Fold [3/5] Epoch [10/100] Initial Loss: 0.1386, Training Loss: 0.0270, Initial Validation Loss: 0.1337, Validation Loss: 0.0603,V Acc: 0.7091, Top 70th Acc: 0.7662, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 17  Rolling back to Epoch (base 0): 12  Top Validation Acc: 0.8181818181818182
Fold [4/5] Epoch [0/100] Initial Loss: 0.1390, Training Loss: 0.1390, Initial Validation Loss: 0.1337, Validation Loss: 0.1337,V Acc: 0.3394, Top 70th Acc: 0.3506, Bottom 30th Acc: 0.3125
Fold [4/5] Epoch [10/100] Initial Loss: 0.1390, Training Loss: 0.0256, Initial Validation Loss: 0.1337, Validation Loss: 0.0471,V Acc: 0.7798, Top 70th Acc: 0.8831, Bottom 30th Acc: 0.5312
Fold [4/5] Epoch [20/100] Initial Loss: 0.1390, Training Loss: 0.0051, Initial Validation Loss: 0.1337, Validation Loss: 0.0364,V Acc: 0.7982, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.4688
Stopping early at Epoch (base 0): 28  Rolling back to Epoch (base 0): 23  Top Validation Acc: 0.948051948051948
Fold [5/5] Epoch [0/100] Initial Loss: 0.1409, Training Loss: 0.1409, Initial Validation Loss: 0.1323, Validation Loss: 0.1323,V Acc: 0.3333, Top 70th Acc: 0.3684, Bottom 30th Acc: 0.2500
Fold [5/5] Epoch [10/100] Initial Loss: 0.1409, Training Loss: 0.0201, Initial Validation Loss: 0.1323, Validation Loss: 0.0366,V Acc: 0.8519, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.6562
Fold [5/5] Epoch [20/100] Initial Loss: 0.1409, Training Loss: 0.0050, Initial Validation Loss: 0.1323, Validation Loss: 0.0285,V Acc: 0.8796, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.6875
Fold [4/5] Epoch [0/100] Initial Loss: 0.1382, Training Loss: 0.1382, Initial Validation Loss: 0.1331, Validation Loss: 0.1331,V Acc: 0.3303, Top 70th Acc: 0.3377, Bottom 30th Acc: 0.3125
Fold [4/5] Epoch [10/100] Initial Loss: 0.1382, Training Loss: 0.0315, Initial Validation Loss: 0.1331, Validation Loss: 0.0323,V Acc: 0.8807, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.7188
Fold [4/5] Epoch [20/100] Initial Loss: 0.1382, Training Loss: 0.0205, Initial Validation Loss: 0.1331, Validation Loss: 0.0209,V Acc: 0.9083, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.7500
Fold [4/5] Epoch [30/100] Initial Loss: 0.1382, Training Loss: 0.0181, Initial Validation Loss: 0.1331, Validation Loss: 0.0200,V Acc: 0.9174, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.7812
Fold [4/5] Epoch [40/100] Initial Loss: 0.1382, Training Loss: 0.0167, Initial Validation Loss: 0.1331, Validation Loss: 0.0200,V Acc: 0.9083, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.7500
Stopping early at Epoch (base 0): 41  Rolling back to Epoch (base 0): 36  Top Validation Acc: 0.974025974025974
Fold [5/5] Epoch [0/100] Initial Loss: 0.1414, Training Loss: 0.1414, Initial Validation Loss: 0.1330, Validation Loss: 0.1330,V Acc: 0.2500, Top 70th Acc: 0.3158, Bottom 30th Acc: 0.0938
Fold [5/5] Epoch [10/100] Initial Loss: 0.1414, Training Loss: 0.0422, Initial Validation Loss: 0.1330, Validation Loss: 0.0454,V Acc: 0.7778, Top 70th Acc: 0.8684, Bottom 30th Acc: 0.5625
Fold [5/5] Epoch [20/100] Initial Loss: 0.1414, Training Loss: 0.0207, Initial Validation Loss: 0.1330, Validation Loss: 0.0293,V Acc: 0.8611, Top 70th Acc: 0.9737, Bottom 30th Acc: 0.5938
Fold [5/5] Epoch [30/100] Initial Loss: 0.1414, Training Loss: 0.0159, Initial Validation Loss: 0.1330, Validation Loss: 0.0282,V Acc: 0.8704, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.6562
Stopping early at Epoch (base 0): 34  Rolling back to Epoch (base 0): 29  Top Validation Acc: 0.9736842105263158
Running train_nn.py with seed 33
CUDA:False
Training samples count:  550
Training on 30 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1378, Training Loss: 0.1378, Initial Validation Loss: 0.1340, Validation Loss: 0.1340,V Acc: 0.4107, Top 70th Acc: 0.5063, Bottom 30th Acc: 0.1818
Fold [1/5] Epoch [10/100] Initial Loss: 0.1378, Training Loss: 0.0317, Initial Validation Loss: 0.1340, Validation Loss: 0.0332,V Acc: 0.8304, Top 70th Acc: 0.9241, Bottom 30th Acc: 0.6061
Fold [1/5] Epoch [20/100] Initial Loss: 0.1378, Training Loss: 0.0188, Initial Validation Loss: 0.1340, Validation Loss: 0.0268,V Acc: 0.8571, Top 70th Acc: 0.9494, Bottom 30th Acc: 0.6364
Fold [1/5] Epoch [30/100] Initial Loss: 0.1378, Training Loss: 0.0164, Initial Validation Loss: 0.1340, Validation Loss: 0.0260,V Acc: 0.8571, Top 70th Acc: 0.9620, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 30  Rolling back to Epoch (base 0): 25  Top Validation Acc: 0.9620253164556962
Fold [2/5] Epoch [0/100] Initial Loss: 0.1379, Training Loss: 0.1379, Initial Validation Loss: 0.1345, Validation Loss: 0.1345,V Acc: 0.2613, Top 70th Acc: 0.2949, Bottom 30th Acc: 0.1818
Fold [2/5] Epoch [10/100] Initial Loss: 0.1379, Training Loss: 0.0291, Initial Validation Loss: 0.1345, Validation Loss: 0.0367,V Acc: 0.8378, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.5758
Fold [2/5] Epoch [20/100] Initial Loss: 0.1379, Training Loss: 0.0192, Initial Validation Loss: 0.1345, Validation Loss: 0.0304,V Acc: 0.8739, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.7273
Fold [2/5] Epoch [30/100] Initial Loss: 0.1379, Training Loss: 0.0170, Initial Validation Loss: 0.1345, Validation Loss: 0.0302,V Acc: 0.8829, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 36  Rolling back to Epoch (base 0): 31  Top Validation Acc: 0.9487179487179487
Fold [3/5] Epoch [0/100] Initial Loss: 0.1408, Training Loss: 0.1408, Initial Validation Loss: 0.1342, Validation Loss: 0.1342,V Acc: 0.3727, Top 70th Acc: 0.4026, Bottom 30th Acc: 0.3030
Fold [3/5] Epoch [10/100] Initial Loss: 0.1408, Training Loss: 0.0501, Initial Validation Loss: 0.1342, Validation Loss: 0.0582,V Acc: 0.7545, Top 70th Acc: 0.8442, Bottom 30th Acc: 0.5455
Fold [3/5] Epoch [20/100] Initial Loss: 0.1408, Training Loss: 0.0214, Initial Validation Loss: 0.1342, Validation Loss: 0.0373,V Acc: 0.7909, Top 70th Acc: 0.8961, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 27  Rolling back to Epoch (base 0): 22  Top Validation Acc: 0.9090909090909091
Fold [4/5] Epoch [0/100] Initial Loss: 0.1402, Training Loss: 0.1402, Initial Validation Loss: 0.1308, Validation Loss: 0.1308,V Acc: 0.3853, Top 70th Acc: 0.4286, Bottom 30th Acc: 0.2812
Fold [4/5] Epoch [10/100] Initial Loss: 0.1402, Training Loss: 0.0300, Initial Validation Loss: 0.1308, Validation Loss: 0.0303,V Acc: 0.8716, Top 70th Acc: 0.9870, Bottom 30th Acc: 0.5938
Fold [4/5] Epoch [20/100] Initial Loss: 0.1402, Training Loss: 0.0188, Initial Validation Loss: 0.1308, Validation Loss: 0.0234,V Acc: 0.9083, Top 70th Acc: 0.9870, Bottom 30th Acc: 0.7188
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.987012987012987
Fold [5/5] Epoch [0/100] Initial Loss: 0.1393, Training Loss: 0.1393, Initial Validation Loss: 0.1309, Validation Loss: 0.1309,V Acc: 0.3056, Top 70th Acc: 0.3026, Bottom 30th Acc: 0.3125
Fold [5/5] Epoch [10/100] Initial Loss: 0.1393, Training Loss: 0.0329, Initial Validation Loss: 0.1309, Validation Loss: 0.0461,V Acc: 0.7315, Top 70th Acc: 0.8553, Bottom 30th Acc: 0.4375
Fold [5/5] Epoch [20/100] Initial Loss: 0.1393, Training Loss: 0.0180, Initial Validation Loss: 0.1309, Validation Loss: 0.0378,V Acc: 0.7870, Top 70th Acc: 0.9211, Bottom 30th Acc: 0.4688
Fold [5/5] Epoch [30/100] Initial Loss: 0.1393, Training Loss: 0.0143, Initial Validation Loss: 0.1309, Validation Loss: 0.0364,V Acc: 0.7778, Top 70th Acc: 0.8947, Bottom 30th Acc: 0.5000
Stopping early at Epoch (base 0): 34  Rolling back to Epoch (base 0): 29  Top Validation Acc: 0.9210526315789473
33 4 [array([0.72208786, 0.04739939, 0.02551684, 0.12011582, 0.08488017],
      dtype=float32)]
Running train_nn.py with seed 34
CUDA:False
Training samples count:  550
Training on 30 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1398, Training Loss: 0.1398, Initial Validation Loss: 0.1353, Validation Loss: 0.1353,V Acc: 0.3393, Top 70th Acc: 0.4051, Bottom 30th Acc: 0.1818
Fold [1/5] Epoch [10/100] Initial Loss: 0.1398, Training Loss: 0.0444, Initial Validation Loss: 0.1353, Validation Loss: 0.0539,V Acc: 0.7500, Top 70th Acc: 0.8354, Bottom 30th Acc: 0.5455
Fold [1/5] Epoch [20/100] Initial Loss: 0.1398, Training Loss: 0.0236, Initial Validation Loss: 0.1353, Validation Loss: 0.0352,V Acc: 0.8036, Top 70th Acc: 0.9494, Bottom 30th Acc: 0.4545
Fold [1/5] Epoch [30/100] Initial Loss: 0.1398, Training Loss: 0.0165, Initial Validation Loss: 0.1353, Validation Loss: 0.0313,V Acc: 0.8393, Top 70th Acc: 0.9620, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 34  Rolling back to Epoch (base 0): 29  Top Validation Acc: 0.9620253164556962
34 0 [array([0.72661424, 0.05186107, 0.03328861, 0.0895744 , 0.09866163],
      dtype=float32)]
Fold [2/5] Epoch [0/100] Initial Loss: 0.1390, Training Loss: 0.1390, Initial Validation Loss: 0.1360, Validation Loss: 0.1360,V Acc: 0.2613, Top 70th Acc: 0.3333, Bottom 30th Acc: 0.0909
Fold [2/5] Epoch [10/100] Initial Loss: 0.1390, Training Loss: 0.0384, Initial Validation Loss: 0.1360, Validation Loss: 0.0447,V Acc: 0.7838, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.4848
Fold [2/5] Epoch [20/100] Initial Loss: 0.1390, Training Loss: 0.0178, Initial Validation Loss: 0.1360, Validation Loss: 0.0325,V Acc: 0.8198, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.5152
Stopping early at Epoch (base 0): 27  Rolling back to Epoch (base 0): 22  Top Validation Acc: 0.9615384615384616
Fold [3/5] Epoch [0/100] Initial Loss: 0.1374, Training Loss: 0.1374, Initial Validation Loss: 0.1339, Validation Loss: 0.1339,V Acc: 0.3727, Top 70th Acc: 0.4675, Bottom 30th Acc: 0.1515
Fold [3/5] Epoch [10/100] Initial Loss: 0.1374, Training Loss: 0.0348, Initial Validation Loss: 0.1339, Validation Loss: 0.0488,V Acc: 0.7727, Top 70th Acc: 0.8701, Bottom 30th Acc: 0.5455
Training on 20 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 46
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 20 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 47
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 20 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 48
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 20 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 49
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 20 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 50
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 20 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 51
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 20 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 52
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 20 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 53
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 20 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 54
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 20 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 55
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 20 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 56
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 20 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 57
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 20 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 58
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 20 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 59
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 20 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 60
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 20 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 61
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 20 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 62
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 20 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 63
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 20 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 64
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 20 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 65
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 20 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 66
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 20 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 67
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 20 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 68
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 20 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 69
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 20 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 70
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 20 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 71
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 20 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 72
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 20 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 73
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 20 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 74
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 20 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 75
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 20 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 76
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 20 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 77
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 20 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 78
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 20 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 79
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 20 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 80
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 20 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 81
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 20 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 82
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 20 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 83
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 20 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 84
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 20 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 85
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 19 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 86
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 20 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 87
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 20 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 88
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 20 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 89
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 20 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 90
Training size: 438
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.75
Running train_nn.py with seed 33
CUDA:False
Training samples count:  550
Training on 2 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1328, Training Loss: 0.1328, Initial Validation Loss: 0.1225, Validation Loss: 0.1225,V Acc: 0.4196, Top 70th Acc: 0.4684, Bottom 30th Acc: 0.3030
Fold [1/5] Epoch [10/100] Initial Loss: 0.1328, Training Loss: 0.0819, Initial Validation Loss: 0.1225, Validation Loss: 0.0809,V Acc: 0.6429, Top 70th Acc: 0.7595, Bottom 30th Acc: 0.3636
Fold [1/5] Epoch [20/100] Initial Loss: 0.1328, Training Loss: 0.0796, Initial Validation Loss: 0.1225, Validation Loss: 0.0783,V Acc: 0.6250, Top 70th Acc: 0.7468, Bottom 30th Acc: 0.3333
Fold [1/5] Epoch [30/100] Initial Loss: 0.1328, Training Loss: 0.0790, Initial Validation Loss: 0.1225, Validation Loss: 0.0785,V Acc: 0.6161, Top 70th Acc: 0.7595, Bottom 30th Acc: 0.2727
Stopping early at Epoch (base 0): 30  Rolling back to Epoch (base 0): 25  Top Validation Acc: 0.759493670886076
Fold [2/5] Epoch [0/100] Initial Loss: 0.1380, Training Loss: 0.1380, Initial Validation Loss: 0.1339, Validation Loss: 0.1339,V Acc: 0.2793, Top 70th Acc: 0.3974, Bottom 30th Acc: 0.0000
Fold [2/5] Epoch [10/100] Initial Loss: 0.1380, Training Loss: 0.0807, Initial Validation Loss: 0.1339, Validation Loss: 0.0802,V Acc: 0.6216, Top 70th Acc: 0.7179, Bottom 30th Acc: 0.3939
Stopping early at Epoch (base 0): 17  Rolling back to Epoch (base 0): 12  Top Validation Acc: 0.7307692307692307
Fold [3/5] Epoch [0/100] Initial Loss: 0.1330, Training Loss: 0.1330, Initial Validation Loss: 0.1214, Validation Loss: 0.1214,V Acc: 0.5000, Top 70th Acc: 0.5455, Bottom 30th Acc: 0.3939
Fold [3/5] Epoch [10/100] Initial Loss: 0.1330, Training Loss: 0.0796, Initial Validation Loss: 0.1214, Validation Loss: 0.0827,V Acc: 0.6182, Top 70th Acc: 0.7013, Bottom 30th Acc: 0.4242
Fold [3/5] Epoch [20/100] Initial Loss: 0.1330, Training Loss: 0.0774, Initial Validation Loss: 0.1214, Validation Loss: 0.0821,V Acc: 0.6091, Top 70th Acc: 0.7013, Bottom 30th Acc: 0.3939
Stopping early at Epoch (base 0): 22  Rolling back to Epoch (base 0): 17  Top Validation Acc: 0.7142857142857143
Fold [4/5] Epoch [0/100] Initial Loss: 0.1424, Training Loss: 0.1424, Initial Validation Loss: 0.1336, Validation Loss: 0.1336,V Acc: 0.3028, Top 70th Acc: 0.3377, Bottom 30th Acc: 0.2188
Fold [4/5] Epoch [10/100] Initial Loss: 0.1424, Training Loss: 0.0803, Initial Validation Loss: 0.1336, Validation Loss: 0.0783,V Acc: 0.6055, Top 70th Acc: 0.7532, Bottom 30th Acc: 0.2500
Stopping early at Epoch (base 0): 17  Rolling back to Epoch (base 0): 12  Top Validation Acc: 0.7402597402597403
Fold [5/5] Epoch [0/100] Initial Loss: 0.1387, Training Loss: 0.1387, Initial Validation Loss: 0.1244, Validation Loss: 0.1244,V Acc: 0.3426, Top 70th Acc: 0.3947, Bottom 30th Acc: 0.2188
Fold [5/5] Epoch [10/100] Initial Loss: 0.1387, Training Loss: 0.0810, Initial Validation Loss: 0.1244, Validation Loss: 0.0761,V Acc: 0.6204, Top 70th Acc: 0.7368, Bottom 30th Acc: 0.3438
Fold [5/5] Epoch [20/100] Initial Loss: 0.1387, Training Loss: 0.0789, Initial Validation Loss: 0.1244, Validation Loss: 0.0754,V Acc: 0.6204, Top 70th Acc: 0.7500, Bottom 30th Acc: 0.3125
Fold [5/5] Epoch [30/100] Initial Loss: 0.1387, Training Loss: 0.0784, Initial Validation Loss: 0.1244, Validation Loss: 0.0747,V Acc: 0.6204, Top 70th Acc: 0.7632, Bottom 30th Acc: 0.2812
Stopping early at Epoch (base 0): 38  Rolling back to Epoch (base 0): 33  Top Validation Acc: 0.75
33 4 [array([0.14075376, 0.35401285, 0.14005493, 0.22190042, 0.14327806],
      dtype=float32)]
Running train_nn.py with seed 34
CUDA:False
Training samples count:  550
Training on 2 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1371, Training Loss: 0.1371, Initial Validation Loss: 0.1285, Validation Loss: 0.1285,V Acc: 0.3839, Top 70th Acc: 0.4557, Bottom 30th Acc: 0.2121
Fold [1/5] Epoch [10/100] Initial Loss: 0.1371, Training Loss: 0.0796, Initial Validation Loss: 0.1285, Validation Loss: 0.0839,V Acc: 0.6071, Top 70th Acc: 0.7089, Bottom 30th Acc: 0.3636
Fold [1/5] Epoch [20/100] Initial Loss: 0.1371, Training Loss: 0.0781, Initial Validation Loss: 0.1285, Validation Loss: 0.0828,V Acc: 0.6339, Top 70th Acc: 0.6962, Bottom 30th Acc: 0.4848
Stopping early at Epoch (base 0): 28  Rolling back to Epoch (base 0): 23  Top Validation Acc: 0.7088607594936709
34 0 [array([0.12208502, 0.37717384, 0.14035425, 0.21721464, 0.14317223],
      dtype=float32)]
Fold [2/5] Epoch [0/100] Initial Loss: 0.1338, Training Loss: 0.1338, Initial Validation Loss: 0.1246, Validation Loss: 0.1246,V Acc: 0.4865, Top 70th Acc: 0.5256, Bottom 30th Acc: 0.3939
Fold [2/5] Epoch [10/100] Initial Loss: 0.1338, Training Loss: 0.0835, Initial Validation Loss: 0.1246, Validation Loss: 0.0729,V Acc: 0.6577, Top 70th Acc: 0.7949, Bottom 30th Acc: 0.3333
Fold [2/5] Epoch [20/100] Initial Loss: 0.1338, Training Loss: 0.0815, Initial Validation Loss: 0.1246, Validation Loss: 0.0707,V Acc: 0.6757, Top 70th Acc: 0.7949, Bottom 30th Acc: 0.3939
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.782051282051282
Fold [3/5] Epoch [0/100] Initial Loss: 0.1344, Training Loss: 0.1344, Initial Validation Loss: 0.1293, Validation Loss: 0.1293,V Acc: 0.3818, Top 70th Acc: 0.4286, Bottom 30th Acc: 0.2727
Fold [3/5] Epoch [10/100] Initial Loss: 0.1344, Training Loss: 0.0797, Initial Validation Loss: 0.1293, Validation Loss: 0.0816,V Acc: 0.6273, Top 70th Acc: 0.7662, Bottom 30th Acc: 0.3030
Fold [3/5] Epoch [20/100] Initial Loss: 0.1344, Training Loss: 0.0782, Initial Validation Loss: 0.1293, Validation Loss: 0.0802,V Acc: 0.6273, Top 70th Acc: 0.7792, Bottom 30th Acc: 0.2727
Fold [3/5] Epoch [30/100] Initial Loss: 0.1344, Training Loss: 0.0775, Initial Validation Loss: 0.1293, Validation Loss: 0.0802,V Acc: 0.6364, Top 70th Acc: 0.7662, Bottom 30th Acc: 0.3333
Stopping early at Epoch (base 0): 39  Rolling back to Epoch (base 0): 34  Top Validation Acc: 0.7922077922077922
Fold [4/5] Epoch [0/100] Initial Loss: 0.1380, Training Loss: 0.1380, Initial Validation Loss: 0.1244, Validation Loss: 0.1244,V Acc: 0.4495, Top 70th Acc: 0.5065, Bottom 30th Acc: 0.3125
Fold [4/5] Epoch [10/100] Initial Loss: 0.1380, Training Loss: 0.0783, Initial Validation Loss: 0.1244, Validation Loss: 0.0832,V Acc: 0.5688, Top 70th Acc: 0.6753, Bottom 30th Acc: 0.3125
Fold [4/5] Epoch [20/100] Initial Loss: 0.1380, Training Loss: 0.0759, Initial Validation Loss: 0.1244, Validation Loss: 0.0830,V Acc: 0.5872, Top 70th Acc: 0.6623, Bottom 30th Acc: 0.4062
Stopping early at Epoch (base 0): 21  Rolling back to Epoch (base 0): 16  Top Validation Acc: 0.6883116883116883
Fold [5/5] Epoch [0/100] Initial Loss: 0.1423, Training Loss: 0.1423, Initial Validation Loss: 0.1278, Validation Loss: 0.1278,V Acc: 0.3981, Top 70th Acc: 0.5000, Bottom 30th Acc: 0.1562
Fold [5/5] Epoch [10/100] Initial Loss: 0.1423, Training Loss: 0.0833, Initial Validation Loss: 0.1278, Validation Loss: 0.0747,V Acc: 0.6759, Top 70th Acc: 0.7763, Bottom 30th Acc: 0.4375
Fold [5/5] Epoch [20/100] Initial Loss: 0.1423, Training Loss: 0.0810, Initial Validation Loss: 0.1278, Validation Loss: 0.0723,V Acc: 0.6574, Top 70th Acc: 0.7763, Bottom 30th Acc: 0.3750
Fold [5/5] Epoch [30/100] Initial Loss: 0.1423, Training Loss: 0.0805, Initial Validation Loss: 0.1278, Validation Loss: 0.0711,V Acc: 0.6759, Top 70th Acc: 0.7632, Bottom 30th Acc: 0.4688
Fold [5/5] Epoch [40/100] Initial Loss: 0.1423, Training Loss: 0.0803, Initial Validation Loss: 0.1278, Validation Loss: 0.0709,V Acc: 0.6759, Top 70th Acc: 0.7763, Bottom 30th Acc: 0.4375
Stopping early at Epoch (base 0): 40  Rolling back to Epoch (base 0): 35  Top Validation Acc: 0.7763157894736842
Running train_nn.py with seed 35
CUDA:False
Training samples count:  550
Training on 2 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1336, Training Loss: 0.1336, Initial Validation Loss: 0.1211, Validation Loss: 0.1211,V Acc: 0.3393, Top 70th Acc: 0.4177, Bottom 30th Acc: 0.1515
Fold [1/5] Epoch [10/100] Initial Loss: 0.1336, Training Loss: 0.0823, Initial Validation Loss: 0.1211, Validation Loss: 0.0736,V Acc: 0.6696, Top 70th Acc: 0.7975, Bottom 30th Acc: 0.3636
Stopping early at Epoch (base 0): 35  Rolling back to Epoch (base 0): 30  Top Validation Acc: 0.9605263157894737
Running train_nn.py with seed 35
CUDA:False
Training samples count:  550
Training on 40 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1407, Training Loss: 0.1407, Initial Validation Loss: 0.1375, Validation Loss: 0.1375,V Acc: 0.2500, Top 70th Acc: 0.2405, Bottom 30th Acc: 0.2727
Fold [1/5] Epoch [10/100] Initial Loss: 0.1407, Training Loss: 0.0351, Initial Validation Loss: 0.1375, Validation Loss: 0.0347,V Acc: 0.8839, Top 70th Acc: 0.9620, Bottom 30th Acc: 0.6970
Fold [1/5] Epoch [20/100] Initial Loss: 0.1407, Training Loss: 0.0152, Initial Validation Loss: 0.1375, Validation Loss: 0.0283,V Acc: 0.8571, Top 70th Acc: 0.9494, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 22  Rolling back to Epoch (base 0): 17  Top Validation Acc: 0.9620253164556962
Fold [2/5] Epoch [0/100] Initial Loss: 0.1403, Training Loss: 0.1403, Initial Validation Loss: 0.1357, Validation Loss: 0.1357,V Acc: 0.2703, Top 70th Acc: 0.3718, Bottom 30th Acc: 0.0303
Fold [2/5] Epoch [10/100] Initial Loss: 0.1403, Training Loss: 0.0317, Initial Validation Loss: 0.1357, Validation Loss: 0.0455,V Acc: 0.7658, Top 70th Acc: 0.8590, Bottom 30th Acc: 0.5455
Fold [2/5] Epoch [20/100] Initial Loss: 0.1403, Training Loss: 0.0187, Initial Validation Loss: 0.1357, Validation Loss: 0.0423,V Acc: 0.7748, Top 70th Acc: 0.8846, Bottom 30th Acc: 0.5152
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.8974358974358975
Fold [3/5] Epoch [0/100] Initial Loss: 0.1393, Training Loss: 0.1393, Initial Validation Loss: 0.1336, Validation Loss: 0.1336,V Acc: 0.2545, Top 70th Acc: 0.3117, Bottom 30th Acc: 0.1212
Fold [3/5] Epoch [10/100] Initial Loss: 0.1393, Training Loss: 0.0332, Initial Validation Loss: 0.1336, Validation Loss: 0.0448,V Acc: 0.7909, Top 70th Acc: 0.8961, Bottom 30th Acc: 0.5455
Fold [3/5] Epoch [20/100] Initial Loss: 0.1393, Training Loss: 0.0176, Initial Validation Loss: 0.1336, Validation Loss: 0.0379,V Acc: 0.8182, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.5758
Fold [3/5] Epoch [30/100] Initial Loss: 0.1393, Training Loss: 0.0124, Initial Validation Loss: 0.1336, Validation Loss: 0.0328,V Acc: 0.8545, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.6061
Fold [3/5] Epoch [40/100] Initial Loss: 0.1393, Training Loss: 0.0106, Initial Validation Loss: 0.1336, Validation Loss: 0.0313,V Acc: 0.8455, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6061
Fold [3/5] Epoch [50/100] Initial Loss: 0.1393, Training Loss: 0.0100, Initial Validation Loss: 0.1336, Validation Loss: 0.0312,V Acc: 0.8364, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 50  Rolling back to Epoch (base 0): 45  Top Validation Acc: 0.935064935064935
35 2 [array([0.7661267 , 0.0423885 , 0.06218299, 0.07382986, 0.05547187],
      dtype=float32)]
Fold [4/5] Epoch [0/100] Initial Loss: 0.1404, Training Loss: 0.1404, Initial Validation Loss: 0.1320, Validation Loss: 0.1320,V Acc: 0.3119, Top 70th Acc: 0.3766, Bottom 30th Acc: 0.1562
Fold [4/5] Epoch [10/100] Initial Loss: 0.1404, Training Loss: 0.0277, Initial Validation Loss: 0.1320, Validation Loss: 0.0353,V Acc: 0.8349, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.5312
Fold [4/5] Epoch [20/100] Initial Loss: 0.1404, Training Loss: 0.0138, Initial Validation Loss: 0.1320, Validation Loss: 0.0272,V Acc: 0.8716, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6875
Fold [4/5] Epoch [30/100] Initial Loss: 0.1404, Training Loss: 0.0117, Initial Validation Loss: 0.1320, Validation Loss: 0.0256,V Acc: 0.8807, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.7188
Stopping early at Epoch (base 0): 31  Rolling back to Epoch (base 0): 26  Top Validation Acc: 0.948051948051948
Fold [5/5] Epoch [0/100] Initial Loss: 0.1406, Training Loss: 0.1406, Initial Validation Loss: 0.1341, Validation Loss: 0.1341,V Acc: 0.2963, Top 70th Acc: 0.3158, Bottom 30th Acc: 0.2500
Fold [5/5] Epoch [10/100] Initial Loss: 0.1406, Training Loss: 0.0212, Initial Validation Loss: 0.1341, Validation Loss: 0.0356,V Acc: 0.8333, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.5312
Fold [5/5] Epoch [20/100] Initial Loss: 0.1406, Training Loss: 0.0131, Initial Validation Loss: 0.1341, Validation Loss: 0.0330,V Acc: 0.8148, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.4688
Stopping early at Epoch (base 0): 29  Rolling back to Epoch (base 0): 24  Top Validation Acc: 0.9473684210526315
Running train_nn.py with seed 36
CUDA:False
Training samples count:  550
Training on 40 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1409, Training Loss: 0.1409, Initial Validation Loss: 0.1320, Validation Loss: 0.1320,V Acc: 0.3661, Top 70th Acc: 0.4177, Bottom 30th Acc: 0.2424
Fold [1/5] Epoch [10/100] Initial Loss: 0.1409, Training Loss: 0.0262, Initial Validation Loss: 0.1320, Validation Loss: 0.0382,V Acc: 0.8214, Top 70th Acc: 0.9114, Bottom 30th Acc: 0.6061
Fold [1/5] Epoch [20/100] Initial Loss: 0.1409, Training Loss: 0.0133, Initial Validation Loss: 0.1320, Validation Loss: 0.0352,V Acc: 0.8214, Top 70th Acc: 0.8987, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.9113924050632911
Fold [2/5] Epoch [0/100] Initial Loss: 0.1368, Training Loss: 0.1368, Initial Validation Loss: 0.1368, Validation Loss: 0.1368,V Acc: 0.3423, Top 70th Acc: 0.4103, Bottom 30th Acc: 0.1818
Fold [2/5] Epoch [10/100] Initial Loss: 0.1368, Training Loss: 0.0418, Initial Validation Loss: 0.1368, Validation Loss: 0.0530,V Acc: 0.7477, Top 70th Acc: 0.8846, Bottom 30th Acc: 0.4242
Fold [2/5] Epoch [20/100] Initial Loss: 0.1368, Training Loss: 0.0177, Initial Validation Loss: 0.1368, Validation Loss: 0.0362,V Acc: 0.8288, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.5455
Fold [2/5] Epoch [30/100] Initial Loss: 0.1368, Training Loss: 0.0126, Initial Validation Loss: 0.1368, Validation Loss: 0.0311,V Acc: 0.8198, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.4848
Stopping early at Epoch (base 0): 35  Rolling back to Epoch (base 0): 30  Top Validation Acc: 0.9615384615384616
Fold [3/5] Epoch [0/100] Initial Loss: 0.1390, Training Loss: 0.1390, Initial Validation Loss: 0.1344, Validation Loss: 0.1344,V Acc: 0.2818, Top 70th Acc: 0.3247, Bottom 30th Acc: 0.1818
Fold [3/5] Epoch [10/100] Initial Loss: 0.1390, Training Loss: 0.0388, Initial Validation Loss: 0.1344, Validation Loss: 0.0430,V Acc: 0.7909, Top 70th Acc: 0.8831, Bottom 30th Acc: 0.5758
Fold [3/5] Epoch [20/100] Initial Loss: 0.1390, Training Loss: 0.0176, Initial Validation Loss: 0.1344, Validation Loss: 0.0291,V Acc: 0.8545, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.6061
Fold [3/5] Epoch [30/100] Initial Loss: 0.1390, Training Loss: 0.0130, Initial Validation Loss: 0.1344, Validation Loss: 0.0268,V Acc: 0.8636, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 37  Rolling back to Epoch (base 0): 32  Top Validation Acc: 0.987012987012987
Fold [4/5] Epoch [0/100] Initial Loss: 0.1380, Training Loss: 0.1380, Initial Validation Loss: 0.1377, Validation Loss: 0.1377,V Acc: 0.2936, Top 70th Acc: 0.3117, Bottom 30th Acc: 0.2500
Fold [4/5] Epoch [10/100] Initial Loss: 0.1380, Training Loss: 0.0312, Initial Validation Loss: 0.1377, Validation Loss: 0.0396,V Acc: 0.8257, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.5000
Fold [4/5] Epoch [20/100] Initial Loss: 0.1380, Training Loss: 0.0153, Initial Validation Loss: 0.1377, Validation Loss: 0.0279,V Acc: 0.8899, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.6875
Stopping early at Epoch (base 0): 28  Rolling back to Epoch (base 0): 23  Top Validation Acc: 0.987012987012987
Fold [5/5] Epoch [0/100] Initial Loss: 0.1415, Training Loss: 0.1415, Initial Validation Loss: 0.1247, Validation Loss: 0.1247,V Acc: 0.4167, Top 70th Acc: 0.4868, Bottom 30th Acc: 0.2500
Fold [5/5] Epoch [10/100] Initial Loss: 0.1415, Training Loss: 0.0324, Initial Validation Loss: 0.1247, Validation Loss: 0.0367,V Acc: 0.7870, Top 70th Acc: 0.8816, Bottom 30th Acc: 0.5625
Fold [5/5] Epoch [20/100] Initial Loss: 0.1415, Training Loss: 0.0147, Initial Validation Loss: 0.1247, Validation Loss: 0.0289,V Acc: 0.8241, Top 70th Acc: 0.9211, Bottom 30th Acc: 0.5938
Fold [1/5] Epoch [10/100] Initial Loss: 0.1253, Training Loss: 0.0221, Initial Validation Loss: 0.1081, Validation Loss: 0.0280,V Acc: 0.8482, Top 70th Acc: 0.9494, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 19  Rolling back to Epoch (base 0): 14  Top Validation Acc: 0.9746835443037974
Fold [2/5] Epoch [0/100] Initial Loss: 0.1374, Training Loss: 0.1374, Initial Validation Loss: 0.1255, Validation Loss: 0.1255,V Acc: 0.4324, Top 70th Acc: 0.5513, Bottom 30th Acc: 0.1515
Fold [2/5] Epoch [10/100] Initial Loss: 0.1374, Training Loss: 0.0204, Initial Validation Loss: 0.1255, Validation Loss: 0.0240,V Acc: 0.9009, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.7273
Fold [2/5] Epoch [20/100] Initial Loss: 0.1374, Training Loss: 0.0142, Initial Validation Loss: 0.1255, Validation Loss: 0.0209,V Acc: 0.9009, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.7273
Stopping early at Epoch (base 0): 29  Rolling back to Epoch (base 0): 24  Top Validation Acc: 0.9743589743589743
46 1 [array([0.85337347, 0.01326732, 0.00972139, 0.06278061, 0.06085712],
      dtype=float32)]
Fold [3/5] Epoch [0/100] Initial Loss: 0.1323, Training Loss: 0.1323, Initial Validation Loss: 0.1225, Validation Loss: 0.1225,V Acc: 0.4182, Top 70th Acc: 0.5065, Bottom 30th Acc: 0.2121
Fold [3/5] Epoch [10/100] Initial Loss: 0.1323, Training Loss: 0.0271, Initial Validation Loss: 0.1225, Validation Loss: 0.0250,V Acc: 0.8818, Top 70th Acc: 0.9870, Bottom 30th Acc: 0.6364
Fold [3/5] Epoch [20/100] Initial Loss: 0.1323, Training Loss: 0.0164, Initial Validation Loss: 0.1225, Validation Loss: 0.0242,V Acc: 0.8818, Top 70th Acc: 0.9870, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 22  Rolling back to Epoch (base 0): 17  Top Validation Acc: 0.987012987012987
Fold [4/5] Epoch [0/100] Initial Loss: 0.1313, Training Loss: 0.1313, Initial Validation Loss: 0.1151, Validation Loss: 0.1151,V Acc: 0.4587, Top 70th Acc: 0.5584, Bottom 30th Acc: 0.2188
Fold [4/5] Epoch [10/100] Initial Loss: 0.1313, Training Loss: 0.0237, Initial Validation Loss: 0.1151, Validation Loss: 0.0332,V Acc: 0.8257, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.5000
Fold [4/5] Epoch [20/100] Initial Loss: 0.1313, Training Loss: 0.0167, Initial Validation Loss: 0.1151, Validation Loss: 0.0232,V Acc: 0.9083, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.7812
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.961038961038961
Fold [5/5] Epoch [0/100] Initial Loss: 0.1271, Training Loss: 0.1271, Initial Validation Loss: 0.1097, Validation Loss: 0.1097,V Acc: 0.4815, Top 70th Acc: 0.6579, Bottom 30th Acc: 0.0625
Fold [5/5] Epoch [10/100] Initial Loss: 0.1271, Training Loss: 0.0225, Initial Validation Loss: 0.1097, Validation Loss: 0.0280,V Acc: 0.8519, Top 70th Acc: 0.9868, Bottom 30th Acc: 0.5312
Fold [5/5] Epoch [20/100] Initial Loss: 0.1271, Training Loss: 0.0155, Initial Validation Loss: 0.1097, Validation Loss: 0.0267,V Acc: 0.8611, Top 70th Acc: 1.0000, Bottom 30th Acc: 0.5312
Stopping early at Epoch (base 0): 27  Rolling back to Epoch (base 0): 22  Top Validation Acc: 1.0
Running train_nn.py with seed 47
CUDA:False
Training samples count:  550
Training on 21 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1324, Training Loss: 0.1324, Initial Validation Loss: 0.1260, Validation Loss: 0.1260,V Acc: 0.4018, Top 70th Acc: 0.4937, Bottom 30th Acc: 0.1818
Fold [1/5] Epoch [10/100] Initial Loss: 0.1324, Training Loss: 0.0209, Initial Validation Loss: 0.1260, Validation Loss: 0.0346,V Acc: 0.8214, Top 70th Acc: 0.9367, Bottom 30th Acc: 0.5455
Fold [1/5] Epoch [20/100] Initial Loss: 0.1324, Training Loss: 0.0150, Initial Validation Loss: 0.1260, Validation Loss: 0.0291,V Acc: 0.8571, Top 70th Acc: 0.9620, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 29  Rolling back to Epoch (base 0): 24  Top Validation Acc: 0.9620253164556962
Fold [2/5] Epoch [0/100] Initial Loss: 0.1368, Training Loss: 0.1368, Initial Validation Loss: 0.1290, Validation Loss: 0.1290,V Acc: 0.4775, Top 70th Acc: 0.5769, Bottom 30th Acc: 0.2424
Fold [2/5] Epoch [10/100] Initial Loss: 0.1368, Training Loss: 0.0259, Initial Validation Loss: 0.1290, Validation Loss: 0.0416,V Acc: 0.8018, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.5455
Fold [2/5] Epoch [20/100] Initial Loss: 0.1368, Training Loss: 0.0156, Initial Validation Loss: 0.1290, Validation Loss: 0.0288,V Acc: 0.8468, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 20  Rolling back to Epoch (base 0): 15  Top Validation Acc: 0.9743589743589743
47 1 [array([0.8228791 , 0.01290055, 0.02093658, 0.11852951, 0.02475435],
      dtype=float32)]
Fold [3/5] Epoch [0/100] Initial Loss: 0.1315, Training Loss: 0.1315, Initial Validation Loss: 0.1157, Validation Loss: 0.1157,V Acc: 0.4636, Top 70th Acc: 0.5714, Bottom 30th Acc: 0.2121
Fold [3/5] Epoch [10/100] Initial Loss: 0.1315, Training Loss: 0.0261, Initial Validation Loss: 0.1157, Validation Loss: 0.0273,V Acc: 0.8545, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.5758
Fold [3/5] Epoch [20/100] Initial Loss: 0.1315, Training Loss: 0.0177, Initial Validation Loss: 0.1157, Validation Loss: 0.0274,V Acc: 0.8727, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 20  Rolling back to Epoch (base 0): 15  Top Validation Acc: 0.961038961038961
Fold [4/5] Epoch [0/100] Initial Loss: 0.1375, Training Loss: 0.1375, Initial Validation Loss: 0.1244, Validation Loss: 0.1244,V Acc: 0.4495, Top 70th Acc: 0.5455, Bottom 30th Acc: 0.2188
Fold [4/5] Epoch [10/100] Initial Loss: 0.1375, Training Loss: 0.0301, Initial Validation Loss: 0.1244, Validation Loss: 0.0266,V Acc: 0.8899, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.7188
Fold [4/5] Epoch [20/100] Initial Loss: 0.1375, Training Loss: 0.0170, Initial Validation Loss: 0.1244, Validation Loss: 0.0146,V Acc: 0.9174, Top 70th Acc: 1.0000, Bottom 30th Acc: 0.7188
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.974025974025974
Fold [5/5] Epoch [0/100] Initial Loss: 0.1360, Training Loss: 0.1360, Initial Validation Loss: 0.1247, Validation Loss: 0.1247,V Acc: 0.4167, Top 70th Acc: 0.5526, Bottom 30th Acc: 0.0938
Fold [5/5] Epoch [10/100] Initial Loss: 0.1360, Training Loss: 0.0268, Initial Validation Loss: 0.1247, Validation Loss: 0.0359,V Acc: 0.8148, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.5000
Fold [5/5] Epoch [20/100] Initial Loss: 0.1360, Training Loss: 0.0163, Initial Validation Loss: 0.1247, Validation Loss: 0.0298,V Acc: 0.8426, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.5938
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.9473684210526315
Running train_nn.py with seed 48
CUDA:False
Training samples count:  550
Training on 21 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1275, Training Loss: 0.1275, Initial Validation Loss: 0.1131, Validation Loss: 0.1131,V Acc: 0.6071, Top 70th Acc: 0.7215, Bottom 30th Acc: 0.3333
Fold [1/5] Epoch [10/100] Initial Loss: 0.1275, Training Loss: 0.0326, Initial Validation Loss: 0.1131, Validation Loss: 0.0358,V Acc: 0.8214, Top 70th Acc: 0.9367, Bottom 30th Acc: 0.5455
Fold [1/5] Epoch [20/100] Initial Loss: 0.1275, Training Loss: 0.0187, Initial Validation Loss: 0.1131, Validation Loss: 0.0284,V Acc: 0.8661, Top 70th Acc: 0.9367, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 22  Rolling back to Epoch (base 0): 17  Top Validation Acc: 0.9367088607594937
Fold [2/5] Epoch [0/100] Initial Loss: 0.1362, Training Loss: 0.1362, Initial Validation Loss: 0.1305, Validation Loss: 0.1305,V Acc: 0.3964, Top 70th Acc: 0.4744, Bottom 30th Acc: 0.2121
Fold [2/5] Epoch [10/100] Initial Loss: 0.1362, Training Loss: 0.0267, Initial Validation Loss: 0.1305, Validation Loss: 0.0393,V Acc: 0.8468, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.6061
Fold [2/5] Epoch [20/100] Initial Loss: 0.1362, Training Loss: 0.0159, Initial Validation Loss: 0.1305, Validation Loss: 0.0315,V Acc: 0.8649, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.6061
Fold [2/5] Epoch [30/100] Initial Loss: 0.1362, Training Loss: 0.0130, Initial Validation Loss: 0.1305, Validation Loss: 0.0291,V Acc: 0.8739, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.6364
Fold [2/5] Epoch [30/100] Initial Loss: 0.1382, Training Loss: 0.0226, Initial Validation Loss: 0.1343, Validation Loss: 0.0331,V Acc: 0.8468, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.6061
Fold [2/5] Epoch [40/100] Initial Loss: 0.1382, Training Loss: 0.0209, Initial Validation Loss: 0.1343, Validation Loss: 0.0314,V Acc: 0.8468, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 48  Rolling back to Epoch (base 0): 43  Top Validation Acc: 0.9487179487179487
Fold [3/5] Epoch [0/100] Initial Loss: 0.1404, Training Loss: 0.1404, Initial Validation Loss: 0.1369, Validation Loss: 0.1369,V Acc: 0.2909, Top 70th Acc: 0.3247, Bottom 30th Acc: 0.2121
Fold [3/5] Epoch [10/100] Initial Loss: 0.1404, Training Loss: 0.0351, Initial Validation Loss: 0.1369, Validation Loss: 0.0467,V Acc: 0.8273, Top 70th Acc: 0.8701, Bottom 30th Acc: 0.7273
Fold [3/5] Epoch [20/100] Initial Loss: 0.1404, Training Loss: 0.0217, Initial Validation Loss: 0.1369, Validation Loss: 0.0395,V Acc: 0.8364, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.9090909090909091
Fold [4/5] Epoch [0/100] Initial Loss: 0.1407, Training Loss: 0.1407, Initial Validation Loss: 0.1317, Validation Loss: 0.1317,V Acc: 0.3486, Top 70th Acc: 0.3117, Bottom 30th Acc: 0.4375
Fold [4/5] Epoch [10/100] Initial Loss: 0.1407, Training Loss: 0.0414, Initial Validation Loss: 0.1317, Validation Loss: 0.0449,V Acc: 0.7982, Top 70th Acc: 0.8701, Bottom 30th Acc: 0.6250
Fold [4/5] Epoch [20/100] Initial Loss: 0.1407, Training Loss: 0.0243, Initial Validation Loss: 0.1317, Validation Loss: 0.0332,V Acc: 0.8440, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.6562
Fold [4/5] Epoch [30/100] Initial Loss: 0.1407, Training Loss: 0.0218, Initial Validation Loss: 0.1317, Validation Loss: 0.0327,V Acc: 0.8440, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.5938
Stopping early at Epoch (base 0): 30  Rolling back to Epoch (base 0): 25  Top Validation Acc: 0.948051948051948
Fold [5/5] Epoch [0/100] Initial Loss: 0.1386, Training Loss: 0.1386, Initial Validation Loss: 0.1285, Validation Loss: 0.1285,V Acc: 0.2500, Top 70th Acc: 0.3553, Bottom 30th Acc: 0.0000
Fold [5/5] Epoch [10/100] Initial Loss: 0.1386, Training Loss: 0.0388, Initial Validation Loss: 0.1285, Validation Loss: 0.0407,V Acc: 0.8148, Top 70th Acc: 0.9211, Bottom 30th Acc: 0.5625
Fold [5/5] Epoch [20/100] Initial Loss: 0.1386, Training Loss: 0.0248, Initial Validation Loss: 0.1285, Validation Loss: 0.0320,V Acc: 0.8148, Top 70th Acc: 0.9737, Bottom 30th Acc: 0.4375
Fold [5/5] Epoch [30/100] Initial Loss: 0.1386, Training Loss: 0.0227, Initial Validation Loss: 0.1285, Validation Loss: 0.0321,V Acc: 0.8148, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.4688
Stopping early at Epoch (base 0): 30  Rolling back to Epoch (base 0): 25  Top Validation Acc: 0.9605263157894737
Running train_nn.py with seed 35
CUDA:False
Training samples count:  550
Training on 20 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1444, Training Loss: 0.1444, Initial Validation Loss: 0.1344, Validation Loss: 0.1344,V Acc: 0.2500, Top 70th Acc: 0.2911, Bottom 30th Acc: 0.1515
Fold [1/5] Epoch [10/100] Initial Loss: 0.1444, Training Loss: 0.0506, Initial Validation Loss: 0.1344, Validation Loss: 0.0500,V Acc: 0.7857, Top 70th Acc: 0.8987, Bottom 30th Acc: 0.5152
Fold [1/5] Epoch [20/100] Initial Loss: 0.1444, Training Loss: 0.0284, Initial Validation Loss: 0.1344, Validation Loss: 0.0325,V Acc: 0.8482, Top 70th Acc: 0.9367, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 27  Rolling back to Epoch (base 0): 22  Top Validation Acc: 0.9367088607594937
Fold [2/5] Epoch [0/100] Initial Loss: 0.1377, Training Loss: 0.1377, Initial Validation Loss: 0.1341, Validation Loss: 0.1341,V Acc: 0.2523, Top 70th Acc: 0.3205, Bottom 30th Acc: 0.0909
Fold [2/5] Epoch [10/100] Initial Loss: 0.1377, Training Loss: 0.0472, Initial Validation Loss: 0.1341, Validation Loss: 0.0533,V Acc: 0.7387, Top 70th Acc: 0.8333, Bottom 30th Acc: 0.5152
Fold [2/5] Epoch [20/100] Initial Loss: 0.1377, Training Loss: 0.0336, Initial Validation Loss: 0.1341, Validation Loss: 0.0456,V Acc: 0.7658, Top 70th Acc: 0.8974, Bottom 30th Acc: 0.4545
Fold [2/5] Epoch [30/100] Initial Loss: 0.1377, Training Loss: 0.0240, Initial Validation Loss: 0.1341, Validation Loss: 0.0392,V Acc: 0.8018, Top 70th Acc: 0.8974, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 35  Rolling back to Epoch (base 0): 30  Top Validation Acc: 0.8717948717948718
Fold [3/5] Epoch [0/100] Initial Loss: 0.1416, Training Loss: 0.1416, Initial Validation Loss: 0.1363, Validation Loss: 0.1363,V Acc: 0.2273, Top 70th Acc: 0.2727, Bottom 30th Acc: 0.1212
Fold [3/5] Epoch [10/100] Initial Loss: 0.1416, Training Loss: 0.0434, Initial Validation Loss: 0.1363, Validation Loss: 0.0433,V Acc: 0.7909, Top 70th Acc: 0.8961, Bottom 30th Acc: 0.5455
Fold [3/5] Epoch [20/100] Initial Loss: 0.1416, Training Loss: 0.0273, Initial Validation Loss: 0.1363, Validation Loss: 0.0326,V Acc: 0.8182, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.5152
Fold [3/5] Epoch [30/100] Initial Loss: 0.1416, Training Loss: 0.0242, Initial Validation Loss: 0.1363, Validation Loss: 0.0325,V Acc: 0.7909, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.4545
Stopping early at Epoch (base 0): 30  Rolling back to Epoch (base 0): 25  Top Validation Acc: 0.935064935064935
35 2 [array([0.29754564, 0.11598233, 0.18845192, 0.29574636, 0.10227372],
      dtype=float32)]
Fold [4/5] Epoch [0/100] Initial Loss: 0.1373, Training Loss: 0.1373, Initial Validation Loss: 0.1295, Validation Loss: 0.1295,V Acc: 0.3303, Top 70th Acc: 0.3247, Bottom 30th Acc: 0.3438
Fold [4/5] Epoch [10/100] Initial Loss: 0.1373, Training Loss: 0.0409, Initial Validation Loss: 0.1295, Validation Loss: 0.0449,V Acc: 0.8165, Top 70th Acc: 0.8831, Bottom 30th Acc: 0.6562
Fold [4/5] Epoch [20/100] Initial Loss: 0.1373, Training Loss: 0.0260, Initial Validation Loss: 0.1295, Validation Loss: 0.0351,V Acc: 0.8440, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.6875
Stopping early at Epoch (base 0): 29  Rolling back to Epoch (base 0): 24  Top Validation Acc: 0.922077922077922
Fold [5/5] Epoch [0/100] Initial Loss: 0.1356, Training Loss: 0.1356, Initial Validation Loss: 0.1305, Validation Loss: 0.1305,V Acc: 0.4444, Top 70th Acc: 0.5395, Bottom 30th Acc: 0.2188
Fold [5/5] Epoch [10/100] Initial Loss: 0.1356, Training Loss: 0.0323, Initial Validation Loss: 0.1305, Validation Loss: 0.0447,V Acc: 0.8241, Top 70th Acc: 0.9079, Bottom 30th Acc: 0.6250
Fold [5/5] Epoch [20/100] Initial Loss: 0.1356, Training Loss: 0.0237, Initial Validation Loss: 0.1305, Validation Loss: 0.0393,V Acc: 0.8519, Top 70th Acc: 0.8947, Bottom 30th Acc: 0.7500
Stopping early at Epoch (base 0): 20  Rolling back to Epoch (base 0): 15  Top Validation Acc: 0.8947368421052632
Running train_nn.py with seed 36
CUDA:False
Training samples count:  550
Training on 20 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1442, Training Loss: 0.1442, Initial Validation Loss: 0.1325, Validation Loss: 0.1325,V Acc: 0.3571, Top 70th Acc: 0.4051, Bottom 30th Acc: 0.2424
Fold [1/5] Epoch [10/100] Initial Loss: 0.1442, Training Loss: 0.0391, Initial Validation Loss: 0.1325, Validation Loss: 0.0469,V Acc: 0.7946, Top 70th Acc: 0.8861, Bottom 30th Acc: 0.5758
Fold [1/5] Epoch [20/100] Initial Loss: 0.1442, Training Loss: 0.0228, Initial Validation Loss: 0.1325, Validation Loss: 0.0349,V Acc: 0.8214, Top 70th Acc: 0.8987, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.8987341772151899
Fold [2/5] Epoch [0/100] Initial Loss: 0.1414, Training Loss: 0.1414, Initial Validation Loss: 0.1373, Validation Loss: 0.1373,V Acc: 0.3423, Top 70th Acc: 0.4103, Bottom 30th Acc: 0.1818
Fold [2/5] Epoch [10/100] Initial Loss: 0.1414, Training Loss: 0.0458, Initial Validation Loss: 0.1373, Validation Loss: 0.0608,V Acc: 0.7117, Top 70th Acc: 0.8205, Bottom 30th Acc: 0.4545
Fold [2/5] Epoch [20/100] Initial Loss: 0.1414, Training Loss: 0.0304, Initial Validation Loss: 0.1373, Validation Loss: 0.0499,V Acc: 0.7568, Top 70th Acc: 0.8718, Bottom 30th Acc: 0.4848
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.9210526315789473
36 4 [array([0.43903828, 0.08185066, 0.03972438, 0.11494022, 0.3244465 ],
      dtype=float32)]
Running train_nn.py with seed 37
CUDA:False
Training samples count:  550
Training on 40 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1376, Training Loss: 0.1376, Initial Validation Loss: 0.1399, Validation Loss: 0.1399,V Acc: 0.2768, Top 70th Acc: 0.3165, Bottom 30th Acc: 0.1818
Fold [1/5] Epoch [10/100] Initial Loss: 0.1376, Training Loss: 0.0357, Initial Validation Loss: 0.1399, Validation Loss: 0.0422,V Acc: 0.8304, Top 70th Acc: 0.9241, Bottom 30th Acc: 0.6061
Fold [1/5] Epoch [20/100] Initial Loss: 0.1376, Training Loss: 0.0166, Initial Validation Loss: 0.1399, Validation Loss: 0.0273,V Acc: 0.8839, Top 70th Acc: 0.9494, Bottom 30th Acc: 0.7273
Stopping early at Epoch (base 0): 27  Rolling back to Epoch (base 0): 22  Top Validation Acc: 0.9620253164556962
Fold [2/5] Epoch [0/100] Initial Loss: 0.1427, Training Loss: 0.1427, Initial Validation Loss: 0.1332, Validation Loss: 0.1332,V Acc: 0.2613, Top 70th Acc: 0.3205, Bottom 30th Acc: 0.1212
Fold [2/5] Epoch [10/100] Initial Loss: 0.1427, Training Loss: 0.0387, Initial Validation Loss: 0.1332, Validation Loss: 0.0494,V Acc: 0.7658, Top 70th Acc: 0.8590, Bottom 30th Acc: 0.5455
Fold [2/5] Epoch [20/100] Initial Loss: 0.1427, Training Loss: 0.0150, Initial Validation Loss: 0.1332, Validation Loss: 0.0339,V Acc: 0.8288, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.5152
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.9358974358974359
37 1 [array([0.7537821 , 0.02879024, 0.05072271, 0.10348932, 0.06321561],
      dtype=float32)]
Fold [3/5] Epoch [0/100] Initial Loss: 0.1368, Training Loss: 0.1368, Initial Validation Loss: 0.1312, Validation Loss: 0.1312,V Acc: 0.3364, Top 70th Acc: 0.4156, Bottom 30th Acc: 0.1515
Fold [3/5] Epoch [10/100] Initial Loss: 0.1368, Training Loss: 0.0390, Initial Validation Loss: 0.1312, Validation Loss: 0.0497,V Acc: 0.7636, Top 70th Acc: 0.8831, Bottom 30th Acc: 0.4848
Fold [3/5] Epoch [20/100] Initial Loss: 0.1368, Training Loss: 0.0164, Initial Validation Loss: 0.1312, Validation Loss: 0.0337,V Acc: 0.8273, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.6061
Fold [3/5] Epoch [30/100] Initial Loss: 0.1368, Training Loss: 0.0132, Initial Validation Loss: 0.1312, Validation Loss: 0.0329,V Acc: 0.8455, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 33  Rolling back to Epoch (base 0): 28  Top Validation Acc: 0.922077922077922
Fold [4/5] Epoch [0/100] Initial Loss: 0.1383, Training Loss: 0.1383, Initial Validation Loss: 0.1351, Validation Loss: 0.1351,V Acc: 0.3119, Top 70th Acc: 0.3247, Bottom 30th Acc: 0.2812
Fold [4/5] Epoch [10/100] Initial Loss: 0.1383, Training Loss: 0.0219, Initial Validation Loss: 0.1351, Validation Loss: 0.0350,V Acc: 0.8257, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.5312
Fold [4/5] Epoch [20/100] Initial Loss: 0.1383, Training Loss: 0.0140, Initial Validation Loss: 0.1351, Validation Loss: 0.0284,V Acc: 0.8532, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6250
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.948051948051948
Fold [5/5] Epoch [0/100] Initial Loss: 0.1394, Training Loss: 0.1394, Initial Validation Loss: 0.1265, Validation Loss: 0.1265,V Acc: 0.3148, Top 70th Acc: 0.3947, Bottom 30th Acc: 0.1250
Fold [5/5] Epoch [10/100] Initial Loss: 0.1394, Training Loss: 0.0304, Initial Validation Loss: 0.1265, Validation Loss: 0.0436,V Acc: 0.7593, Top 70th Acc: 0.8421, Bottom 30th Acc: 0.5625
Fold [5/5] Epoch [20/100] Initial Loss: 0.1394, Training Loss: 0.0174, Initial Validation Loss: 0.1265, Validation Loss: 0.0396,V Acc: 0.7685, Top 70th Acc: 0.8816, Bottom 30th Acc: 0.5000
Fold [5/5] Epoch [30/100] Initial Loss: 0.1394, Training Loss: 0.0138, Initial Validation Loss: 0.1265, Validation Loss: 0.0369,V Acc: 0.7963, Top 70th Acc: 0.8684, Bottom 30th Acc: 0.6250
Fold [5/5] Epoch [40/100] Initial Loss: 0.1394, Training Loss: 0.0120, Initial Validation Loss: 0.1265, Validation Loss: 0.0362,V Acc: 0.7870, Top 70th Acc: 0.8947, Bottom 30th Acc: 0.5312
Fold [5/5] Epoch [50/100] Initial Loss: 0.1394, Training Loss: 0.0110, Initial Validation Loss: 0.1265, Validation Loss: 0.0360,V Acc: 0.8056, Top 70th Acc: 0.8947, Bottom 30th Acc: 0.5938
Stopping early at Epoch (base 0): 52  Rolling back to Epoch (base 0): 47  Top Validation Acc: 0.8947368421052632
Running train_nn.py with seed 38
CUDA:False
Training samples count:  550
Training on 40 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1384, Training Loss: 0.1384, Initial Validation Loss: 0.1361, Validation Loss: 0.1361,V Acc: 0.3214, Top 70th Acc: 0.3671, Bottom 30th Acc: 0.2121
Fold [1/5] Epoch [10/100] Initial Loss: 0.1384, Training Loss: 0.0421, Initial Validation Loss: 0.1361, Validation Loss: 0.0488,V Acc: 0.7946, Top 70th Acc: 0.8734, Bottom 30th Acc: 0.6061
Fold [1/5] Epoch [20/100] Initial Loss: 0.1384, Training Loss: 0.0178, Initial Validation Loss: 0.1361, Validation Loss: 0.0262,V Acc: 0.8750, Top 70th Acc: 0.9747, Bottom 30th Acc: 0.6364
Fold [1/5] Epoch [30/100] Initial Loss: 0.1384, Training Loss: 0.0142, Initial Validation Loss: 0.1361, Validation Loss: 0.0262,V Acc: 0.8839, Top 70th Acc: 0.9494, Bottom 30th Acc: 0.7273
Stopping early at Epoch (base 0): 30  Rolling back to Epoch (base 0): 25  Top Validation Acc: 0.9493670886075949
Fold [2/5] Epoch [0/100] Initial Loss: 0.1406, Training Loss: 0.1406, Initial Validation Loss: 0.1333, Validation Loss: 0.1333,V Acc: 0.2613, Top 70th Acc: 0.2821, Bottom 30th Acc: 0.2121
Fold [2/5] Epoch [10/100] Initial Loss: 0.1406, Training Loss: 0.0219, Initial Validation Loss: 0.1333, Validation Loss: 0.0419,V Acc: 0.8018, Top 70th Acc: 0.8846, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 18  Rolling back to Epoch (base 0): 13  Top Validation Acc: 0.9102564102564102
38 1 [array([0.45445395, 0.06678416, 0.07449233, 0.11444481, 0.28982478],
      dtype=float32)]
Fold [3/5] Epoch [0/100] Initial Loss: 0.1396, Training Loss: 0.1396, Initial Validation Loss: 0.1326, Validation Loss: 0.1326,V Acc: 0.2818, Top 70th Acc: 0.3506, Bottom 30th Acc: 0.1212
Fold [3/5] Epoch [10/100] Initial Loss: 0.1396, Training Loss: 0.0303, Initial Validation Loss: 0.1326, Validation Loss: 0.0368,V Acc: 0.7909, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.4242
Fold [3/5] Epoch [20/100] Initial Loss: 0.1396, Training Loss: 0.0148, Initial Validation Loss: 0.1326, Validation Loss: 0.0258,V Acc: 0.8636, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 28  Rolling back to Epoch (base 0): 23  Top Validation Acc: 0.974025974025974
Fold [4/5] Epoch [0/100] Initial Loss: 0.1383, Training Loss: 0.1383, Initial Validation Loss: 0.1360, Validation Loss: 0.1360,V Acc: 0.2569, Top 70th Acc: 0.3377, Bottom 30th Acc: 0.0625
Fold [4/5] Epoch [10/100] Initial Loss: 0.1383, Training Loss: 0.0344, Initial Validation Loss: 0.1360, Validation Loss: 0.0336,V Acc: 0.8991, Top 70th Acc: 0.9870, Bottom 30th Acc: 0.6875
Fold [4/5] Epoch [20/100] Initial Loss: 0.1383, Training Loss: 0.0172, Initial Validation Loss: 0.1360, Validation Loss: 0.0187,V Acc: 0.9450, Top 70th Acc: 0.9870, Bottom 30th Acc: 0.8438
Stopping early at Epoch (base 0): 27  Rolling back to Epoch (base 0): 22  Top Validation Acc: 1.0
Fold [5/5] Epoch [0/100] Initial Loss: 0.1388, Training Loss: 0.1388, Initial Validation Loss: 0.1273, Validation Loss: 0.1273,V Acc: 0.3148, Top 70th Acc: 0.3421, Bottom 30th Acc: 0.2500
Fold [5/5] Epoch [10/100] Initial Loss: 0.1388, Training Loss: 0.0249, Initial Validation Loss: 0.1273, Validation Loss: 0.0335,V Acc: 0.7870, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.4062
Fold [5/5] Epoch [20/100] Initial Loss: 0.1388, Training Loss: 0.0135, Initial Validation Loss: 0.1273, Validation Loss: 0.0320,V Acc: 0.8333, Top 70th Acc: 0.9211, Bottom 30th Acc: 0.6250
Stopping early at Epoch (base 0): 20  Rolling back to Epoch (base 0): 15  Top Validation Acc: 0.9210526315789473
Running train_nn.py with seed 39
CUDA:False
Training samples count:  
Fold [3/5] Epoch [20/100] Initial Loss: 0.1374, Training Loss: 0.0181, Initial Validation Loss: 0.1339, Validation Loss: 0.0348,V Acc: 0.8455, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6061
Fold [3/5] Epoch [30/100] Initial Loss: 0.1374, Training Loss: 0.0155, Initial Validation Loss: 0.1339, Validation Loss: 0.0319,V Acc: 0.8545, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 36  Rolling back to Epoch (base 0): 31  Top Validation Acc: 0.948051948051948
Fold [4/5] Epoch [0/100] Initial Loss: 0.1377, Training Loss: 0.1377, Initial Validation Loss: 0.1280, Validation Loss: 0.1280,V Acc: 0.4220, Top 70th Acc: 0.5455, Bottom 30th Acc: 0.1250
Fold [4/5] Epoch [10/100] Initial Loss: 0.1377, Training Loss: 0.0299, Initial Validation Loss: 0.1280, Validation Loss: 0.0321,V Acc: 0.8440, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.5938
Fold [4/5] Epoch [20/100] Initial Loss: 0.1377, Training Loss: 0.0174, Initial Validation Loss: 0.1280, Validation Loss: 0.0268,V Acc: 0.8349, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.5000
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.948051948051948
Fold [5/5] Epoch [0/100] Initial Loss: 0.1382, Training Loss: 0.1382, Initial Validation Loss: 0.1283, Validation Loss: 0.1283,V Acc: 0.2685, Top 70th Acc: 0.3684, Bottom 30th Acc: 0.0312
Fold [5/5] Epoch [10/100] Initial Loss: 0.1382, Training Loss: 0.0320, Initial Validation Loss: 0.1283, Validation Loss: 0.0392,V Acc: 0.8056, Top 70th Acc: 0.9211, Bottom 30th Acc: 0.5312
Fold [5/5] Epoch [20/100] Initial Loss: 0.1382, Training Loss: 0.0179, Initial Validation Loss: 0.1283, Validation Loss: 0.0321,V Acc: 0.8241, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.5000
Stopping early at Epoch (base 0): 22  Rolling back to Epoch (base 0): 17  Top Validation Acc: 0.9605263157894737
Running train_nn.py with seed 35
CUDA:False
Training samples count:  550
Training on 30 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1408, Training Loss: 0.1408, Initial Validation Loss: 0.1352, Validation Loss: 0.1352,V Acc: 0.2679, Top 70th Acc: 0.3418, Bottom 30th Acc: 0.0909
Fold [1/5] Epoch [10/100] Initial Loss: 0.1408, Training Loss: 0.0311, Initial Validation Loss: 0.1352, Validation Loss: 0.0358,V Acc: 0.8304, Top 70th Acc: 0.9367, Bottom 30th Acc: 0.5758
Fold [1/5] Epoch [20/100] Initial Loss: 0.1408, Training Loss: 0.0203, Initial Validation Loss: 0.1352, Validation Loss: 0.0332,V Acc: 0.8214, Top 70th Acc: 0.9367, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 29  Rolling back to Epoch (base 0): 24  Top Validation Acc: 0.9240506329113924
Fold [2/5] Epoch [0/100] Initial Loss: 0.1396, Training Loss: 0.1396, Initial Validation Loss: 0.1357, Validation Loss: 0.1357,V Acc: 0.2703, Top 70th Acc: 0.3205, Bottom 30th Acc: 0.1515
Fold [2/5] Epoch [10/100] Initial Loss: 0.1396, Training Loss: 0.0464, Initial Validation Loss: 0.1357, Validation Loss: 0.0540,V Acc: 0.7477, Top 70th Acc: 0.8205, Bottom 30th Acc: 0.5758
Fold [2/5] Epoch [20/100] Initial Loss: 0.1396, Training Loss: 0.0248, Initial Validation Loss: 0.1357, Validation Loss: 0.0432,V Acc: 0.7477, Top 70th Acc: 0.8974, Bottom 30th Acc: 0.3939
Fold [2/5] Epoch [30/100] Initial Loss: 0.1396, Training Loss: 0.0171, Initial Validation Loss: 0.1357, Validation Loss: 0.0374,V Acc: 0.7928, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.5152
Fold [2/5] Epoch [40/100] Initial Loss: 0.1396, Training Loss: 0.0153, Initial Validation Loss: 0.1357, Validation Loss: 0.0380,V Acc: 0.7928, Top 70th Acc: 0.8974, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 42  Rolling back to Epoch (base 0): 37  Top Validation Acc: 0.8974358974358975
Fold [3/5] Epoch [0/100] Initial Loss: 0.1398, Training Loss: 0.1398, Initial Validation Loss: 0.1327, Validation Loss: 0.1327,V Acc: 0.3909, Top 70th Acc: 0.4805, Bottom 30th Acc: 0.1818
Fold [3/5] Epoch [10/100] Initial Loss: 0.1398, Training Loss: 0.0386, Initial Validation Loss: 0.1327, Validation Loss: 0.0414,V Acc: 0.8000, Top 70th Acc: 0.8961, Bottom 30th Acc: 0.5758
Fold [3/5] Epoch [20/100] Initial Loss: 0.1398, Training Loss: 0.0209, Initial Validation Loss: 0.1327, Validation Loss: 0.0298,V Acc: 0.8455, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 29  Rolling back to Epoch (base 0): 24  Top Validation Acc: 0.961038961038961
35 2 [array([0.51971173, 0.0767789 , 0.06435405, 0.09299383, 0.24616145],
      dtype=float32)]
Fold [4/5] Epoch [0/100] Initial Loss: 0.1405, Training Loss: 0.1405, Initial Validation Loss: 0.1327, Validation Loss: 0.1327,V Acc: 0.2936, Top 70th Acc: 0.3377, Bottom 30th Acc: 0.1875
Fold [4/5] Epoch [10/100] Initial Loss: 0.1405, Training Loss: 0.0332, Initial Validation Loss: 0.1327, Validation Loss: 0.0416,V Acc: 0.7890, Top 70th Acc: 0.8961, Bottom 30th Acc: 0.5312
Fold [4/5] Epoch [20/100] Initial Loss: 0.1405, Training Loss: 0.0188, Initial Validation Loss: 0.1327, Validation Loss: 0.0372,V Acc: 0.7982, Top 70th Acc: 0.8831, Bottom 30th Acc: 0.5938
Stopping early at Epoch (base 0): 27  Rolling back to Epoch (base 0): 22  Top Validation Acc: 0.8831168831168831
Fold [5/5] Epoch [0/100] Initial Loss: 0.1397, Training Loss: 0.1397, Initial Validation Loss: 0.1334, Validation Loss: 0.1334,V Acc: 0.4167, Top 70th Acc: 0.5000, Bottom 30th Acc: 0.2188
Fold [5/5] Epoch [10/100] Initial Loss: 0.1397, Training Loss: 0.0327, Initial Validation Loss: 0.1334, Validation Loss: 0.0455,V Acc: 0.7685, Top 70th Acc: 0.9079, Bottom 30th Acc: 0.4375
Fold [5/5] Epoch [20/100] Initial Loss: 0.1397, Training Loss: 0.0190, Initial Validation Loss: 0.1334, Validation Loss: 0.0359,V Acc: 0.8704, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.7188
Stopping early at Epoch (base 0): 29  Rolling back to Epoch (base 0): 24  Top Validation Acc: 0.9210526315789473
Running train_nn.py with seed 36
CUDA:False
Training samples count:  550
Training on 30 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1417, Training Loss: 0.1417, Initial Validation Loss: 0.1355, Validation Loss: 0.1355,V Acc: 0.1786, Top 70th Acc: 0.1772, Bottom 30th Acc: 0.1818
Fold [1/5] Epoch [10/100] Initial Loss: 0.1417, Training Loss: 0.0398, Initial Validation Loss: 0.1355, Validation Loss: 0.0463,V Acc: 0.7857, Top 70th Acc: 0.8734, Bottom 30th Acc: 0.5758
Fold [1/5] Epoch [20/100] Initial Loss: 0.1417, Training Loss: 0.0187, Initial Validation Loss: 0.1355, Validation Loss: 0.0354,V Acc: 0.7946, Top 70th Acc: 0.8987, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.8987341772151899
Fold [2/5] Epoch [0/100] Initial Loss: 0.1406, Training Loss: 0.1406, Initial Validation Loss: 0.1391, Validation Loss: 0.1391,V Acc: 0.2793, Top 70th Acc: 0.2949, Bottom 30th Acc: 0.2424
Fold [2/5] Epoch [10/100] Initial Loss: 0.1406, Training Loss: 0.0426, Initial Validation Loss: 0.1391, Validation Loss: 0.0521,V Acc: 0.7658, Top 70th Acc: 0.8590, Bottom 30th Acc: 0.5455
Fold [2/5] Epoch [20/100] Initial Loss: 0.1406, Training Loss: 0.0192, Initial Validation Loss: 0.1391, Validation Loss: 0.0396,V Acc: 0.8108, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.9102564102564102
Fold [3/5] Epoch [0/100] Initial Loss: 0.1426, Training Loss: 0.1426, Initial Validation Loss: 0.1363, Validation Loss: 0.1363,V Acc: 0.3636, Top 70th Acc: 0.3766, Bottom 30th Acc: 0.3333
Fold [3/5] Epoch [10/100] Initial Loss: 0.1426, Training Loss: 0.0405, Initial Validation Loss: 0.1363, Validation Loss: 0.0423,V Acc: 0.8000, Top 70th Acc: 0.8831, Bottom 30th Acc: 0.6061
Fold [3/5] Epoch [20/100] Initial Loss: 0.1426, Training Loss: 0.0210, Initial Validation Loss: 0.1363, Validation Loss: 0.0304,V Acc: 0.8273, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.5152
Fold [3/5] Epoch [30/100] Initial Loss: 0.1426, Training Loss: 0.0186, Initial Validation Loss: 0.1363, Validation Loss: 0.0305,V Acc: 0.8182, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.5152
Stopping early at Epoch (base 0): 30  Rolling back to Epoch (base 0): 25  Top Validation Acc: 0.948051948051948
Fold [4/5] Epoch [0/100] Initial Loss: 0.1386, Training Loss: 0.1386, Initial Validation Loss: 0.1387, Validation Loss: 0.1387,V Acc: 0.2477, Top 70th Acc: 0.2597, Bottom 30th Acc: 0.2188
Training size: 440
Training size: 441
Training size: 442
Training on 162 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 46
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 162 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 47
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 162 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 48
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 162 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 49
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 162 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 50
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 162 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 51
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 162 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 52
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 162 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 53
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 162 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 54
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 162 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 55
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 162 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 56
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 162 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 57
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 162 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 58
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 162 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 59
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 162 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 60
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 162 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 61
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 162 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 62
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 162 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 63
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 162 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 64
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 162 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 65
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 162 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 66
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 162 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 67
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 162 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 68
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 162 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 69
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 162 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 70
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 162 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 71
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 162 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 72
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 162 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 73
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 162 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 74
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 162 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 75
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 162 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 76
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 162 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 77
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 162 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 78
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 162 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 79
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 162 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 80
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 162 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 81
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 162 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 82
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 162 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 83
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 162 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 84
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 162 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 85
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 162 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 86
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 162 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 87
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 162 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 88
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 162 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 89
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Fold [1/5] Epoch [20/100] Initial Loss: 0.1336, Training Loss: 0.0807, Initial Validation Loss: 0.1211, Validation Loss: 0.0716,V Acc: 0.6786, Top 70th Acc: 0.7975, Bottom 30th Acc: 0.3939
Fold [1/5] Epoch [30/100] Initial Loss: 0.1336, Training Loss: 0.0802, Initial Validation Loss: 0.1211, Validation Loss: 0.0707,V Acc: 0.6875, Top 70th Acc: 0.7975, Bottom 30th Acc: 0.4242
Fold [1/5] Epoch [40/100] Initial Loss: 0.1336, Training Loss: 0.0798, Initial Validation Loss: 0.1211, Validation Loss: 0.0703,V Acc: 0.7054, Top 70th Acc: 0.7975, Bottom 30th Acc: 0.4848
Stopping early at Epoch (base 0): 45  Rolling back to Epoch (base 0): 40  Top Validation Acc: 0.7974683544303798
Fold [2/5] Epoch [0/100] Initial Loss: 0.1393, Training Loss: 0.1393, Initial Validation Loss: 0.1289, Validation Loss: 0.1289,V Acc: 0.5135, Top 70th Acc: 0.6154, Bottom 30th Acc: 0.2727
Fold [2/5] Epoch [10/100] Initial Loss: 0.1393, Training Loss: 0.0825, Initial Validation Loss: 0.1289, Validation Loss: 0.0731,V Acc: 0.6486, Top 70th Acc: 0.7949, Bottom 30th Acc: 0.3030
Fold [2/5] Epoch [20/100] Initial Loss: 0.1393, Training Loss: 0.0813, Initial Validation Loss: 0.1289, Validation Loss: 0.0714,V Acc: 0.6667, Top 70th Acc: 0.7821, Bottom 30th Acc: 0.3939
Fold [2/5] Epoch [30/100] Initial Loss: 0.1393, Training Loss: 0.0808, Initial Validation Loss: 0.1289, Validation Loss: 0.0711,V Acc: 0.6667, Top 70th Acc: 0.7821, Bottom 30th Acc: 0.3939
Stopping early at Epoch (base 0): 35  Rolling back to Epoch (base 0): 30  Top Validation Acc: 0.782051282051282
Fold [3/5] Epoch [0/100] Initial Loss: 0.1327, Training Loss: 0.1327, Initial Validation Loss: 0.1211, Validation Loss: 0.1211,V Acc: 0.4182, Top 70th Acc: 0.5584, Bottom 30th Acc: 0.0909
Fold [3/5] Epoch [10/100] Initial Loss: 0.1327, Training Loss: 0.0801, Initial Validation Loss: 0.1211, Validation Loss: 0.0800,V Acc: 0.5636, Top 70th Acc: 0.6883, Bottom 30th Acc: 0.2727
Fold [3/5] Epoch [20/100] Initial Loss: 0.1327, Training Loss: 0.0777, Initial Validation Loss: 0.1211, Validation Loss: 0.0802,V Acc: 0.5636, Top 70th Acc: 0.7013, Bottom 30th Acc: 0.2424
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.7012987012987013
35 2 [array([0.12522441, 0.3789722 , 0.14825714, 0.2151145 , 0.1324318 ],
      dtype=float32)]
Fold [4/5] Epoch [0/100] Initial Loss: 0.1383, Training Loss: 0.1383, Initial Validation Loss: 0.1286, Validation Loss: 0.1286,V Acc: 0.2844, Top 70th Acc: 0.3506, Bottom 30th Acc: 0.1250
Fold [4/5] Epoch [10/100] Initial Loss: 0.1383, Training Loss: 0.0809, Initial Validation Loss: 0.1286, Validation Loss: 0.0780,V Acc: 0.6514, Top 70th Acc: 0.7532, Bottom 30th Acc: 0.4062
Fold [4/5] Epoch [20/100] Initial Loss: 0.1383, Training Loss: 0.0792, Initial Validation Loss: 0.1286, Validation Loss: 0.0770,V Acc: 0.6606, Top 70th Acc: 0.7532, Bottom 30th Acc: 0.4375
Stopping early at Epoch (base 0): 29  Rolling back to Epoch (base 0): 24  Top Validation Acc: 0.7662337662337663
Fold [5/5] Epoch [0/100] Initial Loss: 0.1394, Training Loss: 0.1394, Initial Validation Loss: 0.1330, Validation Loss: 0.1330,V Acc: 0.3241, Top 70th Acc: 0.3816, Bottom 30th Acc: 0.1875
Fold [5/5] Epoch [10/100] Initial Loss: 0.1394, Training Loss: 0.0781, Initial Validation Loss: 0.1330, Validation Loss: 0.0927,V Acc: 0.5926, Top 70th Acc: 0.6842, Bottom 30th Acc: 0.3750
Fold [5/5] Epoch [20/100] Initial Loss: 0.1394, Training Loss: 0.0755, Initial Validation Loss: 0.1330, Validation Loss: 0.0926,V Acc: 0.5741, Top 70th Acc: 0.6842, Bottom 30th Acc: 0.3125
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.6842105263157895
Running train_nn.py with seed 36
CUDA:False
Training samples count:  550
Training on 2 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1375, Training Loss: 0.1375, Initial Validation Loss: 0.1280, Validation Loss: 0.1280,V Acc: 0.3482, Top 70th Acc: 0.4304, Bottom 30th Acc: 0.1515
Fold [1/5] Epoch [10/100] Initial Loss: 0.1375, Training Loss: 0.0819, Initial Validation Loss: 0.1280, Validation Loss: 0.0766,V Acc: 0.6607, Top 70th Acc: 0.7722, Bottom 30th Acc: 0.3939
Fold [1/5] Epoch [20/100] Initial Loss: 0.1375, Training Loss: 0.0800, Initial Validation Loss: 0.1280, Validation Loss: 0.0743,V Acc: 0.6518, Top 70th Acc: 0.7848, Bottom 30th Acc: 0.3333
Fold [1/5] Epoch [30/100] Initial Loss: 0.1375, Training Loss: 0.0794, Initial Validation Loss: 0.1280, Validation Loss: 0.0735,V Acc: 0.6607, Top 70th Acc: 0.8101, Bottom 30th Acc: 0.3030
Fold [1/5] Epoch [40/100] Initial Loss: 0.1375, Training Loss: 0.0791, Initial Validation Loss: 0.1280, Validation Loss: 0.0729,V Acc: 0.6607, Top 70th Acc: 0.7848, Bottom 30th Acc: 0.3636
Fold [1/5] Epoch [50/100] Initial Loss: 0.1375, Training Loss: 0.0788, Initial Validation Loss: 0.1280, Validation Loss: 0.0727,V Acc: 0.6786, Top 70th Acc: 0.7975, Bottom 30th Acc: 0.3939
Stopping early at Epoch (base 0): 51  Rolling back to Epoch (base 0): 46  Top Validation Acc: 0.7974683544303798
Fold [2/5] Epoch [0/100] Initial Loss: 0.1360, Training Loss: 0.1360, Initial Validation Loss: 0.1307, Validation Loss: 0.1307,V Acc: 0.3784, Top 70th Acc: 0.4487, Bottom 30th Acc: 0.2121
Fold [2/5] Epoch [10/100] Initial Loss: 0.1360, Training Loss: 0.0808, Initial Validation Loss: 0.1307, Validation Loss: 0.0837,V Acc: 0.6216, Top 70th Acc: 0.7051, Bottom 30th Acc: 0.4242
Fold [2/5] Epoch [20/100] Initial Loss: 0.1360, Training Loss: 0.0786, Initial Validation Loss: 0.1307, Validation Loss: 0.0824,V Acc: 0.6126, Top 70th Acc: 0.7179, Bottom 30th Acc: 0.3636
Fold [2/5] Epoch [30/100] Initial Loss: 0.1360, Training Loss: 0.0784, Initial Validation Loss: 0.1307, Validation Loss: 0.0812,V Acc: 0.6396, Top 70th Acc: 0.7179, Bottom 30th Acc: 0.4545
Stopping early at Epoch (base 0): 38  Rolling back to Epoch (base 0): 33  Top Validation Acc: 0.717948717948718
Fold [3/5] Epoch [0/100] Initial Loss: 0.1373, Training Loss: 0.1373, Initial Validation Loss: 0.1286, Validation Loss: 0.1286,V Acc: 0.5273, Top 70th Acc: 0.6623, Bottom 30th Acc: 0.2121
Fold [3/5] Epoch [10/100] Initial Loss: 0.1373, Training Loss: 0.0831, Initial Validation Loss: 0.1286, Validation Loss: 0.0695,V Acc: 0.6727, Top 70th Acc: 0.7922, Bottom 30th Acc: 0.3939
Fold [3/5] Epoch [20/100] Initial Loss: 0.1373, Training Loss: 0.0820, Initial Validation Loss: 0.1286, Validation Loss: 0.0669,V Acc: 0.6909, Top 70th Acc: 0.8052, Bottom 30th Acc: 0.4242
Fold [3/5] Epoch [30/100] Initial Loss: 0.1373, Training Loss: 0.0811, Initial Validation Loss: 0.1286, Validation Loss: 0.0662,V Acc: 0.6727, Top 70th Acc: 0.8182, Bottom 30th Acc: 0.3333
Stopping early at Epoch (base 0): 35  Rolling back to Epoch (base 0): 30  Top Validation Acc: 0.7922077922077922
Fold [4/5] Epoch [0/100] Initial Loss: 0.1367, Training Loss: 0.1367, Initial Validation Loss: 0.1314, Validation Loss: 0.1314,V Acc: 0.4312, Top 70th Acc: 0.5584, Bottom 30th Acc: 0.1250
Fold [4/5] Epoch [10/100] Initial Loss: 0.1367, Training Loss: 0.0785, Initial Validation Loss: 0.1314, Validation Loss: 0.0887,V Acc: 0.5963, Top 70th Acc: 0.7013, Bottom 30th Acc: 0.3438
Fold [4/5] Epoch [20/100] Initial Loss: 0.1367, Training Loss: 0.0762, Initial Validation Loss: 0.1314, Validation Loss: 0.0877,V Acc: 0.5963, Top 70th Acc: 0.7143, Bottom 30th Acc: 0.3125
Fold [4/5] Epoch [30/100] Initial Loss: 0.1367, Training Loss: 0.0758, Initial Validation Loss: 0.1314, Validation Loss: 0.0876,V Acc: 0.6055, Top 70th Acc: 0.7143, Bottom 30th Acc: 0.3438
Stopping early at Epoch (base 0): 34  Rolling back to Epoch (base 0): 29  Top Validation Acc: 0.7142857142857143
Fold [5/5] Epoch [0/100] Initial Loss: 0.1386, Training Loss: 0.1386, Initial Validation Loss: 0.1211, Validation Loss: 0.1211,V Acc: 0.5463, Top 70th Acc: 0.6053, Bottom 30th Acc: 0.4062
Fold [5/5] Epoch [10/100] Initial Loss: 0.1386, Training Loss: 0.0807, Initial Validation Loss: 0.1211, Validation Loss: 0.0787,V Acc: 0.5833, Top 70th Acc: 0.7237, Bottom 30th Acc: 0.2500
Stopping early at Epoch (base 0): 15  Rolling back to Epoch (base 0): 10  Top Validation Acc: 0.7105263157894737
36 4 [array([0.11448073, 0.4016198 , 0.1485839 , 0.1682312 , 0.16708429],
      dtype=float32)]
Fold [5/5] Epoch [30/100] Initial Loss: 0.1409, Training Loss: 0.0039, Initial Validation Loss: 0.1323, Validation Loss: 0.0277,V Acc: 0.8704, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.6562
Stopping early at Epoch (base 0): 36  Rolling back to Epoch (base 0): 31  Top Validation Acc: 0.9605263157894737
Running train_nn.py with seed 27
CUDA:False
Training samples count:  550
Training on 162 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1408, Training Loss: 0.1408, Initial Validation Loss: 0.1341, Validation Loss: 0.1341,V Acc: 0.3482, Top 70th Acc: 0.3924, Bottom 30th Acc: 0.2424
Fold [1/5] Epoch [10/100] Initial Loss: 0.1408, Training Loss: 0.0220, Initial Validation Loss: 0.1341, Validation Loss: 0.0445,V Acc: 0.7857, Top 70th Acc: 0.8861, Bottom 30th Acc: 0.5455
Fold [1/5] Epoch [20/100] Initial Loss: 0.1408, Training Loss: 0.0055, Initial Validation Loss: 0.1341, Validation Loss: 0.0354,V Acc: 0.8036, Top 70th Acc: 0.9114, Bottom 30th Acc: 0.5455
Fold [1/5] Epoch [30/100] Initial Loss: 0.1408, Training Loss: 0.0042, Initial Validation Loss: 0.1341, Validation Loss: 0.0352,V Acc: 0.8125, Top 70th Acc: 0.9241, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 34  Rolling back to Epoch (base 0): 29  Top Validation Acc: 0.9240506329113924
Fold [2/5] Epoch [0/100] Initial Loss: 0.1388, Training Loss: 0.1388, Initial Validation Loss: 0.1337, Validation Loss: 0.1337,V Acc: 0.3604, Top 70th Acc: 0.3846, Bottom 30th Acc: 0.3030
Fold [2/5] Epoch [10/100] Initial Loss: 0.1388, Training Loss: 0.0177, Initial Validation Loss: 0.1337, Validation Loss: 0.0302,V Acc: 0.8739, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.6667
Fold [2/5] Epoch [20/100] Initial Loss: 0.1388, Training Loss: 0.0049, Initial Validation Loss: 0.1337, Validation Loss: 0.0229,V Acc: 0.8829, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 29  Rolling back to Epoch (base 0): 24  Top Validation Acc: 0.9743589743589743
27 1 [array([0.28172427, 0.02437489, 0.04860368, 0.32525262, 0.32004455],
      dtype=float32)]
Fold [3/5] Epoch [0/100] Initial Loss: 0.1378, Training Loss: 0.1378, Initial Validation Loss: 0.1355, Validation Loss: 0.1355,V Acc: 0.2545, Top 70th Acc: 0.3636, Bottom 30th Acc: 0.0000
Fold [3/5] Epoch [10/100] Initial Loss: 0.1378, Training Loss: 0.0241, Initial Validation Loss: 0.1355, Validation Loss: 0.0413,V Acc: 0.8182, Top 70th Acc: 0.8961, Bottom 30th Acc: 0.6364
Fold [3/5] Epoch [20/100] Initial Loss: 0.1378, Training Loss: 0.0073, Initial Validation Loss: 0.1355, Validation Loss: 0.0320,V Acc: 0.8273, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.5152
Fold [3/5] Epoch [30/100] Initial Loss: 0.1378, Training Loss: 0.0054, Initial Validation Loss: 0.1355, Validation Loss: 0.0306,V Acc: 0.8455, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 34  Rolling back to Epoch (base 0): 29  Top Validation Acc: 0.974025974025974
Fold [4/5] Epoch [0/100] Initial Loss: 0.1402, Training Loss: 0.1402, Initial Validation Loss: 0.1351, Validation Loss: 0.1351,V Acc: 0.2477, Top 70th Acc: 0.3506, Bottom 30th Acc: 0.0000
Fold [4/5] Epoch [10/100] Initial Loss: 0.1402, Training Loss: 0.0166, Initial Validation Loss: 0.1351, Validation Loss: 0.0303,V Acc: 0.8899, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.7812
Fold [4/5] Epoch [20/100] Initial Loss: 0.1402, Training Loss: 0.0060, Initial Validation Loss: 0.1351, Validation Loss: 0.0239,V Acc: 0.8991, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.7500
Fold [4/5] Epoch [30/100] Initial Loss: 0.1402, Training Loss: 0.0043, Initial Validation Loss: 0.1351, Validation Loss: 0.0242,V Acc: 0.8807, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.6875
Stopping early at Epoch (base 0): 33  Rolling back to Epoch (base 0): 28  Top Validation Acc: 0.948051948051948
Fold [5/5] Epoch [0/100] Initial Loss: 0.1404, Training Loss: 0.1404, Initial Validation Loss: 0.1322, Validation Loss: 0.1322,V Acc: 0.2593, Top 70th Acc: 0.3026, Bottom 30th Acc: 0.1562
Fold [5/5] Epoch [10/100] Initial Loss: 0.1404, Training Loss: 0.0151, Initial Validation Loss: 0.1322, Validation Loss: 0.0386,V Acc: 0.7870, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.4375
Fold [5/5] Epoch [20/100] Initial Loss: 0.1404, Training Loss: 0.0044, Initial Validation Loss: 0.1322, Validation Loss: 0.0335,V Acc: 0.8148, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.5312
Fold [5/5] Epoch [30/100] Initial Loss: 0.1404, Training Loss: 0.0036, Initial Validation Loss: 0.1322, Validation Loss: 0.0329,V Acc: 0.8056, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.4688
Stopping early at Epoch (base 0): 33  Rolling back to Epoch (base 0): 28  Top Validation Acc: 0.9473684210526315
Running train_nn.py with seed 28
CUDA:False
Training samples count:  550
Training on 162 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1391, Training Loss: 0.1391, Initial Validation Loss: 0.1375, Validation Loss: 0.1375,V Acc: 0.2679, Top 70th Acc: 0.3291, Bottom 30th Acc: 0.1212
Fold [1/5] Epoch [10/100] Initial Loss: 0.1391, Training Loss: 0.0309, Initial Validation Loss: 0.1375, Validation Loss: 0.0609,V Acc: 0.7321, Top 70th Acc: 0.8101, Bottom 30th Acc: 0.5455
Fold [1/5] Epoch [20/100] Initial Loss: 0.1391, Training Loss: 0.0057, Initial Validation Loss: 0.1375, Validation Loss: 0.0452,V Acc: 0.7768, Top 70th Acc: 0.8987, Bottom 30th Acc: 0.4848
Fold [1/5] Epoch [30/100] Initial Loss: 0.1391, Training Loss: 0.0037, Initial Validation Loss: 0.1375, Validation Loss: 0.0408,V Acc: 0.7946, Top 70th Acc: 0.9241, Bottom 30th Acc: 0.4848
Fold [1/5] Epoch [40/100] Initial Loss: 0.1391, Training Loss: 0.0034, Initial Validation Loss: 0.1375, Validation Loss: 0.0392,V Acc: 0.8036, Top 70th Acc: 0.9114, Bottom 30th Acc: 0.5455
Fold [1/5] Epoch [50/100] Initial Loss: 0.1391, Training Loss: 0.0032, Initial Validation Loss: 0.1375, Validation Loss: 0.0381,V Acc: 0.8125, Top 70th Acc: 0.9114, Bottom 30th Acc: 0.5758
Fold [1/5] Epoch [60/100] Initial Loss: 0.1391, Training Loss: 0.0031, Initial Validation Loss: 0.1375, Validation Loss: 0.0373,V Acc: 0.8125, Top 70th Acc: 0.9241, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 68  Rolling back to Epoch (base 0): 63  Top Validation Acc: 0.9367088607594937
Fold [2/5] Epoch [0/100] Initial Loss: 0.1412, Training Loss: 0.1412, Initial Validation Loss: 0.1290, Validation Loss: 0.1290,V Acc: 0.2523, Top 70th Acc: 0.3462, Bottom 30th Acc: 0.0303
Fold [2/5] Epoch [10/100] Initial Loss: 0.1412, Training Loss: 0.0352, Initial Validation Loss: 0.1290, Validation Loss: 0.0509,V Acc: 0.7297, Top 70th Acc: 0.8462, Bottom 30th Acc: 0.4545
Fold [2/5] Epoch [20/100] Initial Loss: 0.1412, Training Loss: 0.0074, Initial Validation Loss: 0.1290, Validation Loss: 0.0354,V Acc: 0.7928, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.5152
Fold [2/5] Epoch [30/100] Initial Loss: 0.1412, Training Loss: 0.0044, Initial Validation Loss: 0.1290, Validation Loss: 0.0330,V Acc: 0.7928, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.4545
Fold [2/5] Epoch [40/100] Initial Loss: 0.1412, Training Loss: 0.0038, Initial Validation Loss: 0.1290, Validation Loss: 0.0316,V Acc: 0.8018, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.5152
Fold [2/5] Epoch [50/100] Initial Loss: 0.1412, Training Loss: 0.0036, Initial Validation Loss: 0.1290, Validation Loss: 0.0301,V Acc: 0.8198, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.5152
Fold [2/5] Epoch [60/100] Initial Loss: 0.1412, Training Loss: 0.0035, Initial Validation Loss: 0.1290, Validation Loss: 0.0293,V Acc: 0.8108, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.5152
Stopping early at Epoch (base 0): 69  Rolling back to Epoch (base 0): 64  Top Validation Acc: 0.9358974358974359
28 1 [array([0.12726271, 0.0357745 , 0.03761848, 0.2815369 , 0.5178074 ],
      dtype=float32)]
Fold [3/5] Epoch [0/100] Initial Loss: 0.1382, Training Loss: 0.1382, Initial Validation Loss: 0.1320, Validation Loss: 0.1320,V Acc: 0.3818, Top 70th Acc: 0.4416, Bottom 30th Acc: 0.2424
Fold [3/5] Epoch [10/100] Initial Loss: 0.1382, Training Loss: 0.0213, Initial Validation Loss: 0.1320, Validation Loss: 0.0358,V Acc: 0.8818, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.7273
Fold [3/5] Epoch [20/100] Initial Loss: 0.1382, Training Loss: 0.0054, Initial Validation Loss: 0.1320, Validation Loss: 0.0261,V Acc: 0.8636, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.6364
Fold [2/5] Epoch [40/100] Initial Loss: 0.1362, Training Loss: 0.0106, Initial Validation Loss: 0.1305, Validation Loss: 0.0282,V Acc: 0.8919, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 49  Rolling back to Epoch (base 0): 44  Top Validation Acc: 0.9615384615384616
48 1 [array([0.8402313 , 0.02575312, 0.02888096, 0.07951047, 0.02562407],
      dtype=float32)]
Fold [3/5] Epoch [0/100] Initial Loss: 0.1322, Training Loss: 0.1322, Initial Validation Loss: 0.1134, Validation Loss: 0.1134,V Acc: 0.5636, Top 70th Acc: 0.7273, Bottom 30th Acc: 0.1818
Fold [3/5] Epoch [10/100] Initial Loss: 0.1322, Training Loss: 0.0221, Initial Validation Loss: 0.1134, Validation Loss: 0.0321,V Acc: 0.8545, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 15  Rolling back to Epoch (base 0): 10  Top Validation Acc: 0.922077922077922
Fold [4/5] Epoch [0/100] Initial Loss: 0.1321, Training Loss: 0.1321, Initial Validation Loss: 0.1142, Validation Loss: 0.1142,V Acc: 0.5138, Top 70th Acc: 0.5714, Bottom 30th Acc: 0.3750
Fold [4/5] Epoch [10/100] Initial Loss: 0.1321, Training Loss: 0.0203, Initial Validation Loss: 0.1142, Validation Loss: 0.0290,V Acc: 0.8532, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6250
Stopping early at Epoch (base 0): 19  Rolling back to Epoch (base 0): 14  Top Validation Acc: 0.948051948051948
Fold [5/5] Epoch [0/100] Initial Loss: 0.1358, Training Loss: 0.1358, Initial Validation Loss: 0.1172, Validation Loss: 0.1172,V Acc: 0.5185, Top 70th Acc: 0.6184, Bottom 30th Acc: 0.2812
Fold [5/5] Epoch [10/100] Initial Loss: 0.1358, Training Loss: 0.0218, Initial Validation Loss: 0.1172, Validation Loss: 0.0221,V Acc: 0.8796, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.6875
Fold [5/5] Epoch [20/100] Initial Loss: 0.1358, Training Loss: 0.0156, Initial Validation Loss: 0.1172, Validation Loss: 0.0232,V Acc: 0.8704, Top 70th Acc: 0.9737, Bottom 30th Acc: 0.6250
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.9868421052631579
Running train_nn.py with seed 49
CUDA:False
Training samples count:  550
Training on 21 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1262, Training Loss: 0.1262, Initial Validation Loss: 0.1097, Validation Loss: 0.1097,V Acc: 0.5625, Top 70th Acc: 0.6709, Bottom 30th Acc: 0.3030
Fold [1/5] Epoch [10/100] Initial Loss: 0.1262, Training Loss: 0.0201, Initial Validation Loss: 0.1097, Validation Loss: 0.0278,V Acc: 0.8661, Top 70th Acc: 0.9620, Bottom 30th Acc: 0.6364
Fold [1/5] Epoch [20/100] Initial Loss: 0.1262, Training Loss: 0.0143, Initial Validation Loss: 0.1097, Validation Loss: 0.0250,V Acc: 0.8750, Top 70th Acc: 0.9620, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 20  Rolling back to Epoch (base 0): 15  Top Validation Acc: 0.9620253164556962
Fold [2/5] Epoch [0/100] Initial Loss: 0.1308, Training Loss: 0.1308, Initial Validation Loss: 0.1146, Validation Loss: 0.1146,V Acc: 0.4595, Top 70th Acc: 0.5897, Bottom 30th Acc: 0.1515
Fold [2/5] Epoch [10/100] Initial Loss: 0.1308, Training Loss: 0.0222, Initial Validation Loss: 0.1146, Validation Loss: 0.0261,V Acc: 0.8919, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.6970
Fold [2/5] Epoch [20/100] Initial Loss: 0.1308, Training Loss: 0.0156, Initial Validation Loss: 0.1146, Validation Loss: 0.0220,V Acc: 0.9009, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.7273
Fold [2/5] Epoch [30/100] Initial Loss: 0.1308, Training Loss: 0.0139, Initial Validation Loss: 0.1146, Validation Loss: 0.0211,V Acc: 0.9279, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.8182
Stopping early at Epoch (base 0): 32  Rolling back to Epoch (base 0): 27  Top Validation Acc: 0.9743589743589743
49 1 [array([0.83962226, 0.01356166, 0.02340783, 0.05583434, 0.06757387],
      dtype=float32)]
Fold [3/5] Epoch [0/100] Initial Loss: 0.1373, Training Loss: 0.1373, Initial Validation Loss: 0.1247, Validation Loss: 0.1247,V Acc: 0.4727, Top 70th Acc: 0.5584, Bottom 30th Acc: 0.2727
Fold [3/5] Epoch [10/100] Initial Loss: 0.1373, Training Loss: 0.0336, Initial Validation Loss: 0.1247, Validation Loss: 0.0400,V Acc: 0.8000, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.5152
Fold [3/5] Epoch [20/100] Initial Loss: 0.1373, Training Loss: 0.0189, Initial Validation Loss: 0.1247, Validation Loss: 0.0276,V Acc: 0.8818, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.7879
Fold [3/5] Epoch [30/100] Initial Loss: 0.1373, Training Loss: 0.0143, Initial Validation Loss: 0.1247, Validation Loss: 0.0235,V Acc: 0.8727, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.6364
Fold [3/5] Epoch [40/100] Initial Loss: 0.1373, Training Loss: 0.0129, Initial Validation Loss: 0.1247, Validation Loss: 0.0234,V Acc: 0.8818, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 41  Rolling back to Epoch (base 0): 36  Top Validation Acc: 0.961038961038961
Fold [4/5] Epoch [0/100] Initial Loss: 0.1271, Training Loss: 0.1271, Initial Validation Loss: 0.1153, Validation Loss: 0.1153,V Acc: 0.6147, Top 70th Acc: 0.7013, Bottom 30th Acc: 0.4062
Fold [4/5] Epoch [10/100] Initial Loss: 0.1271, Training Loss: 0.0226, Initial Validation Loss: 0.1153, Validation Loss: 0.0309,V Acc: 0.8807, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.6562
Stopping early at Epoch (base 0): 16  Rolling back to Epoch (base 0): 11  Top Validation Acc: 0.961038961038961
Fold [5/5] Epoch [0/100] Initial Loss: 0.1340, Training Loss: 0.1340, Initial Validation Loss: 0.1187, Validation Loss: 0.1187,V Acc: 0.4352, Top 70th Acc: 0.5789, Bottom 30th Acc: 0.0938
Fold [5/5] Epoch [10/100] Initial Loss: 0.1340, Training Loss: 0.0222, Initial Validation Loss: 0.1187, Validation Loss: 0.0281,V Acc: 0.8611, Top 70th Acc: 0.9868, Bottom 30th Acc: 0.5625
Stopping early at Epoch (base 0): 18  Rolling back to Epoch (base 0): 13  Top Validation Acc: 0.9736842105263158
Running train_nn.py with seed 50
CUDA:False
Training samples count:  550
Training on 21 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1340, Training Loss: 0.1340, Initial Validation Loss: 0.1239, Validation Loss: 0.1239,V Acc: 0.3929, Top 70th Acc: 0.4430, Bottom 30th Acc: 0.2727
Fold [1/5] Epoch [10/100] Initial Loss: 0.1340, Training Loss: 0.0297, Initial Validation Loss: 0.1239, Validation Loss: 0.0286,V Acc: 0.8750, Top 70th Acc: 0.9747, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 19  Rolling back to Epoch (base 0): 14  Top Validation Acc: 0.9620253164556962
Fold [2/5] Epoch [0/100] Initial Loss: 0.1436, Training Loss: 0.1436, Initial Validation Loss: 0.1266, Validation Loss: 0.1266,V Acc: 0.3423, Top 70th Acc: 0.3718, Bottom 30th Acc: 0.2727
Fold [2/5] Epoch [10/100] Initial Loss: 0.1436, Training Loss: 0.0252, Initial Validation Loss: 0.1266, Validation Loss: 0.0324,V Acc: 0.8288, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.6061
Fold [2/5] Epoch [20/100] Initial Loss: 0.1436, Training Loss: 0.0159, Initial Validation Loss: 0.1266, Validation Loss: 0.0307,V Acc: 0.8378, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.6667
Fold [2/5] Epoch [30/100] Initial Loss: 0.1436, Training Loss: 0.0121, Initial Validation Loss: 0.1266, Validation Loss: 0.0289,V Acc: 0.8468, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 30  Rolling back to Epoch (base 0): 25  Top Validation Acc: 0.9102564102564102
Fold [3/5] Epoch [0/100] Initial Loss: 0.1287, Training Loss: 0.1287, Initial Validation Loss: 0.1148, Validation Loss: 0.1148,V Acc: 0.4636, Top 70th Acc: 0.6364, Bottom 30th Acc: 0.0606
Fold [3/5] Epoch [10/100] Initial Loss: 0.1287, Training Loss: 0.0240, Initial Validation Loss: 0.1148, Validation Loss: 0.0368,V Acc: 0.8000, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.4848
Fold [3/5] Epoch [20/100] Initial Loss: 0.1287, Training Loss: 0.0163, Initial Validation Loss: 0.1148, Validation Loss: 0.0337,V Acc: 0.8364, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.5152
Stopping early at Epoch (base 0): 20  Rolling back to Epoch (base 0): 15  Top Validation Acc: 0.974025974025974
50 2 [array([0.74895906, 0.02554758, 0.01639469, 0.14719631, 0.06190236],
      dtype=float32)]
Fold [4/5] Epoch [0/100] Initial Loss: 0.1333, Training Loss: 0.1333, Initial Validation Loss: 0.1240, Validation Loss: 0.1240,V Acc: 0.4128, Top 70th Acc: 0.4805, Bottom 30th Acc: 0.2500
Fold [2/5] Epoch [30/100] Initial Loss: 0.1414, Training Loss: 0.0214, Initial Validation Loss: 0.1373, Validation Loss: 0.0446,V Acc: 0.7928, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.5152
Stopping early at Epoch (base 0): 34  Rolling back to Epoch (base 0): 29  Top Validation Acc: 0.8974358974358975
Fold [3/5] Epoch [0/100] Initial Loss: 0.1464, Training Loss: 0.1464, Initial Validation Loss: 0.1383, Validation Loss: 0.1383,V Acc: 0.2455, Top 70th Acc: 0.2727, Bottom 30th Acc: 0.1818
Fold [3/5] Epoch [10/100] Initial Loss: 0.1464, Training Loss: 0.0381, Initial Validation Loss: 0.1383, Validation Loss: 0.0334,V Acc: 0.8818, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.7576
Fold [3/5] Epoch [20/100] Initial Loss: 0.1464, Training Loss: 0.0248, Initial Validation Loss: 0.1383, Validation Loss: 0.0292,V Acc: 0.8727, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.7576
Stopping early at Epoch (base 0): 27  Rolling back to Epoch (base 0): 22  Top Validation Acc: 0.948051948051948
Fold [4/5] Epoch [0/100] Initial Loss: 0.1401, Training Loss: 0.1401, Initial Validation Loss: 0.1386, Validation Loss: 0.1386,V Acc: 0.2477, Top 70th Acc: 0.2727, Bottom 30th Acc: 0.1875
Fold [4/5] Epoch [10/100] Initial Loss: 0.1401, Training Loss: 0.0445, Initial Validation Loss: 0.1386, Validation Loss: 0.0467,V Acc: 0.7798, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.4688
Fold [4/5] Epoch [20/100] Initial Loss: 0.1401, Training Loss: 0.0246, Initial Validation Loss: 0.1386, Validation Loss: 0.0340,V Acc: 0.8440, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.5625
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.948051948051948
Fold [5/5] Epoch [0/100] Initial Loss: 0.1408, Training Loss: 0.1408, Initial Validation Loss: 0.1245, Validation Loss: 0.1245,V Acc: 0.3519, Top 70th Acc: 0.4079, Bottom 30th Acc: 0.2188
Fold [5/5] Epoch [10/100] Initial Loss: 0.1408, Training Loss: 0.0381, Initial Validation Loss: 0.1245, Validation Loss: 0.0427,V Acc: 0.7500, Top 70th Acc: 0.8553, Bottom 30th Acc: 0.5000
Fold [5/5] Epoch [20/100] Initial Loss: 0.1408, Training Loss: 0.0248, Initial Validation Loss: 0.1245, Validation Loss: 0.0342,V Acc: 0.7963, Top 70th Acc: 0.9079, Bottom 30th Acc: 0.5312
Stopping early at Epoch (base 0): 29  Rolling back to Epoch (base 0): 24  Top Validation Acc: 0.868421052631579
36 4 [array([0.43588045, 0.0825612 , 0.07520173, 0.2504616 , 0.15589505],
      dtype=float32)]
Running train_nn.py with seed 37
CUDA:False
Training samples count:  550
Training on 20 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1391, Training Loss: 0.1391, Initial Validation Loss: 0.1402, Validation Loss: 0.1402,V Acc: 0.2500, Top 70th Acc: 0.3291, Bottom 30th Acc: 0.0606
Fold [1/5] Epoch [10/100] Initial Loss: 0.1391, Training Loss: 0.0424, Initial Validation Loss: 0.1402, Validation Loss: 0.0488,V Acc: 0.8125, Top 70th Acc: 0.9114, Bottom 30th Acc: 0.5758
Fold [1/5] Epoch [20/100] Initial Loss: 0.1391, Training Loss: 0.0249, Initial Validation Loss: 0.1402, Validation Loss: 0.0354,V Acc: 0.8393, Top 70th Acc: 0.9494, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 27  Rolling back to Epoch (base 0): 22  Top Validation Acc: 0.9493670886075949
Fold [2/5] Epoch [0/100] Initial Loss: 0.1389, Training Loss: 0.1389, Initial Validation Loss: 0.1322, Validation Loss: 0.1322,V Acc: 0.3784, Top 70th Acc: 0.4487, Bottom 30th Acc: 0.2121
Fold [2/5] Epoch [10/100] Initial Loss: 0.1389, Training Loss: 0.0363, Initial Validation Loss: 0.1322, Validation Loss: 0.0364,V Acc: 0.8468, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.6061
Fold [2/5] Epoch [20/100] Initial Loss: 0.1389, Training Loss: 0.0247, Initial Validation Loss: 0.1322, Validation Loss: 0.0321,V Acc: 0.8739, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.7576
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.9102564102564102
37 1 [array([0.31065795, 0.09279701, 0.09873766, 0.38121346, 0.116594  ],
      dtype=float32)]
Fold [3/5] Epoch [0/100] Initial Loss: 0.1406, Training Loss: 0.1406, Initial Validation Loss: 0.1355, Validation Loss: 0.1355,V Acc: 0.2273, Top 70th Acc: 0.2727, Bottom 30th Acc: 0.1212
Fold [3/5] Epoch [10/100] Initial Loss: 0.1406, Training Loss: 0.0386, Initial Validation Loss: 0.1355, Validation Loss: 0.0488,V Acc: 0.7364, Top 70th Acc: 0.8701, Bottom 30th Acc: 0.4242
Fold [3/5] Epoch [20/100] Initial Loss: 0.1406, Training Loss: 0.0240, Initial Validation Loss: 0.1355, Validation Loss: 0.0379,V Acc: 0.8091, Top 70th Acc: 0.8961, Bottom 30th Acc: 0.6061
Fold [3/5] Epoch [30/100] Initial Loss: 0.1406, Training Loss: 0.0208, Initial Validation Loss: 0.1355, Validation Loss: 0.0368,V Acc: 0.8182, Top 70th Acc: 0.8961, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 33  Rolling back to Epoch (base 0): 28  Top Validation Acc: 0.8961038961038961
Fold [4/5] Epoch [0/100] Initial Loss: 0.1391, Training Loss: 0.1391, Initial Validation Loss: 0.1356, Validation Loss: 0.1356,V Acc: 0.3211, Top 70th Acc: 0.3636, Bottom 30th Acc: 0.2188
Fold [4/5] Epoch [10/100] Initial Loss: 0.1391, Training Loss: 0.0372, Initial Validation Loss: 0.1356, Validation Loss: 0.0416,V Acc: 0.7706, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.4375
Fold [4/5] Epoch [20/100] Initial Loss: 0.1391, Training Loss: 0.0247, Initial Validation Loss: 0.1356, Validation Loss: 0.0328,V Acc: 0.8716, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.7188
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.935064935064935
Fold [5/5] Epoch [0/100] Initial Loss: 0.1402, Training Loss: 0.1402, Initial Validation Loss: 0.1276, Validation Loss: 0.1276,V Acc: 0.3148, Top 70th Acc: 0.3684, Bottom 30th Acc: 0.1875
Fold [5/5] Epoch [10/100] Initial Loss: 0.1402, Training Loss: 0.0449, Initial Validation Loss: 0.1276, Validation Loss: 0.0468,V Acc: 0.7500, Top 70th Acc: 0.8421, Bottom 30th Acc: 0.5312
Fold [5/5] Epoch [20/100] Initial Loss: 0.1402, Training Loss: 0.0266, Initial Validation Loss: 0.1276, Validation Loss: 0.0401,V Acc: 0.8241, Top 70th Acc: 0.8684, Bottom 30th Acc: 0.7188
Fold [5/5] Epoch [30/100] Initial Loss: 0.1402, Training Loss: 0.0224, Initial Validation Loss: 0.1276, Validation Loss: 0.0365,V Acc: 0.8056, Top 70th Acc: 0.8947, Bottom 30th Acc: 0.5938
Stopping early at Epoch (base 0): 34  Rolling back to Epoch (base 0): 29  Top Validation Acc: 0.881578947368421
Running train_nn.py with seed 38
CUDA:False
Training samples count:  550
Training on 20 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1393, Training Loss: 0.1393, Initial Validation Loss: 0.1373, Validation Loss: 0.1373,V Acc: 0.2768, Top 70th Acc: 0.3544, Bottom 30th Acc: 0.0909
Fold [1/5] Epoch [10/100] Initial Loss: 0.1393, Training Loss: 0.0444, Initial Validation Loss: 0.1373, Validation Loss: 0.0501,V Acc: 0.7768, Top 70th Acc: 0.8734, Bottom 30th Acc: 0.5455
Fold [1/5] Epoch [20/100] Initial Loss: 0.1393, Training Loss: 0.0255, Initial Validation Loss: 0.1373, Validation Loss: 0.0383,V Acc: 0.8036, Top 70th Acc: 0.9241, Bottom 30th Acc: 0.5152
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.9113924050632911
Fold [2/5] Epoch [0/100] Initial Loss: 0.1386, Training Loss: 0.1386, Initial Validation Loss: 0.1308, Validation Loss: 0.1308,V Acc: 0.4144, Top 70th Acc: 0.5000, Bottom 30th Acc: 0.2121
Fold [2/5] Epoch [10/100] Initial Loss: 0.1386, Training Loss: 0.0422, Initial Validation Loss: 0.1308, Validation Loss: 0.0556,V Acc: 0.7477, Top 70th Acc: 0.8590, Bottom 30th Acc: 0.4848
Fold [2/5] Epoch [20/100] Initial Loss: 0.1386, Training Loss: 0.0241, Initial Validation Loss: 0.1308, Validation Loss: 0.0436,V Acc: 0.7928, Top 70th Acc: 0.8846, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.9102564102564102
38 1 [array([0.21322241, 0.09693306, 0.30850518, 0.24457341, 0.13676594],
      dtype=float32)]
Fold [3/5] Epoch [0/100] Initial Loss: 0.1384, Training Loss: 0.1384, Initial Validation Loss: 0.1328, Validation Loss: 0.1328,V Acc: 0.2727, Top 70th Acc: 0.2857, Bottom 30th Acc: 0.2424
Fold [3/5] Epoch [10/100] Initial Loss: 0.1384, Training Loss: 0.0349, Initial Validation Loss: 0.1328, Validation Loss: 0.0420,V Acc: 0.8182, Top 70th Acc: 0.8831, Bottom 30th Acc: 0.6667550
Training on 40 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1411, Training Loss: 0.1411, Initial Validation Loss: 0.1343, Validation Loss: 0.1343,V Acc: 0.3214, Top 70th Acc: 0.4051, Bottom 30th Acc: 0.1212
Fold [1/5] Epoch [10/100] Initial Loss: 0.1411, Training Loss: 0.0347, Initial Validation Loss: 0.1343, Validation Loss: 0.0411,V Acc: 0.7857, Top 70th Acc: 0.9494, Bottom 30th Acc: 0.3939
Fold [1/5] Epoch [20/100] Initial Loss: 0.1411, Training Loss: 0.0161, Initial Validation Loss: 0.1343, Validation Loss: 0.0278,V Acc: 0.8482, Top 70th Acc: 0.9620, Bottom 30th Acc: 0.5758
Fold [1/5] Epoch [30/100] Initial Loss: 0.1411, Training Loss: 0.0131, Initial Validation Loss: 0.1343, Validation Loss: 0.0269,V Acc: 0.8750, Top 70th Acc: 0.9747, Bottom 30th Acc: 0.6364
Fold [1/5] Epoch [40/100] Initial Loss: 0.1411, Training Loss: 0.0118, Initial Validation Loss: 0.1343, Validation Loss: 0.0259,V Acc: 0.8661, Top 70th Acc: 0.9873, Bottom 30th Acc: 0.5758
Fold [1/5] Epoch [50/100] Initial Loss: 0.1411, Training Loss: 0.0108, Initial Validation Loss: 0.1343, Validation Loss: 0.0267,V Acc: 0.8482, Top 70th Acc: 1.0000, Bottom 30th Acc: 0.4848
Stopping early at Epoch (base 0): 51  Rolling back to Epoch (base 0): 46  Top Validation Acc: 0.9873417721518988
Fold [2/5] Epoch [0/100] Initial Loss: 0.1406, Training Loss: 0.1406, Initial Validation Loss: 0.1365, Validation Loss: 0.1365,V Acc: 0.2793, Top 70th Acc: 0.3205, Bottom 30th Acc: 0.1818
Fold [2/5] Epoch [10/100] Initial Loss: 0.1406, Training Loss: 0.0251, Initial Validation Loss: 0.1365, Validation Loss: 0.0303,V Acc: 0.8919, Top 70th Acc: 0.9872, Bottom 30th Acc: 0.6667
Fold [2/5] Epoch [20/100] Initial Loss: 0.1406, Training Loss: 0.0146, Initial Validation Loss: 0.1365, Validation Loss: 0.0289,V Acc: 0.8559, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 21  Rolling back to Epoch (base 0): 16  Top Validation Acc: 0.9743589743589743
Fold [3/5] Epoch [0/100] Initial Loss: 0.1401, Training Loss: 0.1401, Initial Validation Loss: 0.1325, Validation Loss: 0.1325,V Acc: 0.2909, Top 70th Acc: 0.3506, Bottom 30th Acc: 0.1515
Fold [3/5] Epoch [10/100] Initial Loss: 0.1401, Training Loss: 0.0333, Initial Validation Loss: 0.1325, Validation Loss: 0.0441,V Acc: 0.8273, Top 70th Acc: 0.8831, Bottom 30th Acc: 0.6970
Fold [3/5] Epoch [20/100] Initial Loss: 0.1401, Training Loss: 0.0147, Initial Validation Loss: 0.1325, Validation Loss: 0.0366,V Acc: 0.8364, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 27  Rolling back to Epoch (base 0): 22  Top Validation Acc: 0.922077922077922
Fold [4/5] Epoch [0/100] Initial Loss: 0.1390, Training Loss: 0.1390, Initial Validation Loss: 0.1350, Validation Loss: 0.1350,V Acc: 0.2936, Top 70th Acc: 0.3766, Bottom 30th Acc: 0.0938
Fold [4/5] Epoch [10/100] Initial Loss: 0.1390, Training Loss: 0.0355, Initial Validation Loss: 0.1350, Validation Loss: 0.0475,V Acc: 0.7706, Top 70th Acc: 0.8571, Bottom 30th Acc: 0.5625
Fold [4/5] Epoch [20/100] Initial Loss: 0.1390, Training Loss: 0.0160, Initial Validation Loss: 0.1350, Validation Loss: 0.0320,V Acc: 0.8440, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.6562
Fold [4/5] Epoch [30/100] Initial Loss: 0.1390, Training Loss: 0.0131, Initial Validation Loss: 0.1350, Validation Loss: 0.0291,V Acc: 0.8532, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.6562
Fold [4/5] Epoch [40/100] Initial Loss: 0.1390, Training Loss: 0.0115, Initial Validation Loss: 0.1350, Validation Loss: 0.0292,V Acc: 0.8349, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.5625
Fold [4/5] Epoch [50/100] Initial Loss: 0.1390, Training Loss: 0.0110, Initial Validation Loss: 0.1350, Validation Loss: 0.0273,V Acc: 0.8532, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.5938
Stopping early at Epoch (base 0): 53  Rolling back to Epoch (base 0): 48  Top Validation Acc: 0.961038961038961
39 3 [array([0.5879208 , 0.04404722, 0.04132898, 0.0899532 , 0.23674981],
      dtype=float32)]
Fold [5/5] Epoch [0/100] Initial Loss: 0.1411, Training Loss: 0.1411, Initial Validation Loss: 0.1288, Validation Loss: 0.1288,V Acc: 0.3611, Top 70th Acc: 0.3947, Bottom 30th Acc: 0.2812
Fold [5/5] Epoch [10/100] Initial Loss: 0.1411, Training Loss: 0.0345, Initial Validation Loss: 0.1288, Validation Loss: 0.0444,V Acc: 0.7870, Top 70th Acc: 0.8947, Bottom 30th Acc: 0.5312
Fold [5/5] Epoch [20/100] Initial Loss: 0.1411, Training Loss: 0.0154, Initial Validation Loss: 0.1288, Validation Loss: 0.0329,V Acc: 0.8241, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.5625
Fold [5/5] Epoch [30/100] Initial Loss: 0.1411, Training Loss: 0.0116, Initial Validation Loss: 0.1288, Validation Loss: 0.0308,V Acc: 0.8241, Top 70th Acc: 0.9211, Bottom 30th Acc: 0.5938
Stopping early at Epoch (base 0): 34  Rolling back to Epoch (base 0): 29  Top Validation Acc: 0.9473684210526315
Running train_nn.py with seed 40
CUDA:False
Training samples count:  550
Training on 40 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1421, Training Loss: 0.1421, Initial Validation Loss: 0.1363, Validation Loss: 0.1363,V Acc: 0.2500, Top 70th Acc: 0.3165, Bottom 30th Acc: 0.0909
Fold [1/5] Epoch [10/100] Initial Loss: 0.1421, Training Loss: 0.0350, Initial Validation Loss: 0.1363, Validation Loss: 0.0358,V Acc: 0.8214, Top 70th Acc: 0.9494, Bottom 30th Acc: 0.5152
Fold [1/5] Epoch [20/100] Initial Loss: 0.1421, Training Loss: 0.0160, Initial Validation Loss: 0.1363, Validation Loss: 0.0268,V Acc: 0.8661, Top 70th Acc: 0.9494, Bottom 30th Acc: 0.6667
Fold [1/5] Epoch [30/100] Initial Loss: 0.1421, Training Loss: 0.0137, Initial Validation Loss: 0.1363, Validation Loss: 0.0262,V Acc: 0.8839, Top 70th Acc: 0.9620, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 33  Rolling back to Epoch (base 0): 28  Top Validation Acc: 0.9493670886075949
Fold [2/5] Epoch [0/100] Initial Loss: 0.1390, Training Loss: 0.1390, Initial Validation Loss: 0.1320, Validation Loss: 0.1320,V Acc: 0.3694, Top 70th Acc: 0.4103, Bottom 30th Acc: 0.2727
Fold [2/5] Epoch [10/100] Initial Loss: 0.1390, Training Loss: 0.0319, Initial Validation Loss: 0.1320, Validation Loss: 0.0309,V Acc: 0.8739, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.6970
Fold [2/5] Epoch [20/100] Initial Loss: 0.1390, Training Loss: 0.0161, Initial Validation Loss: 0.1320, Validation Loss: 0.0261,V Acc: 0.8829, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.7273
Stopping early at Epoch (base 0): 22  Rolling back to Epoch (base 0): 17  Top Validation Acc: 0.9487179487179487
40 1 [array([0.568006  , 0.04327278, 0.07100823, 0.1302305 , 0.18748249],
      dtype=float32)]
Fold [3/5] Epoch [0/100] Initial Loss: 0.1406, Training Loss: 0.1406, Initial Validation Loss: 0.1390, Validation Loss: 0.1390,V Acc: 0.2636, Top 70th Acc: 0.2857, Bottom 30th Acc: 0.2121
Fold [3/5] Epoch [10/100] Initial Loss: 0.1406, Training Loss: 0.0414, Initial Validation Loss: 0.1390, Validation Loss: 0.0633,V Acc: 0.7182, Top 70th Acc: 0.7792, Bottom 30th Acc: 0.5758
Fold [3/5] Epoch [20/100] Initial Loss: 0.1406, Training Loss: 0.0182, Initial Validation Loss: 0.1390, Validation Loss: 0.0400,V Acc: 0.8000, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.4848
Fold [3/5] Epoch [30/100] Initial Loss: 0.1406, Training Loss: 0.0128, Initial Validation Loss: 0.1390, Validation Loss: 0.0364,V Acc: 0.8182, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.5152
Stopping early at Epoch (base 0): 36  Rolling back to Epoch (base 0): 31  Top Validation Acc: 0.948051948051948
Fold [4/5] Epoch [0/100] Initial Loss: 0.1408, Training Loss: 0.1408, Initial Validation Loss: 0.1287, Validation Loss: 0.1287,V Acc: 0.2569, Top 70th Acc: 0.2857, Bottom 30th Acc: 0.1875
Fold [4/5] Epoch [10/100] Initial Loss: 0.1408, Training Loss: 0.0318, Initial Validation Loss: 0.1287, Validation Loss: 0.0420,V Acc: 0.7890, Top 70th Acc: 0.8961, Bottom 30th Acc: 0.5312
Fold [4/5] Epoch [20/100] Initial Loss: 0.1408, Training Loss: 0.0151, Initial Validation Loss: 0.1287, Validation Loss: 0.0332,V Acc: 0.8257, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.5938
Fold [4/5] Epoch [30/100] Initial Loss: 0.1408, Training Loss: 0.0117, Initial Validation Loss: 0.1287, Validation Loss: 0.0327,V Acc: 0.8257, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.5625
Fold [4/5] Epoch [10/100] Initial Loss: 0.1333, Training Loss: 0.0238, Initial Validation Loss: 0.1240, Validation Loss: 0.0241,V Acc: 0.8716, Top 70th Acc: 0.9870, Bottom 30th Acc: 0.5938
Fold [4/5] Epoch [20/100] Initial Loss: 0.1333, Training Loss: 0.0166, Initial Validation Loss: 0.1240, Validation Loss: 0.0187,V Acc: 0.9266, Top 70th Acc: 0.9870, Bottom 30th Acc: 0.7812
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.974025974025974
Fold [5/5] Epoch [0/100] Initial Loss: 0.1353, Training Loss: 0.1353, Initial Validation Loss: 0.1221, Validation Loss: 0.1221,V Acc: 0.4722, Top 70th Acc: 0.5526, Bottom 30th Acc: 0.2812
Fold [5/5] Epoch [10/100] Initial Loss: 0.1353, Training Loss: 0.0238, Initial Validation Loss: 0.1221, Validation Loss: 0.0234,V Acc: 0.8796, Top 70th Acc: 1.0000, Bottom 30th Acc: 0.5938
Fold [5/5] Epoch [20/100] Initial Loss: 0.1353, Training Loss: 0.0165, Initial Validation Loss: 0.1221, Validation Loss: 0.0168,V Acc: 0.9259, Top 70th Acc: 1.0000, Bottom 30th Acc: 0.7500
Stopping early at Epoch (base 0): 28  Rolling back to Epoch (base 0): 23  Top Validation Acc: 1.0
Running train_nn.py with seed 51
CUDA:False
Training samples count:  550
Training on 21 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1296, Training Loss: 0.1296, Initial Validation Loss: 0.1210, Validation Loss: 0.1210,V Acc: 0.4196, Top 70th Acc: 0.4810, Bottom 30th Acc: 0.2727
Fold [1/5] Epoch [10/100] Initial Loss: 0.1296, Training Loss: 0.0205, Initial Validation Loss: 0.1210, Validation Loss: 0.0304,V Acc: 0.8571, Top 70th Acc: 0.9494, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 14  Rolling back to Epoch (base 0): 9  Top Validation Acc: 0.9620253164556962
Fold [2/5] Epoch [0/100] Initial Loss: 0.1279, Training Loss: 0.1279, Initial Validation Loss: 0.1094, Validation Loss: 0.1094,V Acc: 0.5495, Top 70th Acc: 0.7051, Bottom 30th Acc: 0.1818
Fold [2/5] Epoch [10/100] Initial Loss: 0.1279, Training Loss: 0.0203, Initial Validation Loss: 0.1094, Validation Loss: 0.0264,V Acc: 0.8559, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 14  Rolling back to Epoch (base 0): 9  Top Validation Acc: 0.9230769230769231
Fold [3/5] Epoch [0/100] Initial Loss: 0.1378, Training Loss: 0.1378, Initial Validation Loss: 0.1237, Validation Loss: 0.1237,V Acc: 0.4727, Top 70th Acc: 0.5974, Bottom 30th Acc: 0.1818
Fold [3/5] Epoch [10/100] Initial Loss: 0.1378, Training Loss: 0.0240, Initial Validation Loss: 0.1237, Validation Loss: 0.0344,V Acc: 0.8364, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.6061
Fold [3/5] Epoch [20/100] Initial Loss: 0.1378, Training Loss: 0.0173, Initial Validation Loss: 0.1237, Validation Loss: 0.0236,V Acc: 0.8636, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.6364
Fold [3/5] Epoch [30/100] Initial Loss: 0.1378, Training Loss: 0.0149, Initial Validation Loss: 0.1237, Validation Loss: 0.0224,V Acc: 0.9000, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.7273
Stopping early at Epoch (base 0): 30  Rolling back to Epoch (base 0): 25  Top Validation Acc: 0.974025974025974
51 2 [array([0.8614345 , 0.01654791, 0.04038363, 0.05919998, 0.02243386],
      dtype=float32)]
Fold [4/5] Epoch [0/100] Initial Loss: 0.1340, Training Loss: 0.1340, Initial Validation Loss: 0.1201, Validation Loss: 0.1201,V Acc: 0.4312, Top 70th Acc: 0.5584, Bottom 30th Acc: 0.1250
Fold [4/5] Epoch [10/100] Initial Loss: 0.1340, Training Loss: 0.0270, Initial Validation Loss: 0.1201, Validation Loss: 0.0266,V Acc: 0.8716, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.6562
Fold [4/5] Epoch [20/100] Initial Loss: 0.1340, Training Loss: 0.0156, Initial Validation Loss: 0.1201, Validation Loss: 0.0237,V Acc: 0.8991, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.7188
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.987012987012987
Fold [5/5] Epoch [0/100] Initial Loss: 0.1335, Training Loss: 0.1335, Initial Validation Loss: 0.1225, Validation Loss: 0.1225,V Acc: 0.5093, Top 70th Acc: 0.6447, Bottom 30th Acc: 0.1875
Fold [5/5] Epoch [10/100] Initial Loss: 0.1335, Training Loss: 0.0205, Initial Validation Loss: 0.1225, Validation Loss: 0.0204,V Acc: 0.8981, Top 70th Acc: 1.0000, Bottom 30th Acc: 0.6562
Fold [5/5] Epoch [20/100] Initial Loss: 0.1335, Training Loss: 0.0154, Initial Validation Loss: 0.1225, Validation Loss: 0.0208,V Acc: 0.9074, Top 70th Acc: 0.9868, Bottom 30th Acc: 0.7188
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.9868421052631579
Running train_nn.py with seed 52
CUDA:False
Training samples count:  550
Training on 21 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1379, Training Loss: 0.1379, Initial Validation Loss: 0.1305, Validation Loss: 0.1305,V Acc: 0.3304, Top 70th Acc: 0.3797, Bottom 30th Acc: 0.2121
Fold [1/5] Epoch [10/100] Initial Loss: 0.1379, Training Loss: 0.0270, Initial Validation Loss: 0.1305, Validation Loss: 0.0295,V Acc: 0.8304, Top 70th Acc: 0.9620, Bottom 30th Acc: 0.5152
Fold [1/5] Epoch [20/100] Initial Loss: 0.1379, Training Loss: 0.0169, Initial Validation Loss: 0.1305, Validation Loss: 0.0263,V Acc: 0.8661, Top 70th Acc: 0.9620, Bottom 30th Acc: 0.6364
Fold [1/5] Epoch [30/100] Initial Loss: 0.1379, Training Loss: 0.0144, Initial Validation Loss: 0.1305, Validation Loss: 0.0234,V Acc: 0.8839, Top 70th Acc: 0.9367, Bottom 30th Acc: 0.7576
Stopping early at Epoch (base 0): 30  Rolling back to Epoch (base 0): 25  Top Validation Acc: 0.9367088607594937
52 0 [array([0.8184775 , 0.03608676, 0.01108499, 0.06096436, 0.07338641],
      dtype=float32)]
Fold [2/5] Epoch [0/100] Initial Loss: 0.1328, Training Loss: 0.1328, Initial Validation Loss: 0.1147, Validation Loss: 0.1147,V Acc: 0.4144, Top 70th Acc: 0.4872, Bottom 30th Acc: 0.2424
Fold [2/5] Epoch [10/100] Initial Loss: 0.1328, Training Loss: 0.0198, Initial Validation Loss: 0.1147, Validation Loss: 0.0294,V Acc: 0.8378, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.5758
Fold [2/5] Epoch [20/100] Initial Loss: 0.1328, Training Loss: 0.0139, Initial Validation Loss: 0.1147, Validation Loss: 0.0292,V Acc: 0.8649, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.9615384615384616
Fold [3/5] Epoch [0/100] Initial Loss: 0.1365, Training Loss: 0.1365, Initial Validation Loss: 0.1241, Validation Loss: 0.1241,V Acc: 0.4545, Top 70th Acc: 0.4545, Bottom 30th Acc: 0.4545
Fold [3/5] Epoch [10/100] Initial Loss: 0.1365, Training Loss: 0.0194, Initial Validation Loss: 0.1241, Validation Loss: 0.0326,V Acc: 0.8545, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.6061
Fold [3/5] Epoch [20/100] Initial Loss: 0.1365, Training Loss: 0.0158, Initial Validation Loss: 0.1241, Validation Loss: 0.0292,V Acc: 0.9000, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.7576
Stopping early at Epoch (base 0): 20  Rolling back to Epoch (base 0): 15  Top Validation Acc: 0.961038961038961
Fold [4/5] Epoch [0/100] Initial Loss: 0.1357, Training Loss: 0.1357, Initial Validation Loss: 0.1223, Validation Loss: 0.1223,V Acc: 0.4862, Top 70th Acc: 0.5584, Bottom 30th Acc: 0.3125
Fold [4/5] Epoch [10/100] Initial Loss: 0.1357, Training Loss: 0.0203, Initial Validation Loss: 0.1223, Validation Loss: 0.0317,V Acc: 0.8440, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.6562
Stopping early at Epoch (base 0): 16  Rolling back to Epoch (base 0): 11  Top Validation Acc: 0.8701298701298701
Fold [5/5] Epoch [0/100] Initial Loss: 0.1370, Training Loss: 0.1370, Initial Validation Loss: 0.1232, Validation Loss: 0.1232,V Acc: 0.4444, Top 70th Acc: 0.5526, Bottom 30th Acc: 0.1875
Fold [5/5] Epoch [10/100] Initial Loss: 0.1370, Training Loss: 0.0228, Initial Validation Loss: 0.1232, Validation Loss: 0.0265,V Acc: 0.8889, Top 70th Acc: 1.0000, Bottom 30th Acc: 0.6250
Stopping early at Epoch (base 0): 14  Rolling back to Epoch (base 0): 9  Top Validation Acc: 1.0
Running train_nn.py with seed 53
CUDA:False
Training samples count:  550
Training on 21 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1389, Training Loss: 0.1389, Initial Validation Loss: 0.1310, Validation Loss: 0.1310,V Acc: 0.4375, Top 70th Acc: 0.5316, Bottom 30th Acc: 0.2121
Fold [4/5] Epoch [10/100] Initial Loss: 0.1386, Training Loss: 0.0381, Initial Validation Loss: 0.1387, Validation Loss: 0.0425,V Acc: 0.8349, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.5625
Fold [4/5] Epoch [20/100] Initial Loss: 0.1386, Training Loss: 0.0213, Initial Validation Loss: 0.1387, Validation Loss: 0.0323,V Acc: 0.8440, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.5312
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.974025974025974
Fold [5/5] Epoch [0/100] Initial Loss: 0.1391, Training Loss: 0.1391, Initial Validation Loss: 0.1258, Validation Loss: 0.1258,V Acc: 0.2963, Top 70th Acc: 0.3421, Bottom 30th Acc: 0.1875
Fold [5/5] Epoch [10/100] Initial Loss: 0.1391, Training Loss: 0.0400, Initial Validation Loss: 0.1258, Validation Loss: 0.0417,V Acc: 0.7593, Top 70th Acc: 0.8684, Bottom 30th Acc: 0.5000
Fold [5/5] Epoch [20/100] Initial Loss: 0.1391, Training Loss: 0.0248, Initial Validation Loss: 0.1258, Validation Loss: 0.0345,V Acc: 0.8148, Top 70th Acc: 0.9079, Bottom 30th Acc: 0.5938
Fold [5/5] Epoch [30/100] Initial Loss: 0.1391, Training Loss: 0.0194, Initial Validation Loss: 0.1258, Validation Loss: 0.0313,V Acc: 0.7963, Top 70th Acc: 0.9211, Bottom 30th Acc: 0.5000
Stopping early at Epoch (base 0): 35  Rolling back to Epoch (base 0): 30  Top Validation Acc: 0.9210526315789473
36 4 [array([0.72676015, 0.09165248, 0.02377247, 0.04738427, 0.11043057],
      dtype=float32)]
Running train_nn.py with seed 37
CUDA:False
Training samples count:  550
Training on 30 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1393, Training Loss: 0.1393, Initial Validation Loss: 0.1376, Validation Loss: 0.1376,V Acc: 0.3393, Top 70th Acc: 0.4051, Bottom 30th Acc: 0.1818
Fold [1/5] Epoch [10/100] Initial Loss: 0.1393, Training Loss: 0.0364, Initial Validation Loss: 0.1376, Validation Loss: 0.0444,V Acc: 0.8214, Top 70th Acc: 0.8861, Bottom 30th Acc: 0.6667
Fold [1/5] Epoch [20/100] Initial Loss: 0.1393, Training Loss: 0.0202, Initial Validation Loss: 0.1376, Validation Loss: 0.0318,V Acc: 0.8393, Top 70th Acc: 0.9620, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 29  Rolling back to Epoch (base 0): 24  Top Validation Acc: 0.9746835443037974
Fold [2/5] Epoch [0/100] Initial Loss: 0.1419, Training Loss: 0.1419, Initial Validation Loss: 0.1360, Validation Loss: 0.1360,V Acc: 0.1712, Top 70th Acc: 0.1538, Bottom 30th Acc: 0.2121
Fold [2/5] Epoch [10/100] Initial Loss: 0.1419, Training Loss: 0.0475, Initial Validation Loss: 0.1360, Validation Loss: 0.0491,V Acc: 0.7658, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.4242
Fold [2/5] Epoch [20/100] Initial Loss: 0.1419, Training Loss: 0.0195, Initial Validation Loss: 0.1360, Validation Loss: 0.0328,V Acc: 0.8198, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.9230769230769231
37 1 [array([0.7228377 , 0.03195659, 0.03352226, 0.10987022, 0.10181326],
      dtype=float32)]
Fold [3/5] Epoch [0/100] Initial Loss: 0.1391, Training Loss: 0.1391, Initial Validation Loss: 0.1304, Validation Loss: 0.1304,V Acc: 0.3818, Top 70th Acc: 0.5195, Bottom 30th Acc: 0.0606
Fold [3/5] Epoch [10/100] Initial Loss: 0.1391, Training Loss: 0.0270, Initial Validation Loss: 0.1304, Validation Loss: 0.0355,V Acc: 0.8364, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.6667
Fold [3/5] Epoch [20/100] Initial Loss: 0.1391, Training Loss: 0.0181, Initial Validation Loss: 0.1304, Validation Loss: 0.0323,V Acc: 0.8364, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.948051948051948
Fold [4/5] Epoch [0/100] Initial Loss: 0.1356, Training Loss: 0.1356, Initial Validation Loss: 0.1318, Validation Loss: 0.1318,V Acc: 0.4495, Top 70th Acc: 0.5584, Bottom 30th Acc: 0.1875
Fold [4/5] Epoch [10/100] Initial Loss: 0.1356, Training Loss: 0.0402, Initial Validation Loss: 0.1318, Validation Loss: 0.0471,V Acc: 0.7706, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.3750
Fold [4/5] Epoch [20/100] Initial Loss: 0.1356, Training Loss: 0.0197, Initial Validation Loss: 0.1318, Validation Loss: 0.0342,V Acc: 0.8349, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.6562
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.922077922077922
Fold [5/5] Epoch [0/100] Initial Loss: 0.1406, Training Loss: 0.1406, Initial Validation Loss: 0.1267, Validation Loss: 0.1267,V Acc: 0.2685, Top 70th Acc: 0.3289, Bottom 30th Acc: 0.1250
Fold [5/5] Epoch [10/100] Initial Loss: 0.1406, Training Loss: 0.0384, Initial Validation Loss: 0.1267, Validation Loss: 0.0432,V Acc: 0.7593, Top 70th Acc: 0.8553, Bottom 30th Acc: 0.5312
Fold [5/5] Epoch [20/100] Initial Loss: 0.1406, Training Loss: 0.0194, Initial Validation Loss: 0.1267, Validation Loss: 0.0321,V Acc: 0.8241, Top 70th Acc: 0.8947, Bottom 30th Acc: 0.6562
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.881578947368421
Running train_nn.py with seed 38
CUDA:False
Training samples count:  550
Training on 30 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1387, Training Loss: 0.1387, Initial Validation Loss: 0.1376, Validation Loss: 0.1376,V Acc: 0.2768, Top 70th Acc: 0.3544, Bottom 30th Acc: 0.0909
Fold [1/5] Epoch [10/100] Initial Loss: 0.1387, Training Loss: 0.0390, Initial Validation Loss: 0.1376, Validation Loss: 0.0487,V Acc: 0.7589, Top 70th Acc: 0.8734, Bottom 30th Acc: 0.4848
Fold [1/5] Epoch [20/100] Initial Loss: 0.1387, Training Loss: 0.0193, Initial Validation Loss: 0.1376, Validation Loss: 0.0307,V Acc: 0.8482, Top 70th Acc: 0.9494, Bottom 30th Acc: 0.6061
Fold [1/5] Epoch [30/100] Initial Loss: 0.1387, Training Loss: 0.0163, Initial Validation Loss: 0.1376, Validation Loss: 0.0306,V Acc: 0.8482, Top 70th Acc: 0.9367, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 30  Rolling back to Epoch (base 0): 25  Top Validation Acc: 0.9367088607594937
Fold [2/5] Epoch [0/100] Initial Loss: 0.1433, Training Loss: 0.1433, Initial Validation Loss: 0.1337, Validation Loss: 0.1337,V Acc: 0.3514, Top 70th Acc: 0.3974, Bottom 30th Acc: 0.2424
Fold [2/5] Epoch [10/100] Initial Loss: 0.1433, Training Loss: 0.0267, Initial Validation Loss: 0.1337, Validation Loss: 0.0461,V Acc: 0.8018, Top 70th Acc: 0.8846, Bottom 30th Acc: 0.6061
Fold [2/5] Epoch [20/100] Initial Loss: 0.1433, Training Loss: 0.0160, Initial Validation Loss: 0.1337, Validation Loss: 0.0407,V Acc: 0.7748, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.4545
Stopping early at Epoch (base 0): 29  Rolling back to Epoch (base 0): 24  Top Validation Acc: 0.9102564102564102
38 1 [array([0.3918153 , 0.16146664, 0.15323177, 0.14091004, 0.15257625],
      dtype=float32)]
Fold [3/5] Epoch [0/100] Initial Loss: 0.1407, Training Loss: 0.1407, Initial Validation Loss: 0.1314, Validation Loss: 0.1314,V Acc: 0.3545, Top 70th Acc: 0.4675, Bottom 30th Acc: 0.0909
Fold [3/5] Epoch [10/100] Initial Loss: 0.1407, Training Loss: 0.0361, Initial Validation Loss: 0.1314, Validation Loss: 0.0454,V Acc: 0.7545, Top 70th Acc: 0.8701, Bottom 30th Acc: 0.4848
Fold [3/5] Epoch [20/100] Initial Loss: 0.1407, Training Loss: 0.0224, Initial Validation Loss: 0.1314, Validation Loss: 0.0347,V Acc: 0.8364, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.5455
Fold [3/5] Epoch [30/100] Initial Loss: 0.1407, Training Loss: 0.0173, Initial Validation Loss: 0.1314, Validation Loss: 0.0319,V Acc: 0.8182, Top 70th Acc: 0.9870, Bottom 30th Acc: 0.4242
Fold [3/5] Epoch [40/100] Initial Loss: 0.1407, Training Loss: 0.0149, Initial Validation Loss: 0.1314, Validation Loss: 0.0295,V Acc: 0.8636, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.6061
Fold [3/5] Epoch [50/100] Initial Loss: 0.1407, Training Loss: 0.0136, Initial Validation Loss: 0.1314, Validation Loss: 0.0276,V Acc: 0.8636, Top 70th Acc: 0.9870, Bottom 30th Acc: 0.5758
Fold [3/5] Epoch [60/100] Initial Loss: 0.1407, Training Loss: 0.0128, Initial Validation Loss: 0.1314, Validation Loss: 0.0272,V Acc: 0.8818, Top 70th Acc: 0.9870, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 65  Rolling back to Epoch (base 0): 60  Top Validation Acc:
Running train_nn.py with seed 37
CUDA:False
Training samples count:  550
Training on 2 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1322, Training Loss: 0.1322, Initial Validation Loss: 0.1295, Validation Loss: 0.1295,V Acc: 0.4643, Top 70th Acc: 0.5570, Bottom 30th Acc: 0.2424
Fold [1/5] Epoch [10/100] Initial Loss: 0.1322, Training Loss: 0.0795, Initial Validation Loss: 0.1295, Validation Loss: 0.0897,V Acc: 0.6071, Top 70th Acc: 0.7215, Bottom 30th Acc: 0.3333
Fold [1/5] Epoch [20/100] Initial Loss: 0.1322, Training Loss: 0.0768, Initial Validation Loss: 0.1295, Validation Loss: 0.0885,V Acc: 0.6071, Top 70th Acc: 0.7215, Bottom 30th Acc: 0.3333
Fold [1/5] Epoch [30/100] Initial Loss: 0.1322, Training Loss: 0.0756, Initial Validation Loss: 0.1295, Validation Loss: 0.0867,V Acc: 0.6339, Top 70th Acc: 0.7215, Bottom 30th Acc: 0.4242
Stopping early at Epoch (base 0): 35  Rolling back to Epoch (base 0): 30  Top Validation Acc: 0.7088607594936709
Fold [2/5] Epoch [0/100] Initial Loss: 0.1350, Training Loss: 0.1350, Initial Validation Loss: 0.1226, Validation Loss: 0.1226,V Acc: 0.5315, Top 70th Acc: 0.6795, Bottom 30th Acc: 0.1818
Fold [2/5] Epoch [10/100] Initial Loss: 0.1350, Training Loss: 0.0827, Initial Validation Loss: 0.1226, Validation Loss: 0.0752,V Acc: 0.6577, Top 70th Acc: 0.7949, Bottom 30th Acc: 0.3333
Fold [2/5] Epoch [20/100] Initial Loss: 0.1350, Training Loss: 0.0806, Initial Validation Loss: 0.1226, Validation Loss: 0.0733,V Acc: 0.6486, Top 70th Acc: 0.7821, Bottom 30th Acc: 0.3333
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.782051282051282
37 1 [array([0.12960313, 0.35065818, 0.15059048, 0.20712261, 0.16202565],
      dtype=float32)]
Fold [3/5] Epoch [0/100] Initial Loss: 0.1389, Training Loss: 0.1389, Initial Validation Loss: 0.1317, Validation Loss: 0.1317,V Acc: 0.3545, Top 70th Acc: 0.3896, Bottom 30th Acc: 0.2727
Fold [3/5] Epoch [10/100] Initial Loss: 0.1389, Training Loss: 0.0816, Initial Validation Loss: 0.1317, Validation Loss: 0.0797,V Acc: 0.6182, Top 70th Acc: 0.7143, Bottom 30th Acc: 0.3939
Fold [3/5] Epoch [20/100] Initial Loss: 0.1389, Training Loss: 0.0794, Initial Validation Loss: 0.1317, Validation Loss: 0.0793,V Acc: 0.6273, Top 70th Acc: 0.7013, Bottom 30th Acc: 0.4545
Stopping early at Epoch (base 0): 22  Rolling back to Epoch (base 0): 17  Top Validation Acc: 0.7012987012987013
Fold [4/5] Epoch [0/100] Initial Loss: 0.1373, Training Loss: 0.1373, Initial Validation Loss: 0.1305, Validation Loss: 0.1305,V Acc: 0.4404, Top 70th Acc: 0.5844, Bottom 30th Acc: 0.0938
Fold [4/5] Epoch [10/100] Initial Loss: 0.1373, Training Loss: 0.0805, Initial Validation Loss: 0.1305, Validation Loss: 0.0794,V Acc: 0.6514, Top 70th Acc: 0.7532, Bottom 30th Acc: 0.4062
Fold [4/5] Epoch [20/100] Initial Loss: 0.1373, Training Loss: 0.0782, Initial Validation Loss: 0.1305, Validation Loss: 0.0777,V Acc: 0.6514, Top 70th Acc: 0.7532, Bottom 30th Acc: 0.4062
Fold [4/5] Epoch [30/100] Initial Loss: 0.1373, Training Loss: 0.0776, Initial Validation Loss: 0.1305, Validation Loss: 0.0767,V Acc: 0.6514, Top 70th Acc: 0.7532, Bottom 30th Acc: 0.4062
Fold [4/5] Epoch [40/100] Initial Loss: 0.1373, Training Loss: 0.0772, Initial Validation Loss: 0.1305, Validation Loss: 0.0769,V Acc: 0.6514, Top 70th Acc: 0.7532, Bottom 30th Acc: 0.4062
Stopping early at Epoch (base 0): 41  Rolling back to Epoch (base 0): 36  Top Validation Acc: 0.7532467532467533
Fold [5/5] Epoch [0/100] Initial Loss: 0.1374, Training Loss: 0.1374, Initial Validation Loss: 0.1213, Validation Loss: 0.1213,V Acc: 0.3333, Top 70th Acc: 0.4342, Bottom 30th Acc: 0.0938
Fold [5/5] Epoch [10/100] Initial Loss: 0.1374, Training Loss: 0.0816, Initial Validation Loss: 0.1213, Validation Loss: 0.0755,V Acc: 0.6204, Top 70th Acc: 0.7237, Bottom 30th Acc: 0.3750
Fold [5/5] Epoch [20/100] Initial Loss: 0.1374, Training Loss: 0.0794, Initial Validation Loss: 0.1213, Validation Loss: 0.0742,V Acc: 0.6296, Top 70th Acc: 0.7368, Bottom 30th Acc: 0.3750
Stopping early at Epoch (base 0): 28  Rolling back to Epoch (base 0): 23  Top Validation Acc: 0.7631578947368421
Running train_nn.py with seed 38
CUDA:False
Training samples count:  550
Training on 2 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1347, Training Loss: 0.1347, Initial Validation Loss: 0.1247, Validation Loss: 0.1247,V Acc: 0.4375, Top 70th Acc: 0.4937, Bottom 30th Acc: 0.3030
Fold [1/5] Epoch [10/100] Initial Loss: 0.1347, Training Loss: 0.0811, Initial Validation Loss: 0.1247, Validation Loss: 0.0794,V Acc: 0.6429, Top 70th Acc: 0.7595, Bottom 30th Acc: 0.3636
Fold [1/5] Epoch [20/100] Initial Loss: 0.1347, Training Loss: 0.0793, Initial Validation Loss: 0.1247, Validation Loss: 0.0778,V Acc: 0.6339, Top 70th Acc: 0.7595, Bottom 30th Acc: 0.3333
Stopping early at Epoch (base 0): 28  Rolling back to Epoch (base 0): 23  Top Validation Acc: 0.7341772151898734
Fold [2/5] Epoch [0/100] Initial Loss: 0.1388, Training Loss: 0.1388, Initial Validation Loss: 0.1293, Validation Loss: 0.1293,V Acc: 0.2973, Top 70th Acc: 0.3462, Bottom 30th Acc: 0.1818
Fold [2/5] Epoch [10/100] Initial Loss: 0.1388, Training Loss: 0.0791, Initial Validation Loss: 0.1293, Validation Loss: 0.0846,V Acc: 0.6126, Top 70th Acc: 0.7436, Bottom 30th Acc: 0.3030
Fold [2/5] Epoch [20/100] Initial Loss: 0.1388, Training Loss: 0.0775, Initial Validation Loss: 0.1293, Validation Loss: 0.0840,V Acc: 0.6126, Top 70th Acc: 0.7051, Bottom 30th Acc: 0.3939
Stopping early at Epoch (base 0): 20  Rolling back to Epoch (base 0): 15  Top Validation Acc: 0.7051282051282052
38 1 [array([0.11841898, 0.3811049 , 0.14507303, 0.18900959, 0.16639347],
      dtype=float32)]
Fold [3/5] Epoch [0/100] Initial Loss: 0.1361, Training Loss: 0.1361, Initial Validation Loss: 0.1264, Validation Loss: 0.1264,V Acc: 0.3818, Top 70th Acc: 0.5065, Bottom 30th Acc: 0.0909
Fold [3/5] Epoch [10/100] Initial Loss: 0.1361, Training Loss: 0.0778, Initial Validation Loss: 0.1264, Validation Loss: 0.0879,V Acc: 0.5364, Top 70th Acc: 0.6753, Bottom 30th Acc: 0.2121
Fold [3/5] Epoch [20/100] Initial Loss: 0.1361, Training Loss: 0.0761, Initial Validation Loss: 0.1264, Validation Loss: 0.0886,V Acc: 0.5455, Top 70th Acc: 0.6753, Bottom 30th Acc: 0.2424
Stopping early at Epoch (base 0): 20  Rolling back to Epoch (base 0): 15  Top Validation Acc: 0.6753246753246753
Fold [4/5] Epoch [0/100] Initial Loss: 0.1393, Training Loss: 0.1393, Initial Validation Loss: 0.1303, Validation Loss: 0.1303,V Acc: 0.5138, Top 70th Acc: 0.5065, Bottom 30th Acc: 0.5312
Fold [4/5] Epoch [10/100] Initial Loss: 0.1393, Training Loss: 0.0825, Initial Validation Loss: 0.1303, Validation Loss: 0.0764,V Acc: 0.6697, Top 70th Acc: 0.7662, Bottom 30th Acc: 0.4375
Fold [4/5] Epoch [20/100] Initial Loss: 0.1393, Training Loss: 0.0803, Initial Validation Loss: 0.1303, Validation Loss: 0.0734,V Acc: 0.6697, Top 70th Acc: 0.7792, Bottom 30th Acc: 0.4062
Fold [4/5] Epoch [30/100] Initial Loss: 0.1393, Training Loss: 0.0795, Initial Validation Loss: 0.1303, Validation Loss: 0.0734,V Acc: 0.6972, Top 70th Acc: 0.7532, Bottom 30th Acc: 0.5625
Stopping early at Epoch (base 0): 30  Rolling back to Epoch (base 0): 25  Top Validation Acc: 0.7532467532467533
Fold [5/5] Epoch [0/100] Initial Loss: 0.1471, Training Loss: 0.1471, Initial Validation Loss: 0.1277, Validation Loss: 0.1277,V Acc: 0.2407, Top 70th Acc: 0.2632, Bottom 30th Acc: 0.1875
Fold [5/5] Epoch [10/100] Initial Loss: 0.1471, Training Loss: 0.0826, Initial Validation Loss: 0.1277, Validation Loss: 0.0704,V Acc: 0.6667, Top 70th Acc: 0.7632, Bottom 30th Acc: 0.4375
Fold [5/5] Epoch [20/100] Initial Loss: 0.1471, Training Loss: 0.0808, Initial Validation Loss: 0.1277, Validation Loss: 0.0685,V Acc: 0.6667, Top 70th Acc: 0.7763, Bottom 30th Acc: 0.4062
Fold [5/5] Epoch [30/100] Initial Loss: 0.1471, Training Loss: 0.0802, Initial Validation Loss: 0.1277, Validation Loss: 0.0691,V Acc: 0.6759, Top 70th Acc: 0.7763, Bottom 30th Acc: 0.4375
Stopping early at Epoch (base 0): 32  Rolling back to Epoch (base 0): 27  Top Validation Acc: 0.75
Running train_nn.py with seed 39
CUDA:False
Training samples count:  550
Training on 2 features
Fold [3/5] Epoch [30/100] Initial Loss: 0.1382, Training Loss: 0.0041, Initial Validation Loss: 0.1320, Validation Loss: 0.0253,V Acc: 0.8636, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 31  Rolling back to Epoch (base 0): 26  Top Validation Acc: 0.961038961038961
Fold [4/5] Epoch [0/100] Initial Loss: 0.1373, Training Loss: 0.1373, Initial Validation Loss: 0.1297, Validation Loss: 0.1297,V Acc: 0.3761, Top 70th Acc: 0.4935, Bottom 30th Acc: 0.0938
Fold [4/5] Epoch [10/100] Initial Loss: 0.1373, Training Loss: 0.0130, Initial Validation Loss: 0.1297, Validation Loss: 0.0256,V Acc: 0.8624, Top 70th Acc: 1.0000, Bottom 30th Acc: 0.5312
Fold [4/5] Epoch [20/100] Initial Loss: 0.1373, Training Loss: 0.0046, Initial Validation Loss: 0.1297, Validation Loss: 0.0225,V Acc: 0.8716, Top 70th Acc: 1.0000, Bottom 30th Acc: 0.5625
Stopping early at Epoch (base 0): 27  Rolling back to Epoch (base 0): 22  Top Validation Acc: 1.0
Fold [5/5] Epoch [0/100] Initial Loss: 0.1412, Training Loss: 0.1412, Initial Validation Loss: 0.1328, Validation Loss: 0.1328,V Acc: 0.3148, Top 70th Acc: 0.3026, Bottom 30th Acc: 0.3438
Fold [5/5] Epoch [10/100] Initial Loss: 0.1412, Training Loss: 0.0238, Initial Validation Loss: 0.1328, Validation Loss: 0.0417,V Acc: 0.7963, Top 70th Acc: 0.9211, Bottom 30th Acc: 0.5000
Stopping early at Epoch (base 0): 18  Rolling back to Epoch (base 0): 13  Top Validation Acc: 0.9078947368421053
Running train_nn.py with seed 29
CUDA:False
Training samples count:  550
Training on 162 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1381, Training Loss: 0.1381, Initial Validation Loss: 0.1389, Validation Loss: 0.1389,V Acc: 0.3304, Top 70th Acc: 0.3797, Bottom 30th Acc: 0.2121
Fold [1/5] Epoch [10/100] Initial Loss: 0.1381, Training Loss: 0.0320, Initial Validation Loss: 0.1389, Validation Loss: 0.0453,V Acc: 0.7768, Top 70th Acc: 0.9114, Bottom 30th Acc: 0.4545
Fold [1/5] Epoch [20/100] Initial Loss: 0.1381, Training Loss: 0.0064, Initial Validation Loss: 0.1389, Validation Loss: 0.0251,V Acc: 0.8750, Top 70th Acc: 0.9873, Bottom 30th Acc: 0.6061
Fold [1/5] Epoch [30/100] Initial Loss: 0.1381, Training Loss: 0.0043, Initial Validation Loss: 0.1389, Validation Loss: 0.0219,V Acc: 0.8929, Top 70th Acc: 1.0000, Bottom 30th Acc: 0.6364
Fold [1/5] Epoch [40/100] Initial Loss: 0.1381, Training Loss: 0.0039, Initial Validation Loss: 0.1389, Validation Loss: 0.0208,V Acc: 0.8929, Top 70th Acc: 1.0000, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 46  Rolling back to Epoch (base 0): 41  Top Validation Acc: 1.0
Fold [2/5] Epoch [0/100] Initial Loss: 0.1378, Training Loss: 0.1378, Initial Validation Loss: 0.1396, Validation Loss: 0.1396,V Acc: 0.2523, Top 70th Acc: 0.3333, Bottom 30th Acc: 0.0606
Fold [2/5] Epoch [10/100] Initial Loss: 0.1378, Training Loss: 0.0185, Initial Validation Loss: 0.1396, Validation Loss: 0.0374,V Acc: 0.8559, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.6364
Fold [2/5] Epoch [20/100] Initial Loss: 0.1378, Training Loss: 0.0053, Initial Validation Loss: 0.1396, Validation Loss: 0.0287,V Acc: 0.8649, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 29  Rolling back to Epoch (base 0): 24  Top Validation Acc: 0.9615384615384616
29 1 [array([0.15514117, 0.04889996, 0.07697182, 0.3672207 , 0.35176638],
      dtype=float32)]
Fold [3/5] Epoch [0/100] Initial Loss: 0.1422, Training Loss: 0.1422, Initial Validation Loss: 0.1334, Validation Loss: 0.1334,V Acc: 0.2545, Top 70th Acc: 0.3117, Bottom 30th Acc: 0.1212
Fold [3/5] Epoch [10/100] Initial Loss: 0.1422, Training Loss: 0.0244, Initial Validation Loss: 0.1334, Validation Loss: 0.0391,V Acc: 0.8182, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.5758
Fold [3/5] Epoch [20/100] Initial Loss: 0.1422, Training Loss: 0.0068, Initial Validation Loss: 0.1334, Validation Loss: 0.0323,V Acc: 0.8182, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.4848
Stopping early at Epoch (base 0): 21  Rolling back to Epoch (base 0): 16  Top Validation Acc: 0.948051948051948
Fold [4/5] Epoch [0/100] Initial Loss: 0.1420, Training Loss: 0.1420, Initial Validation Loss: 0.1297, Validation Loss: 0.1297,V Acc: 0.3028, Top 70th Acc: 0.2857, Bottom 30th Acc: 0.3438
Fold [4/5] Epoch [10/100] Initial Loss: 0.1420, Training Loss: 0.0124, Initial Validation Loss: 0.1297, Validation Loss: 0.0290,V Acc: 0.8349, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.5625
Fold [4/5] Epoch [20/100] Initial Loss: 0.1420, Training Loss: 0.0047, Initial Validation Loss: 0.1297, Validation Loss: 0.0274,V Acc: 0.8532, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.6562
Stopping early at Epoch (base 0): 27  Rolling back to Epoch (base 0): 22  Top Validation Acc: 0.948051948051948
Fold [5/5] Epoch [0/100] Initial Loss: 0.1409, Training Loss: 0.1409, Initial Validation Loss: 0.1325, Validation Loss: 0.1325,V Acc: 0.3426, Top 70th Acc: 0.3947, Bottom 30th Acc: 0.2188
Fold [5/5] Epoch [10/100] Initial Loss: 0.1409, Training Loss: 0.0265, Initial Validation Loss: 0.1325, Validation Loss: 0.0432,V Acc: 0.7870, Top 70th Acc: 0.8947, Bottom 30th Acc: 0.5312
Fold [5/5] Epoch [20/100] Initial Loss: 0.1409, Training Loss: 0.0043, Initial Validation Loss: 0.1325, Validation Loss: 0.0331,V Acc: 0.8241, Top 70th Acc: 0.9211, Bottom 30th Acc: 0.5938
Stopping early at Epoch (base 0): 22  Rolling back to Epoch (base 0): 17  Top Validation Acc: 0.9210526315789473
Running train_nn.py with seed 30
CUDA:False
Training samples count:  550
Training on 162 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1403, Training Loss: 0.1403, Initial Validation Loss: 0.1341, Validation Loss: 0.1341,V Acc: 0.2500, Top 70th Acc: 0.3165, Bottom 30th Acc: 0.0909
Fold [1/5] Epoch [10/100] Initial Loss: 0.1403, Training Loss: 0.0136, Initial Validation Loss: 0.1341, Validation Loss: 0.0337,V Acc: 0.8304, Top 70th Acc: 0.9494, Bottom 30th Acc: 0.5455
Fold [1/5] Epoch [20/100] Initial Loss: 0.1403, Training Loss: 0.0050, Initial Validation Loss: 0.1341, Validation Loss: 0.0313,V Acc: 0.8304, Top 70th Acc: 0.9494, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 29  Rolling back to Epoch (base 0): 24  Top Validation Acc: 0.9493670886075949
Fold [2/5] Epoch [0/100] Initial Loss: 0.1403, Training Loss: 0.1403, Initial Validation Loss: 0.1360, Validation Loss: 0.1360,V Acc: 0.3063, Top 70th Acc: 0.3462, Bottom 30th Acc: 0.2121
Fold [2/5] Epoch [10/100] Initial Loss: 0.1403, Training Loss: 0.0180, Initial Validation Loss: 0.1360, Validation Loss: 0.0397,V Acc: 0.7928, Top 70th Acc: 0.8974, Bottom 30th Acc: 0.5455
Fold [2/5] Epoch [20/100] Initial Loss: 0.1403, Training Loss: 0.0054, Initial Validation Loss: 0.1360, Validation Loss: 0.0336,V Acc: 0.8288, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.5758
Fold [2/5] Epoch [30/100] Initial Loss: 0.1403, Training Loss: 0.0042, Initial Validation Loss: 0.1360, Validation Loss: 0.0326,V Acc: 0.8468, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 36  Rolling back to Epoch (base 0): 31  Top Validation Acc: 0.9358974358974359
30 1 [array([0.3277889 , 0.05910816, 0.04669209, 0.25595695, 0.31045392],
      dtype=float32)]
Fold [3/5] Epoch [0/100] Initial Loss: 0.1392, Training Loss: 0.1392, Initial Validation Loss: 0.1319, Validation Loss: 0.1319,V Acc: 0.3636, Top 70th Acc: 0.4545, Bottom 30th Acc: 0.1515
Fold [3/5] Epoch [10/100] Initial Loss: 0.1392, Training Loss: 0.0220, Initial Validation Loss: 0.1319, Validation Loss: 0.0397,V Acc: 0.8273, Top 70th Acc: 0.8961, Bottom 30th Acc: 0.6667
Fold [3/5] Epoch [20/100] Initial Loss: 0.1392, Training Loss: 0.0052, Initial Validation Loss: 0.1319, Validation Loss: 0.0354,V Acc: 0.8273, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.935064935064935
Fold [4/5] Epoch [0/100] Initial Loss: 0.1436, Training Loss: 0.1436, Initial Validation Loss: 0.1349, Validation Loss: 0.1349,V Acc: 0.2294, Top 70th Acc: 0.3117, Bottom 30th Acc: 0.0312
Fold [4/5] Epoch [10/100] Initial Loss: 0.1436, Training Loss: 0.0180, Initial Validation Loss: 0.1349, Validation Loss: 0.0259,V Acc: 0.9266, Top 70th Acc: 0.9870, Bottom 30th Acc: 0.7812/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)

Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 20 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 91
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 20 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 92
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 20 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 93
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 20 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 94
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 20 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 95
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 20 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 96
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 20 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 97
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 20 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 98
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 20 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 99
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 20 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 100
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 20 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5

Fold [3/5] Epoch [20/100] Initial Loss: 0.1384, Training Loss: 0.0255, Initial Validation Loss: 0.1328, Validation Loss: 0.0343,V Acc: 0.8273, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.6061
Fold [3/5] Epoch [30/100] Initial Loss: 0.1384, Training Loss: 0.0232, Initial Validation Loss: 0.1328, Validation Loss: 0.0326,V Acc: 0.8364, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 38  Rolling back to Epoch (base 0): 33  Top Validation Acc: 0.948051948051948
Fold [4/5] Epoch [0/100] Initial Loss: 0.1386, Training Loss: 0.1386, Initial Validation Loss: 0.1387, Validation Loss: 0.1387,V Acc: 0.2202, Top 70th Acc: 0.2468, Bottom 30th Acc: 0.1562
Fold [4/5] Epoch [10/100] Initial Loss: 0.1386, Training Loss: 0.0397, Initial Validation Loss: 0.1387, Validation Loss: 0.0316,V Acc: 0.9083, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.7812
Fold [4/5] Epoch [20/100] Initial Loss: 0.1386, Training Loss: 0.0284, Initial Validation Loss: 0.1387, Validation Loss: 0.0230,V Acc: 0.9174, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.7812
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.961038961038961
Fold [5/5] Epoch [0/100] Initial Loss: 0.1395, Training Loss: 0.1395, Initial Validation Loss: 0.1266, Validation Loss: 0.1266,V Acc: 0.3981, Top 70th Acc: 0.4737, Bottom 30th Acc: 0.2188
Fold [5/5] Epoch [10/100] Initial Loss: 0.1395, Training Loss: 0.0317, Initial Validation Loss: 0.1266, Validation Loss: 0.0412,V Acc: 0.8148, Top 70th Acc: 0.9079, Bottom 30th Acc: 0.5938
Stopping early at Epoch (base 0): 16  Rolling back to Epoch (base 0): 11  Top Validation Acc: 0.8947368421052632
Running train_nn.py with seed 39
CUDA:False
Training samples count:  550
Training on 20 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1369, Training Loss: 0.1369, Initial Validation Loss: 0.1299, Validation Loss: 0.1299,V Acc: 0.4286, Top 70th Acc: 0.4810, Bottom 30th Acc: 0.3030
Fold [1/5] Epoch [10/100] Initial Loss: 0.1369, Training Loss: 0.0438, Initial Validation Loss: 0.1299, Validation Loss: 0.0457,V Acc: 0.7768, Top 70th Acc: 0.8987, Bottom 30th Acc: 0.4848
Fold [1/5] Epoch [20/100] Initial Loss: 0.1369, Training Loss: 0.0237, Initial Validation Loss: 0.1299, Validation Loss: 0.0306,V Acc: 0.8393, Top 70th Acc: 0.9494, Bottom 30th Acc: 0.5758
Fold [1/5] Epoch [30/100] Initial Loss: 0.1369, Training Loss: 0.0207, Initial Validation Loss: 0.1299, Validation Loss: 0.0316,V Acc: 0.8304, Top 70th Acc: 0.9494, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 31  Rolling back to Epoch (base 0): 26  Top Validation Acc: 0.9493670886075949
Fold [2/5] Epoch [0/100] Initial Loss: 0.1374, Training Loss: 0.1374, Initial Validation Loss: 0.1354, Validation Loss: 0.1354,V Acc: 0.2793, Top 70th Acc: 0.3590, Bottom 30th Acc: 0.0909
Fold [2/5] Epoch [10/100] Initial Loss: 0.1374, Training Loss: 0.0310, Initial Validation Loss: 0.1354, Validation Loss: 0.0319,V Acc: 0.8739, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.6364
Fold [2/5] Epoch [20/100] Initial Loss: 0.1374, Training Loss: 0.0214, Initial Validation Loss: 0.1354, Validation Loss: 0.0276,V Acc: 0.8829, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.9615384615384616
Fold [3/5] Epoch [0/100] Initial Loss: 0.1402, Training Loss: 0.1402, Initial Validation Loss: 0.1313, Validation Loss: 0.1313,V Acc: 0.3273, Top 70th Acc: 0.3636, Bottom 30th Acc: 0.2424
Fold [3/5] Epoch [10/100] Initial Loss: 0.1402, Training Loss: 0.0394, Initial Validation Loss: 0.1313, Validation Loss: 0.0474,V Acc: 0.8000, Top 70th Acc: 0.8571, Bottom 30th Acc: 0.6667
Fold [3/5] Epoch [20/100] Initial Loss: 0.1402, Training Loss: 0.0216, Initial Validation Loss: 0.1313, Validation Loss: 0.0390,V Acc: 0.8273, Top 70th Acc: 0.8831, Bottom 30th Acc: 0.6970
Fold [3/5] Epoch [30/100] Initial Loss: 0.1402, Training Loss: 0.0183, Initial Validation Loss: 0.1313, Validation Loss: 0.0389,V Acc: 0.8000, Top 70th Acc: 0.8831, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 34  Rolling back to Epoch (base 0): 29  Top Validation Acc: 0.8831168831168831
Fold [4/5] Epoch [0/100] Initial Loss: 0.1390, Training Loss: 0.1390, Initial Validation Loss: 0.1328, Validation Loss: 0.1328,V Acc: 0.2569, Top 70th Acc: 0.3506, Bottom 30th Acc: 0.0312
Fold [4/5] Epoch [10/100] Initial Loss: 0.1390, Training Loss: 0.0311, Initial Validation Loss: 0.1328, Validation Loss: 0.0438,V Acc: 0.7615, Top 70th Acc: 0.8701, Bottom 30th Acc: 0.5000
Fold [4/5] Epoch [20/100] Initial Loss: 0.1390, Training Loss: 0.0212, Initial Validation Loss: 0.1328, Validation Loss: 0.0380,V Acc: 0.7798, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.4688
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.922077922077922
39 3 [array([0.26891762, 0.07092968, 0.07686835, 0.35649014, 0.22679423],
      dtype=float32)]
Fold [5/5] Epoch [0/100] Initial Loss: 0.1356, Training Loss: 0.1356, Initial Validation Loss: 0.1247, Validation Loss: 0.1247,V Acc: 0.4907, Top 70th Acc: 0.5395, Bottom 30th Acc: 0.3750
Fold [5/5] Epoch [10/100] Initial Loss: 0.1356, Training Loss: 0.0358, Initial Validation Loss: 0.1247, Validation Loss: 0.0362,V Acc: 0.8333, Top 70th Acc: 0.9211, Bottom 30th Acc: 0.6250
Fold [5/5] Epoch [20/100] Initial Loss: 0.1356, Training Loss: 0.0226, Initial Validation Loss: 0.1247, Validation Loss: 0.0290,V Acc: 0.8241, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.5625
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.9342105263157895
Running train_nn.py with seed 40
CUDA:False
Training samples count:  550
Training on 20 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1373, Training Loss: 0.1373, Initial Validation Loss: 0.1319, Validation Loss: 0.1319,V Acc: 0.3750, Top 70th Acc: 0.4304, Bottom 30th Acc: 0.2424
Fold [1/5] Epoch [10/100] Initial Loss: 0.1373, Training Loss: 0.0464, Initial Validation Loss: 0.1319, Validation Loss: 0.0431,V Acc: 0.7768, Top 70th Acc: 0.8987, Bottom 30th Acc: 0.4848
Fold [1/5] Epoch [20/100] Initial Loss: 0.1373, Training Loss: 0.0259, Initial Validation Loss: 0.1319, Validation Loss: 0.0285,V Acc: 0.8482, Top 70th Acc: 0.9494, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.9493670886075949
Fold [2/5] Epoch [0/100] Initial Loss: 0.1395, Training Loss: 0.1395, Initial Validation Loss: 0.1357, Validation Loss: 0.1357,V Acc: 0.2613, Top 70th Acc: 0.2949, Bottom 30th Acc: 0.1818
Fold [2/5] Epoch [10/100] Initial Loss: 0.1395, Training Loss: 0.0331, Initial Validation Loss: 0.1357, Validation Loss: 0.0340,V Acc: 0.9009, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.8485
Fold [2/5] Epoch [20/100] Initial Loss: 0.1395, Training Loss: 0.0233, Initial Validation Loss: 0.1357, Validation Loss: 0.0256,V Acc: 0.9009, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.7576
Stopping early at Epoch (base 0): 27  Rolling back to Epoch (base 0): 22  Top Validation Acc: 0.9487179487179487
40 1 [array([0.4269315 , 0.04019807, 0.04907397, 0.33596602, 0.14783041],
      dtype=float32)]
Fold [3/5] Epoch [0/100] Initial Loss: 0.1387, Training Loss: 0.1387, Initial Validation Loss: 0.1361, Validation Loss: 0.1361,V Acc: 0.2364, Top 70th Acc: 0.2987, Bottom 30th Acc: 0.0909
Fold [3/5] Epoch [10/100] Initial Loss: 0.1387, Training Loss: 0.0358, Initial Validation Loss: 0.1361, Validation Loss: 0.0491,V Acc: 0.7818, Top 70th Acc: 0.8831, Bottom 30th Acc: 0.5455
Fold [3/5] Epoch [20/100] Initial Loss: 0.1387, Training Loss: 0.0232, Initial Validation Loss: 0.1361, Validation Loss: 0.0397,V Acc: 0.8182, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 29  Rolling back to Epoch (base 0): 24  Top Validation Acc: 0.8831168831168831
Fold [4/5] Epoch [0/100] Initial Loss: 0.1428, Training Loss: 0.1428, Initial Validation Loss: 0.1286, Validation Loss: 0.1286,V Acc: 0.3761, Top 70th Acc: 0.4675, Bottom 30th Acc: 0.1562
Fold [4/5] Epoch [10/100] Initial Loss: 0.1428, Training Loss: 0.0362, Initial Validation Loss: 0.1286, Validation Loss: 0.0392,V Acc: 0.7798, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.4375
Fold [1/5] Epoch [10/100] Initial Loss: 0.1389, Training Loss: 0.0235, Initial Validation Loss: 0.1310, Validation Loss: 0.0257,V Acc: 0.8839, Top 70th Acc: 0.9620, Bottom 30th Acc: 0.6970
Fold [1/5] Epoch [20/100] Initial Loss: 0.1389, Training Loss: 0.0168, Initial Validation Loss: 0.1310, Validation Loss: 0.0219,V Acc: 0.8839, Top 70th Acc: 0.9747, Bottom 30th Acc: 0.6667
Fold [1/5] Epoch [30/100] Initial Loss: 0.1389, Training Loss: 0.0148, Initial Validation Loss: 0.1310, Validation Loss: 0.0231,V Acc: 0.9018, Top 70th Acc: 0.9620, Bottom 30th Acc: 0.7576
Stopping early at Epoch (base 0): 31  Rolling back to Epoch (base 0): 26  Top Validation Acc: 0.9746835443037974
53 0 [array([0.84001935, 0.01908142, 0.01910276, 0.05659695, 0.06519957],
      dtype=float32)]
Fold [2/5] Epoch [0/100] Initial Loss: 0.1390, Training Loss: 0.1390, Initial Validation Loss: 0.1296, Validation Loss: 0.1296,V Acc: 0.2793, Top 70th Acc: 0.3718, Bottom 30th Acc: 0.0606
Fold [2/5] Epoch [10/100] Initial Loss: 0.1390, Training Loss: 0.0184, Initial Validation Loss: 0.1296, Validation Loss: 0.0285,V Acc: 0.8739, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.6667
Fold [2/5] Epoch [20/100] Initial Loss: 0.1390, Training Loss: 0.0141, Initial Validation Loss: 0.1296, Validation Loss: 0.0265,V Acc: 0.8559, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.9743589743589743
Fold [3/5] Epoch [0/100] Initial Loss: 0.1391, Training Loss: 0.1391, Initial Validation Loss: 0.1321, Validation Loss: 0.1321,V Acc: 0.3909, Top 70th Acc: 0.4026, Bottom 30th Acc: 0.3636
Fold [3/5] Epoch [10/100] Initial Loss: 0.1391, Training Loss: 0.0242, Initial Validation Loss: 0.1321, Validation Loss: 0.0324,V Acc: 0.8636, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6667
Fold [3/5] Epoch [20/100] Initial Loss: 0.1391, Training Loss: 0.0173, Initial Validation Loss: 0.1321, Validation Loss: 0.0258,V Acc: 0.9000, Top 70th Acc: 0.9870, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.987012987012987
Fold [4/5] Epoch [0/100] Initial Loss: 0.1335, Training Loss: 0.1335, Initial Validation Loss: 0.1231, Validation Loss: 0.1231,V Acc: 0.4404, Top 70th Acc: 0.5065, Bottom 30th Acc: 0.2812
Fold [4/5] Epoch [10/100] Initial Loss: 0.1335, Training Loss: 0.0202, Initial Validation Loss: 0.1231, Validation Loss: 0.0242,V Acc: 0.8716, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.6562
Fold [4/5] Epoch [20/100] Initial Loss: 0.1335, Training Loss: 0.0153, Initial Validation Loss: 0.1231, Validation Loss: 0.0229,V Acc: 0.8624, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.5938
Stopping early at Epoch (base 0): 20  Rolling back to Epoch (base 0): 15  Top Validation Acc: 0.974025974025974
Fold [5/5] Epoch [0/100] Initial Loss: 0.1426, Training Loss: 0.1426, Initial Validation Loss: 0.1301, Validation Loss: 0.1301,V Acc: 0.1852, Top 70th Acc: 0.1579, Bottom 30th Acc: 0.2500
Fold [5/5] Epoch [10/100] Initial Loss: 0.1426, Training Loss: 0.0213, Initial Validation Loss: 0.1301, Validation Loss: 0.0287,V Acc: 0.8519, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.6250
Fold [5/5] Epoch [20/100] Initial Loss: 0.1426, Training Loss: 0.0151, Initial Validation Loss: 0.1301, Validation Loss: 0.0231,V Acc: 0.8981, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.7812
Stopping early at Epoch (base 0): 20  Rolling back to Epoch (base 0): 15  Top Validation Acc: 0.9473684210526315
Running train_nn.py with seed 54
CUDA:False
Training samples count:  550
Training on 21 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1356, Training Loss: 0.1356, Initial Validation Loss: 0.1223, Validation Loss: 0.1223,V Acc: 0.4643, Top 70th Acc: 0.5949, Bottom 30th Acc: 0.1515
Fold [1/5] Epoch [10/100] Initial Loss: 0.1356, Training Loss: 0.0205, Initial Validation Loss: 0.1223, Validation Loss: 0.0284,V Acc: 0.8661, Top 70th Acc: 0.9620, Bottom 30th Acc: 0.6364
Fold [1/5] Epoch [20/100] Initial Loss: 0.1356, Training Loss: 0.0151, Initial Validation Loss: 0.1223, Validation Loss: 0.0328,V Acc: 0.8125, Top 70th Acc: 0.9367, Bottom 30th Acc: 0.5152
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.9493670886075949
54 0 [array([0.7808964 , 0.02071092, 0.03403193, 0.06488599, 0.09947488],
      dtype=float32)]
Fold [2/5] Epoch [0/100] Initial Loss: 0.1307, Training Loss: 0.1307, Initial Validation Loss: 0.1169, Validation Loss: 0.1169,V Acc: 0.5586, Top 70th Acc: 0.6410, Bottom 30th Acc: 0.3636
Fold [2/5] Epoch [10/100] Initial Loss: 0.1307, Training Loss: 0.0194, Initial Validation Loss: 0.1169, Validation Loss: 0.0234,V Acc: 0.8829, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.6970
Fold [2/5] Epoch [20/100] Initial Loss: 0.1307, Training Loss: 0.0163, Initial Validation Loss: 0.1169, Validation Loss: 0.0203,V Acc: 0.8829, Top 70th Acc: 1.0000, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.9743589743589743
Fold [3/5] Epoch [0/100] Initial Loss: 0.1377, Training Loss: 0.1377, Initial Validation Loss: 0.1252, Validation Loss: 0.1252,V Acc: 0.3909, Top 70th Acc: 0.4026, Bottom 30th Acc: 0.3636
Fold [3/5] Epoch [10/100] Initial Loss: 0.1377, Training Loss: 0.0263, Initial Validation Loss: 0.1252, Validation Loss: 0.0231,V Acc: 0.9364, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.8485
Fold [3/5] Epoch [20/100] Initial Loss: 0.1377, Training Loss: 0.0175, Initial Validation Loss: 0.1252, Validation Loss: 0.0198,V Acc: 0.9364, Top 70th Acc: 0.9870, Bottom 30th Acc: 0.8182
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.974025974025974
Fold [4/5] Epoch [0/100] Initial Loss: 0.1333, Training Loss: 0.1333, Initial Validation Loss: 0.1153, Validation Loss: 0.1153,V Acc: 0.6147, Top 70th Acc: 0.7143, Bottom 30th Acc: 0.3750
Fold [4/5] Epoch [10/100] Initial Loss: 0.1333, Training Loss: 0.0225, Initial Validation Loss: 0.1153, Validation Loss: 0.0270,V Acc: 0.8716, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.6562
Stopping early at Epoch (base 0): 14  Rolling back to Epoch (base 0): 9  Top Validation Acc: 0.974025974025974
Fold [5/5] Epoch [0/100] Initial Loss: 0.1331, Training Loss: 0.1331, Initial Validation Loss: 0.1143, Validation Loss: 0.1143,V Acc: 0.5833, Top 70th Acc: 0.6974, Bottom 30th Acc: 0.3125
Fold [5/5] Epoch [10/100] Initial Loss: 0.1331, Training Loss: 0.0240, Initial Validation Loss: 0.1143, Validation Loss: 0.0355,V Acc: 0.8148, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.5312
Stopping early at Epoch (base 0): 16  Rolling back to Epoch (base 0): 11  Top Validation Acc: 0.9342105263157895
Running train_nn.py with seed 55
CUDA:False
Training samples count:  550
Training on 21 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1345, Training Loss: 0.1345, Initial Validation Loss: 0.1237, Validation Loss: 0.1237,V Acc: 0.5000, Top 70th Acc: 0.5443, Bottom 30th Acc: 0.3939
Fold [1/5] Epoch [10/100] Initial Loss: 0.1345, Training Loss: 0.0231, Initial Validation Loss: 0.1237, Validation Loss: 0.0265,V Acc: 0.8661, Top 70th Acc: 0.9494, Bottom 30th Acc: 0.6667
Fold [1/5] Epoch [20/100] Initial Loss: 0.1345, Training Loss: 0.0152, Initial Validation Loss: 0.1237, Validation Loss: 0.0242,V Acc: 0.8750, Top 70th Acc: 0.9620, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.9746835443037974
Fold [2/5] Epoch [0/100] Initial Loss: 0.1292, Training Loss: 0.1292, Initial Validation Loss: 0.1180, Validation Loss: 0.1180,V Acc: 0.4595, Top 70th Acc: 0.5385, Bottom 30th Acc: 0.2727
Fold [2/5] Epoch [10/100] Initial Loss: 0.1292, Training Loss: 0.0217, Initial Validation Loss: 0.1180, Validation Loss: 0.0276,V Acc: 0.8559, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 16  Rolling back to Epoch (base 0): 11  Top Validation Acc: 0.9615384615384616
Fold [3/5] Epoch [0/100] Initial Loss: 0.1334, Training Loss: 0.1334, Initial Validation Loss: 0.1177, Validation Loss: 0.1177,V Acc: 0.5182, Top 70th Acc: 0.5584, Bottom 30th Acc: 0.4242
Fold [3/5] Epoch [10/100] Initial Loss: 0.1334, Training Loss: 0.0230, Initial Validation Loss: 0.1177, Validation Loss: 0.0300,V Acc: 0.8455, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 31  Rolling back to Epoch (base 0): 26  Top Validation Acc: 0.922077922077922
Fold [5/5] Epoch [0/100] Initial Loss: 0.1403, Training Loss: 0.1403, Initial Validation Loss: 0.1346, Validation Loss: 0.1346,V Acc: 0.2500, Top 70th Acc: 0.3289, Bottom 30th Acc: 0.0625
Fold [5/5] Epoch [10/100] Initial Loss: 0.1403, Training Loss: 0.0327, Initial Validation Loss: 0.1346, Validation Loss: 0.0378,V Acc: 0.8241, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.5000
Fold [5/5] Epoch [20/100] Initial Loss: 0.1403, Training Loss: 0.0170, Initial Validation Loss: 0.1346, Validation Loss: 0.0329,V Acc: 0.8426, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.5625
Fold [5/5] Epoch [30/100] Initial Loss: 0.1403, Training Loss: 0.0129, Initial Validation Loss: 0.1346, Validation Loss: 0.0322,V Acc: 0.8519, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.6562
Stopping early at Epoch (base 0): 39  Rolling back to Epoch (base 0): 34  Top Validation Acc: 0.9210526315789473
Running train_nn.py with seed 41
CUDA:False
Training samples count:  550
Training on 40 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1388, Training Loss: 0.1388, Initial Validation Loss: 0.1409, Validation Loss: 0.1409,V Acc: 0.3125, Top 70th Acc: 0.3544, Bottom 30th Acc: 0.2121
Fold [1/5] Epoch [10/100] Initial Loss: 0.1388, Training Loss: 0.0344, Initial Validation Loss: 0.1409, Validation Loss: 0.0469,V Acc: 0.7946, Top 70th Acc: 0.8861, Bottom 30th Acc: 0.5758
Fold [1/5] Epoch [20/100] Initial Loss: 0.1388, Training Loss: 0.0147, Initial Validation Loss: 0.1409, Validation Loss: 0.0301,V Acc: 0.8661, Top 70th Acc: 0.9747, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 29  Rolling back to Epoch (base 0): 24  Top Validation Acc: 0.9620253164556962
Fold [2/5] Epoch [0/100] Initial Loss: 0.1407, Training Loss: 0.1407, Initial Validation Loss: 0.1325, Validation Loss: 0.1325,V Acc: 0.2883, Top 70th Acc: 0.3462, Bottom 30th Acc: 0.1515
Fold [2/5] Epoch [10/100] Initial Loss: 0.1407, Training Loss: 0.0249, Initial Validation Loss: 0.1325, Validation Loss: 0.0373,V Acc: 0.8018, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.4848
Stopping early at Epoch (base 0): 19  Rolling back to Epoch (base 0): 14  Top Validation Acc: 0.8974358974358975
Fold [3/5] Epoch [0/100] Initial Loss: 0.1409, Training Loss: 0.1409, Initial Validation Loss: 0.1307, Validation Loss: 0.1307,V Acc: 0.3909, Top 70th Acc: 0.4416, Bottom 30th Acc: 0.2727
Fold [3/5] Epoch [10/100] Initial Loss: 0.1409, Training Loss: 0.0358, Initial Validation Loss: 0.1307, Validation Loss: 0.0387,V Acc: 0.8273, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.6364
Fold [3/5] Epoch [20/100] Initial Loss: 0.1409, Training Loss: 0.0165, Initial Validation Loss: 0.1307, Validation Loss: 0.0263,V Acc: 0.8636, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 29  Rolling back to Epoch (base 0): 24  Top Validation Acc: 0.961038961038961
41 2 [array([0.78568363, 0.03362438, 0.02580086, 0.06890935, 0.08598185],
      dtype=float32)]
Fold [4/5] Epoch [0/100] Initial Loss: 0.1435, Training Loss: 0.1435, Initial Validation Loss: 0.1297, Validation Loss: 0.1297,V Acc: 0.2661, Top 70th Acc: 0.3117, Bottom 30th Acc: 0.1562
Fold [4/5] Epoch [10/100] Initial Loss: 0.1435, Training Loss: 0.0426, Initial Validation Loss: 0.1297, Validation Loss: 0.0491,V Acc: 0.7890, Top 70th Acc: 0.8701, Bottom 30th Acc: 0.5938
Fold [4/5] Epoch [20/100] Initial Loss: 0.1435, Training Loss: 0.0172, Initial Validation Loss: 0.1297, Validation Loss: 0.0282,V Acc: 0.8807, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.7188
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.948051948051948
Fold [5/5] Epoch [0/100] Initial Loss: 0.1382, Training Loss: 0.1382, Initial Validation Loss: 0.1364, Validation Loss: 0.1364,V Acc: 0.3148, Top 70th Acc: 0.3421, Bottom 30th Acc: 0.2500
Fold [5/5] Epoch [10/100] Initial Loss: 0.1382, Training Loss: 0.0343, Initial Validation Loss: 0.1364, Validation Loss: 0.0447,V Acc: 0.7778, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.3750
Fold [5/5] Epoch [20/100] Initial Loss: 0.1382, Training Loss: 0.0194, Initial Validation Loss: 0.1364, Validation Loss: 0.0337,V Acc: 0.8611, Top 70th Acc: 0.9737, Bottom 30th Acc: 0.5938
Fold [5/5] Epoch [30/100] Initial Loss: 0.1382, Training Loss: 0.0141, Initial Validation Loss: 0.1364, Validation Loss: 0.0300,V Acc: 0.8704, Top 70th Acc: 0.9737, Bottom 30th Acc: 0.6250
Stopping early at Epoch (base 0): 39  Rolling back to Epoch (base 0): 34  Top Validation Acc: 0.9605263157894737
Running train_nn.py with seed 42
CUDA:False
Training samples count:  550
Training on 40 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1387, Training Loss: 0.1387, Initial Validation Loss: 0.1365, Validation Loss: 0.1365,V Acc: 0.2500, Top 70th Acc: 0.3038, Bottom 30th Acc: 0.1212
Fold [1/5] Epoch [10/100] Initial Loss: 0.1387, Training Loss: 0.0407, Initial Validation Loss: 0.1365, Validation Loss: 0.0538,V Acc: 0.7679, Top 70th Acc: 0.8228, Bottom 30th Acc: 0.6364
Fold [1/5] Epoch [20/100] Initial Loss: 0.1387, Training Loss: 0.0164, Initial Validation Loss: 0.1365, Validation Loss: 0.0346,V Acc: 0.8661, Top 70th Acc: 0.9114, Bottom 30th Acc: 0.7576
Fold [1/5] Epoch [30/100] Initial Loss: 0.1387, Training Loss: 0.0137, Initial Validation Loss: 0.1365, Validation Loss: 0.0331,V Acc: 0.8482, Top 70th Acc: 0.9114, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 33  Rolling back to Epoch (base 0): 28  Top Validation Acc: 0.9113924050632911
Fold [2/5] Epoch [0/100] Initial Loss: 0.1431, Training Loss: 0.1431, Initial Validation Loss: 0.1377, Validation Loss: 0.1377,V Acc: 0.2793, Top 70th Acc: 0.3077, Bottom 30th Acc: 0.2121
Fold [2/5] Epoch [10/100] Initial Loss: 0.1431, Training Loss: 0.0399, Initial Validation Loss: 0.1377, Validation Loss: 0.0500,V Acc: 0.7658, Top 70th Acc: 0.8590, Bottom 30th Acc: 0.5455
Fold [2/5] Epoch [20/100] Initial Loss: 0.1431, Training Loss: 0.0173, Initial Validation Loss: 0.1377, Validation Loss: 0.0415,V Acc: 0.8108, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.5758
Fold [2/5] Epoch [30/100] Initial Loss: 0.1431, Training Loss: 0.0123, Initial Validation Loss: 0.1377, Validation Loss: 0.0404,V Acc: 0.7928, Top 70th Acc: 0.8846, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 32  Rolling back to Epoch (base 0): 27  Top Validation Acc: 0.8846153846153846
Fold [3/5] Epoch [0/100] Initial Loss: 0.1388, Training Loss: 0.1388, Initial Validation Loss: 0.1344, Validation Loss: 0.1344,V Acc: 0.3182, Top 70th Acc: 0.3636, Bottom 30th Acc: 0.2121
Fold [3/5] Epoch [10/100] Initial Loss: 0.1388, Training Loss: 0.0357, Initial Validation Loss: 0.1344, Validation Loss: 0.0424,V Acc: 0.8273, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.5758
Fold [3/5] Epoch [20/100] Initial Loss: 0.1388, Training Loss: 0.0155, Initial Validation Loss: 0.1344, Validation Loss: 0.0260,V Acc: 0.8727, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.961038961038961
Fold [4/5] Epoch [0/100] Initial Loss: 0.1439, Training Loss: 0.1439, Initial Validation Loss: 0.1334, Validation Loss: 0.1334,V Acc: 0.2752, Top 70th Acc: 0.3377, Bottom 30th Acc: 0.1250
Fold [4/5] Epoch [10/100] Initial Loss: 0.1439, Training Loss: 0.0354, Initial Validation Loss: 0.1334, Validation Loss: 0.0364,V Acc: 0.8073, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.4688
Fold [4/5] Epoch [20/100] Initial Loss: 0.1439, Training Loss: 0.0174, Initial Validation Loss: 0.1334, Validation Loss: 0.0250,V Acc: 0.8807, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.6875
Fold [4/5] Epoch [30/100] Initial Loss: 0.1439, Training Loss: 0.0128, Initial Validation Loss: 0.1334, Validation Loss: 0.0235,V Acc: 0.8807, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.6875
Stopping early at Epoch (base 0): 36  Rolling back to Epoch (base 0): 31  Top Validation Acc: 0.948051948051948
Fold [5/5] Epoch [0/100] Initial Loss: 0.1401, Training Loss: 0.1401, Initial Validation Loss: 0.1272, Validation Loss: 0.1272,V Acc: 0.3333, Top 70th Acc: 0.4211, Bottom 30th Acc: 0.1250
Fold [5/5] Epoch [10/100] Initial Loss: 0.1401, Training Loss: 0.0225, Initial Validation Loss: 0.1272, Validation Loss: 0.0322,V Acc: 0.8426, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.5938
Fold [1/5] Epoch [0/100] Initial Loss: 0.1340, Training Loss: 0.1340, Initial Validation Loss: 0.1222, Validation Loss: 0.1222,V Acc: 0.4107, Top 70th Acc: 0.5190, Bottom 30th Acc: 0.1515
Fold [1/5] Epoch [10/100] Initial Loss: 0.1340, Training Loss: 0.0818, Initial Validation Loss: 0.1222, Validation Loss: 0.0759,V Acc: 0.6161, Top 70th Acc: 0.7215, Bottom 30th Acc: 0.3636
Fold [1/5] Epoch [20/100] Initial Loss: 0.1340, Training Loss: 0.0800, Initial Validation Loss: 0.1222, Validation Loss: 0.0741,V Acc: 0.6071, Top 70th Acc: 0.7089, Bottom 30th Acc: 0.3636
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.7215189873417721
Fold [2/5] Epoch [0/100] Initial Loss: 0.1263, Training Loss: 0.1263, Initial Validation Loss: 0.1134, Validation Loss: 0.1134,V Acc: 0.4865, Top 70th Acc: 0.5256, Bottom 30th Acc: 0.3939
Fold [2/5] Epoch [10/100] Initial Loss: 0.1263, Training Loss: 0.0816, Initial Validation Loss: 0.1134, Validation Loss: 0.0761,V Acc: 0.6577, Top 70th Acc: 0.7821, Bottom 30th Acc: 0.3636
Fold [2/5] Epoch [20/100] Initial Loss: 0.1263, Training Loss: 0.0797, Initial Validation Loss: 0.1134, Validation Loss: 0.0741,V Acc: 0.6577, Top 70th Acc: 0.8077, Bottom 30th Acc: 0.3030
Fold [2/5] Epoch [30/100] Initial Loss: 0.1263, Training Loss: 0.0791, Initial Validation Loss: 0.1134, Validation Loss: 0.0731,V Acc: 0.6667, Top 70th Acc: 0.8077, Bottom 30th Acc: 0.3333
Fold [2/5] Epoch [40/100] Initial Loss: 0.1263, Training Loss: 0.0788, Initial Validation Loss: 0.1134, Validation Loss: 0.0723,V Acc: 0.6667, Top 70th Acc: 0.7949, Bottom 30th Acc: 0.3636
Fold [2/5] Epoch [50/100] Initial Loss: 0.1263, Training Loss: 0.0780, Initial Validation Loss: 0.1134, Validation Loss: 0.0727,V Acc: 0.6577, Top 70th Acc: 0.7949, Bottom 30th Acc: 0.3333
Stopping early at Epoch (base 0): 53  Rolling back to Epoch (base 0): 48  Top Validation Acc: 0.8076923076923077
Fold [3/5] Epoch [0/100] Initial Loss: 0.1369, Training Loss: 0.1369, Initial Validation Loss: 0.1253, Validation Loss: 0.1253,V Acc: 0.3273, Top 70th Acc: 0.4026, Bottom 30th Acc: 0.1515
Fold [3/5] Epoch [10/100] Initial Loss: 0.1369, Training Loss: 0.0791, Initial Validation Loss: 0.1253, Validation Loss: 0.0825,V Acc: 0.6273, Top 70th Acc: 0.7532, Bottom 30th Acc: 0.3333
Fold [3/5] Epoch [20/100] Initial Loss: 0.1369, Training Loss: 0.0778, Initial Validation Loss: 0.1253, Validation Loss: 0.0820,V Acc: 0.6091, Top 70th Acc: 0.7403, Bottom 30th Acc: 0.3030
Fold [3/5] Epoch [30/100] Initial Loss: 0.1369, Training Loss: 0.0771, Initial Validation Loss: 0.1253, Validation Loss: 0.0826,V Acc: 0.6091, Top 70th Acc: 0.7532, Bottom 30th Acc: 0.2727
Stopping early at Epoch (base 0): 30  Rolling back to Epoch (base 0): 25  Top Validation Acc: 0.7532467532467533
Fold [4/5] Epoch [0/100] Initial Loss: 0.1354, Training Loss: 0.1354, Initial Validation Loss: 0.1278, Validation Loss: 0.1278,V Acc: 0.4312, Top 70th Acc: 0.4416, Bottom 30th Acc: 0.4062
Fold [4/5] Epoch [10/100] Initial Loss: 0.1354, Training Loss: 0.0775, Initial Validation Loss: 0.1278, Validation Loss: 0.0868,V Acc: 0.6055, Top 70th Acc: 0.7273, Bottom 30th Acc: 0.3125
Fold [4/5] Epoch [20/100] Initial Loss: 0.1354, Training Loss: 0.0760, Initial Validation Loss: 0.1278, Validation Loss: 0.0852,V Acc: 0.6055, Top 70th Acc: 0.7273, Bottom 30th Acc: 0.3125
Fold [4/5] Epoch [30/100] Initial Loss: 0.1354, Training Loss: 0.0753, Initial Validation Loss: 0.1278, Validation Loss: 0.0850,V Acc: 0.6147, Top 70th Acc: 0.7273, Bottom 30th Acc: 0.3438
Fold [4/5] Epoch [40/100] Initial Loss: 0.1354, Training Loss: 0.0749, Initial Validation Loss: 0.1278, Validation Loss: 0.0842,V Acc: 0.6239, Top 70th Acc: 0.7403, Bottom 30th Acc: 0.3438
Fold [4/5] Epoch [50/100] Initial Loss: 0.1354, Training Loss: 0.0744, Initial Validation Loss: 0.1278, Validation Loss: 0.0843,V Acc: 0.6239, Top 70th Acc: 0.7403, Bottom 30th Acc: 0.3438
Stopping early at Epoch (base 0): 52  Rolling back to Epoch (base 0): 47  Top Validation Acc: 0.7402597402597403
39 3 [array([0.13650137, 0.34451315, 0.15138172, 0.23777339, 0.12983033],
      dtype=float32)]
Fold [5/5] Epoch [0/100] Initial Loss: 0.1392, Training Loss: 0.1392, Initial Validation Loss: 0.1270, Validation Loss: 0.1270,V Acc: 0.4907, Top 70th Acc: 0.5132, Bottom 30th Acc: 0.4375
Fold [5/5] Epoch [10/100] Initial Loss: 0.1392, Training Loss: 0.0817, Initial Validation Loss: 0.1270, Validation Loss: 0.0728,V Acc: 0.6759, Top 70th Acc: 0.7632, Bottom 30th Acc: 0.4688
Fold [5/5] Epoch [20/100] Initial Loss: 0.1392, Training Loss: 0.0793, Initial Validation Loss: 0.1270, Validation Loss: 0.0715,V Acc: 0.6667, Top 70th Acc: 0.7368, Bottom 30th Acc: 0.5000
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.7368421052631579
Running train_nn.py with seed 40
CUDA:False
Training samples count:  550
Training on 2 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1381, Training Loss: 0.1381, Initial Validation Loss: 0.1273, Validation Loss: 0.1273,V Acc: 0.5089, Top 70th Acc: 0.5823, Bottom 30th Acc: 0.3333
Fold [1/5] Epoch [10/100] Initial Loss: 0.1381, Training Loss: 0.0828, Initial Validation Loss: 0.1273, Validation Loss: 0.0716,V Acc: 0.6607, Top 70th Acc: 0.7975, Bottom 30th Acc: 0.3333
Fold [1/5] Epoch [20/100] Initial Loss: 0.1381, Training Loss: 0.0815, Initial Validation Loss: 0.1273, Validation Loss: 0.0693,V Acc: 0.6786, Top 70th Acc: 0.7975, Bottom 30th Acc: 0.3939
Fold [1/5] Epoch [30/100] Initial Loss: 0.1381, Training Loss: 0.0809, Initial Validation Loss: 0.1273, Validation Loss: 0.0692,V Acc: 0.6607, Top 70th Acc: 0.7975, Bottom 30th Acc: 0.3333
Fold [1/5] Epoch [40/100] Initial Loss: 0.1381, Training Loss: 0.0807, Initial Validation Loss: 0.1273, Validation Loss: 0.0688,V Acc: 0.6607, Top 70th Acc: 0.7722, Bottom 30th Acc: 0.3939
Fold [1/5] Epoch [50/100] Initial Loss: 0.1381, Training Loss: 0.0806, Initial Validation Loss: 0.1273, Validation Loss: 0.0678,V Acc: 0.6786, Top 70th Acc: 0.7848, Bottom 30th Acc: 0.4242
Fold [1/5] Epoch [60/100] Initial Loss: 0.1381, Training Loss: 0.0806, Initial Validation Loss: 0.1273, Validation Loss: 0.0674,V Acc: 0.6875, Top 70th Acc: 0.8101, Bottom 30th Acc: 0.3939
Stopping early at Epoch (base 0): 66  Rolling back to Epoch (base 0): 61  Top Validation Acc: 0.7974683544303798
Fold [2/5] Epoch [0/100] Initial Loss: 0.1384, Training Loss: 0.1384, Initial Validation Loss: 0.1326, Validation Loss: 0.1326,V Acc: 0.4775, Top 70th Acc: 0.5000, Bottom 30th Acc: 0.4242
Fold [2/5] Epoch [10/100] Initial Loss: 0.1384, Training Loss: 0.0829, Initial Validation Loss: 0.1326, Validation Loss: 0.0804,V Acc: 0.6396, Top 70th Acc: 0.7051, Bottom 30th Acc: 0.4848
Fold [2/5] Epoch [20/100] Initial Loss: 0.1384, Training Loss: 0.0801, Initial Validation Loss: 0.1326, Validation Loss: 0.0791,V Acc: 0.6396, Top 70th Acc: 0.7179, Bottom 30th Acc: 0.4545
Fold [2/5] Epoch [30/100] Initial Loss: 0.1384, Training Loss: 0.0793, Initial Validation Loss: 0.1326, Validation Loss: 0.0777,V Acc: 0.6396, Top 70th Acc: 0.7051, Bottom 30th Acc: 0.4848
Stopping early at Epoch (base 0): 32  Rolling back to Epoch (base 0): 27  Top Validation Acc: 0.717948717948718
40 1 [array([0.12354369, 0.37810493, 0.14455388, 0.19563362, 0.15816386],
      dtype=float32)]
Fold [3/5] Epoch [0/100] Initial Loss: 0.1316, Training Loss: 0.1316, Initial Validation Loss: 0.1237, Validation Loss: 0.1237,V Acc: 0.4182, Top 70th Acc: 0.5195, Bottom 30th Acc: 0.1818
Fold [3/5] Epoch [10/100] Initial Loss: 0.1316, Training Loss: 0.0773, Initial Validation Loss: 0.1237, Validation Loss: 0.0896,V Acc: 0.5727, Top 70th Acc: 0.6883, Bottom 30th Acc: 0.3030
Stopping early at Epoch (base 0): 19  Rolling back to Epoch (base 0): 14  Top Validation Acc: 0.7012987012987013
Fold [4/5] Epoch [0/100] Initial Loss: 0.1431, Training Loss: 0.1431, Initial Validation Loss: 0.1259, Validation Loss: 0.1259,V Acc: 0.3394, Top 70th Acc: 0.4286, Bottom 30th Acc: 0.1250
Fold [4/5] Epoch [10/100] Initial Loss: 0.1431, Training Loss: 0.0810, Initial Validation Loss: 0.1259, Validation Loss: 0.0770,V Acc: 0.6330, Top 70th Acc: 0.7403, Bottom 30th Acc: 0.3750
Fold [4/5] Epoch [20/100] Initial Loss: 0.1431, Training Loss: 0.0790, Initial Validation Loss: 0.1259, Validation Loss: 0.0752,V Acc: 0.6422, Top 70th Acc: 0.7662, Bottom 30th Acc: 0.3438 0.987012987012987
Fold [4/5] Epoch [0/100] Initial Loss: 0.1421, Training Loss: 0.1421, Initial Validation Loss: 0.1381, Validation Loss: 0.1381,V Acc: 0.2385, Top 70th Acc: 0.2987, Bottom 30th Acc: 0.0938
Fold [4/5] Epoch [10/100] Initial Loss: 0.1421, Training Loss: 0.0511, Initial Validation Loss: 0.1381, Validation Loss: 0.0502,V Acc: 0.7982, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.5312
Fold [4/5] Epoch [20/100] Initial Loss: 0.1421, Training Loss: 0.0226, Initial Validation Loss: 0.1381, Validation Loss: 0.0228,V Acc: 0.9083, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.7500
Stopping early at Epoch (base 0): 28  Rolling back to Epoch (base 0): 23  Top Validation Acc: 0.974025974025974
Fold [5/5] Epoch [0/100] Initial Loss: 0.1395, Training Loss: 0.1395, Initial Validation Loss: 0.1283, Validation Loss: 0.1283,V Acc: 0.3241, Top 70th Acc: 0.4211, Bottom 30th Acc: 0.0938
Fold [5/5] Epoch [10/100] Initial Loss: 0.1395, Training Loss: 0.0250, Initial Validation Loss: 0.1283, Validation Loss: 0.0359,V Acc: 0.8148, Top 70th Acc: 0.9211, Bottom 30th Acc: 0.5625
Stopping early at Epoch (base 0): 17  Rolling back to Epoch (base 0): 12  Top Validation Acc: 0.9078947368421053
Running train_nn.py with seed 39
CUDA:False
Training samples count:  550
Training on 30 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1385, Training Loss: 0.1385, Initial Validation Loss: 0.1341, Validation Loss: 0.1341,V Acc: 0.3661, Top 70th Acc: 0.4177, Bottom 30th Acc: 0.2424
Fold [1/5] Epoch [10/100] Initial Loss: 0.1385, Training Loss: 0.0333, Initial Validation Loss: 0.1341, Validation Loss: 0.0368,V Acc: 0.8393, Top 70th Acc: 0.9494, Bottom 30th Acc: 0.5758
Fold [1/5] Epoch [20/100] Initial Loss: 0.1385, Training Loss: 0.0189, Initial Validation Loss: 0.1341, Validation Loss: 0.0286,V Acc: 0.8750, Top 70th Acc: 0.9620, Bottom 30th Acc: 0.6667
Fold [1/5] Epoch [30/100] Initial Loss: 0.1385, Training Loss: 0.0161, Initial Validation Loss: 0.1341, Validation Loss: 0.0284,V Acc: 0.8661, Top 70th Acc: 0.9620, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 31  Rolling back to Epoch (base 0): 26  Top Validation Acc: 0.9746835443037974
Fold [2/5] Epoch [0/100] Initial Loss: 0.1393, Training Loss: 0.1393, Initial Validation Loss: 0.1345, Validation Loss: 0.1345,V Acc: 0.3153, Top 70th Acc: 0.3718, Bottom 30th Acc: 0.1818
Fold [2/5] Epoch [10/100] Initial Loss: 0.1393, Training Loss: 0.0343, Initial Validation Loss: 0.1345, Validation Loss: 0.0347,V Acc: 0.8919, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.6970
Fold [2/5] Epoch [20/100] Initial Loss: 0.1393, Training Loss: 0.0192, Initial Validation Loss: 0.1345, Validation Loss: 0.0289,V Acc: 0.8649, Top 70th Acc: 0.9872, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 28  Rolling back to Epoch (base 0): 23  Top Validation Acc: 0.9871794871794872
Fold [3/5] Epoch [0/100] Initial Loss: 0.1391, Training Loss: 0.1391, Initial Validation Loss: 0.1328, Validation Loss: 0.1328,V Acc: 0.3727, Top 70th Acc: 0.4805, Bottom 30th Acc: 0.1212
Fold [3/5] Epoch [10/100] Initial Loss: 0.1391, Training Loss: 0.0343, Initial Validation Loss: 0.1328, Validation Loss: 0.0442,V Acc: 0.8091, Top 70th Acc: 0.8831, Bottom 30th Acc: 0.6364
Fold [3/5] Epoch [20/100] Initial Loss: 0.1391, Training Loss: 0.0183, Initial Validation Loss: 0.1328, Validation Loss: 0.0352,V Acc: 0.8182, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 29  Rolling back to Epoch (base 0): 24  Top Validation Acc: 0.922077922077922
Fold [4/5] Epoch [0/100] Initial Loss: 0.1387, Training Loss: 0.1387, Initial Validation Loss: 0.1321, Validation Loss: 0.1321,V Acc: 0.3761, Top 70th Acc: 0.4026, Bottom 30th Acc: 0.3125
Fold [4/5] Epoch [10/100] Initial Loss: 0.1387, Training Loss: 0.0281, Initial Validation Loss: 0.1321, Validation Loss: 0.0354,V Acc: 0.8440, Top 70th Acc: 0.8961, Bottom 30th Acc: 0.7188
Fold [4/5] Epoch [20/100] Initial Loss: 0.1387, Training Loss: 0.0183, Initial Validation Loss: 0.1321, Validation Loss: 0.0312,V Acc: 0.8257, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.5000
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.961038961038961
39 3 [array([0.6541924 , 0.05702569, 0.05333481, 0.13964279, 0.09580432],
      dtype=float32)]
Fold [5/5] Epoch [0/100] Initial Loss: 0.1357, Training Loss: 0.1357, Initial Validation Loss: 0.1253, Validation Loss: 0.1253,V Acc: 0.4722, Top 70th Acc: 0.6316, Bottom 30th Acc: 0.0938
Fold [5/5] Epoch [10/100] Initial Loss: 0.1357, Training Loss: 0.0326, Initial Validation Loss: 0.1253, Validation Loss: 0.0415,V Acc: 0.7870, Top 70th Acc: 0.8684, Bottom 30th Acc: 0.5938
Fold [5/5] Epoch [20/100] Initial Loss: 0.1357, Training Loss: 0.0224, Initial Validation Loss: 0.1253, Validation Loss: 0.0380,V Acc: 0.7685, Top 70th Acc: 0.8947, Bottom 30th Acc: 0.4688
Fold [5/5] Epoch [30/100] Initial Loss: 0.1357, Training Loss: 0.0178, Initial Validation Loss: 0.1253, Validation Loss: 0.0342,V Acc: 0.7963, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.4688
Stopping early at Epoch (base 0): 36  Rolling back to Epoch (base 0): 31  Top Validation Acc: 0.9473684210526315
Running train_nn.py with seed 40
CUDA:False
Training samples count:  550
Training on 30 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1401, Training Loss: 0.1401, Initial Validation Loss: 0.1352, Validation Loss: 0.1352,V Acc: 0.3661, Top 70th Acc: 0.4557, Bottom 30th Acc: 0.1515
Fold [1/5] Epoch [10/100] Initial Loss: 0.1401, Training Loss: 0.0327, Initial Validation Loss: 0.1352, Validation Loss: 0.0370,V Acc: 0.8214, Top 70th Acc: 0.9114, Bottom 30th Acc: 0.6061
Fold [1/5] Epoch [20/100] Initial Loss: 0.1401, Training Loss: 0.0193, Initial Validation Loss: 0.1352, Validation Loss: 0.0315,V Acc: 0.8304, Top 70th Acc: 0.9241, Bottom 30th Acc: 0.6061
Fold [1/5] Epoch [30/100] Initial Loss: 0.1401, Training Loss: 0.0164, Initial Validation Loss: 0.1352, Validation Loss: 0.0306,V Acc: 0.8304, Top 70th Acc: 0.9241, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 34  Rolling back to Epoch (base 0): 29  Top Validation Acc: 0.9367088607594937
Fold [2/5] Epoch [0/100] Initial Loss: 0.1404, Training Loss: 0.1404, Initial Validation Loss: 0.1367, Validation Loss: 0.1367,V Acc: 0.2162, Top 70th Acc: 0.2692, Bottom 30th Acc: 0.0909
Fold [2/5] Epoch [10/100] Initial Loss: 0.1404, Training Loss: 0.0380, Initial Validation Loss: 0.1367, Validation Loss: 0.0384,V Acc: 0.8288, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.6061
Fold [2/5] Epoch [20/100] Initial Loss: 0.1404, Training Loss: 0.0195, Initial Validation Loss: 0.1367, Validation Loss: 0.0245,V Acc: 0.8829, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.6667
Fold [2/5] Epoch [30/100] Initial Loss: 0.1404, Training Loss: 0.0163, Initial Validation Loss: 0.1367, Validation Loss: 0.0246,V Acc: 0.8649, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 32  Rolling back to Epoch (base 0): 27  Top Validation Acc: 0.9743589743589743
40 1 [array([0.69555503, 0.06243498, 0.04289952, 0.06680688, 0.13230355],
      dtype=float32)]
Fold [3/5] Epoch [0/100] Initial Loss: 0.1397, Training Loss: 0.1397, Initial Validation Loss: 0.1369, Validation Loss: 0.1369,V Acc: 0.3273, Top 70th Acc: 0.4286, Bottom 30th Acc: 0.0909
Fold [3/5] Epoch [10/100] Initial Loss: 0.1397, Training Loss: 0.0261, Initial Validation Loss: 0.1369, Validation Loss: 0.0410,V Acc: 0.8000, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.5455
Fold [3/5] Epoch [20/100] Initial Loss: 0.1397, Training Loss: 0.0163, Initial Validation Loss: 0.1369, Validation Loss: 0.0360,V Acc: 0.8091, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.5152
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.935064935064935
Fold [4/5] Epoch [0/100] Initial Loss: 0.1397, Training Loss: 0.1397, Initial Validation Loss: 0.1274, Validation Loss: 0.1274,V Acc: 0.3853, Top 70th Acc: 0.4286, Bottom 30th Acc: 0.2812
Fold [4/5] Epoch [10/100] Initial Loss: 0.1397, Training Loss: 0.0352, Initial Validation Loss: 0.1274, Validation Loss: 0.0403,V Acc: 0.8073, Top 70th Acc: 0.8961, Bottom 30th Acc: 0.5938
Fold [4/5] Epoch [20/100] Initial Loss: 0.1397, Training Loss: 0.0180, Initial Validation Loss: 0.1274, Validation Loss: 0.0335,V Acc: 0.7982, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.5000
Fold [4/5] Epoch [20/100] Initial Loss: 0.1436, Training Loss: 0.0052, Initial Validation Loss: 0.1349, Validation Loss: 0.0205,V Acc: 0.9083, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.7812
Stopping early at Epoch (base 0): 22  Rolling back to Epoch (base 0): 17  Top Validation Acc: 0.961038961038961
Fold [5/5] Epoch [0/100] Initial Loss: 0.1376, Training Loss: 0.1376, Initial Validation Loss: 0.1290, Validation Loss: 0.1290,V Acc: 0.3704, Top 70th Acc: 0.4342, Bottom 30th Acc: 0.2188
Fold [5/5] Epoch [10/100] Initial Loss: 0.1376, Training Loss: 0.0213, Initial Validation Loss: 0.1290, Validation Loss: 0.0339,V Acc: 0.8611, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.6250
Fold [5/5] Epoch [20/100] Initial Loss: 0.1376, Training Loss: 0.0044, Initial Validation Loss: 0.1290, Validation Loss: 0.0288,V Acc: 0.8333, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.5312
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.9736842105263158
Running train_nn.py with seed 31
CUDA:False
Training samples count:  550
Training on 162 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1467, Training Loss: 0.1467, Initial Validation Loss: 0.1420, Validation Loss: 0.1420,V Acc: 0.2500, Top 70th Acc: 0.3291, Bottom 30th Acc: 0.0606
Fold [1/5] Epoch [10/100] Initial Loss: 0.1467, Training Loss: 0.0295, Initial Validation Loss: 0.1420, Validation Loss: 0.0472,V Acc: 0.7857, Top 70th Acc: 0.8861, Bottom 30th Acc: 0.5455
Fold [1/5] Epoch [20/100] Initial Loss: 0.1467, Training Loss: 0.0063, Initial Validation Loss: 0.1420, Validation Loss: 0.0316,V Acc: 0.8304, Top 70th Acc: 0.9620, Bottom 30th Acc: 0.5152
Fold [1/5] Epoch [30/100] Initial Loss: 0.1467, Training Loss: 0.0042, Initial Validation Loss: 0.1420, Validation Loss: 0.0298,V Acc: 0.8304, Top 70th Acc: 0.9620, Bottom 30th Acc: 0.5152
Stopping early at Epoch (base 0): 31  Rolling back to Epoch (base 0): 26  Top Validation Acc: 0.9620253164556962
Fold [2/5] Epoch [0/100] Initial Loss: 0.1404, Training Loss: 0.1404, Initial Validation Loss: 0.1323, Validation Loss: 0.1323,V Acc: 0.2703, Top 70th Acc: 0.3205, Bottom 30th Acc: 0.1515
Fold [2/5] Epoch [10/100] Initial Loss: 0.1404, Training Loss: 0.0164, Initial Validation Loss: 0.1323, Validation Loss: 0.0402,V Acc: 0.8288, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.6061
Fold [2/5] Epoch [20/100] Initial Loss: 0.1404, Training Loss: 0.0042, Initial Validation Loss: 0.1323, Validation Loss: 0.0351,V Acc: 0.8288, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.6061
Fold [2/5] Epoch [30/100] Initial Loss: 0.1404, Training Loss: 0.0036, Initial Validation Loss: 0.1323, Validation Loss: 0.0339,V Acc: 0.8378, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.6061
Fold [2/5] Epoch [40/100] Initial Loss: 0.1404, Training Loss: 0.0034, Initial Validation Loss: 0.1323, Validation Loss: 0.0338,V Acc: 0.8468, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 42  Rolling back to Epoch (base 0): 37  Top Validation Acc: 0.9358974358974359
Fold [3/5] Epoch [0/100] Initial Loss: 0.1400, Training Loss: 0.1400, Initial Validation Loss: 0.1338, Validation Loss: 0.1338,V Acc: 0.2909, Top 70th Acc: 0.3506, Bottom 30th Acc: 0.1515
Fold [3/5] Epoch [10/100] Initial Loss: 0.1400, Training Loss: 0.0154, Initial Validation Loss: 0.1338, Validation Loss: 0.0354,V Acc: 0.7909, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.4545
Fold [3/5] Epoch [20/100] Initial Loss: 0.1400, Training Loss: 0.0050, Initial Validation Loss: 0.1338, Validation Loss: 0.0318,V Acc: 0.8364, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.9090909090909091
31 2 [array([0.23635575, 0.08755855, 0.07615173, 0.12860252, 0.47133145],
      dtype=float32)]
Fold [4/5] Epoch [0/100] Initial Loss: 0.1387, Training Loss: 0.1387, Initial Validation Loss: 0.1370, Validation Loss: 0.1370,V Acc: 0.2661, Top 70th Acc: 0.3247, Bottom 30th Acc: 0.1250
Fold [4/5] Epoch [10/100] Initial Loss: 0.1387, Training Loss: 0.0181, Initial Validation Loss: 0.1370, Validation Loss: 0.0326,V Acc: 0.8532, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.5625
Fold [4/5] Epoch [20/100] Initial Loss: 0.1387, Training Loss: 0.0055, Initial Validation Loss: 0.1370, Validation Loss: 0.0261,V Acc: 0.8807, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.6562
Fold [4/5] Epoch [30/100] Initial Loss: 0.1387, Training Loss: 0.0043, Initial Validation Loss: 0.1370, Validation Loss: 0.0242,V Acc: 0.8807, Top 70th Acc: 0.9870, Bottom 30th Acc: 0.6250
Fold [4/5] Epoch [40/100] Initial Loss: 0.1387, Training Loss: 0.0041, Initial Validation Loss: 0.1370, Validation Loss: 0.0236,V Acc: 0.8899, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.6875
Fold [4/5] Epoch [50/100] Initial Loss: 0.1387, Training Loss: 0.0039, Initial Validation Loss: 0.1370, Validation Loss: 0.0235,V Acc: 0.8807, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.6562
Fold [4/5] Epoch [60/100] Initial Loss: 0.1387, Training Loss: 0.0038, Initial Validation Loss: 0.1370, Validation Loss: 0.0233,V Acc: 0.8899, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.6875
Fold [4/5] Epoch [70/100] Initial Loss: 0.1387, Training Loss: 0.0038, Initial Validation Loss: 0.1370, Validation Loss: 0.0229,V Acc: 0.8899, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.6875
Fold [4/5] Epoch [80/100] Initial Loss: 0.1387, Training Loss: 0.0037, Initial Validation Loss: 0.1370, Validation Loss: 0.0228,V Acc: 0.8716, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.6250
Stopping early at Epoch (base 0): 89  Rolling back to Epoch (base 0): 84  Top Validation Acc: 0.974025974025974
Fold [5/5] Epoch [0/100] Initial Loss: 0.1390, Training Loss: 0.1390, Initial Validation Loss: 0.1319, Validation Loss: 0.1319,V Acc: 0.2870, Top 70th Acc: 0.3684, Bottom 30th Acc: 0.0938
Fold [5/5] Epoch [10/100] Initial Loss: 0.1390, Training Loss: 0.0160, Initial Validation Loss: 0.1319, Validation Loss: 0.0265,V Acc: 0.8889, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.7188
Stopping early at Epoch (base 0): 18  Rolling back to Epoch (base 0): 13  Top Validation Acc: 0.9605263157894737
Running train_nn.py with seed 32
CUDA:False
Training samples count:  550
Training on 162 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1403, Training Loss: 0.1403, Initial Validation Loss: 0.1327, Validation Loss: 0.1327,V Acc: 0.3482, Top 70th Acc: 0.4177, Bottom 30th Acc: 0.1818
Fold [1/5] Epoch [10/100] Initial Loss: 0.1403, Training Loss: 0.0235, Initial Validation Loss: 0.1327, Validation Loss: 0.0392,V Acc: 0.7946, Top 70th Acc: 0.9241, Bottom 30th Acc: 0.4848
Fold [1/5] Epoch [20/100] Initial Loss: 0.1403, Training Loss: 0.0055, Initial Validation Loss: 0.1327, Validation Loss: 0.0307,V Acc: 0.8304, Top 70th Acc: 0.9367, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 28  Rolling back to Epoch (base 0): 23  Top Validation Acc: 0.9367088607594937
Fold [2/5] Epoch [0/100] Initial Loss: 0.1385, Training Loss: 0.1385, Initial Validation Loss: 0.1375, Validation Loss: 0.1375,V Acc: 0.2613, Top 70th Acc: 0.3333, Bottom 30th Acc: 0.0909
Fold [2/5] Epoch [10/100] Initial Loss: 0.1385, Training Loss: 0.0144, Initial Validation Loss: 0.1375, Validation Loss: 0.0343,V Acc: 0.8649, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.6970
Fold [2/5] Epoch [20/100] Initial Loss: 0.1385, Training Loss: 0.0048, Initial Validation Loss: 0.1375, Validation Loss: 0.0286,V Acc: 0.8649, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 29  Rolling back to Epoch (base 0): 24  Top Validation Acc: 0.9743589743589743
Fold [3/5] Epoch [0/100] Initial Loss: 0.1405, Training Loss: 0.1405, Initial Validation Loss: 0.1327, Validation Loss: 0.1327,V Acc: 0.2636, Top 70th Acc: 0.3247, Bottom 30th Acc: 0.1212
Fold [3/5] Epoch [10/100] Initial Loss: 0.1405, Training Loss: 0.0198, Initial Validation Loss: 0.1327, Validation Loss: 0.0378,V Acc: 0.8182, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.5455
Fold [3/5] Epoch [20/100] Initial Loss: 0.1405, Training Loss: 0.0058, Initial Validation Loss: 0.1327, Validation Loss: 0.0308,V Acc: 0.8364, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.5758
Fold [3/5] Epoch [30/100] Initial Loss: 0.1405, Training Loss: 0.0043, Initial Validation Loss: 0.1327, Validation Loss: 0.0287,V Acc: 0.8455, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6061
Fold [3/5] Epoch [20/100] Initial Loss: 0.1334, Training Loss: 0.0147, Initial Validation Loss: 0.1177, Validation Loss: 0.0295,V Acc: 0.8545, Top 70th Acc: 0.9870, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 22  Rolling back to Epoch (base 0): 17  Top Validation Acc: 0.948051948051948
Fold [4/5] Epoch [0/100] Initial Loss: 0.1374, Training Loss: 0.1374, Initial Validation Loss: 0.1201, Validation Loss: 0.1201,V Acc: 0.4495, Top 70th Acc: 0.5974, Bottom 30th Acc: 0.0938
Fold [4/5] Epoch [10/100] Initial Loss: 0.1374, Training Loss: 0.0222, Initial Validation Loss: 0.1201, Validation Loss: 0.0233,V Acc: 0.8807, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.6562
Stopping early at Epoch (base 0): 13  Rolling back to Epoch (base 0): 8  Top Validation Acc: 0.961038961038961
Fold [5/5] Epoch [0/100] Initial Loss: 0.1348, Training Loss: 0.1348, Initial Validation Loss: 0.1241, Validation Loss: 0.1241,V Acc: 0.4815, Top 70th Acc: 0.5526, Bottom 30th Acc: 0.3125
Fold [5/5] Epoch [10/100] Initial Loss: 0.1348, Training Loss: 0.0195, Initial Validation Loss: 0.1241, Validation Loss: 0.0296,V Acc: 0.8889, Top 70th Acc: 0.9737, Bottom 30th Acc: 0.6875
Fold [5/5] Epoch [20/100] Initial Loss: 0.1348, Training Loss: 0.0141, Initial Validation Loss: 0.1241, Validation Loss: 0.0292,V Acc: 0.8611, Top 70th Acc: 0.9737, Bottom 30th Acc: 0.5938
Fold [5/5] Epoch [30/100] Initial Loss: 0.1348, Training Loss: 0.0122, Initial Validation Loss: 0.1241, Validation Loss: 0.0304,V Acc: 0.8889, Top 70th Acc: 0.9737, Bottom 30th Acc: 0.6875
Stopping early at Epoch (base 0): 32  Rolling back to Epoch (base 0): 27  Top Validation Acc: 0.9868421052631579
55 4 [array([0.7471619 , 0.02685279, 0.01858967, 0.07282899, 0.13456659],
      dtype=float32)]
Running train_nn.py with seed 56
CUDA:False
Training samples count:  550
Training on 21 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1295, Training Loss: 0.1295, Initial Validation Loss: 0.1136, Validation Loss: 0.1136,V Acc: 0.5446, Top 70th Acc: 0.6076, Bottom 30th Acc: 0.3939
Fold [1/5] Epoch [10/100] Initial Loss: 0.1295, Training Loss: 0.0240, Initial Validation Loss: 0.1136, Validation Loss: 0.0266,V Acc: 0.8393, Top 70th Acc: 0.9747, Bottom 30th Acc: 0.5152
Fold [1/5] Epoch [20/100] Initial Loss: 0.1295, Training Loss: 0.0160, Initial Validation Loss: 0.1136, Validation Loss: 0.0221,V Acc: 0.8571, Top 70th Acc: 0.9747, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 27  Rolling back to Epoch (base 0): 22  Top Validation Acc: 0.9873417721518988
Fold [2/5] Epoch [0/100] Initial Loss: 0.1341, Training Loss: 0.1341, Initial Validation Loss: 0.1207, Validation Loss: 0.1207,V Acc: 0.5045, Top 70th Acc: 0.6410, Bottom 30th Acc: 0.1818
Fold [2/5] Epoch [10/100] Initial Loss: 0.1341, Training Loss: 0.0213, Initial Validation Loss: 0.1207, Validation Loss: 0.0219,V Acc: 0.9099, Top 70th Acc: 0.9872, Bottom 30th Acc: 0.7273
Stopping early at Epoch (base 0): 18  Rolling back to Epoch (base 0): 13  Top Validation Acc: 0.9871794871794872
Fold [3/5] Epoch [0/100] Initial Loss: 0.1367, Training Loss: 0.1367, Initial Validation Loss: 0.1263, Validation Loss: 0.1263,V Acc: 0.5455, Top 70th Acc: 0.6623, Bottom 30th Acc: 0.2727
Fold [3/5] Epoch [10/100] Initial Loss: 0.1367, Training Loss: 0.0229, Initial Validation Loss: 0.1263, Validation Loss: 0.0309,V Acc: 0.8364, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.5152
Fold [3/5] Epoch [20/100] Initial Loss: 0.1367, Training Loss: 0.0159, Initial Validation Loss: 0.1263, Validation Loss: 0.0339,V Acc: 0.8273, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 29  Rolling back to Epoch (base 0): 24  Top Validation Acc: 0.935064935064935
Fold [4/5] Epoch [0/100] Initial Loss: 0.1314, Training Loss: 0.1314, Initial Validation Loss: 0.1219, Validation Loss: 0.1219,V Acc: 0.4495, Top 70th Acc: 0.5584, Bottom 30th Acc: 0.1875
Fold [4/5] Epoch [10/100] Initial Loss: 0.1314, Training Loss: 0.0230, Initial Validation Loss: 0.1219, Validation Loss: 0.0326,V Acc: 0.8899, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.7500
Stopping early at Epoch (base 0): 16  Rolling back to Epoch (base 0): 11  Top Validation Acc: 0.961038961038961
56 3 [array([0.7378984 , 0.01424194, 0.0260942 , 0.10038889, 0.12137654],
      dtype=float32)]
Fold [5/5] Epoch [0/100] Initial Loss: 0.1405, Training Loss: 0.1405, Initial Validation Loss: 0.1282, Validation Loss: 0.1282,V Acc: 0.4167, Top 70th Acc: 0.5263, Bottom 30th Acc: 0.1562
Fold [5/5] Epoch [10/100] Initial Loss: 0.1405, Training Loss: 0.0241, Initial Validation Loss: 0.1282, Validation Loss: 0.0350,V Acc: 0.8333, Top 70th Acc: 0.9079, Bottom 30th Acc: 0.6562
Stopping early at Epoch (base 0): 19  Rolling back to Epoch (base 0): 14  Top Validation Acc: 0.9473684210526315
Running train_nn.py with seed 57
CUDA:False
Training samples count:  550
Training on 21 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1376, Training Loss: 0.1376, Initial Validation Loss: 0.1277, Validation Loss: 0.1277,V Acc: 0.3929, Top 70th Acc: 0.5190, Bottom 30th Acc: 0.0909
Fold [1/5] Epoch [10/100] Initial Loss: 0.1376, Training Loss: 0.0214, Initial Validation Loss: 0.1277, Validation Loss: 0.0284,V Acc: 0.8661, Top 70th Acc: 0.9367, Bottom 30th Acc: 0.6970
Fold [1/5] Epoch [20/100] Initial Loss: 0.1376, Training Loss: 0.0145, Initial Validation Loss: 0.1277, Validation Loss: 0.0273,V Acc: 0.8304, Top 70th Acc: 0.9747, Bottom 30th Acc: 0.4848
Stopping early at Epoch (base 0): 20  Rolling back to Epoch (base 0): 15  Top Validation Acc: 0.9746835443037974
Fold [2/5] Epoch [0/100] Initial Loss: 0.1347, Training Loss: 0.1347, Initial Validation Loss: 0.1266, Validation Loss: 0.1266,V Acc: 0.3333, Top 70th Acc: 0.3974, Bottom 30th Acc: 0.1818
Fold [2/5] Epoch [10/100] Initial Loss: 0.1347, Training Loss: 0.0191, Initial Validation Loss: 0.1266, Validation Loss: 0.0280,V Acc: 0.8739, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.6364
Fold [2/5] Epoch [20/100] Initial Loss: 0.1347, Training Loss: 0.0136, Initial Validation Loss: 0.1266, Validation Loss: 0.0259,V Acc: 0.9009, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.7576
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.9615384615384616
Fold [3/5] Epoch [0/100] Initial Loss: 0.1408, Training Loss: 0.1408, Initial Validation Loss: 0.1304, Validation Loss: 0.1304,V Acc: 0.3000, Top 70th Acc: 0.3377, Bottom 30th Acc: 0.2121
Fold [3/5] Epoch [10/100] Initial Loss: 0.1408, Training Loss: 0.0238, Initial Validation Loss: 0.1304, Validation Loss: 0.0280,V Acc: 0.8636, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.7273
Fold [3/5] Epoch [20/100] Initial Loss: 0.1408, Training Loss: 0.0171, Initial Validation Loss: 0.1304, Validation Loss: 0.0264,V Acc: 0.8636, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 21  Rolling back to Epoch (base 0): 16  Top Validation Acc: 0.935064935064935
57 2 [array([0.744367  , 0.01943189, 0.0427206 , 0.09051163, 0.10296891],
      dtype=float32)]
Fold [4/5] Epoch [0/100] Initial Loss: 0.1311, Training Loss: 0.1311, Initial Validation Loss: 0.1163, Validation Loss: 0.1163,V Acc: 0.5138, Top 70th Acc: 0.6494, Bottom 30th Acc: 0.1875
Fold [4/5] Epoch [10/100] Initial Loss: 0.1311, Training Loss: 0.0213, Initial Validation Loss: 0.1163, Validation Loss: 0.0246,V Acc: 0.8624, Top 70th Acc: 1.0000, Bottom 30th Acc: 0.5312
Stopping early at Epoch (base 0): 19  Rolling back to Epoch (base 0): 14  Top Validation Acc: 0.961038961038961
Fold [5/5] Epoch [0/100] Initial Loss: 0.1360, Training Loss: 0.1360, Initial Validation Loss: 0.1266, Validation Loss: 0.1266,V Acc: 0.5370, Top 70th Acc: 0.6579, Bottom 30th Acc: 0.2500
Fold [5/5] Epoch [10/100] Initial Loss: 0.1360, Training Loss: 0.0333, Initial Validation Loss: 0.1266, Validation Loss: 0.0340,V Acc: 0.8796, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.7500
Fold [5/5] Epoch [20/100] Initial Loss: 0.1360, Training Loss: 0.0166, Initial Validation Loss: 0.1266, Validation Loss: 0.0263,V Acc: 0.8981, Top 70th Acc: 0.9737, Bottom 30th Acc: 0.7188
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.9868421052631579
Running train_nn.py with seed 58
Training on 162 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 90
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 162 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 91
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 162 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 92
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 162 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 93
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 162 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 94
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 162 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 95
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 162 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 96
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 162 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 97
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 162 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 98
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 162 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 99
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 162 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 100
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 162 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5

Fold [5/5] Epoch [20/100] Initial Loss: 0.1401, Training Loss: 0.0135, Initial Validation Loss: 0.1272, Validation Loss: 0.0325,V Acc: 0.8241, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.5000
Stopping early at Epoch (base 0): 21  Rolling back to Epoch (base 0): 16  Top Validation Acc: 0.9605263157894737
42 4 [array([0.5346791 , 0.08674808, 0.12354749, 0.05919367, 0.19583173],
      dtype=float32)]
Running train_nn.py with seed 43
CUDA:False
Training samples count:  550
Training on 40 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1425, Training Loss: 0.1425, Initial Validation Loss: 0.1358, Validation Loss: 0.1358,V Acc: 0.2679, Top 70th Acc: 0.3291, Bottom 30th Acc: 0.1212
Fold [1/5] Epoch [10/100] Initial Loss: 0.1425, Training Loss: 0.0392, Initial Validation Loss: 0.1358, Validation Loss: 0.0493,V Acc: 0.7768, Top 70th Acc: 0.8608, Bottom 30th Acc: 0.5758
Fold [1/5] Epoch [20/100] Initial Loss: 0.1425, Training Loss: 0.0174, Initial Validation Loss: 0.1358, Validation Loss: 0.0348,V Acc: 0.8125, Top 70th Acc: 0.9241, Bottom 30th Acc: 0.5455
Fold [1/5] Epoch [30/100] Initial Loss: 0.1425, Training Loss: 0.0123, Initial Validation Loss: 0.1358, Validation Loss: 0.0306,V Acc: 0.8393, Top 70th Acc: 0.9494, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 39  Rolling back to Epoch (base 0): 34  Top Validation Acc: 0.9367088607594937
Fold [2/5] Epoch [0/100] Initial Loss: 0.1420, Training Loss: 0.1420, Initial Validation Loss: 0.1331, Validation Loss: 0.1331,V Acc: 0.4054, Top 70th Acc: 0.5000, Bottom 30th Acc: 0.1818
Fold [2/5] Epoch [10/100] Initial Loss: 0.1420, Training Loss: 0.0239, Initial Validation Loss: 0.1331, Validation Loss: 0.0360,V Acc: 0.7748, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.3939
Fold [2/5] Epoch [20/100] Initial Loss: 0.1420, Training Loss: 0.0136, Initial Validation Loss: 0.1331, Validation Loss: 0.0320,V Acc: 0.7838, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.3939
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.9615384615384616
43 1 [array([0.5538147 , 0.0400965 , 0.06827256, 0.07093118, 0.26688492],
      dtype=float32)]
Fold [3/5] Epoch [0/100] Initial Loss: 0.1374, Training Loss: 0.1374, Initial Validation Loss: 0.1346, Validation Loss: 0.1346,V Acc: 0.2727, Top 70th Acc: 0.3636, Bottom 30th Acc: 0.0606
Fold [3/5] Epoch [10/100] Initial Loss: 0.1374, Training Loss: 0.0226, Initial Validation Loss: 0.1346, Validation Loss: 0.0319,V Acc: 0.8545, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6364
Fold [3/5] Epoch [20/100] Initial Loss: 0.1374, Training Loss: 0.0132, Initial Validation Loss: 0.1346, Validation Loss: 0.0296,V Acc: 0.8545, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 21  Rolling back to Epoch (base 0): 16  Top Validation Acc: 0.974025974025974
Fold [4/5] Epoch [0/100] Initial Loss: 0.1397, Training Loss: 0.1397, Initial Validation Loss: 0.1363, Validation Loss: 0.1363,V Acc: 0.2569, Top 70th Acc: 0.2857, Bottom 30th Acc: 0.1875
Fold [4/5] Epoch [10/100] Initial Loss: 0.1397, Training Loss: 0.0282, Initial Validation Loss: 0.1363, Validation Loss: 0.0290,V Acc: 0.8899, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.6875
Fold [4/5] Epoch [20/100] Initial Loss: 0.1397, Training Loss: 0.0150, Initial Validation Loss: 0.1363, Validation Loss: 0.0257,V Acc: 0.8899, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.7188
Stopping early at Epoch (base 0): 21  Rolling back to Epoch (base 0): 16  Top Validation Acc: 0.961038961038961
Fold [5/5] Epoch [0/100] Initial Loss: 0.1393, Training Loss: 0.1393, Initial Validation Loss: 0.1291, Validation Loss: 0.1291,V Acc: 0.2778, Top 70th Acc: 0.3289, Bottom 30th Acc: 0.1562
Fold [5/5] Epoch [10/100] Initial Loss: 0.1393, Training Loss: 0.0400, Initial Validation Loss: 0.1291, Validation Loss: 0.0459,V Acc: 0.7778, Top 70th Acc: 0.8553, Bottom 30th Acc: 0.5938
Fold [5/5] Epoch [20/100] Initial Loss: 0.1393, Training Loss: 0.0246, Initial Validation Loss: 0.1291, Validation Loss: 0.0368,V Acc: 0.8148, Top 70th Acc: 0.8816, Bottom 30th Acc: 0.6562
Fold [5/5] Epoch [30/100] Initial Loss: 0.1393, Training Loss: 0.0186, Initial Validation Loss: 0.1291, Validation Loss: 0.0358,V Acc: 0.8056, Top 70th Acc: 0.8947, Bottom 30th Acc: 0.5938
Stopping early at Epoch (base 0): 37  Rolling back to Epoch (base 0): 32  Top Validation Acc: 0.8947368421052632
Running train_nn.py with seed 44
CUDA:False
Training samples count:  550
Training on 40 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1391, Training Loss: 0.1391, Initial Validation Loss: 0.1356, Validation Loss: 0.1356,V Acc: 0.3839, Top 70th Acc: 0.4304, Bottom 30th Acc: 0.2727
Fold [1/5] Epoch [10/100] Initial Loss: 0.1391, Training Loss: 0.0335, Initial Validation Loss: 0.1356, Validation Loss: 0.0372,V Acc: 0.8482, Top 70th Acc: 0.9241, Bottom 30th Acc: 0.6667
Fold [1/5] Epoch [20/100] Initial Loss: 0.1391, Training Loss: 0.0150, Initial Validation Loss: 0.1356, Validation Loss: 0.0307,V Acc: 0.8482, Top 70th Acc: 0.9367, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 21  Rolling back to Epoch (base 0): 16  Top Validation Acc: 0.9493670886075949
44 0 [array([0.46709132, 0.0816647 , 0.15471926, 0.12905774, 0.16746706],
      dtype=float32)]
Fold [2/5] Epoch [0/100] Initial Loss: 0.1394, Training Loss: 0.1394, Initial Validation Loss: 0.1397, Validation Loss: 0.1397,V Acc: 0.3243, Top 70th Acc: 0.3462, Bottom 30th Acc: 0.2727
Fold [2/5] Epoch [10/100] Initial Loss: 0.1394, Training Loss: 0.0292, Initial Validation Loss: 0.1397, Validation Loss: 0.0313,V Acc: 0.8739, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.6667
Fold [2/5] Epoch [20/100] Initial Loss: 0.1394, Training Loss: 0.0161, Initial Validation Loss: 0.1397, Validation Loss: 0.0232,V Acc: 0.9099, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.7576
Fold [2/5] Epoch [30/100] Initial Loss: 0.1394, Training Loss: 0.0137, Initial Validation Loss: 0.1397, Validation Loss: 0.0220,V Acc: 0.8829, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 30  Rolling back to Epoch (base 0): 25  Top Validation Acc: 0.9743589743589743
Fold [3/5] Epoch [0/100] Initial Loss: 0.1405, Training Loss: 0.1405, Initial Validation Loss: 0.1345, Validation Loss: 0.1345,V Acc: 0.3182, Top 70th Acc: 0.3766, Bottom 30th Acc: 0.1818
Fold [3/5] Epoch [10/100] Initial Loss: 0.1405, Training Loss: 0.0404, Initial Validation Loss: 0.1345, Validation Loss: 0.0504,V Acc: 0.7455, Top 70th Acc: 0.8701, Bottom 30th Acc: 0.4545
Fold [3/5] Epoch [20/100] Initial Loss: 0.1405, Training Loss: 0.0142, Initial Validation Loss: 0.1345, Validation Loss: 0.0395,V Acc: 0.8000, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.935064935064935
Fold [4/5] Epoch [0/100] Initial Loss: 0.1429, Training Loss: 0.1429, Initial Validation Loss: 0.1282, Validation Loss: 0.1282,V Acc: 0.4037, Top 70th Acc: 0.4935, Bottom 30th Acc: 0.1875
Fold [4/5] Epoch [10/100] Initial Loss: 0.1429, Training Loss: 0.0335, Initial Validation Loss: 0.1282, Validation Loss: 0.0421,V Acc: 0.7982, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.5312
Fold [4/5] Epoch [20/100] Initial Loss: 0.1429, Training Loss: 0.0139, Initial Validation Loss: 0.1282, Validation Loss: 0.0326,V Acc: 0.8073, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.4375
Fold [4/5] Epoch [30/100] Initial Loss: 0.1429, Training Loss: 0.0115, Initial Validation Loss: 0.1282, Validation Loss: 0.0315,V Acc: 0.8165, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.4375
Stopping early at Epoch (base 0): 37  Rolling back to Epoch (base 0): 32  Top Validation Acc: 0.961038961038961
Fold [5/5] Epoch [0/100] Initial Loss: 0.1384, Training Loss: 0.1384, Initial Validation Loss: 0.1313, Validation Loss: 0.1313,V Acc: 0.2593, Top 70th Acc: 0.2632, Bottom 30th Acc: 0.2500
Fold [5/5] Epoch [10/100] Initial Loss: 0.1384, Training Loss: 0.0256, Initial Validation Loss: 0.1313, Validation Loss: 0.0378,V Acc: 0.8056, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.5000
Fold [5/5] Epoch [20/100] Initial Loss: 0.1384, Training Loss: 0.0133, Initial Validation Loss: 0.1313, Validation Loss: 0.0339,V Acc: 0.8519, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.6562
Fold [4/5] Epoch [20/100] Initial Loss: 0.1428, Training Loss: 0.0229, Initial Validation Loss: 0.1286, Validation Loss: 0.0355,V Acc: 0.7890, Top 70th Acc: 0.8961, Bottom 30th Acc: 0.5312
Stopping early at Epoch (base 0): 21  Rolling back to Epoch (base 0): 16  Top Validation Acc: 0.8831168831168831
Fold [5/5] Epoch [0/100] Initial Loss: 0.1364, Training Loss: 0.1364, Initial Validation Loss: 0.1308, Validation Loss: 0.1308,V Acc: 0.4444, Top 70th Acc: 0.5263, Bottom 30th Acc: 0.2500
Fold [5/5] Epoch [10/100] Initial Loss: 0.1364, Training Loss: 0.0314, Initial Validation Loss: 0.1308, Validation Loss: 0.0326,V Acc: 0.8889, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.7188
Fold [5/5] Epoch [20/100] Initial Loss: 0.1364, Training Loss: 0.0232, Initial Validation Loss: 0.1308, Validation Loss: 0.0287,V Acc: 0.8796, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.7188
Fold [5/5] Epoch [30/100] Initial Loss: 0.1364, Training Loss: 0.0211, Initial Validation Loss: 0.1308, Validation Loss: 0.0271,V Acc: 0.8889, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.7500
Stopping early at Epoch (base 0): 31  Rolling back to Epoch (base 0): 26  Top Validation Acc: 0.9473684210526315
Running train_nn.py with seed 41
CUDA:False
Training samples count:  550
Training on 20 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1393, Training Loss: 0.1393, Initial Validation Loss: 0.1381, Validation Loss: 0.1381,V Acc: 0.2589, Top 70th Acc: 0.3418, Bottom 30th Acc: 0.0606
Fold [1/5] Epoch [10/100] Initial Loss: 0.1393, Training Loss: 0.0300, Initial Validation Loss: 0.1381, Validation Loss: 0.0417,V Acc: 0.8036, Top 70th Acc: 0.9367, Bottom 30th Acc: 0.4848
Fold [1/5] Epoch [20/100] Initial Loss: 0.1393, Training Loss: 0.0223, Initial Validation Loss: 0.1381, Validation Loss: 0.0386,V Acc: 0.8214, Top 70th Acc: 0.9114, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 29  Rolling back to Epoch (base 0): 24  Top Validation Acc: 0.9113924050632911
Fold [2/5] Epoch [0/100] Initial Loss: 0.1386, Training Loss: 0.1386, Initial Validation Loss: 0.1322, Validation Loss: 0.1322,V Acc: 0.2973, Top 70th Acc: 0.3205, Bottom 30th Acc: 0.2424
Fold [2/5] Epoch [10/100] Initial Loss: 0.1386, Training Loss: 0.0371, Initial Validation Loss: 0.1322, Validation Loss: 0.0421,V Acc: 0.8198, Top 70th Acc: 0.8718, Bottom 30th Acc: 0.6970
Fold [2/5] Epoch [20/100] Initial Loss: 0.1386, Training Loss: 0.0227, Initial Validation Loss: 0.1322, Validation Loss: 0.0339,V Acc: 0.8198, Top 70th Acc: 0.8974, Bottom 30th Acc: 0.6364
Fold [2/5] Epoch [30/100] Initial Loss: 0.1386, Training Loss: 0.0200, Initial Validation Loss: 0.1322, Validation Loss: 0.0343,V Acc: 0.8108, Top 70th Acc: 0.8846, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 30  Rolling back to Epoch (base 0): 25  Top Validation Acc: 0.8846153846153846
Fold [3/5] Epoch [0/100] Initial Loss: 0.1408, Training Loss: 0.1408, Initial Validation Loss: 0.1323, Validation Loss: 0.1323,V Acc: 0.3000, Top 70th Acc: 0.3766, Bottom 30th Acc: 0.1212
Fold [3/5] Epoch [10/100] Initial Loss: 0.1408, Training Loss: 0.0488, Initial Validation Loss: 0.1323, Validation Loss: 0.0452,V Acc: 0.7455, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.3636
Fold [3/5] Epoch [20/100] Initial Loss: 0.1408, Training Loss: 0.0341, Initial Validation Loss: 0.1323, Validation Loss: 0.0339,V Acc: 0.8273, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.5758
Fold [3/5] Epoch [30/100] Initial Loss: 0.1408, Training Loss: 0.0239, Initial Validation Loss: 0.1323, Validation Loss: 0.0298,V Acc: 0.8455, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 37  Rolling back to Epoch (base 0): 32  Top Validation Acc: 0.961038961038961
41 2 [array([0.36570117, 0.06423733, 0.06096528, 0.2658976 , 0.2431986 ],
      dtype=float32)]
Fold [4/5] Epoch [0/100] Initial Loss: 0.1403, Training Loss: 0.1403, Initial Validation Loss: 0.1289, Validation Loss: 0.1289,V Acc: 0.2569, Top 70th Acc: 0.3247, Bottom 30th Acc: 0.0938
Fold [4/5] Epoch [10/100] Initial Loss: 0.1403, Training Loss: 0.0398, Initial Validation Loss: 0.1289, Validation Loss: 0.0406,V Acc: 0.8440, Top 70th Acc: 0.8961, Bottom 30th Acc: 0.7188
Fold [4/5] Epoch [20/100] Initial Loss: 0.1403, Training Loss: 0.0249, Initial Validation Loss: 0.1289, Validation Loss: 0.0328,V Acc: 0.8440, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.5938
Stopping early at Epoch (base 0): 29  Rolling back to Epoch (base 0): 24  Top Validation Acc: 0.922077922077922
Fold [5/5] Epoch [0/100] Initial Loss: 0.1376, Training Loss: 0.1376, Initial Validation Loss: 0.1344, Validation Loss: 0.1344,V Acc: 0.4630, Top 70th Acc: 0.5526, Bottom 30th Acc: 0.2500
Fold [5/5] Epoch [10/100] Initial Loss: 0.1376, Training Loss: 0.0338, Initial Validation Loss: 0.1344, Validation Loss: 0.0384,V Acc: 0.8519, Top 70th Acc: 0.8947, Bottom 30th Acc: 0.7500
Fold [5/5] Epoch [20/100] Initial Loss: 0.1376, Training Loss: 0.0233, Initial Validation Loss: 0.1344, Validation Loss: 0.0318,V Acc: 0.8519, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.5938
Fold [5/5] Epoch [30/100] Initial Loss: 0.1376, Training Loss: 0.0214, Initial Validation Loss: 0.1344, Validation Loss: 0.0301,V Acc: 0.8704, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.6875
Stopping early at Epoch (base 0): 33  Rolling back to Epoch (base 0): 28  Top Validation Acc: 0.9342105263157895
Running train_nn.py with seed 42
CUDA:False
Training samples count:  550
Training on 20 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1421, Training Loss: 0.1421, Initial Validation Loss: 0.1335, Validation Loss: 0.1335,V Acc: 0.3839, Top 70th Acc: 0.4810, Bottom 30th Acc: 0.1515
Fold [1/5] Epoch [10/100] Initial Loss: 0.1421, Training Loss: 0.0421, Initial Validation Loss: 0.1335, Validation Loss: 0.0497,V Acc: 0.7857, Top 70th Acc: 0.8354, Bottom 30th Acc: 0.6667
Fold [1/5] Epoch [20/100] Initial Loss: 0.1421, Training Loss: 0.0239, Initial Validation Loss: 0.1335, Validation Loss: 0.0397,V Acc: 0.8214, Top 70th Acc: 0.8734, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.8987341772151899
Fold [2/5] Epoch [0/100] Initial Loss: 0.1358, Training Loss: 0.1358, Initial Validation Loss: 0.1326, Validation Loss: 0.1326,V Acc: 0.3514, Top 70th Acc: 0.3718, Bottom 30th Acc: 0.3030
Fold [2/5] Epoch [10/100] Initial Loss: 0.1358, Training Loss: 0.0414, Initial Validation Loss: 0.1326, Validation Loss: 0.0499,V Acc: 0.7838, Top 70th Acc: 0.8846, Bottom 30th Acc: 0.5455
Fold [2/5] Epoch [20/100] Initial Loss: 0.1358, Training Loss: 0.0242, Initial Validation Loss: 0.1326, Validation Loss: 0.0393,V Acc: 0.7928, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.4848
Fold [2/5] Epoch [30/100] Initial Loss: 0.1358, Training Loss: 0.0216, Initial Validation Loss: 0.1326, Validation Loss: 0.0391,V Acc: 0.7838, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.4545
Stopping early at Epoch (base 0): 32  Rolling back to Epoch (base 0): 27  Top Validation Acc: 0.9230769230769231
Fold [3/5] Epoch [0/100] Initial Loss: 0.1359, Training Loss: 0.1359, Initial Validation Loss: 0.1327, Validation Loss: 0.1327,V Acc: 0.3364, Top 70th Acc: 0.3506, Bottom 30th Acc: 0.3030
Fold [3/5] Epoch [10/100] Initial Loss: 0.1359, Training Loss: 0.0429, Initial Validation Loss: 0.1327, Validation Loss: 0.0473,V Acc: 0.7636, Top 70th Acc: 0.8961, Bottom 30th Acc: 0.4545
Fold [3/5] Epoch [20/100] Initial Loss: 0.1359, Training Loss: 0.0255, Initial Validation Loss: 0.1327, Validation Loss: 0.0332,V Acc: 0.8545, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.6667
Fold [3/5] Epoch [30/100] Initial Loss: 0.1359, Training Loss: 0.0224, Initial Validation Loss: 0.1327, Validation Loss: 0.0341,V Acc: 0.8455, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 32  Rolling back to Epoch (base 0): 27  Top Validation Acc: 0.935064935064935
Fold [4/5] Epoch [0/100] Initial Loss: 0.1402, Training Loss: 0.1402, Initial Validation Loss: 0.1316, Validation Loss: 0.1316,V Acc: 0.2294, Top 70th Acc: 0.3117, Bottom 30th Acc: 0.0312
Fold [4/5] Epoch [10/100] Initial Loss: 0.1402, Training Loss: 0.0340, Initial Validation Loss: 0.1316, Validation Loss: 0.0324,V Acc: 0.8532, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.6562
Fold [4/5] Epoch [30/100] Initial Loss: 0.1431, Training Loss: 0.0779, Initial Validation Loss: 0.1259, Validation Loss: 0.0756,V Acc: 0.6239, Top 70th Acc: 0.7403, Bottom 30th Acc: 0.3438
Stopping early at Epoch (base 0): 36  Rolling back to Epoch (base 0): 31  Top Validation Acc: 0.7402597402597403
Fold [5/5] Epoch [0/100] Initial Loss: 0.1334, Training Loss: 0.1334, Initial Validation Loss: 0.1257, Validation Loss: 0.1257,V Acc: 0.4352, Top 70th Acc: 0.5000, Bottom 30th Acc: 0.2812
Fold [5/5] Epoch [10/100] Initial Loss: 0.1334, Training Loss: 0.0788, Initial Validation Loss: 0.1257, Validation Loss: 0.0791,V Acc: 0.6389, Top 70th Acc: 0.7632, Bottom 30th Acc: 0.3438
Fold [5/5] Epoch [20/100] Initial Loss: 0.1334, Training Loss: 0.0768, Initial Validation Loss: 0.1257, Validation Loss: 0.0787,V Acc: 0.6296, Top 70th Acc: 0.7632, Bottom 30th Acc: 0.3125
Stopping early at Epoch (base 0): 21  Rolling back to Epoch (base 0): 16  Top Validation Acc: 0.7631578947368421
Running train_nn.py with seed 41
CUDA:False
Training samples count:  550
Training on 2 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1322, Training Loss: 0.1322, Initial Validation Loss: 0.1279, Validation Loss: 0.1279,V Acc: 0.3661, Top 70th Acc: 0.4557, Bottom 30th Acc: 0.1515
Fold [1/5] Epoch [10/100] Initial Loss: 0.1322, Training Loss: 0.0785, Initial Validation Loss: 0.1279, Validation Loss: 0.0887,V Acc: 0.5804, Top 70th Acc: 0.7468, Bottom 30th Acc: 0.1818
Fold [1/5] Epoch [20/100] Initial Loss: 0.1322, Training Loss: 0.0771, Initial Validation Loss: 0.1279, Validation Loss: 0.0883,V Acc: 0.5982, Top 70th Acc: 0.7089, Bottom 30th Acc: 0.3333
Fold [1/5] Epoch [30/100] Initial Loss: 0.1322, Training Loss: 0.0767, Initial Validation Loss: 0.1279, Validation Loss: 0.0869,V Acc: 0.6161, Top 70th Acc: 0.7468, Bottom 30th Acc: 0.3030
Stopping early at Epoch (base 0): 30  Rolling back to Epoch (base 0): 25  Top Validation Acc: 0.7468354430379747
Fold [2/5] Epoch [0/100] Initial Loss: 0.1348, Training Loss: 0.1348, Initial Validation Loss: 0.1240, Validation Loss: 0.1240,V Acc: 0.4955, Top 70th Acc: 0.6026, Bottom 30th Acc: 0.2424
Fold [2/5] Epoch [10/100] Initial Loss: 0.1348, Training Loss: 0.0811, Initial Validation Loss: 0.1240, Validation Loss: 0.0770,V Acc: 0.6486, Top 70th Acc: 0.7692, Bottom 30th Acc: 0.3636
Fold [2/5] Epoch [20/100] Initial Loss: 0.1348, Training Loss: 0.0794, Initial Validation Loss: 0.1240, Validation Loss: 0.0754,V Acc: 0.6396, Top 70th Acc: 0.7692, Bottom 30th Acc: 0.3333
Stopping early at Epoch (base 0): 21  Rolling back to Epoch (base 0): 16  Top Validation Acc: 0.7692307692307693
Fold [3/5] Epoch [0/100] Initial Loss: 0.1368, Training Loss: 0.1368, Initial Validation Loss: 0.1255, Validation Loss: 0.1255,V Acc: 0.3818, Top 70th Acc: 0.4156, Bottom 30th Acc: 0.3030
Fold [3/5] Epoch [10/100] Initial Loss: 0.1368, Training Loss: 0.0820, Initial Validation Loss: 0.1255, Validation Loss: 0.0786,V Acc: 0.6182, Top 70th Acc: 0.7532, Bottom 30th Acc: 0.3030
Fold [3/5] Epoch [20/100] Initial Loss: 0.1368, Training Loss: 0.0794, Initial Validation Loss: 0.1255, Validation Loss: 0.0761,V Acc: 0.6273, Top 70th Acc: 0.7532, Bottom 30th Acc: 0.3333
Fold [3/5] Epoch [30/100] Initial Loss: 0.1368, Training Loss: 0.0787, Initial Validation Loss: 0.1255, Validation Loss: 0.0746,V Acc: 0.6636, Top 70th Acc: 0.7662, Bottom 30th Acc: 0.4242
Stopping early at Epoch (base 0): 37  Rolling back to Epoch (base 0): 32  Top Validation Acc: 0.7662337662337663
41 2 [array([0.11806826, 0.3514647 , 0.14620323, 0.21497235, 0.1692915 ],
      dtype=float32)]
Fold [4/5] Epoch [0/100] Initial Loss: 0.1342, Training Loss: 0.1342, Initial Validation Loss: 0.1192, Validation Loss: 0.1192,V Acc: 0.4312, Top 70th Acc: 0.5195, Bottom 30th Acc: 0.2188
Fold [4/5] Epoch [10/100] Initial Loss: 0.1342, Training Loss: 0.0810, Initial Validation Loss: 0.1192, Validation Loss: 0.0751,V Acc: 0.6606, Top 70th Acc: 0.7403, Bottom 30th Acc: 0.4688
Fold [4/5] Epoch [20/100] Initial Loss: 0.1342, Training Loss: 0.0790, Initial Validation Loss: 0.1192, Validation Loss: 0.0739,V Acc: 0.6422, Top 70th Acc: 0.7403, Bottom 30th Acc: 0.4062
Stopping early at Epoch (base 0): 28  Rolling back to Epoch (base 0): 23  Top Validation Acc: 0.7402597402597403
Fold [5/5] Epoch [0/100] Initial Loss: 0.1392, Training Loss: 0.1392, Initial Validation Loss: 0.1339, Validation Loss: 0.1339,V Acc: 0.2500, Top 70th Acc: 0.3289, Bottom 30th Acc: 0.0625
Fold [5/5] Epoch [10/100] Initial Loss: 0.1392, Training Loss: 0.0797, Initial Validation Loss: 0.1339, Validation Loss: 0.0797,V Acc: 0.6296, Top 70th Acc: 0.7368, Bottom 30th Acc: 0.3750
Fold [5/5] Epoch [20/100] Initial Loss: 0.1392, Training Loss: 0.0778, Initial Validation Loss: 0.1339, Validation Loss: 0.0784,V Acc: 0.6296, Top 70th Acc: 0.7632, Bottom 30th Acc: 0.3125
Fold [5/5] Epoch [30/100] Initial Loss: 0.1392, Training Loss: 0.0774, Initial Validation Loss: 0.1339, Validation Loss: 0.0778,V Acc: 0.6389, Top 70th Acc: 0.7895, Bottom 30th Acc: 0.2812
Fold [5/5] Epoch [40/100] Initial Loss: 0.1392, Training Loss: 0.0771, Initial Validation Loss: 0.1339, Validation Loss: 0.0774,V Acc: 0.6389, Top 70th Acc: 0.7632, Bottom 30th Acc: 0.3438
Stopping early at Epoch (base 0): 43  Rolling back to Epoch (base 0): 38  Top Validation Acc: 0.7763157894736842
Running train_nn.py with seed 42
CUDA:False
Training samples count:  550
Training on 2 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1318, Training Loss: 0.1318, Initial Validation Loss: 0.1235, Validation Loss: 0.1235,V Acc: 0.4911, Top 70th Acc: 0.5696, Bottom 30th Acc: 0.3030
Fold [1/5] Epoch [10/100] Initial Loss: 0.1318, Training Loss: 0.0798, Initial Validation Loss: 0.1235, Validation Loss: 0.0835,V Acc: 0.6161, Top 70th Acc: 0.7342, Bottom 30th Acc: 0.3333
Fold [1/5] Epoch [20/100] Initial Loss: 0.1318, Training Loss: 0.0774, Initial Validation Loss: 0.1235, Validation Loss: 0.0831,V Acc: 0.6339, Top 70th Acc: 0.7215, Bottom 30th Acc: 0.4242
Fold [1/5] Epoch [30/100] Initial Loss: 0.1318, Training Loss: 0.0773, Initial Validation Loss: 0.1235, Validation Loss: 0.0813,V Acc: 0.6429, Top 70th Acc: 0.7215, Bottom 30th Acc: 0.4545
Stopping early at Epoch (base 0): 31  Rolling back to Epoch (base 0): 26  Top Validation Acc: 0.7215189873417721
Fold [2/5] Epoch [0/100] Initial Loss: 0.1362, Training Loss: 0.1362, Initial Validation Loss: 0.1280, Validation Loss: 0.1280,V Acc: 0.4234, Top 70th Acc: 0.5385, Bottom 30th Acc: 0.1515
Fold [2/5] Epoch [10/100] Initial Loss: 0.1362, Training Loss: 0.0801, Initial Validation Loss: 0.1280, Validation Loss: 0.0824,V Acc: 0.6486, Top 70th Acc: 0.7179, Bottom 30th Acc: 0.4848
Fold [2/5] Epoch [20/100] Initial Loss: 0.1362, Training Loss: 0.0773, Initial Validation Loss: 0.1280, Validation Loss: 0.0806,V Acc: 0.6396, Top 70th Acc: 0.7308, Bottom 30th Acc: 0.4242
Fold [2/5] Epoch [30/100] Initial Loss: 0.1362, Training Loss: 0.0764, Initial Validation Loss: 0.1280, Validation Loss: 0.0810,V Acc: 0.6577, Top 70th Acc: 0.7179, Bottom 30th Acc: 0.5152
Stopping early at Epoch (base 0): 30  Rolling back to Epoch (base 0): 25  Top Validation Acc: 0.717948717948718
Fold [3/5] Epoch [0/100] Initial Loss: 0.1355, Training Loss: 0.1355, Initial Validation Loss: 0.1280, Validation Loss: 0.1280,V Acc: 0.3909, Top 70th Acc: 0.5065, Bottom 30th Acc: 0.1212
Fold [3/5] Epoch [10/100] Initial Loss: 0.1355, Training Loss: 0.0789, Initial Validation Loss: 0.1280, Validation Loss: 0.0847,V Acc: 0.6182, Top 70th Acc: 0.7273, Bottom 30th Acc: 0.3636
Fold [3/5] Epoch [20/100] Initial Loss: 0.1355, Training Loss: 0.0775, Initial Validation Loss: 0.1280, Validation Loss: 0.0836,V Acc: 0.6091, Top 70th Acc: 0.7013, Bottom 30th Acc: 0.3939
Stopping early at Epoch (base 0): 22  Rolling back to Epoch (base 0): 17  Top Validation Acc: 0.7142857142857143
Fold [4/5] Epoch [0/100] Initial Loss: 0.1369, Training Loss: 0.1369, Initial Validation Loss: 0.1226, Validation Loss: 0.1226,V Acc: 0.4312, Top 70th Acc: 0.4935, Bottom 30th Acc: 0.2812
Fold [4/5] Epoch [10/100] Initial Loss: 0.1369, Training Loss: 0.0839, Initial Validation Loss: 0.1226, Validation Loss: 0.0698,V Acc: 0.6697, Top 70th Acc: 0.7792, Bottom 30th Acc: 0.4062
Fold [4/5] Epoch [30/100] Initial Loss: 0.1397, Training Loss: 0.0148, Initial Validation Loss: 0.1274, Validation Loss: 0.0321,V Acc: 0.7982, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.4688
Stopping early at Epoch (base 0): 30  Rolling back to Epoch (base 0): 25  Top Validation Acc: 0.935064935064935
Fold [5/5] Epoch [0/100] Initial Loss: 0.1387, Training Loss: 0.1387, Initial Validation Loss: 0.1338, Validation Loss: 0.1338,V Acc: 0.3333, Top 70th Acc: 0.4079, Bottom 30th Acc: 0.1562
Fold [5/5] Epoch [10/100] Initial Loss: 0.1387, Training Loss: 0.0302, Initial Validation Loss: 0.1338, Validation Loss: 0.0330,V Acc: 0.8704, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.6562
Fold [5/5] Epoch [20/100] Initial Loss: 0.1387, Training Loss: 0.0177, Initial Validation Loss: 0.1338, Validation Loss: 0.0290,V Acc: 0.8519, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.5938
Stopping early at Epoch (base 0): 27  Rolling back to Epoch (base 0): 22  Top Validation Acc: 0.9473684210526315
Running train_nn.py with seed 41
CUDA:False
Training samples count:  550
Training on 30 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1390, Training Loss: 0.1390, Initial Validation Loss: 0.1412, Validation Loss: 0.1412,V Acc: 0.2946, Top 70th Acc: 0.2785, Bottom 30th Acc: 0.3333
Fold [1/5] Epoch [10/100] Initial Loss: 0.1390, Training Loss: 0.0302, Initial Validation Loss: 0.1412, Validation Loss: 0.0430,V Acc: 0.7857, Top 70th Acc: 0.9241, Bottom 30th Acc: 0.4545
Fold [1/5] Epoch [20/100] Initial Loss: 0.1390, Training Loss: 0.0178, Initial Validation Loss: 0.1412, Validation Loss: 0.0359,V Acc: 0.8304, Top 70th Acc: 0.9367, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 29  Rolling back to Epoch (base 0): 24  Top Validation Acc: 0.9113924050632911
Fold [2/5] Epoch [0/100] Initial Loss: 0.1394, Training Loss: 0.1394, Initial Validation Loss: 0.1329, Validation Loss: 0.1329,V Acc: 0.2703, Top 70th Acc: 0.2308, Bottom 30th Acc: 0.3636
Fold [2/5] Epoch [10/100] Initial Loss: 0.1394, Training Loss: 0.0329, Initial Validation Loss: 0.1329, Validation Loss: 0.0406,V Acc: 0.7928, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.5152
Fold [2/5] Epoch [20/100] Initial Loss: 0.1394, Training Loss: 0.0175, Initial Validation Loss: 0.1329, Validation Loss: 0.0365,V Acc: 0.7928, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.5152
Stopping early at Epoch (base 0): 22  Rolling back to Epoch (base 0): 17  Top Validation Acc: 0.8974358974358975
Fold [3/5] Epoch [0/100] Initial Loss: 0.1400, Training Loss: 0.1400, Initial Validation Loss: 0.1272, Validation Loss: 0.1272,V Acc: 0.4182, Top 70th Acc: 0.5065, Bottom 30th Acc: 0.2121
Fold [3/5] Epoch [10/100] Initial Loss: 0.1400, Training Loss: 0.0329, Initial Validation Loss: 0.1272, Validation Loss: 0.0272,V Acc: 0.8909, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.7273
Stopping early at Epoch (base 0): 19  Rolling back to Epoch (base 0): 14  Top Validation Acc: 0.974025974025974
41 2 [array([0.622952  , 0.08167809, 0.07465825, 0.09920389, 0.12150783],
      dtype=float32)]
Fold [4/5] Epoch [0/100] Initial Loss: 0.1390, Training Loss: 0.1390, Initial Validation Loss: 0.1281, Validation Loss: 0.1281,V Acc: 0.3486, Top 70th Acc: 0.3247, Bottom 30th Acc: 0.4062
Fold [4/5] Epoch [10/100] Initial Loss: 0.1390, Training Loss: 0.0438, Initial Validation Loss: 0.1281, Validation Loss: 0.0449,V Acc: 0.8165, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.5312
Fold [4/5] Epoch [20/100] Initial Loss: 0.1390, Training Loss: 0.0219, Initial Validation Loss: 0.1281, Validation Loss: 0.0285,V Acc: 0.8440, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.5938
Stopping early at Epoch (base 0): 27  Rolling back to Epoch (base 0): 22  Top Validation Acc: 0.935064935064935
Fold [5/5] Epoch [0/100] Initial Loss: 0.1393, Training Loss: 0.1393, Initial Validation Loss: 0.1342, Validation Loss: 0.1342,V Acc: 0.3889, Top 70th Acc: 0.4211, Bottom 30th Acc: 0.3125
Fold [5/5] Epoch [10/100] Initial Loss: 0.1393, Training Loss: 0.0338, Initial Validation Loss: 0.1342, Validation Loss: 0.0423,V Acc: 0.8241, Top 70th Acc: 0.8947, Bottom 30th Acc: 0.6562
Fold [5/5] Epoch [20/100] Initial Loss: 0.1393, Training Loss: 0.0190, Initial Validation Loss: 0.1342, Validation Loss: 0.0317,V Acc: 0.8519, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.6250
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.9473684210526315
Running train_nn.py with seed 42
CUDA:False
Training samples count:  550
Training on 30 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1384, Training Loss: 0.1384, Initial Validation Loss: 0.1369, Validation Loss: 0.1369,V Acc: 0.3304, Top 70th Acc: 0.3924, Bottom 30th Acc: 0.1818
Fold [1/5] Epoch [10/100] Initial Loss: 0.1384, Training Loss: 0.0345, Initial Validation Loss: 0.1369, Validation Loss: 0.0460,V Acc: 0.8125, Top 70th Acc: 0.8608, Bottom 30th Acc: 0.6970
Fold [1/5] Epoch [20/100] Initial Loss: 0.1384, Training Loss: 0.0188, Initial Validation Loss: 0.1369, Validation Loss: 0.0383,V Acc: 0.8393, Top 70th Acc: 0.8734, Bottom 30th Acc: 0.7576
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.8987341772151899
Fold [2/5] Epoch [0/100] Initial Loss: 0.1395, Training Loss: 0.1395, Initial Validation Loss: 0.1361, Validation Loss: 0.1361,V Acc: 0.2703, Top 70th Acc: 0.3333, Bottom 30th Acc: 0.1212
Fold [2/5] Epoch [10/100] Initial Loss: 0.1395, Training Loss: 0.0480, Initial Validation Loss: 0.1361, Validation Loss: 0.0612,V Acc: 0.7027, Top 70th Acc: 0.8205, Bottom 30th Acc: 0.4242
Fold [2/5] Epoch [20/100] Initial Loss: 0.1395, Training Loss: 0.0225, Initial Validation Loss: 0.1361, Validation Loss: 0.0419,V Acc: 0.7748, Top 70th Acc: 0.8974, Bottom 30th Acc: 0.4848
Fold [2/5] Epoch [30/100] Initial Loss: 0.1395, Training Loss: 0.0171, Initial Validation Loss: 0.1361, Validation Loss: 0.0369,V Acc: 0.8018, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.4848
Stopping early at Epoch (base 0): 35  Rolling back to Epoch (base 0): 30  Top Validation Acc: 0.9358974358974359
Fold [3/5] Epoch [0/100] Initial Loss: 0.1392, Training Loss: 0.1392, Initial Validation Loss: 0.1358, Validation Loss: 0.1358,V Acc: 0.2545, Top 70th Acc: 0.3117, Bottom 30th Acc: 0.1212
Fold [3/5] Epoch [10/100] Initial Loss: 0.1392, Training Loss: 0.0327, Initial Validation Loss: 0.1358, Validation Loss: 0.0411,V Acc: 0.8273, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.6364
Fold [3/5] Epoch [20/100] Initial Loss: 0.1392, Training Loss: 0.0189, Initial Validation Loss: 0.1358, Validation Loss: 0.0317,V Acc: 0.8455, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.935064935064935
Fold [4/5] Epoch [0/100] Initial Loss: 0.1359, Training Loss: 0.1359, Initial Validation Loss: 0.1265, Validation Loss: 0.1265,V Acc: 0.3211, Top 70th Acc: 0.3636, Bottom 30th Acc: 0.2188
Fold [4/5] Epoch [10/100] Initial Loss: 0.1359, Training Loss: 0.0264, Initial Validation Loss: 0.1265, Validation Loss: 0.0284,V Acc: 0.8349, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.5625
Stopping early at Epoch (base 0): 17  Rolling back to Epoch (base 0): 12  Top Validation Acc: 0.961038961038961
Fold [5/5] Epoch [0/100] Initial Loss: 0.1386, Training Loss: 0.1386, Initial Validation Loss: 0.1298, Validation Loss: 0.1298,V Acc: 0.2778, Top 70th Acc: 0.3026, Bottom 30th Acc: 0.2188
Fold [5/5] Epoch [10/100] Initial Loss: 0.1386, Training Loss: 0.0308, Initial Validation Loss: 0.1298, Validation Loss: 0.0336,V Acc: 0.8796, Top 70th Acc: 0.9737, Bottom 30th Acc: 0.6562
Stopping early at Epoch (base 0): 18  Rolling back to Epoch (base 0): 13  Top Validation Acc: 0.9605263157894737
42 4 [array([0.43772516, 0.05851385, 0.06509373, 0.12483405, 0.31383318],
      dtype=float32)]
Running train_nn.py with seed 43
CUDA:False
Training samples count:  550
Training on 30 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1383, Training Loss: 0.1383, Initial Validation Loss: 0.1352, Validation Loss: 0.1352,V Acc: 0.4018, Top 70th Acc: 0.4557, Bottom 30th Acc: 0.2727
Fold [1/5] Epoch [10/100] Initial Loss: 0.1383, Training Loss: 0.0396, Initial Validation Loss: 0.1352, Validation Loss: 0.0454,V Acc: 0.8036, Top 70th Acc: 0.8861, Bottom 30th Acc: 0.6061
Fold [3/5] Epoch [40/100] Initial Loss: 0.1405, Training Loss: 0.0040, Initial Validation Loss: 0.1327, Validation Loss: 0.0290,V Acc: 0.8273, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 41  Rolling back to Epoch (base 0): 36  Top Validation Acc: 0.948051948051948
32 2 [array([0.30109558, 0.08007167, 0.05287106, 0.25556713, 0.3103946 ],
      dtype=float32)]
Fold [4/5] Epoch [0/100] Initial Loss: 0.1387, Training Loss: 0.1387, Initial Validation Loss: 0.1351, Validation Loss: 0.1351,V Acc: 0.2569, Top 70th Acc: 0.3506, Bottom 30th Acc: 0.0312
Fold [4/5] Epoch [10/100] Initial Loss: 0.1387, Training Loss: 0.0194, Initial Validation Loss: 0.1351, Validation Loss: 0.0410,V Acc: 0.8073, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.5625
Fold [4/5] Epoch [20/100] Initial Loss: 0.1387, Training Loss: 0.0055, Initial Validation Loss: 0.1351, Validation Loss: 0.0357,V Acc: 0.8165, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.5625
Fold [4/5] Epoch [30/100] Initial Loss: 0.1387, Training Loss: 0.0041, Initial Validation Loss: 0.1351, Validation Loss: 0.0342,V Acc: 0.8257, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.6250
Fold [4/5] Epoch [40/100] Initial Loss: 0.1387, Training Loss: 0.0037, Initial Validation Loss: 0.1351, Validation Loss: 0.0336,V Acc: 0.8349, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.6562
Fold [4/5] Epoch [50/100] Initial Loss: 0.1387, Training Loss: 0.0036, Initial Validation Loss: 0.1351, Validation Loss: 0.0326,V Acc: 0.8349, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.6562
Stopping early at Epoch (base 0): 52  Rolling back to Epoch (base 0): 47  Top Validation Acc: 0.9090909090909091
Fold [5/5] Epoch [0/100] Initial Loss: 0.1413, Training Loss: 0.1413, Initial Validation Loss: 0.1311, Validation Loss: 0.1311,V Acc: 0.2685, Top 70th Acc: 0.3421, Bottom 30th Acc: 0.0938
Fold [5/5] Epoch [10/100] Initial Loss: 0.1413, Training Loss: 0.0206, Initial Validation Loss: 0.1311, Validation Loss: 0.0378,V Acc: 0.8148, Top 70th Acc: 0.9211, Bottom 30th Acc: 0.5625
Fold [5/5] Epoch [20/100] Initial Loss: 0.1413, Training Loss: 0.0051, Initial Validation Loss: 0.1311, Validation Loss: 0.0306,V Acc: 0.8611, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.6562
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.9473684210526315
Running train_nn.py with seed 33
CUDA:False
Training samples count:  550
Training on 162 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1403, Training Loss: 0.1403, Initial Validation Loss: 0.1347, Validation Loss: 0.1347,V Acc: 0.3839, Top 70th Acc: 0.5190, Bottom 30th Acc: 0.0606
Fold [1/5] Epoch [10/100] Initial Loss: 0.1403, Training Loss: 0.0157, Initial Validation Loss: 0.1347, Validation Loss: 0.0284,V Acc: 0.8661, Top 70th Acc: 0.9494, Bottom 30th Acc: 0.6667
Fold [1/5] Epoch [20/100] Initial Loss: 0.1403, Training Loss: 0.0051, Initial Validation Loss: 0.1347, Validation Loss: 0.0262,V Acc: 0.8571, Top 70th Acc: 0.9747, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 20  Rolling back to Epoch (base 0): 15  Top Validation Acc: 0.9746835443037974
Fold [2/5] Epoch [0/100] Initial Loss: 0.1417, Training Loss: 0.1417, Initial Validation Loss: 0.1366, Validation Loss: 0.1366,V Acc: 0.2523, Top 70th Acc: 0.2692, Bottom 30th Acc: 0.2121
Fold [2/5] Epoch [10/100] Initial Loss: 0.1417, Training Loss: 0.0199, Initial Validation Loss: 0.1366, Validation Loss: 0.0362,V Acc: 0.8559, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.6364
Fold [2/5] Epoch [20/100] Initial Loss: 0.1417, Training Loss: 0.0049, Initial Validation Loss: 0.1366, Validation Loss: 0.0297,V Acc: 0.8739, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.7273
Stopping early at Epoch (base 0): 22  Rolling back to Epoch (base 0): 17  Top Validation Acc: 0.9358974358974359
Fold [3/5] Epoch [0/100] Initial Loss: 0.1397, Training Loss: 0.1397, Initial Validation Loss: 0.1352, Validation Loss: 0.1352,V Acc: 0.2545, Top 70th Acc: 0.3117, Bottom 30th Acc: 0.1212
Fold [3/5] Epoch [10/100] Initial Loss: 0.1397, Training Loss: 0.0194, Initial Validation Loss: 0.1352, Validation Loss: 0.0379,V Acc: 0.8273, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.6061
Fold [3/5] Epoch [20/100] Initial Loss: 0.1397, Training Loss: 0.0051, Initial Validation Loss: 0.1352, Validation Loss: 0.0310,V Acc: 0.8545, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 28  Rolling back to Epoch (base 0): 23  Top Validation Acc: 0.935064935064935
Fold [4/5] Epoch [0/100] Initial Loss: 0.1376, Training Loss: 0.1376, Initial Validation Loss: 0.1306, Validation Loss: 0.1306,V Acc: 0.4128, Top 70th Acc: 0.4805, Bottom 30th Acc: 0.2500
Fold [4/5] Epoch [10/100] Initial Loss: 0.1376, Training Loss: 0.0150, Initial Validation Loss: 0.1306, Validation Loss: 0.0266,V Acc: 0.8991, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.7188
Fold [4/5] Epoch [20/100] Initial Loss: 0.1376, Training Loss: 0.0049, Initial Validation Loss: 0.1306, Validation Loss: 0.0227,V Acc: 0.9083, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.7812
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.961038961038961
Fold [5/5] Epoch [0/100] Initial Loss: 0.1410, Training Loss: 0.1410, Initial Validation Loss: 0.1300, Validation Loss: 0.1300,V Acc: 0.2500, Top 70th Acc: 0.3026, Bottom 30th Acc: 0.1250
Fold [5/5] Epoch [10/100] Initial Loss: 0.1410, Training Loss: 0.0168, Initial Validation Loss: 0.1300, Validation Loss: 0.0372,V Acc: 0.7870, Top 70th Acc: 0.9211, Bottom 30th Acc: 0.4688
Fold [5/5] Epoch [20/100] Initial Loss: 0.1410, Training Loss: 0.0046, Initial Validation Loss: 0.1300, Validation Loss: 0.0319,V Acc: 0.8241, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.5312
Fold [5/5] Epoch [30/100] Initial Loss: 0.1410, Training Loss: 0.0037, Initial Validation Loss: 0.1300, Validation Loss: 0.0311,V Acc: 0.8241, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.5312
Fold [5/5] Epoch [40/100] Initial Loss: 0.1410, Training Loss: 0.0034, Initial Validation Loss: 0.1300, Validation Loss: 0.0306,V Acc: 0.8056, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.4688
Stopping early at Epoch (base 0): 44  Rolling back to Epoch (base 0): 39  Top Validation Acc: 0.9473684210526315
33 4 [array([0.20808727, 0.08678495, 0.20744328, 0.26427376, 0.23341079],
      dtype=float32)]
Running train_nn.py with seed 34
CUDA:False
Training samples count:  550
Training on 162 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1405, Training Loss: 0.1405, Initial Validation Loss: 0.1371, Validation Loss: 0.1371,V Acc: 0.3661, Top 70th Acc: 0.4177, Bottom 30th Acc: 0.2424
Fold [1/5] Epoch [10/100] Initial Loss: 0.1405, Training Loss: 0.0217, Initial Validation Loss: 0.1371, Validation Loss: 0.0382,V Acc: 0.8393, Top 70th Acc: 0.8987, Bottom 30th Acc: 0.6970
Fold [1/5] Epoch [20/100] Initial Loss: 0.1405, Training Loss: 0.0066, Initial Validation Loss: 0.1371, Validation Loss: 0.0307,V Acc: 0.8482, Top 70th Acc: 0.9114, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.9240506329113924
34 0 [array([0.254688  , 0.10368083, 0.12460852, 0.18997306, 0.32704964],
      dtype=float32)]
Fold [2/5] Epoch [0/100] Initial Loss: 0.1412, Training Loss: 0.1412, Initial Validation Loss: 0.1373, Validation Loss: 0.1373,V Acc: 0.3153, Top 70th Acc: 0.3462, Bottom 30th Acc: 0.2424
Fold [2/5] Epoch [10/100] Initial Loss: 0.1412, Training Loss: 0.0193, Initial Validation Loss: 0.1373, Validation Loss: 0.0362,V Acc: 0.8288, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.4848
Fold [2/5] Epoch [20/100] Initial Loss: 0.1412, Training Loss: 0.0045, Initial Validation Loss: 0.1373, Validation Loss: 0.0318,V Acc: 0.8198, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.4848
Stopping early at Epoch (base 0): 22  Rolling back to Epoch (base 0): 17  Top Validation Acc: 0.9615384615384616
Fold [3/5] Epoch [0/100] Initial Loss: 0.1395, Training Loss: 0.1395, Initial Validation Loss: 0.1368, Validation Loss: 0.1368,V Acc: 0.2636, Top 70th Acc: 0.3377, Bottom 30th Acc: 0.0909
Fold [3/5] Epoch [10/100] Initial Loss: 0.1395, Training Loss: 0.0205, Initial Validation Loss: 0.1368, Validation Loss: 0.0471,V Acc: 0.7909, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.5152
CUDA:False
Training samples count:  550
Training on 21 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1330, Training Loss: 0.1330, Initial Validation Loss: 0.1267, Validation Loss: 0.1267,V Acc: 0.5179, Top 70th Acc: 0.5443, Bottom 30th Acc: 0.4545
Fold [1/5] Epoch [10/100] Initial Loss: 0.1330, Training Loss: 0.0208, Initial Validation Loss: 0.1267, Validation Loss: 0.0346,V Acc: 0.8482, Top 70th Acc: 0.9494, Bottom 30th Acc: 0.6061
Fold [1/5] Epoch [20/100] Initial Loss: 0.1330, Training Loss: 0.0134, Initial Validation Loss: 0.1267, Validation Loss: 0.0310,V Acc: 0.8571, Top 70th Acc: 0.9620, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 22  Rolling back to Epoch (base 0): 17  Top Validation Acc: 0.9493670886075949
Fold [2/5] Epoch [0/100] Initial Loss: 0.1352, Training Loss: 0.1352, Initial Validation Loss: 0.1229, Validation Loss: 0.1229,V Acc: 0.4505, Top 70th Acc: 0.5385, Bottom 30th Acc: 0.2424
Fold [2/5] Epoch [10/100] Initial Loss: 0.1352, Training Loss: 0.0245, Initial Validation Loss: 0.1229, Validation Loss: 0.0282,V Acc: 0.8829, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.7273
Fold [2/5] Epoch [20/100] Initial Loss: 0.1352, Training Loss: 0.0153, Initial Validation Loss: 0.1229, Validation Loss: 0.0260,V Acc: 0.8739, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.9230769230769231
Fold [3/5] Epoch [0/100] Initial Loss: 0.1312, Training Loss: 0.1312, Initial Validation Loss: 0.1136, Validation Loss: 0.1136,V Acc: 0.4545, Top 70th Acc: 0.5065, Bottom 30th Acc: 0.3333
Fold [3/5] Epoch [10/100] Initial Loss: 0.1312, Training Loss: 0.0237, Initial Validation Loss: 0.1136, Validation Loss: 0.0268,V Acc: 0.8727, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.6667
Fold [3/5] Epoch [20/100] Initial Loss: 0.1312, Training Loss: 0.0165, Initial Validation Loss: 0.1136, Validation Loss: 0.0241,V Acc: 0.8727, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 28  Rolling back to Epoch (base 0): 23  Top Validation Acc: 0.974025974025974
Fold [4/5] Epoch [0/100] Initial Loss: 0.1382, Training Loss: 0.1382, Initial Validation Loss: 0.1248, Validation Loss: 0.1248,V Acc: 0.4404, Top 70th Acc: 0.5714, Bottom 30th Acc: 0.1250
Fold [4/5] Epoch [10/100] Initial Loss: 0.1382, Training Loss: 0.0300, Initial Validation Loss: 0.1248, Validation Loss: 0.0313,V Acc: 0.8807, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.7500
Fold [4/5] Epoch [20/100] Initial Loss: 0.1382, Training Loss: 0.0182, Initial Validation Loss: 0.1248, Validation Loss: 0.0247,V Acc: 0.8899, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.7188
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.961038961038961
58 3 [array([0.71244043, 0.01732484, 0.03521408, 0.16672787, 0.06829277],
      dtype=float32)]
Fold [5/5] Epoch [0/100] Initial Loss: 0.1336, Training Loss: 0.1336, Initial Validation Loss: 0.1191, Validation Loss: 0.1191,V Acc: 0.4259, Top 70th Acc: 0.5526, Bottom 30th Acc: 0.1250
Fold [5/5] Epoch [10/100] Initial Loss: 0.1336, Training Loss: 0.0213, Initial Validation Loss: 0.1191, Validation Loss: 0.0242,V Acc: 0.8796, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.6875
Fold [5/5] Epoch [20/100] Initial Loss: 0.1336, Training Loss: 0.0167, Initial Validation Loss: 0.1191, Validation Loss: 0.0208,V Acc: 0.8889, Top 70th Acc: 0.9868, Bottom 30th Acc: 0.6562
Stopping early at Epoch (base 0): 21  Rolling back to Epoch (base 0): 16  Top Validation Acc: 0.9868421052631579
Running train_nn.py with seed 59
CUDA:False
Training samples count:  550
Training on 21 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1305, Training Loss: 0.1305, Initial Validation Loss: 0.1139, Validation Loss: 0.1139,V Acc: 0.5804, Top 70th Acc: 0.7215, Bottom 30th Acc: 0.2424
Fold [1/5] Epoch [10/100] Initial Loss: 0.1305, Training Loss: 0.0208, Initial Validation Loss: 0.1139, Validation Loss: 0.0352,V Acc: 0.8036, Top 70th Acc: 0.9367, Bottom 30th Acc: 0.4848
Stopping early at Epoch (base 0): 19  Rolling back to Epoch (base 0): 14  Top Validation Acc: 0.9493670886075949
Fold [2/5] Epoch [0/100] Initial Loss: 0.1353, Training Loss: 0.1353, Initial Validation Loss: 0.1232, Validation Loss: 0.1232,V Acc: 0.4054, Top 70th Acc: 0.4487, Bottom 30th Acc: 0.3030
Fold [2/5] Epoch [10/100] Initial Loss: 0.1353, Training Loss: 0.0289, Initial Validation Loss: 0.1232, Validation Loss: 0.0318,V Acc: 0.8378, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.5758
Fold [2/5] Epoch [20/100] Initial Loss: 0.1353, Training Loss: 0.0196, Initial Validation Loss: 0.1232, Validation Loss: 0.0198,V Acc: 0.9009, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.7273
Fold [2/5] Epoch [30/100] Initial Loss: 0.1353, Training Loss: 0.0151, Initial Validation Loss: 0.1232, Validation Loss: 0.0214,V Acc: 0.8829, Top 70th Acc: 0.9872, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 31  Rolling back to Epoch (base 0): 26  Top Validation Acc: 0.9871794871794872
Fold [3/5] Epoch [0/100] Initial Loss: 0.1285, Training Loss: 0.1285, Initial Validation Loss: 0.1104, Validation Loss: 0.1104,V Acc: 0.4545, Top 70th Acc: 0.5974, Bottom 30th Acc: 0.1212
Fold [3/5] Epoch [10/100] Initial Loss: 0.1285, Training Loss: 0.0206, Initial Validation Loss: 0.1104, Validation Loss: 0.0287,V Acc: 0.8727, Top 70th Acc: 0.9870, Bottom 30th Acc: 0.6061
Fold [3/5] Epoch [20/100] Initial Loss: 0.1285, Training Loss: 0.0154, Initial Validation Loss: 0.1104, Validation Loss: 0.0244,V Acc: 0.9182, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.8182
Fold [3/5] Epoch [30/100] Initial Loss: 0.1285, Training Loss: 0.0135, Initial Validation Loss: 0.1104, Validation Loss: 0.0221,V Acc: 0.9091, Top 70th Acc: 0.9870, Bottom 30th Acc: 0.7273
Stopping early at Epoch (base 0): 37  Rolling back to Epoch (base 0): 32  Top Validation Acc: 0.974025974025974
Fold [4/5] Epoch [0/100] Initial Loss: 0.1353, Training Loss: 0.1353, Initial Validation Loss: 0.1265, Validation Loss: 0.1265,V Acc: 0.3028, Top 70th Acc: 0.4156, Bottom 30th Acc: 0.0312
Fold [4/5] Epoch [10/100] Initial Loss: 0.1353, Training Loss: 0.0245, Initial Validation Loss: 0.1265, Validation Loss: 0.0260,V Acc: 0.9083, Top 70th Acc: 0.9870, Bottom 30th Acc: 0.7188
Fold [4/5] Epoch [20/100] Initial Loss: 0.1353, Training Loss: 0.0166, Initial Validation Loss: 0.1265, Validation Loss: 0.0184,V Acc: 0.9358, Top 70th Acc: 0.9870, Bottom 30th Acc: 0.8125
Fold [4/5] Epoch [30/100] Initial Loss: 0.1353, Training Loss: 0.0142, Initial Validation Loss: 0.1265, Validation Loss: 0.0239,V Acc: 0.9174, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.8438
Stopping early at Epoch (base 0): 32  Rolling back to Epoch (base 0): 27  Top Validation Acc: 0.974025974025974
59 3 [array([0.8498726 , 0.01216395, 0.04100039, 0.05338674, 0.04357646],
      dtype=float32)]
Fold [5/5] Epoch [0/100] Initial Loss: 0.1357, Training Loss: 0.1357, Initial Validation Loss: 0.1212, Validation Loss: 0.1212,V Acc: 0.4630, Top 70th Acc: 0.5789, Bottom 30th Acc: 0.1875
Fold [5/5] Epoch [10/100] Initial Loss: 0.1357, Training Loss: 0.0237, Initial Validation Loss: 0.1212, Validation Loss: 0.0216,V Acc: 0.9074, Top 70th Acc: 0.9868, Bottom 30th Acc: 0.7188
Fold [5/5] Epoch [20/100] Initial Loss: 0.1357, Training Loss: 0.0173, Initial Validation Loss: 0.1212, Validation Loss: 0.0218,V Acc: 0.8611, Top 70th Acc: 0.9868, Bottom 30th Acc: 0.5625
Stopping early at Epoch (base 0): 21  Rolling back to Epoch (base 0): 16  Top Validation Acc: 0.9605263157894737
Running train_nn.py with seed 60
CUDA:False
Training samples count:  550
Training on 21 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1343, Training Loss: 0.1343, Initial Validation Loss: 0.1281, Validation Loss: 0.1281,V Acc: 0.4107, Top 70th Acc: 0.4937, Bottom 30th Acc: 0.2121
Fold [1/5] Epoch [10/100] Initial Loss: 0.1343, Training Loss: 0.0242, Initial Validation Loss: 0.1281, Validation Loss: 0.0237,V Acc: 0.9107, Top 70th Acc: 0.9747, Bottom 30th Acc: 0.7576
Fold [1/5] Epoch [20/100] Initial Loss: 0.1343, Training Loss: 0.0165, Initial Validation Loss: 0.1281, Validation Loss: 0.0216,V Acc: 0.9018, Top 70th Acc: 0.9620, Bottom 30th Acc: 0.7576
Stopping early at Epoch (base 0):/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)

Stopping early at Epoch (base 0): 29  Rolling back to Epoch (base 0): 24  Top Validation Acc: 0.9342105263157895
Running train_nn.py with seed 45
CUDA:False
Training samples count:  550
Training on 40 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1407, Training Loss: 0.1407, Initial Validation Loss: 0.1392, Validation Loss: 0.1392,V Acc: 0.2500, Top 70th Acc: 0.2785, Bottom 30th Acc: 0.1818
Fold [1/5] Epoch [10/100] Initial Loss: 0.1407, Training Loss: 0.0418, Initial Validation Loss: 0.1392, Validation Loss: 0.0545,V Acc: 0.7589, Top 70th Acc: 0.8734, Bottom 30th Acc: 0.4848
Fold [1/5] Epoch [20/100] Initial Loss: 0.1407, Training Loss: 0.0172, Initial Validation Loss: 0.1392, Validation Loss: 0.0350,V Acc: 0.8661, Top 70th Acc: 0.9241, Bottom 30th Acc: 0.7273
Fold [1/5] Epoch [30/100] Initial Loss: 0.1407, Training Loss: 0.0129, Initial Validation Loss: 0.1392, Validation Loss: 0.0332,V Acc: 0.8661, Top 70th Acc: 0.9241, Bottom 30th Acc: 0.7273
Stopping early at Epoch (base 0): 32  Rolling back to Epoch (base 0): 27  Top Validation Acc: 0.9367088607594937
Fold [2/5] Epoch [0/100] Initial Loss: 0.1389, Training Loss: 0.1389, Initial Validation Loss: 0.1343, Validation Loss: 0.1343,V Acc: 0.2613, Top 70th Acc: 0.3333, Bottom 30th Acc: 0.0909
Fold [2/5] Epoch [10/100] Initial Loss: 0.1389, Training Loss: 0.0311, Initial Validation Loss: 0.1343, Validation Loss: 0.0330,V Acc: 0.8288, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.5152
Fold [2/5] Epoch [20/100] Initial Loss: 0.1389, Training Loss: 0.0151, Initial Validation Loss: 0.1343, Validation Loss: 0.0260,V Acc: 0.8649, Top 70th Acc: 0.9872, Bottom 30th Acc: 0.5758
Fold [2/5] Epoch [30/100] Initial Loss: 0.1389, Training Loss: 0.0123, Initial Validation Loss: 0.1343, Validation Loss: 0.0248,V Acc: 0.8739, Top 70th Acc: 0.9872, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 35  Rolling back to Epoch (base 0): 30  Top Validation Acc: 0.9743589743589743
Fold [3/5] Epoch [0/100] Initial Loss: 0.1406, Training Loss: 0.1406, Initial Validation Loss: 0.1325, Validation Loss: 0.1325,V Acc: 0.3182, Top 70th Acc: 0.4026, Bottom 30th Acc: 0.1212
Fold [3/5] Epoch [10/100] Initial Loss: 0.1406, Training Loss: 0.0213, Initial Validation Loss: 0.1325, Validation Loss: 0.0387,V Acc: 0.8000, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.5455
Fold [3/5] Epoch [20/100] Initial Loss: 0.1406, Training Loss: 0.0132, Initial Validation Loss: 0.1325, Validation Loss: 0.0356,V Acc: 0.8273, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.9090909090909091
45 2 [array([0.69434315, 0.08129289, 0.08502241, 0.08964318, 0.04969848],
      dtype=float32)]
Fold [4/5] Epoch [0/100] Initial Loss: 0.1373, Training Loss: 0.1373, Initial Validation Loss: 0.1319, Validation Loss: 0.1319,V Acc: 0.2936, Top 70th Acc: 0.3506, Bottom 30th Acc: 0.1562
Fold [4/5] Epoch [10/100] Initial Loss: 0.1373, Training Loss: 0.0379, Initial Validation Loss: 0.1319, Validation Loss: 0.0372,V Acc: 0.8532, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.6875
Fold [4/5] Epoch [20/100] Initial Loss: 0.1373, Training Loss: 0.0163, Initial Validation Loss: 0.1319, Validation Loss: 0.0251,V Acc: 0.8807, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.6562
Stopping early at Epoch (base 0): 27  Rolling back to Epoch (base 0): 22  Top Validation Acc: 0.974025974025974
Fold [5/5] Epoch [0/100] Initial Loss: 0.1440, Training Loss: 0.1440, Initial Validation Loss: 0.1289, Validation Loss: 0.1289,V Acc: 0.3148, Top 70th Acc: 0.3684, Bottom 30th Acc: 0.1875
Fold [5/5] Epoch [10/100] Initial Loss: 0.1440, Training Loss: 0.0401, Initial Validation Loss: 0.1289, Validation Loss: 0.0428,V Acc: 0.7593, Top 70th Acc: 0.9079, Bottom 30th Acc: 0.4062
Fold [5/5] Epoch [20/100] Initial Loss: 0.1440, Training Loss: 0.0185, Initial Validation Loss: 0.1289, Validation Loss: 0.0299,V Acc: 0.8148, Top 70th Acc: 0.9737, Bottom 30th Acc: 0.4375
Fold [5/5] Epoch [30/100] Initial Loss: 0.1440, Training Loss: 0.0143, Initial Validation Loss: 0.1289, Validation Loss: 0.0287,V Acc: 0.8241, Top 70th Acc: 0.9737, Bottom 30th Acc: 0.4688
Fold [5/5] Epoch [40/100] Initial Loss: 0.1440, Training Loss: 0.0128, Initial Validation Loss: 0.1289, Validation Loss: 0.0281,V Acc: 0.8241, Top 70th Acc: 0.9737, Bottom 30th Acc: 0.4688
Stopping early at Epoch (base 0): 40  Rolling back to Epoch (base 0): 35  Top Validation Acc: 0.9736842105263158
Running train_nn.py with seed 46
CUDA:False
Training samples count:  550
Training on 40 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1410, Training Loss: 0.1410, Initial Validation Loss: 0.1336, Validation Loss: 0.1336,V Acc: 0.4018, Top 70th Acc: 0.4430, Bottom 30th Acc: 0.3030
Fold [1/5] Epoch [10/100] Initial Loss: 0.1410, Training Loss: 0.0317, Initial Validation Loss: 0.1336, Validation Loss: 0.0444,V Acc: 0.7857, Top 70th Acc: 0.8608, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 18  Rolling back to Epoch (base 0): 13  Top Validation Acc: 0.8860759493670886
Fold [2/5] Epoch [0/100] Initial Loss: 0.1399, Training Loss: 0.1399, Initial Validation Loss: 0.1356, Validation Loss: 0.1356,V Acc: 0.3333, Top 70th Acc: 0.3718, Bottom 30th Acc: 0.2424
Fold [2/5] Epoch [10/100] Initial Loss: 0.1399, Training Loss: 0.0362, Initial Validation Loss: 0.1356, Validation Loss: 0.0425,V Acc: 0.7748, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.4545
Fold [2/5] Epoch [20/100] Initial Loss: 0.1399, Training Loss: 0.0173, Initial Validation Loss: 0.1356, Validation Loss: 0.0346,V Acc: 0.7928, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.4242
Fold [2/5] Epoch [30/100] Initial Loss: 0.1399, Training Loss: 0.0122, Initial Validation Loss: 0.1356, Validation Loss: 0.0334,V Acc: 0.8018, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.3939
Stopping early at Epoch (base 0): 31  Rolling back to Epoch (base 0): 26  Top Validation Acc: 0.9743589743589743
46 1 [array([0.6014006 , 0.07368729, 0.02902718, 0.08827463, 0.20761023],
      dtype=float32)]
Fold [3/5] Epoch [0/100] Initial Loss: 0.1409, Training Loss: 0.1409, Initial Validation Loss: 0.1364, Validation Loss: 0.1364,V Acc: 0.2727, Top 70th Acc: 0.3377, Bottom 30th Acc: 0.1212
Fold [3/5] Epoch [10/100] Initial Loss: 0.1409, Training Loss: 0.0392, Initial Validation Loss: 0.1364, Validation Loss: 0.0401,V Acc: 0.8455, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.6667
Fold [3/5] Epoch [20/100] Initial Loss: 0.1409, Training Loss: 0.0155, Initial Validation Loss: 0.1364, Validation Loss: 0.0242,V Acc: 0.9000, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.7273
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.961038961038961
Fold [4/5] Epoch [0/100] Initial Loss: 0.1445, Training Loss: 0.1445, Initial Validation Loss: 0.1316, Validation Loss: 0.1316,V Acc: 0.2477, Top 70th Acc: 0.2727, Bottom 30th Acc: 0.1875
Fold [4/5] Epoch [10/100] Initial Loss: 0.1445, Training Loss: 0.0306, Initial Validation Loss: 0.1316, Validation Loss: 0.0378,V Acc: 0.8165, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.5938
Fold [4/5] Epoch [20/100] Initial Loss: 0.1445, Training Loss: 0.0150, Initial Validation Loss: 0.1316, Validation Loss: 0.0325,V Acc: 0.8073, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.4688
Stopping early at Epoch (base 0): 27  Rolling back to Epoch (base 0): 22  Top Validation Acc: 0.961038961038961
Fold [5/5] Epoch [0/100] Initial Loss: 0.1383, Training Loss: 0.1383, Initial Validation Loss: 0.1350, Validation Loss: 0.1350,V Acc: 0.2593, Top 70th Acc: 0.3289, Bottom 30th Acc: 0.0938
Fold [5/5] Epoch [10/100] Initial Loss: 0.1383, Training Loss: 0.0423, Initial Validation Loss: 0.1350, Validation Loss: 0.0479,V Acc: 0.7963, Top 70th Acc: 0.9079, Bottom 30th Acc: 0.5312
Fold [5/5] Epoch [20/100] Initial Loss: 0.1383, Training Loss: 0.0163, Initial Validation Loss: 0.1350, Validation Loss: 0.0261,V Acc: 0.8889, Top 70th Acc: 0.9737, Bottom 30th Acc: 0.6875
Stopping early at Epoch (base 0): 28  Rolling back to Epoch (base 0): 23  Top Validation Acc: 0.9736842105263158
Running train_nn.py with seed 47
CUDA:False
Training samples count:  550
Training on 40 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1354, Training Loss: 0.1354, Initial Validation Loss: 0.1311, Validation Loss: 0.1311,V Acc: 0.3839, Top 70th Acc: 0.4937, Bottom 30th Acc: 0.1212
Fold [4/5] Epoch [20/100] Initial Loss: 0.1402, Training Loss: 0.0251, Initial Validation Loss: 0.1316, Validation Loss: 0.0285,V Acc: 0.8165, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.5000
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.961038961038961
Fold [5/5] Epoch [0/100] Initial Loss: 0.1393, Training Loss: 0.1393, Initial Validation Loss: 0.1295, Validation Loss: 0.1295,V Acc: 0.2407, Top 70th Acc: 0.3421, Bottom 30th Acc: 0.0000
Fold [5/5] Epoch [10/100] Initial Loss: 0.1393, Training Loss: 0.0403, Initial Validation Loss: 0.1295, Validation Loss: 0.0369,V Acc: 0.8148, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.5000
Fold [5/5] Epoch [20/100] Initial Loss: 0.1393, Training Loss: 0.0267, Initial Validation Loss: 0.1295, Validation Loss: 0.0291,V Acc: 0.8889, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.7188
Fold [5/5] Epoch [30/100] Initial Loss: 0.1393, Training Loss: 0.0236, Initial Validation Loss: 0.1295, Validation Loss: 0.0283,V Acc: 0.8611, Top 70th Acc: 0.9737, Bottom 30th Acc: 0.5938
Fold [5/5] Epoch [40/100] Initial Loss: 0.1393, Training Loss: 0.0229, Initial Validation Loss: 0.1295, Validation Loss: 0.0291,V Acc: 0.8981, Top 70th Acc: 0.9737, Bottom 30th Acc: 0.7188
Stopping early at Epoch (base 0): 40  Rolling back to Epoch (base 0): 35  Top Validation Acc: 0.9736842105263158
42 4 [array([0.26044923, 0.0838021 , 0.12510549, 0.3355348 , 0.19510838],
      dtype=float32)]
Running train_nn.py with seed 43
CUDA:False
Training samples count:  550
Training on 20 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1402, Training Loss: 0.1402, Initial Validation Loss: 0.1361, Validation Loss: 0.1361,V Acc: 0.2232, Top 70th Acc: 0.2532, Bottom 30th Acc: 0.1515
Fold [1/5] Epoch [10/100] Initial Loss: 0.1402, Training Loss: 0.0329, Initial Validation Loss: 0.1361, Validation Loss: 0.0367,V Acc: 0.8482, Top 70th Acc: 0.9494, Bottom 30th Acc: 0.6061
Fold [1/5] Epoch [20/100] Initial Loss: 0.1402, Training Loss: 0.0233, Initial Validation Loss: 0.1361, Validation Loss: 0.0330,V Acc: 0.8304, Top 70th Acc: 0.9620, Bottom 30th Acc: 0.5152
Stopping early at Epoch (base 0): 22  Rolling back to Epoch (base 0): 17  Top Validation Acc: 0.9493670886075949
Fold [2/5] Epoch [0/100] Initial Loss: 0.1423, Training Loss: 0.1423, Initial Validation Loss: 0.1341, Validation Loss: 0.1341,V Acc: 0.2883, Top 70th Acc: 0.2949, Bottom 30th Acc: 0.2727
Fold [2/5] Epoch [10/100] Initial Loss: 0.1423, Training Loss: 0.0400, Initial Validation Loss: 0.1341, Validation Loss: 0.0404,V Acc: 0.8018, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.5152
Fold [2/5] Epoch [20/100] Initial Loss: 0.1423, Training Loss: 0.0260, Initial Validation Loss: 0.1341, Validation Loss: 0.0291,V Acc: 0.8649, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.7273
Stopping early at Epoch (base 0): 27  Rolling back to Epoch (base 0): 22  Top Validation Acc: 0.9487179487179487
43 1 [array([0.34960964, 0.07147085, 0.14271708, 0.18224168, 0.2539608 ],
      dtype=float32)]
Fold [3/5] Epoch [0/100] Initial Loss: 0.1400, Training Loss: 0.1400, Initial Validation Loss: 0.1373, Validation Loss: 0.1373,V Acc: 0.3273, Top 70th Acc: 0.3766, Bottom 30th Acc: 0.2121
Fold [3/5] Epoch [10/100] Initial Loss: 0.1400, Training Loss: 0.0321, Initial Validation Loss: 0.1373, Validation Loss: 0.0330,V Acc: 0.8909, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.7576
Stopping early at Epoch (base 0): 19  Rolling back to Epoch (base 0): 14  Top Validation Acc: 0.948051948051948
Fold [4/5] Epoch [0/100] Initial Loss: 0.1381, Training Loss: 0.1381, Initial Validation Loss: 0.1331, Validation Loss: 0.1331,V Acc: 0.2752, Top 70th Acc: 0.3506, Bottom 30th Acc: 0.0938
Fold [4/5] Epoch [10/100] Initial Loss: 0.1381, Training Loss: 0.0397, Initial Validation Loss: 0.1331, Validation Loss: 0.0448,V Acc: 0.7890, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.4688
Fold [4/5] Epoch [20/100] Initial Loss: 0.1381, Training Loss: 0.0276, Initial Validation Loss: 0.1331, Validation Loss: 0.0344,V Acc: 0.8349, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.5625
Fold [4/5] Epoch [30/100] Initial Loss: 0.1381, Training Loss: 0.0232, Initial Validation Loss: 0.1331, Validation Loss: 0.0325,V Acc: 0.8257, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.5625
Stopping early at Epoch (base 0): 30  Rolling back to Epoch (base 0): 25  Top Validation Acc: 0.935064935064935
Fold [5/5] Epoch [0/100] Initial Loss: 0.1402, Training Loss: 0.1402, Initial Validation Loss: 0.1290, Validation Loss: 0.1290,V Acc: 0.3981, Top 70th Acc: 0.4211, Bottom 30th Acc: 0.3438
Fold [5/5] Epoch [10/100] Initial Loss: 0.1402, Training Loss: 0.0400, Initial Validation Loss: 0.1290, Validation Loss: 0.0462,V Acc: 0.7963, Top 70th Acc: 0.8158, Bottom 30th Acc: 0.7500
Fold [5/5] Epoch [20/100] Initial Loss: 0.1402, Training Loss: 0.0232, Initial Validation Loss: 0.1290, Validation Loss: 0.0396,V Acc: 0.8056, Top 70th Acc: 0.8289, Bottom 30th Acc: 0.7500
Fold [5/5] Epoch [30/100] Initial Loss: 0.1402, Training Loss: 0.0205, Initial Validation Loss: 0.1290, Validation Loss: 0.0385,V Acc: 0.7963, Top 70th Acc: 0.8553, Bottom 30th Acc: 0.6562
Stopping early at Epoch (base 0): 33  Rolling back to Epoch (base 0): 28  Top Validation Acc: 0.8552631578947368
Running train_nn.py with seed 44
CUDA:False
Training samples count:  550
Training on 20 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1401, Training Loss: 0.1401, Initial Validation Loss: 0.1364, Validation Loss: 0.1364,V Acc: 0.3125, Top 70th Acc: 0.3671, Bottom 30th Acc: 0.1818
Fold [1/5] Epoch [10/100] Initial Loss: 0.1401, Training Loss: 0.0399, Initial Validation Loss: 0.1364, Validation Loss: 0.0413,V Acc: 0.8214, Top 70th Acc: 0.8861, Bottom 30th Acc: 0.6667
Fold [1/5] Epoch [20/100] Initial Loss: 0.1401, Training Loss: 0.0231, Initial Validation Loss: 0.1364, Validation Loss: 0.0346,V Acc: 0.7946, Top 70th Acc: 0.9367, Bottom 30th Acc: 0.4545
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.9240506329113924
44 0 [array([0.4151071 , 0.11874411, 0.10010889, 0.17420892, 0.19183098],
      dtype=float32)]
Fold [2/5] Epoch [0/100] Initial Loss: 0.1401, Training Loss: 0.1401, Initial Validation Loss: 0.1382, Validation Loss: 0.1382,V Acc: 0.2883, Top 70th Acc: 0.2949, Bottom 30th Acc: 0.2727
Fold [2/5] Epoch [10/100] Initial Loss: 0.1401, Training Loss: 0.0448, Initial Validation Loss: 0.1382, Validation Loss: 0.0461,V Acc: 0.8108, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.5455
Fold [2/5] Epoch [20/100] Initial Loss: 0.1401, Training Loss: 0.0256, Initial Validation Loss: 0.1382, Validation Loss: 0.0257,V Acc: 0.9009, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.7273
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.9615384615384616
Fold [3/5] Epoch [0/100] Initial Loss: 0.1398, Training Loss: 0.1398, Initial Validation Loss: 0.1318, Validation Loss: 0.1318,V Acc: 0.3091, Top 70th Acc: 0.3766, Bottom 30th Acc: 0.1515
Fold [3/5] Epoch [10/100] Initial Loss: 0.1398, Training Loss: 0.0353, Initial Validation Loss: 0.1318, Validation Loss: 0.0393,V Acc: 0.8455, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6061
Fold [3/5] Epoch [20/100] Initial Loss: 0.1398, Training Loss: 0.0226, Initial Validation Loss: 0.1318, Validation Loss: 0.0321,V Acc: 0.8273, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.5152
Stopping early at Epoch (base 0): 27  Rolling back to Epoch (base 0): 22  Top Validation Acc: 0.948051948051948
Fold [4/5] Epoch [0/100] Initial Loss: 0.1398, Training Loss: 0.1398, Initial Validation Loss: 0.1309, Validation Loss: 0.1309,V Acc: 0.2477, Top 70th Acc: 0.3247, Bottom 30th Acc: 0.0625
Fold [4/5] Epoch [10/100] Initial Loss: 0.1398, Training Loss: 0.0304, Initial Validation Loss: 0.1309, Validation Loss: 0.0399,V Acc: 0.7890, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.5000
Stopping early at Epoch (base 0): 18  Rolling back to Epoch (base 0): 13  Top Validation Acc: 0.922077922077922
Fold [5/5] Epoch [0/100] Initial Loss: 0.1394, Training Loss: 0.1394, Initial Validation Loss: 0.1307, Validation Loss: 0.1307,V Acc: 0.3796, Top 70th Acc: 0.3816, Bottom 30th Acc: 0.3750
Fold [5/5] Epoch [10/100] Initial Loss: 0.1394, Training Loss: 0.0369, Initial Validation Loss: 0.1307, Validation Loss: 0.0406,V Acc: 0.8241, Top 70th Acc: 0.9079, Bottom 30th Acc: 0.6250/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)

Fold [4/5] Epoch [20/100] Initial Loss: 0.1369, Training Loss: 0.0823, Initial Validation Loss: 0.1226, Validation Loss: 0.0673,V Acc: 0.6697, Top 70th Acc: 0.7922, Bottom 30th Acc: 0.3750
Fold [4/5] Epoch [30/100] Initial Loss: 0.1369, Training Loss: 0.0818, Initial Validation Loss: 0.1226, Validation Loss: 0.0664,V Acc: 0.6697, Top 70th Acc: 0.7922, Bottom 30th Acc: 0.3750
Fold [4/5] Epoch [40/100] Initial Loss: 0.1369, Training Loss: 0.0817, Initial Validation Loss: 0.1226, Validation Loss: 0.0655,V Acc: 0.6789, Top 70th Acc: 0.8312, Bottom 30th Acc: 0.3125
Stopping early at Epoch (base 0): 45  Rolling back to Epoch (base 0): 40  Top Validation Acc: 0.7922077922077922
Fold [5/5] Epoch [0/100] Initial Loss: 0.1330, Training Loss: 0.1330, Initial Validation Loss: 0.1185, Validation Loss: 0.1185,V Acc: 0.3796, Top 70th Acc: 0.4079, Bottom 30th Acc: 0.3125
Fold [5/5] Epoch [10/100] Initial Loss: 0.1330, Training Loss: 0.0802, Initial Validation Loss: 0.1185, Validation Loss: 0.0767,V Acc: 0.6111, Top 70th Acc: 0.7500, Bottom 30th Acc: 0.2812
Fold [5/5] Epoch [20/100] Initial Loss: 0.1330, Training Loss: 0.0785, Initial Validation Loss: 0.1185, Validation Loss: 0.0766,V Acc: 0.6019, Top 70th Acc: 0.7368, Bottom 30th Acc: 0.2812
Stopping early at Epoch (base 0): 22  Rolling back to Epoch (base 0): 17  Top Validation Acc: 0.7368421052631579
42 4 [array([0.15047264, 0.3594712 , 0.14043984, 0.21995795, 0.12965831],
      dtype=float32)]
Running train_nn.py with seed 43
CUDA:False
Training samples count:  550
Training on 2 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1382, Training Loss: 0.1382, Initial Validation Loss: 0.1320, Validation Loss: 0.1320,V Acc: 0.4464, Top 70th Acc: 0.5063, Bottom 30th Acc: 0.3030
Fold [1/5] Epoch [10/100] Initial Loss: 0.1382, Training Loss: 0.0804, Initial Validation Loss: 0.1320, Validation Loss: 0.0825,V Acc: 0.6161, Top 70th Acc: 0.7089, Bottom 30th Acc: 0.3939
Fold [1/5] Epoch [20/100] Initial Loss: 0.1382, Training Loss: 0.0782, Initial Validation Loss: 0.1320, Validation Loss: 0.0813,V Acc: 0.6339, Top 70th Acc: 0.7342, Bottom 30th Acc: 0.3939
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.7215189873417721
Fold [2/5] Epoch [0/100] Initial Loss: 0.1321, Training Loss: 0.1321, Initial Validation Loss: 0.1146, Validation Loss: 0.1146,V Acc: 0.5315, Top 70th Acc: 0.6282, Bottom 30th Acc: 0.3030
Fold [2/5] Epoch [10/100] Initial Loss: 0.1321, Training Loss: 0.0816, Initial Validation Loss: 0.1146, Validation Loss: 0.0738,V Acc: 0.6036, Top 70th Acc: 0.7564, Bottom 30th Acc: 0.2424
Fold [2/5] Epoch [20/100] Initial Loss: 0.1321, Training Loss: 0.0802, Initial Validation Loss: 0.1146, Validation Loss: 0.0732,V Acc: 0.6216, Top 70th Acc: 0.7436, Bottom 30th Acc: 0.3333
Stopping early at Epoch (base 0): 22  Rolling back to Epoch (base 0): 17  Top Validation Acc: 0.7435897435897436
43 1 [array([0.11542942, 0.3864029 , 0.13274395, 0.21598348, 0.14944023],
      dtype=float32)]
Fold [3/5] Epoch [0/100] Initial Loss: 0.1313, Training Loss: 0.1313, Initial Validation Loss: 0.1180, Validation Loss: 0.1180,V Acc: 0.4909, Top 70th Acc: 0.5974, Bottom 30th Acc: 0.2424
Fold [3/5] Epoch [10/100] Initial Loss: 0.1313, Training Loss: 0.0810, Initial Validation Loss: 0.1180, Validation Loss: 0.0734,V Acc: 0.7000, Top 70th Acc: 0.7792, Bottom 30th Acc: 0.5152
Fold [3/5] Epoch [20/100] Initial Loss: 0.1313, Training Loss: 0.0792, Initial Validation Loss: 0.1180, Validation Loss: 0.0712,V Acc: 0.7182, Top 70th Acc: 0.7922, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.7922077922077922
Fold [4/5] Epoch [0/100] Initial Loss: 0.1402, Training Loss: 0.1402, Initial Validation Loss: 0.1339, Validation Loss: 0.1339,V Acc: 0.3578, Top 70th Acc: 0.3117, Bottom 30th Acc: 0.4688
Fold [4/5] Epoch [10/100] Initial Loss: 0.1402, Training Loss: 0.0800, Initial Validation Loss: 0.1339, Validation Loss: 0.0841,V Acc: 0.6239, Top 70th Acc: 0.7143, Bottom 30th Acc: 0.4062
Fold [4/5] Epoch [20/100] Initial Loss: 0.1402, Training Loss: 0.0779, Initial Validation Loss: 0.1339, Validation Loss: 0.0823,V Acc: 0.6239, Top 70th Acc: 0.7143, Bottom 30th Acc: 0.4062
Fold [4/5] Epoch [30/100] Initial Loss: 0.1402, Training Loss: 0.0769, Initial Validation Loss: 0.1339, Validation Loss: 0.0816,V Acc: 0.6330, Top 70th Acc: 0.7013, Bottom 30th Acc: 0.4688
Stopping early at Epoch (base 0): 35  Rolling back to Epoch (base 0): 30  Top Validation Acc: 0.7142857142857143
Fold [5/5] Epoch [0/100] Initial Loss: 0.1338, Training Loss: 0.1338, Initial Validation Loss: 0.1203, Validation Loss: 0.1203,V Acc: 0.4537, Top 70th Acc: 0.5000, Bottom 30th Acc: 0.3438
Fold [5/5] Epoch [10/100] Initial Loss: 0.1338, Training Loss: 0.0788, Initial Validation Loss: 0.1203, Validation Loss: 0.0823,V Acc: 0.5833, Top 70th Acc: 0.7105, Bottom 30th Acc: 0.2812
Fold [5/5] Epoch [20/100] Initial Loss: 0.1338, Training Loss: 0.0771, Initial Validation Loss: 0.1203, Validation Loss: 0.0817,V Acc: 0.5648, Top 70th Acc: 0.7368, Bottom 30th Acc: 0.1562
Fold [5/5] Epoch [30/100] Initial Loss: 0.1338, Training Loss: 0.0763, Initial Validation Loss: 0.1203, Validation Loss: 0.0811,V Acc: 0.5741, Top 70th Acc: 0.7368, Bottom 30th Acc: 0.1875
Stopping early at Epoch (base 0): 35  Rolling back to Epoch (base 0): 30  Top Validation Acc: 0.7368421052631579
Running train_nn.py with seed 44
CUDA:False
Training samples count:  550
Training on 2 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1410, Training Loss: 0.1410, Initial Validation Loss: 0.1320, Validation Loss: 0.1320,V Acc: 0.2857, Top 70th Acc: 0.3418, Bottom 30th Acc: 0.1515
Fold [1/5] Epoch [10/100] Initial Loss: 0.1410, Training Loss: 0.0837, Initial Validation Loss: 0.1320, Validation Loss: 0.0738,V Acc: 0.6696, Top 70th Acc: 0.7595, Bottom 30th Acc: 0.4545
Fold [1/5] Epoch [20/100] Initial Loss: 0.1410, Training Loss: 0.0817, Initial Validation Loss: 0.1320, Validation Loss: 0.0703,V Acc: 0.6696, Top 70th Acc: 0.7722, Bottom 30th Acc: 0.4242
Stopping early at Epoch (base 0): 27  Rolling back to Epoch (base 0): 22  Top Validation Acc: 0.759493670886076
44 0 [array([0.12068696, 0.32151455, 0.17089577, 0.21844138, 0.16846126],
      dtype=float32)]
Fold [2/5] Epoch [0/100] Initial Loss: 0.1378, Training Loss: 0.1378, Initial Validation Loss: 0.1356, Validation Loss: 0.1356,V Acc: 0.3784, Top 70th Acc: 0.5128, Bottom 30th Acc: 0.0606
Fold [2/5] Epoch [10/100] Initial Loss: 0.1378, Training Loss: 0.0789, Initial Validation Loss: 0.1356, Validation Loss: 0.0891,V Acc: 0.5766, Top 70th Acc: 0.6923, Bottom 30th Acc: 0.3030
Fold [2/5] Epoch [20/100] Initial Loss: 0.1378, Training Loss: 0.0765, Initial Validation Loss: 0.1356, Validation Loss: 0.0880,V Acc: 0.6126, Top 70th Acc: 0.6667, Bottom 30th Acc: 0.4848
Stopping early at Epoch (base 0): 28  Rolling back to Epoch (base 0): 23  Top Validation Acc: 0.6666666666666666
Fold [3/5] Epoch [0/100] Initial Loss: 0.1359, Training Loss: 0.1359, Initial Validation Loss: 0.1260, Validation Loss: 0.1260,V Acc: 0.3182, Top 70th Acc: 0.3636, Bottom 30th Acc: 0.2121
Fold [3/5] Epoch [10/100] Initial Loss: 0.1359, Training Loss: 0.0795, Initial Validation Loss: 0.1260, Validation Loss: 0.0829,V Acc: 0.6182, Top 70th Acc: 0.7273, Bottom 30th Acc: 0.3636
Fold [3/5] Epoch [20/100] Initial Loss: 0.1359, Training Loss: 0.0778, Initial Validation Loss: 0.1260, Validation Loss: 0.0814,V Acc: 0.5909, Top 70th Acc: 0.7532, Bottom 30th Acc: 0.2121
Fold [3/5] Epoch [30/100] Initial Loss: 0.1359, Training Loss: 0.0776, Initial Validation Loss: 0.1260, Validation Loss: 0.0811,V Acc: 0.6000, Top 70th Acc: 0.7532, Bottom 30th Acc: 0.2424
Stopping early at Epoch (base 0): 32  Rolling back to Epoch (base 0): 27  Top Validation Acc: 0.7532467532467533
Fold [4/5] Epoch [0/100] Initial Loss: 0.1416, Training Loss: 0.1416, Initial Validation Loss: 0.1328, Validation Loss: 0.1328,V Acc: 0.2294, Top 70th Acc: 0.2987, Bottom 30th Acc: 0.0625
Fold [4/5] Epoch [10/100] Initial Loss: 0.1416, Training Loss: 0.0832, Initial Validation Loss: 0.1328, Validation Loss: 0.0835,V Acc: 0.5688, Top 70th Acc: 0.6883, Bottom 30th Acc: 0.2812
Fold [1/5] Epoch [20/100] Initial Loss: 0.1383, Training Loss: 0.0178, Initial Validation Loss: 0.1352, Validation Loss: 0.0304,V Acc: 0.8661, Top 70th Acc: 0.9241, Bottom 30th Acc: 0.7273
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.9367088607594937
Fold [2/5] Epoch [0/100] Initial Loss: 0.1392, Training Loss: 0.1392, Initial Validation Loss: 0.1324, Validation Loss: 0.1324,V Acc: 0.3333, Top 70th Acc: 0.3590, Bottom 30th Acc: 0.2727
Fold [2/5] Epoch [10/100] Initial Loss: 0.1392, Training Loss: 0.0349, Initial Validation Loss: 0.1324, Validation Loss: 0.0432,V Acc: 0.7838, Top 70th Acc: 0.8974, Bottom 30th Acc: 0.5152
Fold [2/5] Epoch [20/100] Initial Loss: 0.1392, Training Loss: 0.0188, Initial Validation Loss: 0.1324, Validation Loss: 0.0358,V Acc: 0.8018, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.5455
Fold [2/5] Epoch [30/100] Initial Loss: 0.1392, Training Loss: 0.0159, Initial Validation Loss: 0.1324, Validation Loss: 0.0332,V Acc: 0.8198, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.5152
Fold [2/5] Epoch [40/100] Initial Loss: 0.1392, Training Loss: 0.0147, Initial Validation Loss: 0.1324, Validation Loss: 0.0326,V Acc: 0.8288, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 47  Rolling back to Epoch (base 0): 42  Top Validation Acc: 0.9487179487179487
43 1 [array([0.8026612 , 0.07846846, 0.01391385, 0.05087951, 0.05407688],
      dtype=float32)]
Fold [3/5] Epoch [0/100] Initial Loss: 0.1398, Training Loss: 0.1398, Initial Validation Loss: 0.1372, Validation Loss: 0.1372,V Acc: 0.3545, Top 70th Acc: 0.3766, Bottom 30th Acc: 0.3030
Fold [3/5] Epoch [10/100] Initial Loss: 0.1398, Training Loss: 0.0309, Initial Validation Loss: 0.1372, Validation Loss: 0.0328,V Acc: 0.8909, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 18  Rolling back to Epoch (base 0): 13  Top Validation Acc: 0.948051948051948
Fold [4/5] Epoch [0/100] Initial Loss: 0.1391, Training Loss: 0.1391, Initial Validation Loss: 0.1364, Validation Loss: 0.1364,V Acc: 0.2477, Top 70th Acc: 0.2987, Bottom 30th Acc: 0.1250
Fold [4/5] Epoch [10/100] Initial Loss: 0.1391, Training Loss: 0.0340, Initial Validation Loss: 0.1364, Validation Loss: 0.0322,V Acc: 0.8899, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.6875
Fold [4/5] Epoch [20/100] Initial Loss: 0.1391, Training Loss: 0.0190, Initial Validation Loss: 0.1364, Validation Loss: 0.0247,V Acc: 0.8899, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.6875
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.974025974025974
Fold [5/5] Epoch [0/100] Initial Loss: 0.1397, Training Loss: 0.1397, Initial Validation Loss: 0.1281, Validation Loss: 0.1281,V Acc: 0.3889, Top 70th Acc: 0.5000, Bottom 30th Acc: 0.1250
Fold [5/5] Epoch [10/100] Initial Loss: 0.1397, Training Loss: 0.0263, Initial Validation Loss: 0.1281, Validation Loss: 0.0340,V Acc: 0.8426, Top 70th Acc: 0.8947, Bottom 30th Acc: 0.7188
Fold [5/5] Epoch [20/100] Initial Loss: 0.1397, Training Loss: 0.0179, Initial Validation Loss: 0.1281, Validation Loss: 0.0291,V Acc: 0.8333, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.5938
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.9342105263157895
Running train_nn.py with seed 44
CUDA:False
Training samples count:  550
Training on 30 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1371, Training Loss: 0.1371, Initial Validation Loss: 0.1329, Validation Loss: 0.1329,V Acc: 0.2946, Top 70th Acc: 0.3544, Bottom 30th Acc: 0.1515
Fold [1/5] Epoch [10/100] Initial Loss: 0.1371, Training Loss: 0.0294, Initial Validation Loss: 0.1329, Validation Loss: 0.0304,V Acc: 0.8304, Top 70th Acc: 0.9620, Bottom 30th Acc: 0.5152
Fold [1/5] Epoch [20/100] Initial Loss: 0.1371, Training Loss: 0.0189, Initial Validation Loss: 0.1329, Validation Loss: 0.0321,V Acc: 0.8036, Top 70th Acc: 0.9620, Bottom 30th Acc: 0.4242
Stopping early at Epoch (base 0): 21  Rolling back to Epoch (base 0): 16  Top Validation Acc: 0.9367088607594937
44 0 [array([0.59117794, 0.12406633, 0.07329351, 0.08802491, 0.12343732],
      dtype=float32)]
Fold [2/5] Epoch [0/100] Initial Loss: 0.1375, Training Loss: 0.1375, Initial Validation Loss: 0.1343, Validation Loss: 0.1343,V Acc: 0.4324, Top 70th Acc: 0.5000, Bottom 30th Acc: 0.2727
Fold [2/5] Epoch [10/100] Initial Loss: 0.1375, Training Loss: 0.0395, Initial Validation Loss: 0.1343, Validation Loss: 0.0459,V Acc: 0.7928, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.5152
Fold [2/5] Epoch [20/100] Initial Loss: 0.1375, Training Loss: 0.0281, Initial Validation Loss: 0.1343, Validation Loss: 0.0379,V Acc: 0.8108, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.4545
Fold [2/5] Epoch [30/100] Initial Loss: 0.1375, Training Loss: 0.0228, Initial Validation Loss: 0.1343, Validation Loss: 0.0321,V Acc: 0.8378, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.5455
Fold [2/5] Epoch [40/100] Initial Loss: 0.1375, Training Loss: 0.0198, Initial Validation Loss: 0.1343, Validation Loss: 0.0300,V Acc: 0.8378, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.5152
Stopping early at Epoch (base 0): 47  Rolling back to Epoch (base 0): 42  Top Validation Acc: 0.9615384615384616
Fold [3/5] Epoch [0/100] Initial Loss: 0.1410, Training Loss: 0.1410, Initial Validation Loss: 0.1334, Validation Loss: 0.1334,V Acc: 0.3273, Top 70th Acc: 0.3636, Bottom 30th Acc: 0.2424
Fold [3/5] Epoch [10/100] Initial Loss: 0.1410, Training Loss: 0.0334, Initial Validation Loss: 0.1334, Validation Loss: 0.0368,V Acc: 0.8364, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.5455
Fold [3/5] Epoch [20/100] Initial Loss: 0.1410, Training Loss: 0.0190, Initial Validation Loss: 0.1334, Validation Loss: 0.0325,V Acc: 0.8364, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.961038961038961
Fold [4/5] Epoch [0/100] Initial Loss: 0.1399, Training Loss: 0.1399, Initial Validation Loss: 0.1287, Validation Loss: 0.1287,V Acc: 0.3761, Top 70th Acc: 0.4416, Bottom 30th Acc: 0.2188
Fold [4/5] Epoch [10/100] Initial Loss: 0.1399, Training Loss: 0.0334, Initial Validation Loss: 0.1287, Validation Loss: 0.0451,V Acc: 0.7615, Top 70th Acc: 0.8961, Bottom 30th Acc: 0.4375
Fold [4/5] Epoch [20/100] Initial Loss: 0.1399, Training Loss: 0.0199, Initial Validation Loss: 0.1287, Validation Loss: 0.0377,V Acc: 0.7890, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.4375
Fold [4/5] Epoch [30/100] Initial Loss: 0.1399, Training Loss: 0.0169, Initial Validation Loss: 0.1287, Validation Loss: 0.0361,V Acc: 0.7890, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.4688
Fold [4/5] Epoch [40/100] Initial Loss: 0.1399, Training Loss: 0.0154, Initial Validation Loss: 0.1287, Validation Loss: 0.0352,V Acc: 0.8073, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.5625
Stopping early at Epoch (base 0): 48  Rolling back to Epoch (base 0): 43  Top Validation Acc: 0.922077922077922
Fold [5/5] Epoch [0/100] Initial Loss: 0.1389, Training Loss: 0.1389, Initial Validation Loss: 0.1286, Validation Loss: 0.1286,V Acc: 0.3796, Top 70th Acc: 0.3684, Bottom 30th Acc: 0.4062
Fold [5/5] Epoch [10/100] Initial Loss: 0.1389, Training Loss: 0.0319, Initial Validation Loss: 0.1286, Validation Loss: 0.0357,V Acc: 0.8611, Top 70th Acc: 0.9211, Bottom 30th Acc: 0.7188
Fold [5/5] Epoch [20/100] Initial Loss: 0.1389, Training Loss: 0.0192, Initial Validation Loss: 0.1286, Validation Loss: 0.0314,V Acc: 0.8426, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.5938
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.9473684210526315
Running train_nn.py with seed 45
CUDA:False
Training samples count:  550
Training on 30 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1368, Training Loss: 0.1368, Initial Validation Loss: 0.1361, Validation Loss: 0.1361,V Acc: 0.2857, Top 70th Acc: 0.3418, Bottom 30th Acc: 0.1515
Fold [1/5] Epoch [10/100] Initial Loss: 0.1368, Training Loss: 0.0332, Initial Validation Loss: 0.1361, Validation Loss: 0.0395,V Acc: 0.8304, Top 70th Acc: 0.9241, Bottom 30th Acc: 0.6061
Fold [1/5] Epoch [20/100] Initial Loss: 0.1368, Training Loss: 0.0185, Initial Validation Loss: 0.1361, Validation Loss: 0.0258,V Acc: 0.8929, Top 70th Acc: 0.9620, Bottom 30th Acc: 0.7273 21  Rolling back to Epoch (base 0): 16  Top Validation Acc: 0.9620253164556962
Fold [2/5] Epoch [0/100] Initial Loss: 0.1365, Training Loss: 0.1365, Initial Validation Loss: 0.1261, Validation Loss: 0.1261,V Acc: 0.4324, Top 70th Acc: 0.5000, Bottom 30th Acc: 0.2727
Fold [2/5] Epoch [10/100] Initial Loss: 0.1365, Training Loss: 0.0202, Initial Validation Loss: 0.1261, Validation Loss: 0.0273,V Acc: 0.8378, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.5455
Fold [2/5] Epoch [20/100] Initial Loss: 0.1365, Training Loss: 0.0153, Initial Validation Loss: 0.1261, Validation Loss: 0.0260,V Acc: 0.8649, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 20  Rolling back to Epoch (base 0): 15  Top Validation Acc: 0.9487179487179487
Fold [3/5] Epoch [0/100] Initial Loss: 0.1323, Training Loss: 0.1323, Initial Validation Loss: 0.1119, Validation Loss: 0.1119,V Acc: 0.5636, Top 70th Acc: 0.7143, Bottom 30th Acc: 0.2121
Fold [3/5] Epoch [10/100] Initial Loss: 0.1323, Training Loss: 0.0189, Initial Validation Loss: 0.1119, Validation Loss: 0.0318,V Acc: 0.8818, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 16  Rolling back to Epoch (base 0): 11  Top Validation Acc: 0.987012987012987
Fold [4/5] Epoch [0/100] Initial Loss: 0.1338, Training Loss: 0.1338, Initial Validation Loss: 0.1239, Validation Loss: 0.1239,V Acc: 0.4587, Top 70th Acc: 0.5455, Bottom 30th Acc: 0.2500
Fold [4/5] Epoch [10/100] Initial Loss: 0.1338, Training Loss: 0.0253, Initial Validation Loss: 0.1239, Validation Loss: 0.0292,V Acc: 0.8899, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.7188
Fold [4/5] Epoch [20/100] Initial Loss: 0.1338, Training Loss: 0.0179, Initial Validation Loss: 0.1239, Validation Loss: 0.0292,V Acc: 0.8899, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.6875
Stopping early at Epoch (base 0): 29  Rolling back to Epoch (base 0): 24  Top Validation Acc: 0.974025974025974
Fold [5/5] Epoch [0/100] Initial Loss: 0.1309, Training Loss: 0.1309, Initial Validation Loss: 0.1147, Validation Loss: 0.1147,V Acc: 0.4167, Top 70th Acc: 0.4868, Bottom 30th Acc: 0.2500
Fold [5/5] Epoch [10/100] Initial Loss: 0.1309, Training Loss: 0.0222, Initial Validation Loss: 0.1147, Validation Loss: 0.0269,V Acc: 0.8796, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.6875
Stopping early at Epoch (base 0): 17  Rolling back to Epoch (base 0): 12  Top Validation Acc: 1.0
60 4 [array([0.8418725 , 0.01093053, 0.03738603, 0.06287525, 0.04693566],
      dtype=float32)]
Running train_nn.py with seed 61
CUDA:False
Training samples count:  550
Training on 21 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1304, Training Loss: 0.1304, Initial Validation Loss: 0.1164, Validation Loss: 0.1164,V Acc: 0.4107, Top 70th Acc: 0.5570, Bottom 30th Acc: 0.0606
Fold [1/5] Epoch [10/100] Initial Loss: 0.1304, Training Loss: 0.0195, Initial Validation Loss: 0.1164, Validation Loss: 0.0327,V Acc: 0.8214, Top 70th Acc: 0.9494, Bottom 30th Acc: 0.5152
Fold [1/5] Epoch [20/100] Initial Loss: 0.1304, Training Loss: 0.0141, Initial Validation Loss: 0.1164, Validation Loss: 0.0294,V Acc: 0.8661, Top 70th Acc: 0.9241, Bottom 30th Acc: 0.7273
Stopping early at Epoch (base 0): 20  Rolling back to Epoch (base 0): 15  Top Validation Acc: 0.9240506329113924
Fold [2/5] Epoch [0/100] Initial Loss: 0.1426, Training Loss: 0.1426, Initial Validation Loss: 0.1283, Validation Loss: 0.1283,V Acc: 0.4144, Top 70th Acc: 0.5513, Bottom 30th Acc: 0.0909
Fold [2/5] Epoch [10/100] Initial Loss: 0.1426, Training Loss: 0.0225, Initial Validation Loss: 0.1283, Validation Loss: 0.0313,V Acc: 0.8739, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 16  Rolling back to Epoch (base 0): 11  Top Validation Acc: 0.9358974358974359
Fold [3/5] Epoch [0/100] Initial Loss: 0.1353, Training Loss: 0.1353, Initial Validation Loss: 0.1166, Validation Loss: 0.1166,V Acc: 0.5455, Top 70th Acc: 0.6364, Bottom 30th Acc: 0.3333
Fold [3/5] Epoch [10/100] Initial Loss: 0.1353, Training Loss: 0.0258, Initial Validation Loss: 0.1166, Validation Loss: 0.0364,V Acc: 0.8364, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.6061
Fold [3/5] Epoch [20/100] Initial Loss: 0.1353, Training Loss: 0.0156, Initial Validation Loss: 0.1166, Validation Loss: 0.0237,V Acc: 0.8818, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 21  Rolling back to Epoch (base 0): 16  Top Validation Acc: 0.974025974025974
61 2 [array([0.7864214 , 0.0055467 , 0.026993  , 0.10026032, 0.08077853],
      dtype=float32)]
Fold [4/5] Epoch [0/100] Initial Loss: 0.1339, Training Loss: 0.1339, Initial Validation Loss: 0.1176, Validation Loss: 0.1176,V Acc: 0.4220, Top 70th Acc: 0.5195, Bottom 30th Acc: 0.1875
Fold [4/5] Epoch [10/100] Initial Loss: 0.1339, Training Loss: 0.0240, Initial Validation Loss: 0.1176, Validation Loss: 0.0245,V Acc: 0.8899, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.6875
Stopping early at Epoch (base 0): 17  Rolling back to Epoch (base 0): 12  Top Validation Acc: 0.974025974025974
Fold [5/5] Epoch [0/100] Initial Loss: 0.1343, Training Loss: 0.1343, Initial Validation Loss: 0.1206, Validation Loss: 0.1206,V Acc: 0.5093, Top 70th Acc: 0.5789, Bottom 30th Acc: 0.3438
Fold [5/5] Epoch [10/100] Initial Loss: 0.1343, Training Loss: 0.0221, Initial Validation Loss: 0.1206, Validation Loss: 0.0328,V Acc: 0.8241, Top 70th Acc: 0.9737, Bottom 30th Acc: 0.4688
Stopping early at Epoch (base 0): 13  Rolling back to Epoch (base 0): 8  Top Validation Acc: 0.9736842105263158
Running train_nn.py with seed 62
CUDA:False
Training samples count:  550
Training on 21 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1275, Training Loss: 0.1275, Initial Validation Loss: 0.1184, Validation Loss: 0.1184,V Acc: 0.4554, Top 70th Acc: 0.5443, Bottom 30th Acc: 0.2424
Fold [1/5] Epoch [10/100] Initial Loss: 0.1275, Training Loss: 0.0272, Initial Validation Loss: 0.1184, Validation Loss: 0.0229,V Acc: 0.9107, Top 70th Acc: 0.9873, Bottom 30th Acc: 0.7273
Fold [1/5] Epoch [20/100] Initial Loss: 0.1275, Training Loss: 0.0182, Initial Validation Loss: 0.1184, Validation Loss: 0.0145,V Acc: 0.9286, Top 70th Acc: 0.9873, Bottom 30th Acc: 0.7879
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.9873417721518988
Fold [2/5] Epoch [0/100] Initial Loss: 0.1332, Training Loss: 0.1332, Initial Validation Loss: 0.1223, Validation Loss: 0.1223,V Acc: 0.4685, Top 70th Acc: 0.5513, Bottom 30th Acc: 0.2727
Fold [2/5] Epoch [10/100] Initial Loss: 0.1332, Training Loss: 0.0223, Initial Validation Loss: 0.1223, Validation Loss: 0.0317,V Acc: 0.8468, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.6061
Fold [2/5] Epoch [20/100] Initial Loss: 0.1332, Training Loss: 0.0163, Initial Validation Loss: 0.1223, Validation Loss: 0.0302,V Acc: 0.8378, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 21  Rolling back to Epoch (base 0): 16  Top Validation Acc: 0.9615384615384616
Fold [3/5] Epoch [0/100] Initial Loss: 0.1319, Training Loss: 0.1319, Initial Validation Loss: 0.1219, Validation Loss: 0.1219,V Acc: 0.4091, Top 70th Acc: 0.5195, Bottom 30th Acc: 0.1515
Fold [3/5] Epoch [10/100] Initial Loss: 0.1319, Training Loss: 0.0221, Initial Validation Loss: 0.1219, Validation Loss: 0.0352,V Acc: 0.8273, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 18  Rolling back to Epoch (base 0): 13  Top Validation Acc: 0.948051948051948
Fold [4/5] Epoch [0/100] Initial Loss: 0.1395, Training Loss: 0.1395, Initial Validation Loss: 0.1320, Validation Loss: 0.1320,V Acc: 0.3394, Top 70th Acc: 0.3766, Bottom 30th Acc: 0.2500
Fold [4/5] Epoch [10/100] Initial Loss: 0.1395, Training Loss: 0.0265, Initial Validation Loss: 0.1320, Validation Loss: 0.0363,V Acc: 0.8440, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.5312
Fold [4/5] Epoch [20/100] Initial Loss: 0.1395, Training Loss: 0.0163, Initial Validation Loss: 0.1320, Validation Loss: 0.0266,V Acc: 0.8532, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.5938
Fold [4/5] Epoch [30/100] Initial Loss: 0.1395, Training Loss: 0.0132, Initial Validation Loss: 0.1320, Validation Loss: 0.0269,V Acc: 0.8716, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6875
Fold [3/5] Epoch [20/100] Initial Loss: 0.1395, Training Loss: 0.0049, Initial Validation Loss: 0.1368, Validation Loss: 0.0415,V Acc: 0.8000, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.9090909090909091
Fold [4/5] Epoch [0/100] Initial Loss: 0.1397, Training Loss: 0.1397, Initial Validation Loss: 0.1297, Validation Loss: 0.1297,V Acc: 0.3394, Top 70th Acc: 0.4026, Bottom 30th Acc: 0.1875
Fold [4/5] Epoch [10/100] Initial Loss: 0.1397, Training Loss: 0.0242, Initial Validation Loss: 0.1297, Validation Loss: 0.0415,V Acc: 0.8165, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.5938
Fold [4/5] Epoch [20/100] Initial Loss: 0.1397, Training Loss: 0.0052, Initial Validation Loss: 0.1297, Validation Loss: 0.0285,V Acc: 0.8440, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.5312
Fold [4/5] Epoch [30/100] Initial Loss: 0.1397, Training Loss: 0.0039, Initial Validation Loss: 0.1297, Validation Loss: 0.0277,V Acc: 0.8349, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.5000
Fold [4/5] Epoch [40/100] Initial Loss: 0.1397, Training Loss: 0.0037, Initial Validation Loss: 0.1297, Validation Loss: 0.0274,V Acc: 0.8624, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.5938
Stopping early at Epoch (base 0): 41  Rolling back to Epoch (base 0): 36  Top Validation Acc: 0.974025974025974
Fold [5/5] Epoch [0/100] Initial Loss: 0.1393, Training Loss: 0.1393, Initial Validation Loss: 0.1296, Validation Loss: 0.1296,V Acc: 0.3333, Top 70th Acc: 0.3947, Bottom 30th Acc: 0.1875
Fold [5/5] Epoch [10/100] Initial Loss: 0.1393, Training Loss: 0.0274, Initial Validation Loss: 0.1296, Validation Loss: 0.0461,V Acc: 0.7778, Top 70th Acc: 0.8947, Bottom 30th Acc: 0.5000
Fold [5/5] Epoch [20/100] Initial Loss: 0.1393, Training Loss: 0.0054, Initial Validation Loss: 0.1296, Validation Loss: 0.0315,V Acc: 0.8241, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.5312
Fold [5/5] Epoch [30/100] Initial Loss: 0.1393, Training Loss: 0.0040, Initial Validation Loss: 0.1296, Validation Loss: 0.0310,V Acc: 0.8426, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.6250
Stopping early at Epoch (base 0): 31  Rolling back to Epoch (base 0): 26  Top Validation Acc: 0.9473684210526315
Running train_nn.py with seed 35
CUDA:False
Training samples count:  550
Training on 162 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1406, Training Loss: 0.1406, Initial Validation Loss: 0.1343, Validation Loss: 0.1343,V Acc: 0.2589, Top 70th Acc: 0.3418, Bottom 30th Acc: 0.0606
Fold [1/5] Epoch [10/100] Initial Loss: 0.1406, Training Loss: 0.0202, Initial Validation Loss: 0.1343, Validation Loss: 0.0358,V Acc: 0.8304, Top 70th Acc: 0.9620, Bottom 30th Acc: 0.5152
Fold [1/5] Epoch [20/100] Initial Loss: 0.1406, Training Loss: 0.0054, Initial Validation Loss: 0.1343, Validation Loss: 0.0284,V Acc: 0.8482, Top 70th Acc: 0.9494, Bottom 30th Acc: 0.6061
Fold [1/5] Epoch [30/100] Initial Loss: 0.1406, Training Loss: 0.0042, Initial Validation Loss: 0.1343, Validation Loss: 0.0269,V Acc: 0.8482, Top 70th Acc: 0.9620, Bottom 30th Acc: 0.5758
Fold [1/5] Epoch [40/100] Initial Loss: 0.1406, Training Loss: 0.0039, Initial Validation Loss: 0.1343, Validation Loss: 0.0268,V Acc: 0.8482, Top 70th Acc: 0.9747, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 42  Rolling back to Epoch (base 0): 37  Top Validation Acc: 0.9746835443037974
Fold [2/5] Epoch [0/100] Initial Loss: 0.1412, Training Loss: 0.1412, Initial Validation Loss: 0.1341, Validation Loss: 0.1341,V Acc: 0.4234, Top 70th Acc: 0.5256, Bottom 30th Acc: 0.1818
Fold [2/5] Epoch [10/100] Initial Loss: 0.1412, Training Loss: 0.0143, Initial Validation Loss: 0.1341, Validation Loss: 0.0367,V Acc: 0.8378, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.6667
Fold [2/5] Epoch [20/100] Initial Loss: 0.1412, Training Loss: 0.0049, Initial Validation Loss: 0.1341, Validation Loss: 0.0336,V Acc: 0.8288, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.9230769230769231
Fold [3/5] Epoch [0/100] Initial Loss: 0.1376, Training Loss: 0.1376, Initial Validation Loss: 0.1326, Validation Loss: 0.1326,V Acc: 0.3273, Top 70th Acc: 0.4026, Bottom 30th Acc: 0.1515
Fold [3/5] Epoch [10/100] Initial Loss: 0.1376, Training Loss: 0.0226, Initial Validation Loss: 0.1326, Validation Loss: 0.0397,V Acc: 0.8000, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.4848
Fold [3/5] Epoch [20/100] Initial Loss: 0.1376, Training Loss: 0.0055, Initial Validation Loss: 0.1326, Validation Loss: 0.0282,V Acc: 0.8909, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.6970
Fold [3/5] Epoch [30/100] Initial Loss: 0.1376, Training Loss: 0.0041, Initial Validation Loss: 0.1326, Validation Loss: 0.0259,V Acc: 0.8727, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 35  Rolling back to Epoch (base 0): 30  Top Validation Acc: 0.974025974025974
35 2 [array([0.29332814, 0.13297488, 0.05888116, 0.25494045, 0.2598754 ],
      dtype=float32)]
Fold [4/5] Epoch [0/100] Initial Loss: 0.1390, Training Loss: 0.1390, Initial Validation Loss: 0.1331, Validation Loss: 0.1331,V Acc: 0.2477, Top 70th Acc: 0.2727, Bottom 30th Acc: 0.1875
Fold [4/5] Epoch [10/100] Initial Loss: 0.1390, Training Loss: 0.0209, Initial Validation Loss: 0.1331, Validation Loss: 0.0389,V Acc: 0.8073, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.5625
Fold [4/5] Epoch [20/100] Initial Loss: 0.1390, Training Loss: 0.0049, Initial Validation Loss: 0.1331, Validation Loss: 0.0307,V Acc: 0.8257, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.5938
Fold [4/5] Epoch [30/100] Initial Loss: 0.1390, Training Loss: 0.0037, Initial Validation Loss: 0.1331, Validation Loss: 0.0301,V Acc: 0.8440, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.5938
Fold [4/5] Epoch [40/100] Initial Loss: 0.1390, Training Loss: 0.0034, Initial Validation Loss: 0.1331, Validation Loss: 0.0288,V Acc: 0.8532, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.5938
Stopping early at Epoch (base 0): 45  Rolling back to Epoch (base 0): 40  Top Validation Acc: 0.948051948051948
Fold [5/5] Epoch [0/100] Initial Loss: 0.1398, Training Loss: 0.1398, Initial Validation Loss: 0.1344, Validation Loss: 0.1344,V Acc: 0.3148, Top 70th Acc: 0.3947, Bottom 30th Acc: 0.1250
Fold [5/5] Epoch [10/100] Initial Loss: 0.1398, Training Loss: 0.0133, Initial Validation Loss: 0.1344, Validation Loss: 0.0369,V Acc: 0.8241, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.5625
Fold [5/5] Epoch [20/100] Initial Loss: 0.1398, Training Loss: 0.0047, Initial Validation Loss: 0.1344, Validation Loss: 0.0334,V Acc: 0.8611, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.6250
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.9736842105263158
Running train_nn.py with seed 36
CUDA:False
Training samples count:  550
Training on 162 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1401, Training Loss: 0.1401, Initial Validation Loss: 0.1331, Validation Loss: 0.1331,V Acc: 0.4018, Top 70th Acc: 0.4430, Bottom 30th Acc: 0.3030
Fold [1/5] Epoch [10/100] Initial Loss: 0.1401, Training Loss: 0.0138, Initial Validation Loss: 0.1331, Validation Loss: 0.0375,V Acc: 0.8304, Top 70th Acc: 0.9241, Bottom 30th Acc: 0.6061
Fold [1/5] Epoch [20/100] Initial Loss: 0.1401, Training Loss: 0.0053, Initial Validation Loss: 0.1331, Validation Loss: 0.0341,V Acc: 0.8393, Top 70th Acc: 0.9494, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 21  Rolling back to Epoch (base 0): 16  Top Validation Acc: 0.9493670886075949
Fold [2/5] Epoch [0/100] Initial Loss: 0.1370, Training Loss: 0.1370, Initial Validation Loss: 0.1347, Validation Loss: 0.1347,V Acc: 0.2883, Top 70th Acc: 0.3462, Bottom 30th Acc: 0.1515
Fold [2/5] Epoch [10/100] Initial Loss: 0.1370, Training Loss: 0.0231, Initial Validation Loss: 0.1347, Validation Loss: 0.0464,V Acc: 0.8108, Top 70th Acc: 0.8846, Bottom 30th Acc: 0.6364
Fold [2/5] Epoch [20/100] Initial Loss: 0.1370, Training Loss: 0.0050, Initial Validation Loss: 0.1347, Validation Loss: 0.0330,V Acc: 0.8378, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.5758
Fold [2/5] Epoch [30/100] Initial Loss: 0.1370, Training Loss: 0.0039, Initial Validation Loss: 0.1347, Validation Loss: 0.0312,V Acc: 0.8559, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.6061
Fold [1/5] Epoch [10/100] Initial Loss: 0.1354, Training Loss: 0.0317, Initial Validation Loss: 0.1311, Validation Loss: 0.0467,V Acc: 0.7768, Top 70th Acc: 0.8608, Bottom 30th Acc: 0.5758
Fold [1/5] Epoch [20/100] Initial Loss: 0.1354, Training Loss: 0.0142, Initial Validation Loss: 0.1311, Validation Loss: 0.0368,V Acc: 0.8125, Top 70th Acc: 0.9241, Bottom 30th Acc: 0.5455
Fold [1/5] Epoch [30/100] Initial Loss: 0.1354, Training Loss: 0.0110, Initial Validation Loss: 0.1311, Validation Loss: 0.0358,V Acc: 0.8304, Top 70th Acc: 0.9367, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 33  Rolling back to Epoch (base 0): 28  Top Validation Acc: 0.9240506329113924
Fold [2/5] Epoch [0/100] Initial Loss: 0.1421, Training Loss: 0.1421, Initial Validation Loss: 0.1313, Validation Loss: 0.1313,V Acc: 0.3514, Top 70th Acc: 0.3974, Bottom 30th Acc: 0.2424
Fold [2/5] Epoch [10/100] Initial Loss: 0.1421, Training Loss: 0.0293, Initial Validation Loss: 0.1313, Validation Loss: 0.0370,V Acc: 0.8288, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.6061
Fold [2/5] Epoch [20/100] Initial Loss: 0.1421, Training Loss: 0.0146, Initial Validation Loss: 0.1313, Validation Loss: 0.0305,V Acc: 0.8829, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.7273
Fold [2/5] Epoch [30/100] Initial Loss: 0.1421, Training Loss: 0.0113, Initial Validation Loss: 0.1313, Validation Loss: 0.0300,V Acc: 0.8739, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 31  Rolling back to Epoch (base 0): 26  Top Validation Acc: 0.9615384615384616
47 1 [array([0.75918466, 0.0252992 , 0.01764828, 0.07582932, 0.12203849],
      dtype=float32)]
Fold [3/5] Epoch [0/100] Initial Loss: 0.1398, Training Loss: 0.1398, Initial Validation Loss: 0.1335, Validation Loss: 0.1335,V Acc: 0.3000, Top 70th Acc: 0.3636, Bottom 30th Acc: 0.1515
Fold [3/5] Epoch [10/100] Initial Loss: 0.1398, Training Loss: 0.0239, Initial Validation Loss: 0.1335, Validation Loss: 0.0370,V Acc: 0.8182, Top 70th Acc: 0.8961, Bottom 30th Acc: 0.6364
Fold [3/5] Epoch [20/100] Initial Loss: 0.1398, Training Loss: 0.0137, Initial Validation Loss: 0.1335, Validation Loss: 0.0282,V Acc: 0.8818, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.7576
Fold [3/5] Epoch [30/100] Initial Loss: 0.1398, Training Loss: 0.0118, Initial Validation Loss: 0.1335, Validation Loss: 0.0279,V Acc: 0.8818, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.7576
Stopping early at Epoch (base 0): 30  Rolling back to Epoch (base 0): 25  Top Validation Acc: 0.935064935064935
Fold [4/5] Epoch [0/100] Initial Loss: 0.1404, Training Loss: 0.1404, Initial Validation Loss: 0.1358, Validation Loss: 0.1358,V Acc: 0.2477, Top 70th Acc: 0.3377, Bottom 30th Acc: 0.0312
Fold [4/5] Epoch [10/100] Initial Loss: 0.1404, Training Loss: 0.0438, Initial Validation Loss: 0.1358, Validation Loss: 0.0435,V Acc: 0.7798, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.4375
Fold [4/5] Epoch [20/100] Initial Loss: 0.1404, Training Loss: 0.0178, Initial Validation Loss: 0.1358, Validation Loss: 0.0199,V Acc: 0.8899, Top 70th Acc: 0.9870, Bottom 30th Acc: 0.6562
Stopping early at Epoch (base 0): 27  Rolling back to Epoch (base 0): 22  Top Validation Acc: 0.987012987012987
Fold [5/5] Epoch [0/100] Initial Loss: 0.1380, Training Loss: 0.1380, Initial Validation Loss: 0.1353, Validation Loss: 0.1353,V Acc: 0.2500, Top 70th Acc: 0.3289, Bottom 30th Acc: 0.0625
Fold [5/5] Epoch [10/100] Initial Loss: 0.1380, Training Loss: 0.0265, Initial Validation Loss: 0.1353, Validation Loss: 0.0359,V Acc: 0.8148, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.4688
Fold [5/5] Epoch [20/100] Initial Loss: 0.1380, Training Loss: 0.0133, Initial Validation Loss: 0.1353, Validation Loss: 0.0293,V Acc: 0.8241, Top 70th Acc: 0.9737, Bottom 30th Acc: 0.4688
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.9736842105263158
Running train_nn.py with seed 48
CUDA:False
Training samples count:  550
Training on 40 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1396, Training Loss: 0.1396, Initial Validation Loss: 0.1375, Validation Loss: 0.1375,V Acc: 0.3304, Top 70th Acc: 0.3418, Bottom 30th Acc: 0.3030
Fold [1/5] Epoch [10/100] Initial Loss: 0.1396, Training Loss: 0.0422, Initial Validation Loss: 0.1375, Validation Loss: 0.0451,V Acc: 0.8125, Top 70th Acc: 0.8861, Bottom 30th Acc: 0.6364
Fold [1/5] Epoch [20/100] Initial Loss: 0.1396, Training Loss: 0.0153, Initial Validation Loss: 0.1375, Validation Loss: 0.0326,V Acc: 0.8393, Top 70th Acc: 0.9494, Bottom 30th Acc: 0.5758
Fold [1/5] Epoch [30/100] Initial Loss: 0.1396, Training Loss: 0.0118, Initial Validation Loss: 0.1375, Validation Loss: 0.0323,V Acc: 0.8393, Top 70th Acc: 0.9494, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 37  Rolling back to Epoch (base 0): 32  Top Validation Acc: 0.9620253164556962
Fold [2/5] Epoch [0/100] Initial Loss: 0.1384, Training Loss: 0.1384, Initial Validation Loss: 0.1363, Validation Loss: 0.1363,V Acc: 0.2973, Top 70th Acc: 0.3077, Bottom 30th Acc: 0.2727
Fold [2/5] Epoch [10/100] Initial Loss: 0.1384, Training Loss: 0.0260, Initial Validation Loss: 0.1363, Validation Loss: 0.0446,V Acc: 0.8108, Top 70th Acc: 0.8974, Bottom 30th Acc: 0.6061
Fold [2/5] Epoch [20/100] Initial Loss: 0.1384, Training Loss: 0.0125, Initial Validation Loss: 0.1363, Validation Loss: 0.0373,V Acc: 0.7928, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.4242
Stopping early at Epoch (base 0): 29  Rolling back to Epoch (base 0): 24  Top Validation Acc: 0.9230769230769231
48 1 [array([0.76247406, 0.01208894, 0.05288174, 0.11075389, 0.06180139],
      dtype=float32)]
Fold [3/5] Epoch [0/100] Initial Loss: 0.1396, Training Loss: 0.1396, Initial Validation Loss: 0.1321, Validation Loss: 0.1321,V Acc: 0.2636, Top 70th Acc: 0.3506, Bottom 30th Acc: 0.0606
Fold [3/5] Epoch [10/100] Initial Loss: 0.1396, Training Loss: 0.0494, Initial Validation Loss: 0.1321, Validation Loss: 0.0524,V Acc: 0.7455, Top 70th Acc: 0.8571, Bottom 30th Acc: 0.4848
Fold [3/5] Epoch [20/100] Initial Loss: 0.1396, Training Loss: 0.0221, Initial Validation Loss: 0.1321, Validation Loss: 0.0318,V Acc: 0.8636, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.6970
Fold [3/5] Epoch [30/100] Initial Loss: 0.1396, Training Loss: 0.0138, Initial Validation Loss: 0.1321, Validation Loss: 0.0268,V Acc: 0.8545, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 35  Rolling back to Epoch (base 0): 30  Top Validation Acc: 0.974025974025974
Fold [4/5] Epoch [0/100] Initial Loss: 0.1374, Training Loss: 0.1374, Initial Validation Loss: 0.1315, Validation Loss: 0.1315,V Acc: 0.2661, Top 70th Acc: 0.3506, Bottom 30th Acc: 0.0625
Fold [4/5] Epoch [10/100] Initial Loss: 0.1374, Training Loss: 0.0329, Initial Validation Loss: 0.1315, Validation Loss: 0.0359,V Acc: 0.8257, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.6250
Fold [4/5] Epoch [20/100] Initial Loss: 0.1374, Training Loss: 0.0157, Initial Validation Loss: 0.1315, Validation Loss: 0.0302,V Acc: 0.8532, Top 70th Acc: 0.8961, Bottom 30th Acc: 0.7500
Stopping early at Epoch (base 0): 28  Rolling back to Epoch (base 0): 23  Top Validation Acc: 0.935064935064935
Fold [5/5] Epoch [0/100] Initial Loss: 0.1407, Training Loss: 0.1407, Initial Validation Loss: 0.1330, Validation Loss: 0.1330,V Acc: 0.2500, Top 70th Acc: 0.2632, Bottom 30th Acc: 0.2188
Fold [5/5] Epoch [10/100] Initial Loss: 0.1407, Training Loss: 0.0413, Initial Validation Loss: 0.1330, Validation Loss: 0.0441,V Acc: 0.7963, Top 70th Acc: 0.9079, Bottom 30th Acc: 0.5312
Fold [5/5] Epoch [20/100] Initial Loss: 0.1407, Training Loss: 0.0163, Initial Validation Loss: 0.1330, Validation Loss: 0.0265,V Acc: 0.8611, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.6562
Stopping early at Epoch (base 0): 29  Rolling back to Epoch (base 0): 24  Top Validation Acc: 0.9605263157894737
Running train_nn.py with seed 49
CUDA:False
Training samples count:  550
Training on 40 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1401, Training Loss: 0.1401, Initial Validation Loss: 0.1356, Validation Loss: 0.1356,V Acc: 0.2589, Top 70th Acc: 0.3418, Bottom 30th Acc: 0.0606
Fold [1/5] Epoch [10/100] Initial Loss: 0.1401, Training Loss: 0.0282, Initial Validation Loss: 0.1356, Validation Loss: 0.0413,V Acc: 0.7946, Top 70th Acc: 0.9367, Bottom 30th Acc: 0.4545
Fold [5/5] Epoch [20/100] Initial Loss: 0.1394, Training Loss: 0.0223, Initial Validation Loss: 0.1307, Validation Loss: 0.0296,V Acc: 0.8519, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.6562
Fold [5/5] Epoch [30/100] Initial Loss: 0.1394, Training Loss: 0.0199, Initial Validation Loss: 0.1307, Validation Loss: 0.0304,V Acc: 0.8519, Top 70th Acc: 0.9211, Bottom 30th Acc: 0.6875
Stopping early at Epoch (base 0): 33  Rolling back to Epoch (base 0): 28  Top Validation Acc: 0.9342105263157895
Running train_nn.py with seed 45
CUDA:False
Training samples count:  550
Training on 20 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1390, Training Loss: 0.1390, Initial Validation Loss: 0.1373, Validation Loss: 0.1373,V Acc: 0.2946, Top 70th Acc: 0.3418, Bottom 30th Acc: 0.1818
Fold [1/5] Epoch [10/100] Initial Loss: 0.1390, Training Loss: 0.0417, Initial Validation Loss: 0.1373, Validation Loss: 0.0505,V Acc: 0.7857, Top 70th Acc: 0.8608, Bottom 30th Acc: 0.6061
Fold [1/5] Epoch [20/100] Initial Loss: 0.1390, Training Loss: 0.0260, Initial Validation Loss: 0.1373, Validation Loss: 0.0373,V Acc: 0.8393, Top 70th Acc: 0.9241, Bottom 30th Acc: 0.6364
Fold [1/5] Epoch [30/100] Initial Loss: 0.1390, Training Loss: 0.0225, Initial Validation Loss: 0.1373, Validation Loss: 0.0349,V Acc: 0.8661, Top 70th Acc: 0.9241, Bottom 30th Acc: 0.7273
Stopping early at Epoch (base 0): 35  Rolling back to Epoch (base 0): 30  Top Validation Acc: 0.9240506329113924
Fold [2/5] Epoch [0/100] Initial Loss: 0.1433, Training Loss: 0.1433, Initial Validation Loss: 0.1336, Validation Loss: 0.1336,V Acc: 0.3964, Top 70th Acc: 0.4872, Bottom 30th Acc: 0.1818
Fold [2/5] Epoch [10/100] Initial Loss: 0.1433, Training Loss: 0.0334, Initial Validation Loss: 0.1336, Validation Loss: 0.0332,V Acc: 0.8378, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 18  Rolling back to Epoch (base 0): 13  Top Validation Acc: 0.9102564102564102
Fold [3/5] Epoch [0/100] Initial Loss: 0.1404, Training Loss: 0.1404, Initial Validation Loss: 0.1327, Validation Loss: 0.1327,V Acc: 0.2909, Top 70th Acc: 0.3506, Bottom 30th Acc: 0.1515
Fold [3/5] Epoch [10/100] Initial Loss: 0.1404, Training Loss: 0.0357, Initial Validation Loss: 0.1327, Validation Loss: 0.0554,V Acc: 0.7091, Top 70th Acc: 0.8312, Bottom 30th Acc: 0.4242
Fold [3/5] Epoch [20/100] Initial Loss: 0.1404, Training Loss: 0.0225, Initial Validation Loss: 0.1327, Validation Loss: 0.0456,V Acc: 0.7636, Top 70th Acc: 0.8701, Bottom 30th Acc: 0.5152
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.8701298701298701
45 2 [array([0.42637545, 0.1453619 , 0.1303434 , 0.2200725 , 0.07784668],
      dtype=float32)]
Fold [4/5] Epoch [0/100] Initial Loss: 0.1427, Training Loss: 0.1427, Initial Validation Loss: 0.1331, Validation Loss: 0.1331,V Acc: 0.3211, Top 70th Acc: 0.3247, Bottom 30th Acc: 0.3125
Fold [4/5] Epoch [10/100] Initial Loss: 0.1427, Training Loss: 0.0427, Initial Validation Loss: 0.1331, Validation Loss: 0.0405,V Acc: 0.8532, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.6875
Fold [4/5] Epoch [20/100] Initial Loss: 0.1427, Training Loss: 0.0245, Initial Validation Loss: 0.1331, Validation Loss: 0.0300,V Acc: 0.8716, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6875
Fold [4/5] Epoch [30/100] Initial Loss: 0.1427, Training Loss: 0.0223, Initial Validation Loss: 0.1331, Validation Loss: 0.0293,V Acc: 0.8532, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6250
Stopping early at Epoch (base 0): 30  Rolling back to Epoch (base 0): 25  Top Validation Acc: 0.948051948051948
Fold [5/5] Epoch [0/100] Initial Loss: 0.1409, Training Loss: 0.1409, Initial Validation Loss: 0.1309, Validation Loss: 0.1309,V Acc: 0.3148, Top 70th Acc: 0.3553, Bottom 30th Acc: 0.2188
Fold [5/5] Epoch [10/100] Initial Loss: 0.1409, Training Loss: 0.0478, Initial Validation Loss: 0.1309, Validation Loss: 0.0473,V Acc: 0.7407, Top 70th Acc: 0.8947, Bottom 30th Acc: 0.3750
Fold [5/5] Epoch [20/100] Initial Loss: 0.1409, Training Loss: 0.0285, Initial Validation Loss: 0.1309, Validation Loss: 0.0309,V Acc: 0.8704, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.6875
Fold [5/5] Epoch [30/100] Initial Loss: 0.1409, Training Loss: 0.0233, Initial Validation Loss: 0.1309, Validation Loss: 0.0305,V Acc: 0.8611, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.6562
Fold [5/5] Epoch [40/100] Initial Loss: 0.1409, Training Loss: 0.0212, Initial Validation Loss: 0.1309, Validation Loss: 0.0300,V Acc: 0.8796, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.7188
Stopping early at Epoch (base 0): 40  Rolling back to Epoch (base 0): 35  Top Validation Acc: 0.9473684210526315
Running train_nn.py with seed 46
CUDA:False
Training samples count:  550
Training on 20 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1414, Training Loss: 0.1414, Initial Validation Loss: 0.1338, Validation Loss: 0.1338,V Acc: 0.3750, Top 70th Acc: 0.4684, Bottom 30th Acc: 0.1515
Fold [1/5] Epoch [10/100] Initial Loss: 0.1414, Training Loss: 0.0332, Initial Validation Loss: 0.1338, Validation Loss: 0.0371,V Acc: 0.8036, Top 70th Acc: 0.9114, Bottom 30th Acc: 0.5455
Fold [1/5] Epoch [20/100] Initial Loss: 0.1414, Training Loss: 0.0235, Initial Validation Loss: 0.1338, Validation Loss: 0.0331,V Acc: 0.8036, Top 70th Acc: 0.9114, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.9113924050632911
Fold [2/5] Epoch [0/100] Initial Loss: 0.1388, Training Loss: 0.1388, Initial Validation Loss: 0.1352, Validation Loss: 0.1352,V Acc: 0.2793, Top 70th Acc: 0.3077, Bottom 30th Acc: 0.2121
Fold [2/5] Epoch [10/100] Initial Loss: 0.1388, Training Loss: 0.0383, Initial Validation Loss: 0.1352, Validation Loss: 0.0456,V Acc: 0.7658, Top 70th Acc: 0.8974, Bottom 30th Acc: 0.4545
Fold [2/5] Epoch [20/100] Initial Loss: 0.1388, Training Loss: 0.0230, Initial Validation Loss: 0.1352, Validation Loss: 0.0358,V Acc: 0.8108, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 28  Rolling back to Epoch (base 0): 23  Top Validation Acc: 0.9358974358974359
46 1 [array([0.31611907, 0.10230094, 0.15698728, 0.22788209, 0.19671054],
      dtype=float32)]
Fold [3/5] Epoch [0/100] Initial Loss: 0.1397, Training Loss: 0.1397, Initial Validation Loss: 0.1344, Validation Loss: 0.1344,V Acc: 0.2545, Top 70th Acc: 0.3506, Bottom 30th Acc: 0.0303
Fold [3/5] Epoch [10/100] Initial Loss: 0.1397, Training Loss: 0.0460, Initial Validation Loss: 0.1344, Validation Loss: 0.0455,V Acc: 0.8182, Top 70th Acc: 0.8961, Bottom 30th Acc: 0.6364
Fold [3/5] Epoch [20/100] Initial Loss: 0.1397, Training Loss: 0.0255, Initial Validation Loss: 0.1344, Validation Loss: 0.0335,V Acc: 0.8455, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 29  Rolling back to Epoch (base 0): 24  Top Validation Acc: 0.974025974025974
Fold [4/5] Epoch [0/100] Initial Loss: 0.1423, Training Loss: 0.1423, Initial Validation Loss: 0.1301, Validation Loss: 0.1301,V Acc: 0.3578, Top 70th Acc: 0.3247, Bottom 30th Acc: 0.4375
Fold [4/5] Epoch [10/100] Initial Loss: 0.1423, Training Loss: 0.0496, Initial Validation Loss: 0.1301, Validation Loss: 0.0534,V Acc: 0.7523, Top 70th Acc: 0.7792, Bottom 30th Acc: 0.6875
Fold [4/5] Epoch [20/100] Initial Loss: 0.1423, Training Loss: 0.0261, Initial Validation Loss: 0.1301, Validation Loss: 0.0343,V Acc: 0.8440, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.6875
Stopping early at Epoch (base 0): 27  Rolling back to Epoch (base 0): 22  Top Validation Acc: 0.8961038961038961
Fold [5/5] Epoch [0/100] Initial Loss: 0.1405, Training Loss: 0.1405, Initial Validation Loss: 0.1357, Validation Loss: 0.1357,V Acc: 0.2778, Top 70th Acc: 0.2632, Bottom 30th Acc: 0.3125
Fold [5/5] Epoch [10/100] Initial Loss: 0.1405, Training Loss: 0.0452, Initial Validation Loss: 0.1357, Validation Loss: 0.0471,V Acc: 0.8241, Top 70th Acc: 0.9079, Bottom 30th Acc: 0.6250
Fold [5/5] Epoch [20/100] Initial Loss: 0.1405, Training Loss: 0.0248, Initial Validation Loss: 0.1357, Validation Loss: 0.0332,V Acc: 0.8704, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.6875
Stopping early at Epoch (base 0): 27  Rolling back to Epoch (base 0): 22 /home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)

Stopping early at Epoch (base 0): 31  Rolling back to Epoch (base 0): 26  Top Validation Acc: 0.974025974025974
62 3 [array([0.79494643, 0.01811262, 0.01703774, 0.10417075, 0.06573252],
      dtype=float32)]
Fold [5/5] Epoch [0/100] Initial Loss: 0.1330, Training Loss: 0.1330, Initial Validation Loss: 0.1134, Validation Loss: 0.1134,V Acc: 0.4167, Top 70th Acc: 0.4868, Bottom 30th Acc: 0.2500
Fold [5/5] Epoch [10/100] Initial Loss: 0.1330, Training Loss: 0.0273, Initial Validation Loss: 0.1134, Validation Loss: 0.0280,V Acc: 0.8611, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.6250
Fold [5/5] Epoch [20/100] Initial Loss: 0.1330, Training Loss: 0.0183, Initial Validation Loss: 0.1134, Validation Loss: 0.0212,V Acc: 0.8796, Top 70th Acc: 0.9868, Bottom 30th Acc: 0.6250
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.9605263157894737
Running train_nn.py with seed 63
CUDA:False
Training samples count:  550
Training on 21 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1368, Training Loss: 0.1368, Initial Validation Loss: 0.1303, Validation Loss: 0.1303,V Acc: 0.4464, Top 70th Acc: 0.5823, Bottom 30th Acc: 0.1212
Fold [1/5] Epoch [10/100] Initial Loss: 0.1368, Training Loss: 0.0265, Initial Validation Loss: 0.1303, Validation Loss: 0.0333,V Acc: 0.8750, Top 70th Acc: 0.9114, Bottom 30th Acc: 0.7879
Fold [1/5] Epoch [20/100] Initial Loss: 0.1368, Training Loss: 0.0159, Initial Validation Loss: 0.1303, Validation Loss: 0.0220,V Acc: 0.9286, Top 70th Acc: 0.9873, Bottom 30th Acc: 0.7879
Stopping early at Epoch (base 0): 21  Rolling back to Epoch (base 0): 16  Top Validation Acc: 0.9746835443037974
Fold [2/5] Epoch [0/100] Initial Loss: 0.1416, Training Loss: 0.1416, Initial Validation Loss: 0.1372, Validation Loss: 0.1372,V Acc: 0.3153, Top 70th Acc: 0.3333, Bottom 30th Acc: 0.2727
Fold [2/5] Epoch [10/100] Initial Loss: 0.1416, Training Loss: 0.0261, Initial Validation Loss: 0.1372, Validation Loss: 0.0341,V Acc: 0.8288, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.5455
Fold [2/5] Epoch [20/100] Initial Loss: 0.1416, Training Loss: 0.0146, Initial Validation Loss: 0.1372, Validation Loss: 0.0283,V Acc: 0.8649, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 21  Rolling back to Epoch (base 0): 16  Top Validation Acc: 0.9615384615384616
Fold [3/5] Epoch [0/100] Initial Loss: 0.1360, Training Loss: 0.1360, Initial Validation Loss: 0.1214, Validation Loss: 0.1214,V Acc: 0.5091, Top 70th Acc: 0.5974, Bottom 30th Acc: 0.3030
Fold [3/5] Epoch [10/100] Initial Loss: 0.1360, Training Loss: 0.0214, Initial Validation Loss: 0.1214, Validation Loss: 0.0302,V Acc: 0.8364, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.5758
Fold [3/5] Epoch [20/100] Initial Loss: 0.1360, Training Loss: 0.0146, Initial Validation Loss: 0.1214, Validation Loss: 0.0247,V Acc: 0.8455, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.948051948051948
Fold [4/5] Epoch [0/100] Initial Loss: 0.1317, Training Loss: 0.1317, Initial Validation Loss: 0.1117, Validation Loss: 0.1117,V Acc: 0.5229, Top 70th Acc: 0.6623, Bottom 30th Acc: 0.1875
Fold [4/5] Epoch [10/100] Initial Loss: 0.1317, Training Loss: 0.0235, Initial Validation Loss: 0.1117, Validation Loss: 0.0388,V Acc: 0.7798, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.3750
Stopping early at Epoch (base 0): 18  Rolling back to Epoch (base 0): 13  Top Validation Acc: 0.922077922077922
Fold [5/5] Epoch [0/100] Initial Loss: 0.1339, Training Loss: 0.1339, Initial Validation Loss: 0.1238, Validation Loss: 0.1238,V Acc: 0.5648, Top 70th Acc: 0.6842, Bottom 30th Acc: 0.2812
Fold [5/5] Epoch [10/100] Initial Loss: 0.1339, Training Loss: 0.0293, Initial Validation Loss: 0.1238, Validation Loss: 0.0292,V Acc: 0.8981, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.7812
Fold [5/5] Epoch [20/100] Initial Loss: 0.1339, Training Loss: 0.0174, Initial Validation Loss: 0.1238, Validation Loss: 0.0159,V Acc: 0.9352, Top 70th Acc: 1.0000, Bottom 30th Acc: 0.7812
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 1.0
63 4 [array([0.8012799 , 0.01603246, 0.02392957, 0.09125791, 0.06750021],
      dtype=float32)]
Running train_nn.py with seed 64
CUDA:False
Training samples count:  550
Training on 21 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1360, Training Loss: 0.1360, Initial Validation Loss: 0.1220, Validation Loss: 0.1220,V Acc: 0.4554, Top 70th Acc: 0.5063, Bottom 30th Acc: 0.3333
Fold [1/5] Epoch [10/100] Initial Loss: 0.1360, Training Loss: 0.0191, Initial Validation Loss: 0.1220, Validation Loss: 0.0262,V Acc: 0.8929, Top 70th Acc: 0.9494, Bottom 30th Acc: 0.7576
Fold [1/5] Epoch [20/100] Initial Loss: 0.1360, Training Loss: 0.0135, Initial Validation Loss: 0.1220, Validation Loss: 0.0239,V Acc: 0.8839, Top 70th Acc: 0.9494, Bottom 30th Acc: 0.7273
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.9620253164556962
64 0 [array([0.8038468 , 0.02338197, 0.04403374, 0.07925166, 0.0494859 ],
      dtype=float32)]
Fold [2/5] Epoch [0/100] Initial Loss: 0.1354, Training Loss: 0.1354, Initial Validation Loss: 0.1251, Validation Loss: 0.1251,V Acc: 0.4414, Top 70th Acc: 0.5385, Bottom 30th Acc: 0.2121
Fold [2/5] Epoch [10/100] Initial Loss: 0.1354, Training Loss: 0.0207, Initial Validation Loss: 0.1251, Validation Loss: 0.0279,V Acc: 0.8649, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.6061
Fold [2/5] Epoch [20/100] Initial Loss: 0.1354, Training Loss: 0.0141, Initial Validation Loss: 0.1251, Validation Loss: 0.0262,V Acc: 0.8919, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.7576
Stopping early at Epoch (base 0): 28  Rolling back to Epoch (base 0): 23  Top Validation Acc: 0.9871794871794872
Fold [3/5] Epoch [0/100] Initial Loss: 0.1363, Training Loss: 0.1363, Initial Validation Loss: 0.1263, Validation Loss: 0.1263,V Acc: 0.5364, Top 70th Acc: 0.6494, Bottom 30th Acc: 0.2727
Fold [3/5] Epoch [10/100] Initial Loss: 0.1363, Training Loss: 0.0216, Initial Validation Loss: 0.1263, Validation Loss: 0.0308,V Acc: 0.8636, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6667
Fold [3/5] Epoch [20/100] Initial Loss: 0.1363, Training Loss: 0.0161, Initial Validation Loss: 0.1263, Validation Loss: 0.0246,V Acc: 0.8636, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.935064935064935
Fold [4/5] Epoch [0/100] Initial Loss: 0.1384, Training Loss: 0.1384, Initial Validation Loss: 0.1363, Validation Loss: 0.1363,V Acc: 0.4037, Top 70th Acc: 0.3896, Bottom 30th Acc: 0.4375
Fold [4/5] Epoch [10/100] Initial Loss: 0.1384, Training Loss: 0.0299, Initial Validation Loss: 0.1363, Validation Loss: 0.0292,V Acc: 0.8440, Top 70th Acc: 0.9870, Bottom 30th Acc: 0.5000
Fold [4/5] Epoch [20/100] Initial Loss: 0.1384, Training Loss: 0.0192, Initial Validation Loss: 0.1363, Validation Loss: 0.0187,V Acc: 0.9083, Top 70th Acc: 1.0000, Bottom 30th Acc: 0.6875
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.987012987012987
Fold [5/5] Epoch [0/100] Initial Loss: 0.1400, Training Loss: 0.1400, Initial Validation Loss: 0.1296, Validation Loss: 0.1296,V Acc: 0.2963, Top 70th Acc: 0.3947, Bottom 30th Acc: 0.0625
Fold [5/5] Epoch [10/100] Initial Loss: 0.1400, Training Loss: 0.0265, Initial Validation Loss: 0.1296, Validation Loss: 0.0354,V Acc: 0.8056, Top 70th Acc: 0.9079, Bottom 30th Acc: 0.5625
Fold [5/5] Epoch [20/100] Initial Loss: 0.1400, Training Loss: 0.0172, Initial Validation Loss: 0.1296, Validation Loss: 0.0292,V Acc: 0.8519, Top 70th Acc: 0.9737, Bottom 30th Acc: 0.5625
Stopping early at Epoch (base 0): 20  Rolling back to Epoch (base 0): 15  Top Validation Acc: 0.9736842105263158
Running train_nn.py with seed 65
CUDA:False
Training samples count:  550
Training on 21 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1389, Training Loss: 0.1389, Initial Validation Loss: 0.1281, Validation Loss: 0.1281,V Acc: 0.4375, Top 70th Acc: 0.5696, Bottom 30th Acc: 0.1212
Fold [1/5] Epoch [10/100] Initial Loss: 0.1389, Training Loss: 0.0237, Initial Validation Loss: 0.1281, Validation Loss: 0.0390,V Acc: 0.7768, Top 70th Acc: 0.8987, Bottom 30th Acc: 0.4848
Training on 30 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 46
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 30 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 47
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 30 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 48
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 30 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 49
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 30 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 50
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 30 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 51
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 30 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 52
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 30 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 53
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 30 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 54
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 30 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 55
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 30 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 56
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 30 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 57
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 30 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 58
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 30 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 59
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 30 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 60
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 30 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 61
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 30 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 62
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 30 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 63
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 30 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 64
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 30 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 65
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 30 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 66
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 30 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 67
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 30 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 68
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 30 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 69
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 30 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 70
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 30 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 71
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 30 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 72
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 30 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 73
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 30 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 74
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 30 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 75
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 30 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 76
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 30 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 77
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 30 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 78
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 30 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 79
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 30 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 80
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 30 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 81
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 30 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 82
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 30 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 83
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 30 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 84
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 30 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 85
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 30 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 86
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 30 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 87
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 30 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 88
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 30 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 89
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 30 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 90
Training size: 438
Fold [4/5] Epoch [20/100] Initial Loss: 0.1416, Training Loss: 0.0793, Initial Validation Loss: 0.1328, Validation Loss: 0.0797,V Acc: 0.6055, Top 70th Acc: 0.7143, Bottom 30th Acc: 0.3438
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.7142857142857143
Fold [5/5] Epoch [0/100] Initial Loss: 0.1364, Training Loss: 0.1364, Initial Validation Loss: 0.1222, Validation Loss: 0.1222,V Acc: 0.4907, Top 70th Acc: 0.5132, Bottom 30th Acc: 0.4375
Fold [5/5] Epoch [10/100] Initial Loss: 0.1364, Training Loss: 0.0813, Initial Validation Loss: 0.1222, Validation Loss: 0.0744,V Acc: 0.6759, Top 70th Acc: 0.7500, Bottom 30th Acc: 0.5000
Fold [5/5] Epoch [20/100] Initial Loss: 0.1364, Training Loss: 0.0796, Initial Validation Loss: 0.1222, Validation Loss: 0.0729,V Acc: 0.6481, Top 70th Acc: 0.7632, Bottom 30th Acc: 0.3750
Fold [5/5] Epoch [30/100] Initial Loss: 0.1364, Training Loss: 0.0789, Initial Validation Loss: 0.1222, Validation Loss: 0.0720,V Acc: 0.6481, Top 70th Acc: 0.7632, Bottom 30th Acc: 0.3750
Stopping early at Epoch (base 0): 38  Rolling back to Epoch (base 0): 33  Top Validation Acc: 0.7631578947368421
Running train_nn.py with seed 45
CUDA:False
Training samples count:  550
Training on 2 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1415, Training Loss: 0.1415, Initial Validation Loss: 0.1310, Validation Loss: 0.1310,V Acc: 0.4018, Top 70th Acc: 0.4557, Bottom 30th Acc: 0.2727
Fold [1/5] Epoch [10/100] Initial Loss: 0.1415, Training Loss: 0.0800, Initial Validation Loss: 0.1310, Validation Loss: 0.0862,V Acc: 0.5714, Top 70th Acc: 0.7089, Bottom 30th Acc: 0.2424
Stopping early at Epoch (base 0): 19  Rolling back to Epoch (base 0): 14  Top Validation Acc: 0.7215189873417721
Fold [2/5] Epoch [0/100] Initial Loss: 0.1362, Training Loss: 0.1362, Initial Validation Loss: 0.1262, Validation Loss: 0.1262,V Acc: 0.4775, Top 70th Acc: 0.5897, Bottom 30th Acc: 0.2121
Fold [2/5] Epoch [10/100] Initial Loss: 0.1362, Training Loss: 0.0810, Initial Validation Loss: 0.1262, Validation Loss: 0.0770,V Acc: 0.6126, Top 70th Acc: 0.6795, Bottom 30th Acc: 0.4545
Fold [2/5] Epoch [20/100] Initial Loss: 0.1362, Training Loss: 0.0786, Initial Validation Loss: 0.1262, Validation Loss: 0.0766,V Acc: 0.6126, Top 70th Acc: 0.6923, Bottom 30th Acc: 0.4242
Fold [2/5] Epoch [30/100] Initial Loss: 0.1362, Training Loss: 0.0778, Initial Validation Loss: 0.1262, Validation Loss: 0.0757,V Acc: 0.6036, Top 70th Acc: 0.6795, Bottom 30th Acc: 0.4242
Fold [2/5] Epoch [40/100] Initial Loss: 0.1362, Training Loss: 0.0775, Initial Validation Loss: 0.1262, Validation Loss: 0.0755,V Acc: 0.6126, Top 70th Acc: 0.7051, Bottom 30th Acc: 0.3939
Stopping early at Epoch (base 0): 49  Rolling back to Epoch (base 0): 44  Top Validation Acc: 0.6923076923076923
Fold [3/5] Epoch [0/100] Initial Loss: 0.1423, Training Loss: 0.1423, Initial Validation Loss: 0.1327, Validation Loss: 0.1327,V Acc: 0.4273, Top 70th Acc: 0.5844, Bottom 30th Acc: 0.0606
Fold [3/5] Epoch [10/100] Initial Loss: 0.1423, Training Loss: 0.0801, Initial Validation Loss: 0.1327, Validation Loss: 0.0833,V Acc: 0.6455, Top 70th Acc: 0.7532, Bottom 30th Acc: 0.3939
Fold [3/5] Epoch [20/100] Initial Loss: 0.1423, Training Loss: 0.0779, Initial Validation Loss: 0.1327, Validation Loss: 0.0806,V Acc: 0.6455, Top 70th Acc: 0.7532, Bottom 30th Acc: 0.3939
Fold [3/5] Epoch [30/100] Initial Loss: 0.1423, Training Loss: 0.0777, Initial Validation Loss: 0.1327, Validation Loss: 0.0796,V Acc: 0.6636, Top 70th Acc: 0.7922, Bottom 30th Acc: 0.3636
Fold [3/5] Epoch [40/100] Initial Loss: 0.1423, Training Loss: 0.0772, Initial Validation Loss: 0.1327, Validation Loss: 0.0794,V Acc: 0.6455, Top 70th Acc: 0.7792, Bottom 30th Acc: 0.3333
Stopping early at Epoch (base 0): 45  Rolling back to Epoch (base 0): 40  Top Validation Acc: 0.7792207792207793
45 2 [array([0.09784061, 0.36270925, 0.16006756, 0.22707272, 0.15230991],
      dtype=float32)]
Fold [4/5] Epoch [0/100] Initial Loss: 0.1352, Training Loss: 0.1352, Initial Validation Loss: 0.1187, Validation Loss: 0.1187,V Acc: 0.4128, Top 70th Acc: 0.5455, Bottom 30th Acc: 0.0938
Fold [4/5] Epoch [10/100] Initial Loss: 0.1352, Training Loss: 0.0795, Initial Validation Loss: 0.1187, Validation Loss: 0.0805,V Acc: 0.6514, Top 70th Acc: 0.7922, Bottom 30th Acc: 0.3125
Fold [4/5] Epoch [20/100] Initial Loss: 0.1352, Training Loss: 0.0776, Initial Validation Loss: 0.1187, Validation Loss: 0.0793,V Acc: 0.6514, Top 70th Acc: 0.7922, Bottom 30th Acc: 0.3125
Stopping early at Epoch (base 0): 29  Rolling back to Epoch (base 0): 24  Top Validation Acc: 0.7402597402597403
Fold [5/5] Epoch [0/100] Initial Loss: 0.1335, Training Loss: 0.1335, Initial Validation Loss: 0.1201, Validation Loss: 0.1201,V Acc: 0.3981, Top 70th Acc: 0.5263, Bottom 30th Acc: 0.0938
Fold [5/5] Epoch [10/100] Initial Loss: 0.1335, Training Loss: 0.0832, Initial Validation Loss: 0.1201, Validation Loss: 0.0709,V Acc: 0.6481, Top 70th Acc: 0.8026, Bottom 30th Acc: 0.2812
Fold [5/5] Epoch [20/100] Initial Loss: 0.1335, Training Loss: 0.0817, Initial Validation Loss: 0.1201, Validation Loss: 0.0690,V Acc: 0.6667, Top 70th Acc: 0.7763, Bottom 30th Acc: 0.4062
Fold [5/5] Epoch [30/100] Initial Loss: 0.1335, Training Loss: 0.0811, Initial Validation Loss: 0.1201, Validation Loss: 0.0678,V Acc: 0.6667, Top 70th Acc: 0.8026, Bottom 30th Acc: 0.3438
Stopping early at Epoch (base 0): 36  Rolling back to Epoch (base 0): 31  Top Validation Acc: 0.7894736842105263
Running train_nn.py with seed 46
CUDA:False
Training samples count:  550
Training on 2 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1409, Training Loss: 0.1409, Initial Validation Loss: 0.1332, Validation Loss: 0.1332,V Acc: 0.3214, Top 70th Acc: 0.4304, Bottom 30th Acc: 0.0606
Fold [1/5] Epoch [10/100] Initial Loss: 0.1409, Training Loss: 0.0831, Initial Validation Loss: 0.1332, Validation Loss: 0.0768,V Acc: 0.6339, Top 70th Acc: 0.7468, Bottom 30th Acc: 0.3636
Fold [1/5] Epoch [20/100] Initial Loss: 0.1409, Training Loss: 0.0803, Initial Validation Loss: 0.1332, Validation Loss: 0.0738,V Acc: 0.6339, Top 70th Acc: 0.7595, Bottom 30th Acc: 0.3333
Fold [1/5] Epoch [30/100] Initial Loss: 0.1409, Training Loss: 0.0795, Initial Validation Loss: 0.1332, Validation Loss: 0.0732,V Acc: 0.6339, Top 70th Acc: 0.7722, Bottom 30th Acc: 0.3030
Fold [1/5] Epoch [40/100] Initial Loss: 0.1409, Training Loss: 0.0787, Initial Validation Loss: 0.1332, Validation Loss: 0.0743,V Acc: 0.6429, Top 70th Acc: 0.7722, Bottom 30th Acc: 0.3333
Stopping early at Epoch (base 0): 44  Rolling back to Epoch (base 0): 39  Top Validation Acc: 0.7721518987341772
Fold [2/5] Epoch [0/100] Initial Loss: 0.1364, Training Loss: 0.1364, Initial Validation Loss: 0.1263, Validation Loss: 0.1263,V Acc: 0.4595, Top 70th Acc: 0.6026, Bottom 30th Acc: 0.1212
Fold [2/5] Epoch [10/100] Initial Loss: 0.1364, Training Loss: 0.0822, Initial Validation Loss: 0.1263, Validation Loss: 0.0777,V Acc: 0.6216, Top 70th Acc: 0.7308, Bottom 30th Acc: 0.3636
Stopping early at Epoch (base 0): 14  Rolling back to Epoch (base 0): 9  Top Validation Acc: 0.717948717948718
46 1 [array([0.12845108, 0.38582936, 0.14017668, 0.16559157, 0.17995137],
      dtype=float32)]
Fold [3/5] Epoch [0/100] Initial Loss: 0.1356, Training Loss: 0.1356, Initial Validation Loss: 0.1283, Validation Loss: 0.1283,V Acc: 0.4273, Top 70th Acc: 0.4156, Bottom 30th Acc: 0.4545
Fold [3/5] Epoch [10/100] Initial Loss: 0.1356, Training Loss: 0.0800, Initial Validation Loss: 0.1283, Validation Loss: 0.0817,V Acc: 0.6182, Top 70th Acc: 0.7143, Bottom 30th Acc: 0.3939
Fold [3/5] Epoch [20/100] Initial Loss: 0.1356, Training Loss: 0.0775, Initial Validation Loss: 0.1283, Validation Loss: 0.0802,V Acc: 0.6273, Top 70th Acc: 0.7143, Bottom 30th Acc: 0.4242
Fold [3/5] Epoch [30/100] Initial Loss: 0.1356, Training Loss: 0.0769, Initial Validation Loss: 0.1283, Validation Loss: 0.0804,V Acc: 0.6455, Top 70th Acc: 0.7403, Bottom 30th Acc: 0.4242
Stopping early at Epoch (base 0): 31  Rolling back to Epoch (base 0): 26  Top Validation Acc: 0.7532467532467533
Fold [4/5] Epoch [0/100] Initial Loss: 0.1378, Training Loss: 0.1378, Initial Validation Loss: 0.1225, Validation Loss: 0.1225,V Acc: 0.3670, Top 70th Acc: 0.3766, Bottom 30th Acc: 0.3438/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)

Fold [1/5] Epoch [30/100] Initial Loss: 0.1368, Training Loss: 0.0158, Initial Validation Loss: 0.1361, Validation Loss: 0.0246,V Acc: 0.9107, Top 70th Acc: 0.9620, Bottom 30th Acc: 0.7879
Stopping early at Epoch (base 0): 32  Rolling back to Epoch (base 0): 27  Top Validation Acc: 0.9620253164556962
Fold [2/5] Epoch [0/100] Initial Loss: 0.1389, Training Loss: 0.1389, Initial Validation Loss: 0.1355, Validation Loss: 0.1355,V Acc: 0.2432, Top 70th Acc: 0.2308, Bottom 30th Acc: 0.2727
Fold [2/5] Epoch [10/100] Initial Loss: 0.1389, Training Loss: 0.0336, Initial Validation Loss: 0.1355, Validation Loss: 0.0363,V Acc: 0.8198, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.5455
Fold [2/5] Epoch [20/100] Initial Loss: 0.1389, Training Loss: 0.0187, Initial Validation Loss: 0.1355, Validation Loss: 0.0296,V Acc: 0.8649, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.6667
Fold [2/5] Epoch [30/100] Initial Loss: 0.1389, Training Loss: 0.0155, Initial Validation Loss: 0.1355, Validation Loss: 0.0282,V Acc: 0.8559, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 35  Rolling back to Epoch (base 0): 30  Top Validation Acc: 0.9487179487179487
Fold [3/5] Epoch [0/100] Initial Loss: 0.1448, Training Loss: 0.1448, Initial Validation Loss: 0.1358, Validation Loss: 0.1358,V Acc: 0.3273, Top 70th Acc: 0.3506, Bottom 30th Acc: 0.2727
Fold [3/5] Epoch [10/100] Initial Loss: 0.1448, Training Loss: 0.0333, Initial Validation Loss: 0.1358, Validation Loss: 0.0471,V Acc: 0.7727, Top 70th Acc: 0.8831, Bottom 30th Acc: 0.5152
Fold [3/5] Epoch [20/100] Initial Loss: 0.1448, Training Loss: 0.0160, Initial Validation Loss: 0.1358, Validation Loss: 0.0375,V Acc: 0.8000, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.8831168831168831
45 2 [array([0.66414464, 0.07053766, 0.04762769, 0.14609477, 0.07159517],
      dtype=float32)]
Fold [4/5] Epoch [0/100] Initial Loss: 0.1388, Training Loss: 0.1388, Initial Validation Loss: 0.1347, Validation Loss: 0.1347,V Acc: 0.2477, Top 70th Acc: 0.2468, Bottom 30th Acc: 0.2500
Fold [4/5] Epoch [10/100] Initial Loss: 0.1388, Training Loss: 0.0428, Initial Validation Loss: 0.1347, Validation Loss: 0.0444,V Acc: 0.7982, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.4688
Fold [4/5] Epoch [20/100] Initial Loss: 0.1388, Training Loss: 0.0203, Initial Validation Loss: 0.1347, Validation Loss: 0.0296,V Acc: 0.8440, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.5625
Fold [4/5] Epoch [30/100] Initial Loss: 0.1388, Training Loss: 0.0168, Initial Validation Loss: 0.1347, Validation Loss: 0.0282,V Acc: 0.8624, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6562
Fold [4/5] Epoch [40/100] Initial Loss: 0.1388, Training Loss: 0.0155, Initial Validation Loss: 0.1347, Validation Loss: 0.0267,V Acc: 0.8624, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6562
Stopping early at Epoch (base 0): 45  Rolling back to Epoch (base 0): 40  Top Validation Acc: 0.961038961038961
Fold [5/5] Epoch [0/100] Initial Loss: 0.1411, Training Loss: 0.1411, Initial Validation Loss: 0.1300, Validation Loss: 0.1300,V Acc: 0.2963, Top 70th Acc: 0.3421, Bottom 30th Acc: 0.1875
Fold [5/5] Epoch [10/100] Initial Loss: 0.1411, Training Loss: 0.0356, Initial Validation Loss: 0.1300, Validation Loss: 0.0356,V Acc: 0.8333, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.5625
Fold [5/5] Epoch [20/100] Initial Loss: 0.1411, Training Loss: 0.0176, Initial Validation Loss: 0.1300, Validation Loss: 0.0263,V Acc: 0.8611, Top 70th Acc: 0.9737, Bottom 30th Acc: 0.5938
Stopping early at Epoch (base 0): 27  Rolling back to Epoch (base 0): 22  Top Validation Acc: 0.9605263157894737
Running train_nn.py with seed 46
CUDA:False
Training samples count:  550
Training on 30 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1380, Training Loss: 0.1380, Initial Validation Loss: 0.1304, Validation Loss: 0.1304,V Acc: 0.4196, Top 70th Acc: 0.5063, Bottom 30th Acc: 0.2121
Fold [1/5] Epoch [10/100] Initial Loss: 0.1380, Training Loss: 0.0307, Initial Validation Loss: 0.1304, Validation Loss: 0.0379,V Acc: 0.8125, Top 70th Acc: 0.9114, Bottom 30th Acc: 0.5758
Fold [1/5] Epoch [20/100] Initial Loss: 0.1380, Training Loss: 0.0171, Initial Validation Loss: 0.1304, Validation Loss: 0.0327,V Acc: 0.8214, Top 70th Acc: 0.9241, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.9367088607594937
Fold [2/5] Epoch [0/100] Initial Loss: 0.1387, Training Loss: 0.1387, Initial Validation Loss: 0.1336, Validation Loss: 0.1336,V Acc: 0.3423, Top 70th Acc: 0.3590, Bottom 30th Acc: 0.3030
Fold [2/5] Epoch [10/100] Initial Loss: 0.1387, Training Loss: 0.0386, Initial Validation Loss: 0.1336, Validation Loss: 0.0447,V Acc: 0.8018, Top 70th Acc: 0.8846, Bottom 30th Acc: 0.6061
Fold [2/5] Epoch [20/100] Initial Loss: 0.1387, Training Loss: 0.0190, Initial Validation Loss: 0.1336, Validation Loss: 0.0352,V Acc: 0.8108, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.5152
Stopping early at Epoch (base 0): 27  Rolling back to Epoch (base 0): 22  Top Validation Acc: 0.9230769230769231
46 1 [array([0.5941387 , 0.07650341, 0.12882848, 0.06650654, 0.1340229 ],
      dtype=float32)]
Fold [3/5] Epoch [0/100] Initial Loss: 0.1376, Training Loss: 0.1376, Initial Validation Loss: 0.1341, Validation Loss: 0.1341,V Acc: 0.3727, Top 70th Acc: 0.4416, Bottom 30th Acc: 0.2121
Fold [3/5] Epoch [10/100] Initial Loss: 0.1376, Training Loss: 0.0380, Initial Validation Loss: 0.1341, Validation Loss: 0.0375,V Acc: 0.8364, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.5758
Fold [3/5] Epoch [20/100] Initial Loss: 0.1376, Training Loss: 0.0226, Initial Validation Loss: 0.1341, Validation Loss: 0.0268,V Acc: 0.8909, Top 70th Acc: 0.9870, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.974025974025974
Fold [4/5] Epoch [0/100] Initial Loss: 0.1398, Training Loss: 0.1398, Initial Validation Loss: 0.1276, Validation Loss: 0.1276,V Acc: 0.2844, Top 70th Acc: 0.3636, Bottom 30th Acc: 0.0938
Fold [4/5] Epoch [10/100] Initial Loss: 0.1398, Training Loss: 0.0275, Initial Validation Loss: 0.1276, Validation Loss: 0.0388,V Acc: 0.7706, Top 70th Acc: 0.8961, Bottom 30th Acc: 0.4688
Fold [4/5] Epoch [20/100] Initial Loss: 0.1398, Training Loss: 0.0176, Initial Validation Loss: 0.1276, Validation Loss: 0.0343,V Acc: 0.7890, Top 70th Acc: 0.8961, Bottom 30th Acc: 0.5312
Fold [4/5] Epoch [30/100] Initial Loss: 0.1398, Training Loss: 0.0151, Initial Validation Loss: 0.1276, Validation Loss: 0.0336,V Acc: 0.7982, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.5000
Stopping early at Epoch (base 0): 33  Rolling back to Epoch (base 0): 28  Top Validation Acc: 0.922077922077922
Fold [5/5] Epoch [0/100] Initial Loss: 0.1378, Training Loss: 0.1378, Initial Validation Loss: 0.1323, Validation Loss: 0.1323,V Acc: 0.4352, Top 70th Acc: 0.4342, Bottom 30th Acc: 0.4375
Fold [5/5] Epoch [10/100] Initial Loss: 0.1378, Training Loss: 0.0432, Initial Validation Loss: 0.1323, Validation Loss: 0.0509,V Acc: 0.7593, Top 70th Acc: 0.8947, Bottom 30th Acc: 0.4375
Fold [5/5] Epoch [20/100] Initial Loss: 0.1378, Training Loss: 0.0202, Initial Validation Loss: 0.1323, Validation Loss: 0.0318,V Acc: 0.8519, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.5938
Stopping early at Epoch (base 0): 28  Rolling back to Epoch (base 0): 23  Top Validation Acc: 0.9473684210526315
Running train_nn.py with seed 47
CUDA:False
Training samples count:  550
Training on 30 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1373, Training Loss: 0.1373, Initial Validation Loss: 0.1337, Validation Loss: 0.1337,V Acc: 0.3750, Top 70th Acc: 0.4051, Bottom 30th Acc: 0.3030
Fold [1/5] Epoch [10/100] Initial Loss: 0.1373, Training Loss: 0.0335, Initial Validation Loss: 0.1337, Validation Loss: 0.0428,V Acc: 0.7857, Top 70th Acc: 0.8987, Bottom 30th Acc: 0.5152
Fold [1/5] Epoch [20/100] Initial Loss: 0.1373, Training Loss: 0.0171, Initial Validation Loss: 0.1337, Validation Loss: 0.0304,V Acc: 0.8482, Top 70th Acc: 0.9367, Bottom 30th Acc: 0.6364
Fold [1/5] Epoch [30/100] Initial Loss: 0.1373, Training Loss: 0.0145, Initial Validation Loss: 0.1337, Validation Loss: 0.0307,V Acc: 0.8482, Top 70th Acc: 0.9367, Bottom 30th Acc: 0.6364/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)

Fold [2/5] Epoch [40/100] Initial Loss: 0.1370, Training Loss: 0.0036, Initial Validation Loss: 0.1347, Validation Loss: 0.0310,V Acc: 0.8559, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 41  Rolling back to Epoch (base 0): 36  Top Validation Acc: 0.9615384615384616
Fold [3/5] Epoch [0/100] Initial Loss: 0.1418, Training Loss: 0.1418, Initial Validation Loss: 0.1341, Validation Loss: 0.1341,V Acc: 0.2818, Top 70th Acc: 0.3506, Bottom 30th Acc: 0.1212
Fold [3/5] Epoch [10/100] Initial Loss: 0.1418, Training Loss: 0.0197, Initial Validation Loss: 0.1341, Validation Loss: 0.0322,V Acc: 0.8273, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.5455
Fold [3/5] Epoch [20/100] Initial Loss: 0.1418, Training Loss: 0.0054, Initial Validation Loss: 0.1341, Validation Loss: 0.0259,V Acc: 0.8545, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 28  Rolling back to Epoch (base 0): 23  Top Validation Acc: 0.961038961038961
Fold [4/5] Epoch [0/100] Initial Loss: 0.1381, Training Loss: 0.1381, Initial Validation Loss: 0.1346, Validation Loss: 0.1346,V Acc: 0.2936, Top 70th Acc: 0.3247, Bottom 30th Acc: 0.2188
Fold [4/5] Epoch [10/100] Initial Loss: 0.1381, Training Loss: 0.0175, Initial Validation Loss: 0.1346, Validation Loss: 0.0385,V Acc: 0.8165, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.5312
Fold [4/5] Epoch [20/100] Initial Loss: 0.1381, Training Loss: 0.0047, Initial Validation Loss: 0.1346, Validation Loss: 0.0311,V Acc: 0.8349, Top 70th Acc: 1.0000, Bottom 30th Acc: 0.4375
Stopping early at Epoch (base 0): 27  Rolling back to Epoch (base 0): 22  Top Validation Acc: 1.0
Fold [5/5] Epoch [0/100] Initial Loss: 0.1408, Training Loss: 0.1408, Initial Validation Loss: 0.1272, Validation Loss: 0.1272,V Acc: 0.3611, Top 70th Acc: 0.3553, Bottom 30th Acc: 0.3750
Fold [5/5] Epoch [10/100] Initial Loss: 0.1408, Training Loss: 0.0249, Initial Validation Loss: 0.1272, Validation Loss: 0.0447,V Acc: 0.7315, Top 70th Acc: 0.8421, Bottom 30th Acc: 0.4688
Fold [5/5] Epoch [20/100] Initial Loss: 0.1408, Training Loss: 0.0060, Initial Validation Loss: 0.1272, Validation Loss: 0.0414,V Acc: 0.7593, Top 70th Acc: 0.8684, Bottom 30th Acc: 0.5000
Fold [5/5] Epoch [30/100] Initial Loss: 0.1408, Training Loss: 0.0045, Initial Validation Loss: 0.1272, Validation Loss: 0.0399,V Acc: 0.7685, Top 70th Acc: 0.8816, Bottom 30th Acc: 0.5000
Fold [5/5] Epoch [40/100] Initial Loss: 0.1408, Training Loss: 0.0040, Initial Validation Loss: 0.1272, Validation Loss: 0.0388,V Acc: 0.7407, Top 70th Acc: 0.8816, Bottom 30th Acc: 0.4062
Fold [5/5] Epoch [50/100] Initial Loss: 0.1408, Training Loss: 0.0038, Initial Validation Loss: 0.1272, Validation Loss: 0.0376,V Acc: 0.7500, Top 70th Acc: 0.8947, Bottom 30th Acc: 0.4062
Fold [5/5] Epoch [60/100] Initial Loss: 0.1408, Training Loss: 0.0036, Initial Validation Loss: 0.1272, Validation Loss: 0.0371,V Acc: 0.7315, Top 70th Acc: 0.9079, Bottom 30th Acc: 0.3125
Stopping early at Epoch (base 0): 67  Rolling back to Epoch (base 0): 62  Top Validation Acc: 0.9078947368421053
36 4 [array([0.20690787, 0.02551353, 0.03348968, 0.2742707 , 0.45981815],
      dtype=float32)]
Running train_nn.py with seed 37
CUDA:False
Training samples count:  550
Training on 162 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1388, Training Loss: 0.1388, Initial Validation Loss: 0.1405, Validation Loss: 0.1405,V Acc: 0.2500, Top 70th Acc: 0.3165, Bottom 30th Acc: 0.0909
Fold [1/5] Epoch [10/100] Initial Loss: 0.1388, Training Loss: 0.0187, Initial Validation Loss: 0.1405, Validation Loss: 0.0310,V Acc: 0.8750, Top 70th Acc: 0.9747, Bottom 30th Acc: 0.6364
Fold [1/5] Epoch [20/100] Initial Loss: 0.1388, Training Loss: 0.0050, Initial Validation Loss: 0.1405, Validation Loss: 0.0254,V Acc: 0.8839, Top 70th Acc: 0.9747, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 27  Rolling back to Epoch (base 0): 22  Top Validation Acc: 0.9746835443037974
Fold [2/5] Epoch [0/100] Initial Loss: 0.1399, Training Loss: 0.1399, Initial Validation Loss: 0.1331, Validation Loss: 0.1331,V Acc: 0.2613, Top 70th Acc: 0.3590, Bottom 30th Acc: 0.0303
Fold [2/5] Epoch [10/100] Initial Loss: 0.1399, Training Loss: 0.0139, Initial Validation Loss: 0.1331, Validation Loss: 0.0301,V Acc: 0.8649, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 19  Rolling back to Epoch (base 0): 14  Top Validation Acc: 0.9615384615384616
37 1 [array([0.158848  , 0.0800809 , 0.05666575, 0.22069803, 0.4837073 ],
      dtype=float32)]
Fold [3/5] Epoch [0/100] Initial Loss: 0.1441, Training Loss: 0.1441, Initial Validation Loss: 0.1364, Validation Loss: 0.1364,V Acc: 0.2545, Top 70th Acc: 0.3506, Bottom 30th Acc: 0.0303
Fold [3/5] Epoch [10/100] Initial Loss: 0.1441, Training Loss: 0.0209, Initial Validation Loss: 0.1364, Validation Loss: 0.0338,V Acc: 0.8182, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.5455
Fold [3/5] Epoch [20/100] Initial Loss: 0.1441, Training Loss: 0.0056, Initial Validation Loss: 0.1364, Validation Loss: 0.0253,V Acc: 0.8818, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.7879
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.922077922077922
Fold [4/5] Epoch [0/100] Initial Loss: 0.1411, Training Loss: 0.1411, Initial Validation Loss: 0.1356, Validation Loss: 0.1356,V Acc: 0.2661, Top 70th Acc: 0.3247, Bottom 30th Acc: 0.1250
Fold [4/5] Epoch [10/100] Initial Loss: 0.1411, Training Loss: 0.0251, Initial Validation Loss: 0.1356, Validation Loss: 0.0435,V Acc: 0.7982, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.4375
Fold [4/5] Epoch [20/100] Initial Loss: 0.1411, Training Loss: 0.0046, Initial Validation Loss: 0.1356, Validation Loss: 0.0319,V Acc: 0.8440, Top 70th Acc: 0.9870, Bottom 30th Acc: 0.5000
Fold [4/5] Epoch [30/100] Initial Loss: 0.1411, Training Loss: 0.0035, Initial Validation Loss: 0.1356, Validation Loss: 0.0329,V Acc: 0.8440, Top 70th Acc: 0.9870, Bottom 30th Acc: 0.5000
Stopping early at Epoch (base 0): 30  Rolling back to Epoch (base 0): 25  Top Validation Acc: 0.987012987012987
Fold [5/5] Epoch [0/100] Initial Loss: 0.1385, Training Loss: 0.1385, Initial Validation Loss: 0.1247, Validation Loss: 0.1247,V Acc: 0.4259, Top 70th Acc: 0.5132, Bottom 30th Acc: 0.2188
Fold [5/5] Epoch [10/100] Initial Loss: 0.1385, Training Loss: 0.0156, Initial Validation Loss: 0.1247, Validation Loss: 0.0356,V Acc: 0.7778, Top 70th Acc: 0.9079, Bottom 30th Acc: 0.4688
Fold [5/5] Epoch [20/100] Initial Loss: 0.1385, Training Loss: 0.0052, Initial Validation Loss: 0.1247, Validation Loss: 0.0306,V Acc: 0.8148, Top 70th Acc: 0.8947, Bottom 30th Acc: 0.6250
Fold [5/5] Epoch [30/100] Initial Loss: 0.1385, Training Loss: 0.0040, Initial Validation Loss: 0.1247, Validation Loss: 0.0304,V Acc: 0.8333, Top 70th Acc: 0.9079, Bottom 30th Acc: 0.6562
Stopping early at Epoch (base 0): 31  Rolling back to Epoch (base 0): 26  Top Validation Acc: 0.9078947368421053
Running train_nn.py with seed 38
CUDA:False
Training samples count:  550
Training on 162 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1388, Training Loss: 0.1388, Initial Validation Loss: 0.1385, Validation Loss: 0.1385,V Acc: 0.2500, Top 70th Acc: 0.3291, Bottom 30th Acc: 0.0606
Fold [1/5] Epoch [10/100] Initial Loss: 0.1388, Training Loss: 0.0183, Initial Validation Loss: 0.1385, Validation Loss: 0.0367,V Acc: 0.8304, Top 70th Acc: 0.9367, Bottom 30th Acc: 0.5758
Fold [1/5] Epoch [20/100] Initial Loss: 0.1388, Training Loss: 0.0060, Initial Validation Loss: 0.1385, Validation Loss: 0.0322,V Acc: 0.8482, Top 70th Acc: 0.9367, Bottom 30th Acc: 0.6364
Fold [1/5] Epoch [30/100] Initial Loss: 0.1388, Training Loss: 0.0044, Initial Validation Loss: 0.1385, Validation Loss: 0.0309,V Acc: 0.8393, Top 70th Acc: 0.9494, Bottom 30th Acc: 0.5758
Fold [1/5] Epoch [40/100] Initial Loss: 0.1388, Training Loss: 0.0040, Initial Validation Loss: 0.1385, Validation Loss: 0.0299,V Acc: 0.8393, Top 70th Acc: 0.9494, Bottom 30th Acc: 0.5758
Fold [1/5] Epoch [50/100] Initial Loss: 0.1388, Training Loss: 0.0038, Initial Validation Loss: 0.1385, Validation Loss: 0.0291,V Acc: 0.8571, Top 70th Acc: 0.9494, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0):
Fold [1/5] Epoch [20/100] Initial Loss: 0.1401, Training Loss: 0.0158, Initial Validation Loss: 0.1356, Validation Loss: 0.0350,V Acc: 0.8393, Top 70th Acc: 0.9367, Bottom 30th Acc: 0.6061
Fold [1/5] Epoch [30/100] Initial Loss: 0.1401, Training Loss: 0.0127, Initial Validation Loss: 0.1356, Validation Loss: 0.0340,V Acc: 0.8571, Top 70th Acc: 0.9367, Bottom 30th Acc: 0.6667
Fold [1/5] Epoch [40/100] Initial Loss: 0.1401, Training Loss: 0.0113, Initial Validation Loss: 0.1356, Validation Loss: 0.0325,V Acc: 0.8661, Top 70th Acc: 0.9367, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 42  Rolling back to Epoch (base 0): 37  Top Validation Acc: 0.9367088607594937
Fold [2/5] Epoch [0/100] Initial Loss: 0.1412, Training Loss: 0.1412, Initial Validation Loss: 0.1334, Validation Loss: 0.1334,V Acc: 0.3423, Top 70th Acc: 0.3974, Bottom 30th Acc: 0.2121
Fold [2/5] Epoch [10/100] Initial Loss: 0.1412, Training Loss: 0.0404, Initial Validation Loss: 0.1334, Validation Loss: 0.0473,V Acc: 0.7568, Top 70th Acc: 0.8718, Bottom 30th Acc: 0.4848
Fold [2/5] Epoch [20/100] Initial Loss: 0.1412, Training Loss: 0.0192, Initial Validation Loss: 0.1334, Validation Loss: 0.0303,V Acc: 0.8468, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.5455
Fold [2/5] Epoch [30/100] Initial Loss: 0.1412, Training Loss: 0.0124, Initial Validation Loss: 0.1334, Validation Loss: 0.0265,V Acc: 0.8739, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.6970
Fold [2/5] Epoch [40/100] Initial Loss: 0.1412, Training Loss: 0.0108, Initial Validation Loss: 0.1334, Validation Loss: 0.0261,V Acc: 0.8829, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 46  Rolling back to Epoch (base 0): 41  Top Validation Acc: 0.9615384615384616
49 1 [array([0.47757497, 0.02432771, 0.05596928, 0.10158327, 0.34054473],
      dtype=float32)]
Fold [3/5] Epoch [0/100] Initial Loss: 0.1386, Training Loss: 0.1386, Initial Validation Loss: 0.1297, Validation Loss: 0.1297,V Acc: 0.3000, Top 70th Acc: 0.2857, Bottom 30th Acc: 0.3333
Fold [3/5] Epoch [10/100] Initial Loss: 0.1386, Training Loss: 0.0255, Initial Validation Loss: 0.1297, Validation Loss: 0.0305,V Acc: 0.8364, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.6364
Fold [3/5] Epoch [20/100] Initial Loss: 0.1386, Training Loss: 0.0153, Initial Validation Loss: 0.1297, Validation Loss: 0.0264,V Acc: 0.8455, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 27  Rolling back to Epoch (base 0): 22  Top Validation Acc: 0.987012987012987
Fold [4/5] Epoch [0/100] Initial Loss: 0.1402, Training Loss: 0.1402, Initial Validation Loss: 0.1365, Validation Loss: 0.1365,V Acc: 0.2477, Top 70th Acc: 0.2468, Bottom 30th Acc: 0.2500
Fold [4/5] Epoch [10/100] Initial Loss: 0.1402, Training Loss: 0.0352, Initial Validation Loss: 0.1365, Validation Loss: 0.0462,V Acc: 0.7890, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.5000
Fold [4/5] Epoch [20/100] Initial Loss: 0.1402, Training Loss: 0.0175, Initial Validation Loss: 0.1365, Validation Loss: 0.0304,V Acc: 0.8440, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.5625
Fold [4/5] Epoch [30/100] Initial Loss: 0.1402, Training Loss: 0.0140, Initial Validation Loss: 0.1365, Validation Loss: 0.0288,V Acc: 0.8624, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6562
Stopping early at Epoch (base 0): 38  Rolling back to Epoch (base 0): 33  Top Validation Acc: 0.948051948051948
Fold [5/5] Epoch [0/100] Initial Loss: 0.1414, Training Loss: 0.1414, Initial Validation Loss: 0.1337, Validation Loss: 0.1337,V Acc: 0.2685, Top 70th Acc: 0.2500, Bottom 30th Acc: 0.3125
Fold [5/5] Epoch [10/100] Initial Loss: 0.1414, Training Loss: 0.0286, Initial Validation Loss: 0.1337, Validation Loss: 0.0422,V Acc: 0.7963, Top 70th Acc: 0.9211, Bottom 30th Acc: 0.5000
Fold [5/5] Epoch [20/100] Initial Loss: 0.1414, Training Loss: 0.0131, Initial Validation Loss: 0.1337, Validation Loss: 0.0365,V Acc: 0.8333, Top 70th Acc: 0.9079, Bottom 30th Acc: 0.6562
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.9078947368421053
Running train_nn.py with seed 50
CUDA:False
Training samples count:  550
Training on 40 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1402, Training Loss: 0.1402, Initial Validation Loss: 0.1361, Validation Loss: 0.1361,V Acc: 0.2679, Top 70th Acc: 0.2658, Bottom 30th Acc: 0.2727
Fold [1/5] Epoch [10/100] Initial Loss: 0.1402, Training Loss: 0.0316, Initial Validation Loss: 0.1361, Validation Loss: 0.0426,V Acc: 0.7946, Top 70th Acc: 0.9114, Bottom 30th Acc: 0.5152
Fold [1/5] Epoch [20/100] Initial Loss: 0.1402, Training Loss: 0.0141, Initial Validation Loss: 0.1361, Validation Loss: 0.0336,V Acc: 0.8304, Top 70th Acc: 0.9747, Bottom 30th Acc: 0.4848
Stopping early at Epoch (base 0): 28  Rolling back to Epoch (base 0): 23  Top Validation Acc: 0.9493670886075949
Fold [2/5] Epoch [0/100] Initial Loss: 0.1375, Training Loss: 0.1375, Initial Validation Loss: 0.1278, Validation Loss: 0.1278,V Acc: 0.3063, Top 70th Acc: 0.3462, Bottom 30th Acc: 0.2121
Fold [2/5] Epoch [10/100] Initial Loss: 0.1375, Training Loss: 0.0346, Initial Validation Loss: 0.1278, Validation Loss: 0.0378,V Acc: 0.8108, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.5455
Fold [2/5] Epoch [20/100] Initial Loss: 0.1375, Training Loss: 0.0154, Initial Validation Loss: 0.1278, Validation Loss: 0.0308,V Acc: 0.8468, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.9230769230769231
Fold [3/5] Epoch [0/100] Initial Loss: 0.1416, Training Loss: 0.1416, Initial Validation Loss: 0.1348, Validation Loss: 0.1348,V Acc: 0.3273, Top 70th Acc: 0.3766, Bottom 30th Acc: 0.2121
Fold [3/5] Epoch [10/100] Initial Loss: 0.1416, Training Loss: 0.0416, Initial Validation Loss: 0.1348, Validation Loss: 0.0457,V Acc: 0.7727, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.4242
Fold [3/5] Epoch [20/100] Initial Loss: 0.1416, Training Loss: 0.0167, Initial Validation Loss: 0.1348, Validation Loss: 0.0323,V Acc: 0.8818, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.948051948051948
50 2 [array([0.6251746 , 0.03576158, 0.0570307 , 0.07186976, 0.2101634 ],
      dtype=float32)]
Fold [4/5] Epoch [0/100] Initial Loss: 0.1417, Training Loss: 0.1417, Initial Validation Loss: 0.1357, Validation Loss: 0.1357,V Acc: 0.2385, Top 70th Acc: 0.2597, Bottom 30th Acc: 0.1875
Fold [4/5] Epoch [10/100] Initial Loss: 0.1417, Training Loss: 0.0244, Initial Validation Loss: 0.1357, Validation Loss: 0.0412,V Acc: 0.8165, Top 70th Acc: 0.8961, Bottom 30th Acc: 0.6250
Fold [4/5] Epoch [20/100] Initial Loss: 0.1417, Training Loss: 0.0145, Initial Validation Loss: 0.1357, Validation Loss: 0.0369,V Acc: 0.8349, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.6562
Fold [4/5] Epoch [30/100] Initial Loss: 0.1417, Training Loss: 0.0127, Initial Validation Loss: 0.1357, Validation Loss: 0.0364,V Acc: 0.8624, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.7500
Stopping early at Epoch (base 0): 31  Rolling back to Epoch (base 0): 26  Top Validation Acc: 0.9090909090909091
Fold [5/5] Epoch [0/100] Initial Loss: 0.1388, Training Loss: 0.1388, Initial Validation Loss: 0.1362, Validation Loss: 0.1362,V Acc: 0.1944, Top 70th Acc: 0.2368, Bottom 30th Acc: 0.0938
Fold [5/5] Epoch [10/100] Initial Loss: 0.1388, Training Loss: 0.0423, Initial Validation Loss: 0.1362, Validation Loss: 0.0446,V Acc: 0.8056, Top 70th Acc: 0.9211, Bottom 30th Acc: 0.5312
Fold [5/5] Epoch [20/100] Initial Loss: 0.1388, Training Loss: 0.0178, Initial Validation Loss: 0.1362, Validation Loss: 0.0283,V Acc: 0.8611, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.6562
Fold [5/5] Epoch [30/100] Initial Loss: 0.1388, Training Loss: 0.0126, Initial Validation Loss: 0.1362, Validation Loss: 0.0268,V Acc: 0.8611, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.6250
Stopping early at Epoch (base 0): 35  Rolling back to Epoch (base 0): 30  Top Validation Acc: 0.9605263157894737
Running train_nn.py with seed 51
CUDA:False
Training samples count:  550
Training on 39 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1439, Training Loss: 0.1439, Initial Validation Loss: 0.1358, Validation Loss: 0.1358,V Acc: 0.3393, Top 70th Acc: 0.3544, Bottom 30th Acc: 0.3030 Top Validation Acc: 0.9605263157894737
Running train_nn.py with seed 47
CUDA:False
Training samples count:  550
Training on 20 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1374, Training Loss: 0.1374, Initial Validation Loss: 0.1294, Validation Loss: 0.1294,V Acc: 0.4018, Top 70th Acc: 0.5316, Bottom 30th Acc: 0.0909
Fold [1/5] Epoch [10/100] Initial Loss: 0.1374, Training Loss: 0.0357, Initial Validation Loss: 0.1294, Validation Loss: 0.0482,V Acc: 0.7679, Top 70th Acc: 0.8608, Bottom 30th Acc: 0.5455
Fold [1/5] Epoch [20/100] Initial Loss: 0.1374, Training Loss: 0.0228, Initial Validation Loss: 0.1294, Validation Loss: 0.0376,V Acc: 0.8304, Top 70th Acc: 0.8987, Bottom 30th Acc: 0.6667
Fold [1/5] Epoch [30/100] Initial Loss: 0.1374, Training Loss: 0.0194, Initial Validation Loss: 0.1294, Validation Loss: 0.0367,V Acc: 0.8125, Top 70th Acc: 0.8987, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 30  Rolling back to Epoch (base 0): 25  Top Validation Acc: 0.8987341772151899
Fold [2/5] Epoch [0/100] Initial Loss: 0.1390, Training Loss: 0.1390, Initial Validation Loss: 0.1303, Validation Loss: 0.1303,V Acc: 0.3874, Top 70th Acc: 0.3974, Bottom 30th Acc: 0.3636
Fold [2/5] Epoch [10/100] Initial Loss: 0.1390, Training Loss: 0.0473, Initial Validation Loss: 0.1303, Validation Loss: 0.0508,V Acc: 0.7568, Top 70th Acc: 0.8590, Bottom 30th Acc: 0.5152
Fold [2/5] Epoch [20/100] Initial Loss: 0.1390, Training Loss: 0.0254, Initial Validation Loss: 0.1303, Validation Loss: 0.0339,V Acc: 0.8559, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 27  Rolling back to Epoch (base 0): 22  Top Validation Acc: 0.9487179487179487
47 1 [array([0.42063218, 0.10921618, 0.09940223, 0.2454942 , 0.1252552 ],
      dtype=float32)]
Fold [3/5] Epoch [0/100] Initial Loss: 0.1395, Training Loss: 0.1395, Initial Validation Loss: 0.1300, Validation Loss: 0.1300,V Acc: 0.4182, Top 70th Acc: 0.4935, Bottom 30th Acc: 0.2424
Fold [3/5] Epoch [10/100] Initial Loss: 0.1395, Training Loss: 0.0315, Initial Validation Loss: 0.1300, Validation Loss: 0.0415,V Acc: 0.7909, Top 70th Acc: 0.8701, Bottom 30th Acc: 0.6061
Fold [3/5] Epoch [20/100] Initial Loss: 0.1395, Training Loss: 0.0239, Initial Validation Loss: 0.1300, Validation Loss: 0.0333,V Acc: 0.8091, Top 70th Acc: 0.8961, Bottom 30th Acc: 0.6061
Fold [3/5] Epoch [30/100] Initial Loss: 0.1395, Training Loss: 0.0219, Initial Validation Loss: 0.1300, Validation Loss: 0.0326,V Acc: 0.8273, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 39  Rolling back to Epoch (base 0): 34  Top Validation Acc: 0.9090909090909091
Fold [4/5] Epoch [0/100] Initial Loss: 0.1362, Training Loss: 0.1362, Initial Validation Loss: 0.1294, Validation Loss: 0.1294,V Acc: 0.3853, Top 70th Acc: 0.4805, Bottom 30th Acc: 0.1562
Fold [4/5] Epoch [10/100] Initial Loss: 0.1362, Training Loss: 0.0408, Initial Validation Loss: 0.1294, Validation Loss: 0.0281,V Acc: 0.8899, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.7500
Fold [4/5] Epoch [20/100] Initial Loss: 0.1362, Training Loss: 0.0266, Initial Validation Loss: 0.1294, Validation Loss: 0.0194,V Acc: 0.9174, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.7812
Stopping early at Epoch (base 0): 21  Rolling back to Epoch (base 0): 16  Top Validation Acc: 0.974025974025974
Fold [5/5] Epoch [0/100] Initial Loss: 0.1440, Training Loss: 0.1440, Initial Validation Loss: 0.1355, Validation Loss: 0.1355,V Acc: 0.2315, Top 70th Acc: 0.3026, Bottom 30th Acc: 0.0625
Fold [5/5] Epoch [10/100] Initial Loss: 0.1440, Training Loss: 0.0458, Initial Validation Loss: 0.1355, Validation Loss: 0.0496,V Acc: 0.7778, Top 70th Acc: 0.8816, Bottom 30th Acc: 0.5312
Fold [5/5] Epoch [20/100] Initial Loss: 0.1440, Training Loss: 0.0239, Initial Validation Loss: 0.1355, Validation Loss: 0.0373,V Acc: 0.8056, Top 70th Acc: 0.9079, Bottom 30th Acc: 0.5625
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.9078947368421053
Running train_nn.py with seed 48
CUDA:False
Training samples count:  550
Training on 20 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1382, Training Loss: 0.1382, Initial Validation Loss: 0.1349, Validation Loss: 0.1349,V Acc: 0.3304, Top 70th Acc: 0.3797, Bottom 30th Acc: 0.2121
Fold [1/5] Epoch [10/100] Initial Loss: 0.1382, Training Loss: 0.0456, Initial Validation Loss: 0.1349, Validation Loss: 0.0487,V Acc: 0.7589, Top 70th Acc: 0.8608, Bottom 30th Acc: 0.5152
Fold [1/5] Epoch [20/100] Initial Loss: 0.1382, Training Loss: 0.0256, Initial Validation Loss: 0.1349, Validation Loss: 0.0337,V Acc: 0.8482, Top 70th Acc: 0.9367, Bottom 30th Acc: 0.6364
Fold [1/5] Epoch [30/100] Initial Loss: 0.1382, Training Loss: 0.0230, Initial Validation Loss: 0.1349, Validation Loss: 0.0313,V Acc: 0.8304, Top 70th Acc: 0.9367, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 38  Rolling back to Epoch (base 0): 33  Top Validation Acc: 0.9367088607594937
Fold [2/5] Epoch [0/100] Initial Loss: 0.1437, Training Loss: 0.1437, Initial Validation Loss: 0.1376, Validation Loss: 0.1376,V Acc: 0.2703, Top 70th Acc: 0.2821, Bottom 30th Acc: 0.2424
Fold [2/5] Epoch [10/100] Initial Loss: 0.1437, Training Loss: 0.0339, Initial Validation Loss: 0.1376, Validation Loss: 0.0483,V Acc: 0.8288, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.6364
Fold [2/5] Epoch [20/100] Initial Loss: 0.1437, Training Loss: 0.0208, Initial Validation Loss: 0.1376, Validation Loss: 0.0405,V Acc: 0.8288, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.9102564102564102
48 1 [array([0.58299106, 0.10246724, 0.06626572, 0.15647896, 0.09179701],
      dtype=float32)]
Fold [3/5] Epoch [0/100] Initial Loss: 0.1334, Training Loss: 0.1334, Initial Validation Loss: 0.1241, Validation Loss: 0.1241,V Acc: 0.4182, Top 70th Acc: 0.4805, Bottom 30th Acc: 0.2727
Fold [3/5] Epoch [10/100] Initial Loss: 0.1334, Training Loss: 0.0407, Initial Validation Loss: 0.1241, Validation Loss: 0.0411,V Acc: 0.8000, Top 70th Acc: 0.8961, Bottom 30th Acc: 0.5758
Fold [3/5] Epoch [20/100] Initial Loss: 0.1334, Training Loss: 0.0240, Initial Validation Loss: 0.1241, Validation Loss: 0.0316,V Acc: 0.8545, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 27  Rolling back to Epoch (base 0): 22  Top Validation Acc: 0.9090909090909091
Fold [4/5] Epoch [0/100] Initial Loss: 0.1369, Training Loss: 0.1369, Initial Validation Loss: 0.1287, Validation Loss: 0.1287,V Acc: 0.4037, Top 70th Acc: 0.4805, Bottom 30th Acc: 0.2188
Fold [4/5] Epoch [10/100] Initial Loss: 0.1369, Training Loss: 0.0347, Initial Validation Loss: 0.1287, Validation Loss: 0.0317,V Acc: 0.8807, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.7500
Fold [4/5] Epoch [20/100] Initial Loss: 0.1369, Training Loss: 0.0236, Initial Validation Loss: 0.1287, Validation Loss: 0.0293,V Acc: 0.8440, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.6562
Stopping early at Epoch (base 0): 27  Rolling back to Epoch (base 0): 22  Top Validation Acc: 0.935064935064935
Fold [5/5] Epoch [0/100] Initial Loss: 0.1405, Training Loss: 0.1405, Initial Validation Loss: 0.1332, Validation Loss: 0.1332,V Acc: 0.2500, Top 70th Acc: 0.2632, Bottom 30th Acc: 0.2188
Fold [5/5] Epoch [10/100] Initial Loss: 0.1405, Training Loss: 0.0385, Initial Validation Loss: 0.1332, Validation Loss: 0.0352,V Acc: 0.8611, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.6562
Fold [5/5] Epoch [20/100] Initial Loss: 0.1405, Training Loss: 0.0251, Initial Validation Loss: 0.1332, Validation Loss: 0.0272,V Acc: 0.8889, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.7500
Fold [5/5] Epoch [30/100] Initial Loss: 0.1405, Training Loss: 0.0226, Initial Validation Loss: 0.1332, Validation Loss: 0.0278,V Acc: 0.8704, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.7188
Stopping early at Epoch (base 0): 30  Rolling back to Epoch (base 0): 25  Top Validation Acc: 0.9342105263157895
Running train_nn.py with seed 49
CUDA:False
Training samples count:  550
Training on 20 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1411, Training Loss: 0.1411, Initial Validation Loss: 0.1356, Validation Loss: 0.1356,V Acc: 0.2589, Top 70th Acc: 0.3038, Bottom 30th Acc: 0.1515
Fold [1/5] Epoch [20/100] Initial Loss: 0.1389, Training Loss: 0.0175, Initial Validation Loss: 0.1281, Validation Loss: 0.0279,V Acc: 0.8214, Top 70th Acc: 0.9494, Bottom 30th Acc: 0.5152
Stopping early at Epoch (base 0): 28  Rolling back to Epoch (base 0): 23  Top Validation Acc: 0.9493670886075949
Fold [2/5] Epoch [0/100] Initial Loss: 0.1384, Training Loss: 0.1384, Initial Validation Loss: 0.1294, Validation Loss: 0.1294,V Acc: 0.4505, Top 70th Acc: 0.5897, Bottom 30th Acc: 0.1212
Fold [2/5] Epoch [10/100] Initial Loss: 0.1384, Training Loss: 0.0269, Initial Validation Loss: 0.1294, Validation Loss: 0.0324,V Acc: 0.9009, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.7273
Fold [2/5] Epoch [20/100] Initial Loss: 0.1384, Training Loss: 0.0155, Initial Validation Loss: 0.1294, Validation Loss: 0.0249,V Acc: 0.8739, Top 70th Acc: 0.9872, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 27  Rolling back to Epoch (base 0): 22  Top Validation Acc: 0.9743589743589743
Fold [3/5] Epoch [0/100] Initial Loss: 0.1307, Training Loss: 0.1307, Initial Validation Loss: 0.1182, Validation Loss: 0.1182,V Acc: 0.4636, Top 70th Acc: 0.6364, Bottom 30th Acc: 0.0606
Fold [3/5] Epoch [10/100] Initial Loss: 0.1307, Training Loss: 0.0198, Initial Validation Loss: 0.1182, Validation Loss: 0.0334,V Acc: 0.8455, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 17  Rolling back to Epoch (base 0): 12  Top Validation Acc: 0.8961038961038961
Fold [4/5] Epoch [0/100] Initial Loss: 0.1387, Training Loss: 0.1387, Initial Validation Loss: 0.1273, Validation Loss: 0.1273,V Acc: 0.4312, Top 70th Acc: 0.5584, Bottom 30th Acc: 0.1250
Fold [4/5] Epoch [10/100] Initial Loss: 0.1387, Training Loss: 0.0278, Initial Validation Loss: 0.1273, Validation Loss: 0.0218,V Acc: 0.9358, Top 70th Acc: 0.9870, Bottom 30th Acc: 0.8125
Fold [4/5] Epoch [20/100] Initial Loss: 0.1387, Training Loss: 0.0172, Initial Validation Loss: 0.1273, Validation Loss: 0.0187,V Acc: 0.9083, Top 70th Acc: 1.0000, Bottom 30th Acc: 0.6875
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.987012987012987
65 3 [array([0.7542231 , 0.03633258, 0.02329156, 0.08802843, 0.09812431],
      dtype=float32)]
Fold [5/5] Epoch [0/100] Initial Loss: 0.1338, Training Loss: 0.1338, Initial Validation Loss: 0.1171, Validation Loss: 0.1171,V Acc: 0.4444, Top 70th Acc: 0.5263, Bottom 30th Acc: 0.2500
Fold [5/5] Epoch [10/100] Initial Loss: 0.1338, Training Loss: 0.0224, Initial Validation Loss: 0.1171, Validation Loss: 0.0271,V Acc: 0.8704, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.7188
Fold [5/5] Epoch [20/100] Initial Loss: 0.1338, Training Loss: 0.0166, Initial Validation Loss: 0.1171, Validation Loss: 0.0249,V Acc: 0.8889, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.7500
Stopping early at Epoch (base 0): 20  Rolling back to Epoch (base 0): 15  Top Validation Acc: 0.9473684210526315
Running train_nn.py with seed 66
CUDA:False
Training samples count:  550
Training on 21 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1332, Training Loss: 0.1332, Initial Validation Loss: 0.1280, Validation Loss: 0.1280,V Acc: 0.4375, Top 70th Acc: 0.4557, Bottom 30th Acc: 0.3939
Fold [1/5] Epoch [10/100] Initial Loss: 0.1332, Training Loss: 0.0241, Initial Validation Loss: 0.1280, Validation Loss: 0.0305,V Acc: 0.8839, Top 70th Acc: 0.9367, Bottom 30th Acc: 0.7576
Fold [1/5] Epoch [20/100] Initial Loss: 0.1332, Training Loss: 0.0154, Initial Validation Loss: 0.1280, Validation Loss: 0.0202,V Acc: 0.8929, Top 70th Acc: 0.9873, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.9746835443037974
Fold [2/5] Epoch [0/100] Initial Loss: 0.1316, Training Loss: 0.1316, Initial Validation Loss: 0.1174, Validation Loss: 0.1174,V Acc: 0.5495, Top 70th Acc: 0.6282, Bottom 30th Acc: 0.3636
Fold [2/5] Epoch [10/100] Initial Loss: 0.1316, Training Loss: 0.0183, Initial Validation Loss: 0.1174, Validation Loss: 0.0245,V Acc: 0.9279, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.8788
Fold [2/5] Epoch [20/100] Initial Loss: 0.1316, Training Loss: 0.0142, Initial Validation Loss: 0.1174, Validation Loss: 0.0236,V Acc: 0.8919, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.7273
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.9743589743589743
66 1 [array([0.7398902 , 0.02770679, 0.04283956, 0.11199666, 0.07756679],
      dtype=float32)]
Fold [3/5] Epoch [0/100] Initial Loss: 0.1298, Training Loss: 0.1298, Initial Validation Loss: 0.1111, Validation Loss: 0.1111,V Acc: 0.5182, Top 70th Acc: 0.6494, Bottom 30th Acc: 0.2121
Fold [3/5] Epoch [10/100] Initial Loss: 0.1298, Training Loss: 0.0225, Initial Validation Loss: 0.1111, Validation Loss: 0.0280,V Acc: 0.8636, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 16  Rolling back to Epoch (base 0): 11  Top Validation Acc: 0.948051948051948
Fold [4/5] Epoch [0/100] Initial Loss: 0.1338, Training Loss: 0.1338, Initial Validation Loss: 0.1217, Validation Loss: 0.1217,V Acc: 0.4587, Top 70th Acc: 0.5714, Bottom 30th Acc: 0.1875
Fold [4/5] Epoch [10/100] Initial Loss: 0.1338, Training Loss: 0.0250, Initial Validation Loss: 0.1217, Validation Loss: 0.0277,V Acc: 0.8807, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.6875
Fold [4/5] Epoch [20/100] Initial Loss: 0.1338, Training Loss: 0.0187, Initial Validation Loss: 0.1217, Validation Loss: 0.0299,V Acc: 0.8440, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.6562
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.974025974025974
Fold [5/5] Epoch [0/100] Initial Loss: 0.1392, Training Loss: 0.1392, Initial Validation Loss: 0.1274, Validation Loss: 0.1274,V Acc: 0.2500, Top 70th Acc: 0.3421, Bottom 30th Acc: 0.0312
Fold [5/5] Epoch [10/100] Initial Loss: 0.1392, Training Loss: 0.0199, Initial Validation Loss: 0.1274, Validation Loss: 0.0362,V Acc: 0.8241, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.5625
Stopping early at Epoch (base 0): 16  Rolling back to Epoch (base 0): 11  Top Validation Acc: 0.9342105263157895
Running train_nn.py with seed 67
CUDA:False
Training samples count:  550
Training on 21 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1361, Training Loss: 0.1361, Initial Validation Loss: 0.1278, Validation Loss: 0.1278,V Acc: 0.4286, Top 70th Acc: 0.5443, Bottom 30th Acc: 0.1515
Fold [1/5] Epoch [10/100] Initial Loss: 0.1361, Training Loss: 0.0231, Initial Validation Loss: 0.1278, Validation Loss: 0.0315,V Acc: 0.8482, Top 70th Acc: 0.9494, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 18  Rolling back to Epoch (base 0): 13  Top Validation Acc: 0.9746835443037974
Fold [2/5] Epoch [0/100] Initial Loss: 0.1321, Training Loss: 0.1321, Initial Validation Loss: 0.1149, Validation Loss: 0.1149,V Acc: 0.4865, Top 70th Acc: 0.6538, Bottom 30th Acc: 0.0909
Fold [2/5] Epoch [10/100] Initial Loss: 0.1321, Training Loss: 0.0219, Initial Validation Loss: 0.1149, Validation Loss: 0.0391,V Acc: 0.8018, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.5455
Fold [2/5] Epoch [20/100] Initial Loss: 0.1321, Training Loss: 0.0151, Initial Validation Loss: 0.1149, Validation Loss: 0.0278,V Acc: 0.8468, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.5758
Fold [2/5] Epoch [30/100] Initial Loss: 0.1321, Training Loss: 0.0132, Initial Validation Loss: 0.1149, Validation Loss: 0.0299,V Acc: 0.8378, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 30  Rolling back to Epoch (base 0): 25  Top Validation Acc: 0.9487179487179487
Fold [3/5] Epoch [0/100] Initial Loss: 0.1333, Training Loss: 0.1333, Initial Validation Loss: 0.1210, Validation Loss: 0.1210,V Acc: 0.4727, Top 70th Acc: 0.6104, Bottom 30th Acc: 0.1515
Fold [3/5] Epoch [10/100] Initial Loss: 0.1333, Training Loss: 0.0266, Initial Validation Loss: 0.1210, Validation Loss: 0.0303,V Acc: 0.8909, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.7273
Fold [3/5] Epoch [20/100] Initial Loss: 0.1333, Training Loss: 0.0179, Initial Validation Loss: 0.1210, Validation Loss: 0.0225,V Acc: 0.8818, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0):
Fold [4/5] Epoch [10/100] Initial Loss: 0.1378, Training Loss: 0.0791, Initial Validation Loss: 0.1225, Validation Loss: 0.0837,V Acc: 0.5963, Top 70th Acc: 0.7273, Bottom 30th Acc: 0.2812
Fold [4/5] Epoch [20/100] Initial Loss: 0.1378, Training Loss: 0.0776, Initial Validation Loss: 0.1225, Validation Loss: 0.0830,V Acc: 0.5963, Top 70th Acc: 0.7273, Bottom 30th Acc: 0.2812
Fold [4/5] Epoch [30/100] Initial Loss: 0.1378, Training Loss: 0.0767, Initial Validation Loss: 0.1225, Validation Loss: 0.0821,V Acc: 0.5688, Top 70th Acc: 0.7273, Bottom 30th Acc: 0.1875
Stopping early at Epoch (base 0): 37  Rolling back to Epoch (base 0): 32  Top Validation Acc: 0.7272727272727273
Fold [5/5] Epoch [0/100] Initial Loss: 0.1310, Training Loss: 0.1310, Initial Validation Loss: 0.1191, Validation Loss: 0.1191,V Acc: 0.5000, Top 70th Acc: 0.5921, Bottom 30th Acc: 0.2812
Fold [5/5] Epoch [10/100] Initial Loss: 0.1310, Training Loss: 0.0797, Initial Validation Loss: 0.1191, Validation Loss: 0.0778,V Acc: 0.6481, Top 70th Acc: 0.7632, Bottom 30th Acc: 0.3750
Fold [5/5] Epoch [20/100] Initial Loss: 0.1310, Training Loss: 0.0784, Initial Validation Loss: 0.1191, Validation Loss: 0.0766,V Acc: 0.6481, Top 70th Acc: 0.7632, Bottom 30th Acc: 0.3750
Stopping early at Epoch (base 0): 29  Rolling back to Epoch (base 0): 24  Top Validation Acc: 0.7763157894736842
Running train_nn.py with seed 47
CUDA:False
Training samples count:  550
Training on 2 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1361, Training Loss: 0.1361, Initial Validation Loss: 0.1299, Validation Loss: 0.1299,V Acc: 0.2946, Top 70th Acc: 0.3291, Bottom 30th Acc: 0.2121
Fold [1/5] Epoch [10/100] Initial Loss: 0.1361, Training Loss: 0.0785, Initial Validation Loss: 0.1299, Validation Loss: 0.0865,V Acc: 0.6071, Top 70th Acc: 0.6582, Bottom 30th Acc: 0.4848
Stopping early at Epoch (base 0): 14  Rolling back to Epoch (base 0): 9  Top Validation Acc: 0.6582278481012658
Fold [2/5] Epoch [0/100] Initial Loss: 0.1382, Training Loss: 0.1382, Initial Validation Loss: 0.1228, Validation Loss: 0.1228,V Acc: 0.4144, Top 70th Acc: 0.5513, Bottom 30th Acc: 0.0909
Fold [2/5] Epoch [10/100] Initial Loss: 0.1382, Training Loss: 0.0809, Initial Validation Loss: 0.1228, Validation Loss: 0.0773,V Acc: 0.6306, Top 70th Acc: 0.7564, Bottom 30th Acc: 0.3333
Fold [2/5] Epoch [20/100] Initial Loss: 0.1382, Training Loss: 0.0788, Initial Validation Loss: 0.1228, Validation Loss: 0.0756,V Acc: 0.6577, Top 70th Acc: 0.7436, Bottom 30th Acc: 0.4545
Fold [2/5] Epoch [30/100] Initial Loss: 0.1382, Training Loss: 0.0779, Initial Validation Loss: 0.1228, Validation Loss: 0.0752,V Acc: 0.6216, Top 70th Acc: 0.7308, Bottom 30th Acc: 0.3636
Fold [2/5] Epoch [40/100] Initial Loss: 0.1382, Training Loss: 0.0778, Initial Validation Loss: 0.1228, Validation Loss: 0.0750,V Acc: 0.6306, Top 70th Acc: 0.7308, Bottom 30th Acc: 0.3939
Stopping early at Epoch (base 0): 40  Rolling back to Epoch (base 0): 35  Top Validation Acc: 0.7307692307692307
47 1 [array([0.15367657, 0.33880746, 0.13016964, 0.23483717, 0.14250909],
      dtype=float32)]
Fold [3/5] Epoch [0/100] Initial Loss: 0.1361, Training Loss: 0.1361, Initial Validation Loss: 0.1241, Validation Loss: 0.1241,V Acc: 0.3909, Top 70th Acc: 0.4935, Bottom 30th Acc: 0.1515
Fold [3/5] Epoch [10/100] Initial Loss: 0.1361, Training Loss: 0.0799, Initial Validation Loss: 0.1241, Validation Loss: 0.0806,V Acc: 0.6182, Top 70th Acc: 0.7273, Bottom 30th Acc: 0.3636
Fold [3/5] Epoch [20/100] Initial Loss: 0.1361, Training Loss: 0.0782, Initial Validation Loss: 0.1241, Validation Loss: 0.0799,V Acc: 0.6182, Top 70th Acc: 0.7273, Bottom 30th Acc: 0.3636
Fold [3/5] Epoch [30/100] Initial Loss: 0.1361, Training Loss: 0.0774, Initial Validation Loss: 0.1241, Validation Loss: 0.0791,V Acc: 0.6182, Top 70th Acc: 0.7273, Bottom 30th Acc: 0.3636
Fold [3/5] Epoch [40/100] Initial Loss: 0.1361, Training Loss: 0.0766, Initial Validation Loss: 0.1241, Validation Loss: 0.0786,V Acc: 0.6091, Top 70th Acc: 0.7403, Bottom 30th Acc: 0.3030
Stopping early at Epoch (base 0): 42  Rolling back to Epoch (base 0): 37  Top Validation Acc: 0.7532467532467533
Fold [4/5] Epoch [0/100] Initial Loss: 0.1369, Training Loss: 0.1369, Initial Validation Loss: 0.1263, Validation Loss: 0.1263,V Acc: 0.4037, Top 70th Acc: 0.3896, Bottom 30th Acc: 0.4375
Fold [4/5] Epoch [10/100] Initial Loss: 0.1369, Training Loss: 0.0832, Initial Validation Loss: 0.1263, Validation Loss: 0.0722,V Acc: 0.6606, Top 70th Acc: 0.7792, Bottom 30th Acc: 0.3750
Fold [4/5] Epoch [20/100] Initial Loss: 0.1369, Training Loss: 0.0813, Initial Validation Loss: 0.1263, Validation Loss: 0.0696,V Acc: 0.6697, Top 70th Acc: 0.7792, Bottom 30th Acc: 0.4062
Fold [4/5] Epoch [30/100] Initial Loss: 0.1369, Training Loss: 0.0805, Initial Validation Loss: 0.1263, Validation Loss: 0.0681,V Acc: 0.6789, Top 70th Acc: 0.8182, Bottom 30th Acc: 0.3438
Stopping early at Epoch (base 0): 33  Rolling back to Epoch (base 0): 28  Top Validation Acc: 0.7922077922077922
Fold [5/5] Epoch [0/100] Initial Loss: 0.1355, Training Loss: 0.1355, Initial Validation Loss: 0.1265, Validation Loss: 0.1265,V Acc: 0.4259, Top 70th Acc: 0.5658, Bottom 30th Acc: 0.0938
Fold [5/5] Epoch [10/100] Initial Loss: 0.1355, Training Loss: 0.0798, Initial Validation Loss: 0.1265, Validation Loss: 0.0802,V Acc: 0.6296, Top 70th Acc: 0.7632, Bottom 30th Acc: 0.3125
Fold [5/5] Epoch [20/100] Initial Loss: 0.1355, Training Loss: 0.0780, Initial Validation Loss: 0.1265, Validation Loss: 0.0775,V Acc: 0.6296, Top 70th Acc: 0.7500, Bottom 30th Acc: 0.3438
Fold [5/5] Epoch [30/100] Initial Loss: 0.1355, Training Loss: 0.0774, Initial Validation Loss: 0.1265, Validation Loss: 0.0768,V Acc: 0.6296, Top 70th Acc: 0.7632, Bottom 30th Acc: 0.3125
Stopping early at Epoch (base 0): 36  Rolling back to Epoch (base 0): 31  Top Validation Acc: 0.7763157894736842
Running train_nn.py with seed 48
CUDA:False
Training samples count:  550
Training on 2 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1429, Training Loss: 0.1429, Initial Validation Loss: 0.1334, Validation Loss: 0.1334,V Acc: 0.3839, Top 70th Acc: 0.4684, Bottom 30th Acc: 0.1818
Fold [1/5] Epoch [10/100] Initial Loss: 0.1429, Training Loss: 0.0812, Initial Validation Loss: 0.1334, Validation Loss: 0.0803,V Acc: 0.6250, Top 70th Acc: 0.7342, Bottom 30th Acc: 0.3636
Fold [1/5] Epoch [20/100] Initial Loss: 0.1429, Training Loss: 0.0790, Initial Validation Loss: 0.1334, Validation Loss: 0.0794,V Acc: 0.6161, Top 70th Acc: 0.7595, Bottom 30th Acc: 0.2727
Fold [1/5] Epoch [30/100] Initial Loss: 0.1429, Training Loss: 0.0783, Initial Validation Loss: 0.1334, Validation Loss: 0.0790,V Acc: 0.6161, Top 70th Acc: 0.7342, Bottom 30th Acc: 0.3333
Stopping early at Epoch (base 0): 39  Rolling back to Epoch (base 0): 34  Top Validation Acc: 0.7721518987341772
Fold [2/5] Epoch [0/100] Initial Loss: 0.1318, Training Loss: 0.1318, Initial Validation Loss: 0.1271, Validation Loss: 0.1271,V Acc: 0.4685, Top 70th Acc: 0.5128, Bottom 30th Acc: 0.3636
Fold [2/5] Epoch [10/100] Initial Loss: 0.1318, Training Loss: 0.0756, Initial Validation Loss: 0.1271, Validation Loss: 0.1007,V Acc: 0.5135, Top 70th Acc: 0.6154, Bottom 30th Acc: 0.2727
Stopping early at Epoch (base 0): 16  Rolling back to Epoch (base 0): 11  Top Validation Acc: 0.6153846153846154
48 1 [array([0.10954461, 0.4070996 , 0.16218977, 0.1661357 , 0.15503031],
      dtype=float32)]
Fold [3/5] Epoch [0/100] Initial Loss: 0.1376, Training Loss: 0.1376, Initial Validation Loss: 0.1259, Validation Loss: 0.1259,V Acc: 0.4455, Top 70th Acc: 0.6104, Bottom 30th Acc: 0.0606
Fold [3/5] Epoch [10/100] Initial Loss: 0.1376, Training Loss: 0.0798, Initial Validation Loss: 0.1259, Validation Loss: 0.0791,V Acc: 0.6182, Top 70th Acc: 0.7403, Bottom 30th Acc: 0.3333
Fold [3/5] Epoch [20/100] Initial Loss: 0.1376, Training Loss: 0.0776, Initial Validation Loss: 0.1259, Validation Loss: 0.0781,V Acc: 0.6091, Top 70th Acc: 0.7273, Bottom 30th Acc: 0.3333
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.7402597402597403
Fold [4/5] Epoch [0/100] Initial Loss: 0.1381, Training Loss: 0.1381, Initial Validation Loss: 0.1240, Validation Loss: 0.1240,V Acc: 0.4587, Top 70th Acc: 0.5844, Bottom 30th Acc: 0.1562
Stopping early at Epoch (base 0): 31  Rolling back to Epoch (base 0): 26  Top Validation Acc: 0.9367088607594937
Fold [2/5] Epoch [0/100] Initial Loss: 0.1387, Training Loss: 0.1387, Initial Validation Loss: 0.1318, Validation Loss: 0.1318,V Acc: 0.4234, Top 70th Acc: 0.5000, Bottom 30th Acc: 0.2424
Fold [2/5] Epoch [10/100] Initial Loss: 0.1387, Training Loss: 0.0354, Initial Validation Loss: 0.1318, Validation Loss: 0.0410,V Acc: 0.8378, Top 70th Acc: 0.8846, Bottom 30th Acc: 0.7273
Fold [2/5] Epoch [20/100] Initial Loss: 0.1387, Training Loss: 0.0185, Initial Validation Loss: 0.1318, Validation Loss: 0.0306,V Acc: 0.8468, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.9358974358974359
47 1 [array([0.5503292 , 0.06928191, 0.05048266, 0.1083528 , 0.22155342],
      dtype=float32)]
Fold [3/5] Epoch [0/100] Initial Loss: 0.1380, Training Loss: 0.1380, Initial Validation Loss: 0.1313, Validation Loss: 0.1313,V Acc: 0.3091, Top 70th Acc: 0.4026, Bottom 30th Acc: 0.0909
Fold [3/5] Epoch [10/100] Initial Loss: 0.1380, Training Loss: 0.0269, Initial Validation Loss: 0.1313, Validation Loss: 0.0418,V Acc: 0.8000, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.5455
Fold [3/5] Epoch [20/100] Initial Loss: 0.1380, Training Loss: 0.0170, Initial Validation Loss: 0.1313, Validation Loss: 0.0331,V Acc: 0.8273, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.6061
Fold [3/5] Epoch [30/100] Initial Loss: 0.1380, Training Loss: 0.0149, Initial Validation Loss: 0.1313, Validation Loss: 0.0332,V Acc: 0.8273, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 31  Rolling back to Epoch (base 0): 26  Top Validation Acc: 0.9090909090909091
Fold [4/5] Epoch [0/100] Initial Loss: 0.1388, Training Loss: 0.1388, Initial Validation Loss: 0.1329, Validation Loss: 0.1329,V Acc: 0.4128, Top 70th Acc: 0.4675, Bottom 30th Acc: 0.2812
Fold [4/5] Epoch [10/100] Initial Loss: 0.1388, Training Loss: 0.0355, Initial Validation Loss: 0.1329, Validation Loss: 0.0282,V Acc: 0.8899, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.6875
Fold [4/5] Epoch [20/100] Initial Loss: 0.1388, Training Loss: 0.0184, Initial Validation Loss: 0.1329, Validation Loss: 0.0207,V Acc: 0.9174, Top 70th Acc: 0.9870, Bottom 30th Acc: 0.7500
Fold [4/5] Epoch [30/100] Initial Loss: 0.1388, Training Loss: 0.0153, Initial Validation Loss: 0.1329, Validation Loss: 0.0197,V Acc: 0.9174, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.7812
Stopping early at Epoch (base 0): 30  Rolling back to Epoch (base 0): 25  Top Validation Acc: 0.974025974025974
Fold [5/5] Epoch [0/100] Initial Loss: 0.1371, Training Loss: 0.1371, Initial Validation Loss: 0.1328, Validation Loss: 0.1328,V Acc: 0.2500, Top 70th Acc: 0.3289, Bottom 30th Acc: 0.0625
Fold [5/5] Epoch [10/100] Initial Loss: 0.1371, Training Loss: 0.0309, Initial Validation Loss: 0.1328, Validation Loss: 0.0370,V Acc: 0.8333, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.5625
Fold [5/5] Epoch [20/100] Initial Loss: 0.1371, Training Loss: 0.0175, Initial Validation Loss: 0.1328, Validation Loss: 0.0311,V Acc: 0.8519, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.6250
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.9736842105263158
Running train_nn.py with seed 48
CUDA:False
Training samples count:  550
Training on 30 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1393, Training Loss: 0.1393, Initial Validation Loss: 0.1348, Validation Loss: 0.1348,V Acc: 0.4018, Top 70th Acc: 0.4051, Bottom 30th Acc: 0.3939
Fold [1/5] Epoch [10/100] Initial Loss: 0.1393, Training Loss: 0.0279, Initial Validation Loss: 0.1348, Validation Loss: 0.0365,V Acc: 0.8482, Top 70th Acc: 0.9114, Bottom 30th Acc: 0.6970
Fold [1/5] Epoch [20/100] Initial Loss: 0.1393, Training Loss: 0.0168, Initial Validation Loss: 0.1348, Validation Loss: 0.0341,V Acc: 0.8214, Top 70th Acc: 0.9241, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.9240506329113924
Fold [2/5] Epoch [0/100] Initial Loss: 0.1365, Training Loss: 0.1365, Initial Validation Loss: 0.1337, Validation Loss: 0.1337,V Acc: 0.4234, Top 70th Acc: 0.4744, Bottom 30th Acc: 0.3030
Fold [2/5] Epoch [10/100] Initial Loss: 0.1365, Training Loss: 0.0356, Initial Validation Loss: 0.1337, Validation Loss: 0.0575,V Acc: 0.7477, Top 70th Acc: 0.8718, Bottom 30th Acc: 0.4545
Fold [2/5] Epoch [20/100] Initial Loss: 0.1365, Training Loss: 0.0154, Initial Validation Loss: 0.1337, Validation Loss: 0.0402,V Acc: 0.8378, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.6061
Fold [2/5] Epoch [30/100] Initial Loss: 0.1365, Training Loss: 0.0130, Initial Validation Loss: 0.1337, Validation Loss: 0.0412,V Acc: 0.8108, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.4848
Stopping early at Epoch (base 0): 30  Rolling back to Epoch (base 0): 25  Top Validation Acc: 0.9487179487179487
48 1 [array([0.81496465, 0.04462832, 0.02329248, 0.08457898, 0.0325355 ],
      dtype=float32)]
Fold [3/5] Epoch [0/100] Initial Loss: 0.1393, Training Loss: 0.1393, Initial Validation Loss: 0.1325, Validation Loss: 0.1325,V Acc: 0.2545, Top 70th Acc: 0.3247, Bottom 30th Acc: 0.0909
Fold [3/5] Epoch [10/100] Initial Loss: 0.1393, Training Loss: 0.0383, Initial Validation Loss: 0.1325, Validation Loss: 0.0394,V Acc: 0.8091, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.5758
Fold [3/5] Epoch [20/100] Initial Loss: 0.1393, Training Loss: 0.0228, Initial Validation Loss: 0.1325, Validation Loss: 0.0314,V Acc: 0.8364, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.5455
Fold [3/5] Epoch [30/100] Initial Loss: 0.1393, Training Loss: 0.0168, Initial Validation Loss: 0.1325, Validation Loss: 0.0285,V Acc: 0.8455, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.5758
Fold [3/5] Epoch [40/100] Initial Loss: 0.1393, Training Loss: 0.0144, Initial Validation Loss: 0.1325, Validation Loss: 0.0289,V Acc: 0.8364, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 41  Rolling back to Epoch (base 0): 36  Top Validation Acc: 0.948051948051948
Fold [4/5] Epoch [0/100] Initial Loss: 0.1374, Training Loss: 0.1374, Initial Validation Loss: 0.1288, Validation Loss: 0.1288,V Acc: 0.3211, Top 70th Acc: 0.4156, Bottom 30th Acc: 0.0938
Fold [4/5] Epoch [10/100] Initial Loss: 0.1374, Training Loss: 0.0361, Initial Validation Loss: 0.1288, Validation Loss: 0.0411,V Acc: 0.7890, Top 70th Acc: 0.8701, Bottom 30th Acc: 0.5938
Fold [4/5] Epoch [20/100] Initial Loss: 0.1374, Training Loss: 0.0201, Initial Validation Loss: 0.1288, Validation Loss: 0.0266,V Acc: 0.8716, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6875
Fold [4/5] Epoch [30/100] Initial Loss: 0.1374, Training Loss: 0.0162, Initial Validation Loss: 0.1288, Validation Loss: 0.0247,V Acc: 0.8716, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.7188
Stopping early at Epoch (base 0): 35  Rolling back to Epoch (base 0): 30  Top Validation Acc: 0.948051948051948
Fold [5/5] Epoch [0/100] Initial Loss: 0.1390, Training Loss: 0.1390, Initial Validation Loss: 0.1322, Validation Loss: 0.1322,V Acc: 0.2685, Top 70th Acc: 0.2895, Bottom 30th Acc: 0.2188
Fold [5/5] Epoch [10/100] Initial Loss: 0.1390, Training Loss: 0.0424, Initial Validation Loss: 0.1322, Validation Loss: 0.0413,V Acc: 0.7778, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.4062
Fold [5/5] Epoch [20/100] Initial Loss: 0.1390, Training Loss: 0.0222, Initial Validation Loss: 0.1322, Validation Loss: 0.0269,V Acc: 0.8426, Top 70th Acc: 0.9737, Bottom 30th Acc: 0.5312
Fold [5/5] Epoch [30/100] Initial Loss: 0.1390, Training Loss: 0.0175, Initial Validation Loss: 0.1322, Validation Loss: 0.0245,V Acc: 0.8704, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.6562
Stopping early at Epoch (base 0): 38  Rolling back to Epoch (base 0): 33  Top Validation Acc: 0.9473684210526315
Running train_nn.py with seed 49
CUDA:False
Training samples count:  550
Training on 30 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1383, Training Loss: 0.1383, Initial Validation Loss: 0.1316, Validation Loss: 0.1316,V Acc: 0.3304, Top 70th Acc: 0.3924, Bottom 30th Acc: 0.1818
Fold [1/5] Epoch [10/100] Initial Loss: 0.1383, Training Loss: 0.0293, Initial Validation Loss: 0.1316, Validation Loss: 0.0329,V Acc: 0.8482, Top 70th Acc: 0.9620, Bottom 30th Acc: 0.5758 57  Rolling back to Epoch (base 0): 52  Top Validation Acc: 0.9493670886075949
Fold [2/5] Epoch [0/100] Initial Loss: 0.1423, Training Loss: 0.1423, Initial Validation Loss: 0.1338, Validation Loss: 0.1338,V Acc: 0.2613, Top 70th Acc: 0.2692, Bottom 30th Acc: 0.2424
Fold [2/5] Epoch [10/100] Initial Loss: 0.1423, Training Loss: 0.0208, Initial Validation Loss: 0.1338, Validation Loss: 0.0493,V Acc: 0.7477, Top 70th Acc: 0.8718, Bottom 30th Acc: 0.4545
Fold [2/5] Epoch [20/100] Initial Loss: 0.1423, Training Loss: 0.0049, Initial Validation Loss: 0.1338, Validation Loss: 0.0376,V Acc: 0.8108, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.9102564102564102
38 1 [array([0.05029858, 0.03747144, 0.11573329, 0.274474  , 0.5220227 ],
      dtype=float32)]
Fold [3/5] Epoch [0/100] Initial Loss: 0.1440, Training Loss: 0.1440, Initial Validation Loss: 0.1348, Validation Loss: 0.1348,V Acc: 0.2636, Top 70th Acc: 0.3377, Bottom 30th Acc: 0.0909
Fold [3/5] Epoch [10/100] Initial Loss: 0.1440, Training Loss: 0.0317, Initial Validation Loss: 0.1348, Validation Loss: 0.0483,V Acc: 0.7364, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.3333
Fold [3/5] Epoch [20/100] Initial Loss: 0.1440, Training Loss: 0.0057, Initial Validation Loss: 0.1348, Validation Loss: 0.0305,V Acc: 0.8455, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.5455
Fold [3/5] Epoch [30/100] Initial Loss: 0.1440, Training Loss: 0.0037, Initial Validation Loss: 0.1348, Validation Loss: 0.0289,V Acc: 0.8273, Top 70th Acc: 0.9870, Bottom 30th Acc: 0.4545
Stopping early at Epoch (base 0): 30  Rolling back to Epoch (base 0): 25  Top Validation Acc: 0.987012987012987
Fold [4/5] Epoch [0/100] Initial Loss: 0.1395, Training Loss: 0.1395, Initial Validation Loss: 0.1383, Validation Loss: 0.1383,V Acc: 0.2752, Top 70th Acc: 0.2987, Bottom 30th Acc: 0.2188
Fold [4/5] Epoch [10/100] Initial Loss: 0.1395, Training Loss: 0.0303, Initial Validation Loss: 0.1383, Validation Loss: 0.0363,V Acc: 0.8349, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.5000
Fold [4/5] Epoch [20/100] Initial Loss: 0.1395, Training Loss: 0.0059, Initial Validation Loss: 0.1383, Validation Loss: 0.0209,V Acc: 0.9083, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.7500
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.974025974025974
Fold [5/5] Epoch [0/100] Initial Loss: 0.1405, Training Loss: 0.1405, Initial Validation Loss: 0.1297, Validation Loss: 0.1297,V Acc: 0.3241, Top 70th Acc: 0.4342, Bottom 30th Acc: 0.0625
Fold [5/5] Epoch [10/100] Initial Loss: 0.1405, Training Loss: 0.0176, Initial Validation Loss: 0.1297, Validation Loss: 0.0380,V Acc: 0.7593, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.3438
Fold [5/5] Epoch [20/100] Initial Loss: 0.1405, Training Loss: 0.0049, Initial Validation Loss: 0.1297, Validation Loss: 0.0296,V Acc: 0.8148, Top 70th Acc: 0.9737, Bottom 30th Acc: 0.4375
Fold [5/5] Epoch [30/100] Initial Loss: 0.1405, Training Loss: 0.0040, Initial Validation Loss: 0.1297, Validation Loss: 0.0289,V Acc: 0.8333, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.5625
Fold [5/5] Epoch [40/100] Initial Loss: 0.1405, Training Loss: 0.0037, Initial Validation Loss: 0.1297, Validation Loss: 0.0288,V Acc: 0.8241, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.5312
Fold [5/5] Epoch [50/100] Initial Loss: 0.1405, Training Loss: 0.0036, Initial Validation Loss: 0.1297, Validation Loss: 0.0285,V Acc: 0.8148, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.5000
Stopping early at Epoch (base 0): 51  Rolling back to Epoch (base 0): 46  Top Validation Acc: 0.9473684210526315
Running train_nn.py with seed 39
CUDA:False
Training samples count:  550
Training on 162 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1386, Training Loss: 0.1386, Initial Validation Loss: 0.1313, Validation Loss: 0.1313,V Acc: 0.3929, Top 70th Acc: 0.4557, Bottom 30th Acc: 0.2424
Fold [1/5] Epoch [10/100] Initial Loss: 0.1386, Training Loss: 0.0185, Initial Validation Loss: 0.1313, Validation Loss: 0.0364,V Acc: 0.8125, Top 70th Acc: 0.9367, Bottom 30th Acc: 0.5152
Fold [1/5] Epoch [20/100] Initial Loss: 0.1386, Training Loss: 0.0057, Initial Validation Loss: 0.1313, Validation Loss: 0.0317,V Acc: 0.8393, Top 70th Acc: 0.9367, Bottom 30th Acc: 0.6061
Fold [1/5] Epoch [30/100] Initial Loss: 0.1386, Training Loss: 0.0043, Initial Validation Loss: 0.1313, Validation Loss: 0.0300,V Acc: 0.8482, Top 70th Acc: 0.9494, Bottom 30th Acc: 0.6061
Fold [1/5] Epoch [40/100] Initial Loss: 0.1386, Training Loss: 0.0039, Initial Validation Loss: 0.1313, Validation Loss: 0.0291,V Acc: 0.8571, Top 70th Acc: 0.9494, Bottom 30th Acc: 0.6364
Fold [1/5] Epoch [50/100] Initial Loss: 0.1386, Training Loss: 0.0037, Initial Validation Loss: 0.1313, Validation Loss: 0.0276,V Acc: 0.8482, Top 70th Acc: 0.9494, Bottom 30th Acc: 0.6061
Fold [1/5] Epoch [60/100] Initial Loss: 0.1386, Training Loss: 0.0036, Initial Validation Loss: 0.1313, Validation Loss: 0.0268,V Acc: 0.8571, Top 70th Acc: 0.9494, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 66  Rolling back to Epoch (base 0): 61  Top Validation Acc: 0.9493670886075949
Fold [2/5] Epoch [0/100] Initial Loss: 0.1386, Training Loss: 0.1386, Initial Validation Loss: 0.1354, Validation Loss: 0.1354,V Acc: 0.3694, Top 70th Acc: 0.4359, Bottom 30th Acc: 0.2121
Fold [2/5] Epoch [10/100] Initial Loss: 0.1386, Training Loss: 0.0267, Initial Validation Loss: 0.1354, Validation Loss: 0.0445,V Acc: 0.8108, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.5758
Fold [2/5] Epoch [20/100] Initial Loss: 0.1386, Training Loss: 0.0052, Initial Validation Loss: 0.1354, Validation Loss: 0.0276,V Acc: 0.8919, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.6970
Fold [2/5] Epoch [30/100] Initial Loss: 0.1386, Training Loss: 0.0038, Initial Validation Loss: 0.1354, Validation Loss: 0.0266,V Acc: 0.9009, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.7273
Stopping early at Epoch (base 0): 34  Rolling back to Epoch (base 0): 29  Top Validation Acc: 0.9743589743589743
Fold [3/5] Epoch [0/100] Initial Loss: 0.1420, Training Loss: 0.1420, Initial Validation Loss: 0.1328, Validation Loss: 0.1328,V Acc: 0.3182, Top 70th Acc: 0.4156, Bottom 30th Acc: 0.0909
Fold [3/5] Epoch [10/100] Initial Loss: 0.1420, Training Loss: 0.0129, Initial Validation Loss: 0.1328, Validation Loss: 0.0390,V Acc: 0.8455, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.6364
Fold [3/5] Epoch [20/100] Initial Loss: 0.1420, Training Loss: 0.0045, Initial Validation Loss: 0.1328, Validation Loss: 0.0374,V Acc: 0.8091, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 20  Rolling back to Epoch (base 0): 15  Top Validation Acc: 0.9090909090909091
Fold [4/5] Epoch [0/100] Initial Loss: 0.1385, Training Loss: 0.1385, Initial Validation Loss: 0.1351, Validation Loss: 0.1351,V Acc: 0.2661, Top 70th Acc: 0.3117, Bottom 30th Acc: 0.1562
Fold [4/5] Epoch [10/100] Initial Loss: 0.1385, Training Loss: 0.0205, Initial Validation Loss: 0.1351, Validation Loss: 0.0447,V Acc: 0.7798, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.4688
Fold [4/5] Epoch [20/100] Initial Loss: 0.1385, Training Loss: 0.0068, Initial Validation Loss: 0.1351, Validation Loss: 0.0404,V Acc: 0.7798, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.4062
Fold [4/5] Epoch [30/100] Initial Loss: 0.1385, Training Loss: 0.0056, Initial Validation Loss: 0.1351, Validation Loss: 0.0395,V Acc: 0.7706, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.3750
Fold [4/5] Epoch [40/100] Initial Loss: 0.1385, Training Loss: 0.0049, Initial Validation Loss: 0.1351, Validation Loss: 0.0380,V Acc: 0.7798, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.3750
Fold [4/5] Epoch [50/100] Initial Loss: 0.1385, Training Loss: 0.0045, Initial Validation Loss: 0.1351, Validation Loss: 0.0364,V Acc: 0.7982, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.4688
Fold [4/5] Epoch [60/100] Initial Loss: 0.1385, Training Loss: 0.0042, Initial Validation Loss: 0.1351, Validation Loss: 0.0352,V Acc: 0.8073, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.4688
Fold [4/5] Epoch [70/100] Initial Loss: 0.1385, Training Loss: 0.0038, Initial Validation Loss: 0.1351, Validation Loss: 0.0339,V Acc: 0.8073, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.5000
Fold [1/5] Epoch [10/100] Initial Loss: 0.1439, Training Loss: 0.0363, Initial Validation Loss: 0.1358, Validation Loss: 0.0463,V Acc: 0.7500, Top 70th Acc: 0.8861, Bottom 30th Acc: 0.4242
Fold [1/5] Epoch [20/100] Initial Loss: 0.1439, Training Loss: 0.0209, Initial Validation Loss: 0.1358, Validation Loss: 0.0458,V Acc: 0.7679, Top 70th Acc: 0.8861, Bottom 30th Acc: 0.4848
Stopping early at Epoch (base 0): 20  Rolling back to Epoch (base 0): 15  Top Validation Acc: 0.8860759493670886
Fold [2/5] Epoch [0/100] Initial Loss: 0.1381, Training Loss: 0.1381, Initial Validation Loss: 0.1328, Validation Loss: 0.1328,V Acc: 0.3063, Top 70th Acc: 0.3590, Bottom 30th Acc: 0.1818
Fold [2/5] Epoch [10/100] Initial Loss: 0.1381, Training Loss: 0.0264, Initial Validation Loss: 0.1328, Validation Loss: 0.0380,V Acc: 0.8108, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.5758
Fold [2/5] Epoch [20/100] Initial Loss: 0.1381, Training Loss: 0.0143, Initial Validation Loss: 0.1328, Validation Loss: 0.0348,V Acc: 0.8198, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.5152
Stopping early at Epoch (base 0): 21  Rolling back to Epoch (base 0): 16  Top Validation Acc: 0.9487179487179487
Fold [3/5] Epoch [0/100] Initial Loss: 0.1398, Training Loss: 0.1398, Initial Validation Loss: 0.1296, Validation Loss: 0.1296,V Acc: 0.3818, Top 70th Acc: 0.4416, Bottom 30th Acc: 0.2424
Fold [3/5] Epoch [10/100] Initial Loss: 0.1398, Training Loss: 0.0295, Initial Validation Loss: 0.1296, Validation Loss: 0.0469,V Acc: 0.7545, Top 70th Acc: 0.8701, Bottom 30th Acc: 0.4848
Fold [3/5] Epoch [20/100] Initial Loss: 0.1398, Training Loss: 0.0159, Initial Validation Loss: 0.1296, Validation Loss: 0.0387,V Acc: 0.8091, Top 70th Acc: 0.8961, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 28  Rolling back to Epoch (base 0): 23  Top Validation Acc: 0.9090909090909091
51 2 [array([0.59032303, 0.03327572, 0.08447277, 0.1665044 , 0.12542404],
      dtype=float32)]
Fold [4/5] Epoch [0/100] Initial Loss: 0.1377, Training Loss: 0.1377, Initial Validation Loss: 0.1333, Validation Loss: 0.1333,V Acc: 0.3761, Top 70th Acc: 0.4805, Bottom 30th Acc: 0.1250
Fold [4/5] Epoch [10/100] Initial Loss: 0.1377, Training Loss: 0.0305, Initial Validation Loss: 0.1333, Validation Loss: 0.0372,V Acc: 0.8349, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.6250
Fold [4/5] Epoch [20/100] Initial Loss: 0.1377, Training Loss: 0.0140, Initial Validation Loss: 0.1333, Validation Loss: 0.0354,V Acc: 0.8257, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.5625
Stopping early at Epoch (base 0): 22  Rolling back to Epoch (base 0): 17  Top Validation Acc: 0.935064935064935
Fold [5/5] Epoch [0/100] Initial Loss: 0.1383, Training Loss: 0.1383, Initial Validation Loss: 0.1321, Validation Loss: 0.1321,V Acc: 0.2500, Top 70th Acc: 0.3421, Bottom 30th Acc: 0.0312
Fold [5/5] Epoch [10/100] Initial Loss: 0.1383, Training Loss: 0.0326, Initial Validation Loss: 0.1321, Validation Loss: 0.0329,V Acc: 0.8241, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.5000
Fold [5/5] Epoch [20/100] Initial Loss: 0.1383, Training Loss: 0.0163, Initial Validation Loss: 0.1321, Validation Loss: 0.0233,V Acc: 0.8796, Top 70th Acc: 0.9868, Bottom 30th Acc: 0.6250
Stopping early at Epoch (base 0): 27  Rolling back to Epoch (base 0): 22  Top Validation Acc: 0.9868421052631579
Running train_nn.py with seed 52
CUDA:False
Training samples count:  550
Training on 40 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1405, Training Loss: 0.1405, Initial Validation Loss: 0.1353, Validation Loss: 0.1353,V Acc: 0.3125, Top 70th Acc: 0.3291, Bottom 30th Acc: 0.2727
Fold [1/5] Epoch [10/100] Initial Loss: 0.1405, Training Loss: 0.0254, Initial Validation Loss: 0.1353, Validation Loss: 0.0340,V Acc: 0.8125, Top 70th Acc: 0.9241, Bottom 30th Acc: 0.5455
Fold [1/5] Epoch [20/100] Initial Loss: 0.1405, Training Loss: 0.0144, Initial Validation Loss: 0.1353, Validation Loss: 0.0304,V Acc: 0.8393, Top 70th Acc: 0.9241, Bottom 30th Acc: 0.6364
Fold [1/5] Epoch [30/100] Initial Loss: 0.1405, Training Loss: 0.0122, Initial Validation Loss: 0.1353, Validation Loss: 0.0292,V Acc: 0.8482, Top 70th Acc: 0.9367, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 30  Rolling back to Epoch (base 0): 25  Top Validation Acc: 0.9367088607594937
52 0 [array([0.3709603 , 0.10632724, 0.04180549, 0.12969024, 0.3512167 ],
      dtype=float32)]
Fold [2/5] Epoch [0/100] Initial Loss: 0.1452, Training Loss: 0.1452, Initial Validation Loss: 0.1361, Validation Loss: 0.1361,V Acc: 0.2523, Top 70th Acc: 0.2949, Bottom 30th Acc: 0.1515
Fold [2/5] Epoch [10/100] Initial Loss: 0.1452, Training Loss: 0.0350, Initial Validation Loss: 0.1361, Validation Loss: 0.0433,V Acc: 0.7928, Top 70th Acc: 0.8974, Bottom 30th Acc: 0.5455
Fold [2/5] Epoch [20/100] Initial Loss: 0.1452, Training Loss: 0.0157, Initial Validation Loss: 0.1361, Validation Loss: 0.0322,V Acc: 0.8108, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.4848
Fold [2/5] Epoch [30/100] Initial Loss: 0.1452, Training Loss: 0.0134, Initial Validation Loss: 0.1361, Validation Loss: 0.0284,V Acc: 0.8378, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.5758
Fold [2/5] Epoch [40/100] Initial Loss: 0.1452, Training Loss: 0.0121, Initial Validation Loss: 0.1361, Validation Loss: 0.0281,V Acc: 0.8378, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 44  Rolling back to Epoch (base 0): 39  Top Validation Acc: 0.9487179487179487
Fold [3/5] Epoch [0/100] Initial Loss: 0.1396, Training Loss: 0.1396, Initial Validation Loss: 0.1325, Validation Loss: 0.1325,V Acc: 0.2636, Top 70th Acc: 0.3377, Bottom 30th Acc: 0.0909
Fold [3/5] Epoch [10/100] Initial Loss: 0.1396, Training Loss: 0.0275, Initial Validation Loss: 0.1325, Validation Loss: 0.0385,V Acc: 0.8273, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.5758
Fold [3/5] Epoch [20/100] Initial Loss: 0.1396, Training Loss: 0.0152, Initial Validation Loss: 0.1325, Validation Loss: 0.0316,V Acc: 0.8727, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.7576
Stopping early at Epoch (base 0): 28  Rolling back to Epoch (base 0): 23  Top Validation Acc: 0.935064935064935
Fold [4/5] Epoch [0/100] Initial Loss: 0.1393, Training Loss: 0.1393, Initial Validation Loss: 0.1339, Validation Loss: 0.1339,V Acc: 0.2661, Top 70th Acc: 0.3117, Bottom 30th Acc: 0.1562
Fold [4/5] Epoch [10/100] Initial Loss: 0.1393, Training Loss: 0.0311, Initial Validation Loss: 0.1339, Validation Loss: 0.0548,V Acc: 0.7523, Top 70th Acc: 0.8312, Bottom 30th Acc: 0.5625
Fold [4/5] Epoch [20/100] Initial Loss: 0.1393, Training Loss: 0.0158, Initial Validation Loss: 0.1339, Validation Loss: 0.0472,V Acc: 0.7523, Top 70th Acc: 0.8701, Bottom 30th Acc: 0.4688
Fold [4/5] Epoch [30/100] Initial Loss: 0.1393, Training Loss: 0.0113, Initial Validation Loss: 0.1339, Validation Loss: 0.0426,V Acc: 0.7798, Top 70th Acc: 0.8701, Bottom 30th Acc: 0.5625
Fold [4/5] Epoch [40/100] Initial Loss: 0.1393, Training Loss: 0.0096, Initial Validation Loss: 0.1339, Validation Loss: 0.0397,V Acc: 0.8073, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.5625
Stopping early at Epoch (base 0): 45  Rolling back to Epoch (base 0): 40  Top Validation Acc: 0.8831168831168831
Fold [5/5] Epoch [0/100] Initial Loss: 0.1378, Training Loss: 0.1378, Initial Validation Loss: 0.1319, Validation Loss: 0.1319,V Acc: 0.4259, Top 70th Acc: 0.5000, Bottom 30th Acc: 0.2500
Fold [5/5] Epoch [10/100] Initial Loss: 0.1378, Training Loss: 0.0337, Initial Validation Loss: 0.1319, Validation Loss: 0.0321,V Acc: 0.8704, Top 70th Acc: 0.9737, Bottom 30th Acc: 0.6250
Fold [5/5] Epoch [20/100] Initial Loss: 0.1378, Training Loss: 0.0167, Initial Validation Loss: 0.1319, Validation Loss: 0.0289,V Acc: 0.8519, Top 70th Acc: 0.9737, Bottom 30th Acc: 0.5625
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.9605263157894737
Running train_nn.py with seed 53
CUDA:False
Training samples count:  550
Training on 40 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1410, Training Loss: 0.1410, Initial Validation Loss: 0.1370, Validation Loss: 0.1370,V Acc: 0.2589, Top 70th Acc: 0.3165, Bottom 30th Acc: 0.1212
Fold [1/5] Epoch [10/100] Initial Loss: 0.1410, Training Loss: 0.0351, Initial Validation Loss: 0.1370, Validation Loss: 0.0511,V Acc: 0.7768, Top 70th Acc: 0.8608, Bottom 30th Acc: 0.5758 21  Top Validation Acc: 0.961038961038961
Fold [4/5] Epoch [0/100] Initial Loss: 0.1322, Training Loss: 0.1322, Initial Validation Loss: 0.1155, Validation Loss: 0.1155,V Acc: 0.5046, Top 70th Acc: 0.5584, Bottom 30th Acc: 0.3750
Fold [4/5] Epoch [10/100] Initial Loss: 0.1322, Training Loss: 0.0225, Initial Validation Loss: 0.1155, Validation Loss: 0.0273,V Acc: 0.8532, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6250
Stopping early at Epoch (base 0): 18  Rolling back to Epoch (base 0): 13  Top Validation Acc: 0.974025974025974
67 3 [array([0.68983936, 0.01672751, 0.03871474, 0.19303805, 0.0616804 ],
      dtype=float32)]
Fold [5/5] Epoch [0/100] Initial Loss: 0.1304, Training Loss: 0.1304, Initial Validation Loss: 0.1102, Validation Loss: 0.1102,V Acc: 0.5093, Top 70th Acc: 0.5789, Bottom 30th Acc: 0.3438
Fold [5/5] Epoch [10/100] Initial Loss: 0.1304, Training Loss: 0.0242, Initial Validation Loss: 0.1102, Validation Loss: 0.0304,V Acc: 0.8519, Top 70th Acc: 0.9868, Bottom 30th Acc: 0.5312
Stopping early at Epoch (base 0): 18  Rolling back to Epoch (base 0): 13  Top Validation Acc: 0.9736842105263158
Running train_nn.py with seed 68
CUDA:False
Training samples count:  550
Training on 21 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1391, Training Loss: 0.1391, Initial Validation Loss: 0.1325, Validation Loss: 0.1325,V Acc: 0.3839, Top 70th Acc: 0.3671, Bottom 30th Acc: 0.4242
Fold [1/5] Epoch [10/100] Initial Loss: 0.1391, Training Loss: 0.0232, Initial Validation Loss: 0.1325, Validation Loss: 0.0332,V Acc: 0.8482, Top 70th Acc: 0.9494, Bottom 30th Acc: 0.6061
Fold [1/5] Epoch [20/100] Initial Loss: 0.1391, Training Loss: 0.0156, Initial Validation Loss: 0.1325, Validation Loss: 0.0286,V Acc: 0.8750, Top 70th Acc: 0.9494, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 22  Rolling back to Epoch (base 0): 17  Top Validation Acc: 0.9493670886075949
68 0 [array([0.8162608 , 0.02612595, 0.02504939, 0.06649295, 0.06607085],
      dtype=float32)]
Fold [2/5] Epoch [0/100] Initial Loss: 0.1317, Training Loss: 0.1317, Initial Validation Loss: 0.1246, Validation Loss: 0.1246,V Acc: 0.4234, Top 70th Acc: 0.5513, Bottom 30th Acc: 0.1212
Fold [2/5] Epoch [10/100] Initial Loss: 0.1317, Training Loss: 0.0221, Initial Validation Loss: 0.1246, Validation Loss: 0.0286,V Acc: 0.8649, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.6364
Fold [2/5] Epoch [20/100] Initial Loss: 0.1317, Training Loss: 0.0157, Initial Validation Loss: 0.1246, Validation Loss: 0.0292,V Acc: 0.8559, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 20  Rolling back to Epoch (base 0): 15  Top Validation Acc: 0.9743589743589743
Fold [3/5] Epoch [0/100] Initial Loss: 0.1300, Training Loss: 0.1300, Initial Validation Loss: 0.1148, Validation Loss: 0.1148,V Acc: 0.4545, Top 70th Acc: 0.5844, Bottom 30th Acc: 0.1515
Fold [3/5] Epoch [10/100] Initial Loss: 0.1300, Training Loss: 0.0243, Initial Validation Loss: 0.1148, Validation Loss: 0.0250,V Acc: 0.8636, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.6364
Fold [3/5] Epoch [20/100] Initial Loss: 0.1300, Training Loss: 0.0178, Initial Validation Loss: 0.1148, Validation Loss: 0.0224,V Acc: 0.8909, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.7273
Stopping early at Epoch (base 0): 22  Rolling back to Epoch (base 0): 17  Top Validation Acc: 0.961038961038961
Fold [4/5] Epoch [0/100] Initial Loss: 0.1338, Training Loss: 0.1338, Initial Validation Loss: 0.1157, Validation Loss: 0.1157,V Acc: 0.6239, Top 70th Acc: 0.7532, Bottom 30th Acc: 0.3125
Fold [4/5] Epoch [10/100] Initial Loss: 0.1338, Training Loss: 0.0227, Initial Validation Loss: 0.1157, Validation Loss: 0.0249,V Acc: 0.8624, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.6250
Stopping early at Epoch (base 0): 15  Rolling back to Epoch (base 0): 10  Top Validation Acc: 0.948051948051948
Fold [5/5] Epoch [0/100] Initial Loss: 0.1308, Training Loss: 0.1308, Initial Validation Loss: 0.1183, Validation Loss: 0.1183,V Acc: 0.5093, Top 70th Acc: 0.6184, Bottom 30th Acc: 0.2500
Fold [5/5] Epoch [10/100] Initial Loss: 0.1308, Training Loss: 0.0211, Initial Validation Loss: 0.1183, Validation Loss: 0.0254,V Acc: 0.8796, Top 70th Acc: 0.9737, Bottom 30th Acc: 0.6562
Stopping early at Epoch (base 0): 19  Rolling back to Epoch (base 0): 14  Top Validation Acc: 0.9736842105263158
Running train_nn.py with seed 69
CUDA:False
Training samples count:  550
Training on 21 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1376, Training Loss: 0.1376, Initial Validation Loss: 0.1243, Validation Loss: 0.1243,V Acc: 0.4375, Top 70th Acc: 0.5949, Bottom 30th Acc: 0.0606
Fold [1/5] Epoch [10/100] Initial Loss: 0.1376, Training Loss: 0.0219, Initial Validation Loss: 0.1243, Validation Loss: 0.0262,V Acc: 0.8929, Top 70th Acc: 0.9873, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 19  Rolling back to Epoch (base 0): 14  Top Validation Acc: 0.9620253164556962
Fold [2/5] Epoch [0/100] Initial Loss: 0.1323, Training Loss: 0.1323, Initial Validation Loss: 0.1217, Validation Loss: 0.1217,V Acc: 0.5135, Top 70th Acc: 0.6026, Bottom 30th Acc: 0.3030
Fold [2/5] Epoch [10/100] Initial Loss: 0.1323, Training Loss: 0.0218, Initial Validation Loss: 0.1217, Validation Loss: 0.0321,V Acc: 0.8468, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 19  Rolling back to Epoch (base 0): 14  Top Validation Acc: 0.9743589743589743
Fold [3/5] Epoch [0/100] Initial Loss: 0.1315, Training Loss: 0.1315, Initial Validation Loss: 0.1116, Validation Loss: 0.1116,V Acc: 0.4455, Top 70th Acc: 0.5714, Bottom 30th Acc: 0.1515
Fold [3/5] Epoch [10/100] Initial Loss: 0.1315, Training Loss: 0.0254, Initial Validation Loss: 0.1116, Validation Loss: 0.0200,V Acc: 0.8909, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.6970
Fold [3/5] Epoch [20/100] Initial Loss: 0.1315, Training Loss: 0.0162, Initial Validation Loss: 0.1116, Validation Loss: 0.0230,V Acc: 0.9182, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.8182
Stopping early at Epoch (base 0): 21  Rolling back to Epoch (base 0): 16  Top Validation Acc: 0.974025974025974
Fold [4/5] Epoch [0/100] Initial Loss: 0.1277, Training Loss: 0.1277, Initial Validation Loss: 0.1186, Validation Loss: 0.1186,V Acc: 0.4679, Top 70th Acc: 0.5714, Bottom 30th Acc: 0.2188
Fold [4/5] Epoch [10/100] Initial Loss: 0.1277, Training Loss: 0.0285, Initial Validation Loss: 0.1186, Validation Loss: 0.0336,V Acc: 0.8440, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.5625
Fold [4/5] Epoch [20/100] Initial Loss: 0.1277, Training Loss: 0.0185, Initial Validation Loss: 0.1186, Validation Loss: 0.0219,V Acc: 0.9083, Top 70th Acc: 0.9870, Bottom 30th Acc: 0.7188
Fold [4/5] Epoch [30/100] Initial Loss: 0.1277, Training Loss: 0.0147, Initial Validation Loss: 0.1186, Validation Loss: 0.0186,V Acc: 0.9083, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.7500
Fold [4/5] Epoch [40/100] Initial Loss: 0.1277, Training Loss: 0.0126, Initial Validation Loss: 0.1186, Validation Loss: 0.0158,V Acc: 0.9266, Top 70th Acc: 0.9870, Bottom 30th Acc: 0.7812
Stopping early at Epoch (base 0): 40  Rolling back to Epoch (base 0): 35  Top Validation Acc: 0.987012987012987
Fold [5/5] Epoch [0/100] Initial Loss: 0.1368, Training Loss: 0.1368, Initial Validation Loss: 0.1282, Validation Loss: 0.1282,V Acc: 0.4722, Top 70th Acc: 0.5263, Bottom 30th Acc: 0.3438
Fold [5/5] Epoch [10/100] Initial Loss: 0.1368, Training Loss: 0.0248, Initial Validation Loss: 0.1282, Validation Loss: 0.0331,V Acc: 0.8241, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.5000
Fold [5/5] Epoch [20/100] Initial Loss: 0.1368, Training Loss: 0.0172, Initial Validation Loss: 0.1282, Validation Loss: 0.0296,V Acc: 0.8333, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.5938
Fold [5/5] Epoch [30/100] Initial Loss: 0.1368, Training Loss: 0.0155, Initial Validation Loss: 0.1282, Validation Loss: 0.0335,V Acc: 0.8426, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.6250
Stopping early at Epoch (base 0): 31  Rolling back to Epoch (base 0): 26  Top Validation Acc: 0.8947368421052632
69 4 [array([0.64964837, 0.01779534, 0.05754814, 0.0698272 , 0.20518103],
      dtype=float32)]
Running train_nn.py with seed 70
CUDA:False
Training samples count:  550
Training on 21 features
Fold [1/5] Epoch [10/100] Initial Loss: 0.1411, Training Loss: 0.0412, Initial Validation Loss: 0.1356, Validation Loss: 0.0429,V Acc: 0.7946, Top 70th Acc: 0.8987, Bottom 30th Acc: 0.5455
Fold [1/5] Epoch [20/100] Initial Loss: 0.1411, Training Loss: 0.0283, Initial Validation Loss: 0.1356, Validation Loss: 0.0351,V Acc: 0.8125, Top 70th Acc: 0.9114, Bottom 30th Acc: 0.5758
Fold [1/5] Epoch [30/100] Initial Loss: 0.1411, Training Loss: 0.0225, Initial Validation Loss: 0.1356, Validation Loss: 0.0304,V Acc: 0.8482, Top 70th Acc: 0.9114, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 35  Rolling back to Epoch (base 0): 30  Top Validation Acc: 0.9113924050632911
Fold [2/5] Epoch [0/100] Initial Loss: 0.1377, Training Loss: 0.1377, Initial Validation Loss: 0.1328, Validation Loss: 0.1328,V Acc: 0.3874, Top 70th Acc: 0.4359, Bottom 30th Acc: 0.2727
Fold [2/5] Epoch [10/100] Initial Loss: 0.1377, Training Loss: 0.0372, Initial Validation Loss: 0.1328, Validation Loss: 0.0343,V Acc: 0.8378, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.6061
Fold [2/5] Epoch [20/100] Initial Loss: 0.1377, Training Loss: 0.0244, Initial Validation Loss: 0.1328, Validation Loss: 0.0258,V Acc: 0.8649, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.6667
Fold [2/5] Epoch [30/100] Initial Loss: 0.1377, Training Loss: 0.0213, Initial Validation Loss: 0.1328, Validation Loss: 0.0263,V Acc: 0.8559, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 30  Rolling back to Epoch (base 0): 25  Top Validation Acc: 0.9615384615384616
49 1 [array([0.2711197 , 0.11461383, 0.08906445, 0.23279706, 0.29240486],
      dtype=float32)]
Fold [3/5] Epoch [0/100] Initial Loss: 0.1391, Training Loss: 0.1391, Initial Validation Loss: 0.1308, Validation Loss: 0.1308,V Acc: 0.4000, Top 70th Acc: 0.4416, Bottom 30th Acc: 0.3030
Fold [3/5] Epoch [10/100] Initial Loss: 0.1391, Training Loss: 0.0331, Initial Validation Loss: 0.1308, Validation Loss: 0.0408,V Acc: 0.8091, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.5758
Fold [3/5] Epoch [20/100] Initial Loss: 0.1391, Training Loss: 0.0222, Initial Validation Loss: 0.1308, Validation Loss: 0.0352,V Acc: 0.8182, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 27  Rolling back to Epoch (base 0): 22  Top Validation Acc: 0.8831168831168831
Fold [4/5] Epoch [0/100] Initial Loss: 0.1415, Training Loss: 0.1415, Initial Validation Loss: 0.1365, Validation Loss: 0.1365,V Acc: 0.3394, Top 70th Acc: 0.3247, Bottom 30th Acc: 0.3750
Fold [4/5] Epoch [10/100] Initial Loss: 0.1415, Training Loss: 0.0392, Initial Validation Loss: 0.1365, Validation Loss: 0.0471,V Acc: 0.7706, Top 70th Acc: 0.8831, Bottom 30th Acc: 0.5000
Fold [4/5] Epoch [20/100] Initial Loss: 0.1415, Training Loss: 0.0244, Initial Validation Loss: 0.1365, Validation Loss: 0.0357,V Acc: 0.8532, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.7188
Fold [4/5] Epoch [30/100] Initial Loss: 0.1415, Training Loss: 0.0210, Initial Validation Loss: 0.1365, Validation Loss: 0.0323,V Acc: 0.8624, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.6875
Stopping early at Epoch (base 0): 39  Rolling back to Epoch (base 0): 34  Top Validation Acc: 0.935064935064935
Fold [5/5] Epoch [0/100] Initial Loss: 0.1433, Training Loss: 0.1433, Initial Validation Loss: 0.1350, Validation Loss: 0.1350,V Acc: 0.3241, Top 70th Acc: 0.3553, Bottom 30th Acc: 0.2500
Fold [5/5] Epoch [10/100] Initial Loss: 0.1433, Training Loss: 0.0376, Initial Validation Loss: 0.1350, Validation Loss: 0.0491,V Acc: 0.7685, Top 70th Acc: 0.9079, Bottom 30th Acc: 0.4375
Fold [5/5] Epoch [20/100] Initial Loss: 0.1433, Training Loss: 0.0251, Initial Validation Loss: 0.1350, Validation Loss: 0.0435,V Acc: 0.8056, Top 70th Acc: 0.9079, Bottom 30th Acc: 0.5625
Fold [5/5] Epoch [30/100] Initial Loss: 0.1433, Training Loss: 0.0191, Initial Validation Loss: 0.1350, Validation Loss: 0.0410,V Acc: 0.7963, Top 70th Acc: 0.9079, Bottom 30th Acc: 0.5312
Stopping early at Epoch (base 0): 37  Rolling back to Epoch (base 0): 32  Top Validation Acc: 0.9210526315789473
Running train_nn.py with seed 50
CUDA:False
Training samples count:  550
Training on 20 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1380, Training Loss: 0.1380, Initial Validation Loss: 0.1329, Validation Loss: 0.1329,V Acc: 0.2321, Top 70th Acc: 0.3165, Bottom 30th Acc: 0.0303
Fold [1/5] Epoch [10/100] Initial Loss: 0.1380, Training Loss: 0.0506, Initial Validation Loss: 0.1329, Validation Loss: 0.0541,V Acc: 0.7679, Top 70th Acc: 0.8608, Bottom 30th Acc: 0.5455
Fold [1/5] Epoch [20/100] Initial Loss: 0.1380, Training Loss: 0.0240, Initial Validation Loss: 0.1329, Validation Loss: 0.0369,V Acc: 0.8304, Top 70th Acc: 0.9241, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 28  Rolling back to Epoch (base 0): 23  Top Validation Acc: 0.9113924050632911
Fold [2/5] Epoch [0/100] Initial Loss: 0.1393, Training Loss: 0.1393, Initial Validation Loss: 0.1287, Validation Loss: 0.1287,V Acc: 0.3063, Top 70th Acc: 0.3718, Bottom 30th Acc: 0.1515
Fold [2/5] Epoch [10/100] Initial Loss: 0.1393, Training Loss: 0.0398, Initial Validation Loss: 0.1287, Validation Loss: 0.0352,V Acc: 0.8198, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.5455
Fold [2/5] Epoch [20/100] Initial Loss: 0.1393, Training Loss: 0.0241, Initial Validation Loss: 0.1287, Validation Loss: 0.0299,V Acc: 0.8468, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.9487179487179487
Fold [3/5] Epoch [0/100] Initial Loss: 0.1408, Training Loss: 0.1408, Initial Validation Loss: 0.1319, Validation Loss: 0.1319,V Acc: 0.2727, Top 70th Acc: 0.3247, Bottom 30th Acc: 0.1515
Fold [3/5] Epoch [10/100] Initial Loss: 0.1408, Training Loss: 0.0334, Initial Validation Loss: 0.1319, Validation Loss: 0.0393,V Acc: 0.8000, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 18  Rolling back to Epoch (base 0): 13  Top Validation Acc: 0.8831168831168831
50 2 [array([0.39393476, 0.10608552, 0.11847384, 0.20913514, 0.17237076],
      dtype=float32)]
Fold [4/5] Epoch [0/100] Initial Loss: 0.1408, Training Loss: 0.1408, Initial Validation Loss: 0.1358, Validation Loss: 0.1358,V Acc: 0.2477, Top 70th Acc: 0.3506, Bottom 30th Acc: 0.0000
Fold [4/5] Epoch [10/100] Initial Loss: 0.1408, Training Loss: 0.0390, Initial Validation Loss: 0.1358, Validation Loss: 0.0534,V Acc: 0.7798, Top 70th Acc: 0.8442, Bottom 30th Acc: 0.6250
Fold [4/5] Epoch [20/100] Initial Loss: 0.1408, Training Loss: 0.0235, Initial Validation Loss: 0.1358, Validation Loss: 0.0422,V Acc: 0.8349, Top 70th Acc: 0.8701, Bottom 30th Acc: 0.7500
Fold [4/5] Epoch [30/100] Initial Loss: 0.1408, Training Loss: 0.0208, Initial Validation Loss: 0.1358, Validation Loss: 0.0424,V Acc: 0.8165, Top 70th Acc: 0.8831, Bottom 30th Acc: 0.6562
Stopping early at Epoch (base 0): 31  Rolling back to Epoch (base 0): 26  Top Validation Acc: 0.9090909090909091
Fold [5/5] Epoch [0/100] Initial Loss: 0.1360, Training Loss: 0.1360, Initial Validation Loss: 0.1330, Validation Loss: 0.1330,V Acc: 0.3241, Top 70th Acc: 0.3684, Bottom 30th Acc: 0.2188
Fold [5/5] Epoch [10/100] Initial Loss: 0.1360, Training Loss: 0.0368, Initial Validation Loss: 0.1330, Validation Loss: 0.0364,V Acc: 0.8056, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.5000
Fold [5/5] Epoch [20/100] Initial Loss: 0.1360, Training Loss: 0.0262, Initial Validation Loss: 0.1330, Validation Loss: 0.0272,V Acc: 0.8889, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.7188
Fold [5/5] Epoch [30/100] Initial Loss: 0.1360, Training Loss: 0.0229, Initial Validation Loss: 0.1330, Validation Loss: 0.0255,V Acc: 0.8889, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.7188
Stopping early at Epoch (base 0): 34  Rolling back to Epoch (base 0): 29  Top Validation Acc: 0.9605263157894737
Running train_nn.py with seed 51
CUDA:False
Training samples count:  550
Training on 20 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1383, Training Loss: 0.1383, Initial Validation Loss: 0.1348, Validation Loss: 0.1348,V Acc: 0.3214, Top 70th Acc: 0.2785, Bottom 30th Acc: 0.4242
Fold [1/5] Epoch [10/100] Initial Loss: 0.1383, Training Loss: 0.0301, Initial Validation Loss: 0.1348, Validation Loss: 0.0343,V Acc: 0.8393, Top 70th Acc: 0.9494, Bottom 30th Acc: 0.5758
Fold [4/5] Epoch [10/100] Initial Loss: 0.1381, Training Loss: 0.0845, Initial Validation Loss: 0.1240, Validation Loss: 0.0675,V Acc: 0.6881, Top 70th Acc: 0.8442, Bottom 30th Acc: 0.3125
Fold [4/5] Epoch [20/100] Initial Loss: 0.1381, Training Loss: 0.0830, Initial Validation Loss: 0.1240, Validation Loss: 0.0644,V Acc: 0.7248, Top 70th Acc: 0.8442, Bottom 30th Acc: 0.4375
Fold [4/5] Epoch [30/100] Initial Loss: 0.1381, Training Loss: 0.0822, Initial Validation Loss: 0.1240, Validation Loss: 0.0645,V Acc: 0.7156, Top 70th Acc: 0.8571, Bottom 30th Acc: 0.3750
Stopping early at Epoch (base 0): 36  Rolling back to Epoch (base 0): 31  Top Validation Acc: 0.8441558441558441
Fold [5/5] Epoch [0/100] Initial Loss: 0.1441, Training Loss: 0.1441, Initial Validation Loss: 0.1284, Validation Loss: 0.1284,V Acc: 0.2870, Top 70th Acc: 0.3553, Bottom 30th Acc: 0.1250
Fold [5/5] Epoch [10/100] Initial Loss: 0.1441, Training Loss: 0.0828, Initial Validation Loss: 0.1284, Validation Loss: 0.0713,V Acc: 0.6759, Top 70th Acc: 0.7500, Bottom 30th Acc: 0.5000
Stopping early at Epoch (base 0): 17  Rolling back to Epoch (base 0): 12  Top Validation Acc: 0.7763157894736842
Running train_nn.py with seed 49
CUDA:False
Training samples count:  550
Training on 2 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1342, Training Loss: 0.1342, Initial Validation Loss: 0.1246, Validation Loss: 0.1246,V Acc: 0.5179, Top 70th Acc: 0.5696, Bottom 30th Acc: 0.3939
Fold [1/5] Epoch [10/100] Initial Loss: 0.1342, Training Loss: 0.0815, Initial Validation Loss: 0.1246, Validation Loss: 0.0787,V Acc: 0.6518, Top 70th Acc: 0.7595, Bottom 30th Acc: 0.3939
Fold [1/5] Epoch [20/100] Initial Loss: 0.1342, Training Loss: 0.0790, Initial Validation Loss: 0.1246, Validation Loss: 0.0772,V Acc: 0.6518, Top 70th Acc: 0.7722, Bottom 30th Acc: 0.3636
Stopping early at Epoch (base 0): 28  Rolling back to Epoch (base 0): 23  Top Validation Acc: 0.759493670886076
Fold [2/5] Epoch [0/100] Initial Loss: 0.1429, Training Loss: 0.1429, Initial Validation Loss: 0.1327, Validation Loss: 0.1327,V Acc: 0.4054, Top 70th Acc: 0.4487, Bottom 30th Acc: 0.3030
Fold [2/5] Epoch [10/100] Initial Loss: 0.1429, Training Loss: 0.0801, Initial Validation Loss: 0.1327, Validation Loss: 0.0820,V Acc: 0.6216, Top 70th Acc: 0.7436, Bottom 30th Acc: 0.3333
Fold [2/5] Epoch [20/100] Initial Loss: 0.1429, Training Loss: 0.0780, Initial Validation Loss: 0.1327, Validation Loss: 0.0803,V Acc: 0.6486, Top 70th Acc: 0.7436, Bottom 30th Acc: 0.4242
Fold [2/5] Epoch [30/100] Initial Loss: 0.1429, Training Loss: 0.0775, Initial Validation Loss: 0.1327, Validation Loss: 0.0791,V Acc: 0.6396, Top 70th Acc: 0.7436, Bottom 30th Acc: 0.3939
Stopping early at Epoch (base 0): 34  Rolling back to Epoch (base 0): 29  Top Validation Acc: 0.7564102564102564
49 1 [array([0.10475899, 0.39586413, 0.1445471 , 0.2092162 , 0.1456135 ],
      dtype=float32)]
Fold [3/5] Epoch [0/100] Initial Loss: 0.1398, Training Loss: 0.1398, Initial Validation Loss: 0.1242, Validation Loss: 0.1242,V Acc: 0.3727, Top 70th Acc: 0.4416, Bottom 30th Acc: 0.2121
Fold [3/5] Epoch [10/100] Initial Loss: 0.1398, Training Loss: 0.0820, Initial Validation Loss: 0.1242, Validation Loss: 0.0752,V Acc: 0.6636, Top 70th Acc: 0.7532, Bottom 30th Acc: 0.4545
Stopping early at Epoch (base 0): 19  Rolling back to Epoch (base 0): 14  Top Validation Acc: 0.7792207792207793
Fold [4/5] Epoch [0/100] Initial Loss: 0.1404, Training Loss: 0.1404, Initial Validation Loss: 0.1319, Validation Loss: 0.1319,V Acc: 0.3761, Top 70th Acc: 0.4545, Bottom 30th Acc: 0.1875
Fold [4/5] Epoch [10/100] Initial Loss: 0.1404, Training Loss: 0.0788, Initial Validation Loss: 0.1319, Validation Loss: 0.0843,V Acc: 0.5780, Top 70th Acc: 0.6494, Bottom 30th Acc: 0.4062
Stopping early at Epoch (base 0): 17  Rolling back to Epoch (base 0): 12  Top Validation Acc: 0.6883116883116883
Fold [5/5] Epoch [0/100] Initial Loss: 0.1296, Training Loss: 0.1296, Initial Validation Loss: 0.1147, Validation Loss: 0.1147,V Acc: 0.5278, Top 70th Acc: 0.6184, Bottom 30th Acc: 0.3125
Fold [5/5] Epoch [10/100] Initial Loss: 0.1296, Training Loss: 0.0813, Initial Validation Loss: 0.1147, Validation Loss: 0.0772,V Acc: 0.6296, Top 70th Acc: 0.7368, Bottom 30th Acc: 0.3750
Fold [5/5] Epoch [20/100] Initial Loss: 0.1296, Training Loss: 0.0795, Initial Validation Loss: 0.1147, Validation Loss: 0.0764,V Acc: 0.6296, Top 70th Acc: 0.7500, Bottom 30th Acc: 0.3438
Fold [5/5] Epoch [30/100] Initial Loss: 0.1296, Training Loss: 0.0792, Initial Validation Loss: 0.1147, Validation Loss: 0.0759,V Acc: 0.6389, Top 70th Acc: 0.7500, Bottom 30th Acc: 0.3750
Stopping early at Epoch (base 0): 31  Rolling back to Epoch (base 0): 26  Top Validation Acc: 0.75
Running train_nn.py with seed 50
CUDA:False
Training samples count:  550
Training on 2 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1398, Training Loss: 0.1398, Initial Validation Loss: 0.1338, Validation Loss: 0.1338,V Acc: 0.2768, Top 70th Acc: 0.3291, Bottom 30th Acc: 0.1515
Fold [1/5] Epoch [10/100] Initial Loss: 0.1398, Training Loss: 0.0795, Initial Validation Loss: 0.1338, Validation Loss: 0.0894,V Acc: 0.5714, Top 70th Acc: 0.6582, Bottom 30th Acc: 0.3636
Fold [1/5] Epoch [20/100] Initial Loss: 0.1398, Training Loss: 0.0771, Initial Validation Loss: 0.1338, Validation Loss: 0.0874,V Acc: 0.5625, Top 70th Acc: 0.6835, Bottom 30th Acc: 0.2727
Fold [1/5] Epoch [30/100] Initial Loss: 0.1398, Training Loss: 0.0759, Initial Validation Loss: 0.1338, Validation Loss: 0.0871,V Acc: 0.5714, Top 70th Acc: 0.6962, Bottom 30th Acc: 0.2727
Stopping early at Epoch (base 0): 34  Rolling back to Epoch (base 0): 29  Top Validation Acc: 0.6962025316455697
Fold [2/5] Epoch [0/100] Initial Loss: 0.1402, Training Loss: 0.1402, Initial Validation Loss: 0.1253, Validation Loss: 0.1253,V Acc: 0.5315, Top 70th Acc: 0.6795, Bottom 30th Acc: 0.1818
Fold [2/5] Epoch [10/100] Initial Loss: 0.1402, Training Loss: 0.0814, Initial Validation Loss: 0.1253, Validation Loss: 0.0761,V Acc: 0.6396, Top 70th Acc: 0.7564, Bottom 30th Acc: 0.3636
Stopping early at Epoch (base 0): 17  Rolling back to Epoch (base 0): 12  Top Validation Acc: 0.7564102564102564
Fold [3/5] Epoch [0/100] Initial Loss: 0.1348, Training Loss: 0.1348, Initial Validation Loss: 0.1249, Validation Loss: 0.1249,V Acc: 0.3545, Top 70th Acc: 0.4935, Bottom 30th Acc: 0.0303
Fold [3/5] Epoch [10/100] Initial Loss: 0.1348, Training Loss: 0.0816, Initial Validation Loss: 0.1249, Validation Loss: 0.0775,V Acc: 0.6364, Top 70th Acc: 0.7403, Bottom 30th Acc: 0.3939
Fold [3/5] Epoch [20/100] Initial Loss: 0.1348, Training Loss: 0.0793, Initial Validation Loss: 0.1249, Validation Loss: 0.0761,V Acc: 0.6455, Top 70th Acc: 0.7273, Bottom 30th Acc: 0.4545
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.7532467532467533
50 2 [array([0.10577768, 0.3759876 , 0.1533007 , 0.2129996 , 0.15193437],
      dtype=float32)]
Fold [4/5] Epoch [0/100] Initial Loss: 0.1368, Training Loss: 0.1368, Initial Validation Loss: 0.1291, Validation Loss: 0.1291,V Acc: 0.4037, Top 70th Acc: 0.4156, Bottom 30th Acc: 0.3750
Fold [4/5] Epoch [10/100] Initial Loss: 0.1368, Training Loss: 0.0815, Initial Validation Loss: 0.1291, Validation Loss: 0.0793,V Acc: 0.6330, Top 70th Acc: 0.7662, Bottom 30th Acc: 0.3125
Fold [4/5] Epoch [20/100] Initial Loss: 0.1368, Training Loss: 0.0794, Initial Validation Loss: 0.1291, Validation Loss: 0.0775,V Acc: 0.6422, Top 70th Acc: 0.7532, Bottom 30th Acc: 0.3750
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.7662337662337663
Fold [5/5] Epoch [0/100] Initial Loss: 0.1271, Training Loss: 0.1271, Initial Validation Loss: 0.1140, Validation Loss: 0.1140,V Acc: 0.5648, Top 70th Acc: 0.6842, Bottom 30th Acc: 0.2812
Fold [5/5] Epoch [10/100] Initial Loss: 0.1271, Training Loss: 0.0812, Initial Validation Loss: 0.1140, Validation Loss: 0.0776,V Acc: 0.6389, Top 70th Acc: 0.7632, Bottom 30th Acc: 0.3438
Fold [5/5] Epoch [20/100] Initial Loss: 0.1271, Training Loss: 0.0797, Initial Validation Loss: 0.1140, Validation Loss: 0.0765,V Acc: 0.6481, Top 70th Acc: 0.7500, Bottom 30th Acc: 0.4062
Fold [1/5] Epoch [20/100] Initial Loss: 0.1383, Training Loss: 0.0198, Initial Validation Loss: 0.1316, Validation Loss: 0.0304,V Acc: 0.8393, Top 70th Acc: 0.9367, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 20  Rolling back to Epoch (base 0): 15  Top Validation Acc: 0.9367088607594937
Fold [2/5] Epoch [0/100] Initial Loss: 0.1415, Training Loss: 0.1415, Initial Validation Loss: 0.1338, Validation Loss: 0.1338,V Acc: 0.4144, Top 70th Acc: 0.4103, Bottom 30th Acc: 0.4242
Fold [2/5] Epoch [10/100] Initial Loss: 0.1415, Training Loss: 0.0328, Initial Validation Loss: 0.1338, Validation Loss: 0.0362,V Acc: 0.8559, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.6970
Fold [2/5] Epoch [20/100] Initial Loss: 0.1415, Training Loss: 0.0196, Initial Validation Loss: 0.1338, Validation Loss: 0.0274,V Acc: 0.8559, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.9487179487179487
49 1 [array([0.72205555, 0.08783791, 0.02854417, 0.07228875, 0.08927374],
      dtype=float32)]
Fold [3/5] Epoch [0/100] Initial Loss: 0.1397, Training Loss: 0.1397, Initial Validation Loss: 0.1329, Validation Loss: 0.1329,V Acc: 0.2636, Top 70th Acc: 0.2987, Bottom 30th Acc: 0.1818
Fold [3/5] Epoch [10/100] Initial Loss: 0.1397, Training Loss: 0.0433, Initial Validation Loss: 0.1329, Validation Loss: 0.0475,V Acc: 0.7182, Top 70th Acc: 0.8961, Bottom 30th Acc: 0.3030
Fold [3/5] Epoch [20/100] Initial Loss: 0.1397, Training Loss: 0.0207, Initial Validation Loss: 0.1329, Validation Loss: 0.0301,V Acc: 0.8455, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 21  Rolling back to Epoch (base 0): 16  Top Validation Acc: 0.948051948051948
Fold [4/5] Epoch [0/100] Initial Loss: 0.1421, Training Loss: 0.1421, Initial Validation Loss: 0.1364, Validation Loss: 0.1364,V Acc: 0.2844, Top 70th Acc: 0.2987, Bottom 30th Acc: 0.2500
Fold [4/5] Epoch [10/100] Initial Loss: 0.1421, Training Loss: 0.0419, Initial Validation Loss: 0.1364, Validation Loss: 0.0476,V Acc: 0.8165, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.5938
Fold [4/5] Epoch [20/100] Initial Loss: 0.1421, Training Loss: 0.0198, Initial Validation Loss: 0.1364, Validation Loss: 0.0341,V Acc: 0.8624, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.6875
Fold [4/5] Epoch [30/100] Initial Loss: 0.1421, Training Loss: 0.0173, Initial Validation Loss: 0.1364, Validation Loss: 0.0339,V Acc: 0.8532, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.6562
Stopping early at Epoch (base 0): 32  Rolling back to Epoch (base 0): 27  Top Validation Acc: 0.9090909090909091
Fold [5/5] Epoch [0/100] Initial Loss: 0.1396, Training Loss: 0.1396, Initial Validation Loss: 0.1333, Validation Loss: 0.1333,V Acc: 0.2870, Top 70th Acc: 0.3421, Bottom 30th Acc: 0.1562
Fold [5/5] Epoch [10/100] Initial Loss: 0.1396, Training Loss: 0.0318, Initial Validation Loss: 0.1333, Validation Loss: 0.0478,V Acc: 0.7870, Top 70th Acc: 0.8684, Bottom 30th Acc: 0.5938
Fold [5/5] Epoch [20/100] Initial Loss: 0.1396, Training Loss: 0.0179, Initial Validation Loss: 0.1333, Validation Loss: 0.0377,V Acc: 0.8241, Top 70th Acc: 0.9079, Bottom 30th Acc: 0.6250
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.9210526315789473
Running train_nn.py with seed 50
CUDA:False
Training samples count:  550
Training on 30 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1390, Training Loss: 0.1390, Initial Validation Loss: 0.1345, Validation Loss: 0.1345,V Acc: 0.2946, Top 70th Acc: 0.3544, Bottom 30th Acc: 0.1515
Fold [1/5] Epoch [10/100] Initial Loss: 0.1390, Training Loss: 0.0293, Initial Validation Loss: 0.1345, Validation Loss: 0.0370,V Acc: 0.8304, Top 70th Acc: 0.9241, Bottom 30th Acc: 0.6061
Fold [1/5] Epoch [20/100] Initial Loss: 0.1390, Training Loss: 0.0179, Initial Validation Loss: 0.1345, Validation Loss: 0.0316,V Acc: 0.8393, Top 70th Acc: 0.9367, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 28  Rolling back to Epoch (base 0): 23  Top Validation Acc: 0.9493670886075949
Fold [2/5] Epoch [0/100] Initial Loss: 0.1385, Training Loss: 0.1385, Initial Validation Loss: 0.1281, Validation Loss: 0.1281,V Acc: 0.3964, Top 70th Acc: 0.4615, Bottom 30th Acc: 0.2424
Fold [2/5] Epoch [10/100] Initial Loss: 0.1385, Training Loss: 0.0335, Initial Validation Loss: 0.1281, Validation Loss: 0.0376,V Acc: 0.8018, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.5455
Fold [2/5] Epoch [20/100] Initial Loss: 0.1385, Training Loss: 0.0179, Initial Validation Loss: 0.1281, Validation Loss: 0.0358,V Acc: 0.7748, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.4545
Stopping early at Epoch (base 0): 20  Rolling back to Epoch (base 0): 15  Top Validation Acc: 0.9102564102564102
Fold [3/5] Epoch [0/100] Initial Loss: 0.1405, Training Loss: 0.1405, Initial Validation Loss: 0.1332, Validation Loss: 0.1332,V Acc: 0.3364, Top 70th Acc: 0.4026, Bottom 30th Acc: 0.1818
Fold [3/5] Epoch [10/100] Initial Loss: 0.1405, Training Loss: 0.0268, Initial Validation Loss: 0.1332, Validation Loss: 0.0346,V Acc: 0.8273, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 16  Rolling back to Epoch (base 0): 11  Top Validation Acc: 0.935064935064935
50 2 [array([0.4837446 , 0.04877916, 0.08760788, 0.15591666, 0.2239517 ],
      dtype=float32)]
Fold [4/5] Epoch [0/100] Initial Loss: 0.1361, Training Loss: 0.1361, Initial Validation Loss: 0.1295, Validation Loss: 0.1295,V Acc: 0.4128, Top 70th Acc: 0.5325, Bottom 30th Acc: 0.1250
Fold [4/5] Epoch [10/100] Initial Loss: 0.1361, Training Loss: 0.0371, Initial Validation Loss: 0.1295, Validation Loss: 0.0504,V Acc: 0.8165, Top 70th Acc: 0.8442, Bottom 30th Acc: 0.7500
Fold [4/5] Epoch [20/100] Initial Loss: 0.1361, Training Loss: 0.0185, Initial Validation Loss: 0.1295, Validation Loss: 0.0416,V Acc: 0.7982, Top 70th Acc: 0.8961, Bottom 30th Acc: 0.5625
Stopping early at Epoch (base 0): 28  Rolling back to Epoch (base 0): 23  Top Validation Acc: 0.9090909090909091
Fold [5/5] Epoch [0/100] Initial Loss: 0.1405, Training Loss: 0.1405, Initial Validation Loss: 0.1356, Validation Loss: 0.1356,V Acc: 0.3241, Top 70th Acc: 0.3553, Bottom 30th Acc: 0.2500
Fold [5/5] Epoch [10/100] Initial Loss: 0.1405, Training Loss: 0.0425, Initial Validation Loss: 0.1356, Validation Loss: 0.0440,V Acc: 0.8148, Top 70th Acc: 0.8947, Bottom 30th Acc: 0.6250
Fold [5/5] Epoch [20/100] Initial Loss: 0.1405, Training Loss: 0.0207, Initial Validation Loss: 0.1356, Validation Loss: 0.0301,V Acc: 0.8426, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.5625
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.9473684210526315
Running train_nn.py with seed 51
CUDA:False
Training samples count:  550
Training on 30 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1405, Training Loss: 0.1405, Initial Validation Loss: 0.1359, Validation Loss: 0.1359,V Acc: 0.2768, Top 70th Acc: 0.2785, Bottom 30th Acc: 0.2727
Fold [1/5] Epoch [10/100] Initial Loss: 0.1405, Training Loss: 0.0312, Initial Validation Loss: 0.1359, Validation Loss: 0.0433,V Acc: 0.7946, Top 70th Acc: 0.9114, Bottom 30th Acc: 0.5152
Fold [1/5] Epoch [20/100] Initial Loss: 0.1405, Training Loss: 0.0205, Initial Validation Loss: 0.1359, Validation Loss: 0.0398,V Acc: 0.7857, Top 70th Acc: 0.9241, Bottom 30th Acc: 0.4545
Fold [1/5] Epoch [30/100] Initial Loss: 0.1405, Training Loss: 0.0167, Initial Validation Loss: 0.1359, Validation Loss: 0.0386,V Acc: 0.8036, Top 70th Acc: 0.9241, Bottom 30th Acc: 0.5152
Stopping early at Epoch (base 0): 34  Rolling back to Epoch (base 0): 29  Top Validation Acc: 0.9367088607594937
Fold [2/5] Epoch [0/100] Initial Loss: 0.1373, Training Loss: 0.1373, Initial Validation Loss: 0.1329, Validation Loss: 0.1329,V Acc: 0.2883, Top 70th Acc: 0.3462, Bottom 30th Acc: 0.1515
Fold [2/5] Epoch [10/100] Initial Loss: 0.1373, Training Loss: 0.0281, Initial Validation Loss: 0.1329, Validation Loss: 0.0406,V Acc: 0.8288, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.5758
Fold [2/5] Epoch [20/100] Initial Loss: 0.1373, Training Loss: 0.0177, Initial Validation Loss: 0.1329, Validation Loss: 0.0376,V Acc: 0.8108, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.5455
Fold [1/5] Epoch [0/100] Initial Loss: 0.1350, Training Loss: 0.1350, Initial Validation Loss: 0.1192, Validation Loss: 0.1192,V Acc: 0.4375, Top 70th Acc: 0.5063, Bottom 30th Acc: 0.2727
Fold [1/5] Epoch [10/100] Initial Loss: 0.1350, Training Loss: 0.0219, Initial Validation Loss: 0.1192, Validation Loss: 0.0258,V Acc: 0.8750, Top 70th Acc: 0.9620, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 16  Rolling back to Epoch (base 0): 11  Top Validation Acc: 0.9113924050632911
70 0 [array([0.7708249 , 0.02720952, 0.03554792, 0.0687241 , 0.09769348],
      dtype=float32)]
Fold [2/5] Epoch [0/100] Initial Loss: 0.1368, Training Loss: 0.1368, Initial Validation Loss: 0.1209, Validation Loss: 0.1209,V Acc: 0.4324, Top 70th Acc: 0.5385, Bottom 30th Acc: 0.1818
Fold [2/5] Epoch [10/100] Initial Loss: 0.1368, Training Loss: 0.0196, Initial Validation Loss: 0.1209, Validation Loss: 0.0338,V Acc: 0.8468, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 16  Rolling back to Epoch (base 0): 11  Top Validation Acc: 0.9487179487179487
Fold [3/5] Epoch [0/100] Initial Loss: 0.1308, Training Loss: 0.1308, Initial Validation Loss: 0.1160, Validation Loss: 0.1160,V Acc: 0.5182, Top 70th Acc: 0.6234, Bottom 30th Acc: 0.2727
Fold [3/5] Epoch [10/100] Initial Loss: 0.1308, Training Loss: 0.0207, Initial Validation Loss: 0.1160, Validation Loss: 0.0274,V Acc: 0.8545, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 14  Rolling back to Epoch (base 0): 9  Top Validation Acc: 0.987012987012987
Fold [4/5] Epoch [0/100] Initial Loss: 0.1330, Training Loss: 0.1330, Initial Validation Loss: 0.1270, Validation Loss: 0.1270,V Acc: 0.4404, Top 70th Acc: 0.5974, Bottom 30th Acc: 0.0625
Fold [4/5] Epoch [10/100] Initial Loss: 0.1330, Training Loss: 0.0266, Initial Validation Loss: 0.1270, Validation Loss: 0.0229,V Acc: 0.8807, Top 70th Acc: 0.9870, Bottom 30th Acc: 0.6250
Fold [4/5] Epoch [20/100] Initial Loss: 0.1330, Training Loss: 0.0178, Initial Validation Loss: 0.1270, Validation Loss: 0.0217,V Acc: 0.8899, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.7188
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.961038961038961
Fold [5/5] Epoch [0/100] Initial Loss: 0.1386, Training Loss: 0.1386, Initial Validation Loss: 0.1198, Validation Loss: 0.1198,V Acc: 0.4722, Top 70th Acc: 0.6053, Bottom 30th Acc: 0.1562
Fold [5/5] Epoch [10/100] Initial Loss: 0.1386, Training Loss: 0.0246, Initial Validation Loss: 0.1198, Validation Loss: 0.0328,V Acc: 0.8519, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.6562
Stopping early at Epoch (base 0): 19  Rolling back to Epoch (base 0): 14  Top Validation Acc: 0.9342105263157895
Running train_nn.py with seed 71
CUDA:False
Training samples count:  550
Training on 21 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1400, Training Loss: 0.1400, Initial Validation Loss: 0.1317, Validation Loss: 0.1317,V Acc: 0.4821, Top 70th Acc: 0.5570, Bottom 30th Acc: 0.3030
Fold [1/5] Epoch [10/100] Initial Loss: 0.1400, Training Loss: 0.0270, Initial Validation Loss: 0.1317, Validation Loss: 0.0225,V Acc: 0.9018, Top 70th Acc: 1.0000, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 19  Rolling back to Epoch (base 0): 14  Top Validation Acc: 0.9873417721518988
Fold [2/5] Epoch [0/100] Initial Loss: 0.1358, Training Loss: 0.1358, Initial Validation Loss: 0.1223, Validation Loss: 0.1223,V Acc: 0.4414, Top 70th Acc: 0.4744, Bottom 30th Acc: 0.3636
Fold [2/5] Epoch [10/100] Initial Loss: 0.1358, Training Loss: 0.0286, Initial Validation Loss: 0.1223, Validation Loss: 0.0311,V Acc: 0.8559, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.6667
Fold [2/5] Epoch [20/100] Initial Loss: 0.1358, Training Loss: 0.0156, Initial Validation Loss: 0.1223, Validation Loss: 0.0358,V Acc: 0.8288, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.9230769230769231
Fold [3/5] Epoch [0/100] Initial Loss: 0.1334, Training Loss: 0.1334, Initial Validation Loss: 0.1145, Validation Loss: 0.1145,V Acc: 0.6091, Top 70th Acc: 0.7403, Bottom 30th Acc: 0.3030
Fold [3/5] Epoch [10/100] Initial Loss: 0.1334, Training Loss: 0.0255, Initial Validation Loss: 0.1145, Validation Loss: 0.0276,V Acc: 0.8818, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.6970
Fold [3/5] Epoch [20/100] Initial Loss: 0.1334, Training Loss: 0.0164, Initial Validation Loss: 0.1145, Validation Loss: 0.0235,V Acc: 0.8818, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 28  Rolling back to Epoch (base 0): 23  Top Validation Acc: 0.987012987012987
71 2 [array([0.9020771 , 0.01253312, 0.00948418, 0.04607605, 0.02982964],
      dtype=float32)]
Fold [4/5] Epoch [0/100] Initial Loss: 0.1299, Training Loss: 0.1299, Initial Validation Loss: 0.1217, Validation Loss: 0.1217,V Acc: 0.5688, Top 70th Acc: 0.6104, Bottom 30th Acc: 0.4688
Fold [4/5] Epoch [10/100] Initial Loss: 0.1299, Training Loss: 0.0198, Initial Validation Loss: 0.1217, Validation Loss: 0.0257,V Acc: 0.9174, Top 70th Acc: 0.9870, Bottom 30th Acc: 0.7500
Fold [4/5] Epoch [20/100] Initial Loss: 0.1299, Training Loss: 0.0158, Initial Validation Loss: 0.1217, Validation Loss: 0.0214,V Acc: 0.9174, Top 70th Acc: 0.9870, Bottom 30th Acc: 0.7500
Fold [4/5] Epoch [30/100] Initial Loss: 0.1299, Training Loss: 0.0153, Initial Validation Loss: 0.1217, Validation Loss: 0.0213,V Acc: 0.8991, Top 70th Acc: 0.9870, Bottom 30th Acc: 0.6875
Stopping early at Epoch (base 0): 32  Rolling back to Epoch (base 0): 27  Top Validation Acc: 0.987012987012987
Fold [5/5] Epoch [0/100] Initial Loss: 0.1330, Training Loss: 0.1330, Initial Validation Loss: 0.1178, Validation Loss: 0.1178,V Acc: 0.5926, Top 70th Acc: 0.6184, Bottom 30th Acc: 0.5312
Fold [5/5] Epoch [10/100] Initial Loss: 0.1330, Training Loss: 0.0195, Initial Validation Loss: 0.1178, Validation Loss: 0.0277,V Acc: 0.8611, Top 70th Acc: 0.9211, Bottom 30th Acc: 0.7188
Stopping early at Epoch (base 0): 15  Rolling back to Epoch (base 0): 10  Top Validation Acc: 0.9078947368421053
Running train_nn.py with seed 72
CUDA:False
Training samples count:  550
Training on 21 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1317, Training Loss: 0.1317, Initial Validation Loss: 0.1168, Validation Loss: 0.1168,V Acc: 0.4911, Top 70th Acc: 0.5949, Bottom 30th Acc: 0.2424
Fold [1/5] Epoch [10/100] Initial Loss: 0.1317, Training Loss: 0.0197, Initial Validation Loss: 0.1168, Validation Loss: 0.0308,V Acc: 0.8393, Top 70th Acc: 0.9494, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 16  Rolling back to Epoch (base 0): 11  Top Validation Acc: 0.9240506329113924
Fold [2/5] Epoch [0/100] Initial Loss: 0.1377, Training Loss: 0.1377, Initial Validation Loss: 0.1256, Validation Loss: 0.1256,V Acc: 0.4054, Top 70th Acc: 0.4487, Bottom 30th Acc: 0.3030
Fold [2/5] Epoch [10/100] Initial Loss: 0.1377, Training Loss: 0.0210, Initial Validation Loss: 0.1256, Validation Loss: 0.0292,V Acc: 0.8559, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 18  Rolling back to Epoch (base 0): 13  Top Validation Acc: 0.9743589743589743
Fold [3/5] Epoch [0/100] Initial Loss: 0.1366, Training Loss: 0.1366, Initial Validation Loss: 0.1264, Validation Loss: 0.1264,V Acc: 0.3909, Top 70th Acc: 0.4675, Bottom 30th Acc: 0.2121
Fold [3/5] Epoch [10/100] Initial Loss: 0.1366, Training Loss: 0.0239, Initial Validation Loss: 0.1264, Validation Loss: 0.0315,V Acc: 0.8455, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.5455
Fold [3/5] Epoch [20/100] Initial Loss: 0.1366, Training Loss: 0.0149, Initial Validation Loss: 0.1264, Validation Loss: 0.0246,V Acc: 0.9000, Top 70th Acc: 0.9870, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 21  Rolling back to Epoch (base 0): 16  Top Validation Acc: 0.974025974025974
Fold [4/5] Epoch [0/100] Initial Loss: 0.1328, Training Loss: 0.1328, Initial Validation Loss: 0.1258, Validation Loss: 0.1258,V Acc: 0.3945, Top 70th Acc: 0.5584, Bottom 30th Acc: 0.0000
Fold [4/5] Epoch [10/100] Initial Loss: 0.1328, Training Loss: 0.0248, Initial Validation Loss: 0.1258, Validation Loss: 0.0256,V Acc: 0.8532, Top 70th Acc: 0.9870, Bottom 30th Acc: 0.5312
Fold [4/5] Epoch [80/100] Initial Loss: 0.1385, Training Loss: 0.0036, Initial Validation Loss: 0.1351, Validation Loss: 0.0335,V Acc: 0.8257, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.5312
Stopping early at Epoch (base 0): 87  Rolling back to Epoch (base 0): 82  Top Validation Acc: 0.935064935064935
39 3 [array([0.50539726, 0.04023242, 0.05260457, 0.23254228, 0.16922349],
      dtype=float32)]
Fold [5/5] Epoch [0/100] Initial Loss: 0.1400, Training Loss: 0.1400, Initial Validation Loss: 0.1308, Validation Loss: 0.1308,V Acc: 0.2500, Top 70th Acc: 0.3421, Bottom 30th Acc: 0.0312
Fold [5/5] Epoch [10/100] Initial Loss: 0.1400, Training Loss: 0.0212, Initial Validation Loss: 0.1308, Validation Loss: 0.0392,V Acc: 0.8056, Top 70th Acc: 0.9079, Bottom 30th Acc: 0.5625
Fold [5/5] Epoch [20/100] Initial Loss: 0.1400, Training Loss: 0.0051, Initial Validation Loss: 0.1308, Validation Loss: 0.0305,V Acc: 0.8426, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.5625
Fold [5/5] Epoch [30/100] Initial Loss: 0.1400, Training Loss: 0.0041, Initial Validation Loss: 0.1308, Validation Loss: 0.0300,V Acc: 0.8333, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.5312
Stopping early at Epoch (base 0): 30  Rolling back to Epoch (base 0): 25  Top Validation Acc: 0.9605263157894737
Running train_nn.py with seed 40
CUDA:False
Training samples count:  550
Training on 162 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1402, Training Loss: 0.1402, Initial Validation Loss: 0.1357, Validation Loss: 0.1357,V Acc: 0.2589, Top 70th Acc: 0.3544, Bottom 30th Acc: 0.0303
Fold [1/5] Epoch [10/100] Initial Loss: 0.1402, Training Loss: 0.0212, Initial Validation Loss: 0.1357, Validation Loss: 0.0357,V Acc: 0.8393, Top 70th Acc: 0.9367, Bottom 30th Acc: 0.6061
Fold [1/5] Epoch [20/100] Initial Loss: 0.1402, Training Loss: 0.0049, Initial Validation Loss: 0.1357, Validation Loss: 0.0305,V Acc: 0.8304, Top 70th Acc: 0.9620, Bottom 30th Acc: 0.5152
Stopping early at Epoch (base 0): 21  Rolling back to Epoch (base 0): 16  Top Validation Acc: 0.9493670886075949
Fold [2/5] Epoch [0/100] Initial Loss: 0.1393, Training Loss: 0.1393, Initial Validation Loss: 0.1363, Validation Loss: 0.1363,V Acc: 0.2523, Top 70th Acc: 0.3333, Bottom 30th Acc: 0.0606
Fold [2/5] Epoch [10/100] Initial Loss: 0.1393, Training Loss: 0.0293, Initial Validation Loss: 0.1363, Validation Loss: 0.0372,V Acc: 0.8739, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.6970
Fold [2/5] Epoch [20/100] Initial Loss: 0.1393, Training Loss: 0.0061, Initial Validation Loss: 0.1363, Validation Loss: 0.0257,V Acc: 0.8919, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.7273
Stopping early at Epoch (base 0): 22  Rolling back to Epoch (base 0): 17  Top Validation Acc: 0.9615384615384616
40 1 [array([0.3941958 , 0.08434209, 0.08379675, 0.16568235, 0.27198303],
      dtype=float32)]
Fold [3/5] Epoch [0/100] Initial Loss: 0.1388, Training Loss: 0.1388, Initial Validation Loss: 0.1364, Validation Loss: 0.1364,V Acc: 0.2909, Top 70th Acc: 0.3506, Bottom 30th Acc: 0.1515
Fold [3/5] Epoch [10/100] Initial Loss: 0.1388, Training Loss: 0.0155, Initial Validation Loss: 0.1364, Validation Loss: 0.0423,V Acc: 0.7909, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.4848
Fold [3/5] Epoch [20/100] Initial Loss: 0.1388, Training Loss: 0.0050, Initial Validation Loss: 0.1364, Validation Loss: 0.0418,V Acc: 0.8000, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.4848
Stopping early at Epoch (base 0): 20  Rolling back to Epoch (base 0): 15  Top Validation Acc: 0.935064935064935
Fold [4/5] Epoch [0/100] Initial Loss: 0.1419, Training Loss: 0.1419, Initial Validation Loss: 0.1289, Validation Loss: 0.1289,V Acc: 0.2936, Top 70th Acc: 0.3117, Bottom 30th Acc: 0.2500
Fold [4/5] Epoch [10/100] Initial Loss: 0.1419, Training Loss: 0.0144, Initial Validation Loss: 0.1289, Validation Loss: 0.0380,V Acc: 0.8165, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.5625
Fold [4/5] Epoch [20/100] Initial Loss: 0.1419, Training Loss: 0.0049, Initial Validation Loss: 0.1289, Validation Loss: 0.0355,V Acc: 0.8349, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.6562
Fold [4/5] Epoch [30/100] Initial Loss: 0.1419, Training Loss: 0.0040, Initial Validation Loss: 0.1289, Validation Loss: 0.0349,V Acc: 0.8349, Top 70th Acc: 0.8961, Bottom 30th Acc: 0.6875
Fold [4/5] Epoch [40/100] Initial Loss: 0.1419, Training Loss: 0.0037, Initial Validation Loss: 0.1289, Validation Loss: 0.0339,V Acc: 0.8532, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.7188
Fold [4/5] Epoch [50/100] Initial Loss: 0.1419, Training Loss: 0.0036, Initial Validation Loss: 0.1289, Validation Loss: 0.0337,V Acc: 0.8349, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.6562
Fold [4/5] Epoch [60/100] Initial Loss: 0.1419, Training Loss: 0.0035, Initial Validation Loss: 0.1289, Validation Loss: 0.0332,V Acc: 0.8440, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.6875
Stopping early at Epoch (base 0): 66  Rolling back to Epoch (base 0): 61  Top Validation Acc: 0.8961038961038961
Fold [5/5] Epoch [0/100] Initial Loss: 0.1380, Training Loss: 0.1380, Initial Validation Loss: 0.1333, Validation Loss: 0.1333,V Acc: 0.2685, Top 70th Acc: 0.3421, Bottom 30th Acc: 0.0938
Fold [5/5] Epoch [10/100] Initial Loss: 0.1380, Training Loss: 0.0186, Initial Validation Loss: 0.1333, Validation Loss: 0.0398,V Acc: 0.7870, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.4375
Fold [5/5] Epoch [20/100] Initial Loss: 0.1380, Training Loss: 0.0057, Initial Validation Loss: 0.1333, Validation Loss: 0.0329,V Acc: 0.8333, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.5625
Fold [5/5] Epoch [30/100] Initial Loss: 0.1380, Training Loss: 0.0043, Initial Validation Loss: 0.1333, Validation Loss: 0.0293,V Acc: 0.8519, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.5938
Fold [5/5] Epoch [40/100] Initial Loss: 0.1380, Training Loss: 0.0040, Initial Validation Loss: 0.1333, Validation Loss: 0.0276,V Acc: 0.8611, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.6562
Stopping early at Epoch (base 0): 47  Rolling back to Epoch (base 0): 42  Top Validation Acc: 0.9605263157894737
Running train_nn.py with seed 41
CUDA:False
Training samples count:  550
Training on 162 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1381, Training Loss: 0.1381, Initial Validation Loss: 0.1375, Validation Loss: 0.1375,V Acc: 0.3750, Top 70th Acc: 0.4051, Bottom 30th Acc: 0.3030
Fold [1/5] Epoch [10/100] Initial Loss: 0.1381, Training Loss: 0.0232, Initial Validation Loss: 0.1375, Validation Loss: 0.0472,V Acc: 0.7857, Top 70th Acc: 0.8608, Bottom 30th Acc: 0.6061
Fold [1/5] Epoch [20/100] Initial Loss: 0.1381, Training Loss: 0.0049, Initial Validation Loss: 0.1375, Validation Loss: 0.0349,V Acc: 0.8036, Top 70th Acc: 0.9494, Bottom 30th Acc: 0.4545
Fold [1/5] Epoch [30/100] Initial Loss: 0.1381, Training Loss: 0.0037, Initial Validation Loss: 0.1375, Validation Loss: 0.0331,V Acc: 0.8304, Top 70th Acc: 0.9494, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 30  Rolling back to Epoch (base 0): 25  Top Validation Acc: 0.9493670886075949
Fold [2/5] Epoch [0/100] Initial Loss: 0.1399, Training Loss: 0.1399, Initial Validation Loss: 0.1305, Validation Loss: 0.1305,V Acc: 0.4685, Top 70th Acc: 0.5513, Bottom 30th Acc: 0.2727
Fold [2/5] Epoch [10/100] Initial Loss: 0.1399, Training Loss: 0.0125, Initial Validation Loss: 0.1305, Validation Loss: 0.0406,V Acc: 0.7658, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.4242
Fold [2/5] Epoch [20/100] Initial Loss: 0.1399, Training Loss: 0.0046, Initial Validation Loss: 0.1305, Validation Loss: 0.0350,V Acc: 0.7928, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.4848
Stopping early at Epoch (base 0): 28  Rolling back to Epoch (base 0): 23  Top Validation Acc: 0.9102564102564102
Fold [3/5] Epoch [0/100] Initial Loss: 0.1404, Training Loss: 0.1404, Initial Validation Loss: 0.1332, Validation Loss: 0.1332,V Acc: 0.2636, Top 70th Acc: 0.2857, Bottom 30th Acc: 0.2121
Fold [3/5] Epoch [10/100] Initial Loss: 0.1404, Training Loss: 0.0325, Initial Validation Loss: 0.1332, Validation Loss: 0.0393,V Acc: 0.8000, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.4242
Fold [3/5] Epoch [20/100] Initial Loss: 0.1404, Training Loss: 0.0054, Initial Validation Loss: 0.1332, Validation Loss: 0.0216,V Acc: 0.8818, Top 70th Acc: 1.0000, Bottom 30th Acc: 0.6061
Fold [1/5] Epoch [20/100] Initial Loss: 0.1410, Training Loss: 0.0152, Initial Validation Loss: 0.1370, Validation Loss: 0.0394,V Acc: 0.8036, Top 70th Acc: 0.8987, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 29  Rolling back to Epoch (base 0): 24  Top Validation Acc: 0.8987341772151899
53 0 [array([0.47818765, 0.06483276, 0.13471612, 0.16684191, 0.15542153],
      dtype=float32)]
Fold [2/5] Epoch [0/100] Initial Loss: 0.1400, Training Loss: 0.1400, Initial Validation Loss: 0.1346, Validation Loss: 0.1346,V Acc: 0.2523, Top 70th Acc: 0.2436, Bottom 30th Acc: 0.2727
Fold [2/5] Epoch [10/100] Initial Loss: 0.1400, Training Loss: 0.0337, Initial Validation Loss: 0.1346, Validation Loss: 0.0398,V Acc: 0.8288, Top 70th Acc: 0.8846, Bottom 30th Acc: 0.6970
Fold [2/5] Epoch [20/100] Initial Loss: 0.1400, Training Loss: 0.0151, Initial Validation Loss: 0.1346, Validation Loss: 0.0305,V Acc: 0.8378, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.6061
Fold [2/5] Epoch [30/100] Initial Loss: 0.1400, Training Loss: 0.0118, Initial Validation Loss: 0.1346, Validation Loss: 0.0305,V Acc: 0.8378, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 34  Rolling back to Epoch (base 0): 29  Top Validation Acc: 0.9230769230769231
Fold [3/5] Epoch [0/100] Initial Loss: 0.1388, Training Loss: 0.1388, Initial Validation Loss: 0.1324, Validation Loss: 0.1324,V Acc: 0.3727, Top 70th Acc: 0.4545, Bottom 30th Acc: 0.1818
Fold [3/5] Epoch [10/100] Initial Loss: 0.1388, Training Loss: 0.0264, Initial Validation Loss: 0.1324, Validation Loss: 0.0316,V Acc: 0.9000, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.7273
Fold [3/5] Epoch [20/100] Initial Loss: 0.1388, Training Loss: 0.0154, Initial Validation Loss: 0.1324, Validation Loss: 0.0252,V Acc: 0.8636, Top 70th Acc: 1.0000, Bottom 30th Acc: 0.5455
Fold [3/5] Epoch [30/100] Initial Loss: 0.1388, Training Loss: 0.0130, Initial Validation Loss: 0.1324, Validation Loss: 0.0227,V Acc: 0.8818, Top 70th Acc: 1.0000, Bottom 30th Acc: 0.6061
Fold [3/5] Epoch [40/100] Initial Loss: 0.1388, Training Loss: 0.0118, Initial Validation Loss: 0.1324, Validation Loss: 0.0222,V Acc: 0.8727, Top 70th Acc: 1.0000, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 45  Rolling back to Epoch (base 0): 40  Top Validation Acc: 1.0
Fold [4/5] Epoch [0/100] Initial Loss: 0.1370, Training Loss: 0.1370, Initial Validation Loss: 0.1318, Validation Loss: 0.1318,V Acc: 0.3945, Top 70th Acc: 0.4675, Bottom 30th Acc: 0.2188
Fold [4/5] Epoch [10/100] Initial Loss: 0.1370, Training Loss: 0.0276, Initial Validation Loss: 0.1318, Validation Loss: 0.0405,V Acc: 0.7890, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.5000
Fold [4/5] Epoch [20/100] Initial Loss: 0.1370, Training Loss: 0.0150, Initial Validation Loss: 0.1318, Validation Loss: 0.0315,V Acc: 0.8165, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.5000
Fold [4/5] Epoch [30/100] Initial Loss: 0.1370, Training Loss: 0.0121, Initial Validation Loss: 0.1318, Validation Loss: 0.0311,V Acc: 0.8257, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.5312
Stopping early at Epoch (base 0): 31  Rolling back to Epoch (base 0): 26  Top Validation Acc: 0.948051948051948
Fold [5/5] Epoch [0/100] Initial Loss: 0.1373, Training Loss: 0.1373, Initial Validation Loss: 0.1257, Validation Loss: 0.1257,V Acc: 0.3889, Top 70th Acc: 0.4079, Bottom 30th Acc: 0.3438
Fold [5/5] Epoch [10/100] Initial Loss: 0.1373, Training Loss: 0.0314, Initial Validation Loss: 0.1257, Validation Loss: 0.0417,V Acc: 0.8056, Top 70th Acc: 0.8684, Bottom 30th Acc: 0.6562
Fold [5/5] Epoch [20/100] Initial Loss: 0.1373, Training Loss: 0.0151, Initial Validation Loss: 0.1257, Validation Loss: 0.0385,V Acc: 0.8241, Top 70th Acc: 0.8816, Bottom 30th Acc: 0.6875
Stopping early at Epoch (base 0): 28  Rolling back to Epoch (base 0): 23  Top Validation Acc: 0.868421052631579
Running train_nn.py with seed 54
CUDA:False
Training samples count:  550
Training on 40 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1379, Training Loss: 0.1379, Initial Validation Loss: 0.1294, Validation Loss: 0.1294,V Acc: 0.4643, Top 70th Acc: 0.5316, Bottom 30th Acc: 0.3030
Fold [1/5] Epoch [10/100] Initial Loss: 0.1379, Training Loss: 0.0293, Initial Validation Loss: 0.1294, Validation Loss: 0.0311,V Acc: 0.8571, Top 70th Acc: 0.9620, Bottom 30th Acc: 0.6061
Fold [1/5] Epoch [20/100] Initial Loss: 0.1379, Training Loss: 0.0168, Initial Validation Loss: 0.1294, Validation Loss: 0.0265,V Acc: 0.8571, Top 70th Acc: 0.9747, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 22  Rolling back to Epoch (base 0): 17  Top Validation Acc: 0.9746835443037974
54 0 [array([0.58710665, 0.1564151 , 0.05273281, 0.07338413, 0.13036135],
      dtype=float32)]
Fold [2/5] Epoch [0/100] Initial Loss: 0.1384, Training Loss: 0.1384, Initial Validation Loss: 0.1296, Validation Loss: 0.1296,V Acc: 0.5405, Top 70th Acc: 0.6410, Bottom 30th Acc: 0.3030
Fold [2/5] Epoch [10/100] Initial Loss: 0.1384, Training Loss: 0.0350, Initial Validation Loss: 0.1296, Validation Loss: 0.0435,V Acc: 0.7838, Top 70th Acc: 0.8974, Bottom 30th Acc: 0.5152
Fold [2/5] Epoch [20/100] Initial Loss: 0.1384, Training Loss: 0.0147, Initial Validation Loss: 0.1296, Validation Loss: 0.0302,V Acc: 0.8829, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.7576
Stopping early at Epoch (base 0): 22  Rolling back to Epoch (base 0): 17  Top Validation Acc: 0.9358974358974359
Fold [3/5] Epoch [0/100] Initial Loss: 0.1359, Training Loss: 0.1359, Initial Validation Loss: 0.1328, Validation Loss: 0.1328,V Acc: 0.2909, Top 70th Acc: 0.3636, Bottom 30th Acc: 0.1212
Fold [3/5] Epoch [10/100] Initial Loss: 0.1359, Training Loss: 0.0276, Initial Validation Loss: 0.1328, Validation Loss: 0.0303,V Acc: 0.8818, Top 70th Acc: 0.9870, Bottom 30th Acc: 0.6364
Fold [3/5] Epoch [20/100] Initial Loss: 0.1359, Training Loss: 0.0165, Initial Validation Loss: 0.1328, Validation Loss: 0.0236,V Acc: 0.9273, Top 70th Acc: 0.9870, Bottom 30th Acc: 0.7879
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 1.0
Fold [4/5] Epoch [0/100] Initial Loss: 0.1445, Training Loss: 0.1445, Initial Validation Loss: 0.1350, Validation Loss: 0.1350,V Acc: 0.2936, Top 70th Acc: 0.3247, Bottom 30th Acc: 0.2188
Fold [4/5] Epoch [10/100] Initial Loss: 0.1445, Training Loss: 0.0334, Initial Validation Loss: 0.1350, Validation Loss: 0.0462,V Acc: 0.7798, Top 70th Acc: 0.8961, Bottom 30th Acc: 0.5000
Stopping early at Epoch (base 0): 19  Rolling back to Epoch (base 0): 14  Top Validation Acc: 0.9090909090909091
Fold [5/5] Epoch [0/100] Initial Loss: 0.1392, Training Loss: 0.1392, Initial Validation Loss: 0.1307, Validation Loss: 0.1307,V Acc: 0.2778, Top 70th Acc: 0.3158, Bottom 30th Acc: 0.1875
Fold [5/5] Epoch [10/100] Initial Loss: 0.1392, Training Loss: 0.0249, Initial Validation Loss: 0.1307, Validation Loss: 0.0380,V Acc: 0.7593, Top 70th Acc: 0.9079, Bottom 30th Acc: 0.4062
Stopping early at Epoch (base 0): 18  Rolling back to Epoch (base 0): 13  Top Validation Acc: 0.8947368421052632
Running train_nn.py with seed 55
CUDA:False
Training samples count:  550
Training on 40 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1424, Training Loss: 0.1424, Initial Validation Loss: 0.1369, Validation Loss: 0.1369,V Acc: 0.2589, Top 70th Acc: 0.3038, Bottom 30th Acc: 0.1515
Fold [1/5] Epoch [10/100] Initial Loss: 0.1424, Training Loss: 0.0343, Initial Validation Loss: 0.1369, Validation Loss: 0.0342,V Acc: 0.8750, Top 70th Acc: 0.9873, Bottom 30th Acc: 0.6061
Fold [1/5] Epoch [20/100] Initial Loss: 0.1424, Training Loss: 0.0151, Initial Validation Loss: 0.1369, Validation Loss: 0.0239,V Acc: 0.9018, Top 70th Acc: 0.9873, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.9873417721518988
Fold [2/5] Epoch [0/100] Initial Loss: 0.1389, Training Loss: 0.1389, Initial Validation Loss: 0.1334, Validation Loss: 0.1334,V Acc: 0.2883, Top 70th Acc: 0.3590, Bottom 30th Acc: 0.1212
Fold [2/5] Epoch [10/100] Initial Loss: 0.1389, Training Loss: 0.0319, Initial Validation Loss: 0.1334, Validation Loss: 0.0365,V Acc: 0.8288, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.5758
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 30 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 91
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 30 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 92
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 30 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 93
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 30 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 94
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 30 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 95
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 30 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 96
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 30 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 97
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 30 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 98
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 30 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 99
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 30 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 100
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 29 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5

Stopping early at Epoch (base 0): 19  Rolling back to Epoch (base 0): 14  Top Validation Acc: 0.9113924050632911
Fold [2/5] Epoch [0/100] Initial Loss: 0.1382, Training Loss: 0.1382, Initial Validation Loss: 0.1344, Validation Loss: 0.1344,V Acc: 0.4234, Top 70th Acc: 0.4872, Bottom 30th Acc: 0.2727
Fold [2/5] Epoch [10/100] Initial Loss: 0.1382, Training Loss: 0.0472, Initial Validation Loss: 0.1344, Validation Loss: 0.0560,V Acc: 0.7477, Top 70th Acc: 0.8718, Bottom 30th Acc: 0.4545
Fold [2/5] Epoch [20/100] Initial Loss: 0.1382, Training Loss: 0.0276, Initial Validation Loss: 0.1344, Validation Loss: 0.0416,V Acc: 0.8018, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.4848
Fold [2/5] Epoch [30/100] Initial Loss: 0.1382, Training Loss: 0.0215, Initial Validation Loss: 0.1344, Validation Loss: 0.0409,V Acc: 0.8018, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.5152
Stopping early at Epoch (base 0): 30  Rolling back to Epoch (base 0): 25  Top Validation Acc: 0.9230769230769231
Fold [3/5] Epoch [0/100] Initial Loss: 0.1404, Training Loss: 0.1404, Initial Validation Loss: 0.1286, Validation Loss: 0.1286,V Acc: 0.3455, Top 70th Acc: 0.3766, Bottom 30th Acc: 0.2727
Fold [3/5] Epoch [10/100] Initial Loss: 0.1404, Training Loss: 0.0345, Initial Validation Loss: 0.1286, Validation Loss: 0.0424,V Acc: 0.7909, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.5152
Fold [3/5] Epoch [20/100] Initial Loss: 0.1404, Training Loss: 0.0234, Initial Validation Loss: 0.1286, Validation Loss: 0.0371,V Acc: 0.7818, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.4848
Stopping early at Epoch (base 0): 27  Rolling back to Epoch (base 0): 22  Top Validation Acc: 0.9090909090909091
51 2 [array([0.23650862, 0.06636901, 0.09511066, 0.3458714 , 0.25614038],
      dtype=float32)]
Fold [4/5] Epoch [0/100] Initial Loss: 0.1378, Training Loss: 0.1378, Initial Validation Loss: 0.1344, Validation Loss: 0.1344,V Acc: 0.2477, Top 70th Acc: 0.2727, Bottom 30th Acc: 0.1875
Fold [4/5] Epoch [10/100] Initial Loss: 0.1378, Training Loss: 0.0352, Initial Validation Loss: 0.1344, Validation Loss: 0.0461,V Acc: 0.8073, Top 70th Acc: 0.8831, Bottom 30th Acc: 0.6250
Fold [4/5] Epoch [20/100] Initial Loss: 0.1378, Training Loss: 0.0237, Initial Validation Loss: 0.1344, Validation Loss: 0.0366,V Acc: 0.8440, Top 70th Acc: 0.8961, Bottom 30th Acc: 0.7188
Fold [4/5] Epoch [30/100] Initial Loss: 0.1378, Training Loss: 0.0214, Initial Validation Loss: 0.1344, Validation Loss: 0.0360,V Acc: 0.8440, Top 70th Acc: 0.8961, Bottom 30th Acc: 0.7188
Stopping early at Epoch (base 0): 31  Rolling back to Epoch (base 0): 26  Top Validation Acc: 0.8831168831168831
Fold [5/5] Epoch [0/100] Initial Loss: 0.1345, Training Loss: 0.1345, Initial Validation Loss: 0.1294, Validation Loss: 0.1294,V Acc: 0.3889, Top 70th Acc: 0.4474, Bottom 30th Acc: 0.2500
Fold [5/5] Epoch [10/100] Initial Loss: 0.1345, Training Loss: 0.0463, Initial Validation Loss: 0.1294, Validation Loss: 0.0420,V Acc: 0.7870, Top 70th Acc: 0.9211, Bottom 30th Acc: 0.4688
Fold [5/5] Epoch [20/100] Initial Loss: 0.1345, Training Loss: 0.0280, Initial Validation Loss: 0.1294, Validation Loss: 0.0318,V Acc: 0.8148, Top 70th Acc: 0.9737, Bottom 30th Acc: 0.4375
Fold [5/5] Epoch [30/100] Initial Loss: 0.1345, Training Loss: 0.0240, Initial Validation Loss: 0.1294, Validation Loss: 0.0285,V Acc: 0.8333, Top 70th Acc: 0.9737, Bottom 30th Acc: 0.5000
Stopping early at Epoch (base 0): 30  Rolling back to Epoch (base 0): 25  Top Validation Acc: 0.9736842105263158
Running train_nn.py with seed 52
CUDA:False
Training samples count:  550
Training on 20 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1403, Training Loss: 0.1403, Initial Validation Loss: 0.1354, Validation Loss: 0.1354,V Acc: 0.2500, Top 70th Acc: 0.3291, Bottom 30th Acc: 0.0606
Fold [1/5] Epoch [10/100] Initial Loss: 0.1403, Training Loss: 0.0349, Initial Validation Loss: 0.1354, Validation Loss: 0.0350,V Acc: 0.8393, Top 70th Acc: 0.9367, Bottom 30th Acc: 0.6061
Fold [1/5] Epoch [20/100] Initial Loss: 0.1403, Training Loss: 0.0246, Initial Validation Loss: 0.1354, Validation Loss: 0.0313,V Acc: 0.8304, Top 70th Acc: 0.9241, Bottom 30th Acc: 0.6061
Fold [1/5] Epoch [30/100] Initial Loss: 0.1403, Training Loss: 0.0226, Initial Validation Loss: 0.1354, Validation Loss: 0.0303,V Acc: 0.8571, Top 70th Acc: 0.9114, Bottom 30th Acc: 0.7273
Stopping early at Epoch (base 0): 32  Rolling back to Epoch (base 0): 27  Top Validation Acc: 0.9240506329113924
52 0 [array([0.19448066, 0.05718271, 0.18996966, 0.45585346, 0.10251348],
      dtype=float32)]
Fold [2/5] Epoch [0/100] Initial Loss: 0.1326, Training Loss: 0.1326, Initial Validation Loss: 0.1216, Validation Loss: 0.1216,V Acc: 0.4595, Top 70th Acc: 0.4231, Bottom 30th Acc: 0.5455
Fold [2/5] Epoch [10/100] Initial Loss: 0.1326, Training Loss: 0.0358, Initial Validation Loss: 0.1216, Validation Loss: 0.0425,V Acc: 0.7838, Top 70th Acc: 0.8974, Bottom 30th Acc: 0.5152
Fold [2/5] Epoch [20/100] Initial Loss: 0.1326, Training Loss: 0.0242, Initial Validation Loss: 0.1216, Validation Loss: 0.0334,V Acc: 0.8288, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.5455
Fold [2/5] Epoch [30/100] Initial Loss: 0.1326, Training Loss: 0.0211, Initial Validation Loss: 0.1216, Validation Loss: 0.0335,V Acc: 0.8018, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.4848
Stopping early at Epoch (base 0): 30  Rolling back to Epoch (base 0): 25  Top Validation Acc: 0.9358974358974359
Fold [3/5] Epoch [0/100] Initial Loss: 0.1415, Training Loss: 0.1415, Initial Validation Loss: 0.1343, Validation Loss: 0.1343,V Acc: 0.3182, Top 70th Acc: 0.3636, Bottom 30th Acc: 0.2121
Fold [3/5] Epoch [10/100] Initial Loss: 0.1415, Training Loss: 0.0351, Initial Validation Loss: 0.1343, Validation Loss: 0.0492,V Acc: 0.7909, Top 70th Acc: 0.8701, Bottom 30th Acc: 0.6061
Fold [3/5] Epoch [20/100] Initial Loss: 0.1415, Training Loss: 0.0237, Initial Validation Loss: 0.1343, Validation Loss: 0.0422,V Acc: 0.8182, Top 70th Acc: 0.8831, Bottom 30th Acc: 0.6667
Fold [3/5] Epoch [30/100] Initial Loss: 0.1415, Training Loss: 0.0209, Initial Validation Loss: 0.1343, Validation Loss: 0.0390,V Acc: 0.8364, Top 70th Acc: 0.8961, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 38  Rolling back to Epoch (base 0): 33  Top Validation Acc: 0.8831168831168831
Fold [4/5] Epoch [0/100] Initial Loss: 0.1408, Training Loss: 0.1408, Initial Validation Loss: 0.1298, Validation Loss: 0.1298,V Acc: 0.3578, Top 70th Acc: 0.4026, Bottom 30th Acc: 0.2500
Fold [4/5] Epoch [10/100] Initial Loss: 0.1408, Training Loss: 0.0302, Initial Validation Loss: 0.1298, Validation Loss: 0.0518,V Acc: 0.7248, Top 70th Acc: 0.8312, Bottom 30th Acc: 0.4688
Fold [4/5] Epoch [20/100] Initial Loss: 0.1408, Training Loss: 0.0211, Initial Validation Loss: 0.1298, Validation Loss: 0.0479,V Acc: 0.7890, Top 70th Acc: 0.8571, Bottom 30th Acc: 0.6250
Stopping early at Epoch (base 0): 22  Rolling back to Epoch (base 0): 17  Top Validation Acc: 0.8571428571428571
Fold [5/5] Epoch [0/100] Initial Loss: 0.1398, Training Loss: 0.1398, Initial Validation Loss: 0.1334, Validation Loss: 0.1334,V Acc: 0.3056, Top 70th Acc: 0.3816, Bottom 30th Acc: 0.1250
Fold [5/5] Epoch [10/100] Initial Loss: 0.1398, Training Loss: 0.0372, Initial Validation Loss: 0.1334, Validation Loss: 0.0352,V Acc: 0.8519, Top 70th Acc: 0.9211, Bottom 30th Acc: 0.6875
Fold [5/5] Epoch [20/100] Initial Loss: 0.1398, Training Loss: 0.0241, Initial Validation Loss: 0.1334, Validation Loss: 0.0292,V Acc: 0.8426, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.5625
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.9605263157894737
Running train_nn.py with seed 53
CUDA:False
Training samples count:  550
Training on 20 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1415, Training Loss: 0.1415, Initial Validation Loss: 0.1377, Validation Loss: 0.1377,V Acc: 0.2500, Top 70th Acc: 0.3165, Bottom 30th Acc: 0.0909
Fold [1/5] Epoch [10/100] Initial Loss: 0.1415, Training Loss: 0.0351, Initial Validation Loss: 0.1377, Validation Loss: 0.0468,V Acc: 0.8125, Top 70th Acc: 0.8481, Bottom 30th Acc: 0.7273
Fold [1/5] Epoch [20/100] Initial Loss: 0.1415, Training Loss: 0.0229, Initial Validation Loss: 0.1377, Validation Loss: 0.0393,V Acc: 0.8393, Top 70th Acc: 0.8861, Bottom 30th Acc: 0.7273
Stopping early at Epoch (base 0): 22  Rolling back to Epoch (base 0): 17  Top Validation Acc: 0.7631578947368421
Running train_nn.py with seed 51
CUDA:False
Training samples count:  550
Training on 2 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1336, Training Loss: 0.1336, Initial Validation Loss: 0.1276, Validation Loss: 0.1276,V Acc: 0.2857, Top 70th Acc: 0.3671, Bottom 30th Acc: 0.0909
Fold [1/5] Epoch [10/100] Initial Loss: 0.1336, Training Loss: 0.0806, Initial Validation Loss: 0.1276, Validation Loss: 0.0806,V Acc: 0.5982, Top 70th Acc: 0.7595, Bottom 30th Acc: 0.2121
Fold [1/5] Epoch [20/100] Initial Loss: 0.1336, Training Loss: 0.0790, Initial Validation Loss: 0.1276, Validation Loss: 0.0784,V Acc: 0.5982, Top 70th Acc: 0.7342, Bottom 30th Acc: 0.2727
Fold [1/5] Epoch [30/100] Initial Loss: 0.1336, Training Loss: 0.0783, Initial Validation Loss: 0.1276, Validation Loss: 0.0777,V Acc: 0.6161, Top 70th Acc: 0.7468, Bottom 30th Acc: 0.3030
Stopping early at Epoch (base 0): 35  Rolling back to Epoch (base 0): 30  Top Validation Acc: 0.7341772151898734
Fold [2/5] Epoch [0/100] Initial Loss: 0.1323, Training Loss: 0.1323, Initial Validation Loss: 0.1198, Validation Loss: 0.1198,V Acc: 0.3874, Top 70th Acc: 0.4487, Bottom 30th Acc: 0.2424
Fold [2/5] Epoch [10/100] Initial Loss: 0.1323, Training Loss: 0.0784, Initial Validation Loss: 0.1198, Validation Loss: 0.0847,V Acc: 0.6216, Top 70th Acc: 0.7179, Bottom 30th Acc: 0.3939
Stopping early at Epoch (base 0): 15  Rolling back to Epoch (base 0): 10  Top Validation Acc: 0.7051282051282052
Fold [3/5] Epoch [0/100] Initial Loss: 0.1363, Training Loss: 0.1363, Initial Validation Loss: 0.1183, Validation Loss: 0.1183,V Acc: 0.4909, Top 70th Acc: 0.6104, Bottom 30th Acc: 0.2121
Fold [3/5] Epoch [10/100] Initial Loss: 0.1363, Training Loss: 0.0817, Initial Validation Loss: 0.1183, Validation Loss: 0.0748,V Acc: 0.6455, Top 70th Acc: 0.7792, Bottom 30th Acc: 0.3333
Fold [3/5] Epoch [20/100] Initial Loss: 0.1363, Training Loss: 0.0798, Initial Validation Loss: 0.1183, Validation Loss: 0.0739,V Acc: 0.6636, Top 70th Acc: 0.7792, Bottom 30th Acc: 0.3939
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.7662337662337663
51 2 [array([0.11438161, 0.3673585 , 0.15647767, 0.20654394, 0.15523826],
      dtype=float32)]
Fold [4/5] Epoch [0/100] Initial Loss: 0.1316, Training Loss: 0.1316, Initial Validation Loss: 0.1222, Validation Loss: 0.1222,V Acc: 0.4128, Top 70th Acc: 0.4935, Bottom 30th Acc: 0.2188
Fold [4/5] Epoch [10/100] Initial Loss: 0.1316, Training Loss: 0.0805, Initial Validation Loss: 0.1222, Validation Loss: 0.0841,V Acc: 0.5963, Top 70th Acc: 0.6883, Bottom 30th Acc: 0.3750
Fold [4/5] Epoch [20/100] Initial Loss: 0.1316, Training Loss: 0.0781, Initial Validation Loss: 0.1222, Validation Loss: 0.0834,V Acc: 0.6239, Top 70th Acc: 0.7013, Bottom 30th Acc: 0.4375
Stopping early at Epoch (base 0): 21  Rolling back to Epoch (base 0): 16  Top Validation Acc: 0.6883116883116883
Fold [5/5] Epoch [0/100] Initial Loss: 0.1286, Training Loss: 0.1286, Initial Validation Loss: 0.1183, Validation Loss: 0.1183,V Acc: 0.4259, Top 70th Acc: 0.5132, Bottom 30th Acc: 0.2188
Fold [5/5] Epoch [10/100] Initial Loss: 0.1286, Training Loss: 0.0813, Initial Validation Loss: 0.1183, Validation Loss: 0.0751,V Acc: 0.6481, Top 70th Acc: 0.7632, Bottom 30th Acc: 0.3750
Fold [5/5] Epoch [20/100] Initial Loss: 0.1286, Training Loss: 0.0794, Initial Validation Loss: 0.1183, Validation Loss: 0.0728,V Acc: 0.6574, Top 70th Acc: 0.7632, Bottom 30th Acc: 0.4062
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.7763157894736842
Running train_nn.py with seed 52
CUDA:False
Training samples count:  550
Training on 2 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1389, Training Loss: 0.1389, Initial Validation Loss: 0.1286, Validation Loss: 0.1286,V Acc: 0.2946, Top 70th Acc: 0.3797, Bottom 30th Acc: 0.0909
Fold [1/5] Epoch [10/100] Initial Loss: 0.1389, Training Loss: 0.0820, Initial Validation Loss: 0.1286, Validation Loss: 0.0772,V Acc: 0.6339, Top 70th Acc: 0.7848, Bottom 30th Acc: 0.2727
Fold [1/5] Epoch [20/100] Initial Loss: 0.1389, Training Loss: 0.0805, Initial Validation Loss: 0.1286, Validation Loss: 0.0740,V Acc: 0.6339, Top 70th Acc: 0.7722, Bottom 30th Acc: 0.3030
Fold [1/5] Epoch [30/100] Initial Loss: 0.1389, Training Loss: 0.0799, Initial Validation Loss: 0.1286, Validation Loss: 0.0734,V Acc: 0.6339, Top 70th Acc: 0.7722, Bottom 30th Acc: 0.3030
Stopping early at Epoch (base 0): 35  Rolling back to Epoch (base 0): 30  Top Validation Acc: 0.7721518987341772
52 0 [array([0.10937791, 0.38981524, 0.13034792, 0.20693581, 0.1635231 ],
      dtype=float32)]
Fold [2/5] Epoch [0/100] Initial Loss: 0.1381, Training Loss: 0.1381, Initial Validation Loss: 0.1298, Validation Loss: 0.1298,V Acc: 0.3784, Top 70th Acc: 0.3974, Bottom 30th Acc: 0.3333
Fold [2/5] Epoch [10/100] Initial Loss: 0.1381, Training Loss: 0.0818, Initial Validation Loss: 0.1298, Validation Loss: 0.0793,V Acc: 0.6306, Top 70th Acc: 0.6795, Bottom 30th Acc: 0.5152
Fold [2/5] Epoch [20/100] Initial Loss: 0.1381, Training Loss: 0.0793, Initial Validation Loss: 0.1298, Validation Loss: 0.0777,V Acc: 0.6396, Top 70th Acc: 0.6923, Bottom 30th Acc: 0.5152
Fold [2/5] Epoch [30/100] Initial Loss: 0.1381, Training Loss: 0.0785, Initial Validation Loss: 0.1298, Validation Loss: 0.0776,V Acc: 0.6486, Top 70th Acc: 0.7051, Bottom 30th Acc: 0.5152
Stopping early at Epoch (base 0): 32  Rolling back to Epoch (base 0): 27  Top Validation Acc: 0.6923076923076923
Fold [3/5] Epoch [0/100] Initial Loss: 0.1459, Training Loss: 0.1459, Initial Validation Loss: 0.1336, Validation Loss: 0.1336,V Acc: 0.2636, Top 70th Acc: 0.3247, Bottom 30th Acc: 0.1212
Fold [3/5] Epoch [10/100] Initial Loss: 0.1459, Training Loss: 0.0809, Initial Validation Loss: 0.1336, Validation Loss: 0.0813,V Acc: 0.6273, Top 70th Acc: 0.7922, Bottom 30th Acc: 0.2424
Fold [3/5] Epoch [20/100] Initial Loss: 0.1459, Training Loss: 0.0790, Initial Validation Loss: 0.1336, Validation Loss: 0.0784,V Acc: 0.6273, Top 70th Acc: 0.7662, Bottom 30th Acc: 0.3030
Fold [3/5] Epoch [30/100] Initial Loss: 0.1459, Training Loss: 0.0785, Initial Validation Loss: 0.1336, Validation Loss: 0.0781,V Acc: 0.6364, Top 70th Acc: 0.7662, Bottom 30th Acc: 0.3333
Fold [3/5] Epoch [40/100] Initial Loss: 0.1459, Training Loss: 0.0781, Initial Validation Loss: 0.1336, Validation Loss: 0.0777,V Acc: 0.6364, Top 70th Acc: 0.7662, Bottom 30th Acc: 0.3333
Fold [3/5] Epoch [50/100] Initial Loss: 0.1459, Training Loss: 0.0777, Initial Validation Loss: 0.1336, Validation Loss: 0.0780,V Acc: 0.6273, Top 70th Acc: 0.7662, Bottom 30th Acc: 0.3030
Stopping early at Epoch (base 0): 50  Rolling back to Epoch (base 0): 45  Top Validation Acc: 0.7662337662337663
Fold [4/5] Epoch [0/100] Initial Loss: 0.1368, Training Loss: 0.1368, Initial Validation Loss: 0.1275, Validation Loss: 0.1275,V Acc: 0.2569, Top 70th Acc: 0.3506, Bottom 30th Acc: 0.0312
Fold [4/5] Epoch [10/100] Initial Loss: 0.1368, Training Loss: 0.0805, Initial Validation Loss: 0.1275, Validation Loss: 0.0811,V Acc: 0.6330, Top 70th Acc: 0.6753, Bottom 30th Acc: 0.5312
Stopping early at Epoch (base 0): 18  Rolling back to Epoch (base 0): 13  Top Validation Acc: 0.6753246753246753
Fold [5/5] Epoch [0/100] Initial Loss: 0.1363, Training Loss: 0.1363, Initial Validation Loss: 0.1262, Validation Loss: 0.1262,V Acc: 0.4722, Top 70th Acc: 0.5132, Bottom 30th Acc: 0.3750
Fold [5/5] Epoch [10/100] Initial Loss: 0.1363, Training Loss: 0.0802, Initial Validation Loss: 0.1262, Validation Loss: 0.0809,V Acc: 0.6204, Top 70th Acc: 0.7632, Bottom 30th Acc: 0.2812
Fold [5/5] Epoch [20/100] Initial Loss: 0.1363, Training Loss: 0.0782, Initial Validation Loss: 0.1262, Validation Loss: 0.0805,V Acc: 0.6296, Top 70th Acc: 0.7632, Bottom 30th Acc: 0.3125
Fold [5/5] Epoch [30/100] Initial Loss: 0.1363, Training Loss: 0.0778, Initial Validation Loss: 0.1262, Validation Loss: 0.0791,V Acc: 0.6296, Top 70th Acc: 0.7895, Bottom 30th Acc: 0.2500
Stopping early at Epoch (base 0): 35  Rolling back to Epoch (base 0): 30 
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.9358974358974359
Fold [3/5] Epoch [0/100] Initial Loss: 0.1392, Training Loss: 0.1392, Initial Validation Loss: 0.1304, Validation Loss: 0.1304,V Acc: 0.3000, Top 70th Acc: 0.3766, Bottom 30th Acc: 0.1212
Fold [3/5] Epoch [10/100] Initial Loss: 0.1392, Training Loss: 0.0332, Initial Validation Loss: 0.1304, Validation Loss: 0.0451,V Acc: 0.7818, Top 70th Acc: 0.8961, Bottom 30th Acc: 0.5152
Fold [3/5] Epoch [20/100] Initial Loss: 0.1392, Training Loss: 0.0187, Initial Validation Loss: 0.1304, Validation Loss: 0.0372,V Acc: 0.8182, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.9090909090909091
51 2 [array([0.59739226, 0.097169  , 0.05260521, 0.1132713 , 0.1395623 ],
      dtype=float32)]
Fold [4/5] Epoch [0/100] Initial Loss: 0.1384, Training Loss: 0.1384, Initial Validation Loss: 0.1334, Validation Loss: 0.1334,V Acc: 0.3394, Top 70th Acc: 0.3636, Bottom 30th Acc: 0.2812
Fold [4/5] Epoch [10/100] Initial Loss: 0.1384, Training Loss: 0.0273, Initial Validation Loss: 0.1334, Validation Loss: 0.0401,V Acc: 0.7982, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.5312
Fold [4/5] Epoch [20/100] Initial Loss: 0.1384, Training Loss: 0.0178, Initial Validation Loss: 0.1334, Validation Loss: 0.0354,V Acc: 0.8165, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.5625
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.922077922077922
Fold [5/5] Epoch [0/100] Initial Loss: 0.1395, Training Loss: 0.1395, Initial Validation Loss: 0.1364, Validation Loss: 0.1364,V Acc: 0.2500, Top 70th Acc: 0.3421, Bottom 30th Acc: 0.0312
Fold [5/5] Epoch [10/100] Initial Loss: 0.1395, Training Loss: 0.0440, Initial Validation Loss: 0.1364, Validation Loss: 0.0387,V Acc: 0.8148, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.5000
Fold [5/5] Epoch [20/100] Initial Loss: 0.1395, Training Loss: 0.0220, Initial Validation Loss: 0.1364, Validation Loss: 0.0258,V Acc: 0.8611, Top 70th Acc: 1.0000, Bottom 30th Acc: 0.5312
Fold [5/5] Epoch [30/100] Initial Loss: 0.1395, Training Loss: 0.0177, Initial Validation Loss: 0.1364, Validation Loss: 0.0239,V Acc: 0.8796, Top 70th Acc: 0.9737, Bottom 30th Acc: 0.6562
Stopping early at Epoch (base 0): 33  Rolling back to Epoch (base 0): 28  Top Validation Acc: 0.9868421052631579
Running train_nn.py with seed 52
CUDA:False
Training samples count:  550
Training on 30 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1379, Training Loss: 0.1379, Initial Validation Loss: 0.1334, Validation Loss: 0.1334,V Acc: 0.2500, Top 70th Acc: 0.3544, Bottom 30th Acc: 0.0000
Fold [1/5] Epoch [10/100] Initial Loss: 0.1379, Training Loss: 0.0420, Initial Validation Loss: 0.1334, Validation Loss: 0.0432,V Acc: 0.8125, Top 70th Acc: 0.9114, Bottom 30th Acc: 0.5758
Fold [1/5] Epoch [20/100] Initial Loss: 0.1379, Training Loss: 0.0200, Initial Validation Loss: 0.1334, Validation Loss: 0.0281,V Acc: 0.8750, Top 70th Acc: 0.9367, Bottom 30th Acc: 0.7273
Fold [1/5] Epoch [30/100] Initial Loss: 0.1379, Training Loss: 0.0166, Initial Validation Loss: 0.1334, Validation Loss: 0.0261,V Acc: 0.8571, Top 70th Acc: 0.9494, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 32  Rolling back to Epoch (base 0): 27  Top Validation Acc: 0.9367088607594937
52 0 [array([0.6624803 , 0.0968842 , 0.04638038, 0.08864263, 0.10561254],
      dtype=float32)]
Fold [2/5] Epoch [0/100] Initial Loss: 0.1393, Training Loss: 0.1393, Initial Validation Loss: 0.1326, Validation Loss: 0.1326,V Acc: 0.2883, Top 70th Acc: 0.3462, Bottom 30th Acc: 0.1515
Fold [2/5] Epoch [10/100] Initial Loss: 0.1393, Training Loss: 0.0400, Initial Validation Loss: 0.1326, Validation Loss: 0.0428,V Acc: 0.7387, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.3333
Fold [2/5] Epoch [20/100] Initial Loss: 0.1393, Training Loss: 0.0192, Initial Validation Loss: 0.1326, Validation Loss: 0.0359,V Acc: 0.7928, Top 70th Acc: 0.8974, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.8846153846153846
Fold [3/5] Epoch [0/100] Initial Loss: 0.1404, Training Loss: 0.1404, Initial Validation Loss: 0.1352, Validation Loss: 0.1352,V Acc: 0.2636, Top 70th Acc: 0.2857, Bottom 30th Acc: 0.2121
Fold [3/5] Epoch [10/100] Initial Loss: 0.1404, Training Loss: 0.0367, Initial Validation Loss: 0.1352, Validation Loss: 0.0487,V Acc: 0.7818, Top 70th Acc: 0.8571, Bottom 30th Acc: 0.6061
Fold [3/5] Epoch [20/100] Initial Loss: 0.1404, Training Loss: 0.0198, Initial Validation Loss: 0.1352, Validation Loss: 0.0362,V Acc: 0.8364, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 28  Rolling back to Epoch (base 0): 23  Top Validation Acc: 0.935064935064935
Fold [4/5] Epoch [0/100] Initial Loss: 0.1375, Training Loss: 0.1375, Initial Validation Loss: 0.1311, Validation Loss: 0.1311,V Acc: 0.3578, Top 70th Acc: 0.4286, Bottom 30th Acc: 0.1875
Fold [4/5] Epoch [10/100] Initial Loss: 0.1375, Training Loss: 0.0220, Initial Validation Loss: 0.1311, Validation Loss: 0.0439,V Acc: 0.7890, Top 70th Acc: 0.8701, Bottom 30th Acc: 0.5938
Fold [4/5] Epoch [20/100] Initial Loss: 0.1375, Training Loss: 0.0152, Initial Validation Loss: 0.1311, Validation Loss: 0.0388,V Acc: 0.7706, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.4375
Stopping early at Epoch (base 0): 29  Rolling back to Epoch (base 0): 24  Top Validation Acc: 0.8961038961038961
Fold [5/5] Epoch [0/100] Initial Loss: 0.1373, Training Loss: 0.1373, Initial Validation Loss: 0.1305, Validation Loss: 0.1305,V Acc: 0.3889, Top 70th Acc: 0.3947, Bottom 30th Acc: 0.3750
Fold [5/5] Epoch [10/100] Initial Loss: 0.1373, Training Loss: 0.0378, Initial Validation Loss: 0.1305, Validation Loss: 0.0360,V Acc: 0.8426, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.6250
Fold [5/5] Epoch [20/100] Initial Loss: 0.1373, Training Loss: 0.0226, Initial Validation Loss: 0.1305, Validation Loss: 0.0276,V Acc: 0.8796, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.6875
Fold [5/5] Epoch [30/100] Initial Loss: 0.1373, Training Loss: 0.0175, Initial Validation Loss: 0.1305, Validation Loss: 0.0269,V Acc: 0.8704, Top 70th Acc: 0.9737, Bottom 30th Acc: 0.6250
Stopping early at Epoch (base 0): 38  Rolling back to Epoch (base 0): 33  Top Validation Acc: 0.9736842105263158
Running train_nn.py with seed 53
CUDA:False
Training samples count:  550
Training on 30 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1398, Training Loss: 0.1398, Initial Validation Loss: 0.1354, Validation Loss: 0.1354,V Acc: 0.3571, Top 70th Acc: 0.3924, Bottom 30th Acc: 0.2727
Fold [1/5] Epoch [10/100] Initial Loss: 0.1398, Training Loss: 0.0404, Initial Validation Loss: 0.1354, Validation Loss: 0.0501,V Acc: 0.7946, Top 70th Acc: 0.8354, Bottom 30th Acc: 0.6970
Fold [1/5] Epoch [20/100] Initial Loss: 0.1398, Training Loss: 0.0185, Initial Validation Loss: 0.1354, Validation Loss: 0.0365,V Acc: 0.8214, Top 70th Acc: 0.9241, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.9240506329113924
53 0 [array([0.6024588 , 0.11968143, 0.05256841, 0.09755722, 0.1277342 ],
      dtype=float32)]
Fold [2/5] Epoch [0/100] Initial Loss: 0.1380, Training Loss: 0.1380, Initial Validation Loss: 0.1293, Validation Loss: 0.1293,V Acc: 0.3784, Top 70th Acc: 0.5000, Bottom 30th Acc: 0.0909
Fold [2/5] Epoch [10/100] Initial Loss: 0.1380, Training Loss: 0.0335, Initial Validation Loss: 0.1293, Validation Loss: 0.0398,V Acc: 0.8198, Top 70th Acc: 0.8718, Bottom 30th Acc: 0.6970
Fold [2/5] Epoch [20/100] Initial Loss: 0.1380, Training Loss: 0.0163, Initial Validation Loss: 0.1293, Validation Loss: 0.0337,V Acc: 0.7838, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.4242
Stopping early at Epoch (base 0): 21  Rolling back to Epoch (base 0): 16  Top Validation Acc: 0.9358974358974359
Fold [3/5] Epoch [0/100] Initial Loss: 0.1396, Training Loss: 0.1396, Initial Validation Loss: 0.1355, Validation Loss: 0.1355,V Acc: 0.3364, Top 70th Acc: 0.3506, Bottom 30th Acc: 0.3030
Fold [3/5] Epoch [10/100] Initial Loss: 0.1396, Training Loss: 0.0381, Initial Validation Loss: 0.1355, Validation Loss: 0.0364,V Acc: 0.8455, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.5455
Fold [4/5] Epoch [20/100] Initial Loss: 0.1328, Training Loss: 0.0157, Initial Validation Loss: 0.1258, Validation Loss: 0.0224,V Acc: 0.8532, Top 70th Acc: 0.9870, Bottom 30th Acc: 0.5312
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.974025974025974
Fold [5/5] Epoch [0/100] Initial Loss: 0.1396, Training Loss: 0.1396, Initial Validation Loss: 0.1291, Validation Loss: 0.1291,V Acc: 0.4444, Top 70th Acc: 0.5395, Bottom 30th Acc: 0.2188
Fold [5/5] Epoch [10/100] Initial Loss: 0.1396, Training Loss: 0.0290, Initial Validation Loss: 0.1291, Validation Loss: 0.0321,V Acc: 0.8611, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.6562
Fold [5/5] Epoch [20/100] Initial Loss: 0.1396, Training Loss: 0.0184, Initial Validation Loss: 0.1291, Validation Loss: 0.0242,V Acc: 0.9074, Top 70th Acc: 0.9737, Bottom 30th Acc: 0.7500
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.9736842105263158
72 4 [array([0.78029096, 0.01361384, 0.03661975, 0.1023205 , 0.06715497],
      dtype=float32)]
Running train_nn.py with seed 73
CUDA:False
Training samples count:  550
Training on 21 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1364, Training Loss: 0.1364, Initial Validation Loss: 0.1282, Validation Loss: 0.1282,V Acc: 0.4018, Top 70th Acc: 0.4430, Bottom 30th Acc: 0.3030
Fold [1/5] Epoch [10/100] Initial Loss: 0.1364, Training Loss: 0.0258, Initial Validation Loss: 0.1282, Validation Loss: 0.0370,V Acc: 0.8482, Top 70th Acc: 0.8987, Bottom 30th Acc: 0.7273
Fold [1/5] Epoch [20/100] Initial Loss: 0.1364, Training Loss: 0.0163, Initial Validation Loss: 0.1282, Validation Loss: 0.0318,V Acc: 0.8304, Top 70th Acc: 0.9494, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 22  Rolling back to Epoch (base 0): 17  Top Validation Acc: 0.9113924050632911
Fold [2/5] Epoch [0/100] Initial Loss: 0.1366, Training Loss: 0.1366, Initial Validation Loss: 0.1298, Validation Loss: 0.1298,V Acc: 0.3243, Top 70th Acc: 0.3590, Bottom 30th Acc: 0.2424
Fold [2/5] Epoch [10/100] Initial Loss: 0.1366, Training Loss: 0.0203, Initial Validation Loss: 0.1298, Validation Loss: 0.0400,V Acc: 0.8018, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.4848
Fold [2/5] Epoch [20/100] Initial Loss: 0.1366, Training Loss: 0.0148, Initial Validation Loss: 0.1298, Validation Loss: 0.0274,V Acc: 0.8649, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 22  Rolling back to Epoch (base 0): 17  Top Validation Acc: 0.9615384615384616
73 1 [array([0.8553656 , 0.01609097, 0.02886009, 0.06425306, 0.03543025],
      dtype=float32)]
Fold [3/5] Epoch [0/100] Initial Loss: 0.1315, Training Loss: 0.1315, Initial Validation Loss: 0.1137, Validation Loss: 0.1137,V Acc: 0.5909, Top 70th Acc: 0.6623, Bottom 30th Acc: 0.4242
Fold [3/5] Epoch [10/100] Initial Loss: 0.1315, Training Loss: 0.0212, Initial Validation Loss: 0.1137, Validation Loss: 0.0225,V Acc: 0.9091, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.7576
Stopping early at Epoch (base 0): 16  Rolling back to Epoch (base 0): 11  Top Validation Acc: 0.974025974025974
Fold [4/5] Epoch [0/100] Initial Loss: 0.1301, Training Loss: 0.1301, Initial Validation Loss: 0.1155, Validation Loss: 0.1155,V Acc: 0.4862, Top 70th Acc: 0.5714, Bottom 30th Acc: 0.2812
Fold [4/5] Epoch [10/100] Initial Loss: 0.1301, Training Loss: 0.0213, Initial Validation Loss: 0.1155, Validation Loss: 0.0392,V Acc: 0.7982, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.5000
Fold [4/5] Epoch [20/100] Initial Loss: 0.1301, Training Loss: 0.0156, Initial Validation Loss: 0.1155, Validation Loss: 0.0359,V Acc: 0.7982, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.4375
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.922077922077922
Fold [5/5] Epoch [0/100] Initial Loss: 0.1249, Training Loss: 0.1249, Initial Validation Loss: 0.1029, Validation Loss: 0.1029,V Acc: 0.5556, Top 70th Acc: 0.6711, Bottom 30th Acc: 0.2812
Fold [5/5] Epoch [10/100] Initial Loss: 0.1249, Training Loss: 0.0205, Initial Validation Loss: 0.1029, Validation Loss: 0.0182,V Acc: 0.9259, Top 70th Acc: 1.0000, Bottom 30th Acc: 0.7500
Stopping early at Epoch (base 0): 13  Rolling back to Epoch (base 0): 8  Top Validation Acc: 1.0
Running train_nn.py with seed 74
CUDA:False
Training samples count:  550
Training on 21 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1338, Training Loss: 0.1338, Initial Validation Loss: 0.1179, Validation Loss: 0.1179,V Acc: 0.5179, Top 70th Acc: 0.6203, Bottom 30th Acc: 0.2727
Fold [1/5] Epoch [10/100] Initial Loss: 0.1338, Training Loss: 0.0172, Initial Validation Loss: 0.1179, Validation Loss: 0.0317,V Acc: 0.8393, Top 70th Acc: 0.9367, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 14  Rolling back to Epoch (base 0): 9  Top Validation Acc: 0.9367088607594937
Fold [2/5] Epoch [0/100] Initial Loss: 0.1343, Training Loss: 0.1343, Initial Validation Loss: 0.1248, Validation Loss: 0.1248,V Acc: 0.3423, Top 70th Acc: 0.3974, Bottom 30th Acc: 0.2121
Fold [2/5] Epoch [10/100] Initial Loss: 0.1343, Training Loss: 0.0254, Initial Validation Loss: 0.1248, Validation Loss: 0.0263,V Acc: 0.8739, Top 70th Acc: 0.9872, Bottom 30th Acc: 0.6061
Fold [2/5] Epoch [20/100] Initial Loss: 0.1343, Training Loss: 0.0153, Initial Validation Loss: 0.1248, Validation Loss: 0.0238,V Acc: 0.8559, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.5758
Fold [2/5] Epoch [30/100] Initial Loss: 0.1343, Training Loss: 0.0140, Initial Validation Loss: 0.1248, Validation Loss: 0.0216,V Acc: 0.9009, Top 70th Acc: 0.9872, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 35  Rolling back to Epoch (base 0): 30  Top Validation Acc: 0.9871794871794872
Fold [3/5] Epoch [0/100] Initial Loss: 0.1310, Training Loss: 0.1310, Initial Validation Loss: 0.1139, Validation Loss: 0.1139,V Acc: 0.4909, Top 70th Acc: 0.6104, Bottom 30th Acc: 0.2121
Fold [3/5] Epoch [10/100] Initial Loss: 0.1310, Training Loss: 0.0201, Initial Validation Loss: 0.1139, Validation Loss: 0.0276,V Acc: 0.8455, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 19  Rolling back to Epoch (base 0): 14  Top Validation Acc: 0.922077922077922
Fold [4/5] Epoch [0/100] Initial Loss: 0.1347, Training Loss: 0.1347, Initial Validation Loss: 0.1219, Validation Loss: 0.1219,V Acc: 0.4679, Top 70th Acc: 0.5325, Bottom 30th Acc: 0.3125
Fold [4/5] Epoch [10/100] Initial Loss: 0.1347, Training Loss: 0.0201, Initial Validation Loss: 0.1219, Validation Loss: 0.0184,V Acc: 0.9174, Top 70th Acc: 0.9870, Bottom 30th Acc: 0.7500
Fold [4/5] Epoch [20/100] Initial Loss: 0.1347, Training Loss: 0.0156, Initial Validation Loss: 0.1219, Validation Loss: 0.0177,V Acc: 0.9266, Top 70th Acc: 0.9870, Bottom 30th Acc: 0.7812
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.987012987012987
74 3 [array([0.763824  , 0.02688076, 0.03901374, 0.10693538, 0.06334621],
      dtype=float32)]
Fold [5/5] Epoch [0/100] Initial Loss: 0.1259, Training Loss: 0.1259, Initial Validation Loss: 0.1044, Validation Loss: 0.1044,V Acc: 0.5370, Top 70th Acc: 0.6842, Bottom 30th Acc: 0.1875
Fold [5/5] Epoch [10/100] Initial Loss: 0.1259, Training Loss: 0.0225, Initial Validation Loss: 0.1044, Validation Loss: 0.0252,V Acc: 0.9167, Top 70th Acc: 0.9868, Bottom 30th Acc: 0.7500
Fold [5/5] Epoch [20/100] Initial Loss: 0.1259, Training Loss: 0.0187, Initial Validation Loss: 0.1044, Validation Loss: 0.0239,V Acc: 0.9074, Top 70th Acc: 0.9868, Bottom 30th Acc: 0.7188
Stopping early at Epoch (base 0): 27  Rolling back to Epoch (base 0): 22  Top Validation Acc: 1.0
Running train_nn.py with seed 75
CUDA:False
Training samples count:  550
Training on 21 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1275, Training Loss: 0.1275, Initial Validation Loss: 0.1181, Validation Loss: 0.1181,V Acc: 0.4375, Top 70th Acc: 0.5316, Bottom 30th Acc: 0.2121
Fold [1/5] Epoch [10/100] Initial Loss: 0.1275, Training Loss: 0.0216, Initial Validation Loss: 0.1181, Validation Loss: 0.0254,V Acc: 0.8929, Top 70th Acc: 0.9873, Bottom 30th Acc: 0.6667
Fold [1/5] Epoch [20/100] Initial Loss: 0.1275, Training Loss: 0.0158, Initial Validation Loss: 0.1181, Validation Loss: 0.0243,V Acc: 0.9018, Top 70th Acc: 0.9620, Bottom 30th Acc: 0.7576
Fold [2/5] Epoch [20/100] Initial Loss: 0.1389, Training Loss: 0.0144, Initial Validation Loss: 0.1334, Validation Loss: 0.0268,V Acc: 0.8559, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.9230769230769231
Fold [3/5] Epoch [0/100] Initial Loss: 0.1385, Training Loss: 0.1385, Initial Validation Loss: 0.1342, Validation Loss: 0.1342,V Acc: 0.2545, Top 70th Acc: 0.3377, Bottom 30th Acc: 0.0606
Fold [3/5] Epoch [10/100] Initial Loss: 0.1385, Training Loss: 0.0294, Initial Validation Loss: 0.1342, Validation Loss: 0.0403,V Acc: 0.8182, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.5758
Fold [3/5] Epoch [20/100] Initial Loss: 0.1385, Training Loss: 0.0125, Initial Validation Loss: 0.1342, Validation Loss: 0.0333,V Acc: 0.8182, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.5152
Fold [3/5] Epoch [30/100] Initial Loss: 0.1385, Training Loss: 0.0099, Initial Validation Loss: 0.1342, Validation Loss: 0.0326,V Acc: 0.8182, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 39  Rolling back to Epoch (base 0): 34  Top Validation Acc: 0.948051948051948
Fold [4/5] Epoch [0/100] Initial Loss: 0.1423, Training Loss: 0.1423, Initial Validation Loss: 0.1304, Validation Loss: 0.1304,V Acc: 0.2936, Top 70th Acc: 0.3117, Bottom 30th Acc: 0.2500
Fold [4/5] Epoch [10/100] Initial Loss: 0.1423, Training Loss: 0.0445, Initial Validation Loss: 0.1304, Validation Loss: 0.0392,V Acc: 0.7890, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.4688
Fold [4/5] Epoch [20/100] Initial Loss: 0.1423, Training Loss: 0.0141, Initial Validation Loss: 0.1304, Validation Loss: 0.0239,V Acc: 0.8349, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.5312
Stopping early at Epoch (base 0): 29  Rolling back to Epoch (base 0): 24  Top Validation Acc: 0.987012987012987
Fold [5/5] Epoch [0/100] Initial Loss: 0.1352, Training Loss: 0.1352, Initial Validation Loss: 0.1307, Validation Loss: 0.1307,V Acc: 0.4444, Top 70th Acc: 0.4474, Bottom 30th Acc: 0.4375
Fold [5/5] Epoch [10/100] Initial Loss: 0.1352, Training Loss: 0.0233, Initial Validation Loss: 0.1307, Validation Loss: 0.0376,V Acc: 0.8519, Top 70th Acc: 0.9079, Bottom 30th Acc: 0.7188
Stopping early at Epoch (base 0): 19  Rolling back to Epoch (base 0): 14  Top Validation Acc: 0.9473684210526315
55 4 [array([0.48195803, 0.1288278 , 0.05193534, 0.0753247 , 0.2619542 ],
      dtype=float32)]
Running train_nn.py with seed 56
CUDA:False
Training samples count:  550
Training on 40 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1421, Training Loss: 0.1421, Initial Validation Loss: 0.1331, Validation Loss: 0.1331,V Acc: 0.2679, Top 70th Acc: 0.3418, Bottom 30th Acc: 0.0909
Fold [1/5] Epoch [10/100] Initial Loss: 0.1421, Training Loss: 0.0358, Initial Validation Loss: 0.1331, Validation Loss: 0.0410,V Acc: 0.8125, Top 70th Acc: 0.8987, Bottom 30th Acc: 0.6061
Fold [1/5] Epoch [20/100] Initial Loss: 0.1421, Training Loss: 0.0177, Initial Validation Loss: 0.1331, Validation Loss: 0.0306,V Acc: 0.8661, Top 70th Acc: 0.9620, Bottom 30th Acc: 0.6364
Fold [1/5] Epoch [30/100] Initial Loss: 0.1421, Training Loss: 0.0127, Initial Validation Loss: 0.1331, Validation Loss: 0.0288,V Acc: 0.8482, Top 70th Acc: 0.9620, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 35  Rolling back to Epoch (base 0): 30  Top Validation Acc: 0.9620253164556962
Fold [2/5] Epoch [0/100] Initial Loss: 0.1377, Training Loss: 0.1377, Initial Validation Loss: 0.1322, Validation Loss: 0.1322,V Acc: 0.3423, Top 70th Acc: 0.4103, Bottom 30th Acc: 0.1818
Fold [2/5] Epoch [10/100] Initial Loss: 0.1377, Training Loss: 0.0370, Initial Validation Loss: 0.1322, Validation Loss: 0.0379,V Acc: 0.8108, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.5152
Stopping early at Epoch (base 0): 19  Rolling back to Epoch (base 0): 14  Top Validation Acc: 0.9102564102564102
Fold [3/5] Epoch [0/100] Initial Loss: 0.1395, Training Loss: 0.1395, Initial Validation Loss: 0.1333, Validation Loss: 0.1333,V Acc: 0.2545, Top 70th Acc: 0.3377, Bottom 30th Acc: 0.0606
Fold [3/5] Epoch [10/100] Initial Loss: 0.1395, Training Loss: 0.0292, Initial Validation Loss: 0.1333, Validation Loss: 0.0352,V Acc: 0.8273, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.5152
Fold [3/5] Epoch [20/100] Initial Loss: 0.1395, Training Loss: 0.0152, Initial Validation Loss: 0.1333, Validation Loss: 0.0315,V Acc: 0.8364, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 21  Rolling back to Epoch (base 0): 16  Top Validation Acc: 0.948051948051948
Fold [4/5] Epoch [0/100] Initial Loss: 0.1398, Training Loss: 0.1398, Initial Validation Loss: 0.1352, Validation Loss: 0.1352,V Acc: 0.2661, Top 70th Acc: 0.3506, Bottom 30th Acc: 0.0625
Fold [4/5] Epoch [10/100] Initial Loss: 0.1398, Training Loss: 0.0251, Initial Validation Loss: 0.1352, Validation Loss: 0.0353,V Acc: 0.8349, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.6250
Fold [4/5] Epoch [20/100] Initial Loss: 0.1398, Training Loss: 0.0141, Initial Validation Loss: 0.1352, Validation Loss: 0.0327,V Acc: 0.8165, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.5312
Stopping early at Epoch (base 0): 22  Rolling back to Epoch (base 0): 17  Top Validation Acc: 0.935064935064935
56 3 [array([0.50535476, 0.06984048, 0.08054692, 0.1161904 , 0.2280674 ],
      dtype=float32)]
Fold [5/5] Epoch [0/100] Initial Loss: 0.1394, Training Loss: 0.1394, Initial Validation Loss: 0.1338, Validation Loss: 0.1338,V Acc: 0.2500, Top 70th Acc: 0.2763, Bottom 30th Acc: 0.1875
Fold [5/5] Epoch [10/100] Initial Loss: 0.1394, Training Loss: 0.0311, Initial Validation Loss: 0.1338, Validation Loss: 0.0445,V Acc: 0.8148, Top 70th Acc: 0.8816, Bottom 30th Acc: 0.6562
Fold [5/5] Epoch [20/100] Initial Loss: 0.1394, Training Loss: 0.0137, Initial Validation Loss: 0.1338, Validation Loss: 0.0357,V Acc: 0.8333, Top 70th Acc: 0.9211, Bottom 30th Acc: 0.6250
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.9078947368421053
Running train_nn.py with seed 57
CUDA:False
Training samples count:  550
Training on 40 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1405, Training Loss: 0.1405, Initial Validation Loss: 0.1360, Validation Loss: 0.1360,V Acc: 0.2679, Top 70th Acc: 0.3165, Bottom 30th Acc: 0.1515
Fold [1/5] Epoch [10/100] Initial Loss: 0.1405, Training Loss: 0.0355, Initial Validation Loss: 0.1360, Validation Loss: 0.0426,V Acc: 0.7857, Top 70th Acc: 0.8987, Bottom 30th Acc: 0.5152
Fold [1/5] Epoch [20/100] Initial Loss: 0.1405, Training Loss: 0.0154, Initial Validation Loss: 0.1360, Validation Loss: 0.0291,V Acc: 0.8571, Top 70th Acc: 0.9494, Bottom 30th Acc: 0.6364
Fold [1/5] Epoch [30/100] Initial Loss: 0.1405, Training Loss: 0.0125, Initial Validation Loss: 0.1360, Validation Loss: 0.0284,V Acc: 0.8571, Top 70th Acc: 0.9494, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 32  Rolling back to Epoch (base 0): 27  Top Validation Acc: 0.9493670886075949
Fold [2/5] Epoch [0/100] Initial Loss: 0.1431, Training Loss: 0.1431, Initial Validation Loss: 0.1352, Validation Loss: 0.1352,V Acc: 0.2703, Top 70th Acc: 0.3333, Bottom 30th Acc: 0.1212
Fold [2/5] Epoch [10/100] Initial Loss: 0.1431, Training Loss: 0.0266, Initial Validation Loss: 0.1352, Validation Loss: 0.0327,V Acc: 0.8468, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.6061
Fold [2/5] Epoch [20/100] Initial Loss: 0.1431, Training Loss: 0.0147, Initial Validation Loss: 0.1352, Validation Loss: 0.0297,V Acc: 0.8378, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 28  Rolling back to Epoch (base 0): 23  Top Validation Acc: 0.9358974358974359
Fold [3/5] Epoch [0/100] Initial Loss: 0.1401, Training Loss: 0.1401, Initial Validation Loss: 0.1283, Validation Loss: 0.1283,V Acc: 0.3455, Top 70th Acc: 0.4416, Bottom 30th Acc: 0.1212
Fold [3/5] Epoch [10/100] Initial Loss: 0.1401, Training Loss: 0.0311, Initial Validation Loss: 0.1283, Validation Loss: 0.0388,V Acc: 0.7909, Top 70th Acc: 0.8961, Bottom 30th Acc: 0.5455
Fold [3/5] Epoch [20/100] Initial Loss: 0.1401, Training Loss: 0.0137, Initial Validation Loss: 0.1283, Validation Loss: 0.0294,V Acc: 0.8455, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.8987341772151899
53 0 [array([0.24114794, 0.08397808, 0.14113243, 0.29518056, 0.23856102],
      dtype=float32)]
Fold [2/5] Epoch [0/100] Initial Loss: 0.1390, Training Loss: 0.1390, Initial Validation Loss: 0.1328, Validation Loss: 0.1328,V Acc: 0.2613, Top 70th Acc: 0.3590, Bottom 30th Acc: 0.0303
Fold [2/5] Epoch [10/100] Initial Loss: 0.1390, Training Loss: 0.0290, Initial Validation Loss: 0.1328, Validation Loss: 0.0359,V Acc: 0.8198, Top 70th Acc: 0.8974, Bottom 30th Acc: 0.6364
Fold [2/5] Epoch [20/100] Initial Loss: 0.1390, Training Loss: 0.0220, Initial Validation Loss: 0.1328, Validation Loss: 0.0356,V Acc: 0.8018, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.5152
Stopping early at Epoch (base 0): 21  Rolling back to Epoch (base 0): 16  Top Validation Acc: 0.9230769230769231
Fold [3/5] Epoch [0/100] Initial Loss: 0.1385, Training Loss: 0.1385, Initial Validation Loss: 0.1357, Validation Loss: 0.1357,V Acc: 0.3000, Top 70th Acc: 0.3247, Bottom 30th Acc: 0.2424
Fold [3/5] Epoch [10/100] Initial Loss: 0.1385, Training Loss: 0.0469, Initial Validation Loss: 0.1357, Validation Loss: 0.0443,V Acc: 0.8182, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.6061
Fold [3/5] Epoch [20/100] Initial Loss: 0.1385, Training Loss: 0.0271, Initial Validation Loss: 0.1357, Validation Loss: 0.0294,V Acc: 0.8636, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6667
Fold [3/5] Epoch [30/100] Initial Loss: 0.1385, Training Loss: 0.0242, Initial Validation Loss: 0.1357, Validation Loss: 0.0277,V Acc: 0.8636, Top 70th Acc: 0.9870, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 33  Rolling back to Epoch (base 0): 28  Top Validation Acc: 0.974025974025974
Fold [4/5] Epoch [0/100] Initial Loss: 0.1390, Training Loss: 0.1390, Initial Validation Loss: 0.1339, Validation Loss: 0.1339,V Acc: 0.3119, Top 70th Acc: 0.3247, Bottom 30th Acc: 0.2812
Fold [4/5] Epoch [10/100] Initial Loss: 0.1390, Training Loss: 0.0453, Initial Validation Loss: 0.1339, Validation Loss: 0.0471,V Acc: 0.7615, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.3750
Fold [4/5] Epoch [20/100] Initial Loss: 0.1390, Training Loss: 0.0282, Initial Validation Loss: 0.1339, Validation Loss: 0.0370,V Acc: 0.8165, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.5625
Fold [4/5] Epoch [30/100] Initial Loss: 0.1390, Training Loss: 0.0219, Initial Validation Loss: 0.1339, Validation Loss: 0.0362,V Acc: 0.7982, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.5000
Stopping early at Epoch (base 0): 36  Rolling back to Epoch (base 0): 31  Top Validation Acc: 0.922077922077922
Fold [5/5] Epoch [0/100] Initial Loss: 0.1412, Training Loss: 0.1412, Initial Validation Loss: 0.1290, Validation Loss: 0.1290,V Acc: 0.2963, Top 70th Acc: 0.3816, Bottom 30th Acc: 0.0938
Fold [5/5] Epoch [10/100] Initial Loss: 0.1412, Training Loss: 0.0427, Initial Validation Loss: 0.1290, Validation Loss: 0.0412,V Acc: 0.7870, Top 70th Acc: 0.9211, Bottom 30th Acc: 0.4688
Fold [5/5] Epoch [20/100] Initial Loss: 0.1412, Training Loss: 0.0312, Initial Validation Loss: 0.1290, Validation Loss: 0.0352,V Acc: 0.8241, Top 70th Acc: 0.9211, Bottom 30th Acc: 0.5938
Fold [5/5] Epoch [30/100] Initial Loss: 0.1412, Training Loss: 0.0245, Initial Validation Loss: 0.1290, Validation Loss: 0.0329,V Acc: 0.8241, Top 70th Acc: 0.9211, Bottom 30th Acc: 0.5938
Stopping early at Epoch (base 0): 34  Rolling back to Epoch (base 0): 29  Top Validation Acc: 0.9210526315789473
Running train_nn.py with seed 54
CUDA:False
Training samples count:  550
Training on 20 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1394, Training Loss: 0.1394, Initial Validation Loss: 0.1296, Validation Loss: 0.1296,V Acc: 0.3929, Top 70th Acc: 0.4430, Bottom 30th Acc: 0.2727
Fold [1/5] Epoch [10/100] Initial Loss: 0.1394, Training Loss: 0.0476, Initial Validation Loss: 0.1296, Validation Loss: 0.0465,V Acc: 0.7500, Top 70th Acc: 0.8987, Bottom 30th Acc: 0.3939
Fold [1/5] Epoch [20/100] Initial Loss: 0.1394, Training Loss: 0.0265, Initial Validation Loss: 0.1296, Validation Loss: 0.0291,V Acc: 0.8839, Top 70th Acc: 0.9367, Bottom 30th Acc: 0.7576
Fold [1/5] Epoch [30/100] Initial Loss: 0.1394, Training Loss: 0.0228, Initial Validation Loss: 0.1296, Validation Loss: 0.0281,V Acc: 0.8571, Top 70th Acc: 0.9367, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 30  Rolling back to Epoch (base 0): 25  Top Validation Acc: 0.9367088607594937
54 0 [array([0.30339858, 0.26828438, 0.08375827, 0.1932605 , 0.15129827],
      dtype=float32)]
Fold [2/5] Epoch [0/100] Initial Loss: 0.1400, Training Loss: 0.1400, Initial Validation Loss: 0.1302, Validation Loss: 0.1302,V Acc: 0.2793, Top 70th Acc: 0.3590, Bottom 30th Acc: 0.0909
Fold [2/5] Epoch [10/100] Initial Loss: 0.1400, Training Loss: 0.0304, Initial Validation Loss: 0.1302, Validation Loss: 0.0346,V Acc: 0.8739, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.7576
Fold [2/5] Epoch [20/100] Initial Loss: 0.1400, Training Loss: 0.0236, Initial Validation Loss: 0.1302, Validation Loss: 0.0314,V Acc: 0.8468, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.6061
Fold [2/5] Epoch [30/100] Initial Loss: 0.1400, Training Loss: 0.0216, Initial Validation Loss: 0.1302, Validation Loss: 0.0308,V Acc: 0.8559, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 32  Rolling back to Epoch (base 0): 27  Top Validation Acc: 0.9358974358974359
Fold [3/5] Epoch [0/100] Initial Loss: 0.1411, Training Loss: 0.1411, Initial Validation Loss: 0.1391, Validation Loss: 0.1391,V Acc: 0.4091, Top 70th Acc: 0.4286, Bottom 30th Acc: 0.3636
Fold [3/5] Epoch [10/100] Initial Loss: 0.1411, Training Loss: 0.0331, Initial Validation Loss: 0.1391, Validation Loss: 0.0302,V Acc: 0.8818, Top 70th Acc: 1.0000, Bottom 30th Acc: 0.6061
Fold [3/5] Epoch [20/100] Initial Loss: 0.1411, Training Loss: 0.0250, Initial Validation Loss: 0.1391, Validation Loss: 0.0233,V Acc: 0.9364, Top 70th Acc: 0.9870, Bottom 30th Acc: 0.8182
Stopping early at Epoch (base 0): 22  Rolling back to Epoch (base 0): 17  Top Validation Acc: 1.0
Fold [4/5] Epoch [0/100] Initial Loss: 0.1394, Training Loss: 0.1394, Initial Validation Loss: 0.1338, Validation Loss: 0.1338,V Acc: 0.3119, Top 70th Acc: 0.3506, Bottom 30th Acc: 0.2188
Fold [4/5] Epoch [10/100] Initial Loss: 0.1394, Training Loss: 0.0370, Initial Validation Loss: 0.1338, Validation Loss: 0.0505,V Acc: 0.7523, Top 70th Acc: 0.8571, Bottom 30th Acc: 0.5000
Fold [4/5] Epoch [20/100] Initial Loss: 0.1394, Training Loss: 0.0219, Initial Validation Loss: 0.1338, Validation Loss: 0.0412,V Acc: 0.8165, Top 70th Acc: 0.8831, Bottom 30th Acc: 0.6562
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.8961038961038961
Fold [5/5] Epoch [0/100] Initial Loss: 0.1407, Training Loss: 0.1407, Initial Validation Loss: 0.1305, Validation Loss: 0.1305,V Acc: 0.3333, Top 70th Acc: 0.3553, Bottom 30th Acc: 0.2812
Fold [5/5] Epoch [10/100] Initial Loss: 0.1407, Training Loss: 0.0352, Initial Validation Loss: 0.1305, Validation Loss: 0.0464,V Acc: 0.7130, Top 70th Acc: 0.8553, Bottom 30th Acc: 0.3750
Fold [5/5] Epoch [20/100] Initial Loss: 0.1407, Training Loss: 0.0222, Initial Validation Loss: 0.1305, Validation Loss: 0.0424,V Acc: 0.7315, Top 70th Acc: 0.8684, Bottom 30th Acc: 0.4062
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.8947368421052632
Running train_nn.py with seed 55
CUDA:False
Training samples count:  550
Training on 20 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1398, Training Loss: 0.1398, Initial Validation Loss: 0.1371, Validation Loss: 0.1371,V Acc: 0.2500, Top 70th Acc: 0.3165, Bottom 30th Acc: 0.0909
Fold [1/5] Epoch [10/100] Initial Loss: 0.1398, Training Loss: 0.0355, Initial Validation Loss: 0.1371, Validation Loss: 0.0339,V Acc: 0.8750, Top 70th Acc: 0.9620, Bottom 30th Acc: 0.6667
Fold [1/5] Epoch [20/100] Initial Loss: 0.1398, Training Loss: 0.0253, Initial Validation Loss: 0.1371, Validation Loss: 0.0261,V Acc: 0.8929, Top 70th Acc: 0.9620, Bottom 30th Acc: 0.7273
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc:
Fold [3/5] Epoch [30/100] Initial Loss: 0.1404, Training Loss: 0.0039, Initial Validation Loss: 0.1332, Validation Loss: 0.0203,V Acc: 0.8909, Top 70th Acc: 1.0000, Bottom 30th Acc: 0.6364
Fold [3/5] Epoch [40/100] Initial Loss: 0.1404, Training Loss: 0.0036, Initial Validation Loss: 0.1332, Validation Loss: 0.0198,V Acc: 0.9091, Top 70th Acc: 1.0000, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 48  Rolling back to Epoch (base 0): 43  Top Validation Acc: 1.0
41 2 [array([0.30289862, 0.07947624, 0.06670287, 0.1836586 , 0.36726364],
      dtype=float32)]
Fold [4/5] Epoch [0/100] Initial Loss: 0.1446, Training Loss: 0.1446, Initial Validation Loss: 0.1313, Validation Loss: 0.1313,V Acc: 0.2477, Top 70th Acc: 0.3117, Bottom 30th Acc: 0.0938
Fold [4/5] Epoch [10/100] Initial Loss: 0.1446, Training Loss: 0.0204, Initial Validation Loss: 0.1313, Validation Loss: 0.0378,V Acc: 0.8349, Top 70th Acc: 0.8961, Bottom 30th Acc: 0.6875
Fold [4/5] Epoch [20/100] Initial Loss: 0.1446, Training Loss: 0.0072, Initial Validation Loss: 0.1313, Validation Loss: 0.0343,V Acc: 0.8624, Top 70th Acc: 0.8961, Bottom 30th Acc: 0.7812
Fold [4/5] Epoch [30/100] Initial Loss: 0.1446, Training Loss: 0.0047, Initial Validation Loss: 0.1313, Validation Loss: 0.0323,V Acc: 0.8624, Top 70th Acc: 0.8961, Bottom 30th Acc: 0.7812
Fold [4/5] Epoch [40/100] Initial Loss: 0.1446, Training Loss: 0.0041, Initial Validation Loss: 0.1313, Validation Loss: 0.0306,V Acc: 0.8440, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.6562
Fold [4/5] Epoch [50/100] Initial Loss: 0.1446, Training Loss: 0.0038, Initial Validation Loss: 0.1313, Validation Loss: 0.0299,V Acc: 0.8440, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.6250
Fold [4/5] Epoch [60/100] Initial Loss: 0.1446, Training Loss: 0.0038, Initial Validation Loss: 0.1313, Validation Loss: 0.0298,V Acc: 0.8624, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.6875
Stopping early at Epoch (base 0): 62  Rolling back to Epoch (base 0): 57  Top Validation Acc: 0.935064935064935
Fold [5/5] Epoch [0/100] Initial Loss: 0.1389, Training Loss: 0.1389, Initial Validation Loss: 0.1375, Validation Loss: 0.1375,V Acc: 0.2870, Top 70th Acc: 0.3553, Bottom 30th Acc: 0.1250
Fold [5/5] Epoch [10/100] Initial Loss: 0.1389, Training Loss: 0.0238, Initial Validation Loss: 0.1375, Validation Loss: 0.0400,V Acc: 0.8241, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.5000
Fold [5/5] Epoch [20/100] Initial Loss: 0.1389, Training Loss: 0.0062, Initial Validation Loss: 0.1375, Validation Loss: 0.0301,V Acc: 0.8611, Top 70th Acc: 0.9737, Bottom 30th Acc: 0.5938
Fold [5/5] Epoch [30/100] Initial Loss: 0.1389, Training Loss: 0.0043, Initial Validation Loss: 0.1375, Validation Loss: 0.0291,V Acc: 0.8704, Top 70th Acc: 0.9737, Bottom 30th Acc: 0.6250
Fold [5/5] Epoch [40/100] Initial Loss: 0.1389, Training Loss: 0.0039, Initial Validation Loss: 0.1375, Validation Loss: 0.0282,V Acc: 0.8796, Top 70th Acc: 0.9868, Bottom 30th Acc: 0.6250
Stopping early at Epoch (base 0): 42  Rolling back to Epoch (base 0): 37  Top Validation Acc: 0.9868421052631579
Running train_nn.py with seed 42
CUDA:False
Training samples count:  550
Training on 162 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1387, Training Loss: 0.1387, Initial Validation Loss: 0.1340, Validation Loss: 0.1340,V Acc: 0.4643, Top 70th Acc: 0.5063, Bottom 30th Acc: 0.3636
Fold [1/5] Epoch [10/100] Initial Loss: 0.1387, Training Loss: 0.0144, Initial Validation Loss: 0.1340, Validation Loss: 0.0309,V Acc: 0.8839, Top 70th Acc: 0.9367, Bottom 30th Acc: 0.7576
Fold [1/5] Epoch [20/100] Initial Loss: 0.1387, Training Loss: 0.0051, Initial Validation Loss: 0.1340, Validation Loss: 0.0272,V Acc: 0.8839, Top 70th Acc: 0.9620, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.9746835443037974
Fold [2/5] Epoch [0/100] Initial Loss: 0.1428, Training Loss: 0.1428, Initial Validation Loss: 0.1379, Validation Loss: 0.1379,V Acc: 0.2523, Top 70th Acc: 0.3333, Bottom 30th Acc: 0.0606
Fold [2/5] Epoch [10/100] Initial Loss: 0.1428, Training Loss: 0.0147, Initial Validation Loss: 0.1379, Validation Loss: 0.0429,V Acc: 0.7297, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.2727
Fold [2/5] Epoch [20/100] Initial Loss: 0.1428, Training Loss: 0.0047, Initial Validation Loss: 0.1379, Validation Loss: 0.0361,V Acc: 0.8108, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.4848
Fold [2/5] Epoch [30/100] Initial Loss: 0.1428, Training Loss: 0.0038, Initial Validation Loss: 0.1379, Validation Loss: 0.0349,V Acc: 0.8288, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.5152
Fold [2/5] Epoch [40/100] Initial Loss: 0.1428, Training Loss: 0.0036, Initial Validation Loss: 0.1379, Validation Loss: 0.0348,V Acc: 0.8468, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 44  Rolling back to Epoch (base 0): 39  Top Validation Acc: 0.9615384615384616
Fold [3/5] Epoch [0/100] Initial Loss: 0.1406, Training Loss: 0.1406, Initial Validation Loss: 0.1363, Validation Loss: 0.1363,V Acc: 0.2545, Top 70th Acc: 0.3506, Bottom 30th Acc: 0.0303
Fold [3/5] Epoch [10/100] Initial Loss: 0.1406, Training Loss: 0.0137, Initial Validation Loss: 0.1363, Validation Loss: 0.0352,V Acc: 0.8273, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.5758
Fold [3/5] Epoch [20/100] Initial Loss: 0.1406, Training Loss: 0.0043, Initial Validation Loss: 0.1363, Validation Loss: 0.0329,V Acc: 0.8273, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.961038961038961
Fold [4/5] Epoch [0/100] Initial Loss: 0.1406, Training Loss: 0.1406, Initial Validation Loss: 0.1309, Validation Loss: 0.1309,V Acc: 0.3486, Top 70th Acc: 0.4286, Bottom 30th Acc: 0.1562
Fold [4/5] Epoch [10/100] Initial Loss: 0.1406, Training Loss: 0.0147, Initial Validation Loss: 0.1309, Validation Loss: 0.0380,V Acc: 0.7706, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.4062
Fold [4/5] Epoch [20/100] Initial Loss: 0.1406, Training Loss: 0.0052, Initial Validation Loss: 0.1309, Validation Loss: 0.0350,V Acc: 0.8073, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.5000
Fold [4/5] Epoch [30/100] Initial Loss: 0.1406, Training Loss: 0.0042, Initial Validation Loss: 0.1309, Validation Loss: 0.0342,V Acc: 0.8073, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.5000
Fold [4/5] Epoch [40/100] Initial Loss: 0.1406, Training Loss: 0.0038, Initial Validation Loss: 0.1309, Validation Loss: 0.0331,V Acc: 0.7982, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.4688
Fold [4/5] Epoch [50/100] Initial Loss: 0.1406, Training Loss: 0.0037, Initial Validation Loss: 0.1309, Validation Loss: 0.0326,V Acc: 0.8165, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.5625
Fold [4/5] Epoch [60/100] Initial Loss: 0.1406, Training Loss: 0.0036, Initial Validation Loss: 0.1309, Validation Loss: 0.0323,V Acc: 0.8073, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.5625
Stopping early at Epoch (base 0): 60  Rolling back to Epoch (base 0): 55  Top Validation Acc: 0.9090909090909091
Fold [5/5] Epoch [0/100] Initial Loss: 0.1392, Training Loss: 0.1392, Initial Validation Loss: 0.1303, Validation Loss: 0.1303,V Acc: 0.3056, Top 70th Acc: 0.3553, Bottom 30th Acc: 0.1875
Fold [5/5] Epoch [10/100] Initial Loss: 0.1392, Training Loss: 0.0151, Initial Validation Loss: 0.1303, Validation Loss: 0.0294,V Acc: 0.9074, Top 70th Acc: 0.9737, Bottom 30th Acc: 0.7500
Fold [5/5] Epoch [20/100] Initial Loss: 0.1392, Training Loss: 0.0054, Initial Validation Loss: 0.1303, Validation Loss: 0.0255,V Acc: 0.8796, Top 70th Acc: 0.9868, Bottom 30th Acc: 0.6250
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.9736842105263158
42 4 [array([0.12183954, 0.06143776, 0.151673  , 0.14961739, 0.5154323 ],
      dtype=float32)]
Running train_nn.py with seed 43
CUDA:False
Training samples count:  550
Training on 162 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1393, Training Loss: 0.1393, Initial Validation Loss: 0.1350, Validation Loss: 0.1350,V Acc: 0.3839, Top 70th Acc: 0.4304, Bottom 30th Acc: 0.2727
Fold [1/5] Epoch [10/100] Initial Loss: 0.1393, Training Loss: 0.0118, Initial Validation Loss: 0.1350, Validation Loss: 0.0342,V Acc: 0.8571, Top 70th Acc: 0.9620, Bottom 30th Acc: 0.6061 Top Validation Acc: 0.7631578947368421
Running train_nn.py with seed 53
CUDA:False
Training samples count:  550
Training on 2 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1320, Training Loss: 0.1320, Initial Validation Loss: 0.1250, Validation Loss: 0.1250,V Acc: 0.4464, Top 70th Acc: 0.4810, Bottom 30th Acc: 0.3636
Fold [1/5] Epoch [10/100] Initial Loss: 0.1320, Training Loss: 0.0799, Initial Validation Loss: 0.1250, Validation Loss: 0.0845,V Acc: 0.6339, Top 70th Acc: 0.7468, Bottom 30th Acc: 0.3636
Fold [1/5] Epoch [20/100] Initial Loss: 0.1320, Training Loss: 0.0782, Initial Validation Loss: 0.1250, Validation Loss: 0.0832,V Acc: 0.6161, Top 70th Acc: 0.7468, Bottom 30th Acc: 0.3030
Fold [1/5] Epoch [30/100] Initial Loss: 0.1320, Training Loss: 0.0774, Initial Validation Loss: 0.1250, Validation Loss: 0.0829,V Acc: 0.6071, Top 70th Acc: 0.7342, Bottom 30th Acc: 0.3030
Stopping early at Epoch (base 0): 36  Rolling back to Epoch (base 0): 31  Top Validation Acc: 0.759493670886076
53 0 [array([0.12594098, 0.34775257, 0.14097866, 0.22018535, 0.16514242],
      dtype=float32)]
Fold [2/5] Epoch [0/100] Initial Loss: 0.1398, Training Loss: 0.1398, Initial Validation Loss: 0.1295, Validation Loss: 0.1295,V Acc: 0.4414, Top 70th Acc: 0.5000, Bottom 30th Acc: 0.3030
Fold [2/5] Epoch [10/100] Initial Loss: 0.1398, Training Loss: 0.0813, Initial Validation Loss: 0.1295, Validation Loss: 0.0798,V Acc: 0.6036, Top 70th Acc: 0.7179, Bottom 30th Acc: 0.3333
Fold [2/5] Epoch [20/100] Initial Loss: 0.1398, Training Loss: 0.0789, Initial Validation Loss: 0.1295, Validation Loss: 0.0787,V Acc: 0.5946, Top 70th Acc: 0.7179, Bottom 30th Acc: 0.3030
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.717948717948718
Fold [3/5] Epoch [0/100] Initial Loss: 0.1404, Training Loss: 0.1404, Initial Validation Loss: 0.1327, Validation Loss: 0.1327,V Acc: 0.3182, Top 70th Acc: 0.4156, Bottom 30th Acc: 0.0909
Fold [3/5] Epoch [10/100] Initial Loss: 0.1404, Training Loss: 0.0814, Initial Validation Loss: 0.1327, Validation Loss: 0.0763,V Acc: 0.6364, Top 70th Acc: 0.7532, Bottom 30th Acc: 0.3636
Fold [3/5] Epoch [20/100] Initial Loss: 0.1404, Training Loss: 0.0795, Initial Validation Loss: 0.1327, Validation Loss: 0.0757,V Acc: 0.6182, Top 70th Acc: 0.7403, Bottom 30th Acc: 0.3333
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.7532467532467533
Fold [4/5] Epoch [0/100] Initial Loss: 0.1266, Training Loss: 0.1266, Initial Validation Loss: 0.1156, Validation Loss: 0.1156,V Acc: 0.4954, Top 70th Acc: 0.5455, Bottom 30th Acc: 0.3750
Fold [4/5] Epoch [10/100] Initial Loss: 0.1266, Training Loss: 0.0791, Initial Validation Loss: 0.1156, Validation Loss: 0.0818,V Acc: 0.6239, Top 70th Acc: 0.7273, Bottom 30th Acc: 0.3750
Fold [4/5] Epoch [20/100] Initial Loss: 0.1266, Training Loss: 0.0773, Initial Validation Loss: 0.1156, Validation Loss: 0.0806,V Acc: 0.5963, Top 70th Acc: 0.7273, Bottom 30th Acc: 0.2812
Fold [4/5] Epoch [30/100] Initial Loss: 0.1266, Training Loss: 0.0768, Initial Validation Loss: 0.1156, Validation Loss: 0.0796,V Acc: 0.6330, Top 70th Acc: 0.7273, Bottom 30th Acc: 0.4062
Fold [4/5] Epoch [40/100] Initial Loss: 0.1266, Training Loss: 0.0764, Initial Validation Loss: 0.1156, Validation Loss: 0.0797,V Acc: 0.6514, Top 70th Acc: 0.7273, Bottom 30th Acc: 0.4688
Stopping early at Epoch (base 0): 43  Rolling back to Epoch (base 0): 38  Top Validation Acc: 0.7142857142857143
Fold [5/5] Epoch [0/100] Initial Loss: 0.1396, Training Loss: 0.1396, Initial Validation Loss: 0.1247, Validation Loss: 0.1247,V Acc: 0.2963, Top 70th Acc: 0.3421, Bottom 30th Acc: 0.1875
Fold [5/5] Epoch [10/100] Initial Loss: 0.1396, Training Loss: 0.0819, Initial Validation Loss: 0.1247, Validation Loss: 0.0743,V Acc: 0.6574, Top 70th Acc: 0.7632, Bottom 30th Acc: 0.4062
Fold [5/5] Epoch [20/100] Initial Loss: 0.1396, Training Loss: 0.0797, Initial Validation Loss: 0.1247, Validation Loss: 0.0725,V Acc: 0.6667, Top 70th Acc: 0.7632, Bottom 30th Acc: 0.4375
Fold [5/5] Epoch [30/100] Initial Loss: 0.1396, Training Loss: 0.0793, Initial Validation Loss: 0.1247, Validation Loss: 0.0714,V Acc: 0.6759, Top 70th Acc: 0.7368, Bottom 30th Acc: 0.5312
Fold [5/5] Epoch [40/100] Initial Loss: 0.1396, Training Loss: 0.0790, Initial Validation Loss: 0.1247, Validation Loss: 0.0706,V Acc: 0.6944, Top 70th Acc: 0.7632, Bottom 30th Acc: 0.5312
Fold [5/5] Epoch [50/100] Initial Loss: 0.1396, Training Loss: 0.0787, Initial Validation Loss: 0.1247, Validation Loss: 0.0709,V Acc: 0.6944, Top 70th Acc: 0.7500, Bottom 30th Acc: 0.5625
Stopping early at Epoch (base 0): 50  Rolling back to Epoch (base 0): 45  Top Validation Acc: 0.75
Running train_nn.py with seed 54
CUDA:False
Training samples count:  550
Training on 2 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1382, Training Loss: 0.1382, Initial Validation Loss: 0.1261, Validation Loss: 0.1261,V Acc: 0.3393, Top 70th Acc: 0.4051, Bottom 30th Acc: 0.1818
Fold [1/5] Epoch [10/100] Initial Loss: 0.1382, Training Loss: 0.0788, Initial Validation Loss: 0.1261, Validation Loss: 0.0853,V Acc: 0.5714, Top 70th Acc: 0.6962, Bottom 30th Acc: 0.2727
Fold [1/5] Epoch [20/100] Initial Loss: 0.1382, Training Loss: 0.0772, Initial Validation Loss: 0.1261, Validation Loss: 0.0849,V Acc: 0.5804, Top 70th Acc: 0.6962, Bottom 30th Acc: 0.3030
Stopping early at Epoch (base 0): 22  Rolling back to Epoch (base 0): 17  Top Validation Acc: 0.7088607594936709
54 0 [array([0.09428366, 0.38151303, 0.14606984, 0.20688367, 0.1712498 ],
      dtype=float32)]
Fold [2/5] Epoch [0/100] Initial Loss: 0.1371, Training Loss: 0.1371, Initial Validation Loss: 0.1293, Validation Loss: 0.1293,V Acc: 0.3514, Top 70th Acc: 0.3718, Bottom 30th Acc: 0.3030
Fold [2/5] Epoch [10/100] Initial Loss: 0.1371, Training Loss: 0.0837, Initial Validation Loss: 0.1293, Validation Loss: 0.0757,V Acc: 0.6847, Top 70th Acc: 0.7949, Bottom 30th Acc: 0.4242
Stopping early at Epoch (base 0): 16  Rolling back to Epoch (base 0): 11  Top Validation Acc: 0.8076923076923077
Fold [3/5] Epoch [0/100] Initial Loss: 0.1330, Training Loss: 0.1330, Initial Validation Loss: 0.1236, Validation Loss: 0.1236,V Acc: 0.5273, Top 70th Acc: 0.5455, Bottom 30th Acc: 0.4848
Fold [3/5] Epoch [10/100] Initial Loss: 0.1330, Training Loss: 0.0799, Initial Validation Loss: 0.1236, Validation Loss: 0.0818,V Acc: 0.6273, Top 70th Acc: 0.7403, Bottom 30th Acc: 0.3636
Fold [3/5] Epoch [20/100] Initial Loss: 0.1330, Training Loss: 0.0780, Initial Validation Loss: 0.1236, Validation Loss: 0.0816,V Acc: 0.5909, Top 70th Acc: 0.7532, Bottom 30th Acc: 0.2121
Stopping early at Epoch (base 0): 20  Rolling back to Epoch (base 0): 15  Top Validation Acc: 0.7532467532467533
Fold [4/5] Epoch [0/100] Initial Loss: 0.1394, Training Loss: 0.1394, Initial Validation Loss: 0.1298, Validation Loss: 0.1298,V Acc: 0.4037, Top 70th Acc: 0.4286, Bottom 30th Acc: 0.3438
Fold [4/5] Epoch [10/100] Initial Loss: 0.1394, Training Loss: 0.0807, Initial Validation Loss: 0.1298, Validation Loss: 0.0782,V Acc: 0.6422, Top 70th Acc: 0.7403, Bottom 30th Acc: 0.4062
Fold [4/5] Epoch [20/100] Initial Loss: 0.1394, Training Loss: 0.0788, Initial Validation Loss: 0.1298, Validation Loss: 0.0772,V Acc: 0.6422, Top 70th Acc: 0.7273, Bottom 30th Acc: 0.4375
Stopping early at Epoch (base 0): 29  Rolling back to Epoch (base 0): 24  Top Validation Acc: 0.7272727272727273
Fold [5/5] Epoch [0/100] Initial Loss: 0.1435, Training Loss: 0.1435, Initial Validation Loss: 0.1290, Validation Loss: 0.1290,V Acc: 0.4259, Top 70th Acc: 0.5132, Bottom 30th Acc: 0.2188
Fold [5/5] Epoch [10/100] Initial Loss: 0.1435, Training Loss: 0.0812, Initial Validation Loss: 0.1290, Validation Loss: 0.0793,V Acc: 0.6111, Top 70th Acc: 0.7500, Bottom 30th Acc: 0.2812
Fold [5/5] Epoch [20/100] Initial Loss: 0.1435, Training Loss: 0.0788, Initial Validation Loss: 0.1290, Validation Loss: 0.0775,V Acc: 0.6019, Top 70th Acc: 0.7500, Bottom 30th Acc: 0.2500
Fold [5/5] Epoch [30/100] Initial Loss: 0.1435, Training Loss: 0.0777, Initial Validation Loss: 0.1290, Validation Loss: 0.0776,V Acc: 0.6204, Top 70th Acc: 0.7237, Bottom 30th Acc: 0.3750
Fold [3/5] Epoch [20/100] Initial Loss: 0.1396, Training Loss: 0.0196, Initial Validation Loss: 0.1355, Validation Loss: 0.0249,V Acc: 0.9000, Top 70th Acc: 0.9870, Bottom 30th Acc: 0.6970
Fold [3/5] Epoch [30/100] Initial Loss: 0.1396, Training Loss: 0.0175, Initial Validation Loss: 0.1355, Validation Loss: 0.0235,V Acc: 0.9091, Top 70th Acc: 1.0000, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 33  Rolling back to Epoch (base 0): 28  Top Validation Acc: 1.0
Fold [4/5] Epoch [0/100] Initial Loss: 0.1393, Training Loss: 0.1393, Initial Validation Loss: 0.1353, Validation Loss: 0.1353,V Acc: 0.2661, Top 70th Acc: 0.3247, Bottom 30th Acc: 0.1250
Fold [4/5] Epoch [10/100] Initial Loss: 0.1393, Training Loss: 0.0366, Initial Validation Loss: 0.1353, Validation Loss: 0.0445,V Acc: 0.7982, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.5312
Fold [4/5] Epoch [20/100] Initial Loss: 0.1393, Training Loss: 0.0185, Initial Validation Loss: 0.1353, Validation Loss: 0.0335,V Acc: 0.8165, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.5312
Fold [4/5] Epoch [30/100] Initial Loss: 0.1393, Training Loss: 0.0147, Initial Validation Loss: 0.1353, Validation Loss: 0.0333,V Acc: 0.8257, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.5625
Stopping early at Epoch (base 0): 31  Rolling back to Epoch (base 0): 26  Top Validation Acc: 0.935064935064935
Fold [5/5] Epoch [0/100] Initial Loss: 0.1374, Training Loss: 0.1374, Initial Validation Loss: 0.1260, Validation Loss: 0.1260,V Acc: 0.3611, Top 70th Acc: 0.4737, Bottom 30th Acc: 0.0938
Fold [5/5] Epoch [10/100] Initial Loss: 0.1374, Training Loss: 0.0294, Initial Validation Loss: 0.1260, Validation Loss: 0.0300,V Acc: 0.8704, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.7188
Fold [5/5] Epoch [20/100] Initial Loss: 0.1374, Training Loss: 0.0177, Initial Validation Loss: 0.1260, Validation Loss: 0.0279,V Acc: 0.8519, Top 70th Acc: 0.9211, Bottom 30th Acc: 0.6875
Stopping early at Epoch (base 0): 20  Rolling back to Epoch (base 0): 15  Top Validation Acc: 0.9210526315789473
Running train_nn.py with seed 54
CUDA:False
Training samples count:  550
Training on 30 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1424, Training Loss: 0.1424, Initial Validation Loss: 0.1341, Validation Loss: 0.1341,V Acc: 0.3214, Top 70th Acc: 0.3797, Bottom 30th Acc: 0.1818
Fold [1/5] Epoch [10/100] Initial Loss: 0.1424, Training Loss: 0.0300, Initial Validation Loss: 0.1341, Validation Loss: 0.0311,V Acc: 0.8661, Top 70th Acc: 0.9367, Bottom 30th Acc: 0.6970
Fold [1/5] Epoch [20/100] Initial Loss: 0.1424, Training Loss: 0.0191, Initial Validation Loss: 0.1341, Validation Loss: 0.0269,V Acc: 0.8482, Top 70th Acc: 0.9367, Bottom 30th Acc: 0.6364
Fold [1/5] Epoch [30/100] Initial Loss: 0.1424, Training Loss: 0.0168, Initial Validation Loss: 0.1341, Validation Loss: 0.0259,V Acc: 0.8571, Top 70th Acc: 0.9620, Bottom 30th Acc: 0.6061
Fold [1/5] Epoch [40/100] Initial Loss: 0.1424, Training Loss: 0.0159, Initial Validation Loss: 0.1341, Validation Loss: 0.0254,V Acc: 0.8482, Top 70th Acc: 0.9620, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 41  Rolling back to Epoch (base 0): 36  Top Validation Acc: 0.9746835443037974
54 0 [array([0.8122656 , 0.04776441, 0.01613212, 0.06294905, 0.0608889 ],
      dtype=float32)]
Fold [2/5] Epoch [0/100] Initial Loss: 0.1401, Training Loss: 0.1401, Initial Validation Loss: 0.1313, Validation Loss: 0.1313,V Acc: 0.2703, Top 70th Acc: 0.3590, Bottom 30th Acc: 0.0606
Fold [2/5] Epoch [10/100] Initial Loss: 0.1401, Training Loss: 0.0249, Initial Validation Loss: 0.1313, Validation Loss: 0.0335,V Acc: 0.8559, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.6667
Fold [2/5] Epoch [20/100] Initial Loss: 0.1401, Training Loss: 0.0166, Initial Validation Loss: 0.1313, Validation Loss: 0.0310,V Acc: 0.8378, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.9487179487179487
Fold [3/5] Epoch [0/100] Initial Loss: 0.1365, Training Loss: 0.1365, Initial Validation Loss: 0.1360, Validation Loss: 0.1360,V Acc: 0.2545, Top 70th Acc: 0.3506, Bottom 30th Acc: 0.0303
Fold [3/5] Epoch [10/100] Initial Loss: 0.1365, Training Loss: 0.0276, Initial Validation Loss: 0.1360, Validation Loss: 0.0213,V Acc: 0.9545, Top 70th Acc: 1.0000, Bottom 30th Acc: 0.8485
Fold [3/5] Epoch [20/100] Initial Loss: 0.1365, Training Loss: 0.0203, Initial Validation Loss: 0.1360, Validation Loss: 0.0166,V Acc: 0.9364, Top 70th Acc: 1.0000, Bottom 30th Acc: 0.7879
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 1.0
Fold [4/5] Epoch [0/100] Initial Loss: 0.1394, Training Loss: 0.1394, Initial Validation Loss: 0.1337, Validation Loss: 0.1337,V Acc: 0.3853, Top 70th Acc: 0.4026, Bottom 30th Acc: 0.3438
Fold [4/5] Epoch [10/100] Initial Loss: 0.1394, Training Loss: 0.0303, Initial Validation Loss: 0.1337, Validation Loss: 0.0447,V Acc: 0.7798, Top 70th Acc: 0.8701, Bottom 30th Acc: 0.5625
Stopping early at Epoch (base 0): 19  Rolling back to Epoch (base 0): 14  Top Validation Acc: 0.8961038961038961
Fold [5/5] Epoch [0/100] Initial Loss: 0.1400, Training Loss: 0.1400, Initial Validation Loss: 0.1300, Validation Loss: 0.1300,V Acc: 0.2685, Top 70th Acc: 0.2895, Bottom 30th Acc: 0.2188
Fold [5/5] Epoch [10/100] Initial Loss: 0.1400, Training Loss: 0.0355, Initial Validation Loss: 0.1300, Validation Loss: 0.0431,V Acc: 0.7593, Top 70th Acc: 0.8947, Bottom 30th Acc: 0.4375
Fold [5/5] Epoch [20/100] Initial Loss: 0.1400, Training Loss: 0.0167, Initial Validation Loss: 0.1300, Validation Loss: 0.0359,V Acc: 0.8056, Top 70th Acc: 0.8947, Bottom 30th Acc: 0.5938
Stopping early at Epoch (base 0): 27  Rolling back to Epoch (base 0): 22  Top Validation Acc: 0.8947368421052632
Running train_nn.py with seed 55
CUDA:False
Training samples count:  550
Training on 30 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1398, Training Loss: 0.1398, Initial Validation Loss: 0.1335, Validation Loss: 0.1335,V Acc: 0.4464, Top 70th Acc: 0.4684, Bottom 30th Acc: 0.3939
Fold [1/5] Epoch [10/100] Initial Loss: 0.1398, Training Loss: 0.0301, Initial Validation Loss: 0.1335, Validation Loss: 0.0306,V Acc: 0.8661, Top 70th Acc: 0.9747, Bottom 30th Acc: 0.6061
Fold [1/5] Epoch [20/100] Initial Loss: 0.1398, Training Loss: 0.0181, Initial Validation Loss: 0.1335, Validation Loss: 0.0236,V Acc: 0.8839, Top 70th Acc: 1.0000, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.9873417721518988
Fold [2/5] Epoch [0/100] Initial Loss: 0.1393, Training Loss: 0.1393, Initial Validation Loss: 0.1337, Validation Loss: 0.1337,V Acc: 0.2703, Top 70th Acc: 0.3205, Bottom 30th Acc: 0.1515
Fold [2/5] Epoch [10/100] Initial Loss: 0.1393, Training Loss: 0.0333, Initial Validation Loss: 0.1337, Validation Loss: 0.0418,V Acc: 0.8018, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.5152
Fold [2/5] Epoch [20/100] Initial Loss: 0.1393, Training Loss: 0.0178, Initial Validation Loss: 0.1337, Validation Loss: 0.0296,V Acc: 0.8378, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.9358974358974359
Fold [3/5] Epoch [0/100] Initial Loss: 0.1381, Training Loss: 0.1381, Initial Validation Loss: 0.1320, Validation Loss: 0.1320,V Acc: 0.3091, Top 70th Acc: 0.2987, Bottom 30th Acc: 0.3333
Fold [3/5] Epoch [10/100] Initial Loss: 0.1381, Training Loss: 0.0256, Initial Validation Loss: 0.1320, Validation Loss: 0.0396,V Acc: 0.8091, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.5152
Fold [3/5] Epoch [20/100] Initial Loss: 0.1381, Training Loss: 0.0150, Initial Validation Loss: 0.1320, Validation Loss: 0.0361,V Acc: 0.8182, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.5455
Fold [3/5] Epoch [30/100] Initial Loss: 0.1381, Training Loss: 0.0131, Initial Validation Loss: 0.1320, Validation Loss: 0.0364,V Acc: 0.8273, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 30  Rolling back to Epoch (base 0): 25  Top Validation Acc: 0.935064935064935
Fold [4/5] Epoch [0/100] Initial Loss: 0.1409, Training Loss: 0.1409, Initial Validation Loss: 0.1301, Validation Loss: 0.1301,V Acc: 0.3119, Top 70th Acc: 0.3247, Bottom 30th Acc: 0.2812
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.9746835443037974
Fold [2/5] Epoch [0/100] Initial Loss: 0.1359, Training Loss: 0.1359, Initial Validation Loss: 0.1316, Validation Loss: 0.1316,V Acc: 0.5045, Top 70th Acc: 0.5641, Bottom 30th Acc: 0.3636
Fold [2/5] Epoch [10/100] Initial Loss: 0.1359, Training Loss: 0.0252, Initial Validation Loss: 0.1316, Validation Loss: 0.0333,V Acc: 0.8919, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.7576
Fold [2/5] Epoch [20/100] Initial Loss: 0.1359, Training Loss: 0.0166, Initial Validation Loss: 0.1316, Validation Loss: 0.0251,V Acc: 0.9279, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.8182
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.9871794871794872
Fold [3/5] Epoch [0/100] Initial Loss: 0.1335, Training Loss: 0.1335, Initial Validation Loss: 0.1148, Validation Loss: 0.1148,V Acc: 0.5455, Top 70th Acc: 0.6494, Bottom 30th Acc: 0.3030
Fold [3/5] Epoch [10/100] Initial Loss: 0.1335, Training Loss: 0.0205, Initial Validation Loss: 0.1148, Validation Loss: 0.0319,V Acc: 0.8273, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.5152
Fold [3/5] Epoch [20/100] Initial Loss: 0.1335, Training Loss: 0.0145, Initial Validation Loss: 0.1148, Validation Loss: 0.0293,V Acc: 0.8273, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 21  Rolling back to Epoch (base 0): 16  Top Validation Acc: 0.948051948051948
Fold [4/5] Epoch [0/100] Initial Loss: 0.1285, Training Loss: 0.1285, Initial Validation Loss: 0.1105, Validation Loss: 0.1105,V Acc: 0.4771, Top 70th Acc: 0.6234, Bottom 30th Acc: 0.1250
Fold [4/5] Epoch [10/100] Initial Loss: 0.1285, Training Loss: 0.0203, Initial Validation Loss: 0.1105, Validation Loss: 0.0223,V Acc: 0.8716, Top 70th Acc: 1.0000, Bottom 30th Acc: 0.5625
Stopping early at Epoch (base 0): 16  Rolling back to Epoch (base 0): 11  Top Validation Acc: 0.987012987012987
75 3 [array([0.69758236, 0.02859313, 0.04055084, 0.13658002, 0.09669367],
      dtype=float32)]
Fold [5/5] Epoch [0/100] Initial Loss: 0.1378, Training Loss: 0.1378, Initial Validation Loss: 0.1222, Validation Loss: 0.1222,V Acc: 0.4722, Top 70th Acc: 0.5263, Bottom 30th Acc: 0.3438
Fold [5/5] Epoch [10/100] Initial Loss: 0.1378, Training Loss: 0.0299, Initial Validation Loss: 0.1222, Validation Loss: 0.0323,V Acc: 0.8704, Top 70th Acc: 0.9079, Bottom 30th Acc: 0.7812
Fold [5/5] Epoch [20/100] Initial Loss: 0.1378, Training Loss: 0.0181, Initial Validation Loss: 0.1222, Validation Loss: 0.0251,V Acc: 0.8889, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.7188
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.9605263157894737
Running train_nn.py with seed 76
CUDA:False
Training samples count:  550
Training on 21 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1355, Training Loss: 0.1355, Initial Validation Loss: 0.1249, Validation Loss: 0.1249,V Acc: 0.4286, Top 70th Acc: 0.5063, Bottom 30th Acc: 0.2424
Fold [1/5] Epoch [10/100] Initial Loss: 0.1355, Training Loss: 0.0260, Initial Validation Loss: 0.1249, Validation Loss: 0.0366,V Acc: 0.8393, Top 70th Acc: 0.9367, Bottom 30th Acc: 0.6061
Fold [1/5] Epoch [20/100] Initial Loss: 0.1355, Training Loss: 0.0156, Initial Validation Loss: 0.1249, Validation Loss: 0.0280,V Acc: 0.8750, Top 70th Acc: 0.9494, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 20  Rolling back to Epoch (base 0): 15  Top Validation Acc: 0.9493670886075949
Fold [2/5] Epoch [0/100] Initial Loss: 0.1309, Training Loss: 0.1309, Initial Validation Loss: 0.1125, Validation Loss: 0.1125,V Acc: 0.4775, Top 70th Acc: 0.6154, Bottom 30th Acc: 0.1515
Fold [2/5] Epoch [10/100] Initial Loss: 0.1309, Training Loss: 0.0241, Initial Validation Loss: 0.1125, Validation Loss: 0.0258,V Acc: 0.8739, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 19  Rolling back to Epoch (base 0): 14  Top Validation Acc: 0.9615384615384616
Fold [3/5] Epoch [0/100] Initial Loss: 0.1375, Training Loss: 0.1375, Initial Validation Loss: 0.1213, Validation Loss: 0.1213,V Acc: 0.4455, Top 70th Acc: 0.5195, Bottom 30th Acc: 0.2727
Fold [3/5] Epoch [10/100] Initial Loss: 0.1375, Training Loss: 0.0269, Initial Validation Loss: 0.1213, Validation Loss: 0.0282,V Acc: 0.8727, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6970
Fold [3/5] Epoch [20/100] Initial Loss: 0.1375, Training Loss: 0.0182, Initial Validation Loss: 0.1213, Validation Loss: 0.0314,V Acc: 0.8182, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.5455
Fold [3/5] Epoch [30/100] Initial Loss: 0.1375, Training Loss: 0.0134, Initial Validation Loss: 0.1213, Validation Loss: 0.0236,V Acc: 0.8818, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 37  Rolling back to Epoch (base 0): 32  Top Validation Acc: 0.948051948051948
76 2 [array([0.86757904, 0.01218674, 0.02416724, 0.06873528, 0.02733172],
      dtype=float32)]
Fold [4/5] Epoch [0/100] Initial Loss: 0.1342, Training Loss: 0.1342, Initial Validation Loss: 0.1244, Validation Loss: 0.1244,V Acc: 0.5229, Top 70th Acc: 0.6883, Bottom 30th Acc: 0.1250
Fold [4/5] Epoch [10/100] Initial Loss: 0.1342, Training Loss: 0.0275, Initial Validation Loss: 0.1244, Validation Loss: 0.0284,V Acc: 0.8624, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.5938
Fold [4/5] Epoch [20/100] Initial Loss: 0.1342, Training Loss: 0.0172, Initial Validation Loss: 0.1244, Validation Loss: 0.0254,V Acc: 0.8807, Top 70th Acc: 0.9870, Bottom 30th Acc: 0.6250
Stopping early at Epoch (base 0): 21  Rolling back to Epoch (base 0): 16  Top Validation Acc: 0.961038961038961
Fold [5/5] Epoch [0/100] Initial Loss: 0.1342, Training Loss: 0.1342, Initial Validation Loss: 0.1197, Validation Loss: 0.1197,V Acc: 0.4444, Top 70th Acc: 0.5395, Bottom 30th Acc: 0.2188
Fold [5/5] Epoch [10/100] Initial Loss: 0.1342, Training Loss: 0.0245, Initial Validation Loss: 0.1197, Validation Loss: 0.0263,V Acc: 0.8981, Top 70th Acc: 0.9737, Bottom 30th Acc: 0.7188
Fold [5/5] Epoch [20/100] Initial Loss: 0.1342, Training Loss: 0.0174, Initial Validation Loss: 0.1197, Validation Loss: 0.0210,V Acc: 0.9167, Top 70th Acc: 0.9737, Bottom 30th Acc: 0.7812
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.9736842105263158
Running train_nn.py with seed 77
CUDA:False
Training samples count:  550
Training on 21 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1378, Training Loss: 0.1378, Initial Validation Loss: 0.1326, Validation Loss: 0.1326,V Acc: 0.4911, Top 70th Acc: 0.5949, Bottom 30th Acc: 0.2424
Fold [1/5] Epoch [10/100] Initial Loss: 0.1378, Training Loss: 0.0230, Initial Validation Loss: 0.1326, Validation Loss: 0.0284,V Acc: 0.8661, Top 70th Acc: 0.9747, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 16  Rolling back to Epoch (base 0): 11  Top Validation Acc: 0.9620253164556962
Fold [2/5] Epoch [0/100] Initial Loss: 0.1307, Training Loss: 0.1307, Initial Validation Loss: 0.1181, Validation Loss: 0.1181,V Acc: 0.4955, Top 70th Acc: 0.6154, Bottom 30th Acc: 0.2121
Fold [2/5] Epoch [10/100] Initial Loss: 0.1307, Training Loss: 0.0236, Initial Validation Loss: 0.1181, Validation Loss: 0.0217,V Acc: 0.9279, Top 70th Acc: 0.9872, Bottom 30th Acc: 0.7879
Fold [2/5] Epoch [20/100] Initial Loss: 0.1307, Training Loss: 0.0178, Initial Validation Loss: 0.1181, Validation Loss: 0.0246,V Acc: 0.8919, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 1.0
Fold [3/5] Epoch [0/100] Initial Loss: 0.1271, Training Loss: 0.1271, Initial Validation Loss: 0.1051, Validation Loss: 0.1051,V Acc: 0.5727, Top 70th Acc: 0.6234, Bottom 30th Acc: 0.4545
Fold [3/5] Epoch [10/100] Initial Loss: 0.1271, Training Loss: 0.0205, Initial Validation Loss: 0.1051, Validation Loss: 0.0287,V Acc: 0.8636, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.6364
Fold [3/5] Epoch [20/100] Initial Loss: 0.1271, Training Loss: 0.0155, Initial Validation Loss: 0.1051, Validation Loss: 0.0377,V Acc: 0.8182, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 27  Rolling back to Epoch (base 0):/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)

Fold [3/5] Epoch [30/100] Initial Loss: 0.1401, Training Loss: 0.0111, Initial Validation Loss: 0.1283, Validation Loss: 0.0275,V Acc: 0.8455, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6061
Fold [3/5] Epoch [40/100] Initial Loss: 0.1401, Training Loss: 0.0102, Initial Validation Loss: 0.1283, Validation Loss: 0.0271,V Acc: 0.8545, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 40  Rolling back to Epoch (base 0): 35  Top Validation Acc: 0.948051948051948
57 2 [array([0.6592175 , 0.03743254, 0.0402781 , 0.10616312, 0.15690872],
      dtype=float32)]
Fold [4/5] Epoch [0/100] Initial Loss: 0.1377, Training Loss: 0.1377, Initial Validation Loss: 0.1318, Validation Loss: 0.1318,V Acc: 0.2936, Top 70th Acc: 0.3506, Bottom 30th Acc: 0.1562
Fold [4/5] Epoch [10/100] Initial Loss: 0.1377, Training Loss: 0.0320, Initial Validation Loss: 0.1318, Validation Loss: 0.0411,V Acc: 0.7982, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.5000
Fold [4/5] Epoch [20/100] Initial Loss: 0.1377, Training Loss: 0.0142, Initial Validation Loss: 0.1318, Validation Loss: 0.0333,V Acc: 0.7982, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.4062
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.948051948051948
Fold [5/5] Epoch [0/100] Initial Loss: 0.1368, Training Loss: 0.1368, Initial Validation Loss: 0.1349, Validation Loss: 0.1349,V Acc: 0.3148, Top 70th Acc: 0.3684, Bottom 30th Acc: 0.1875
Fold [5/5] Epoch [10/100] Initial Loss: 0.1368, Training Loss: 0.0212, Initial Validation Loss: 0.1349, Validation Loss: 0.0338,V Acc: 0.8796, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.6875
Fold [5/5] Epoch [20/100] Initial Loss: 0.1368, Training Loss: 0.0124, Initial Validation Loss: 0.1349, Validation Loss: 0.0317,V Acc: 0.8704, Top 70th Acc: 0.9737, Bottom 30th Acc: 0.6250
Stopping early at Epoch (base 0): 20  Rolling back to Epoch (base 0): 15  Top Validation Acc: 0.9736842105263158
Running train_nn.py with seed 58
CUDA:False
Training samples count:  550
Training on 40 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1410, Training Loss: 0.1410, Initial Validation Loss: 0.1390, Validation Loss: 0.1390,V Acc: 0.2857, Top 70th Acc: 0.2658, Bottom 30th Acc: 0.3333
Fold [1/5] Epoch [10/100] Initial Loss: 0.1410, Training Loss: 0.0246, Initial Validation Loss: 0.1390, Validation Loss: 0.0398,V Acc: 0.8571, Top 70th Acc: 0.9367, Bottom 30th Acc: 0.6667
Fold [1/5] Epoch [20/100] Initial Loss: 0.1410, Training Loss: 0.0129, Initial Validation Loss: 0.1390, Validation Loss: 0.0334,V Acc: 0.8839, Top 70th Acc: 0.9367, Bottom 30th Acc: 0.7576
Fold [1/5] Epoch [30/100] Initial Loss: 0.1410, Training Loss: 0.0113, Initial Validation Loss: 0.1390, Validation Loss: 0.0317,V Acc: 0.8839, Top 70th Acc: 0.9367, Bottom 30th Acc: 0.7576
Stopping early at Epoch (base 0): 35  Rolling back to Epoch (base 0): 30  Top Validation Acc: 0.9367088607594937
Fold [2/5] Epoch [0/100] Initial Loss: 0.1413, Training Loss: 0.1413, Initial Validation Loss: 0.1326, Validation Loss: 0.1326,V Acc: 0.2883, Top 70th Acc: 0.3462, Bottom 30th Acc: 0.1515
Fold [2/5] Epoch [10/100] Initial Loss: 0.1413, Training Loss: 0.0303, Initial Validation Loss: 0.1326, Validation Loss: 0.0339,V Acc: 0.8559, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.6364
Fold [2/5] Epoch [20/100] Initial Loss: 0.1413, Training Loss: 0.0139, Initial Validation Loss: 0.1326, Validation Loss: 0.0268,V Acc: 0.8288, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.4848
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.9615384615384616
Fold [3/5] Epoch [0/100] Initial Loss: 0.1454, Training Loss: 0.1454, Initial Validation Loss: 0.1345, Validation Loss: 0.1345,V Acc: 0.3000, Top 70th Acc: 0.3377, Bottom 30th Acc: 0.2121
Fold [3/5] Epoch [10/100] Initial Loss: 0.1454, Training Loss: 0.0320, Initial Validation Loss: 0.1345, Validation Loss: 0.0315,V Acc: 0.8909, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.7273
Fold [3/5] Epoch [20/100] Initial Loss: 0.1454, Training Loss: 0.0144, Initial Validation Loss: 0.1345, Validation Loss: 0.0210,V Acc: 0.8909, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.7273
Stopping early at Epoch (base 0): 28  Rolling back to Epoch (base 0): 23  Top Validation Acc: 0.948051948051948
Fold [4/5] Epoch [0/100] Initial Loss: 0.1410, Training Loss: 0.1410, Initial Validation Loss: 0.1345, Validation Loss: 0.1345,V Acc: 0.2661, Top 70th Acc: 0.2597, Bottom 30th Acc: 0.2812
Fold [4/5] Epoch [10/100] Initial Loss: 0.1410, Training Loss: 0.0353, Initial Validation Loss: 0.1345, Validation Loss: 0.0392,V Acc: 0.8165, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.5312
Fold [4/5] Epoch [20/100] Initial Loss: 0.1410, Training Loss: 0.0134, Initial Validation Loss: 0.1345, Validation Loss: 0.0311,V Acc: 0.8165, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.5312
Stopping early at Epoch (base 0): 29  Rolling back to Epoch (base 0): 24  Top Validation Acc: 0.935064935064935
58 3 [array([0.54265183, 0.07189325, 0.07797196, 0.06429847, 0.24318455],
      dtype=float32)]
Fold [5/5] Epoch [0/100] Initial Loss: 0.1425, Training Loss: 0.1425, Initial Validation Loss: 0.1322, Validation Loss: 0.1322,V Acc: 0.2407, Top 70th Acc: 0.2763, Bottom 30th Acc: 0.1562
Fold [5/5] Epoch [10/100] Initial Loss: 0.1425, Training Loss: 0.0237, Initial Validation Loss: 0.1322, Validation Loss: 0.0348,V Acc: 0.8333, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.5625
Fold [5/5] Epoch [20/100] Initial Loss: 0.1425, Training Loss: 0.0136, Initial Validation Loss: 0.1322, Validation Loss: 0.0296,V Acc: 0.8426, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.5938
Stopping early at Epoch (base 0): 21  Rolling back to Epoch (base 0): 16  Top Validation Acc: 0.9605263157894737
Running train_nn.py with seed 59
CUDA:False
Training samples count:  550
Training on 40 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1378, Training Loss: 0.1378, Initial Validation Loss: 0.1363, Validation Loss: 0.1363,V Acc: 0.2857, Top 70th Acc: 0.3418, Bottom 30th Acc: 0.1515
Fold [1/5] Epoch [10/100] Initial Loss: 0.1378, Training Loss: 0.0425, Initial Validation Loss: 0.1363, Validation Loss: 0.0584,V Acc: 0.7411, Top 70th Acc: 0.8481, Bottom 30th Acc: 0.4848
Fold [1/5] Epoch [20/100] Initial Loss: 0.1378, Training Loss: 0.0174, Initial Validation Loss: 0.1363, Validation Loss: 0.0434,V Acc: 0.7679, Top 70th Acc: 0.8861, Bottom 30th Acc: 0.4848
Fold [1/5] Epoch [30/100] Initial Loss: 0.1378, Training Loss: 0.0118, Initial Validation Loss: 0.1363, Validation Loss: 0.0392,V Acc: 0.8036, Top 70th Acc: 0.8987, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 33  Rolling back to Epoch (base 0): 28  Top Validation Acc: 0.8734177215189873
Fold [2/5] Epoch [0/100] Initial Loss: 0.1382, Training Loss: 0.1382, Initial Validation Loss: 0.1313, Validation Loss: 0.1313,V Acc: 0.4324, Top 70th Acc: 0.5000, Bottom 30th Acc: 0.2727
Fold [2/5] Epoch [10/100] Initial Loss: 0.1382, Training Loss: 0.0279, Initial Validation Loss: 0.1313, Validation Loss: 0.0425,V Acc: 0.7838, Top 70th Acc: 0.8846, Bottom 30th Acc: 0.5455
Fold [2/5] Epoch [20/100] Initial Loss: 0.1382, Training Loss: 0.0153, Initial Validation Loss: 0.1313, Validation Loss: 0.0293,V Acc: 0.8288, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.4848
Fold [2/5] Epoch [30/100] Initial Loss: 0.1382, Training Loss: 0.0125, Initial Validation Loss: 0.1313, Validation Loss: 0.0270,V Acc: 0.8559, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 35  Rolling back to Epoch (base 0): 30  Top Validation Acc: 0.9615384615384616
Fold [3/5] Epoch [0/100] Initial Loss: 0.1375, Training Loss: 0.1375, Initial Validation Loss: 0.1321, Validation Loss: 0.1321,V Acc: 0.3000, Top 70th Acc: 0.3766, Bottom 30th Acc: 0.1212
Fold [3/5] Epoch [10/100] Initial Loss: 0.1375, Training Loss: 0.0377, Initial Validation Loss: 0.1321, Validation Loss: 0.0395,V Acc: 0.8364, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 19  Rolling back to Epoch (base 0): 14  Top Validation Acc: 0.974025974025974
Fold [4/5] Epoch [0/100] Initial Loss: 0.1415, Training Loss: 0.1415, Initial Validation Loss: 0.1344, Validation Loss: 0.1344,V Acc: 0.3119, Top 70th Acc: 0.3896, Bottom 30th Acc: 0.1250 0.9620253164556962
Fold [2/5] Epoch [0/100] Initial Loss: 0.1351, Training Loss: 0.1351, Initial Validation Loss: 0.1281, Validation Loss: 0.1281,V Acc: 0.3694, Top 70th Acc: 0.4744, Bottom 30th Acc: 0.1212
Fold [2/5] Epoch [10/100] Initial Loss: 0.1351, Training Loss: 0.0279, Initial Validation Loss: 0.1281, Validation Loss: 0.0362,V Acc: 0.8198, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.6061
Fold [2/5] Epoch [20/100] Initial Loss: 0.1351, Training Loss: 0.0227, Initial Validation Loss: 0.1281, Validation Loss: 0.0360,V Acc: 0.8288, Top 70th Acc: 0.8974, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 28  Rolling back to Epoch (base 0): 23  Top Validation Acc: 0.9102564102564102
Fold [3/5] Epoch [0/100] Initial Loss: 0.1416, Training Loss: 0.1416, Initial Validation Loss: 0.1348, Validation Loss: 0.1348,V Acc: 0.3455, Top 70th Acc: 0.3766, Bottom 30th Acc: 0.2727
Fold [3/5] Epoch [10/100] Initial Loss: 0.1416, Training Loss: 0.0326, Initial Validation Loss: 0.1348, Validation Loss: 0.0490,V Acc: 0.7636, Top 70th Acc: 0.8831, Bottom 30th Acc: 0.4848
Fold [3/5] Epoch [20/100] Initial Loss: 0.1416, Training Loss: 0.0218, Initial Validation Loss: 0.1348, Validation Loss: 0.0450,V Acc: 0.7818, Top 70th Acc: 0.8961, Bottom 30th Acc: 0.5152
Fold [3/5] Epoch [30/100] Initial Loss: 0.1416, Training Loss: 0.0194, Initial Validation Loss: 0.1348, Validation Loss: 0.0448,V Acc: 0.7727, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.4242
Stopping early at Epoch (base 0): 39  Rolling back to Epoch (base 0): 34  Top Validation Acc: 0.9090909090909091
Fold [4/5] Epoch [0/100] Initial Loss: 0.1397, Training Loss: 0.1397, Initial Validation Loss: 0.1288, Validation Loss: 0.1288,V Acc: 0.3486, Top 70th Acc: 0.4416, Bottom 30th Acc: 0.1250
Fold [4/5] Epoch [10/100] Initial Loss: 0.1397, Training Loss: 0.0381, Initial Validation Loss: 0.1288, Validation Loss: 0.0330,V Acc: 0.8349, Top 70th Acc: 0.8961, Bottom 30th Acc: 0.6875
Fold [4/5] Epoch [20/100] Initial Loss: 0.1397, Training Loss: 0.0247, Initial Validation Loss: 0.1288, Validation Loss: 0.0269,V Acc: 0.8532, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.6562
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.948051948051948
Fold [5/5] Epoch [0/100] Initial Loss: 0.1374, Training Loss: 0.1374, Initial Validation Loss: 0.1320, Validation Loss: 0.1320,V Acc: 0.3426, Top 70th Acc: 0.3553, Bottom 30th Acc: 0.3125
Fold [5/5] Epoch [10/100] Initial Loss: 0.1374, Training Loss: 0.0337, Initial Validation Loss: 0.1320, Validation Loss: 0.0398,V Acc: 0.8519, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.6562
Stopping early at Epoch (base 0): 19  Rolling back to Epoch (base 0): 14  Top Validation Acc: 0.9342105263157895
55 4 [array([0.35139835, 0.17262377, 0.10793565, 0.21596932, 0.15207295],
      dtype=float32)]
Running train_nn.py with seed 56
CUDA:False
Training samples count:  550
Training on 20 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1387, Training Loss: 0.1387, Initial Validation Loss: 0.1334, Validation Loss: 0.1334,V Acc: 0.3929, Top 70th Acc: 0.4937, Bottom 30th Acc: 0.1515
Fold [1/5] Epoch [10/100] Initial Loss: 0.1387, Training Loss: 0.0345, Initial Validation Loss: 0.1334, Validation Loss: 0.0406,V Acc: 0.7946, Top 70th Acc: 0.8987, Bottom 30th Acc: 0.5455
Fold [1/5] Epoch [20/100] Initial Loss: 0.1387, Training Loss: 0.0231, Initial Validation Loss: 0.1334, Validation Loss: 0.0353,V Acc: 0.8304, Top 70th Acc: 0.9114, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 21  Rolling back to Epoch (base 0): 16  Top Validation Acc: 0.8987341772151899
Fold [2/5] Epoch [0/100] Initial Loss: 0.1415, Training Loss: 0.1415, Initial Validation Loss: 0.1344, Validation Loss: 0.1344,V Acc: 0.2432, Top 70th Acc: 0.2821, Bottom 30th Acc: 0.1515
Fold [2/5] Epoch [10/100] Initial Loss: 0.1415, Training Loss: 0.0489, Initial Validation Loss: 0.1344, Validation Loss: 0.0408,V Acc: 0.8198, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.5455
Fold [2/5] Epoch [20/100] Initial Loss: 0.1415, Training Loss: 0.0307, Initial Validation Loss: 0.1344, Validation Loss: 0.0293,V Acc: 0.8919, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.6970
Fold [2/5] Epoch [30/100] Initial Loss: 0.1415, Training Loss: 0.0255, Initial Validation Loss: 0.1344, Validation Loss: 0.0252,V Acc: 0.8739, Top 70th Acc: 0.9872, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 35  Rolling back to Epoch (base 0): 30  Top Validation Acc: 0.9743589743589743
Fold [3/5] Epoch [0/100] Initial Loss: 0.1393, Training Loss: 0.1393, Initial Validation Loss: 0.1315, Validation Loss: 0.1315,V Acc: 0.4182, Top 70th Acc: 0.5325, Bottom 30th Acc: 0.1515
Fold [3/5] Epoch [10/100] Initial Loss: 0.1393, Training Loss: 0.0400, Initial Validation Loss: 0.1315, Validation Loss: 0.0484,V Acc: 0.7818, Top 70th Acc: 0.8571, Bottom 30th Acc: 0.6061
Fold [3/5] Epoch [20/100] Initial Loss: 0.1393, Training Loss: 0.0232, Initial Validation Loss: 0.1315, Validation Loss: 0.0373,V Acc: 0.8273, Top 70th Acc: 0.8961, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.9090909090909091
Fold [4/5] Epoch [0/100] Initial Loss: 0.1384, Training Loss: 0.1384, Initial Validation Loss: 0.1355, Validation Loss: 0.1355,V Acc: 0.3119, Top 70th Acc: 0.2857, Bottom 30th Acc: 0.3750
Fold [4/5] Epoch [10/100] Initial Loss: 0.1384, Training Loss: 0.0353, Initial Validation Loss: 0.1355, Validation Loss: 0.0427,V Acc: 0.8165, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.5625
Fold [4/5] Epoch [20/100] Initial Loss: 0.1384, Training Loss: 0.0236, Initial Validation Loss: 0.1355, Validation Loss: 0.0327,V Acc: 0.8257, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.5312
Stopping early at Epoch (base 0): 29  Rolling back to Epoch (base 0): 24  Top Validation Acc: 0.935064935064935
56 3 [array([0.35867035, 0.08476873, 0.1251818 , 0.19635119, 0.23502792],
      dtype=float32)]
Fold [5/5] Epoch [0/100] Initial Loss: 0.1399, Training Loss: 0.1399, Initial Validation Loss: 0.1329, Validation Loss: 0.1329,V Acc: 0.2778, Top 70th Acc: 0.2368, Bottom 30th Acc: 0.3750
Fold [5/5] Epoch [10/100] Initial Loss: 0.1399, Training Loss: 0.0432, Initial Validation Loss: 0.1329, Validation Loss: 0.0549,V Acc: 0.7222, Top 70th Acc: 0.7895, Bottom 30th Acc: 0.5625
Fold [5/5] Epoch [20/100] Initial Loss: 0.1399, Training Loss: 0.0234, Initial Validation Loss: 0.1329, Validation Loss: 0.0411,V Acc: 0.8056, Top 70th Acc: 0.8684, Bottom 30th Acc: 0.6562
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.868421052631579
Running train_nn.py with seed 57
CUDA:False
Training samples count:  550
Training on 20 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1391, Training Loss: 0.1391, Initial Validation Loss: 0.1330, Validation Loss: 0.1330,V Acc: 0.4018, Top 70th Acc: 0.5063, Bottom 30th Acc: 0.1515
Fold [1/5] Epoch [10/100] Initial Loss: 0.1391, Training Loss: 0.0409, Initial Validation Loss: 0.1330, Validation Loss: 0.0474,V Acc: 0.8125, Top 70th Acc: 0.8608, Bottom 30th Acc: 0.6970
Fold [1/5] Epoch [20/100] Initial Loss: 0.1391, Training Loss: 0.0256, Initial Validation Loss: 0.1330, Validation Loss: 0.0370,V Acc: 0.8393, Top 70th Acc: 0.9114, Bottom 30th Acc: 0.6667
Fold [1/5] Epoch [30/100] Initial Loss: 0.1391, Training Loss: 0.0227, Initial Validation Loss: 0.1330, Validation Loss: 0.0343,V Acc: 0.8571, Top 70th Acc: 0.9241, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 32  Rolling back to Epoch (base 0): 27  Top Validation Acc: 0.9367088607594937
Fold [2/5] Epoch [0/100] Initial Loss: 0.1362, Training Loss: 0.1362, Initial Validation Loss: 0.1311, Validation Loss: 0.1311,V Acc: 0.4595, Top 70th Acc: 0.5128, Bottom 30th Acc: 0.3333
Fold [2/5] Epoch [10/100] Initial Loss: 0.1362, Training Loss: 0.0354, Initial Validation Loss: 0.1311, Validation Loss: 0.0420,V Acc: 0.8018, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.4848
Fold [2/5] Epoch [20/100] Initial Loss: 0.1362, Training Loss: 0.0228, Initial Validation Loss: 0.1311, Validation Loss: 0.0386,V Acc: 0.7928, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.5152
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0):
Fold [1/5] Epoch [20/100] Initial Loss: 0.1393, Training Loss: 0.0045, Initial Validation Loss: 0.1350, Validation Loss: 0.0320,V Acc: 0.8214, Top 70th Acc: 0.9494, Bottom 30th Acc: 0.5152
Stopping early at Epoch (base 0): 21  Rolling back to Epoch (base 0): 16  Top Validation Acc: 0.9620253164556962
Fold [2/5] Epoch [0/100] Initial Loss: 0.1399, Training Loss: 0.1399, Initial Validation Loss: 0.1332, Validation Loss: 0.1332,V Acc: 0.3243, Top 70th Acc: 0.3718, Bottom 30th Acc: 0.2121
Fold [2/5] Epoch [10/100] Initial Loss: 0.1399, Training Loss: 0.0198, Initial Validation Loss: 0.1332, Validation Loss: 0.0407,V Acc: 0.7838, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.4848
Fold [2/5] Epoch [20/100] Initial Loss: 0.1399, Training Loss: 0.0061, Initial Validation Loss: 0.1332, Validation Loss: 0.0362,V Acc: 0.8198, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.8974358974358975
43 1 [array([0.4547034 , 0.03936866, 0.08868954, 0.2636924 , 0.15354599],
      dtype=float32)]
Fold [3/5] Epoch [0/100] Initial Loss: 0.1384, Training Loss: 0.1384, Initial Validation Loss: 0.1368, Validation Loss: 0.1368,V Acc: 0.3364, Top 70th Acc: 0.3636, Bottom 30th Acc: 0.2727
Fold [3/5] Epoch [10/100] Initial Loss: 0.1384, Training Loss: 0.0245, Initial Validation Loss: 0.1368, Validation Loss: 0.0419,V Acc: 0.8364, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.6061
Fold [3/5] Epoch [20/100] Initial Loss: 0.1384, Training Loss: 0.0059, Initial Validation Loss: 0.1368, Validation Loss: 0.0321,V Acc: 0.8455, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.5455
Fold [3/5] Epoch [30/100] Initial Loss: 0.1384, Training Loss: 0.0043, Initial Validation Loss: 0.1368, Validation Loss: 0.0306,V Acc: 0.8455, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.5455
Fold [3/5] Epoch [40/100] Initial Loss: 0.1384, Training Loss: 0.0039, Initial Validation Loss: 0.1368, Validation Loss: 0.0300,V Acc: 0.8545, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 47  Rolling back to Epoch (base 0): 42  Top Validation Acc: 0.987012987012987
Fold [4/5] Epoch [0/100] Initial Loss: 0.1394, Training Loss: 0.1394, Initial Validation Loss: 0.1360, Validation Loss: 0.1360,V Acc: 0.3578, Top 70th Acc: 0.4416, Bottom 30th Acc: 0.1562
Fold [4/5] Epoch [10/100] Initial Loss: 0.1394, Training Loss: 0.0284, Initial Validation Loss: 0.1360, Validation Loss: 0.0345,V Acc: 0.8349, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.5312
Fold [4/5] Epoch [20/100] Initial Loss: 0.1394, Training Loss: 0.0056, Initial Validation Loss: 0.1360, Validation Loss: 0.0210,V Acc: 0.8991, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.7500
Fold [4/5] Epoch [30/100] Initial Loss: 0.1394, Training Loss: 0.0040, Initial Validation Loss: 0.1360, Validation Loss: 0.0201,V Acc: 0.8991, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.7500
Stopping early at Epoch (base 0): 32  Rolling back to Epoch (base 0): 27  Top Validation Acc: 0.961038961038961
Fold [5/5] Epoch [0/100] Initial Loss: 0.1461, Training Loss: 0.1461, Initial Validation Loss: 0.1330, Validation Loss: 0.1330,V Acc: 0.2500, Top 70th Acc: 0.3026, Bottom 30th Acc: 0.1250
Fold [5/5] Epoch [10/100] Initial Loss: 0.1461, Training Loss: 0.0192, Initial Validation Loss: 0.1330, Validation Loss: 0.0343,V Acc: 0.8241, Top 70th Acc: 0.9079, Bottom 30th Acc: 0.6250
Fold [5/5] Epoch [20/100] Initial Loss: 0.1461, Training Loss: 0.0058, Initial Validation Loss: 0.1330, Validation Loss: 0.0313,V Acc: 0.8333, Top 70th Acc: 0.9211, Bottom 30th Acc: 0.6250
Stopping early at Epoch (base 0): 20  Rolling back to Epoch (base 0): 15  Top Validation Acc: 0.9210526315789473
Running train_nn.py with seed 44
CUDA:False
Training samples count:  550
Training on 162 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1390, Training Loss: 0.1390, Initial Validation Loss: 0.1336, Validation Loss: 0.1336,V Acc: 0.3661, Top 70th Acc: 0.3924, Bottom 30th Acc: 0.3030
Fold [1/5] Epoch [10/100] Initial Loss: 0.1390, Training Loss: 0.0182, Initial Validation Loss: 0.1336, Validation Loss: 0.0351,V Acc: 0.7946, Top 70th Acc: 0.9114, Bottom 30th Acc: 0.5152
Stopping early at Epoch (base 0): 18  Rolling back to Epoch (base 0): 13  Top Validation Acc: 0.9113924050632911
44 0 [array([0.31960788, 0.05377633, 0.05015602, 0.19183205, 0.3846277 ],
      dtype=float32)]
Fold [2/5] Epoch [0/100] Initial Loss: 0.1381, Training Loss: 0.1381, Initial Validation Loss: 0.1378, Validation Loss: 0.1378,V Acc: 0.2523, Top 70th Acc: 0.3462, Bottom 30th Acc: 0.0303
Fold [2/5] Epoch [10/100] Initial Loss: 0.1381, Training Loss: 0.0165, Initial Validation Loss: 0.1378, Validation Loss: 0.0307,V Acc: 0.9009, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.8182
Fold [2/5] Epoch [20/100] Initial Loss: 0.1381, Training Loss: 0.0054, Initial Validation Loss: 0.1378, Validation Loss: 0.0227,V Acc: 0.9099, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.7879
Fold [2/5] Epoch [30/100] Initial Loss: 0.1381, Training Loss: 0.0042, Initial Validation Loss: 0.1378, Validation Loss: 0.0217,V Acc: 0.9099, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.7879
Fold [2/5] Epoch [40/100] Initial Loss: 0.1381, Training Loss: 0.0039, Initial Validation Loss: 0.1378, Validation Loss: 0.0216,V Acc: 0.9009, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.7273
Stopping early at Epoch (base 0): 40  Rolling back to Epoch (base 0): 35  Top Validation Acc: 0.9743589743589743
Fold [3/5] Epoch [0/100] Initial Loss: 0.1379, Training Loss: 0.1379, Initial Validation Loss: 0.1314, Validation Loss: 0.1314,V Acc: 0.2818, Top 70th Acc: 0.3377, Bottom 30th Acc: 0.1515
Fold [3/5] Epoch [10/100] Initial Loss: 0.1379, Training Loss: 0.0258, Initial Validation Loss: 0.1314, Validation Loss: 0.0468,V Acc: 0.7727, Top 70th Acc: 0.8571, Bottom 30th Acc: 0.5758
Fold [3/5] Epoch [20/100] Initial Loss: 0.1379, Training Loss: 0.0058, Initial Validation Loss: 0.1314, Validation Loss: 0.0350,V Acc: 0.8000, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.4545
Fold [3/5] Epoch [30/100] Initial Loss: 0.1379, Training Loss: 0.0043, Initial Validation Loss: 0.1314, Validation Loss: 0.0315,V Acc: 0.8545, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.5758
Fold [3/5] Epoch [40/100] Initial Loss: 0.1379, Training Loss: 0.0039, Initial Validation Loss: 0.1314, Validation Loss: 0.0297,V Acc: 0.8636, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.6061
Fold [3/5] Epoch [50/100] Initial Loss: 0.1379, Training Loss: 0.0038, Initial Validation Loss: 0.1314, Validation Loss: 0.0285,V Acc: 0.8636, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.6061
Fold [3/5] Epoch [60/100] Initial Loss: 0.1379, Training Loss: 0.0037, Initial Validation Loss: 0.1314, Validation Loss: 0.0272,V Acc: 0.8636, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 62  Rolling back to Epoch (base 0): 57  Top Validation Acc: 0.974025974025974
Fold [4/5] Epoch [0/100] Initial Loss: 0.1408, Training Loss: 0.1408, Initial Validation Loss: 0.1321, Validation Loss: 0.1321,V Acc: 0.2477, Top 70th Acc: 0.2857, Bottom 30th Acc: 0.1562
Fold [4/5] Epoch [10/100] Initial Loss: 0.1408, Training Loss: 0.0281, Initial Validation Loss: 0.1321, Validation Loss: 0.0430,V Acc: 0.8257, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.5938
Fold [4/5] Epoch [20/100] Initial Loss: 0.1408, Training Loss: 0.0056, Initial Validation Loss: 0.1321, Validation Loss: 0.0315,V Acc: 0.8532, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6250
Fold [4/5] Epoch [30/100] Initial Loss: 0.1408, Training Loss: 0.0041, Initial Validation Loss: 0.1321, Validation Loss: 0.0304,V Acc: 0.8716, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6875
Stopping early at Epoch (base 0): 36  Rolling back to Epoch (base 0): 31  Top Validation Acc: 0.961038961038961
Fold [5/5] Epoch [0/100] Initial Loss: 0.1406, Training Loss: 0.1406, Initial Validation Loss: 0.1307, Validation Loss: 0.1307,V Acc: 0.3333, Top 70th Acc: 0.4342, Bottom 30th Acc: 0.0938
Fold [5/5] Epoch [10/100] Initial Loss: 0.1406, Training Loss: 0.0201, Initial Validation Loss: 0.1307, Validation Loss: 0.0476,V Acc: 0.7593, Top 70th Acc: 0.8816, Bottom 30th Acc: 0.4688
Fold [5/5] Epoch [20/100] Initial Loss: 0.1406, Training Loss: 0.0049, Initial Validation Loss: 0.1307, Validation Loss: 0.0341,V Acc: 0.8333, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.5625
Stopping early at Epoch (base 0): 33  Rolling back to Epoch (base 0): 28  Top Validation Acc: 0.7236842105263158
Running train_nn.py with seed 55
CUDA:False
Training samples count:  550
Training on 2 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1319, Training Loss: 0.1319, Initial Validation Loss: 0.1205, Validation Loss: 0.1205,V Acc: 0.4643, Top 70th Acc: 0.5823, Bottom 30th Acc: 0.1818
Fold [1/5] Epoch [10/100] Initial Loss: 0.1319, Training Loss: 0.0810, Initial Validation Loss: 0.1205, Validation Loss: 0.0779,V Acc: 0.6250, Top 70th Acc: 0.7215, Bottom 30th Acc: 0.3939
Stopping early at Epoch (base 0): 17  Rolling back to Epoch (base 0): 12  Top Validation Acc: 0.7468354430379747
Fold [2/5] Epoch [0/100] Initial Loss: 0.1328, Training Loss: 0.1328, Initial Validation Loss: 0.1295, Validation Loss: 0.1295,V Acc: 0.3604, Top 70th Acc: 0.4487, Bottom 30th Acc: 0.1515
Fold [2/5] Epoch [10/100] Initial Loss: 0.1328, Training Loss: 0.0799, Initial Validation Loss: 0.1295, Validation Loss: 0.0822,V Acc: 0.5946, Top 70th Acc: 0.7051, Bottom 30th Acc: 0.3333
Fold [2/5] Epoch [20/100] Initial Loss: 0.1328, Training Loss: 0.0783, Initial Validation Loss: 0.1295, Validation Loss: 0.0805,V Acc: 0.5946, Top 70th Acc: 0.7308, Bottom 30th Acc: 0.2727
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.6923076923076923
Fold [3/5] Epoch [0/100] Initial Loss: 0.1378, Training Loss: 0.1378, Initial Validation Loss: 0.1272, Validation Loss: 0.1272,V Acc: 0.4182, Top 70th Acc: 0.5455, Bottom 30th Acc: 0.1212
Fold [3/5] Epoch [10/100] Initial Loss: 0.1378, Training Loss: 0.0794, Initial Validation Loss: 0.1272, Validation Loss: 0.0817,V Acc: 0.6364, Top 70th Acc: 0.7403, Bottom 30th Acc: 0.3939
Fold [3/5] Epoch [20/100] Initial Loss: 0.1378, Training Loss: 0.0771, Initial Validation Loss: 0.1272, Validation Loss: 0.0810,V Acc: 0.6455, Top 70th Acc: 0.7273, Bottom 30th Acc: 0.4545
Fold [3/5] Epoch [30/100] Initial Loss: 0.1378, Training Loss: 0.0766, Initial Validation Loss: 0.1272, Validation Loss: 0.0797,V Acc: 0.6545, Top 70th Acc: 0.7532, Bottom 30th Acc: 0.4242
Stopping early at Epoch (base 0): 34  Rolling back to Epoch (base 0): 29  Top Validation Acc: 0.7402597402597403
Fold [4/5] Epoch [0/100] Initial Loss: 0.1308, Training Loss: 0.1308, Initial Validation Loss: 0.1124, Validation Loss: 0.1124,V Acc: 0.4220, Top 70th Acc: 0.4805, Bottom 30th Acc: 0.2812
Fold [4/5] Epoch [10/100] Initial Loss: 0.1308, Training Loss: 0.0815, Initial Validation Loss: 0.1124, Validation Loss: 0.0714,V Acc: 0.6606, Top 70th Acc: 0.7403, Bottom 30th Acc: 0.4688
Fold [4/5] Epoch [20/100] Initial Loss: 0.1308, Training Loss: 0.0802, Initial Validation Loss: 0.1124, Validation Loss: 0.0706,V Acc: 0.6606, Top 70th Acc: 0.7532, Bottom 30th Acc: 0.4375
Stopping early at Epoch (base 0): 27  Rolling back to Epoch (base 0): 22  Top Validation Acc: 0.7662337662337663
Fold [5/5] Epoch [0/100] Initial Loss: 0.1358, Training Loss: 0.1358, Initial Validation Loss: 0.1285, Validation Loss: 0.1285,V Acc: 0.4259, Top 70th Acc: 0.5658, Bottom 30th Acc: 0.0938
Fold [5/5] Epoch [10/100] Initial Loss: 0.1358, Training Loss: 0.0791, Initial Validation Loss: 0.1285, Validation Loss: 0.0834,V Acc: 0.6204, Top 70th Acc: 0.7105, Bottom 30th Acc: 0.4062
Fold [5/5] Epoch [20/100] Initial Loss: 0.1358, Training Loss: 0.0775, Initial Validation Loss: 0.1285, Validation Loss: 0.0829,V Acc: 0.6204, Top 70th Acc: 0.6974, Bottom 30th Acc: 0.4375
Stopping early at Epoch (base 0): 29  Rolling back to Epoch (base 0): 24  Top Validation Acc: 0.6973684210526315
55 4 [array([0.13241947, 0.3746564 , 0.13024063, 0.22760141, 0.13508202],
      dtype=float32)]
Running train_nn.py with seed 56
CUDA:False
Training samples count:  550
Training on 2 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1365, Training Loss: 0.1365, Initial Validation Loss: 0.1294, Validation Loss: 0.1294,V Acc: 0.4732, Top 70th Acc: 0.4937, Bottom 30th Acc: 0.4242
Fold [1/5] Epoch [10/100] Initial Loss: 0.1365, Training Loss: 0.0806, Initial Validation Loss: 0.1294, Validation Loss: 0.0820,V Acc: 0.6071, Top 70th Acc: 0.7595, Bottom 30th Acc: 0.2424
Fold [1/5] Epoch [20/100] Initial Loss: 0.1365, Training Loss: 0.0788, Initial Validation Loss: 0.1294, Validation Loss: 0.0805,V Acc: 0.6071, Top 70th Acc: 0.7342, Bottom 30th Acc: 0.3030
Fold [1/5] Epoch [30/100] Initial Loss: 0.1365, Training Loss: 0.0782, Initial Validation Loss: 0.1294, Validation Loss: 0.0805,V Acc: 0.6071, Top 70th Acc: 0.7342, Bottom 30th Acc: 0.3030
Stopping early at Epoch (base 0): 30  Rolling back to Epoch (base 0): 25  Top Validation Acc: 0.7341772151898734
Fold [2/5] Epoch [0/100] Initial Loss: 0.1383, Training Loss: 0.1383, Initial Validation Loss: 0.1276, Validation Loss: 0.1276,V Acc: 0.4234, Top 70th Acc: 0.5000, Bottom 30th Acc: 0.2424
Fold [2/5] Epoch [10/100] Initial Loss: 0.1383, Training Loss: 0.0832, Initial Validation Loss: 0.1276, Validation Loss: 0.0729,V Acc: 0.6306, Top 70th Acc: 0.7179, Bottom 30th Acc: 0.4242
Fold [2/5] Epoch [20/100] Initial Loss: 0.1383, Training Loss: 0.0807, Initial Validation Loss: 0.1276, Validation Loss: 0.0727,V Acc: 0.6396, Top 70th Acc: 0.7179, Bottom 30th Acc: 0.4545
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.7051282051282052
Fold [3/5] Epoch [0/100] Initial Loss: 0.1354, Training Loss: 0.1354, Initial Validation Loss: 0.1218, Validation Loss: 0.1218,V Acc: 0.4545, Top 70th Acc: 0.5714, Bottom 30th Acc: 0.1818
Fold [3/5] Epoch [10/100] Initial Loss: 0.1354, Training Loss: 0.0798, Initial Validation Loss: 0.1218, Validation Loss: 0.0827,V Acc: 0.5727, Top 70th Acc: 0.7403, Bottom 30th Acc: 0.1818
Fold [3/5] Epoch [20/100] Initial Loss: 0.1354, Training Loss: 0.0777, Initial Validation Loss: 0.1218, Validation Loss: 0.0801,V Acc: 0.6000, Top 70th Acc: 0.7532, Bottom 30th Acc: 0.2424
Fold [3/5] Epoch [30/100] Initial Loss: 0.1354, Training Loss: 0.0773, Initial Validation Loss: 0.1218, Validation Loss: 0.0801,V Acc: 0.6000, Top 70th Acc: 0.7662, Bottom 30th Acc: 0.2121
Stopping early at Epoch (base 0): 33  Rolling back to Epoch (base 0): 28  Top Validation Acc: 0.7532467532467533
Fold [4/5] Epoch [0/100] Initial Loss: 0.1381, Training Loss: 0.1381, Initial Validation Loss: 0.1330, Validation Loss: 0.1330,V Acc: 0.4128, Top 70th Acc: 0.3766, Bottom 30th Acc: 0.5000
Fold [4/5] Epoch [10/100] Initial Loss: 0.1381, Training Loss: 0.0797, Initial Validation Loss: 0.1330, Validation Loss: 0.0817,V Acc: 0.6514, Top 70th Acc: 0.7532, Bottom 30th Acc: 0.4062
Fold [4/5] Epoch [20/100] Initial Loss: 0.1381, Training Loss: 0.0780, Initial Validation Loss: 0.1330, Validation Loss: 0.0806,V Acc: 0.6606, Top 70th Acc: 0.7403, Bottom 30th Acc: 0.4688
Fold [4/5] Epoch [30/100] Initial Loss: 0.1381, Training Loss: 0.0773, Initial Validation Loss: 0.1330, Validation Loss: 0.0797,V Acc: 0.6606, Top 70th Acc: 0.7403, Bottom 30th Acc: 0.4688
Stopping early at Epoch (base 0): 39  Rolling back to Epoch (base 0): 34  Top Validation Acc: 0.7272727272727273
56 3 [array([0.15211564, 0.311436  , 0.1438017 , 0.23208524, 0.16056143],
      dtype=float32)]
Fold [5/5] Epoch [0/100] Initial Loss: 0.1361, Training Loss: 0.1361, Initial Validation Loss: 0.1265, Validation Loss: 0.1265,V Acc: 0.3519, Top 70th Acc: 0.3553, Bottom 30th Acc: 0.3438
Fold [5/5] Epoch [10/100] Initial Loss: 0.1361, Training Loss: 0.0812, Initial Validation Loss: 0.1265, Validation Loss: 0.0787,V Acc: 0.6481, Top 70th Acc: 0.7632, Bottom 30th Acc: 0.3750
Fold [5/5] Epoch [20/100] Initial Loss: 0.1361, Training Loss: 0.0794, Initial Validation Loss: 0.1265, Validation Loss: 0.0765,V Acc: 0.6667, Top 70th Acc: 0.7632, Bottom 30th Acc: 0.4375
Fold [5/5] Epoch [30/100] Initial Loss: 0.1361, Training Loss: 0.0788, Initial Validation Loss: 0.1265, Validation Loss: 0.0758,V Acc: 0.6667, Top 70th Acc: 0.7500, Bottom 30th Acc: 0.4688
Stopping early at Epoch (base 0): 36  Rolling back to Epoch (base 0): 31  Top Validation Acc: 0.7368421052631579
Running train_nn.py with seed 57
CUDA:False
Training samples count:  550
Training on 2 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1383, Training Loss: 0.1383, Initial Validation Loss: 0.1315, Validation Loss: 0.1315,V Acc: 0.5000, Top 70th Acc: 0.5823, Bottom 30th Acc: 0.3030
Fold [4/5] Epoch [10/100] Initial Loss: 0.1409, Training Loss: 0.0412, Initial Validation Loss: 0.1301, Validation Loss: 0.0415,V Acc: 0.7706, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.4375
Fold [4/5] Epoch [20/100] Initial Loss: 0.1409, Training Loss: 0.0201, Initial Validation Loss: 0.1301, Validation Loss: 0.0313,V Acc: 0.8165, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.5312
Fold [4/5] Epoch [30/100] Initial Loss: 0.1409, Training Loss: 0.0164, Initial Validation Loss: 0.1301, Validation Loss: 0.0306,V Acc: 0.7798, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.4062
Stopping early at Epoch (base 0): 31  Rolling back to Epoch (base 0): 26  Top Validation Acc: 0.935064935064935
Fold [5/5] Epoch [0/100] Initial Loss: 0.1408, Training Loss: 0.1408, Initial Validation Loss: 0.1340, Validation Loss: 0.1340,V Acc: 0.2870, Top 70th Acc: 0.3421, Bottom 30th Acc: 0.1562
Fold [5/5] Epoch [10/100] Initial Loss: 0.1408, Training Loss: 0.0332, Initial Validation Loss: 0.1340, Validation Loss: 0.0413,V Acc: 0.8241, Top 70th Acc: 0.9211, Bottom 30th Acc: 0.5938
Stopping early at Epoch (base 0): 19  Rolling back to Epoch (base 0): 14  Top Validation Acc: 0.9210526315789473
55 4 [array([0.4854406 , 0.12104952, 0.08381777, 0.1494463 , 0.16024578],
      dtype=float32)]
Running train_nn.py with seed 56
CUDA:False
Training samples count:  550
Training on 30 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1395, Training Loss: 0.1395, Initial Validation Loss: 0.1342, Validation Loss: 0.1342,V Acc: 0.3125, Top 70th Acc: 0.3544, Bottom 30th Acc: 0.2121
Fold [1/5] Epoch [10/100] Initial Loss: 0.1395, Training Loss: 0.0319, Initial Validation Loss: 0.1342, Validation Loss: 0.0412,V Acc: 0.8036, Top 70th Acc: 0.9114, Bottom 30th Acc: 0.5455
Fold [1/5] Epoch [20/100] Initial Loss: 0.1395, Training Loss: 0.0214, Initial Validation Loss: 0.1342, Validation Loss: 0.0348,V Acc: 0.8125, Top 70th Acc: 0.9367, Bottom 30th Acc: 0.5152
Fold [1/5] Epoch [30/100] Initial Loss: 0.1395, Training Loss: 0.0174, Initial Validation Loss: 0.1342, Validation Loss: 0.0337,V Acc: 0.8214, Top 70th Acc: 0.9367, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 34  Rolling back to Epoch (base 0): 29  Top Validation Acc: 0.9240506329113924
Fold [2/5] Epoch [0/100] Initial Loss: 0.1379, Training Loss: 0.1379, Initial Validation Loss: 0.1321, Validation Loss: 0.1321,V Acc: 0.4414, Top 70th Acc: 0.5385, Bottom 30th Acc: 0.2121
Fold [2/5] Epoch [10/100] Initial Loss: 0.1379, Training Loss: 0.0390, Initial Validation Loss: 0.1321, Validation Loss: 0.0357,V Acc: 0.8378, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.6061
Fold [2/5] Epoch [20/100] Initial Loss: 0.1379, Training Loss: 0.0207, Initial Validation Loss: 0.1321, Validation Loss: 0.0235,V Acc: 0.8829, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.6970
Fold [2/5] Epoch [30/100] Initial Loss: 0.1379, Training Loss: 0.0174, Initial Validation Loss: 0.1321, Validation Loss: 0.0230,V Acc: 0.9009, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.7879
Stopping early at Epoch (base 0): 31  Rolling back to Epoch (base 0): 26  Top Validation Acc: 0.9615384615384616
Fold [3/5] Epoch [0/100] Initial Loss: 0.1396, Training Loss: 0.1396, Initial Validation Loss: 0.1328, Validation Loss: 0.1328,V Acc: 0.3182, Top 70th Acc: 0.4156, Bottom 30th Acc: 0.0909
Fold [3/5] Epoch [10/100] Initial Loss: 0.1396, Training Loss: 0.0296, Initial Validation Loss: 0.1328, Validation Loss: 0.0366,V Acc: 0.8091, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.5152
Fold [3/5] Epoch [20/100] Initial Loss: 0.1396, Training Loss: 0.0180, Initial Validation Loss: 0.1328, Validation Loss: 0.0349,V Acc: 0.8091, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.5152
Stopping early at Epoch (base 0): 21  Rolling back to Epoch (base 0): 16  Top Validation Acc: 0.935064935064935
Fold [4/5] Epoch [0/100] Initial Loss: 0.1395, Training Loss: 0.1395, Initial Validation Loss: 0.1372, Validation Loss: 0.1372,V Acc: 0.2569, Top 70th Acc: 0.2468, Bottom 30th Acc: 0.2812
Fold [4/5] Epoch [10/100] Initial Loss: 0.1395, Training Loss: 0.0400, Initial Validation Loss: 0.1372, Validation Loss: 0.0468,V Acc: 0.7982, Top 70th Acc: 0.8961, Bottom 30th Acc: 0.5625
Fold [4/5] Epoch [20/100] Initial Loss: 0.1395, Training Loss: 0.0197, Initial Validation Loss: 0.1372, Validation Loss: 0.0329,V Acc: 0.8349, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.5625
Fold [4/5] Epoch [30/100] Initial Loss: 0.1395, Training Loss: 0.0165, Initial Validation Loss: 0.1372, Validation Loss: 0.0329,V Acc: 0.8257, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.5312
Stopping early at Epoch (base 0): 37  Rolling back to Epoch (base 0): 32  Top Validation Acc: 0.948051948051948
56 3 [array([0.57363063, 0.20115556, 0.03684726, 0.06787682, 0.12048974],
      dtype=float32)]
Fold [5/5] Epoch [0/100] Initial Loss: 0.1406, Training Loss: 0.1406, Initial Validation Loss: 0.1334, Validation Loss: 0.1334,V Acc: 0.2685, Top 70th Acc: 0.2895, Bottom 30th Acc: 0.2188
Fold [5/5] Epoch [10/100] Initial Loss: 0.1406, Training Loss: 0.0448, Initial Validation Loss: 0.1334, Validation Loss: 0.0556,V Acc: 0.7315, Top 70th Acc: 0.8289, Bottom 30th Acc: 0.5000
Fold [5/5] Epoch [20/100] Initial Loss: 0.1406, Training Loss: 0.0190, Initial Validation Loss: 0.1334, Validation Loss: 0.0376,V Acc: 0.7963, Top 70th Acc: 0.9079, Bottom 30th Acc: 0.5312
Fold [5/5] Epoch [30/100] Initial Loss: 0.1406, Training Loss: 0.0160, Initial Validation Loss: 0.1334, Validation Loss: 0.0368,V Acc: 0.8241, Top 70th Acc: 0.9211, Bottom 30th Acc: 0.5938
Stopping early at Epoch (base 0): 31  Rolling back to Epoch (base 0): 26  Top Validation Acc: 0.9210526315789473
Running train_nn.py with seed 57
CUDA:False
Training samples count:  550
Training on 30 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1383, Training Loss: 0.1383, Initial Validation Loss: 0.1318, Validation Loss: 0.1318,V Acc: 0.3482, Top 70th Acc: 0.3418, Bottom 30th Acc: 0.3636
Fold [1/5] Epoch [10/100] Initial Loss: 0.1383, Training Loss: 0.0425, Initial Validation Loss: 0.1318, Validation Loss: 0.0524,V Acc: 0.7411, Top 70th Acc: 0.8354, Bottom 30th Acc: 0.5152
Fold [1/5] Epoch [20/100] Initial Loss: 0.1383, Training Loss: 0.0230, Initial Validation Loss: 0.1318, Validation Loss: 0.0390,V Acc: 0.7857, Top 70th Acc: 0.8987, Bottom 30th Acc: 0.5152
Fold [1/5] Epoch [30/100] Initial Loss: 0.1383, Training Loss: 0.0179, Initial Validation Loss: 0.1318, Validation Loss: 0.0356,V Acc: 0.7946, Top 70th Acc: 0.9367, Bottom 30th Acc: 0.4545
Stopping early at Epoch (base 0): 38  Rolling back to Epoch (base 0): 33  Top Validation Acc: 0.9240506329113924
Fold [2/5] Epoch [0/100] Initial Loss: 0.1398, Training Loss: 0.1398, Initial Validation Loss: 0.1355, Validation Loss: 0.1355,V Acc: 0.2883, Top 70th Acc: 0.3205, Bottom 30th Acc: 0.2121
Fold [2/5] Epoch [10/100] Initial Loss: 0.1398, Training Loss: 0.0306, Initial Validation Loss: 0.1355, Validation Loss: 0.0374,V Acc: 0.8378, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.5758
Fold [2/5] Epoch [20/100] Initial Loss: 0.1398, Training Loss: 0.0182, Initial Validation Loss: 0.1355, Validation Loss: 0.0310,V Acc: 0.8468, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 28  Rolling back to Epoch (base 0): 23  Top Validation Acc: 0.9358974358974359
Fold [3/5] Epoch [0/100] Initial Loss: 0.1389, Training Loss: 0.1389, Initial Validation Loss: 0.1293, Validation Loss: 0.1293,V Acc: 0.4000, Top 70th Acc: 0.4675, Bottom 30th Acc: 0.2424
Fold [3/5] Epoch [10/100] Initial Loss: 0.1389, Training Loss: 0.0386, Initial Validation Loss: 0.1293, Validation Loss: 0.0337,V Acc: 0.8273, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.5758
Fold [3/5] Epoch [20/100] Initial Loss: 0.1389, Training Loss: 0.0202, Initial Validation Loss: 0.1293, Validation Loss: 0.0232,V Acc: 0.8364, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.961038961038961
57 2 [array([0.63608116, 0.08766422, 0.03913246, 0.05950008, 0.17762202],
      dtype=float32)]
Fold [4/5] Epoch [0/100] Initial Loss: 0.1387, Training Loss: 0.1387, Initial Validation Loss: 0.1322, Validation Loss: 0.1322,V Acc: 0.3303, Top 70th Acc: 0.4026, Bottom 30th Acc: 0.1562 22  Top Validation Acc: 0.974025974025974
Fold [4/5] Epoch [0/100] Initial Loss: 0.1323, Training Loss: 0.1323, Initial Validation Loss: 0.1149, Validation Loss: 0.1149,V Acc: 0.3945, Top 70th Acc: 0.4416, Bottom 30th Acc: 0.2812
Fold [4/5] Epoch [10/100] Initial Loss: 0.1323, Training Loss: 0.0327, Initial Validation Loss: 0.1149, Validation Loss: 0.0286,V Acc: 0.8807, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.7500
Fold [4/5] Epoch [20/100] Initial Loss: 0.1323, Training Loss: 0.0176, Initial Validation Loss: 0.1149, Validation Loss: 0.0244,V Acc: 0.8624, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.6250
Fold [4/5] Epoch [30/100] Initial Loss: 0.1323, Training Loss: 0.0149, Initial Validation Loss: 0.1149, Validation Loss: 0.0261,V Acc: 0.8440, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.5938
Stopping early at Epoch (base 0): 30  Rolling back to Epoch (base 0): 25  Top Validation Acc: 0.948051948051948
77 3 [array([0.7305276 , 0.01765766, 0.04649207, 0.11212492, 0.09319775],
      dtype=float32)]
Fold [5/5] Epoch [0/100] Initial Loss: 0.1377, Training Loss: 0.1377, Initial Validation Loss: 0.1283, Validation Loss: 0.1283,V Acc: 0.3889, Top 70th Acc: 0.4079, Bottom 30th Acc: 0.3438
Fold [5/5] Epoch [10/100] Initial Loss: 0.1377, Training Loss: 0.0284, Initial Validation Loss: 0.1283, Validation Loss: 0.0381,V Acc: 0.8426, Top 70th Acc: 0.9079, Bottom 30th Acc: 0.6875
Fold [5/5] Epoch [20/100] Initial Loss: 0.1377, Training Loss: 0.0149, Initial Validation Loss: 0.1283, Validation Loss: 0.0335,V Acc: 0.8611, Top 70th Acc: 0.9211, Bottom 30th Acc: 0.7188
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.8947368421052632
Running train_nn.py with seed 78
CUDA:False
Training samples count:  550
Training on 21 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1328, Training Loss: 0.1328, Initial Validation Loss: 0.1263, Validation Loss: 0.1263,V Acc: 0.4018, Top 70th Acc: 0.5063, Bottom 30th Acc: 0.1515
Fold [1/5] Epoch [10/100] Initial Loss: 0.1328, Training Loss: 0.0290, Initial Validation Loss: 0.1263, Validation Loss: 0.0254,V Acc: 0.8839, Top 70th Acc: 0.9747, Bottom 30th Acc: 0.6667
Fold [1/5] Epoch [20/100] Initial Loss: 0.1328, Training Loss: 0.0186, Initial Validation Loss: 0.1263, Validation Loss: 0.0193,V Acc: 0.9196, Top 70th Acc: 0.9747, Bottom 30th Acc: 0.7879
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.9746835443037974
Fold [2/5] Epoch [0/100] Initial Loss: 0.1252, Training Loss: 0.1252, Initial Validation Loss: 0.1048, Validation Loss: 0.1048,V Acc: 0.6306, Top 70th Acc: 0.6923, Bottom 30th Acc: 0.4848
Fold [2/5] Epoch [10/100] Initial Loss: 0.1252, Training Loss: 0.0217, Initial Validation Loss: 0.1048, Validation Loss: 0.0262,V Acc: 0.8739, Top 70th Acc: 0.9872, Bottom 30th Acc: 0.6061
Fold [2/5] Epoch [20/100] Initial Loss: 0.1252, Training Loss: 0.0177, Initial Validation Loss: 0.1048, Validation Loss: 0.0333,V Acc: 0.8468, Top 70th Acc: 0.9872, Bottom 30th Acc: 0.5152
Stopping early at Epoch (base 0): 22  Rolling back to Epoch (base 0): 17  Top Validation Acc: 0.9743589743589743
Fold [3/5] Epoch [0/100] Initial Loss: 0.1326, Training Loss: 0.1326, Initial Validation Loss: 0.1222, Validation Loss: 0.1222,V Acc: 0.4545, Top 70th Acc: 0.5584, Bottom 30th Acc: 0.2121
Fold [3/5] Epoch [10/100] Initial Loss: 0.1326, Training Loss: 0.0253, Initial Validation Loss: 0.1222, Validation Loss: 0.0306,V Acc: 0.8818, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.6667
Fold [3/5] Epoch [20/100] Initial Loss: 0.1326, Training Loss: 0.0159, Initial Validation Loss: 0.1222, Validation Loss: 0.0260,V Acc: 0.9091, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.8182
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.935064935064935
Fold [4/5] Epoch [0/100] Initial Loss: 0.1316, Training Loss: 0.1316, Initial Validation Loss: 0.1214, Validation Loss: 0.1214,V Acc: 0.4862, Top 70th Acc: 0.6104, Bottom 30th Acc: 0.1875
Fold [4/5] Epoch [10/100] Initial Loss: 0.1316, Training Loss: 0.0235, Initial Validation Loss: 0.1214, Validation Loss: 0.0330,V Acc: 0.8532, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.6875
Stopping early at Epoch (base 0): 16  Rolling back to Epoch (base 0): 11  Top Validation Acc: 0.9090909090909091
Fold [5/5] Epoch [0/100] Initial Loss: 0.1351, Training Loss: 0.1351, Initial Validation Loss: 0.1159, Validation Loss: 0.1159,V Acc: 0.4722, Top 70th Acc: 0.6053, Bottom 30th Acc: 0.1562
Fold [5/5] Epoch [10/100] Initial Loss: 0.1351, Training Loss: 0.0205, Initial Validation Loss: 0.1159, Validation Loss: 0.0292,V Acc: 0.8148, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.4688
Fold [5/5] Epoch [20/100] Initial Loss: 0.1351, Training Loss: 0.0163, Initial Validation Loss: 0.1159, Validation Loss: 0.0241,V Acc: 0.8611, Top 70th Acc: 0.9737, Bottom 30th Acc: 0.5938
Stopping early at Epoch (base 0): 29  Rolling back to Epoch (base 0): 24  Top Validation Acc: 0.9736842105263158
78 4 [array([0.7165087 , 0.02465479, 0.02821779, 0.12328707, 0.10733157],
      dtype=float32)]
Running train_nn.py with seed 79
CUDA:False
Training samples count:  550
Training on 21 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1268, Training Loss: 0.1268, Initial Validation Loss: 0.1129, Validation Loss: 0.1129,V Acc: 0.4732, Top 70th Acc: 0.5696, Bottom 30th Acc: 0.2424
Fold [1/5] Epoch [10/100] Initial Loss: 0.1268, Training Loss: 0.0261, Initial Validation Loss: 0.1129, Validation Loss: 0.0320,V Acc: 0.8214, Top 70th Acc: 0.9620, Bottom 30th Acc: 0.4848
Fold [1/5] Epoch [20/100] Initial Loss: 0.1268, Training Loss: 0.0176, Initial Validation Loss: 0.1129, Validation Loss: 0.0315,V Acc: 0.8571, Top 70th Acc: 0.9367, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 27  Rolling back to Epoch (base 0): 22  Top Validation Acc: 0.9620253164556962
Fold [2/5] Epoch [0/100] Initial Loss: 0.1320, Training Loss: 0.1320, Initial Validation Loss: 0.1264, Validation Loss: 0.1264,V Acc: 0.3423, Top 70th Acc: 0.3590, Bottom 30th Acc: 0.3030
Fold [2/5] Epoch [10/100] Initial Loss: 0.1320, Training Loss: 0.0228, Initial Validation Loss: 0.1264, Validation Loss: 0.0265,V Acc: 0.9009, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.7576
Fold [2/5] Epoch [20/100] Initial Loss: 0.1320, Training Loss: 0.0169, Initial Validation Loss: 0.1264, Validation Loss: 0.0256,V Acc: 0.8649, Top 70th Acc: 1.0000, Bottom 30th Acc: 0.5455
Fold [2/5] Epoch [30/100] Initial Loss: 0.1320, Training Loss: 0.0130, Initial Validation Loss: 0.1264, Validation Loss: 0.0236,V Acc: 0.8739, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 31  Rolling back to Epoch (base 0): 26  Top Validation Acc: 0.9871794871794872
Fold [3/5] Epoch [0/100] Initial Loss: 0.1402, Training Loss: 0.1402, Initial Validation Loss: 0.1297, Validation Loss: 0.1297,V Acc: 0.4182, Top 70th Acc: 0.5325, Bottom 30th Acc: 0.1515
Fold [3/5] Epoch [10/100] Initial Loss: 0.1402, Training Loss: 0.0245, Initial Validation Loss: 0.1297, Validation Loss: 0.0273,V Acc: 0.8909, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.7576
Stopping early at Epoch (base 0): 19  Rolling back to Epoch (base 0): 14  Top Validation Acc: 0.948051948051948
79 2 [array([0.7127338 , 0.03590126, 0.04259449, 0.11546163, 0.09330887],
      dtype=float32)]
Fold [4/5] Epoch [0/100] Initial Loss: 0.1347, Training Loss: 0.1347, Initial Validation Loss: 0.1152, Validation Loss: 0.1152,V Acc: 0.4128, Top 70th Acc: 0.5325, Bottom 30th Acc: 0.1250
Fold [4/5] Epoch [10/100] Initial Loss: 0.1347, Training Loss: 0.0253, Initial Validation Loss: 0.1152, Validation Loss: 0.0303,V Acc: 0.8440, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.6562
Fold [4/5] Epoch [20/100] Initial Loss: 0.1347, Training Loss: 0.0174, Initial Validation Loss: 0.1152, Validation Loss: 0.0282,V Acc: 0.8349, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.5312
Stopping early at Epoch (base 0): 21  Rolling back to Epoch (base 0): 16  Top Validation Acc: 0.961038961038961
Fold [5/5] Epoch [0/100] Initial Loss: 0.1301, Training Loss: 0.1301, Initial Validation Loss: 0.1141, Validation Loss: 0.1141,V Acc: 0.4630, Top 70th Acc: 0.5789, Bottom 30th Acc: 0.1875
Fold [5/5] Epoch [10/100] Initial Loss: 0.1301, Training Loss: 0.0221, Initial Validation Loss: 0.1141, Validation Loss: 0.0306,V Acc: 0.8704, Top 70th Acc: 0.9211, Bottom 30th Acc: 0.7500
Fold [4/5] Epoch [10/100] Initial Loss: 0.1415, Training Loss: 0.0402, Initial Validation Loss: 0.1344, Validation Loss: 0.0394,V Acc: 0.8257, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.5000
Fold [4/5] Epoch [20/100] Initial Loss: 0.1415, Training Loss: 0.0163, Initial Validation Loss: 0.1344, Validation Loss: 0.0253,V Acc: 0.9083, Top 70th Acc: 0.9870, Bottom 30th Acc: 0.7188
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.987012987012987
59 3 [array([0.69081527, 0.02655107, 0.08368073, 0.09893971, 0.1000132 ],
      dtype=float32)]
Fold [5/5] Epoch [0/100] Initial Loss: 0.1400, Training Loss: 0.1400, Initial Validation Loss: 0.1314, Validation Loss: 0.1314,V Acc: 0.2593, Top 70th Acc: 0.3289, Bottom 30th Acc: 0.0938
Fold [5/5] Epoch [10/100] Initial Loss: 0.1400, Training Loss: 0.0217, Initial Validation Loss: 0.1314, Validation Loss: 0.0348,V Acc: 0.8056, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.5000
Fold [5/5] Epoch [20/100] Initial Loss: 0.1400, Training Loss: 0.0124, Initial Validation Loss: 0.1314, Validation Loss: 0.0287,V Acc: 0.8333, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.5625
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.9342105263157895
Running train_nn.py with seed 60
CUDA:False
Training samples count:  550
Training on 40 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1386, Training Loss: 0.1386, Initial Validation Loss: 0.1335, Validation Loss: 0.1335,V Acc: 0.2768, Top 70th Acc: 0.3544, Bottom 30th Acc: 0.0909
Fold [1/5] Epoch [10/100] Initial Loss: 0.1386, Training Loss: 0.0388, Initial Validation Loss: 0.1335, Validation Loss: 0.0482,V Acc: 0.7589, Top 70th Acc: 0.8481, Bottom 30th Acc: 0.5455
Fold [1/5] Epoch [20/100] Initial Loss: 0.1386, Training Loss: 0.0211, Initial Validation Loss: 0.1335, Validation Loss: 0.0338,V Acc: 0.8304, Top 70th Acc: 0.9241, Bottom 30th Acc: 0.6061
Fold [1/5] Epoch [30/100] Initial Loss: 0.1386, Training Loss: 0.0133, Initial Validation Loss: 0.1335, Validation Loss: 0.0268,V Acc: 0.8661, Top 70th Acc: 0.9494, Bottom 30th Acc: 0.6667
Fold [1/5] Epoch [40/100] Initial Loss: 0.1386, Training Loss: 0.0110, Initial Validation Loss: 0.1335, Validation Loss: 0.0262,V Acc: 0.8661, Top 70th Acc: 0.9494, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 41  Rolling back to Epoch (base 0): 36  Top Validation Acc: 0.9493670886075949
Fold [2/5] Epoch [0/100] Initial Loss: 0.1401, Training Loss: 0.1401, Initial Validation Loss: 0.1336, Validation Loss: 0.1336,V Acc: 0.3243, Top 70th Acc: 0.4231, Bottom 30th Acc: 0.0909
Fold [2/5] Epoch [10/100] Initial Loss: 0.1401, Training Loss: 0.0297, Initial Validation Loss: 0.1336, Validation Loss: 0.0485,V Acc: 0.7477, Top 70th Acc: 0.8718, Bottom 30th Acc: 0.4545
Fold [2/5] Epoch [20/100] Initial Loss: 0.1401, Training Loss: 0.0137, Initial Validation Loss: 0.1336, Validation Loss: 0.0358,V Acc: 0.8378, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.6061
Fold [2/5] Epoch [30/100] Initial Loss: 0.1401, Training Loss: 0.0116, Initial Validation Loss: 0.1336, Validation Loss: 0.0356,V Acc: 0.8198, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 31  Rolling back to Epoch (base 0): 26  Top Validation Acc: 0.9230769230769231
Fold [3/5] Epoch [0/100] Initial Loss: 0.1448, Training Loss: 0.1448, Initial Validation Loss: 0.1330, Validation Loss: 0.1330,V Acc: 0.3727, Top 70th Acc: 0.4416, Bottom 30th Acc: 0.2121
Fold [3/5] Epoch [10/100] Initial Loss: 0.1448, Training Loss: 0.0233, Initial Validation Loss: 0.1330, Validation Loss: 0.0314,V Acc: 0.8182, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.5455
Fold [3/5] Epoch [20/100] Initial Loss: 0.1448, Training Loss: 0.0126, Initial Validation Loss: 0.1330, Validation Loss: 0.0272,V Acc: 0.8364, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.935064935064935
Fold [4/5] Epoch [0/100] Initial Loss: 0.1382, Training Loss: 0.1382, Initial Validation Loss: 0.1338, Validation Loss: 0.1338,V Acc: 0.2936, Top 70th Acc: 0.3636, Bottom 30th Acc: 0.1250
Fold [4/5] Epoch [10/100] Initial Loss: 0.1382, Training Loss: 0.0303, Initial Validation Loss: 0.1338, Validation Loss: 0.0423,V Acc: 0.8257, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.5938
Fold [4/5] Epoch [20/100] Initial Loss: 0.1382, Training Loss: 0.0146, Initial Validation Loss: 0.1338, Validation Loss: 0.0316,V Acc: 0.8440, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.5312
Fold [4/5] Epoch [30/100] Initial Loss: 0.1382, Training Loss: 0.0121, Initial Validation Loss: 0.1338, Validation Loss: 0.0323,V Acc: 0.8349, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.5312
Stopping early at Epoch (base 0): 34  Rolling back to Epoch (base 0): 29  Top Validation Acc: 0.948051948051948
Fold [5/5] Epoch [0/100] Initial Loss: 0.1437, Training Loss: 0.1437, Initial Validation Loss: 0.1320, Validation Loss: 0.1320,V Acc: 0.3148, Top 70th Acc: 0.3421, Bottom 30th Acc: 0.2500
Fold [5/5] Epoch [10/100] Initial Loss: 0.1437, Training Loss: 0.0436, Initial Validation Loss: 0.1320, Validation Loss: 0.0418,V Acc: 0.8148, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.4688
Fold [5/5] Epoch [20/100] Initial Loss: 0.1437, Training Loss: 0.0161, Initial Validation Loss: 0.1320, Validation Loss: 0.0203,V Acc: 0.8889, Top 70th Acc: 0.9868, Bottom 30th Acc: 0.6562
Fold [5/5] Epoch [30/100] Initial Loss: 0.1437, Training Loss: 0.0125, Initial Validation Loss: 0.1320, Validation Loss: 0.0211,V Acc: 0.8981, Top 70th Acc: 0.9737, Bottom 30th Acc: 0.7188
Stopping early at Epoch (base 0): 36  Rolling back to Epoch (base 0): 31  Top Validation Acc: 0.9736842105263158
60 4 [array([0.5533499 , 0.03968921, 0.09318289, 0.16678864, 0.14698923],
      dtype=float32)]
Running train_nn.py with seed 61
CUDA:False
Training samples count:  550
Training on 40 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1377, Training Loss: 0.1377, Initial Validation Loss: 0.1334, Validation Loss: 0.1334,V Acc: 0.2679, Top 70th Acc: 0.3418, Bottom 30th Acc: 0.0909
Fold [1/5] Epoch [10/100] Initial Loss: 0.1377, Training Loss: 0.0219, Initial Validation Loss: 0.1334, Validation Loss: 0.0285,V Acc: 0.8393, Top 70th Acc: 0.9620, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 18  Rolling back to Epoch (base 0): 13  Top Validation Acc: 0.9620253164556962
Fold [2/5] Epoch [0/100] Initial Loss: 0.1403, Training Loss: 0.1403, Initial Validation Loss: 0.1323, Validation Loss: 0.1323,V Acc: 0.3694, Top 70th Acc: 0.3718, Bottom 30th Acc: 0.3636
Fold [2/5] Epoch [10/100] Initial Loss: 0.1403, Training Loss: 0.0362, Initial Validation Loss: 0.1323, Validation Loss: 0.0525,V Acc: 0.7117, Top 70th Acc: 0.8590, Bottom 30th Acc: 0.3636
Fold [2/5] Epoch [20/100] Initial Loss: 0.1403, Training Loss: 0.0154, Initial Validation Loss: 0.1323, Validation Loss: 0.0360,V Acc: 0.8468, Top 70th Acc: 0.8974, Bottom 30th Acc: 0.7273
Fold [2/5] Epoch [30/100] Initial Loss: 0.1403, Training Loss: 0.0111, Initial Validation Loss: 0.1323, Validation Loss: 0.0322,V Acc: 0.8378, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.6667
Fold [2/5] Epoch [40/100] Initial Loss: 0.1403, Training Loss: 0.0101, Initial Validation Loss: 0.1323, Validation Loss: 0.0310,V Acc: 0.8468, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.6970
Fold [2/5] Epoch [50/100] Initial Loss: 0.1403, Training Loss: 0.0095, Initial Validation Loss: 0.1323, Validation Loss: 0.0313,V Acc: 0.8378, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 56  Rolling back to Epoch (base 0): 51  Top Validation Acc: 0.9102564102564102
Fold [3/5] Epoch [0/100] Initial Loss: 0.1393, Training Loss: 0.1393, Initial Validation Loss: 0.1338, Validation Loss: 0.1338,V Acc: 0.2636, Top 70th Acc: 0.2987, Bottom 30th Acc: 0.1818
Fold [3/5] Epoch [10/100] Initial Loss: 0.1393, Training Loss: 0.0281, Initial Validation Loss: 0.1338, Validation Loss: 0.0413,V Acc: 0.8182, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.6061
Fold [3/5] Epoch [20/100] Initial Loss: 0.1393, Training Loss: 0.0143, Initial Validation Loss: 0.1338, Validation Loss: 0.0329,V Acc: 0.8182, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.5152/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
 18  Top Validation Acc: 0.9102564102564102
Fold [3/5] Epoch [0/100] Initial Loss: 0.1448, Training Loss: 0.1448, Initial Validation Loss: 0.1309, Validation Loss: 0.1309,V Acc: 0.2636, Top 70th Acc: 0.3636, Bottom 30th Acc: 0.0303
Fold [3/5] Epoch [10/100] Initial Loss: 0.1448, Training Loss: 0.0332, Initial Validation Loss: 0.1309, Validation Loss: 0.0312,V Acc: 0.8818, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.7879
Fold [3/5] Epoch [20/100] Initial Loss: 0.1448, Training Loss: 0.0242, Initial Validation Loss: 0.1309, Validation Loss: 0.0266,V Acc: 0.8727, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.7576
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.935064935064935
57 2 [array([0.20793347, 0.18078573, 0.2025305 , 0.2721158 , 0.13663451],
      dtype=float32)]
Fold [4/5] Epoch [0/100] Initial Loss: 0.1376, Training Loss: 0.1376, Initial Validation Loss: 0.1296, Validation Loss: 0.1296,V Acc: 0.3853, Top 70th Acc: 0.4935, Bottom 30th Acc: 0.1250
Fold [4/5] Epoch [10/100] Initial Loss: 0.1376, Training Loss: 0.0328, Initial Validation Loss: 0.1296, Validation Loss: 0.0342,V Acc: 0.8440, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.6875
Stopping early at Epoch (base 0): 19  Rolling back to Epoch (base 0): 14  Top Validation Acc: 0.9090909090909091
Fold [5/5] Epoch [0/100] Initial Loss: 0.1406, Training Loss: 0.1406, Initial Validation Loss: 0.1364, Validation Loss: 0.1364,V Acc: 0.3426, Top 70th Acc: 0.3158, Bottom 30th Acc: 0.4062
Fold [5/5] Epoch [10/100] Initial Loss: 0.1406, Training Loss: 0.0410, Initial Validation Loss: 0.1364, Validation Loss: 0.0548,V Acc: 0.7315, Top 70th Acc: 0.8684, Bottom 30th Acc: 0.4062
Fold [5/5] Epoch [20/100] Initial Loss: 0.1406, Training Loss: 0.0240, Initial Validation Loss: 0.1364, Validation Loss: 0.0417,V Acc: 0.8148, Top 70th Acc: 0.9079, Bottom 30th Acc: 0.5938
Fold [5/5] Epoch [30/100] Initial Loss: 0.1406, Training Loss: 0.0215, Initial Validation Loss: 0.1364, Validation Loss: 0.0389,V Acc: 0.8148, Top 70th Acc: 0.9211, Bottom 30th Acc: 0.5625
Stopping early at Epoch (base 0): 32  Rolling back to Epoch (base 0): 27  Top Validation Acc: 0.9210526315789473
Running train_nn.py with seed 58
CUDA:False
Training samples count:  550
Training on 20 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1359, Training Loss: 0.1359, Initial Validation Loss: 0.1318, Validation Loss: 0.1318,V Acc: 0.4196, Top 70th Acc: 0.5063, Bottom 30th Acc: 0.2121
Fold [1/5] Epoch [10/100] Initial Loss: 0.1359, Training Loss: 0.0337, Initial Validation Loss: 0.1318, Validation Loss: 0.0464,V Acc: 0.7946, Top 70th Acc: 0.8987, Bottom 30th Acc: 0.5455
Fold [1/5] Epoch [20/100] Initial Loss: 0.1359, Training Loss: 0.0235, Initial Validation Loss: 0.1318, Validation Loss: 0.0423,V Acc: 0.8036, Top 70th Acc: 0.9367, Bottom 30th Acc: 0.4848
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.9240506329113924
Fold [2/5] Epoch [0/100] Initial Loss: 0.1405, Training Loss: 0.1405, Initial Validation Loss: 0.1326, Validation Loss: 0.1326,V Acc: 0.2703, Top 70th Acc: 0.3462, Bottom 30th Acc: 0.0909
Fold [2/5] Epoch [10/100] Initial Loss: 0.1405, Training Loss: 0.0343, Initial Validation Loss: 0.1326, Validation Loss: 0.0337,V Acc: 0.8468, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.6364
Fold [2/5] Epoch [20/100] Initial Loss: 0.1405, Training Loss: 0.0245, Initial Validation Loss: 0.1326, Validation Loss: 0.0318,V Acc: 0.8198, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.9230769230769231
Fold [3/5] Epoch [0/100] Initial Loss: 0.1405, Training Loss: 0.1405, Initial Validation Loss: 0.1323, Validation Loss: 0.1323,V Acc: 0.3364, Top 70th Acc: 0.4286, Bottom 30th Acc: 0.1212
Fold [3/5] Epoch [10/100] Initial Loss: 0.1405, Training Loss: 0.0434, Initial Validation Loss: 0.1323, Validation Loss: 0.0448,V Acc: 0.7909, Top 70th Acc: 0.8701, Bottom 30th Acc: 0.6061
Fold [3/5] Epoch [20/100] Initial Loss: 0.1405, Training Loss: 0.0243, Initial Validation Loss: 0.1323, Validation Loss: 0.0327,V Acc: 0.8455, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.6364
Fold [3/5] Epoch [30/100] Initial Loss: 0.1405, Training Loss: 0.0219, Initial Validation Loss: 0.1323, Validation Loss: 0.0322,V Acc: 0.8364, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 33  Rolling back to Epoch (base 0): 28  Top Validation Acc: 0.922077922077922
Fold [4/5] Epoch [0/100] Initial Loss: 0.1410, Training Loss: 0.1410, Initial Validation Loss: 0.1331, Validation Loss: 0.1331,V Acc: 0.3853, Top 70th Acc: 0.4416, Bottom 30th Acc: 0.2500
Fold [4/5] Epoch [10/100] Initial Loss: 0.1410, Training Loss: 0.0332, Initial Validation Loss: 0.1331, Validation Loss: 0.0350,V Acc: 0.8440, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.5625
Fold [4/5] Epoch [20/100] Initial Loss: 0.1410, Training Loss: 0.0243, Initial Validation Loss: 0.1331, Validation Loss: 0.0339,V Acc: 0.8257, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.5625
Stopping early at Epoch (base 0): 22  Rolling back to Epoch (base 0): 17  Top Validation Acc: 0.948051948051948
58 3 [array([0.35669953, 0.08746593, 0.18645303, 0.16635932, 0.20302229],
      dtype=float32)]
Fold [5/5] Epoch [0/100] Initial Loss: 0.1398, Training Loss: 0.1398, Initial Validation Loss: 0.1318, Validation Loss: 0.1318,V Acc: 0.3241, Top 70th Acc: 0.3421, Bottom 30th Acc: 0.2812
Fold [5/5] Epoch [10/100] Initial Loss: 0.1398, Training Loss: 0.0347, Initial Validation Loss: 0.1318, Validation Loss: 0.0384,V Acc: 0.8241, Top 70th Acc: 0.8947, Bottom 30th Acc: 0.6562
Fold [5/5] Epoch [20/100] Initial Loss: 0.1398, Training Loss: 0.0244, Initial Validation Loss: 0.1318, Validation Loss: 0.0297,V Acc: 0.8704, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.6562
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.9473684210526315
Running train_nn.py with seed 59
CUDA:False
Training samples count:  550
Training on 20 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1395, Training Loss: 0.1395, Initial Validation Loss: 0.1374, Validation Loss: 0.1374,V Acc: 0.2589, Top 70th Acc: 0.3038, Bottom 30th Acc: 0.1515
Fold [1/5] Epoch [10/100] Initial Loss: 0.1395, Training Loss: 0.0379, Initial Validation Loss: 0.1374, Validation Loss: 0.0516,V Acc: 0.7589, Top 70th Acc: 0.8481, Bottom 30th Acc: 0.5455
Fold [1/5] Epoch [20/100] Initial Loss: 0.1395, Training Loss: 0.0258, Initial Validation Loss: 0.1374, Validation Loss: 0.0417,V Acc: 0.8036, Top 70th Acc: 0.8861, Bottom 30th Acc: 0.6061
Fold [1/5] Epoch [30/100] Initial Loss: 0.1395, Training Loss: 0.0214, Initial Validation Loss: 0.1374, Validation Loss: 0.0388,V Acc: 0.7857, Top 70th Acc: 0.8861, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 39  Rolling back to Epoch (base 0): 34  Top Validation Acc: 0.8607594936708861
Fold [2/5] Epoch [0/100] Initial Loss: 0.1400, Training Loss: 0.1400, Initial Validation Loss: 0.1346, Validation Loss: 0.1346,V Acc: 0.3153, Top 70th Acc: 0.3718, Bottom 30th Acc: 0.1818
Fold [2/5] Epoch [10/100] Initial Loss: 0.1400, Training Loss: 0.0346, Initial Validation Loss: 0.1346, Validation Loss: 0.0453,V Acc: 0.7928, Top 70th Acc: 0.8718, Bottom 30th Acc: 0.6061
Fold [2/5] Epoch [20/100] Initial Loss: 0.1400, Training Loss: 0.0228, Initial Validation Loss: 0.1346, Validation Loss: 0.0390,V Acc: 0.8018, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.5455
Fold [2/5] Epoch [30/100] Initial Loss: 0.1400, Training Loss: 0.0210, Initial Validation Loss: 0.1346, Validation Loss: 0.0375,V Acc: 0.8108, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 35  Rolling back to Epoch (base 0): 30  Top Validation Acc: 0.8974358974358975
Fold [3/5] Epoch [0/100] Initial Loss: 0.1403, Training Loss: 0.1403, Initial Validation Loss: 0.1321, Validation Loss: 0.1321,V Acc: 0.3091, Top 70th Acc: 0.3506, Bottom 30th Acc: 0.2121
Fold [3/5] Epoch [10/100] Initial Loss: 0.1403, Training Loss: 0.0388, Initial Validation Loss: 0.1321, Validation Loss: 0.0402,V Acc: 0.7909, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.4848
Fold [3/5] Epoch [20/100] Initial Loss: 0.1403, Training Loss: 0.0249, Initial Validation Loss: 0.1321, Validation Loss: 0.0340,V Acc: 0.8364, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.6364
Fold [1/5] Epoch [10/100] Initial Loss: 0.1383, Training Loss: 0.0817, Initial Validation Loss: 0.1315, Validation Loss: 0.0795,V Acc: 0.5982, Top 70th Acc: 0.7215, Bottom 30th Acc: 0.3030
Fold [1/5] Epoch [20/100] Initial Loss: 0.1383, Training Loss: 0.0784, Initial Validation Loss: 0.1315, Validation Loss: 0.0778,V Acc: 0.6339, Top 70th Acc: 0.7342, Bottom 30th Acc: 0.3939
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.7341772151898734
Fold [2/5] Epoch [0/100] Initial Loss: 0.1376, Training Loss: 0.1376, Initial Validation Loss: 0.1304, Validation Loss: 0.1304,V Acc: 0.3243, Top 70th Acc: 0.3590, Bottom 30th Acc: 0.2424
Stopping early at Epoch (base 0): 8  Rolling back to Epoch (base 0): 3  Top Validation Acc: 0.6282051282051282
Fold [3/5] Epoch [0/100] Initial Loss: 0.1415, Training Loss: 0.1415, Initial Validation Loss: 0.1309, Validation Loss: 0.1309,V Acc: 0.4273, Top 70th Acc: 0.4935, Bottom 30th Acc: 0.2727
Fold [3/5] Epoch [10/100] Initial Loss: 0.1415, Training Loss: 0.0830, Initial Validation Loss: 0.1309, Validation Loss: 0.0735,V Acc: 0.6455, Top 70th Acc: 0.7403, Bottom 30th Acc: 0.4242
Fold [3/5] Epoch [20/100] Initial Loss: 0.1415, Training Loss: 0.0809, Initial Validation Loss: 0.1309, Validation Loss: 0.0709,V Acc: 0.6727, Top 70th Acc: 0.7792, Bottom 30th Acc: 0.4242
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.7662337662337663
57 2 [array([0.11392671, 0.36379436, 0.14998198, 0.20570685, 0.16659024],
      dtype=float32)]
Fold [4/5] Epoch [0/100] Initial Loss: 0.1318, Training Loss: 0.1318, Initial Validation Loss: 0.1154, Validation Loss: 0.1154,V Acc: 0.5413, Top 70th Acc: 0.6623, Bottom 30th Acc: 0.2500
Fold [4/5] Epoch [10/100] Initial Loss: 0.1318, Training Loss: 0.0811, Initial Validation Loss: 0.1154, Validation Loss: 0.0775,V Acc: 0.6055, Top 70th Acc: 0.7273, Bottom 30th Acc: 0.3125
Fold [4/5] Epoch [20/100] Initial Loss: 0.1318, Training Loss: 0.0798, Initial Validation Loss: 0.1154, Validation Loss: 0.0755,V Acc: 0.5963, Top 70th Acc: 0.7273, Bottom 30th Acc: 0.2812
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.7662337662337663
Fold [5/5] Epoch [0/100] Initial Loss: 0.1383, Training Loss: 0.1383, Initial Validation Loss: 0.1328, Validation Loss: 0.1328,V Acc: 0.5185, Top 70th Acc: 0.5526, Bottom 30th Acc: 0.4375
Fold [5/5] Epoch [10/100] Initial Loss: 0.1383, Training Loss: 0.0830, Initial Validation Loss: 0.1328, Validation Loss: 0.0747,V Acc: 0.7037, Top 70th Acc: 0.8289, Bottom 30th Acc: 0.4062
Fold [5/5] Epoch [20/100] Initial Loss: 0.1383, Training Loss: 0.0810, Initial Validation Loss: 0.1328, Validation Loss: 0.0716,V Acc: 0.7037, Top 70th Acc: 0.8158, Bottom 30th Acc: 0.4375
Fold [5/5] Epoch [30/100] Initial Loss: 0.1383, Training Loss: 0.0801, Initial Validation Loss: 0.1328, Validation Loss: 0.0713,V Acc: 0.7130, Top 70th Acc: 0.8158, Bottom 30th Acc: 0.4688
Stopping early at Epoch (base 0): 35  Rolling back to Epoch (base 0): 30  Top Validation Acc: 0.8289473684210527
Running train_nn.py with seed 58
CUDA:False
Training samples count:  550
Training on 2 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1374, Training Loss: 0.1374, Initial Validation Loss: 0.1280, Validation Loss: 0.1280,V Acc: 0.4732, Top 70th Acc: 0.5696, Bottom 30th Acc: 0.2424
Fold [1/5] Epoch [10/100] Initial Loss: 0.1374, Training Loss: 0.0768, Initial Validation Loss: 0.1280, Validation Loss: 0.0930,V Acc: 0.5625, Top 70th Acc: 0.6835, Bottom 30th Acc: 0.2727
Stopping early at Epoch (base 0): 18  Rolling back to Epoch (base 0): 13  Top Validation Acc: 0.6962025316455697
Fold [2/5] Epoch [0/100] Initial Loss: 0.1378, Training Loss: 0.1378, Initial Validation Loss: 0.1283, Validation Loss: 0.1283,V Acc: 0.4234, Top 70th Acc: 0.5641, Bottom 30th Acc: 0.0909
Fold [2/5] Epoch [10/100] Initial Loss: 0.1378, Training Loss: 0.0822, Initial Validation Loss: 0.1283, Validation Loss: 0.0741,V Acc: 0.6667, Top 70th Acc: 0.7949, Bottom 30th Acc: 0.3636
Fold [2/5] Epoch [20/100] Initial Loss: 0.1378, Training Loss: 0.0807, Initial Validation Loss: 0.1283, Validation Loss: 0.0726,V Acc: 0.6577, Top 70th Acc: 0.7821, Bottom 30th Acc: 0.3636
Fold [2/5] Epoch [30/100] Initial Loss: 0.1378, Training Loss: 0.0801, Initial Validation Loss: 0.1283, Validation Loss: 0.0725,V Acc: 0.6577, Top 70th Acc: 0.7821, Bottom 30th Acc: 0.3636
Stopping early at Epoch (base 0): 31  Rolling back to Epoch (base 0): 26  Top Validation Acc: 0.7948717948717948
Fold [3/5] Epoch [0/100] Initial Loss: 0.1308, Training Loss: 0.1308, Initial Validation Loss: 0.1173, Validation Loss: 0.1173,V Acc: 0.5091, Top 70th Acc: 0.6494, Bottom 30th Acc: 0.1818
Fold [3/5] Epoch [10/100] Initial Loss: 0.1308, Training Loss: 0.0823, Initial Validation Loss: 0.1173, Validation Loss: 0.0729,V Acc: 0.6545, Top 70th Acc: 0.7922, Bottom 30th Acc: 0.3333
Fold [3/5] Epoch [20/100] Initial Loss: 0.1308, Training Loss: 0.0809, Initial Validation Loss: 0.1173, Validation Loss: 0.0710,V Acc: 0.7000, Top 70th Acc: 0.7922, Bottom 30th Acc: 0.4848
Stopping early at Epoch (base 0): 27  Rolling back to Epoch (base 0): 22  Top Validation Acc: 0.7922077922077922
Fold [4/5] Epoch [0/100] Initial Loss: 0.1368, Training Loss: 0.1368, Initial Validation Loss: 0.1281, Validation Loss: 0.1281,V Acc: 0.4954, Top 70th Acc: 0.6364, Bottom 30th Acc: 0.1562
Fold [4/5] Epoch [10/100] Initial Loss: 0.1368, Training Loss: 0.0810, Initial Validation Loss: 0.1281, Validation Loss: 0.0773,V Acc: 0.6055, Top 70th Acc: 0.7013, Bottom 30th Acc: 0.3750
Stopping early at Epoch (base 0): 19  Rolling back to Epoch (base 0): 14  Top Validation Acc: 0.7142857142857143
58 3 [array([0.13365251, 0.37879163, 0.15082386, 0.19169073, 0.1450413 ],
      dtype=float32)]
Fold [5/5] Epoch [0/100] Initial Loss: 0.1369, Training Loss: 0.1369, Initial Validation Loss: 0.1269, Validation Loss: 0.1269,V Acc: 0.3333, Top 70th Acc: 0.3553, Bottom 30th Acc: 0.2812
Fold [5/5] Epoch [10/100] Initial Loss: 0.1369, Training Loss: 0.0792, Initial Validation Loss: 0.1269, Validation Loss: 0.0824,V Acc: 0.5926, Top 70th Acc: 0.7237, Bottom 30th Acc: 0.2812
Stopping early at Epoch (base 0): 13  Rolling back to Epoch (base 0): 8  Top Validation Acc: 0.7105263157894737
Running train_nn.py with seed 59
CUDA:False
Training samples count:  550
Training on 2 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1414, Training Loss: 0.1414, Initial Validation Loss: 0.1379, Validation Loss: 0.1379,V Acc: 0.2679, Top 70th Acc: 0.3671, Bottom 30th Acc: 0.0303
Fold [1/5] Epoch [10/100] Initial Loss: 0.1414, Training Loss: 0.0802, Initial Validation Loss: 0.1379, Validation Loss: 0.0862,V Acc: 0.6161, Top 70th Acc: 0.7215, Bottom 30th Acc: 0.3636
Fold [1/5] Epoch [20/100] Initial Loss: 0.1414, Training Loss: 0.0779, Initial Validation Loss: 0.1379, Validation Loss: 0.0844,V Acc: 0.6161, Top 70th Acc: 0.7215, Bottom 30th Acc: 0.3636
Fold [1/5] Epoch [30/100] Initial Loss: 0.1414, Training Loss: 0.0773, Initial Validation Loss: 0.1379, Validation Loss: 0.0831,V Acc: 0.6518, Top 70th Acc: 0.7089, Bottom 30th Acc: 0.5152
Stopping early at Epoch (base 0): 39  Rolling back to Epoch (base 0): 34  Top Validation Acc: 0.7215189873417721
Fold [2/5] Epoch [0/100] Initial Loss: 0.1362, Training Loss: 0.1362, Initial Validation Loss: 0.1296, Validation Loss: 0.1296,V Acc: 0.4955, Top 70th Acc: 0.5385, Bottom 30th Acc: 0.3939
Fold [2/5] Epoch [10/100] Initial Loss: 0.1362, Training Loss: 0.0807, Initial Validation Loss: 0.1296, Validation Loss: 0.0807,V Acc: 0.6216, Top 70th Acc: 0.7051, Bottom 30th Acc: 0.4242
Fold [2/5] Epoch [20/100] Initial Loss: 0.1362, Training Loss: 0.0785, Initial Validation Loss: 0.1296, Validation Loss: 0.0792,V Acc: 0.6216, Top 70th Acc: 0.7179, Bottom 30th Acc: 0.3939
Fold [2/5] Epoch [30/100] Initial Loss: 0.1362, Training Loss: 0.0780, Initial Validation Loss: 0.1296, Validation Loss: 0.0788,V Acc: 0.6216, Top 70th Acc: 0.7179, Bottom 30th Acc: 0.3939
Stopping early at Epoch (base 0): 30  Rolling back to Epoch (base 0): 25  Top Validation Acc: 0.717948717948718
Fold [3/5] Epoch [0/100] Initial Loss: 0.1394, Training Loss: 0.1394, Initial Validation Loss: 0.1289, Validation Loss: 0.1289,V Acc: 0.3818, Top 70th Acc: 0.4156, Bottom 30th Acc: 0.3030
Stopping early at Epoch (base 0): 29  Rolling back to Epoch (base 0): 24  Top Validation Acc: 0.9342105263157895
Running train_nn.py with seed 45
CUDA:False
Training samples count:  550
Training on 162 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1417, Training Loss: 0.1417, Initial Validation Loss: 0.1382, Validation Loss: 0.1382,V Acc: 0.2768, Top 70th Acc: 0.3544, Bottom 30th Acc: 0.0909
Fold [1/5] Epoch [10/100] Initial Loss: 0.1417, Training Loss: 0.0164, Initial Validation Loss: 0.1382, Validation Loss: 0.0394,V Acc: 0.8125, Top 70th Acc: 0.9367, Bottom 30th Acc: 0.5152
Fold [1/5] Epoch [20/100] Initial Loss: 0.1417, Training Loss: 0.0061, Initial Validation Loss: 0.1382, Validation Loss: 0.0364,V Acc: 0.8393, Top 70th Acc: 0.9367, Bottom 30th Acc: 0.6061
Fold [1/5] Epoch [30/100] Initial Loss: 0.1417, Training Loss: 0.0045, Initial Validation Loss: 0.1382, Validation Loss: 0.0349,V Acc: 0.8036, Top 70th Acc: 0.9494, Bottom 30th Acc: 0.4545
Stopping early at Epoch (base 0): 38  Rolling back to Epoch (base 0): 33  Top Validation Acc: 0.9493670886075949
Fold [2/5] Epoch [0/100] Initial Loss: 0.1423, Training Loss: 0.1423, Initial Validation Loss: 0.1353, Validation Loss: 0.1353,V Acc: 0.2432, Top 70th Acc: 0.3333, Bottom 30th Acc: 0.0303
Fold [2/5] Epoch [10/100] Initial Loss: 0.1423, Training Loss: 0.0204, Initial Validation Loss: 0.1353, Validation Loss: 0.0298,V Acc: 0.8468, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.6061
Fold [2/5] Epoch [20/100] Initial Loss: 0.1423, Training Loss: 0.0072, Initial Validation Loss: 0.1353, Validation Loss: 0.0253,V Acc: 0.8649, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.9487179487179487
Fold [3/5] Epoch [0/100] Initial Loss: 0.1405, Training Loss: 0.1405, Initial Validation Loss: 0.1325, Validation Loss: 0.1325,V Acc: 0.2727, Top 70th Acc: 0.3506, Bottom 30th Acc: 0.0909
Fold [3/5] Epoch [10/100] Initial Loss: 0.1405, Training Loss: 0.0120, Initial Validation Loss: 0.1325, Validation Loss: 0.0428,V Acc: 0.7545, Top 70th Acc: 0.8961, Bottom 30th Acc: 0.4242
Fold [3/5] Epoch [20/100] Initial Loss: 0.1405, Training Loss: 0.0042, Initial Validation Loss: 0.1325, Validation Loss: 0.0406,V Acc: 0.7909, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.5152
Stopping early at Epoch (base 0): 27  Rolling back to Epoch (base 0): 22  Top Validation Acc: 0.8961038961038961
45 2 [array([0.3199793 , 0.14246206, 0.11359501, 0.2234943 , 0.20046933],
      dtype=float32)]
Fold [4/5] Epoch [0/100] Initial Loss: 0.1381, Training Loss: 0.1381, Initial Validation Loss: 0.1341, Validation Loss: 0.1341,V Acc: 0.3578, Top 70th Acc: 0.4286, Bottom 30th Acc: 0.1875
Fold [4/5] Epoch [10/100] Initial Loss: 0.1381, Training Loss: 0.0216, Initial Validation Loss: 0.1341, Validation Loss: 0.0369,V Acc: 0.8349, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.5938
Fold [4/5] Epoch [20/100] Initial Loss: 0.1381, Training Loss: 0.0061, Initial Validation Loss: 0.1341, Validation Loss: 0.0320,V Acc: 0.8165, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.5000
Fold [4/5] Epoch [30/100] Initial Loss: 0.1381, Training Loss: 0.0046, Initial Validation Loss: 0.1341, Validation Loss: 0.0296,V Acc: 0.8624, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6562
Fold [4/5] Epoch [40/100] Initial Loss: 0.1381, Training Loss: 0.0042, Initial Validation Loss: 0.1341, Validation Loss: 0.0281,V Acc: 0.8807, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.6875
Fold [4/5] Epoch [50/100] Initial Loss: 0.1381, Training Loss: 0.0040, Initial Validation Loss: 0.1341, Validation Loss: 0.0265,V Acc: 0.8807, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.6562
Fold [4/5] Epoch [60/100] Initial Loss: 0.1381, Training Loss: 0.0038, Initial Validation Loss: 0.1341, Validation Loss: 0.0260,V Acc: 0.8807, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.6562
Stopping early at Epoch (base 0): 60  Rolling back to Epoch (base 0): 55  Top Validation Acc: 0.974025974025974
Fold [5/5] Epoch [0/100] Initial Loss: 0.1401, Training Loss: 0.1401, Initial Validation Loss: 0.1312, Validation Loss: 0.1312,V Acc: 0.3148, Top 70th Acc: 0.3289, Bottom 30th Acc: 0.2812
Fold [5/5] Epoch [10/100] Initial Loss: 0.1401, Training Loss: 0.0137, Initial Validation Loss: 0.1312, Validation Loss: 0.0272,V Acc: 0.8611, Top 70th Acc: 0.9737, Bottom 30th Acc: 0.5938
Stopping early at Epoch (base 0): 18  Rolling back to Epoch (base 0): 13  Top Validation Acc: 0.9868421052631579
Running train_nn.py with seed 46
CUDA:False
Training samples count:  550
Training on 162 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1404, Training Loss: 0.1404, Initial Validation Loss: 0.1351, Validation Loss: 0.1351,V Acc: 0.2321, Top 70th Acc: 0.2658, Bottom 30th Acc: 0.1515
Fold [1/5] Epoch [10/100] Initial Loss: 0.1404, Training Loss: 0.0141, Initial Validation Loss: 0.1351, Validation Loss: 0.0359,V Acc: 0.8482, Top 70th Acc: 0.9114, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 18  Rolling back to Epoch (base 0): 13  Top Validation Acc: 0.9113924050632911
Fold [2/5] Epoch [0/100] Initial Loss: 0.1382, Training Loss: 0.1382, Initial Validation Loss: 0.1334, Validation Loss: 0.1334,V Acc: 0.3784, Top 70th Acc: 0.4615, Bottom 30th Acc: 0.1818
Fold [2/5] Epoch [10/100] Initial Loss: 0.1382, Training Loss: 0.0161, Initial Validation Loss: 0.1334, Validation Loss: 0.0361,V Acc: 0.8378, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.6667
Fold [2/5] Epoch [20/100] Initial Loss: 0.1382, Training Loss: 0.0046, Initial Validation Loss: 0.1334, Validation Loss: 0.0294,V Acc: 0.8468, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.6667
Fold [2/5] Epoch [30/100] Initial Loss: 0.1382, Training Loss: 0.0037, Initial Validation Loss: 0.1334, Validation Loss: 0.0285,V Acc: 0.8468, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 31  Rolling back to Epoch (base 0): 26  Top Validation Acc: 0.9487179487179487
46 1 [array([0.20384997, 0.06320718, 0.03001187, 0.17425129, 0.52867967],
      dtype=float32)]
Fold [3/5] Epoch [0/100] Initial Loss: 0.1377, Training Loss: 0.1377, Initial Validation Loss: 0.1345, Validation Loss: 0.1345,V Acc: 0.4273, Top 70th Acc: 0.5325, Bottom 30th Acc: 0.1818
Fold [3/5] Epoch [10/100] Initial Loss: 0.1377, Training Loss: 0.0112, Initial Validation Loss: 0.1345, Validation Loss: 0.0240,V Acc: 0.8818, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.6667
Fold [3/5] Epoch [20/100] Initial Loss: 0.1377, Training Loss: 0.0049, Initial Validation Loss: 0.1345, Validation Loss: 0.0226,V Acc: 0.8636, Top 70th Acc: 0.9870, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.987012987012987
Fold [4/5] Epoch [0/100] Initial Loss: 0.1439, Training Loss: 0.1439, Initial Validation Loss: 0.1308, Validation Loss: 0.1308,V Acc: 0.2385, Top 70th Acc: 0.2857, Bottom 30th Acc: 0.1250
Fold [4/5] Epoch [10/100] Initial Loss: 0.1439, Training Loss: 0.0161, Initial Validation Loss: 0.1308, Validation Loss: 0.0425,V Acc: 0.8073, Top 70th Acc: 0.8961, Bottom 30th Acc: 0.5938
Fold [4/5] Epoch [20/100] Initial Loss: 0.1439, Training Loss: 0.0063, Initial Validation Loss: 0.1308, Validation Loss: 0.0386,V Acc: 0.8257, Top 70th Acc: 0.8961, Bottom 30th Acc: 0.6562
Fold [4/5] Epoch [30/100] Initial Loss: 0.1439, Training Loss: 0.0051, Initial Validation Loss: 0.1308, Validation Loss: 0.0371,V Acc: 0.8257, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.5938
Fold [4/5] Epoch [40/100] Initial Loss: 0.1439, Training Loss: 0.0046, Initial Validation Loss: 0.1308, Validation Loss: 0.0369,V Acc: 0.8349, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.6562
Fold [4/5] Epoch [50/100] Initial Loss: 0.1439, Training Loss: 0.0041, Initial Validation Loss: 0.1308, Validation Loss: 0.0353,V Acc: 0.8349, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.6250
Fold [4/5] Epoch [60/100] Initial Loss: 0.1439, Training Loss: 0.0039, Initial Validation Loss: 0.1308, Validation Loss: 0.0344,V Acc: 0.8532, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.6875
Fold [4/5] Epoch [70/100] Initial Loss: 0.1439, Training Loss: 0.0037, Initial Validation Loss: 0.1308, Validation Loss: 0.0342,V Acc: 0.8532, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.6875
Stopping early at Epoch (base 0): 16  Rolling back to Epoch (base 0): 11  Top Validation Acc: 0.9342105263157895
Running train_nn.py with seed 80
CUDA:False
Training samples count:  550
Training on 21 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1305, Training Loss: 0.1305, Initial Validation Loss: 0.1267, Validation Loss: 0.1267,V Acc: 0.3750, Top 70th Acc: 0.4810, Bottom 30th Acc: 0.1212
Fold [1/5] Epoch [10/100] Initial Loss: 0.1305, Training Loss: 0.0202, Initial Validation Loss: 0.1267, Validation Loss: 0.0291,V Acc: 0.8750, Top 70th Acc: 0.9620, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 18  Rolling back to Epoch (base 0): 13  Top Validation Acc: 0.9240506329113924
Fold [2/5] Epoch [0/100] Initial Loss: 0.1305, Training Loss: 0.1305, Initial Validation Loss: 0.1167, Validation Loss: 0.1167,V Acc: 0.4955, Top 70th Acc: 0.6538, Bottom 30th Acc: 0.1212
Fold [2/5] Epoch [10/100] Initial Loss: 0.1305, Training Loss: 0.0204, Initial Validation Loss: 0.1167, Validation Loss: 0.0297,V Acc: 0.8649, Top 70th Acc: 0.9872, Bottom 30th Acc: 0.5758
Fold [2/5] Epoch [20/100] Initial Loss: 0.1305, Training Loss: 0.0134, Initial Validation Loss: 0.1167, Validation Loss: 0.0306,V Acc: 0.8649, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 22  Rolling back to Epoch (base 0): 17  Top Validation Acc: 0.9743589743589743
80 1 [array([0.77164423, 0.02156932, 0.0328707 , 0.1358095 , 0.03810621],
      dtype=float32)]
Fold [3/5] Epoch [0/100] Initial Loss: 0.1381, Training Loss: 0.1381, Initial Validation Loss: 0.1275, Validation Loss: 0.1275,V Acc: 0.4273, Top 70th Acc: 0.4935, Bottom 30th Acc: 0.2727
Fold [3/5] Epoch [10/100] Initial Loss: 0.1381, Training Loss: 0.0265, Initial Validation Loss: 0.1275, Validation Loss: 0.0262,V Acc: 0.9000, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.7273
Stopping early at Epoch (base 0): 18  Rolling back to Epoch (base 0): 13  Top Validation Acc: 0.987012987012987
Fold [4/5] Epoch [0/100] Initial Loss: 0.1413, Training Loss: 0.1413, Initial Validation Loss: 0.1295, Validation Loss: 0.1295,V Acc: 0.2294, Top 70th Acc: 0.2987, Bottom 30th Acc: 0.0625
Fold [4/5] Epoch [10/100] Initial Loss: 0.1413, Training Loss: 0.0259, Initial Validation Loss: 0.1295, Validation Loss: 0.0336,V Acc: 0.8165, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.5312
Stopping early at Epoch (base 0): 19  Rolling back to Epoch (base 0): 14  Top Validation Acc: 0.9090909090909091
Fold [5/5] Epoch [0/100] Initial Loss: 0.1358, Training Loss: 0.1358, Initial Validation Loss: 0.1242, Validation Loss: 0.1242,V Acc: 0.3611, Top 70th Acc: 0.4211, Bottom 30th Acc: 0.2188
Fold [5/5] Epoch [10/100] Initial Loss: 0.1358, Training Loss: 0.0297, Initial Validation Loss: 0.1242, Validation Loss: 0.0315,V Acc: 0.8611, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.6562
Fold [5/5] Epoch [20/100] Initial Loss: 0.1358, Training Loss: 0.0162, Initial Validation Loss: 0.1242, Validation Loss: 0.0233,V Acc: 0.8796, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.6875
Fold [5/5] Epoch [30/100] Initial Loss: 0.1358, Training Loss: 0.0123, Initial Validation Loss: 0.1242, Validation Loss: 0.0265,V Acc: 0.8704, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.6875
Stopping early at Epoch (base 0): 33  Rolling back to Epoch (base 0): 28  Top Validation Acc: 0.9473684210526315
Running train_nn.py with seed 81
CUDA:False
Training samples count:  550
Training on 21 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1405, Training Loss: 0.1405, Initial Validation Loss: 0.1320, Validation Loss: 0.1320,V Acc: 0.4375, Top 70th Acc: 0.5696, Bottom 30th Acc: 0.1212
Fold [1/5] Epoch [10/100] Initial Loss: 0.1405, Training Loss: 0.0261, Initial Validation Loss: 0.1320, Validation Loss: 0.0265,V Acc: 0.8750, Top 70th Acc: 0.9873, Bottom 30th Acc: 0.6061
Fold [1/5] Epoch [20/100] Initial Loss: 0.1405, Training Loss: 0.0193, Initial Validation Loss: 0.1320, Validation Loss: 0.0221,V Acc: 0.8750, Top 70th Acc: 0.9873, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.9873417721518988
Fold [2/5] Epoch [0/100] Initial Loss: 0.1360, Training Loss: 0.1360, Initial Validation Loss: 0.1288, Validation Loss: 0.1288,V Acc: 0.3243, Top 70th Acc: 0.3846, Bottom 30th Acc: 0.1818
Fold [2/5] Epoch [10/100] Initial Loss: 0.1360, Training Loss: 0.0211, Initial Validation Loss: 0.1288, Validation Loss: 0.0341,V Acc: 0.8378, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.5758
Fold [2/5] Epoch [20/100] Initial Loss: 0.1360, Training Loss: 0.0152, Initial Validation Loss: 0.1288, Validation Loss: 0.0280,V Acc: 0.8649, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 20  Rolling back to Epoch (base 0): 15  Top Validation Acc: 0.9615384615384616
Fold [3/5] Epoch [0/100] Initial Loss: 0.1326, Training Loss: 0.1326, Initial Validation Loss: 0.1211, Validation Loss: 0.1211,V Acc: 0.5455, Top 70th Acc: 0.6494, Bottom 30th Acc: 0.3030
Fold [3/5] Epoch [10/100] Initial Loss: 0.1326, Training Loss: 0.0188, Initial Validation Loss: 0.1211, Validation Loss: 0.0297,V Acc: 0.8455, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.6364
Fold [3/5] Epoch [20/100] Initial Loss: 0.1326, Training Loss: 0.0144, Initial Validation Loss: 0.1211, Validation Loss: 0.0265,V Acc: 0.8909, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.7273
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.948051948051948
Fold [4/5] Epoch [0/100] Initial Loss: 0.1300, Training Loss: 0.1300, Initial Validation Loss: 0.1201, Validation Loss: 0.1201,V Acc: 0.5046, Top 70th Acc: 0.5714, Bottom 30th Acc: 0.3438
Fold [4/5] Epoch [10/100] Initial Loss: 0.1300, Training Loss: 0.0216, Initial Validation Loss: 0.1201, Validation Loss: 0.0246,V Acc: 0.9083, Top 70th Acc: 0.9870, Bottom 30th Acc: 0.7188
Stopping early at Epoch (base 0): 18  Rolling back to Epoch (base 0): 13  Top Validation Acc: 0.987012987012987
Fold [5/5] Epoch [0/100] Initial Loss: 0.1394, Training Loss: 0.1394, Initial Validation Loss: 0.1223, Validation Loss: 0.1223,V Acc: 0.4815, Top 70th Acc: 0.5395, Bottom 30th Acc: 0.3438
Fold [5/5] Epoch [10/100] Initial Loss: 0.1394, Training Loss: 0.0262, Initial Validation Loss: 0.1223, Validation Loss: 0.0218,V Acc: 0.8981, Top 70th Acc: 1.0000, Bottom 30th Acc: 0.6562
Fold [5/5] Epoch [20/100] Initial Loss: 0.1394, Training Loss: 0.0174, Initial Validation Loss: 0.1223, Validation Loss: 0.0201,V Acc: 0.8796, Top 70th Acc: 0.9868, Bottom 30th Acc: 0.6250
Fold [5/5] Epoch [30/100] Initial Loss: 0.1394, Training Loss: 0.0158, Initial Validation Loss: 0.1223, Validation Loss: 0.0200,V Acc: 0.9167, Top 70th Acc: 0.9868, Bottom 30th Acc: 0.7500
Stopping early at Epoch (base 0): 33  Rolling back to Epoch (base 0): 28  Top Validation Acc: 0.9868421052631579
81 4 [array([0.78473234, 0.01417828, 0.03031342, 0.08771267, 0.08306332],
      dtype=float32)]
Running train_nn.py with seed 82
CUDA:False
Training samples count:  550
Training on 21 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1349, Training Loss: 0.1349, Initial Validation Loss: 0.1202, Validation Loss: 0.1202,V Acc: 0.2857, Top 70th Acc: 0.3544, Bottom 30th Acc: 0.1212
Fold [1/5] Epoch [10/100] Initial Loss: 0.1349, Training Loss: 0.0211, Initial Validation Loss: 0.1202, Validation Loss: 0.0255,V Acc: 0.8750, Top 70th Acc: 0.9747, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 15  Rolling back to Epoch (base 0): 10  Top Validation Acc: 0.9493670886075949
Fold [2/5] Epoch [0/100] Initial Loss: 0.1414, Training Loss: 0.1414, Initial Validation Loss: 0.1336, Validation Loss: 0.1336,V Acc: 0.2973, Top 70th Acc: 0.3974, Bottom 30th Acc: 0.0606
Fold [2/5] Epoch [10/100] Initial Loss: 0.1414, Training Loss: 0.0200, Initial Validation Loss: 0.1336, Validation Loss: 0.0363,V Acc: 0.8198, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.5455
Fold [2/5] Epoch [20/100] Initial Loss: 0.1414, Training Loss: 0.0130, Initial Validation Loss: 0.1336, Validation Loss: 0.0380,V Acc: 0.8378, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 22  Rolling back to Epoch (base 0): 17  Top Validation Acc: 0.9487179487179487
Fold [3/5] Epoch [0/100] Initial Loss: 0.1368, Training Loss: 0.1368, Initial Validation Loss: 0.1322, Validation Loss: 0.1322,V Acc: 0.5545, Top 70th Acc: 0.5325, Bottom 30th Acc: 0.6061
Fold [4/5] Epoch [10/100] Initial Loss: 0.1387, Training Loss: 0.0445, Initial Validation Loss: 0.1322, Validation Loss: 0.0541,V Acc: 0.7248, Top 70th Acc: 0.8182, Bottom 30th Acc: 0.5000
Fold [4/5] Epoch [20/100] Initial Loss: 0.1387, Training Loss: 0.0211, Initial Validation Loss: 0.1322, Validation Loss: 0.0353,V Acc: 0.8165, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.5625
Fold [4/5] Epoch [30/100] Initial Loss: 0.1387, Training Loss: 0.0168, Initial Validation Loss: 0.1322, Validation Loss: 0.0339,V Acc: 0.8349, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.6250
Stopping early at Epoch (base 0): 36  Rolling back to Epoch (base 0): 31  Top Validation Acc: 0.9090909090909091
Fold [5/5] Epoch [0/100] Initial Loss: 0.1366, Training Loss: 0.1366, Initial Validation Loss: 0.1356, Validation Loss: 0.1356,V Acc: 0.3148, Top 70th Acc: 0.4079, Bottom 30th Acc: 0.0938
Fold [5/5] Epoch [10/100] Initial Loss: 0.1366, Training Loss: 0.0482, Initial Validation Loss: 0.1356, Validation Loss: 0.0602,V Acc: 0.7130, Top 70th Acc: 0.8289, Bottom 30th Acc: 0.4375
Fold [5/5] Epoch [20/100] Initial Loss: 0.1366, Training Loss: 0.0231, Initial Validation Loss: 0.1356, Validation Loss: 0.0399,V Acc: 0.7593, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.3125
Fold [5/5] Epoch [30/100] Initial Loss: 0.1366, Training Loss: 0.0174, Initial Validation Loss: 0.1356, Validation Loss: 0.0337,V Acc: 0.8611, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.6562
Stopping early at Epoch (base 0): 35  Rolling back to Epoch (base 0): 30  Top Validation Acc: 0.9473684210526315
Running train_nn.py with seed 58
CUDA:False
Training samples count:  550
Training on 30 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1372, Training Loss: 0.1372, Initial Validation Loss: 0.1367, Validation Loss: 0.1367,V Acc: 0.3214, Top 70th Acc: 0.3924, Bottom 30th Acc: 0.1515
Fold [1/5] Epoch [10/100] Initial Loss: 0.1372, Training Loss: 0.0309, Initial Validation Loss: 0.1367, Validation Loss: 0.0393,V Acc: 0.8750, Top 70th Acc: 0.9367, Bottom 30th Acc: 0.7273
Fold [1/5] Epoch [20/100] Initial Loss: 0.1372, Training Loss: 0.0177, Initial Validation Loss: 0.1367, Validation Loss: 0.0290,V Acc: 0.8750, Top 70th Acc: 0.9620, Bottom 30th Acc: 0.6667
Fold [1/5] Epoch [30/100] Initial Loss: 0.1372, Training Loss: 0.0157, Initial Validation Loss: 0.1367, Validation Loss: 0.0276,V Acc: 0.8839, Top 70th Acc: 0.9494, Bottom 30th Acc: 0.7273
Stopping early at Epoch (base 0): 35  Rolling back to Epoch (base 0): 30  Top Validation Acc: 0.9493670886075949
Fold [2/5] Epoch [0/100] Initial Loss: 0.1395, Training Loss: 0.1395, Initial Validation Loss: 0.1325, Validation Loss: 0.1325,V Acc: 0.2613, Top 70th Acc: 0.3333, Bottom 30th Acc: 0.0909
Fold [2/5] Epoch [10/100] Initial Loss: 0.1395, Training Loss: 0.0298, Initial Validation Loss: 0.1325, Validation Loss: 0.0339,V Acc: 0.8288, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.6061
Fold [2/5] Epoch [20/100] Initial Loss: 0.1395, Training Loss: 0.0173, Initial Validation Loss: 0.1325, Validation Loss: 0.0288,V Acc: 0.8288, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.5152
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.9487179487179487
Fold [3/5] Epoch [0/100] Initial Loss: 0.1403, Training Loss: 0.1403, Initial Validation Loss: 0.1343, Validation Loss: 0.1343,V Acc: 0.3000, Top 70th Acc: 0.3247, Bottom 30th Acc: 0.2424
Fold [3/5] Epoch [10/100] Initial Loss: 0.1403, Training Loss: 0.0311, Initial Validation Loss: 0.1343, Validation Loss: 0.0326,V Acc: 0.8455, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.5758
Fold [3/5] Epoch [20/100] Initial Loss: 0.1403, Training Loss: 0.0171, Initial Validation Loss: 0.1343, Validation Loss: 0.0259,V Acc: 0.8545, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 28  Rolling back to Epoch (base 0): 23  Top Validation Acc: 0.974025974025974
Fold [4/5] Epoch [0/100] Initial Loss: 0.1394, Training Loss: 0.1394, Initial Validation Loss: 0.1333, Validation Loss: 0.1333,V Acc: 0.2477, Top 70th Acc: 0.3117, Bottom 30th Acc: 0.0938
Fold [4/5] Epoch [10/100] Initial Loss: 0.1394, Training Loss: 0.0362, Initial Validation Loss: 0.1333, Validation Loss: 0.0379,V Acc: 0.8165, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.5938
Fold [4/5] Epoch [20/100] Initial Loss: 0.1394, Training Loss: 0.0167, Initial Validation Loss: 0.1333, Validation Loss: 0.0302,V Acc: 0.8440, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.6250
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.948051948051948
58 3 [array([0.71440715, 0.02286516, 0.02714049, 0.06780757, 0.16777965],
      dtype=float32)]
Fold [5/5] Epoch [0/100] Initial Loss: 0.1389, Training Loss: 0.1389, Initial Validation Loss: 0.1309, Validation Loss: 0.1309,V Acc: 0.2685, Top 70th Acc: 0.3421, Bottom 30th Acc: 0.0938
Fold [5/5] Epoch [10/100] Initial Loss: 0.1389, Training Loss: 0.0264, Initial Validation Loss: 0.1309, Validation Loss: 0.0343,V Acc: 0.8148, Top 70th Acc: 0.9737, Bottom 30th Acc: 0.4375
Fold [5/5] Epoch [20/100] Initial Loss: 0.1389, Training Loss: 0.0173, Initial Validation Loss: 0.1309, Validation Loss: 0.0308,V Acc: 0.8519, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.5938
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.9473684210526315
Running train_nn.py with seed 59
CUDA:False
Training samples count:  550
Training on 30 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1385, Training Loss: 0.1385, Initial Validation Loss: 0.1361, Validation Loss: 0.1361,V Acc: 0.3393, Top 70th Acc: 0.3924, Bottom 30th Acc: 0.2121
Fold [1/5] Epoch [10/100] Initial Loss: 0.1385, Training Loss: 0.0322, Initial Validation Loss: 0.1361, Validation Loss: 0.0480,V Acc: 0.7679, Top 70th Acc: 0.8861, Bottom 30th Acc: 0.4848
Fold [1/5] Epoch [20/100] Initial Loss: 0.1385, Training Loss: 0.0187, Initial Validation Loss: 0.1361, Validation Loss: 0.0392,V Acc: 0.7946, Top 70th Acc: 0.8987, Bottom 30th Acc: 0.5455
Fold [1/5] Epoch [30/100] Initial Loss: 0.1385, Training Loss: 0.0149, Initial Validation Loss: 0.1361, Validation Loss: 0.0375,V Acc: 0.7946, Top 70th Acc: 0.9241, Bottom 30th Acc: 0.4848
Stopping early at Epoch (base 0): 33  Rolling back to Epoch (base 0): 28  Top Validation Acc: 0.9113924050632911
Fold [2/5] Epoch [0/100] Initial Loss: 0.1357, Training Loss: 0.1357, Initial Validation Loss: 0.1293, Validation Loss: 0.1293,V Acc: 0.3964, Top 70th Acc: 0.4615, Bottom 30th Acc: 0.2424
Fold [2/5] Epoch [10/100] Initial Loss: 0.1357, Training Loss: 0.0309, Initial Validation Loss: 0.1293, Validation Loss: 0.0418,V Acc: 0.8108, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.5758
Fold [2/5] Epoch [20/100] Initial Loss: 0.1357, Training Loss: 0.0212, Initial Validation Loss: 0.1293, Validation Loss: 0.0373,V Acc: 0.8198, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.5758
Fold [2/5] Epoch [30/100] Initial Loss: 0.1357, Training Loss: 0.0171, Initial Validation Loss: 0.1293, Validation Loss: 0.0348,V Acc: 0.8198, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.5152
Fold [2/5] Epoch [40/100] Initial Loss: 0.1357, Training Loss: 0.0156, Initial Validation Loss: 0.1293, Validation Loss: 0.0321,V Acc: 0.8468, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.5758
Fold [2/5] Epoch [50/100] Initial Loss: 0.1357, Training Loss: 0.0148, Initial Validation Loss: 0.1293, Validation Loss: 0.0325,V Acc: 0.8468, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 54  Rolling back to Epoch (base 0): 49  Top Validation Acc: 0.9615384615384616
Fold [3/5] Epoch [0/100] Initial Loss: 0.1389, Training Loss: 0.1389, Initial Validation Loss: 0.1294, Validation Loss: 0.1294,V Acc: 0.2727, Top 70th Acc: 0.3636, Bottom 30th Acc: 0.0606
Fold [3/5] Epoch [10/100] Initial Loss: 0.1389, Training Loss: 0.0315, Initial Validation Loss: 0.1294, Validation Loss: 0.0334,V Acc: 0.8636, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 17  Rolling back to Epoch (base 0): 12  Top Validation Acc: 0.948051948051948
Fold [4/5] Epoch [0/100] Initial Loss: 0.1405, Training Loss: 0.1405, Initial Validation Loss: 0.1352, Validation Loss: 0.1352,V Acc: 0.3761, Top 70th Acc: 0.4545, Bottom 30th Acc: 0.1875/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)

Training on 40 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 46
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 40 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 47
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 40 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 48
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 40 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 49
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 40 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 50
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 40 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 51
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 39 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 52
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 40 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 53
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 40 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 54
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 40 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 55
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 40 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 56
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 40 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 57
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 40 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 58
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 40 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 59
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 40 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 60
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 40 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 61
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 40 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 62
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 40 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 63
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 40 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 64
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 40 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 65
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 40 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 66
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 40 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 67
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 40 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 68
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 40 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 69
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 40 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 70
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 40 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 71
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 40 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 72
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 40 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 73
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 40 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 74
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 40 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 75
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 40 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 76
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 40 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 77
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 40 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 78
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 40 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 79
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 40 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 80
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 40 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 81
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 40 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 82
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 40 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 83
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 40 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 84
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 40 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 85
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 40 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 86
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 40 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 87
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 40 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 88
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 40 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 89
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 40 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 90
Training size: 438
Stopping early at Epoch (base 0): 28  Rolling back to Epoch (base 0): 23  Top Validation Acc: 0.948051948051948
61 2 [array([0.5156266 , 0.04724923, 0.02989892, 0.15497836, 0.2522468 ],
      dtype=float32)]
Fold [4/5] Epoch [0/100] Initial Loss: 0.1411, Training Loss: 0.1411, Initial Validation Loss: 0.1340, Validation Loss: 0.1340,V Acc: 0.2661, Top 70th Acc: 0.3377, Bottom 30th Acc: 0.0938
Fold [4/5] Epoch [10/100] Initial Loss: 0.1411, Training Loss: 0.0308, Initial Validation Loss: 0.1340, Validation Loss: 0.0397,V Acc: 0.7706, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.4062
Fold [4/5] Epoch [20/100] Initial Loss: 0.1411, Training Loss: 0.0140, Initial Validation Loss: 0.1340, Validation Loss: 0.0293,V Acc: 0.8349, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.5312
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.961038961038961
Fold [5/5] Epoch [0/100] Initial Loss: 0.1399, Training Loss: 0.1399, Initial Validation Loss: 0.1333, Validation Loss: 0.1333,V Acc: 0.3704, Top 70th Acc: 0.4474, Bottom 30th Acc: 0.1875
Fold [5/5] Epoch [10/100] Initial Loss: 0.1399, Training Loss: 0.0280, Initial Validation Loss: 0.1333, Validation Loss: 0.0352,V Acc: 0.8333, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.5625
Fold [5/5] Epoch [20/100] Initial Loss: 0.1399, Training Loss: 0.0157, Initial Validation Loss: 0.1333, Validation Loss: 0.0280,V Acc: 0.8704, Top 70th Acc: 0.9737, Bottom 30th Acc: 0.6250
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.9736842105263158
Running train_nn.py with seed 62
CUDA:False
Training samples count:  550
Training on 40 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1382, Training Loss: 0.1382, Initial Validation Loss: 0.1368, Validation Loss: 0.1368,V Acc: 0.3661, Top 70th Acc: 0.4557, Bottom 30th Acc: 0.1515
Fold [1/5] Epoch [10/100] Initial Loss: 0.1382, Training Loss: 0.0317, Initial Validation Loss: 0.1368, Validation Loss: 0.0288,V Acc: 0.8571, Top 70th Acc: 0.9747, Bottom 30th Acc: 0.5758
Fold [1/5] Epoch [20/100] Initial Loss: 0.1382, Training Loss: 0.0166, Initial Validation Loss: 0.1368, Validation Loss: 0.0203,V Acc: 0.9196, Top 70th Acc: 0.9747, Bottom 30th Acc: 0.7879
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.9620253164556962
Fold [2/5] Epoch [0/100] Initial Loss: 0.1425, Training Loss: 0.1425, Initial Validation Loss: 0.1362, Validation Loss: 0.1362,V Acc: 0.2613, Top 70th Acc: 0.2949, Bottom 30th Acc: 0.1818
Fold [2/5] Epoch [10/100] Initial Loss: 0.1425, Training Loss: 0.0432, Initial Validation Loss: 0.1362, Validation Loss: 0.0569,V Acc: 0.7568, Top 70th Acc: 0.7949, Bottom 30th Acc: 0.6667
Fold [2/5] Epoch [20/100] Initial Loss: 0.1425, Training Loss: 0.0143, Initial Validation Loss: 0.1362, Validation Loss: 0.0409,V Acc: 0.8018, Top 70th Acc: 0.8974, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 29  Rolling back to Epoch (base 0): 24  Top Validation Acc: 0.8974358974358975
Fold [3/5] Epoch [0/100] Initial Loss: 0.1399, Training Loss: 0.1399, Initial Validation Loss: 0.1346, Validation Loss: 0.1346,V Acc: 0.3091, Top 70th Acc: 0.3117, Bottom 30th Acc: 0.3030
Fold [3/5] Epoch [10/100] Initial Loss: 0.1399, Training Loss: 0.0294, Initial Validation Loss: 0.1346, Validation Loss: 0.0391,V Acc: 0.8455, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6061
Fold [3/5] Epoch [20/100] Initial Loss: 0.1399, Training Loss: 0.0134, Initial Validation Loss: 0.1346, Validation Loss: 0.0371,V Acc: 0.8455, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 21  Rolling back to Epoch (base 0): 16  Top Validation Acc: 0.8961038961038961
Fold [4/5] Epoch [0/100] Initial Loss: 0.1372, Training Loss: 0.1372, Initial Validation Loss: 0.1302, Validation Loss: 0.1302,V Acc: 0.4679, Top 70th Acc: 0.5455, Bottom 30th Acc: 0.2812
Fold [4/5] Epoch [10/100] Initial Loss: 0.1372, Training Loss: 0.0216, Initial Validation Loss: 0.1302, Validation Loss: 0.0376,V Acc: 0.7798, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.4688
Fold [4/5] Epoch [20/100] Initial Loss: 0.1372, Training Loss: 0.0137, Initial Validation Loss: 0.1302, Validation Loss: 0.0315,V Acc: 0.8073, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.4375
Fold [4/5] Epoch [30/100] Initial Loss: 0.1372, Training Loss: 0.0118, Initial Validation Loss: 0.1302, Validation Loss: 0.0291,V Acc: 0.8440, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.5625
Stopping early at Epoch (base 0): 30  Rolling back to Epoch (base 0): 25  Top Validation Acc: 0.961038961038961
62 3 [array([0.56643534, 0.03836061, 0.06991118, 0.13515984, 0.19013296],
      dtype=float32)]
Fold [5/5] Epoch [0/100] Initial Loss: 0.1420, Training Loss: 0.1420, Initial Validation Loss: 0.1306, Validation Loss: 0.1306,V Acc: 0.2500, Top 70th Acc: 0.2632, Bottom 30th Acc: 0.2188
Fold [5/5] Epoch [10/100] Initial Loss: 0.1420, Training Loss: 0.0388, Initial Validation Loss: 0.1306, Validation Loss: 0.0403,V Acc: 0.8333, Top 70th Acc: 0.9211, Bottom 30th Acc: 0.6250
Fold [5/5] Epoch [20/100] Initial Loss: 0.1420, Training Loss: 0.0152, Initial Validation Loss: 0.1306, Validation Loss: 0.0273,V Acc: 0.8889, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.7188
Stopping early at Epoch (base 0): 28  Rolling back to Epoch (base 0): 23  Top Validation Acc: 0.9605263157894737
Running train_nn.py with seed 63
CUDA:False
Training samples count:  550
Training on 40 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1395, Training Loss: 0.1395, Initial Validation Loss: 0.1371, Validation Loss: 0.1371,V Acc: 0.2589, Top 70th Acc: 0.3038, Bottom 30th Acc: 0.1515
Fold [1/5] Epoch [10/100] Initial Loss: 0.1395, Training Loss: 0.0325, Initial Validation Loss: 0.1371, Validation Loss: 0.0342,V Acc: 0.8571, Top 70th Acc: 0.9367, Bottom 30th Acc: 0.6667
Fold [1/5] Epoch [20/100] Initial Loss: 0.1395, Training Loss: 0.0161, Initial Validation Loss: 0.1371, Validation Loss: 0.0259,V Acc: 0.8661, Top 70th Acc: 0.9494, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 27  Rolling back to Epoch (base 0): 22  Top Validation Acc: 0.9746835443037974
Fold [2/5] Epoch [0/100] Initial Loss: 0.1388, Training Loss: 0.1388, Initial Validation Loss: 0.1343, Validation Loss: 0.1343,V Acc: 0.3153, Top 70th Acc: 0.3462, Bottom 30th Acc: 0.2424
Fold [2/5] Epoch [10/100] Initial Loss: 0.1388, Training Loss: 0.0312, Initial Validation Loss: 0.1343, Validation Loss: 0.0440,V Acc: 0.8018, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.5152
Fold [2/5] Epoch [20/100] Initial Loss: 0.1388, Training Loss: 0.0143, Initial Validation Loss: 0.1343, Validation Loss: 0.0342,V Acc: 0.8378, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 28  Rolling back to Epoch (base 0): 23  Top Validation Acc: 0.9358974358974359
Fold [3/5] Epoch [0/100] Initial Loss: 0.1393, Training Loss: 0.1393, Initial Validation Loss: 0.1301, Validation Loss: 0.1301,V Acc: 0.3091, Top 70th Acc: 0.3896, Bottom 30th Acc: 0.1212
Fold [3/5] Epoch [10/100] Initial Loss: 0.1393, Training Loss: 0.0404, Initial Validation Loss: 0.1301, Validation Loss: 0.0467,V Acc: 0.7636, Top 70th Acc: 0.8831, Bottom 30th Acc: 0.4848
Fold [3/5] Epoch [20/100] Initial Loss: 0.1393, Training Loss: 0.0153, Initial Validation Loss: 0.1301, Validation Loss: 0.0322,V Acc: 0.8364, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 29  Rolling back to Epoch (base 0): 24  Top Validation Acc: 0.935064935064935
Fold [4/5] Epoch [0/100] Initial Loss: 0.1445, Training Loss: 0.1445, Initial Validation Loss: 0.1314, Validation Loss: 0.1314,V Acc: 0.2294, Top 70th Acc: 0.2597, Bottom 30th Acc: 0.1562
Fold [4/5] Epoch [10/100] Initial Loss: 0.1445, Training Loss: 0.0381, Initial Validation Loss: 0.1314, Validation Loss: 0.0482,V Acc: 0.7156, Top 70th Acc: 0.8312, Bottom 30th Acc: 0.4375
Fold [4/5] Epoch [20/100] Initial Loss: 0.1445, Training Loss: 0.0167, Initial Validation Loss: 0.1314, Validation Loss: 0.0362,V Acc: 0.8349, Top 70th Acc: 0.8701, Bottom 30th Acc: 0.7500
Fold [4/5] Epoch [30/100] Initial Loss: 0.1445, Training Loss: 0.0123, Initial Validation Loss: 0.1314, Validation Loss: 0.0332,V Acc: 0.8257, Top 70th Acc: 0.8961, Bottom 30th Acc: 0.6562
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.922077922077922
Fold [4/5] Epoch [0/100] Initial Loss: 0.1379, Training Loss: 0.1379, Initial Validation Loss: 0.1313, Validation Loss: 0.1313,V Acc: 0.3119, Top 70th Acc: 0.3117, Bottom 30th Acc: 0.3125
Fold [4/5] Epoch [10/100] Initial Loss: 0.1379, Training Loss: 0.0310, Initial Validation Loss: 0.1313, Validation Loss: 0.0322,V Acc: 0.8899, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.7812
Fold [4/5] Epoch [20/100] Initial Loss: 0.1379, Training Loss: 0.0255, Initial Validation Loss: 0.1313, Validation Loss: 0.0298,V Acc: 0.8807, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.7188
Stopping early at Epoch (base 0): 20  Rolling back to Epoch (base 0): 15  Top Validation Acc: 0.948051948051948
59 3 [array([0.32136372, 0.11892263, 0.25512546, 0.19209488, 0.11249326],
      dtype=float32)]
Fold [5/5] Epoch [0/100] Initial Loss: 0.1398, Training Loss: 0.1398, Initial Validation Loss: 0.1303, Validation Loss: 0.1303,V Acc: 0.2870, Top 70th Acc: 0.3289, Bottom 30th Acc: 0.1875
Fold [5/5] Epoch [10/100] Initial Loss: 0.1398, Training Loss: 0.0381, Initial Validation Loss: 0.1303, Validation Loss: 0.0363,V Acc: 0.8148, Top 70th Acc: 0.9211, Bottom 30th Acc: 0.5625
Fold [5/5] Epoch [20/100] Initial Loss: 0.1398, Training Loss: 0.0237, Initial Validation Loss: 0.1303, Validation Loss: 0.0320,V Acc: 0.8333, Top 70th Acc: 0.9211, Bottom 30th Acc: 0.6250
Stopping early at Epoch (base 0): 22  Rolling back to Epoch (base 0): 17  Top Validation Acc: 0.9342105263157895
Running train_nn.py with seed 60
CUDA:False
Training samples count:  550
Training on 20 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1402, Training Loss: 0.1402, Initial Validation Loss: 0.1381, Validation Loss: 0.1381,V Acc: 0.2679, Top 70th Acc: 0.3165, Bottom 30th Acc: 0.1515
Fold [1/5] Epoch [10/100] Initial Loss: 0.1402, Training Loss: 0.0339, Initial Validation Loss: 0.1381, Validation Loss: 0.0359,V Acc: 0.8661, Top 70th Acc: 0.9241, Bottom 30th Acc: 0.7273
Fold [1/5] Epoch [20/100] Initial Loss: 0.1402, Training Loss: 0.0244, Initial Validation Loss: 0.1381, Validation Loss: 0.0328,V Acc: 0.8571, Top 70th Acc: 0.9241, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.9240506329113924
Fold [2/5] Epoch [0/100] Initial Loss: 0.1411, Training Loss: 0.1411, Initial Validation Loss: 0.1365, Validation Loss: 0.1365,V Acc: 0.2342, Top 70th Acc: 0.2564, Bottom 30th Acc: 0.1818
Fold [2/5] Epoch [10/100] Initial Loss: 0.1411, Training Loss: 0.0347, Initial Validation Loss: 0.1365, Validation Loss: 0.0561,V Acc: 0.7387, Top 70th Acc: 0.8205, Bottom 30th Acc: 0.5455
Fold [2/5] Epoch [20/100] Initial Loss: 0.1411, Training Loss: 0.0231, Initial Validation Loss: 0.1365, Validation Loss: 0.0459,V Acc: 0.8018, Top 70th Acc: 0.8846, Bottom 30th Acc: 0.6061
Fold [2/5] Epoch [30/100] Initial Loss: 0.1411, Training Loss: 0.0205, Initial Validation Loss: 0.1365, Validation Loss: 0.0430,V Acc: 0.7928, Top 70th Acc: 0.8846, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 36  Rolling back to Epoch (base 0): 31  Top Validation Acc: 0.8974358974358975
Fold [3/5] Epoch [0/100] Initial Loss: 0.1379, Training Loss: 0.1379, Initial Validation Loss: 0.1308, Validation Loss: 0.1308,V Acc: 0.2545, Top 70th Acc: 0.3506, Bottom 30th Acc: 0.0303
Fold [3/5] Epoch [10/100] Initial Loss: 0.1379, Training Loss: 0.0387, Initial Validation Loss: 0.1308, Validation Loss: 0.0397,V Acc: 0.7909, Top 70th Acc: 0.8831, Bottom 30th Acc: 0.5758
Fold [3/5] Epoch [20/100] Initial Loss: 0.1379, Training Loss: 0.0241, Initial Validation Loss: 0.1308, Validation Loss: 0.0330,V Acc: 0.8091, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.5152
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.948051948051948
Fold [4/5] Epoch [0/100] Initial Loss: 0.1421, Training Loss: 0.1421, Initial Validation Loss: 0.1354, Validation Loss: 0.1354,V Acc: 0.3394, Top 70th Acc: 0.3766, Bottom 30th Acc: 0.2500
Fold [4/5] Epoch [10/100] Initial Loss: 0.1421, Training Loss: 0.0364, Initial Validation Loss: 0.1354, Validation Loss: 0.0413,V Acc: 0.8624, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.7188
Fold [4/5] Epoch [20/100] Initial Loss: 0.1421, Training Loss: 0.0237, Initial Validation Loss: 0.1354, Validation Loss: 0.0343,V Acc: 0.8624, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.6875
Stopping early at Epoch (base 0): 22  Rolling back to Epoch (base 0): 17  Top Validation Acc: 0.935064935064935
Fold [5/5] Epoch [0/100] Initial Loss: 0.1343, Training Loss: 0.1343, Initial Validation Loss: 0.1237, Validation Loss: 0.1237,V Acc: 0.3611, Top 70th Acc: 0.4342, Bottom 30th Acc: 0.1875
Fold [5/5] Epoch [10/100] Initial Loss: 0.1343, Training Loss: 0.0401, Initial Validation Loss: 0.1237, Validation Loss: 0.0317,V Acc: 0.8796, Top 70th Acc: 0.9868, Bottom 30th Acc: 0.6250
Fold [5/5] Epoch [20/100] Initial Loss: 0.1343, Training Loss: 0.0255, Initial Validation Loss: 0.1237, Validation Loss: 0.0258,V Acc: 0.8704, Top 70th Acc: 0.9868, Bottom 30th Acc: 0.5938
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.9868421052631579
60 4 [array([0.32685083, 0.14773354, 0.2247238 , 0.2231706 , 0.07752135],
      dtype=float32)]
Running train_nn.py with seed 61
CUDA:False
Training samples count:  550
Training on 20 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1416, Training Loss: 0.1416, Initial Validation Loss: 0.1345, Validation Loss: 0.1345,V Acc: 0.3214, Top 70th Acc: 0.3671, Bottom 30th Acc: 0.2121
Fold [1/5] Epoch [10/100] Initial Loss: 0.1416, Training Loss: 0.0502, Initial Validation Loss: 0.1345, Validation Loss: 0.0481,V Acc: 0.7679, Top 70th Acc: 0.8861, Bottom 30th Acc: 0.4848
Fold [1/5] Epoch [20/100] Initial Loss: 0.1416, Training Loss: 0.0252, Initial Validation Loss: 0.1345, Validation Loss: 0.0306,V Acc: 0.8393, Top 70th Acc: 0.9620, Bottom 30th Acc: 0.5455
Fold [1/5] Epoch [30/100] Initial Loss: 0.1416, Training Loss: 0.0211, Initial Validation Loss: 0.1345, Validation Loss: 0.0303,V Acc: 0.8214, Top 70th Acc: 0.9367, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 32  Rolling back to Epoch (base 0): 27  Top Validation Acc: 0.9493670886075949
Fold [2/5] Epoch [0/100] Initial Loss: 0.1366, Training Loss: 0.1366, Initial Validation Loss: 0.1298, Validation Loss: 0.1298,V Acc: 0.3964, Top 70th Acc: 0.4487, Bottom 30th Acc: 0.2727
Fold [2/5] Epoch [10/100] Initial Loss: 0.1366, Training Loss: 0.0328, Initial Validation Loss: 0.1298, Validation Loss: 0.0385,V Acc: 0.8288, Top 70th Acc: 0.8846, Bottom 30th Acc: 0.6970
Fold [2/5] Epoch [20/100] Initial Loss: 0.1366, Training Loss: 0.0214, Initial Validation Loss: 0.1298, Validation Loss: 0.0326,V Acc: 0.8559, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.9230769230769231
Fold [3/5] Epoch [0/100] Initial Loss: 0.1375, Training Loss: 0.1375, Initial Validation Loss: 0.1319, Validation Loss: 0.1319,V Acc: 0.4182, Top 70th Acc: 0.4545, Bottom 30th Acc: 0.3333
Fold [3/5] Epoch [10/100] Initial Loss: 0.1375, Training Loss: 0.0308, Initial Validation Loss: 0.1319, Validation Loss: 0.0424,V Acc: 0.7727, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.4545
Fold [3/5] Epoch [20/100] Initial Loss: 0.1375, Training Loss: 0.0215, Initial Validation Loss: 0.1319, Validation Loss: 0.0381,V Acc: 0.8091, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.5152
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.922077922077922
61 2 [array([0.3868225 , 0.0350005 , 0.10919625, 0.26087034, 0.20811036],
      dtype=float32)]
Fold [4/5] Epoch [0/100] Initial Loss: 0.1386, Training Loss: 0.1386, Initial Validation Loss: 0.1320, Validation Loss: 0.1320,V Acc: 0.3303, Top 70th Acc: 0.3506, Bottom 30th Acc: 0.2812
Fold [4/5] Epoch [10/100] Initial Loss: 0.1386, Training Loss: 0.0464, Initial Validation Loss: 0.1320, Validation Loss: 0.0526,V Acc: 0.7523, Top 70th Acc: 0.8701, Bottom 30th Acc: 0.4688
Fold [4/5] Epoch [20/100] Initial Loss: 0.1386, Training Loss: 0.0312, Initial Validation Loss: 0.1320, Validation Loss: 0.0385,V Acc: 0.8349, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.6250
Fold [3/5] Epoch [10/100] Initial Loss: 0.1368, Training Loss: 0.0275, Initial Validation Loss: 0.1322, Validation Loss: 0.0293,V Acc: 0.8818, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 18  Rolling back to Epoch (base 0): 13  Top Validation Acc: 0.987012987012987
Fold [4/5] Epoch [0/100] Initial Loss: 0.1361, Training Loss: 0.1361, Initial Validation Loss: 0.1284, Validation Loss: 0.1284,V Acc: 0.5229, Top 70th Acc: 0.5844, Bottom 30th Acc: 0.3750
Fold [4/5] Epoch [10/100] Initial Loss: 0.1361, Training Loss: 0.0208, Initial Validation Loss: 0.1284, Validation Loss: 0.0259,V Acc: 0.8716, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.6250
Stopping early at Epoch (base 0): 12  Rolling back to Epoch (base 0): 7  Top Validation Acc: 0.974025974025974
Fold [5/5] Epoch [0/100] Initial Loss: 0.1371, Training Loss: 0.1371, Initial Validation Loss: 0.1226, Validation Loss: 0.1226,V Acc: 0.4167, Top 70th Acc: 0.4737, Bottom 30th Acc: 0.2812
Fold [5/5] Epoch [10/100] Initial Loss: 0.1371, Training Loss: 0.0281, Initial Validation Loss: 0.1226, Validation Loss: 0.0298,V Acc: 0.8796, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.6875
Stopping early at Epoch (base 0): 16  Rolling back to Epoch (base 0): 11  Top Validation Acc: 0.9473684210526315
82 4 [array([0.7818299 , 0.02881904, 0.02687948, 0.10561042, 0.05686115],
      dtype=float32)]
Running train_nn.py with seed 83
CUDA:False
Training samples count:  550
Training on 21 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1333, Training Loss: 0.1333, Initial Validation Loss: 0.1228, Validation Loss: 0.1228,V Acc: 0.5089, Top 70th Acc: 0.6076, Bottom 30th Acc: 0.2727
Fold [1/5] Epoch [10/100] Initial Loss: 0.1333, Training Loss: 0.0255, Initial Validation Loss: 0.1228, Validation Loss: 0.0206,V Acc: 0.9107, Top 70th Acc: 1.0000, Bottom 30th Acc: 0.6970
Fold [1/5] Epoch [20/100] Initial Loss: 0.1333, Training Loss: 0.0191, Initial Validation Loss: 0.1228, Validation Loss: 0.0173,V Acc: 0.9375, Top 70th Acc: 1.0000, Bottom 30th Acc: 0.7879
Stopping early at Epoch (base 0): 20  Rolling back to Epoch (base 0): 15  Top Validation Acc: 1.0
Fold [2/5] Epoch [0/100] Initial Loss: 0.1342, Training Loss: 0.1342, Initial Validation Loss: 0.1211, Validation Loss: 0.1211,V Acc: 0.5135, Top 70th Acc: 0.6026, Bottom 30th Acc: 0.3030
Fold [2/5] Epoch [10/100] Initial Loss: 0.1342, Training Loss: 0.0227, Initial Validation Loss: 0.1211, Validation Loss: 0.0219,V Acc: 0.8919, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 14  Rolling back to Epoch (base 0): 9  Top Validation Acc: 0.9743589743589743
Fold [3/5] Epoch [0/100] Initial Loss: 0.1366, Training Loss: 0.1366, Initial Validation Loss: 0.1210, Validation Loss: 0.1210,V Acc: 0.5273, Top 70th Acc: 0.5714, Bottom 30th Acc: 0.4242
Fold [3/5] Epoch [10/100] Initial Loss: 0.1366, Training Loss: 0.0202, Initial Validation Loss: 0.1210, Validation Loss: 0.0320,V Acc: 0.8636, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.6364
Fold [3/5] Epoch [20/100] Initial Loss: 0.1366, Training Loss: 0.0145, Initial Validation Loss: 0.1210, Validation Loss: 0.0272,V Acc: 0.8545, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.948051948051948
Fold [4/5] Epoch [0/100] Initial Loss: 0.1343, Training Loss: 0.1343, Initial Validation Loss: 0.1194, Validation Loss: 0.1194,V Acc: 0.5963, Top 70th Acc: 0.6623, Bottom 30th Acc: 0.4375
Fold [4/5] Epoch [10/100] Initial Loss: 0.1343, Training Loss: 0.0224, Initial Validation Loss: 0.1194, Validation Loss: 0.0290,V Acc: 0.8807, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.6875
Fold [4/5] Epoch [20/100] Initial Loss: 0.1343, Training Loss: 0.0151, Initial Validation Loss: 0.1194, Validation Loss: 0.0296,V Acc: 0.8257, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.5000
Stopping early at Epoch (base 0): 22  Rolling back to Epoch (base 0): 17  Top Validation Acc: 0.961038961038961
83 3 [array([0.67320454, 0.04863548, 0.03518029, 0.10267913, 0.14030056],
      dtype=float32)]
Fold [5/5] Epoch [0/100] Initial Loss: 0.1282, Training Loss: 0.1282, Initial Validation Loss: 0.1140, Validation Loss: 0.1140,V Acc: 0.4259, Top 70th Acc: 0.5000, Bottom 30th Acc: 0.2500
Fold [5/5] Epoch [10/100] Initial Loss: 0.1282, Training Loss: 0.0213, Initial Validation Loss: 0.1140, Validation Loss: 0.0378,V Acc: 0.7963, Top 70th Acc: 0.9079, Bottom 30th Acc: 0.5312
Fold [5/5] Epoch [20/100] Initial Loss: 0.1282, Training Loss: 0.0149, Initial Validation Loss: 0.1140, Validation Loss: 0.0345,V Acc: 0.8148, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.5312
Stopping early at Epoch (base 0): 21  Rolling back to Epoch (base 0): 16  Top Validation Acc: 0.9078947368421053
Running train_nn.py with seed 84
CUDA:False
Training samples count:  550
Training on 21 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1311, Training Loss: 0.1311, Initial Validation Loss: 0.1154, Validation Loss: 0.1154,V Acc: 0.4554, Top 70th Acc: 0.5696, Bottom 30th Acc: 0.1818
Fold [1/5] Epoch [10/100] Initial Loss: 0.1311, Training Loss: 0.0205, Initial Validation Loss: 0.1154, Validation Loss: 0.0327,V Acc: 0.8125, Top 70th Acc: 0.9620, Bottom 30th Acc: 0.4545
Stopping early at Epoch (base 0): 19  Rolling back to Epoch (base 0): 14  Top Validation Acc: 0.9493670886075949
Fold [2/5] Epoch [0/100] Initial Loss: 0.1385, Training Loss: 0.1385, Initial Validation Loss: 0.1312, Validation Loss: 0.1312,V Acc: 0.3514, Top 70th Acc: 0.4231, Bottom 30th Acc: 0.1818
Fold [2/5] Epoch [10/100] Initial Loss: 0.1385, Training Loss: 0.0215, Initial Validation Loss: 0.1312, Validation Loss: 0.0249,V Acc: 0.9009, Top 70th Acc: 1.0000, Bottom 30th Acc: 0.6667
Fold [2/5] Epoch [20/100] Initial Loss: 0.1385, Training Loss: 0.0153, Initial Validation Loss: 0.1312, Validation Loss: 0.0225,V Acc: 0.9009, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.7273
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.9743589743589743
84 1 [array([0.8238339 , 0.02493571, 0.02943365, 0.05999851, 0.06179825],
      dtype=float32)]
Fold [3/5] Epoch [0/100] Initial Loss: 0.1328, Training Loss: 0.1328, Initial Validation Loss: 0.1177, Validation Loss: 0.1177,V Acc: 0.4091, Top 70th Acc: 0.5455, Bottom 30th Acc: 0.0909
Fold [3/5] Epoch [10/100] Initial Loss: 0.1328, Training Loss: 0.0255, Initial Validation Loss: 0.1177, Validation Loss: 0.0329,V Acc: 0.8455, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.6667
Fold [3/5] Epoch [20/100] Initial Loss: 0.1328, Training Loss: 0.0188, Initial Validation Loss: 0.1177, Validation Loss: 0.0248,V Acc: 0.8636, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.948051948051948
Fold [4/5] Epoch [0/100] Initial Loss: 0.1335, Training Loss: 0.1335, Initial Validation Loss: 0.1215, Validation Loss: 0.1215,V Acc: 0.4587, Top 70th Acc: 0.5844, Bottom 30th Acc: 0.1562
Fold [4/5] Epoch [10/100] Initial Loss: 0.1335, Training Loss: 0.0267, Initial Validation Loss: 0.1215, Validation Loss: 0.0338,V Acc: 0.8349, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.5625
Fold [4/5] Epoch [20/100] Initial Loss: 0.1335, Training Loss: 0.0153, Initial Validation Loss: 0.1215, Validation Loss: 0.0234,V Acc: 0.8899, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.7188
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.948051948051948
Fold [5/5] Epoch [0/100] Initial Loss: 0.1358, Training Loss: 0.1358, Initial Validation Loss: 0.1235, Validation Loss: 0.1235,V Acc: 0.4352, Top 70th Acc: 0.5263, Bottom 30th Acc: 0.2188
Fold [5/5] Epoch [10/100] Initial Loss: 0.1358, Training Loss: 0.0213, Initial Validation Loss: 0.1235, Validation Loss: 0.0295,V Acc: 0.8704, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.7188
Stopping early at Epoch (base 0): 18  Rolling back to Epoch (base 0): 13  Top Validation Acc: 0.9473684210526315
Running train_nn.py with seed 85
CUDA:False
Training samples count:  550
Training on 21 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1307, Training Loss: 0.1307, Initial Validation Loss: 0.1201, Validation Loss: 0.1201,V Acc: 0.5000, Top 70th Acc: 0.5949, Bottom 30th Acc: 0.2727/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)

Fold [3/5] Epoch [10/100] Initial Loss: 0.1394, Training Loss: 0.0824, Initial Validation Loss: 0.1289, Validation Loss: 0.0771,V Acc: 0.6455, Top 70th Acc: 0.7662, Bottom 30th Acc: 0.3636
Fold [3/5] Epoch [20/100] Initial Loss: 0.1394, Training Loss: 0.0801, Initial Validation Loss: 0.1289, Validation Loss: 0.0752,V Acc: 0.6455, Top 70th Acc: 0.7792, Bottom 30th Acc: 0.3333
Stopping early at Epoch (base 0): 28  Rolling back to Epoch (base 0): 23  Top Validation Acc: 0.7662337662337663
Fold [4/5] Epoch [0/100] Initial Loss: 0.1318, Training Loss: 0.1318, Initial Validation Loss: 0.1213, Validation Loss: 0.1213,V Acc: 0.4037, Top 70th Acc: 0.4545, Bottom 30th Acc: 0.2812
Fold [4/5] Epoch [10/100] Initial Loss: 0.1318, Training Loss: 0.0807, Initial Validation Loss: 0.1213, Validation Loss: 0.0821,V Acc: 0.6055, Top 70th Acc: 0.7403, Bottom 30th Acc: 0.2812
Stopping early at Epoch (base 0): 19  Rolling back to Epoch (base 0): 14  Top Validation Acc: 0.7662337662337663
59 3 [array([0.12639329, 0.3741224 , 0.14029935, 0.19631062, 0.16287433],
      dtype=float32)]
Fold [5/5] Epoch [0/100] Initial Loss: 0.1361, Training Loss: 0.1361, Initial Validation Loss: 0.1223, Validation Loss: 0.1223,V Acc: 0.3704, Top 70th Acc: 0.4474, Bottom 30th Acc: 0.1875
Fold [5/5] Epoch [10/100] Initial Loss: 0.1361, Training Loss: 0.0826, Initial Validation Loss: 0.1223, Validation Loss: 0.0745,V Acc: 0.6389, Top 70th Acc: 0.7500, Bottom 30th Acc: 0.3750
Fold [5/5] Epoch [20/100] Initial Loss: 0.1361, Training Loss: 0.0802, Initial Validation Loss: 0.1223, Validation Loss: 0.0728,V Acc: 0.6481, Top 70th Acc: 0.7632, Bottom 30th Acc: 0.3750
Fold [5/5] Epoch [30/100] Initial Loss: 0.1361, Training Loss: 0.0792, Initial Validation Loss: 0.1223, Validation Loss: 0.0717,V Acc: 0.6296, Top 70th Acc: 0.7895, Bottom 30th Acc: 0.2500
Stopping early at Epoch (base 0): 32  Rolling back to Epoch (base 0): 27  Top Validation Acc: 0.7763157894736842
Running train_nn.py with seed 60
CUDA:False
Training samples count:  550
Training on 2 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1329, Training Loss: 0.1329, Initial Validation Loss: 0.1244, Validation Loss: 0.1244,V Acc: 0.5089, Top 70th Acc: 0.5570, Bottom 30th Acc: 0.3939
Fold [1/5] Epoch [10/100] Initial Loss: 0.1329, Training Loss: 0.0800, Initial Validation Loss: 0.1244, Validation Loss: 0.0822,V Acc: 0.6339, Top 70th Acc: 0.7215, Bottom 30th Acc: 0.4242
Fold [1/5] Epoch [20/100] Initial Loss: 0.1329, Training Loss: 0.0779, Initial Validation Loss: 0.1244, Validation Loss: 0.0804,V Acc: 0.6339, Top 70th Acc: 0.7215, Bottom 30th Acc: 0.4242
Fold [1/5] Epoch [30/100] Initial Loss: 0.1329, Training Loss: 0.0772, Initial Validation Loss: 0.1244, Validation Loss: 0.0804,V Acc: 0.6250, Top 70th Acc: 0.7342, Bottom 30th Acc: 0.3636
Stopping early at Epoch (base 0): 32  Rolling back to Epoch (base 0): 27  Top Validation Acc: 0.7215189873417721
Fold [2/5] Epoch [0/100] Initial Loss: 0.1296, Training Loss: 0.1296, Initial Validation Loss: 0.1176, Validation Loss: 0.1176,V Acc: 0.5135, Top 70th Acc: 0.6026, Bottom 30th Acc: 0.3030
Fold [2/5] Epoch [10/100] Initial Loss: 0.1296, Training Loss: 0.0800, Initial Validation Loss: 0.1176, Validation Loss: 0.0817,V Acc: 0.6036, Top 70th Acc: 0.7179, Bottom 30th Acc: 0.3333
Fold [2/5] Epoch [20/100] Initial Loss: 0.1296, Training Loss: 0.0780, Initial Validation Loss: 0.1176, Validation Loss: 0.0796,V Acc: 0.6216, Top 70th Acc: 0.7179, Bottom 30th Acc: 0.3939
Fold [2/5] Epoch [30/100] Initial Loss: 0.1296, Training Loss: 0.0772, Initial Validation Loss: 0.1176, Validation Loss: 0.0795,V Acc: 0.6396, Top 70th Acc: 0.7308, Bottom 30th Acc: 0.4242
Stopping early at Epoch (base 0): 39  Rolling back to Epoch (base 0): 34  Top Validation Acc: 0.717948717948718
Fold [3/5] Epoch [0/100] Initial Loss: 0.1418, Training Loss: 0.1418, Initial Validation Loss: 0.1304, Validation Loss: 0.1304,V Acc: 0.3000, Top 70th Acc: 0.3766, Bottom 30th Acc: 0.1212
Fold [3/5] Epoch [10/100] Initial Loss: 0.1418, Training Loss: 0.0813, Initial Validation Loss: 0.1304, Validation Loss: 0.0786,V Acc: 0.6545, Top 70th Acc: 0.7532, Bottom 30th Acc: 0.4242
Fold [3/5] Epoch [20/100] Initial Loss: 0.1418, Training Loss: 0.0793, Initial Validation Loss: 0.1304, Validation Loss: 0.0781,V Acc: 0.6455, Top 70th Acc: 0.7403, Bottom 30th Acc: 0.4242
Stopping early at Epoch (base 0): 20  Rolling back to Epoch (base 0): 15  Top Validation Acc: 0.7402597402597403
Fold [4/5] Epoch [0/100] Initial Loss: 0.1340, Training Loss: 0.1340, Initial Validation Loss: 0.1278, Validation Loss: 0.1278,V Acc: 0.5229, Top 70th Acc: 0.5584, Bottom 30th Acc: 0.4375
Fold [4/5] Epoch [10/100] Initial Loss: 0.1340, Training Loss: 0.0812, Initial Validation Loss: 0.1278, Validation Loss: 0.0794,V Acc: 0.6422, Top 70th Acc: 0.7532, Bottom 30th Acc: 0.3750
Stopping early at Epoch (base 0): 19  Rolling back to Epoch (base 0): 14  Top Validation Acc: 0.7402597402597403
Fold [5/5] Epoch [0/100] Initial Loss: 0.1372, Training Loss: 0.1372, Initial Validation Loss: 0.1237, Validation Loss: 0.1237,V Acc: 0.3889, Top 70th Acc: 0.4474, Bottom 30th Acc: 0.2500
Fold [5/5] Epoch [10/100] Initial Loss: 0.1372, Training Loss: 0.0818, Initial Validation Loss: 0.1237, Validation Loss: 0.0777,V Acc: 0.5926, Top 70th Acc: 0.7368, Bottom 30th Acc: 0.2500
Fold [5/5] Epoch [20/100] Initial Loss: 0.1372, Training Loss: 0.0801, Initial Validation Loss: 0.1237, Validation Loss: 0.0752,V Acc: 0.5926, Top 70th Acc: 0.7368, Bottom 30th Acc: 0.2500
Stopping early at Epoch (base 0): 29  Rolling back to Epoch (base 0): 24  Top Validation Acc: 0.7368421052631579
60 4 [array([0.14055899, 0.37997517, 0.13130581, 0.19597688, 0.15218313],
      dtype=float32)]
Running train_nn.py with seed 61
CUDA:False
Training samples count:  550
Training on 2 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1349, Training Loss: 0.1349, Initial Validation Loss: 0.1255, Validation Loss: 0.1255,V Acc: 0.4196, Top 70th Acc: 0.4304, Bottom 30th Acc: 0.3939
Fold [1/5] Epoch [10/100] Initial Loss: 0.1349, Training Loss: 0.0834, Initial Validation Loss: 0.1255, Validation Loss: 0.0729,V Acc: 0.6518, Top 70th Acc: 0.8228, Bottom 30th Acc: 0.2424
Fold [1/5] Epoch [20/100] Initial Loss: 0.1349, Training Loss: 0.0817, Initial Validation Loss: 0.1255, Validation Loss: 0.0712,V Acc: 0.6429, Top 70th Acc: 0.7975, Bottom 30th Acc: 0.2727
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.810126582278481
Fold [2/5] Epoch [0/100] Initial Loss: 0.1370, Training Loss: 0.1370, Initial Validation Loss: 0.1238, Validation Loss: 0.1238,V Acc: 0.4144, Top 70th Acc: 0.5128, Bottom 30th Acc: 0.1818
Fold [2/5] Epoch [10/100] Initial Loss: 0.1370, Training Loss: 0.0793, Initial Validation Loss: 0.1238, Validation Loss: 0.0836,V Acc: 0.5766, Top 70th Acc: 0.7308, Bottom 30th Acc: 0.2121
Stopping early at Epoch (base 0): 15  Rolling back to Epoch (base 0): 10  Top Validation Acc: 0.7051282051282052
Fold [3/5] Epoch [0/100] Initial Loss: 0.1394, Training Loss: 0.1394, Initial Validation Loss: 0.1287, Validation Loss: 0.1287,V Acc: 0.5182, Top 70th Acc: 0.5974, Bottom 30th Acc: 0.3333
Fold [3/5] Epoch [10/100] Initial Loss: 0.1394, Training Loss: 0.0813, Initial Validation Loss: 0.1287, Validation Loss: 0.0765,V Acc: 0.6545, Top 70th Acc: 0.7273, Bottom 30th Acc: 0.4848
Fold [3/5] Epoch [20/100] Initial Loss: 0.1394, Training Loss: 0.0799, Initial Validation Loss: 0.1287, Validation Loss: 0.0750,V Acc: 0.6455, Top 70th Acc: 0.7143, Bottom 30th Acc: 0.4848
Fold [3/5] Epoch [30/100] Initial Loss: 0.1394, Training Loss: 0.0796, Initial Validation Loss: 0.1287, Validation Loss: 0.0745,V Acc: 0.6545, Top 70th Acc: 0.7273, Bottom 30th Acc: 0.4848
Stopping early at Epoch (base 0): 31  Rolling back to Epoch (base 0): 26  Top Validation Acc: 0.7142857142857143
61 2 [array([0.12766571, 0.34438223, 0.15477969, 0.2112102 , 0.16196218],
      dtype=float32)]
Fold [4/5] Epoch [0/100] Initial Loss: 0.1374, Training Loss: 0.1374, Initial Validation Loss: 0.1275, Validation Loss: 0.1275,V Acc: 0.4404, Top 70th Acc: 0.5195, Bottom 30th Acc: 0.2500
Fold [4/5] Epoch [10/100] Initial Loss: 0.1374, Training Loss: 0.0792, Initial Validation Loss: 0.1275, Validation Loss: 0.0827,V Acc: 0.6239, Top 70th Acc: 0.7143, Bottom 30th Acc: 0.4062/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)

Fold [4/5] Epoch [10/100] Initial Loss: 0.1405, Training Loss: 0.0321, Initial Validation Loss: 0.1352, Validation Loss: 0.0314,V Acc: 0.8716, Top 70th Acc: 0.9870, Bottom 30th Acc: 0.5938
Fold [4/5] Epoch [20/100] Initial Loss: 0.1405, Training Loss: 0.0198, Initial Validation Loss: 0.1352, Validation Loss: 0.0235,V Acc: 0.9083, Top 70th Acc: 0.9870, Bottom 30th Acc: 0.7188
Fold [4/5] Epoch [30/100] Initial Loss: 0.1405, Training Loss: 0.0171, Initial Validation Loss: 0.1352, Validation Loss: 0.0249,V Acc: 0.8716, Top 70th Acc: 0.9870, Bottom 30th Acc: 0.5938
Stopping early at Epoch (base 0): 31  Rolling back to Epoch (base 0): 26  Top Validation Acc: 0.987012987012987
59 3 [array([0.7159599 , 0.06700973, 0.06408505, 0.08202571, 0.07091955],
      dtype=float32)]
Fold [5/5] Epoch [0/100] Initial Loss: 0.1383, Training Loss: 0.1383, Initial Validation Loss: 0.1293, Validation Loss: 0.1293,V Acc: 0.2685, Top 70th Acc: 0.3158, Bottom 30th Acc: 0.1562
Fold [5/5] Epoch [10/100] Initial Loss: 0.1383, Training Loss: 0.0270, Initial Validation Loss: 0.1293, Validation Loss: 0.0328,V Acc: 0.8333, Top 70th Acc: 0.9211, Bottom 30th Acc: 0.6250
Fold [5/5] Epoch [20/100] Initial Loss: 0.1383, Training Loss: 0.0170, Initial Validation Loss: 0.1293, Validation Loss: 0.0312,V Acc: 0.8148, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.5000
Stopping early at Epoch (base 0): 21  Rolling back to Epoch (base 0): 16  Top Validation Acc: 0.9342105263157895
Running train_nn.py with seed 60
CUDA:False
Training samples count:  550
Training on 30 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1437, Training Loss: 0.1437, Initial Validation Loss: 0.1363, Validation Loss: 0.1363,V Acc: 0.4107, Top 70th Acc: 0.5063, Bottom 30th Acc: 0.1818
Fold [1/5] Epoch [10/100] Initial Loss: 0.1437, Training Loss: 0.0296, Initial Validation Loss: 0.1363, Validation Loss: 0.0347,V Acc: 0.8304, Top 70th Acc: 0.9494, Bottom 30th Acc: 0.5455
Fold [1/5] Epoch [20/100] Initial Loss: 0.1437, Training Loss: 0.0186, Initial Validation Loss: 0.1363, Validation Loss: 0.0285,V Acc: 0.8482, Top 70th Acc: 0.9620, Bottom 30th Acc: 0.5758
Fold [1/5] Epoch [30/100] Initial Loss: 0.1437, Training Loss: 0.0165, Initial Validation Loss: 0.1363, Validation Loss: 0.0272,V Acc: 0.8571, Top 70th Acc: 0.9620, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 34  Rolling back to Epoch (base 0): 29  Top Validation Acc: 0.9620253164556962
Fold [2/5] Epoch [0/100] Initial Loss: 0.1389, Training Loss: 0.1389, Initial Validation Loss: 0.1317, Validation Loss: 0.1317,V Acc: 0.3333, Top 70th Acc: 0.3590, Bottom 30th Acc: 0.2727
Fold [2/5] Epoch [10/100] Initial Loss: 0.1389, Training Loss: 0.0271, Initial Validation Loss: 0.1317, Validation Loss: 0.0463,V Acc: 0.7658, Top 70th Acc: 0.8590, Bottom 30th Acc: 0.5455
Fold [2/5] Epoch [20/100] Initial Loss: 0.1389, Training Loss: 0.0170, Initial Validation Loss: 0.1317, Validation Loss: 0.0419,V Acc: 0.8018, Top 70th Acc: 0.8590, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 21  Rolling back to Epoch (base 0): 16  Top Validation Acc: 0.8589743589743589
Fold [3/5] Epoch [0/100] Initial Loss: 0.1383, Training Loss: 0.1383, Initial Validation Loss: 0.1320, Validation Loss: 0.1320,V Acc: 0.3455, Top 70th Acc: 0.3896, Bottom 30th Acc: 0.2424
Fold [3/5] Epoch [10/100] Initial Loss: 0.1383, Training Loss: 0.0349, Initial Validation Loss: 0.1320, Validation Loss: 0.0389,V Acc: 0.8000, Top 70th Acc: 0.8701, Bottom 30th Acc: 0.6364
Fold [3/5] Epoch [20/100] Initial Loss: 0.1383, Training Loss: 0.0180, Initial Validation Loss: 0.1320, Validation Loss: 0.0326,V Acc: 0.8091, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.5455
Fold [3/5] Epoch [30/100] Initial Loss: 0.1383, Training Loss: 0.0156, Initial Validation Loss: 0.1320, Validation Loss: 0.0296,V Acc: 0.8182, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.5152
Stopping early at Epoch (base 0): 35  Rolling back to Epoch (base 0): 30  Top Validation Acc: 0.935064935064935
Fold [4/5] Epoch [0/100] Initial Loss: 0.1387, Training Loss: 0.1387, Initial Validation Loss: 0.1349, Validation Loss: 0.1349,V Acc: 0.3394, Top 70th Acc: 0.4156, Bottom 30th Acc: 0.1562
Fold [4/5] Epoch [10/100] Initial Loss: 0.1387, Training Loss: 0.0318, Initial Validation Loss: 0.1349, Validation Loss: 0.0397,V Acc: 0.8624, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.7500
Fold [4/5] Epoch [20/100] Initial Loss: 0.1387, Training Loss: 0.0183, Initial Validation Loss: 0.1349, Validation Loss: 0.0321,V Acc: 0.8532, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6250
Stopping early at Epoch (base 0): 28  Rolling back to Epoch (base 0): 23  Top Validation Acc: 0.935064935064935
Fold [5/5] Epoch [0/100] Initial Loss: 0.1385, Training Loss: 0.1385, Initial Validation Loss: 0.1297, Validation Loss: 0.1297,V Acc: 0.2963, Top 70th Acc: 0.3553, Bottom 30th Acc: 0.1562
Fold [5/5] Epoch [10/100] Initial Loss: 0.1385, Training Loss: 0.0325, Initial Validation Loss: 0.1297, Validation Loss: 0.0300,V Acc: 0.8704, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.6562
Fold [5/5] Epoch [20/100] Initial Loss: 0.1385, Training Loss: 0.0199, Initial Validation Loss: 0.1297, Validation Loss: 0.0238,V Acc: 0.8796, Top 70th Acc: 0.9737, Bottom 30th Acc: 0.6562
Stopping early at Epoch (base 0): 27  Rolling back to Epoch (base 0): 22  Top Validation Acc: 0.9736842105263158
60 4 [array([0.74970216, 0.1143873 , 0.0299761 , 0.05978502, 0.04614937],
      dtype=float32)]
Running train_nn.py with seed 61
CUDA:False
Training samples count:  550
Training on 30 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1376, Training Loss: 0.1376, Initial Validation Loss: 0.1321, Validation Loss: 0.1321,V Acc: 0.3214, Top 70th Acc: 0.3671, Bottom 30th Acc: 0.2121
Fold [1/5] Epoch [10/100] Initial Loss: 0.1376, Training Loss: 0.0314, Initial Validation Loss: 0.1321, Validation Loss: 0.0335,V Acc: 0.8393, Top 70th Acc: 0.9241, Bottom 30th Acc: 0.6364
Fold [1/5] Epoch [20/100] Initial Loss: 0.1376, Training Loss: 0.0182, Initial Validation Loss: 0.1321, Validation Loss: 0.0300,V Acc: 0.8393, Top 70th Acc: 0.9494, Bottom 30th Acc: 0.5758
Fold [1/5] Epoch [30/100] Initial Loss: 0.1376, Training Loss: 0.0152, Initial Validation Loss: 0.1321, Validation Loss: 0.0291,V Acc: 0.8482, Top 70th Acc: 0.9241, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 36  Rolling back to Epoch (base 0): 31  Top Validation Acc: 0.9240506329113924
Fold [2/5] Epoch [0/100] Initial Loss: 0.1383, Training Loss: 0.1383, Initial Validation Loss: 0.1333, Validation Loss: 0.1333,V Acc: 0.3243, Top 70th Acc: 0.4231, Bottom 30th Acc: 0.0909
Fold [2/5] Epoch [10/100] Initial Loss: 0.1383, Training Loss: 0.0344, Initial Validation Loss: 0.1333, Validation Loss: 0.0466,V Acc: 0.7748, Top 70th Acc: 0.8462, Bottom 30th Acc: 0.6061
Fold [2/5] Epoch [20/100] Initial Loss: 0.1383, Training Loss: 0.0176, Initial Validation Loss: 0.1333, Validation Loss: 0.0339,V Acc: 0.8288, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 28  Rolling back to Epoch (base 0): 23  Top Validation Acc: 0.8974358974358975
Fold [3/5] Epoch [0/100] Initial Loss: 0.1411, Training Loss: 0.1411, Initial Validation Loss: 0.1324, Validation Loss: 0.1324,V Acc: 0.3455, Top 70th Acc: 0.3896, Bottom 30th Acc: 0.2424
Fold [3/5] Epoch [10/100] Initial Loss: 0.1411, Training Loss: 0.0304, Initial Validation Loss: 0.1324, Validation Loss: 0.0394,V Acc: 0.8364, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.6061
Fold [3/5] Epoch [20/100] Initial Loss: 0.1411, Training Loss: 0.0172, Initial Validation Loss: 0.1324, Validation Loss: 0.0320,V Acc: 0.8182, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.4848
Fold [3/5] Epoch [30/100] Initial Loss: 0.1411, Training Loss: 0.0150, Initial Validation Loss: 0.1324, Validation Loss: 0.0315,V Acc: 0.8182, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.4848
Stopping early at Epoch (base 0): 33  Rolling back to Epoch (base 0): 28  Top Validation Acc: 0.961038961038961
61 2 [array([0.5721783 , 0.04160152, 0.05994499, 0.16988882, 0.15638635],
      dtype=float32)]
Fold [4/5] Epoch [0/100] Initial Loss: 0.1377, Training Loss: 0.1377, Initial Validation Loss: 0.1303, Validation Loss: 0.1303,V Acc: 0.3394, Top 70th Acc: 0.3377, Bottom 30th Acc: 0.3438
Stopping early at Epoch (base 0): 76  Rolling back to Epoch (base 0): 71  Top Validation Acc: 0.922077922077922
Fold [5/5] Epoch [0/100] Initial Loss: 0.1390, Training Loss: 0.1390, Initial Validation Loss: 0.1361, Validation Loss: 0.1361,V Acc: 0.3519, Top 70th Acc: 0.3947, Bottom 30th Acc: 0.2500
Fold [5/5] Epoch [10/100] Initial Loss: 0.1390, Training Loss: 0.0245, Initial Validation Loss: 0.1361, Validation Loss: 0.0467,V Acc: 0.7870, Top 70th Acc: 0.8947, Bottom 30th Acc: 0.5312
Fold [5/5] Epoch [20/100] Initial Loss: 0.1390, Training Loss: 0.0073, Initial Validation Loss: 0.1361, Validation Loss: 0.0397,V Acc: 0.7963, Top 70th Acc: 0.8947, Bottom 30th Acc: 0.5625
Fold [5/5] Epoch [30/100] Initial Loss: 0.1390, Training Loss: 0.0050, Initial Validation Loss: 0.1361, Validation Loss: 0.0381,V Acc: 0.8148, Top 70th Acc: 0.9079, Bottom 30th Acc: 0.5938
Fold [5/5] Epoch [40/100] Initial Loss: 0.1390, Training Loss: 0.0044, Initial Validation Loss: 0.1361, Validation Loss: 0.0368,V Acc: 0.8241, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.5625
Fold [5/5] Epoch [50/100] Initial Loss: 0.1390, Training Loss: 0.0041, Initial Validation Loss: 0.1361, Validation Loss: 0.0354,V Acc: 0.8241, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.5312
Fold [5/5] Epoch [60/100] Initial Loss: 0.1390, Training Loss: 0.0039, Initial Validation Loss: 0.1361, Validation Loss: 0.0342,V Acc: 0.8333, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.5625
Fold [5/5] Epoch [70/100] Initial Loss: 0.1390, Training Loss: 0.0037, Initial Validation Loss: 0.1361, Validation Loss: 0.0327,V Acc: 0.8426, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.5938
Fold [5/5] Epoch [80/100] Initial Loss: 0.1390, Training Loss: 0.0037, Initial Validation Loss: 0.1361, Validation Loss: 0.0322,V Acc: 0.8426, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.5938
Fold [5/5] Epoch [90/100] Initial Loss: 0.1390, Training Loss: 0.0036, Initial Validation Loss: 0.1361, Validation Loss: 0.0318,V Acc: 0.8426, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.6250
Stopping early at Epoch (base 0): 91  Rolling back to Epoch (base 0): 86  Top Validation Acc: 0.9473684210526315
Running train_nn.py with seed 47
CUDA:False
Training samples count:  550
Training on 162 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1375, Training Loss: 0.1375, Initial Validation Loss: 0.1350, Validation Loss: 0.1350,V Acc: 0.2500, Top 70th Acc: 0.3291, Bottom 30th Acc: 0.0606
Fold [1/5] Epoch [10/100] Initial Loss: 0.1375, Training Loss: 0.0162, Initial Validation Loss: 0.1350, Validation Loss: 0.0444,V Acc: 0.7946, Top 70th Acc: 0.8608, Bottom 30th Acc: 0.6364
Fold [1/5] Epoch [20/100] Initial Loss: 0.1375, Training Loss: 0.0059, Initial Validation Loss: 0.1350, Validation Loss: 0.0429,V Acc: 0.7589, Top 70th Acc: 0.8987, Bottom 30th Acc: 0.4242
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.8987341772151899
Fold [2/5] Epoch [0/100] Initial Loss: 0.1412, Training Loss: 0.1412, Initial Validation Loss: 0.1331, Validation Loss: 0.1331,V Acc: 0.2973, Top 70th Acc: 0.3462, Bottom 30th Acc: 0.1818
Fold [2/5] Epoch [10/100] Initial Loss: 0.1412, Training Loss: 0.0157, Initial Validation Loss: 0.1331, Validation Loss: 0.0349,V Acc: 0.8739, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.6667
Fold [2/5] Epoch [20/100] Initial Loss: 0.1412, Training Loss: 0.0041, Initial Validation Loss: 0.1331, Validation Loss: 0.0317,V Acc: 0.8739, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 20  Rolling back to Epoch (base 0): 15  Top Validation Acc: 0.9615384615384616
47 1 [array([0.22303657, 0.05490952, 0.07154357, 0.21596822, 0.43454203],
      dtype=float32)]
Fold [3/5] Epoch [0/100] Initial Loss: 0.1380, Training Loss: 0.1380, Initial Validation Loss: 0.1303, Validation Loss: 0.1303,V Acc: 0.4545, Top 70th Acc: 0.5714, Bottom 30th Acc: 0.1818
Fold [3/5] Epoch [10/100] Initial Loss: 0.1380, Training Loss: 0.0111, Initial Validation Loss: 0.1303, Validation Loss: 0.0352,V Acc: 0.8091, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.5152
Fold [3/5] Epoch [20/100] Initial Loss: 0.1380, Training Loss: 0.0047, Initial Validation Loss: 0.1303, Validation Loss: 0.0329,V Acc: 0.8091, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.4545
Stopping early at Epoch (base 0): 20  Rolling back to Epoch (base 0): 15  Top Validation Acc: 0.961038961038961
Fold [4/5] Epoch [0/100] Initial Loss: 0.1390, Training Loss: 0.1390, Initial Validation Loss: 0.1325, Validation Loss: 0.1325,V Acc: 0.3486, Top 70th Acc: 0.4026, Bottom 30th Acc: 0.2188
Fold [4/5] Epoch [10/100] Initial Loss: 0.1390, Training Loss: 0.0259, Initial Validation Loss: 0.1325, Validation Loss: 0.0287,V Acc: 0.9083, Top 70th Acc: 0.9870, Bottom 30th Acc: 0.7188
Fold [4/5] Epoch [20/100] Initial Loss: 0.1390, Training Loss: 0.0060, Initial Validation Loss: 0.1325, Validation Loss: 0.0185,V Acc: 0.8991, Top 70th Acc: 1.0000, Bottom 30th Acc: 0.6562
Fold [4/5] Epoch [30/100] Initial Loss: 0.1390, Training Loss: 0.0044, Initial Validation Loss: 0.1325, Validation Loss: 0.0174,V Acc: 0.9083, Top 70th Acc: 0.9870, Bottom 30th Acc: 0.7188
Stopping early at Epoch (base 0): 35  Rolling back to Epoch (base 0): 30  Top Validation Acc: 0.987012987012987
Fold [5/5] Epoch [0/100] Initial Loss: 0.1402, Training Loss: 0.1402, Initial Validation Loss: 0.1356, Validation Loss: 0.1356,V Acc: 0.2500, Top 70th Acc: 0.3553, Bottom 30th Acc: 0.0000
Fold [5/5] Epoch [10/100] Initial Loss: 0.1402, Training Loss: 0.0359, Initial Validation Loss: 0.1356, Validation Loss: 0.0488,V Acc: 0.7407, Top 70th Acc: 0.8947, Bottom 30th Acc: 0.3750
Fold [5/5] Epoch [20/100] Initial Loss: 0.1402, Training Loss: 0.0069, Initial Validation Loss: 0.1356, Validation Loss: 0.0306,V Acc: 0.8519, Top 70th Acc: 0.9737, Bottom 30th Acc: 0.5625
Fold [5/5] Epoch [30/100] Initial Loss: 0.1402, Training Loss: 0.0048, Initial Validation Loss: 0.1356, Validation Loss: 0.0287,V Acc: 0.8426, Top 70th Acc: 0.9737, Bottom 30th Acc: 0.5312
Fold [5/5] Epoch [40/100] Initial Loss: 0.1402, Training Loss: 0.0041, Initial Validation Loss: 0.1356, Validation Loss: 0.0276,V Acc: 0.8519, Top 70th Acc: 0.9737, Bottom 30th Acc: 0.5625
Fold [5/5] Epoch [50/100] Initial Loss: 0.1402, Training Loss: 0.0039, Initial Validation Loss: 0.1356, Validation Loss: 0.0278,V Acc: 0.8611, Top 70th Acc: 0.9868, Bottom 30th Acc: 0.5625
Stopping early at Epoch (base 0): 57  Rolling back to Epoch (base 0): 52  Top Validation Acc: 0.9868421052631579
Running train_nn.py with seed 48
CUDA:False
Training samples count:  550
Training on 162 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1439, Training Loss: 0.1439, Initial Validation Loss: 0.1384, Validation Loss: 0.1384,V Acc: 0.3929, Top 70th Acc: 0.5063, Bottom 30th Acc: 0.1212
Fold [1/5] Epoch [10/100] Initial Loss: 0.1439, Training Loss: 0.0168, Initial Validation Loss: 0.1384, Validation Loss: 0.0416,V Acc: 0.7946, Top 70th Acc: 0.9241, Bottom 30th Acc: 0.4848
Fold [1/5] Epoch [20/100] Initial Loss: 0.1439, Training Loss: 0.0052, Initial Validation Loss: 0.1384, Validation Loss: 0.0382,V Acc: 0.8214, Top 70th Acc: 0.8987, Bottom 30th Acc: 0.6364
Fold [1/5] Epoch [30/100] Initial Loss: 0.1439, Training Loss: 0.0041, Initial Validation Loss: 0.1384, Validation Loss: 0.0365,V Acc: 0.8125, Top 70th Acc: 0.9367, Bottom 30th Acc: 0.5152
Fold [1/5] Epoch [40/100] Initial Loss: 0.1439, Training Loss: 0.0039, Initial Validation Loss: 0.1384, Validation Loss: 0.0355,V Acc: 0.8304, Top 70th Acc: 0.9367, Bottom 30th Acc: 0.5758
Fold [1/5] Epoch [50/100] Initial Loss: 0.1439, Training Loss: 0.0037, Initial Validation Loss: 0.1384, Validation Loss: 0.0348,V Acc: 0.8036, Top 70th Acc: 0.9367, Bottom 30th Acc: 0.4848
Fold [1/5] Epoch [60/100] Initial Loss: 0.1439, Training Loss: 0.0036, Initial Validation Loss: 0.1384, Validation Loss: 0.0347,V Acc: 0.7946, Top 70th Acc: 0.9367, Bottom 30th Acc: 0.4545
Fold [1/5] Epoch [70/100] Initial Loss: 0.1439, Training Loss: 0.0036, Initial Validation Loss: 0.1384, Validation Loss: 0.0341,V Acc: 0.8036, Top 70th Acc: 0.9494, Bottom 30th Acc: 0.4545
Fold [1/5] Epoch [80/100] Initial Loss: 0.1439, Training Loss: 0.0035, Initial Validation Loss: 0.1384, Validation Loss: 0.0338,V Acc: 0.8036, Top 70th Acc: 0.9620, Bottom 30th Acc: 0.4242/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)

Stopping early at Epoch (base 0): 35  Rolling back to Epoch (base 0): 30  Top Validation Acc: 0.9090909090909091
Fold [5/5] Epoch [0/100] Initial Loss: 0.1378, Training Loss: 0.1378, Initial Validation Loss: 0.1361, Validation Loss: 0.1361,V Acc: 0.3981, Top 70th Acc: 0.4211, Bottom 30th Acc: 0.3438
Fold [5/5] Epoch [10/100] Initial Loss: 0.1378, Training Loss: 0.0318, Initial Validation Loss: 0.1361, Validation Loss: 0.0353,V Acc: 0.8426, Top 70th Acc: 0.9737, Bottom 30th Acc: 0.5312
Fold [5/5] Epoch [20/100] Initial Loss: 0.1378, Training Loss: 0.0147, Initial Validation Loss: 0.1361, Validation Loss: 0.0260,V Acc: 0.8796, Top 70th Acc: 0.9868, Bottom 30th Acc: 0.6250
Fold [5/5] Epoch [30/100] Initial Loss: 0.1378, Training Loss: 0.0120, Initial Validation Loss: 0.1361, Validation Loss: 0.0242,V Acc: 0.8981, Top 70th Acc: 0.9868, Bottom 30th Acc: 0.6875
Stopping early at Epoch (base 0): 38  Rolling back to Epoch (base 0): 33  Top Validation Acc: 0.9868421052631579
63 4 [array([0.39322448, 0.05122848, 0.10239569, 0.14888011, 0.30427125],
      dtype=float32)]
Running train_nn.py with seed 64
CUDA:False
Training samples count:  550
Training on 40 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1441, Training Loss: 0.1441, Initial Validation Loss: 0.1337, Validation Loss: 0.1337,V Acc: 0.2768, Top 70th Acc: 0.3418, Bottom 30th Acc: 0.1212
Fold [1/5] Epoch [10/100] Initial Loss: 0.1441, Training Loss: 0.0394, Initial Validation Loss: 0.1337, Validation Loss: 0.0457,V Acc: 0.7589, Top 70th Acc: 0.8987, Bottom 30th Acc: 0.4242
Fold [1/5] Epoch [20/100] Initial Loss: 0.1441, Training Loss: 0.0155, Initial Validation Loss: 0.1337, Validation Loss: 0.0289,V Acc: 0.8393, Top 70th Acc: 0.9620, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 29  Rolling back to Epoch (base 0): 24  Top Validation Acc: 0.9620253164556962
64 0 [array([0.5560007 , 0.08478738, 0.05828216, 0.10745761, 0.19347219],
      dtype=float32)]
Fold [2/5] Epoch [0/100] Initial Loss: 0.1390, Training Loss: 0.1390, Initial Validation Loss: 0.1356, Validation Loss: 0.1356,V Acc: 0.4054, Top 70th Acc: 0.4744, Bottom 30th Acc: 0.2424
Fold [2/5] Epoch [10/100] Initial Loss: 0.1390, Training Loss: 0.0340, Initial Validation Loss: 0.1356, Validation Loss: 0.0376,V Acc: 0.8198, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.5152
Fold [2/5] Epoch [20/100] Initial Loss: 0.1390, Training Loss: 0.0134, Initial Validation Loss: 0.1356, Validation Loss: 0.0330,V Acc: 0.7928, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.3636
Fold [2/5] Epoch [30/100] Initial Loss: 0.1390, Training Loss: 0.0100, Initial Validation Loss: 0.1356, Validation Loss: 0.0330,V Acc: 0.7928, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.4242
Stopping early at Epoch (base 0): 33  Rolling back to Epoch (base 0): 28  Top Validation Acc: 0.9615384615384616
Fold [3/5] Epoch [0/100] Initial Loss: 0.1387, Training Loss: 0.1387, Initial Validation Loss: 0.1316, Validation Loss: 0.1316,V Acc: 0.2818, Top 70th Acc: 0.3506, Bottom 30th Acc: 0.1212
Fold [3/5] Epoch [10/100] Initial Loss: 0.1387, Training Loss: 0.0258, Initial Validation Loss: 0.1316, Validation Loss: 0.0396,V Acc: 0.7909, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.4545
Fold [3/5] Epoch [20/100] Initial Loss: 0.1387, Training Loss: 0.0132, Initial Validation Loss: 0.1316, Validation Loss: 0.0319,V Acc: 0.8545, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 27  Rolling back to Epoch (base 0): 22  Top Validation Acc: 0.948051948051948
Fold [4/5] Epoch [0/100] Initial Loss: 0.1398, Training Loss: 0.1398, Initial Validation Loss: 0.1379, Validation Loss: 0.1379,V Acc: 0.2569, Top 70th Acc: 0.2468, Bottom 30th Acc: 0.2812
Fold [4/5] Epoch [10/100] Initial Loss: 0.1398, Training Loss: 0.0315, Initial Validation Loss: 0.1379, Validation Loss: 0.0306,V Acc: 0.8716, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.6562
Fold [4/5] Epoch [20/100] Initial Loss: 0.1398, Training Loss: 0.0154, Initial Validation Loss: 0.1379, Validation Loss: 0.0215,V Acc: 0.8991, Top 70th Acc: 0.9870, Bottom 30th Acc: 0.6875
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.974025974025974
Fold [5/5] Epoch [0/100] Initial Loss: 0.1411, Training Loss: 0.1411, Initial Validation Loss: 0.1318, Validation Loss: 0.1318,V Acc: 0.2593, Top 70th Acc: 0.2895, Bottom 30th Acc: 0.1875
Fold [5/5] Epoch [10/100] Initial Loss: 0.1411, Training Loss: 0.0274, Initial Validation Loss: 0.1318, Validation Loss: 0.0399,V Acc: 0.8333, Top 70th Acc: 0.9079, Bottom 30th Acc: 0.6562
Fold [5/5] Epoch [20/100] Initial Loss: 0.1411, Training Loss: 0.0132, Initial Validation Loss: 0.1318, Validation Loss: 0.0320,V Acc: 0.8333, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.5938
Stopping early at Epoch (base 0): 27  Rolling back to Epoch (base 0): 22  Top Validation Acc: 0.9342105263157895
Running train_nn.py with seed 65
CUDA:False
Training samples count:  550
Training on 40 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1388, Training Loss: 0.1388, Initial Validation Loss: 0.1314, Validation Loss: 0.1314,V Acc: 0.3482, Top 70th Acc: 0.3924, Bottom 30th Acc: 0.2424
Fold [1/5] Epoch [10/100] Initial Loss: 0.1388, Training Loss: 0.0285, Initial Validation Loss: 0.1314, Validation Loss: 0.0389,V Acc: 0.8482, Top 70th Acc: 0.9114, Bottom 30th Acc: 0.6970
Fold [1/5] Epoch [20/100] Initial Loss: 0.1388, Training Loss: 0.0143, Initial Validation Loss: 0.1314, Validation Loss: 0.0340,V Acc: 0.8304, Top 70th Acc: 0.9114, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.8987341772151899
Fold [2/5] Epoch [0/100] Initial Loss: 0.1425, Training Loss: 0.1425, Initial Validation Loss: 0.1408, Validation Loss: 0.1408,V Acc: 0.2523, Top 70th Acc: 0.2564, Bottom 30th Acc: 0.2424
Fold [2/5] Epoch [10/100] Initial Loss: 0.1425, Training Loss: 0.0427, Initial Validation Loss: 0.1408, Validation Loss: 0.0563,V Acc: 0.7207, Top 70th Acc: 0.8590, Bottom 30th Acc: 0.3939
Fold [2/5] Epoch [20/100] Initial Loss: 0.1425, Training Loss: 0.0192, Initial Validation Loss: 0.1408, Validation Loss: 0.0344,V Acc: 0.8559, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.6667
Fold [2/5] Epoch [30/100] Initial Loss: 0.1425, Training Loss: 0.0128, Initial Validation Loss: 0.1408, Validation Loss: 0.0302,V Acc: 0.8649, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.6970
Fold [2/5] Epoch [40/100] Initial Loss: 0.1425, Training Loss: 0.0112, Initial Validation Loss: 0.1408, Validation Loss: 0.0299,V Acc: 0.8559, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 42  Rolling back to Epoch (base 0): 37  Top Validation Acc: 0.9358974358974359
Fold [3/5] Epoch [0/100] Initial Loss: 0.1385, Training Loss: 0.1385, Initial Validation Loss: 0.1342, Validation Loss: 0.1342,V Acc: 0.3455, Top 70th Acc: 0.4026, Bottom 30th Acc: 0.2121
Fold [3/5] Epoch [10/100] Initial Loss: 0.1385, Training Loss: 0.0285, Initial Validation Loss: 0.1342, Validation Loss: 0.0481,V Acc: 0.7727, Top 70th Acc: 0.8831, Bottom 30th Acc: 0.5152
Fold [3/5] Epoch [20/100] Initial Loss: 0.1385, Training Loss: 0.0139, Initial Validation Loss: 0.1342, Validation Loss: 0.0395,V Acc: 0.7909, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.5152
Fold [3/5] Epoch [30/100] Initial Loss: 0.1385, Training Loss: 0.0115, Initial Validation Loss: 0.1342, Validation Loss: 0.0384,V Acc: 0.8182, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 39  Rolling back to Epoch (base 0): 34  Top Validation Acc: 0.922077922077922
Fold [4/5] Epoch [0/100] Initial Loss: 0.1421, Training Loss: 0.1421, Initial Validation Loss: 0.1350, Validation Loss: 0.1350,V Acc: 0.2477, Top 70th Acc: 0.2857, Bottom 30th Acc: 0.1562
Fold [4/5] Epoch [10/100] Initial Loss: 0.1421, Training Loss: 0.0357, Initial Validation Loss: 0.1350, Validation Loss: 0.0417,V Acc: 0.7890, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.5000
Fold [4/5] Epoch [20/100] Initial Loss: 0.1421, Training Loss: 0.0164, Initial Validation Loss: 0.1350, Validation Loss: 0.0324,V Acc: 0.8073, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.4688
Stopping early at Epoch (base 0): 29  Rolling back to Epoch (base 0): 24  Top Validation Acc:
Fold [4/5] Epoch [30/100] Initial Loss: 0.1386, Training Loss: 0.0243, Initial Validation Loss: 0.1320, Validation Loss: 0.0314,V Acc: 0.8624, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6562
Fold [4/5] Epoch [40/100] Initial Loss: 0.1386, Training Loss: 0.0215, Initial Validation Loss: 0.1320, Validation Loss: 0.0309,V Acc: 0.8807, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.7188
Stopping early at Epoch (base 0): 44  Rolling back to Epoch (base 0): 39  Top Validation Acc: 0.948051948051948
Fold [5/5] Epoch [0/100] Initial Loss: 0.1379, Training Loss: 0.1379, Initial Validation Loss: 0.1314, Validation Loss: 0.1314,V Acc: 0.3611, Top 70th Acc: 0.4211, Bottom 30th Acc: 0.2188
Fold [5/5] Epoch [10/100] Initial Loss: 0.1379, Training Loss: 0.0343, Initial Validation Loss: 0.1314, Validation Loss: 0.0444,V Acc: 0.8056, Top 70th Acc: 0.8684, Bottom 30th Acc: 0.6562
Fold [5/5] Epoch [20/100] Initial Loss: 0.1379, Training Loss: 0.0235, Initial Validation Loss: 0.1314, Validation Loss: 0.0360,V Acc: 0.8333, Top 70th Acc: 0.9211, Bottom 30th Acc: 0.6250
Fold [5/5] Epoch [30/100] Initial Loss: 0.1379, Training Loss: 0.0214, Initial Validation Loss: 0.1314, Validation Loss: 0.0339,V Acc: 0.8426, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.5938
Stopping early at Epoch (base 0): 35  Rolling back to Epoch (base 0): 30  Top Validation Acc: 0.9342105263157895
Running train_nn.py with seed 62
CUDA:False
Training samples count:  550
Training on 20 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1377, Training Loss: 0.1377, Initial Validation Loss: 0.1365, Validation Loss: 0.1365,V Acc: 0.3750, Top 70th Acc: 0.4177, Bottom 30th Acc: 0.2727
Fold [1/5] Epoch [10/100] Initial Loss: 0.1377, Training Loss: 0.0493, Initial Validation Loss: 0.1365, Validation Loss: 0.0442,V Acc: 0.7946, Top 70th Acc: 0.9114, Bottom 30th Acc: 0.5152
Fold [1/5] Epoch [20/100] Initial Loss: 0.1377, Training Loss: 0.0273, Initial Validation Loss: 0.1365, Validation Loss: 0.0226,V Acc: 0.9018, Top 70th Acc: 0.9747, Bottom 30th Acc: 0.7273
Stopping early at Epoch (base 0): 29  Rolling back to Epoch (base 0): 24  Top Validation Acc: 0.9620253164556962
Fold [2/5] Epoch [0/100] Initial Loss: 0.1383, Training Loss: 0.1383, Initial Validation Loss: 0.1336, Validation Loss: 0.1336,V Acc: 0.3874, Top 70th Acc: 0.5128, Bottom 30th Acc: 0.0909
Fold [2/5] Epoch [10/100] Initial Loss: 0.1383, Training Loss: 0.0393, Initial Validation Loss: 0.1336, Validation Loss: 0.0541,V Acc: 0.7477, Top 70th Acc: 0.8333, Bottom 30th Acc: 0.5455
Fold [2/5] Epoch [20/100] Initial Loss: 0.1383, Training Loss: 0.0215, Initial Validation Loss: 0.1336, Validation Loss: 0.0446,V Acc: 0.7748, Top 70th Acc: 0.8590, Bottom 30th Acc: 0.5758
Fold [2/5] Epoch [30/100] Initial Loss: 0.1383, Training Loss: 0.0190, Initial Validation Loss: 0.1336, Validation Loss: 0.0448,V Acc: 0.7568, Top 70th Acc: 0.8590, Bottom 30th Acc: 0.5152
Stopping early at Epoch (base 0): 33  Rolling back to Epoch (base 0): 28  Top Validation Acc: 0.8717948717948718
Fold [3/5] Epoch [0/100] Initial Loss: 0.1382, Training Loss: 0.1382, Initial Validation Loss: 0.1329, Validation Loss: 0.1329,V Acc: 0.3364, Top 70th Acc: 0.3766, Bottom 30th Acc: 0.2424
Fold [3/5] Epoch [10/100] Initial Loss: 0.1382, Training Loss: 0.0406, Initial Validation Loss: 0.1329, Validation Loss: 0.0449,V Acc: 0.8091, Top 70th Acc: 0.8831, Bottom 30th Acc: 0.6364
Fold [3/5] Epoch [20/100] Initial Loss: 0.1382, Training Loss: 0.0245, Initial Validation Loss: 0.1329, Validation Loss: 0.0327,V Acc: 0.8364, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.5152
Fold [3/5] Epoch [30/100] Initial Loss: 0.1382, Training Loss: 0.0214, Initial Validation Loss: 0.1329, Validation Loss: 0.0332,V Acc: 0.8182, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 31  Rolling back to Epoch (base 0): 26  Top Validation Acc: 0.948051948051948
Fold [4/5] Epoch [0/100] Initial Loss: 0.1362, Training Loss: 0.1362, Initial Validation Loss: 0.1302, Validation Loss: 0.1302,V Acc: 0.3486, Top 70th Acc: 0.3896, Bottom 30th Acc: 0.2500
Fold [4/5] Epoch [10/100] Initial Loss: 0.1362, Training Loss: 0.0404, Initial Validation Loss: 0.1302, Validation Loss: 0.0441,V Acc: 0.7615, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.4062
Fold [4/5] Epoch [20/100] Initial Loss: 0.1362, Training Loss: 0.0239, Initial Validation Loss: 0.1302, Validation Loss: 0.0332,V Acc: 0.8532, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.6875
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.922077922077922
62 3 [array([0.4163795 , 0.07238583, 0.0504657 , 0.25049177, 0.21027711],
      dtype=float32)]
Fold [5/5] Epoch [0/100] Initial Loss: 0.1394, Training Loss: 0.1394, Initial Validation Loss: 0.1293, Validation Loss: 0.1293,V Acc: 0.2500, Top 70th Acc: 0.3026, Bottom 30th Acc: 0.1250
Fold [5/5] Epoch [10/100] Initial Loss: 0.1394, Training Loss: 0.0360, Initial Validation Loss: 0.1293, Validation Loss: 0.0366,V Acc: 0.8241, Top 70th Acc: 0.9079, Bottom 30th Acc: 0.6250
Fold [5/5] Epoch [20/100] Initial Loss: 0.1394, Training Loss: 0.0232, Initial Validation Loss: 0.1293, Validation Loss: 0.0306,V Acc: 0.8426, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.5938
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.9473684210526315
Running train_nn.py with seed 63
CUDA:False
Training samples count:  550
Training on 20 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1389, Training Loss: 0.1389, Initial Validation Loss: 0.1365, Validation Loss: 0.1365,V Acc: 0.2679, Top 70th Acc: 0.3418, Bottom 30th Acc: 0.0909
Fold [1/5] Epoch [10/100] Initial Loss: 0.1389, Training Loss: 0.0336, Initial Validation Loss: 0.1365, Validation Loss: 0.0309,V Acc: 0.8929, Top 70th Acc: 0.9367, Bottom 30th Acc: 0.7879
Fold [1/5] Epoch [20/100] Initial Loss: 0.1389, Training Loss: 0.0257, Initial Validation Loss: 0.1365, Validation Loss: 0.0281,V Acc: 0.8839, Top 70th Acc: 0.9367, Bottom 30th Acc: 0.7576
Fold [1/5] Epoch [30/100] Initial Loss: 0.1389, Training Loss: 0.0234, Initial Validation Loss: 0.1365, Validation Loss: 0.0287,V Acc: 0.8929, Top 70th Acc: 0.9367, Bottom 30th Acc: 0.7879
Stopping early at Epoch (base 0): 30  Rolling back to Epoch (base 0): 25  Top Validation Acc: 0.9367088607594937
Fold [2/5] Epoch [0/100] Initial Loss: 0.1396, Training Loss: 0.1396, Initial Validation Loss: 0.1347, Validation Loss: 0.1347,V Acc: 0.2793, Top 70th Acc: 0.2949, Bottom 30th Acc: 0.2424
Fold [2/5] Epoch [10/100] Initial Loss: 0.1396, Training Loss: 0.0301, Initial Validation Loss: 0.1347, Validation Loss: 0.0404,V Acc: 0.7928, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.4242
Stopping early at Epoch (base 0): 17  Rolling back to Epoch (base 0): 12  Top Validation Acc: 0.9358974358974359
Fold [3/5] Epoch [0/100] Initial Loss: 0.1381, Training Loss: 0.1381, Initial Validation Loss: 0.1294, Validation Loss: 0.1294,V Acc: 0.3455, Top 70th Acc: 0.4156, Bottom 30th Acc: 0.1818
Fold [3/5] Epoch [10/100] Initial Loss: 0.1381, Training Loss: 0.0367, Initial Validation Loss: 0.1294, Validation Loss: 0.0360,V Acc: 0.7909, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.4848
Fold [3/5] Epoch [20/100] Initial Loss: 0.1381, Training Loss: 0.0246, Initial Validation Loss: 0.1294, Validation Loss: 0.0315,V Acc: 0.8000, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.4545
Stopping early at Epoch (base 0): 21  Rolling back to Epoch (base 0): 16  Top Validation Acc: 0.935064935064935
Fold [4/5] Epoch [0/100] Initial Loss: 0.1433, Training Loss: 0.1433, Initial Validation Loss: 0.1307, Validation Loss: 0.1307,V Acc: 0.2844, Top 70th Acc: 0.3506, Bottom 30th Acc: 0.1250
Fold [4/5] Epoch [10/100] Initial Loss: 0.1433, Training Loss: 0.0401, Initial Validation Loss: 0.1307, Validation Loss: 0.0499,V Acc: 0.7615, Top 70th Acc: 0.8182, Bottom 30th Acc: 0.6250
Fold [4/5] Epoch [20/100] Initial Loss: 0.1433, Training Loss: 0.0254, Initial Validation Loss: 0.1307, Validation Loss: 0.0359,V Acc: 0.8165, Top 70th Acc: 0.8961, Bottom 30th Acc: 0.6250
Stopping early at Epoch (base 0): 28  Rolling back to Epoch (base 0): 23  Top Validation Acc: 0.8831168831168831
Fold [5/5] Epoch [0/100] Initial Loss: 0.1357, Training Loss: 0.1357, Initial Validation Loss: 0.1297, Validation Loss: 0.1297,V Acc: 0.4167, Top 70th Acc: 0.5000, Bottom 30th Acc: 0.2188
Fold [1/5] Epoch [10/100] Initial Loss: 0.1307, Training Loss: 0.0245, Initial Validation Loss: 0.1201, Validation Loss: 0.0275,V Acc: 0.8750, Top 70th Acc: 0.9494, Bottom 30th Acc: 0.6970
Fold [1/5] Epoch [20/100] Initial Loss: 0.1307, Training Loss: 0.0164, Initial Validation Loss: 0.1201, Validation Loss: 0.0227,V Acc: 0.8929, Top 70th Acc: 0.9747, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.9746835443037974
Fold [2/5] Epoch [0/100] Initial Loss: 0.1340, Training Loss: 0.1340, Initial Validation Loss: 0.1233, Validation Loss: 0.1233,V Acc: 0.5135, Top 70th Acc: 0.7051, Bottom 30th Acc: 0.0606
Fold [2/5] Epoch [10/100] Initial Loss: 0.1340, Training Loss: 0.0217, Initial Validation Loss: 0.1233, Validation Loss: 0.0314,V Acc: 0.8739, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.6970
Fold [2/5] Epoch [20/100] Initial Loss: 0.1340, Training Loss: 0.0138, Initial Validation Loss: 0.1233, Validation Loss: 0.0304,V Acc: 0.8739, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 21  Rolling back to Epoch (base 0): 16  Top Validation Acc: 0.9615384615384616
Fold [3/5] Epoch [0/100] Initial Loss: 0.1300, Training Loss: 0.1300, Initial Validation Loss: 0.1100, Validation Loss: 0.1100,V Acc: 0.6091, Top 70th Acc: 0.6623, Bottom 30th Acc: 0.4848
Fold [3/5] Epoch [10/100] Initial Loss: 0.1300, Training Loss: 0.0212, Initial Validation Loss: 0.1100, Validation Loss: 0.0178,V Acc: 0.9182, Top 70th Acc: 1.0000, Bottom 30th Acc: 0.7273
Stopping early at Epoch (base 0): 15  Rolling back to Epoch (base 0): 10  Top Validation Acc: 0.948051948051948
85 2 [array([0.79340184, 0.0341549 , 0.02450178, 0.09889894, 0.04904254],
      dtype=float32)]
Fold [4/5] Epoch [0/100] Initial Loss: 0.1350, Training Loss: 0.1350, Initial Validation Loss: 0.1236, Validation Loss: 0.1236,V Acc: 0.4404, Top 70th Acc: 0.4935, Bottom 30th Acc: 0.3125
Fold [4/5] Epoch [10/100] Initial Loss: 0.1350, Training Loss: 0.0212, Initial Validation Loss: 0.1236, Validation Loss: 0.0265,V Acc: 0.8899, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.6875
Stopping early at Epoch (base 0): 15  Rolling back to Epoch (base 0): 10  Top Validation Acc: 0.974025974025974
Fold [5/5] Epoch [0/100] Initial Loss: 0.1333, Training Loss: 0.1333, Initial Validation Loss: 0.1116, Validation Loss: 0.1116,V Acc: 0.4074, Top 70th Acc: 0.5263, Bottom 30th Acc: 0.1250
Fold [5/5] Epoch [10/100] Initial Loss: 0.1333, Training Loss: 0.0179, Initial Validation Loss: 0.1116, Validation Loss: 0.0339,V Acc: 0.7963, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.4688
Stopping early at Epoch (base 0): 18  Rolling back to Epoch (base 0): 13  Top Validation Acc: 0.9473684210526315
Running train_nn.py with seed 86
CUDA:False
Training samples count:  550
Training on 21 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1375, Training Loss: 0.1375, Initial Validation Loss: 0.1255, Validation Loss: 0.1255,V Acc: 0.4643, Top 70th Acc: 0.6076, Bottom 30th Acc: 0.1212
Fold [1/5] Epoch [10/100] Initial Loss: 0.1375, Training Loss: 0.0233, Initial Validation Loss: 0.1255, Validation Loss: 0.0394,V Acc: 0.8125, Top 70th Acc: 0.9367, Bottom 30th Acc: 0.5152
Stopping early at Epoch (base 0): 17  Rolling back to Epoch (base 0): 12  Top Validation Acc: 0.9493670886075949
86 0 [array([0.6744287 , 0.01695092, 0.07411909, 0.11993816, 0.11456317],
      dtype=float32)]
Fold [2/5] Epoch [0/100] Initial Loss: 0.1342, Training Loss: 0.1342, Initial Validation Loss: 0.1248, Validation Loss: 0.1248,V Acc: 0.4234, Top 70th Acc: 0.4487, Bottom 30th Acc: 0.3636
Fold [2/5] Epoch [10/100] Initial Loss: 0.1342, Training Loss: 0.0223, Initial Validation Loss: 0.1248, Validation Loss: 0.0257,V Acc: 0.8829, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 13  Rolling back to Epoch (base 0): 8  Top Validation Acc: 0.9871794871794872
Fold [3/5] Epoch [0/100] Initial Loss: 0.1362, Training Loss: 0.1362, Initial Validation Loss: 0.1239, Validation Loss: 0.1239,V Acc: 0.3909, Top 70th Acc: 0.4416, Bottom 30th Acc: 0.2727
Fold [3/5] Epoch [10/100] Initial Loss: 0.1362, Training Loss: 0.0210, Initial Validation Loss: 0.1239, Validation Loss: 0.0221,V Acc: 0.9000, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.7273
Fold [3/5] Epoch [20/100] Initial Loss: 0.1362, Training Loss: 0.0169, Initial Validation Loss: 0.1239, Validation Loss: 0.0191,V Acc: 0.8727, Top 70th Acc: 0.9870, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 21  Rolling back to Epoch (base 0): 16  Top Validation Acc: 0.961038961038961
Fold [4/5] Epoch [0/100] Initial Loss: 0.1334, Training Loss: 0.1334, Initial Validation Loss: 0.1172, Validation Loss: 0.1172,V Acc: 0.4404, Top 70th Acc: 0.5455, Bottom 30th Acc: 0.1875
Fold [4/5] Epoch [10/100] Initial Loss: 0.1334, Training Loss: 0.0219, Initial Validation Loss: 0.1172, Validation Loss: 0.0293,V Acc: 0.8624, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.6250
Fold [4/5] Epoch [20/100] Initial Loss: 0.1334, Training Loss: 0.0154, Initial Validation Loss: 0.1172, Validation Loss: 0.0307,V Acc: 0.8440, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.5938
Stopping early at Epoch (base 0): 20  Rolling back to Epoch (base 0): 15  Top Validation Acc: 0.948051948051948
Fold [5/5] Epoch [0/100] Initial Loss: 0.1356, Training Loss: 0.1356, Initial Validation Loss: 0.1218, Validation Loss: 0.1218,V Acc: 0.4722, Top 70th Acc: 0.5658, Bottom 30th Acc: 0.2500
Fold [5/5] Epoch [10/100] Initial Loss: 0.1356, Training Loss: 0.0235, Initial Validation Loss: 0.1218, Validation Loss: 0.0390,V Acc: 0.8056, Top 70th Acc: 0.8816, Bottom 30th Acc: 0.6250
Fold [5/5] Epoch [20/100] Initial Loss: 0.1356, Training Loss: 0.0170, Initial Validation Loss: 0.1218, Validation Loss: 0.0314,V Acc: 0.8426, Top 70th Acc: 0.9211, Bottom 30th Acc: 0.6562
Stopping early at Epoch (base 0): 21  Rolling back to Epoch (base 0): 16  Top Validation Acc: 0.9342105263157895
Running train_nn.py with seed 87
CUDA:False
Training samples count:  550
Training on 21 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1383, Training Loss: 0.1383, Initial Validation Loss: 0.1314, Validation Loss: 0.1314,V Acc: 0.3304, Top 70th Acc: 0.4304, Bottom 30th Acc: 0.0909
Fold [1/5] Epoch [10/100] Initial Loss: 0.1383, Training Loss: 0.0206, Initial Validation Loss: 0.1314, Validation Loss: 0.0307,V Acc: 0.8571, Top 70th Acc: 0.9241, Bottom 30th Acc: 0.6970
Fold [1/5] Epoch [20/100] Initial Loss: 0.1383, Training Loss: 0.0149, Initial Validation Loss: 0.1314, Validation Loss: 0.0255,V Acc: 0.8839, Top 70th Acc: 0.9241, Bottom 30th Acc: 0.7879
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.9620253164556962
Fold [2/5] Epoch [0/100] Initial Loss: 0.1312, Training Loss: 0.1312, Initial Validation Loss: 0.1197, Validation Loss: 0.1197,V Acc: 0.5586, Top 70th Acc: 0.6410, Bottom 30th Acc: 0.3636
Fold [2/5] Epoch [10/100] Initial Loss: 0.1312, Training Loss: 0.0206, Initial Validation Loss: 0.1197, Validation Loss: 0.0255,V Acc: 0.8829, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.6667
Fold [2/5] Epoch [20/100] Initial Loss: 0.1312, Training Loss: 0.0149, Initial Validation Loss: 0.1197, Validation Loss: 0.0252,V Acc: 0.8829, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 27  Rolling back to Epoch (base 0): 22  Top Validation Acc: 0.9615384615384616
87 1 [array([0.86371934, 0.01105241, 0.0155047 , 0.05625336, 0.05347025],
      dtype=float32)]
Fold [3/5] Epoch [0/100] Initial Loss: 0.1342, Training Loss: 0.1342, Initial Validation Loss: 0.1199, Validation Loss: 0.1199,V Acc: 0.6000, Top 70th Acc: 0.7273, Bottom 30th Acc: 0.3030
Fold [3/5] Epoch [10/100] Initial Loss: 0.1342, Training Loss: 0.0342, Initial Validation Loss: 0.1199, Validation Loss: 0.0337,V Acc: 0.8364, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.5758
Fold [3/5] Epoch [20/100] Initial Loss: 0.1342, Training Loss: 0.0207, Initial Validation Loss: 0.1199, Validation Loss: 0.0264,V Acc: 0.8545, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 28  Rolling back to Epoch (base 0): 23  Top Validation Acc: 0.987012987012987
Fold [4/5] Epoch [0/100] Initial Loss: 0.1338, Training Loss: 0.1338, Initial Validation Loss: 0.1166, Validation Loss: 0.1166,V Acc: 0.5046, Top 70th Acc: 0.6753, Bottom 30th Acc: 0.0938
Fold [4/5] Epoch [20/100] Initial Loss: 0.1374, Training Loss: 0.0768, Initial Validation Loss: 0.1275, Validation Loss: 0.0815,V Acc: 0.6147, Top 70th Acc: 0.7403, Bottom 30th Acc: 0.3125
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.7272727272727273
Fold [5/5] Epoch [0/100] Initial Loss: 0.1379, Training Loss: 0.1379, Initial Validation Loss: 0.1311, Validation Loss: 0.1311,V Acc: 0.3704, Top 70th Acc: 0.4211, Bottom 30th Acc: 0.2500
Fold [5/5] Epoch [10/100] Initial Loss: 0.1379, Training Loss: 0.0797, Initial Validation Loss: 0.1311, Validation Loss: 0.0819,V Acc: 0.6204, Top 70th Acc: 0.7237, Bottom 30th Acc: 0.3750
Fold [5/5] Epoch [20/100] Initial Loss: 0.1379, Training Loss: 0.0771, Initial Validation Loss: 0.1311, Validation Loss: 0.0820,V Acc: 0.6481, Top 70th Acc: 0.6974, Bottom 30th Acc: 0.5312
Stopping early at Epoch (base 0): 21  Rolling back to Epoch (base 0): 16  Top Validation Acc: 0.7105263157894737
Running train_nn.py with seed 62
CUDA:False
Training samples count:  550
Training on 2 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1375, Training Loss: 0.1375, Initial Validation Loss: 0.1357, Validation Loss: 0.1357,V Acc: 0.3661, Top 70th Acc: 0.4937, Bottom 30th Acc: 0.0606
Fold [1/5] Epoch [10/100] Initial Loss: 0.1375, Training Loss: 0.0833, Initial Validation Loss: 0.1357, Validation Loss: 0.0741,V Acc: 0.6875, Top 70th Acc: 0.7722, Bottom 30th Acc: 0.4848
Fold [1/5] Epoch [20/100] Initial Loss: 0.1375, Training Loss: 0.0812, Initial Validation Loss: 0.1357, Validation Loss: 0.0726,V Acc: 0.6964, Top 70th Acc: 0.7722, Bottom 30th Acc: 0.5152
Stopping early at Epoch (base 0): 28  Rolling back to Epoch (base 0): 23  Top Validation Acc: 0.7721518987341772
Fold [2/5] Epoch [0/100] Initial Loss: 0.1349, Training Loss: 0.1349, Initial Validation Loss: 0.1240, Validation Loss: 0.1240,V Acc: 0.3874, Top 70th Acc: 0.4359, Bottom 30th Acc: 0.2727
Fold [2/5] Epoch [10/100] Initial Loss: 0.1349, Training Loss: 0.0799, Initial Validation Loss: 0.1240, Validation Loss: 0.0796,V Acc: 0.6306, Top 70th Acc: 0.7179, Bottom 30th Acc: 0.4242
Fold [2/5] Epoch [20/100] Initial Loss: 0.1349, Training Loss: 0.0783, Initial Validation Loss: 0.1240, Validation Loss: 0.0785,V Acc: 0.6486, Top 70th Acc: 0.7436, Bottom 30th Acc: 0.4242
Fold [2/5] Epoch [30/100] Initial Loss: 0.1349, Training Loss: 0.0772, Initial Validation Loss: 0.1240, Validation Loss: 0.0784,V Acc: 0.6577, Top 70th Acc: 0.7308, Bottom 30th Acc: 0.4848
Stopping early at Epoch (base 0): 39  Rolling back to Epoch (base 0): 34  Top Validation Acc: 0.7307692307692307
Fold [3/5] Epoch [0/100] Initial Loss: 0.1395, Training Loss: 0.1395, Initial Validation Loss: 0.1252, Validation Loss: 0.1252,V Acc: 0.5364, Top 70th Acc: 0.5844, Bottom 30th Acc: 0.4242
Fold [3/5] Epoch [10/100] Initial Loss: 0.1395, Training Loss: 0.0817, Initial Validation Loss: 0.1252, Validation Loss: 0.0752,V Acc: 0.6364, Top 70th Acc: 0.7792, Bottom 30th Acc: 0.3030
Fold [3/5] Epoch [20/100] Initial Loss: 0.1395, Training Loss: 0.0794, Initial Validation Loss: 0.1252, Validation Loss: 0.0747,V Acc: 0.6273, Top 70th Acc: 0.7532, Bottom 30th Acc: 0.3333
Stopping early at Epoch (base 0): 22  Rolling back to Epoch (base 0): 17  Top Validation Acc: 0.7532467532467533
Fold [4/5] Epoch [0/100] Initial Loss: 0.1389, Training Loss: 0.1389, Initial Validation Loss: 0.1330, Validation Loss: 0.1330,V Acc: 0.3761, Top 70th Acc: 0.3766, Bottom 30th Acc: 0.3750
Fold [4/5] Epoch [10/100] Initial Loss: 0.1389, Training Loss: 0.0792, Initial Validation Loss: 0.1330, Validation Loss: 0.0884,V Acc: 0.5688, Top 70th Acc: 0.7013, Bottom 30th Acc: 0.2500
Fold [4/5] Epoch [20/100] Initial Loss: 0.1389, Training Loss: 0.0768, Initial Validation Loss: 0.1330, Validation Loss: 0.0872,V Acc: 0.5872, Top 70th Acc: 0.6883, Bottom 30th Acc: 0.3438
Stopping early at Epoch (base 0): 20  Rolling back to Epoch (base 0): 15  Top Validation Acc: 0.6883116883116883
62 3 [array([0.11277231, 0.4047852 , 0.12640828, 0.19413374, 0.16190036],
      dtype=float32)]
Fold [5/5] Epoch [0/100] Initial Loss: 0.1382, Training Loss: 0.1382, Initial Validation Loss: 0.1201, Validation Loss: 0.1201,V Acc: 0.4352, Top 70th Acc: 0.5263, Bottom 30th Acc: 0.2188
Fold [5/5] Epoch [10/100] Initial Loss: 0.1382, Training Loss: 0.0802, Initial Validation Loss: 0.1201, Validation Loss: 0.0803,V Acc: 0.5833, Top 70th Acc: 0.7105, Bottom 30th Acc: 0.2812
Fold [5/5] Epoch [20/100] Initial Loss: 0.1382, Training Loss: 0.0779, Initial Validation Loss: 0.1201, Validation Loss: 0.0819,V Acc: 0.5926, Top 70th Acc: 0.6974, Bottom 30th Acc: 0.3438
Stopping early at Epoch (base 0): 21  Rolling back to Epoch (base 0): 16  Top Validation Acc: 0.7236842105263158
Running train_nn.py with seed 63
CUDA:False
Training samples count:  550
Training on 2 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1383, Training Loss: 0.1383, Initial Validation Loss: 0.1355, Validation Loss: 0.1355,V Acc: 0.2500, Top 70th Acc: 0.3418, Bottom 30th Acc: 0.0303
Fold [1/5] Epoch [10/100] Initial Loss: 0.1383, Training Loss: 0.0845, Initial Validation Loss: 0.1355, Validation Loss: 0.0734,V Acc: 0.6696, Top 70th Acc: 0.8228, Bottom 30th Acc: 0.3030
Fold [1/5] Epoch [20/100] Initial Loss: 0.1383, Training Loss: 0.0821, Initial Validation Loss: 0.1355, Validation Loss: 0.0703,V Acc: 0.6786, Top 70th Acc: 0.8354, Bottom 30th Acc: 0.3030
Fold [1/5] Epoch [30/100] Initial Loss: 0.1383, Training Loss: 0.0811, Initial Validation Loss: 0.1355, Validation Loss: 0.0707,V Acc: 0.6964, Top 70th Acc: 0.8101, Bottom 30th Acc: 0.4242
Stopping early at Epoch (base 0): 31  Rolling back to Epoch (base 0): 26  Top Validation Acc: 0.8227848101265823
Fold [2/5] Epoch [0/100] Initial Loss: 0.1365, Training Loss: 0.1365, Initial Validation Loss: 0.1277, Validation Loss: 0.1277,V Acc: 0.4414, Top 70th Acc: 0.5128, Bottom 30th Acc: 0.2727
Fold [2/5] Epoch [10/100] Initial Loss: 0.1365, Training Loss: 0.0785, Initial Validation Loss: 0.1277, Validation Loss: 0.0893,V Acc: 0.5495, Top 70th Acc: 0.6410, Bottom 30th Acc: 0.3333
Fold [2/5] Epoch [20/100] Initial Loss: 0.1365, Training Loss: 0.0763, Initial Validation Loss: 0.1277, Validation Loss: 0.0882,V Acc: 0.5676, Top 70th Acc: 0.6667, Bottom 30th Acc: 0.3333
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.6794871794871795
Fold [3/5] Epoch [0/100] Initial Loss: 0.1390, Training Loss: 0.1390, Initial Validation Loss: 0.1252, Validation Loss: 0.1252,V Acc: 0.3182, Top 70th Acc: 0.3896, Bottom 30th Acc: 0.1515
Fold [3/5] Epoch [10/100] Initial Loss: 0.1390, Training Loss: 0.0826, Initial Validation Loss: 0.1252, Validation Loss: 0.0706,V Acc: 0.6727, Top 70th Acc: 0.7532, Bottom 30th Acc: 0.4848
Fold [3/5] Epoch [20/100] Initial Loss: 0.1390, Training Loss: 0.0807, Initial Validation Loss: 0.1252, Validation Loss: 0.0693,V Acc: 0.6636, Top 70th Acc: 0.7662, Bottom 30th Acc: 0.4242
Fold [3/5] Epoch [30/100] Initial Loss: 0.1390, Training Loss: 0.0805, Initial Validation Loss: 0.1252, Validation Loss: 0.0686,V Acc: 0.6909, Top 70th Acc: 0.7662, Bottom 30th Acc: 0.5152
Fold [3/5] Epoch [40/100] Initial Loss: 0.1390, Training Loss: 0.0800, Initial Validation Loss: 0.1252, Validation Loss: 0.0676,V Acc: 0.6909, Top 70th Acc: 0.7792, Bottom 30th Acc: 0.4848
Stopping early at Epoch (base 0): 44  Rolling back to Epoch (base 0): 39  Top Validation Acc: 0.7662337662337663
Fold [4/5] Epoch [0/100] Initial Loss: 0.1339, Training Loss: 0.1339, Initial Validation Loss: 0.1191, Validation Loss: 0.1191,V Acc: 0.4771, Top 70th Acc: 0.5584, Bottom 30th Acc: 0.2812
Fold [4/5] Epoch [10/100] Initial Loss: 0.1339, Training Loss: 0.0788, Initial Validation Loss: 0.1191, Validation Loss: 0.0860,V Acc: 0.5872, Top 70th Acc: 0.6883, Bottom 30th Acc: 0.3438
Stopping early at Epoch (base 0): 16  Rolling back to Epoch (base 0): 11  Top Validation Acc: 0.6883116883116883
Fold [5/5] Epoch [0/100] Initial Loss: 0.1333, Training Loss: 0.1333, Initial Validation Loss: 0.1270, Validation Loss: 0.1270,V Acc: 0.4074, Top 70th Acc: 0.4605, Bottom 30th Acc: 0.2812
Fold [5/5] Epoch [10/100] Initial Loss: 0.1333, Training Loss: 0.0808, Initial Validation Loss: 0.1270, Validation Loss: 0.0790,V Acc: 0.6296, Top 70th Acc: 0.8158, Bottom 30th Acc: 0.1875
Fold [4/5] Epoch [10/100] Initial Loss: 0.1377, Training Loss: 0.0341, Initial Validation Loss: 0.1303, Validation Loss: 0.0399,V Acc: 0.7798, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.4375
Fold [4/5] Epoch [20/100] Initial Loss: 0.1377, Training Loss: 0.0178, Initial Validation Loss: 0.1303, Validation Loss: 0.0293,V Acc: 0.8532, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6250
Fold [4/5] Epoch [30/100] Initial Loss: 0.1377, Training Loss: 0.0153, Initial Validation Loss: 0.1303, Validation Loss: 0.0299,V Acc: 0.8624, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.6250
Stopping early at Epoch (base 0): 30  Rolling back to Epoch (base 0): 25  Top Validation Acc: 0.961038961038961
Fold [5/5] Epoch [0/100] Initial Loss: 0.1393, Training Loss: 0.1393, Initial Validation Loss: 0.1348, Validation Loss: 0.1348,V Acc: 0.2315, Top 70th Acc: 0.2500, Bottom 30th Acc: 0.1875
Fold [5/5] Epoch [10/100] Initial Loss: 0.1393, Training Loss: 0.0260, Initial Validation Loss: 0.1348, Validation Loss: 0.0334,V Acc: 0.8611, Top 70th Acc: 0.9211, Bottom 30th Acc: 0.7188
Stopping early at Epoch (base 0): 18  Rolling back to Epoch (base 0): 13  Top Validation Acc: 0.9342105263157895
Running train_nn.py with seed 62
CUDA:False
Training samples count:  550
Training on 30 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1376, Training Loss: 0.1376, Initial Validation Loss: 0.1356, Validation Loss: 0.1356,V Acc: 0.3036, Top 70th Acc: 0.3924, Bottom 30th Acc: 0.0909
Fold [1/5] Epoch [10/100] Initial Loss: 0.1376, Training Loss: 0.0423, Initial Validation Loss: 0.1356, Validation Loss: 0.0338,V Acc: 0.8750, Top 70th Acc: 0.9494, Bottom 30th Acc: 0.6970
Fold [1/5] Epoch [20/100] Initial Loss: 0.1376, Training Loss: 0.0217, Initial Validation Loss: 0.1356, Validation Loss: 0.0183,V Acc: 0.9196, Top 70th Acc: 0.9873, Bottom 30th Acc: 0.7576
Fold [1/5] Epoch [30/100] Initial Loss: 0.1376, Training Loss: 0.0184, Initial Validation Loss: 0.1356, Validation Loss: 0.0184,V Acc: 0.9196, Top 70th Acc: 0.9620, Bottom 30th Acc: 0.8182
Stopping early at Epoch (base 0): 32  Rolling back to Epoch (base 0): 27  Top Validation Acc: 0.9620253164556962
Fold [2/5] Epoch [0/100] Initial Loss: 0.1366, Training Loss: 0.1366, Initial Validation Loss: 0.1309, Validation Loss: 0.1309,V Acc: 0.3333, Top 70th Acc: 0.3974, Bottom 30th Acc: 0.1818
Fold [2/5] Epoch [10/100] Initial Loss: 0.1366, Training Loss: 0.0405, Initial Validation Loss: 0.1309, Validation Loss: 0.0564,V Acc: 0.7117, Top 70th Acc: 0.8205, Bottom 30th Acc: 0.4545
Fold [2/5] Epoch [20/100] Initial Loss: 0.1366, Training Loss: 0.0168, Initial Validation Loss: 0.1309, Validation Loss: 0.0376,V Acc: 0.8108, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 28  Rolling back to Epoch (base 0): 23  Top Validation Acc: 0.9230769230769231
Fold [3/5] Epoch [0/100] Initial Loss: 0.1361, Training Loss: 0.1361, Initial Validation Loss: 0.1301, Validation Loss: 0.1301,V Acc: 0.3818, Top 70th Acc: 0.5065, Bottom 30th Acc: 0.0909
Fold [3/5] Epoch [10/100] Initial Loss: 0.1361, Training Loss: 0.0303, Initial Validation Loss: 0.1301, Validation Loss: 0.0348,V Acc: 0.8545, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.5758
Fold [3/5] Epoch [20/100] Initial Loss: 0.1361, Training Loss: 0.0190, Initial Validation Loss: 0.1301, Validation Loss: 0.0302,V Acc: 0.8909, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.7879
Stopping early at Epoch (base 0): 21  Rolling back to Epoch (base 0): 16  Top Validation Acc: 0.935064935064935
Fold [4/5] Epoch [0/100] Initial Loss: 0.1384, Training Loss: 0.1384, Initial Validation Loss: 0.1343, Validation Loss: 0.1343,V Acc: 0.3028, Top 70th Acc: 0.3377, Bottom 30th Acc: 0.2188
Fold [4/5] Epoch [10/100] Initial Loss: 0.1384, Training Loss: 0.0385, Initial Validation Loss: 0.1343, Validation Loss: 0.0485,V Acc: 0.7706, Top 70th Acc: 0.8571, Bottom 30th Acc: 0.5625
Fold [4/5] Epoch [20/100] Initial Loss: 0.1384, Training Loss: 0.0199, Initial Validation Loss: 0.1343, Validation Loss: 0.0359,V Acc: 0.8165, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.5312
Fold [4/5] Epoch [30/100] Initial Loss: 0.1384, Training Loss: 0.0166, Initial Validation Loss: 0.1343, Validation Loss: 0.0341,V Acc: 0.7982, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.4688
Stopping early at Epoch (base 0): 34  Rolling back to Epoch (base 0): 29  Top Validation Acc: 0.948051948051948
62 3 [array([0.7365607 , 0.06441396, 0.04229268, 0.08574693, 0.07098576],
      dtype=float32)]
Fold [5/5] Epoch [0/100] Initial Loss: 0.1400, Training Loss: 0.1400, Initial Validation Loss: 0.1275, Validation Loss: 0.1275,V Acc: 0.3611, Top 70th Acc: 0.4737, Bottom 30th Acc: 0.0938
Fold [5/5] Epoch [10/100] Initial Loss: 0.1400, Training Loss: 0.0292, Initial Validation Loss: 0.1275, Validation Loss: 0.0325,V Acc: 0.8426, Top 70th Acc: 0.9737, Bottom 30th Acc: 0.5312
Fold [5/5] Epoch [20/100] Initial Loss: 0.1400, Training Loss: 0.0186, Initial Validation Loss: 0.1275, Validation Loss: 0.0276,V Acc: 0.8426, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.5625
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.9605263157894737
Running train_nn.py with seed 63
CUDA:False
Training samples count:  550
Training on 30 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1398, Training Loss: 0.1398, Initial Validation Loss: 0.1375, Validation Loss: 0.1375,V Acc: 0.2589, Top 70th Acc: 0.2911, Bottom 30th Acc: 0.1818
Fold [1/5] Epoch [10/100] Initial Loss: 0.1398, Training Loss: 0.0375, Initial Validation Loss: 0.1375, Validation Loss: 0.0384,V Acc: 0.8214, Top 70th Acc: 0.9241, Bottom 30th Acc: 0.5758
Fold [1/5] Epoch [20/100] Initial Loss: 0.1398, Training Loss: 0.0194, Initial Validation Loss: 0.1375, Validation Loss: 0.0247,V Acc: 0.8929, Top 70th Acc: 0.9494, Bottom 30th Acc: 0.7576
Stopping early at Epoch (base 0): 27  Rolling back to Epoch (base 0): 22  Top Validation Acc: 0.9620253164556962
Fold [2/5] Epoch [0/100] Initial Loss: 0.1413, Training Loss: 0.1413, Initial Validation Loss: 0.1367, Validation Loss: 0.1367,V Acc: 0.2523, Top 70th Acc: 0.3205, Bottom 30th Acc: 0.0909
Fold [2/5] Epoch [10/100] Initial Loss: 0.1413, Training Loss: 0.0299, Initial Validation Loss: 0.1367, Validation Loss: 0.0358,V Acc: 0.8378, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.5152
Fold [2/5] Epoch [20/100] Initial Loss: 0.1413, Training Loss: 0.0163, Initial Validation Loss: 0.1367, Validation Loss: 0.0311,V Acc: 0.8468, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.6061
Fold [2/5] Epoch [30/100] Initial Loss: 0.1413, Training Loss: 0.0139, Initial Validation Loss: 0.1367, Validation Loss: 0.0312,V Acc: 0.8288, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.4848
Stopping early at Epoch (base 0): 30  Rolling back to Epoch (base 0): 25  Top Validation Acc: 0.9743589743589743
Fold [3/5] Epoch [0/100] Initial Loss: 0.1426, Training Loss: 0.1426, Initial Validation Loss: 0.1322, Validation Loss: 0.1322,V Acc: 0.2727, Top 70th Acc: 0.2857, Bottom 30th Acc: 0.2424
Fold [3/5] Epoch [10/100] Initial Loss: 0.1426, Training Loss: 0.0405, Initial Validation Loss: 0.1322, Validation Loss: 0.0459,V Acc: 0.7455, Top 70th Acc: 0.8961, Bottom 30th Acc: 0.3939
Fold [3/5] Epoch [20/100] Initial Loss: 0.1426, Training Loss: 0.0233, Initial Validation Loss: 0.1322, Validation Loss: 0.0358,V Acc: 0.8000, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.4848
Fold [3/5] Epoch [30/100] Initial Loss: 0.1426, Training Loss: 0.0192, Initial Validation Loss: 0.1322, Validation Loss: 0.0298,V Acc: 0.8364, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 35  Rolling back to Epoch (base 0): 30  Top Validation Acc: 0.948051948051948
Fold [4/5] Epoch [0/100] Initial Loss: 0.1386, Training Loss: 0.1386, Initial Validation Loss: 0.1279, Validation Loss: 0.1279,V Acc: 0.2477, Top 70th Acc: 0.3247, Bottom 30th Acc: 0.0625
Fold [4/5] Epoch [10/100] Initial Loss: 0.1386, Training Loss: 0.0277, Initial Validation Loss: 0.1279, Validation Loss: 0.0401,V Acc: 0.8073, Top 70th Acc: 0.8831, Bottom 30th Acc: 0.6250
Fold [4/5] Epoch [20/100] Initial Loss: 0.1386, Training Loss: 0.0163, Initial Validation Loss: 0.1279, Validation Loss: 0.0346,V Acc: 0.8257, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.6250
Stopping early at Epoch (base 0): 81  Rolling back to Epoch (base 0): 76  Top Validation Acc: 0.9620253164556962
Fold [2/5] Epoch [0/100] Initial Loss: 0.1387, Training Loss: 0.1387, Initial Validation Loss: 0.1374, Validation Loss: 0.1374,V Acc: 0.3514, Top 70th Acc: 0.3590, Bottom 30th Acc: 0.3333
Fold [2/5] Epoch [10/100] Initial Loss: 0.1387, Training Loss: 0.0110, Initial Validation Loss: 0.1374, Validation Loss: 0.0396,V Acc: 0.8288, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.6061
Fold [2/5] Epoch [20/100] Initial Loss: 0.1387, Training Loss: 0.0038, Initial Validation Loss: 0.1374, Validation Loss: 0.0361,V Acc: 0.8288, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.5152
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.9615384615384616
48 1 [array([0.23452947, 0.07149945, 0.08401509, 0.3198579 , 0.29009807],
      dtype=float32)]
Fold [3/5] Epoch [0/100] Initial Loss: 0.1424, Training Loss: 0.1424, Initial Validation Loss: 0.1331, Validation Loss: 0.1331,V Acc: 0.2273, Top 70th Acc: 0.2468, Bottom 30th Acc: 0.1818
Fold [3/5] Epoch [10/100] Initial Loss: 0.1424, Training Loss: 0.0177, Initial Validation Loss: 0.1331, Validation Loss: 0.0315,V Acc: 0.8545, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.5758
Fold [3/5] Epoch [20/100] Initial Loss: 0.1424, Training Loss: 0.0052, Initial Validation Loss: 0.1331, Validation Loss: 0.0268,V Acc: 0.8727, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6970
Fold [3/5] Epoch [30/100] Initial Loss: 0.1424, Training Loss: 0.0040, Initial Validation Loss: 0.1331, Validation Loss: 0.0262,V Acc: 0.8909, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.7273
Stopping early at Epoch (base 0): 35  Rolling back to Epoch (base 0): 30  Top Validation Acc: 0.948051948051948
Fold [4/5] Epoch [0/100] Initial Loss: 0.1404, Training Loss: 0.1404, Initial Validation Loss: 0.1321, Validation Loss: 0.1321,V Acc: 0.3119, Top 70th Acc: 0.3377, Bottom 30th Acc: 0.2500
Fold [4/5] Epoch [10/100] Initial Loss: 0.1404, Training Loss: 0.0139, Initial Validation Loss: 0.1321, Validation Loss: 0.0265,V Acc: 0.8716, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6875
Fold [4/5] Epoch [20/100] Initial Loss: 0.1404, Training Loss: 0.0048, Initial Validation Loss: 0.1321, Validation Loss: 0.0232,V Acc: 0.8807, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.7188
Fold [4/5] Epoch [30/100] Initial Loss: 0.1404, Training Loss: 0.0039, Initial Validation Loss: 0.1321, Validation Loss: 0.0228,V Acc: 0.8716, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.7188
Stopping early at Epoch (base 0): 34  Rolling back to Epoch (base 0): 29  Top Validation Acc: 0.935064935064935
Fold [5/5] Epoch [0/100] Initial Loss: 0.1423, Training Loss: 0.1423, Initial Validation Loss: 0.1313, Validation Loss: 0.1313,V Acc: 0.2870, Top 70th Acc: 0.3158, Bottom 30th Acc: 0.2188
Fold [5/5] Epoch [10/100] Initial Loss: 0.1423, Training Loss: 0.0144, Initial Validation Loss: 0.1313, Validation Loss: 0.0276,V Acc: 0.8704, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.6562
Stopping early at Epoch (base 0): 18  Rolling back to Epoch (base 0): 13  Top Validation Acc: 0.9736842105263158
Running train_nn.py with seed 49
CUDA:False
Training samples count:  550
Training on 162 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1411, Training Loss: 0.1411, Initial Validation Loss: 0.1362, Validation Loss: 0.1362,V Acc: 0.2500, Top 70th Acc: 0.3165, Bottom 30th Acc: 0.0909
Fold [1/5] Epoch [10/100] Initial Loss: 0.1411, Training Loss: 0.0170, Initial Validation Loss: 0.1362, Validation Loss: 0.0326,V Acc: 0.8304, Top 70th Acc: 0.9620, Bottom 30th Acc: 0.5152
Fold [1/5] Epoch [20/100] Initial Loss: 0.1411, Training Loss: 0.0052, Initial Validation Loss: 0.1362, Validation Loss: 0.0313,V Acc: 0.8482, Top 70th Acc: 0.9747, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 20  Rolling back to Epoch (base 0): 15  Top Validation Acc: 0.9746835443037974
Fold [2/5] Epoch [0/100] Initial Loss: 0.1424, Training Loss: 0.1424, Initial Validation Loss: 0.1354, Validation Loss: 0.1354,V Acc: 0.2973, Top 70th Acc: 0.3846, Bottom 30th Acc: 0.0909
Fold [2/5] Epoch [10/100] Initial Loss: 0.1424, Training Loss: 0.0184, Initial Validation Loss: 0.1354, Validation Loss: 0.0310,V Acc: 0.8378, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.5152
Fold [2/5] Epoch [20/100] Initial Loss: 0.1424, Training Loss: 0.0048, Initial Validation Loss: 0.1354, Validation Loss: 0.0283,V Acc: 0.8829, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.7576
Stopping early at Epoch (base 0): 22  Rolling back to Epoch (base 0): 17  Top Validation Acc: 0.9487179487179487
49 1 [array([0.21607919, 0.03960244, 0.09634855, 0.22598198, 0.4219878 ],
      dtype=float32)]
Fold [3/5] Epoch [0/100] Initial Loss: 0.1408, Training Loss: 0.1408, Initial Validation Loss: 0.1316, Validation Loss: 0.1316,V Acc: 0.2909, Top 70th Acc: 0.3247, Bottom 30th Acc: 0.2121
Fold [3/5] Epoch [10/100] Initial Loss: 0.1408, Training Loss: 0.0157, Initial Validation Loss: 0.1316, Validation Loss: 0.0364,V Acc: 0.8273, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.6364
Fold [3/5] Epoch [20/100] Initial Loss: 0.1408, Training Loss: 0.0048, Initial Validation Loss: 0.1316, Validation Loss: 0.0326,V Acc: 0.8364, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.6364
Fold [3/5] Epoch [30/100] Initial Loss: 0.1408, Training Loss: 0.0037, Initial Validation Loss: 0.1316, Validation Loss: 0.0315,V Acc: 0.8364, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 38  Rolling back to Epoch (base 0): 33  Top Validation Acc: 0.922077922077922
Fold [4/5] Epoch [0/100] Initial Loss: 0.1371, Training Loss: 0.1371, Initial Validation Loss: 0.1328, Validation Loss: 0.1328,V Acc: 0.4312, Top 70th Acc: 0.5584, Bottom 30th Acc: 0.1250
Fold [4/5] Epoch [10/100] Initial Loss: 0.1371, Training Loss: 0.0160, Initial Validation Loss: 0.1328, Validation Loss: 0.0342,V Acc: 0.8440, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.5938
Fold [4/5] Epoch [20/100] Initial Loss: 0.1371, Training Loss: 0.0054, Initial Validation Loss: 0.1328, Validation Loss: 0.0282,V Acc: 0.8532, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.5938
Stopping early at Epoch (base 0): 27  Rolling back to Epoch (base 0): 22  Top Validation Acc: 0.961038961038961
Fold [5/5] Epoch [0/100] Initial Loss: 0.1379, Training Loss: 0.1379, Initial Validation Loss: 0.1334, Validation Loss: 0.1334,V Acc: 0.3519, Top 70th Acc: 0.4474, Bottom 30th Acc: 0.1250
Fold [5/5] Epoch [10/100] Initial Loss: 0.1379, Training Loss: 0.0256, Initial Validation Loss: 0.1334, Validation Loss: 0.0454,V Acc: 0.7963, Top 70th Acc: 0.8947, Bottom 30th Acc: 0.5625
Fold [5/5] Epoch [20/100] Initial Loss: 0.1379, Training Loss: 0.0053, Initial Validation Loss: 0.1334, Validation Loss: 0.0328,V Acc: 0.8333, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.5625
Fold [5/5] Epoch [30/100] Initial Loss: 0.1379, Training Loss: 0.0041, Initial Validation Loss: 0.1334, Validation Loss: 0.0308,V Acc: 0.8519, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.5938
Fold [5/5] Epoch [40/100] Initial Loss: 0.1379, Training Loss: 0.0037, Initial Validation Loss: 0.1334, Validation Loss: 0.0301,V Acc: 0.8519, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.5938
Stopping early at Epoch (base 0): 48  Rolling back to Epoch (base 0): 43  Top Validation Acc: 0.9605263157894737
Running train_nn.py with seed 50
CUDA:False
Training samples count:  550
Training on 162 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1405, Training Loss: 0.1405, Initial Validation Loss: 0.1335, Validation Loss: 0.1335,V Acc: 0.2857, Top 70th Acc: 0.3291, Bottom 30th Acc: 0.1818
Fold [1/5] Epoch [10/100] Initial Loss: 0.1405, Training Loss: 0.0226, Initial Validation Loss: 0.1335, Validation Loss: 0.0431,V Acc: 0.8125, Top 70th Acc: 0.8861, Bottom 30th Acc: 0.6364
Fold [1/5] Epoch [20/100] Initial Loss: 0.1405, Training Loss: 0.0049, Initial Validation Loss: 0.1335, Validation Loss: 0.0301,V Acc: 0.8482, Top 70th Acc: 0.9620, Bottom 30th Acc: 0.5758
Fold [1/5] Epoch [30/100] Initial Loss: 0.1405, Training Loss: 0.0039, Initial Validation Loss: 0.1335, Validation Loss: 0.0294,V Acc: 0.8661, Top 70th Acc: 0.9747, Bottom 30th Acc: 0.6061
Fold [1/5] Epoch [40/100] Initial Loss: 0.1405, Training Loss: 0.0037, Initial Validation Loss: 0.1335, Validation Loss: 0.0289,V Acc: 0.8482, Top 70th Acc: 0.9747, Bottom 30th Acc: 0.5455 0.948051948051948
65 3 [array([0.45918524, 0.05740505, 0.11875349, 0.11544866, 0.2492075 ],
      dtype=float32)]
Fold [5/5] Epoch [0/100] Initial Loss: 0.1389, Training Loss: 0.1389, Initial Validation Loss: 0.1282, Validation Loss: 0.1282,V Acc: 0.2593, Top 70th Acc: 0.3421, Bottom 30th Acc: 0.0625
Fold [5/5] Epoch [10/100] Initial Loss: 0.1389, Training Loss: 0.0307, Initial Validation Loss: 0.1282, Validation Loss: 0.0361,V Acc: 0.8148, Top 70th Acc: 0.8947, Bottom 30th Acc: 0.6250
Fold [5/5] Epoch [20/100] Initial Loss: 0.1389, Training Loss: 0.0145, Initial Validation Loss: 0.1282, Validation Loss: 0.0255,V Acc: 0.8611, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.6875
Stopping early at Epoch (base 0): 29  Rolling back to Epoch (base 0): 24  Top Validation Acc: 0.9605263157894737
Running train_nn.py with seed 66
CUDA:False
Training samples count:  550
Training on 40 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1370, Training Loss: 0.1370, Initial Validation Loss: 0.1360, Validation Loss: 0.1360,V Acc: 0.3839, Top 70th Acc: 0.4304, Bottom 30th Acc: 0.2727
Fold [1/5] Epoch [10/100] Initial Loss: 0.1370, Training Loss: 0.0392, Initial Validation Loss: 0.1360, Validation Loss: 0.0449,V Acc: 0.8036, Top 70th Acc: 0.9241, Bottom 30th Acc: 0.5152
Fold [1/5] Epoch [20/100] Initial Loss: 0.1370, Training Loss: 0.0182, Initial Validation Loss: 0.1360, Validation Loss: 0.0255,V Acc: 0.9018, Top 70th Acc: 0.9620, Bottom 30th Acc: 0.7576
Fold [1/5] Epoch [30/100] Initial Loss: 0.1370, Training Loss: 0.0130, Initial Validation Loss: 0.1360, Validation Loss: 0.0212,V Acc: 0.9375, Top 70th Acc: 0.9620, Bottom 30th Acc: 0.8788
Stopping early at Epoch (base 0): 33  Rolling back to Epoch (base 0): 28  Top Validation Acc: 0.9620253164556962
Fold [2/5] Epoch [0/100] Initial Loss: 0.1393, Training Loss: 0.1393, Initial Validation Loss: 0.1325, Validation Loss: 0.1325,V Acc: 0.2793, Top 70th Acc: 0.3590, Bottom 30th Acc: 0.0909
Fold [2/5] Epoch [10/100] Initial Loss: 0.1393, Training Loss: 0.0245, Initial Validation Loss: 0.1325, Validation Loss: 0.0379,V Acc: 0.8288, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.5455
Fold [2/5] Epoch [20/100] Initial Loss: 0.1393, Training Loss: 0.0135, Initial Validation Loss: 0.1325, Validation Loss: 0.0316,V Acc: 0.8559, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.9487179487179487
66 1 [array([0.6160371 , 0.04932855, 0.0903504 , 0.15693863, 0.08734544],
      dtype=float32)]
Fold [3/5] Epoch [0/100] Initial Loss: 0.1427, Training Loss: 0.1427, Initial Validation Loss: 0.1325, Validation Loss: 0.1325,V Acc: 0.2545, Top 70th Acc: 0.3377, Bottom 30th Acc: 0.0606
Fold [3/5] Epoch [10/100] Initial Loss: 0.1427, Training Loss: 0.0324, Initial Validation Loss: 0.1325, Validation Loss: 0.0408,V Acc: 0.8091, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.5152
Fold [3/5] Epoch [20/100] Initial Loss: 0.1427, Training Loss: 0.0151, Initial Validation Loss: 0.1325, Validation Loss: 0.0318,V Acc: 0.8273, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.5152
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.961038961038961
Fold [4/5] Epoch [0/100] Initial Loss: 0.1384, Training Loss: 0.1384, Initial Validation Loss: 0.1298, Validation Loss: 0.1298,V Acc: 0.4037, Top 70th Acc: 0.4545, Bottom 30th Acc: 0.2812
Fold [4/5] Epoch [10/100] Initial Loss: 0.1384, Training Loss: 0.0284, Initial Validation Loss: 0.1298, Validation Loss: 0.0428,V Acc: 0.7982, Top 70th Acc: 0.8961, Bottom 30th Acc: 0.5625
Fold [4/5] Epoch [20/100] Initial Loss: 0.1384, Training Loss: 0.0146, Initial Validation Loss: 0.1298, Validation Loss: 0.0353,V Acc: 0.8257, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.6250
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.9090909090909091
Fold [5/5] Epoch [0/100] Initial Loss: 0.1397, Training Loss: 0.1397, Initial Validation Loss: 0.1328, Validation Loss: 0.1328,V Acc: 0.3056, Top 70th Acc: 0.3553, Bottom 30th Acc: 0.1875
Fold [5/5] Epoch [10/100] Initial Loss: 0.1397, Training Loss: 0.0435, Initial Validation Loss: 0.1328, Validation Loss: 0.0487,V Acc: 0.7407, Top 70th Acc: 0.8947, Bottom 30th Acc: 0.3750
Fold [5/5] Epoch [20/100] Initial Loss: 0.1397, Training Loss: 0.0133, Initial Validation Loss: 0.1328, Validation Loss: 0.0373,V Acc: 0.8148, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.5312
Stopping early at Epoch (base 0): 22  Rolling back to Epoch (base 0): 17  Top Validation Acc: 0.9342105263157895
Running train_nn.py with seed 67
CUDA:False
Training samples count:  550
Training on 40 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1383, Training Loss: 0.1383, Initial Validation Loss: 0.1377, Validation Loss: 0.1377,V Acc: 0.2500, Top 70th Acc: 0.3165, Bottom 30th Acc: 0.0909
Fold [1/5] Epoch [10/100] Initial Loss: 0.1383, Training Loss: 0.0308, Initial Validation Loss: 0.1377, Validation Loss: 0.0378,V Acc: 0.8750, Top 70th Acc: 0.9114, Bottom 30th Acc: 0.7879
Fold [1/5] Epoch [20/100] Initial Loss: 0.1383, Training Loss: 0.0147, Initial Validation Loss: 0.1377, Validation Loss: 0.0273,V Acc: 0.8750, Top 70th Acc: 0.9620, Bottom 30th Acc: 0.6667
Fold [1/5] Epoch [30/100] Initial Loss: 0.1383, Training Loss: 0.0126, Initial Validation Loss: 0.1377, Validation Loss: 0.0273,V Acc: 0.8839, Top 70th Acc: 0.9620, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 31  Rolling back to Epoch (base 0): 26  Top Validation Acc: 0.9620253164556962
Fold [2/5] Epoch [0/100] Initial Loss: 0.1408, Training Loss: 0.1408, Initial Validation Loss: 0.1317, Validation Loss: 0.1317,V Acc: 0.4414, Top 70th Acc: 0.5256, Bottom 30th Acc: 0.2424
Fold [2/5] Epoch [10/100] Initial Loss: 0.1408, Training Loss: 0.0429, Initial Validation Loss: 0.1317, Validation Loss: 0.0454,V Acc: 0.7568, Top 70th Acc: 0.8846, Bottom 30th Acc: 0.4545
Fold [2/5] Epoch [20/100] Initial Loss: 0.1408, Training Loss: 0.0149, Initial Validation Loss: 0.1317, Validation Loss: 0.0349,V Acc: 0.8018, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 28  Rolling back to Epoch (base 0): 23  Top Validation Acc: 0.9230769230769231
Fold [3/5] Epoch [0/100] Initial Loss: 0.1428, Training Loss: 0.1428, Initial Validation Loss: 0.1378, Validation Loss: 0.1378,V Acc: 0.3455, Top 70th Acc: 0.3896, Bottom 30th Acc: 0.2424
Fold [3/5] Epoch [10/100] Initial Loss: 0.1428, Training Loss: 0.0265, Initial Validation Loss: 0.1378, Validation Loss: 0.0302,V Acc: 0.8545, Top 70th Acc: 0.9870, Bottom 30th Acc: 0.5455
Fold [3/5] Epoch [20/100] Initial Loss: 0.1428, Training Loss: 0.0151, Initial Validation Loss: 0.1378, Validation Loss: 0.0227,V Acc: 0.9091, Top 70th Acc: 0.9870, Bottom 30th Acc: 0.7273
Stopping early at Epoch (base 0): 27  Rolling back to Epoch (base 0): 22  Top Validation Acc: 0.987012987012987
Fold [4/5] Epoch [0/100] Initial Loss: 0.1403, Training Loss: 0.1403, Initial Validation Loss: 0.1301, Validation Loss: 0.1301,V Acc: 0.2661, Top 70th Acc: 0.2857, Bottom 30th Acc: 0.2188
Fold [4/5] Epoch [10/100] Initial Loss: 0.1403, Training Loss: 0.0274, Initial Validation Loss: 0.1301, Validation Loss: 0.0400,V Acc: 0.7982, Top 70th Acc: 0.8701, Bottom 30th Acc: 0.6250
Fold [4/5] Epoch [20/100] Initial Loss: 0.1403, Training Loss: 0.0164, Initial Validation Loss: 0.1301, Validation Loss: 0.0369,V Acc: 0.8073, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.5625
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.9090909090909091
67 3 [array([0.38840422, 0.0502188 , 0.08932626, 0.10541688, 0.3666338 ],
      dtype=float32)]
Fold [5/5] Epoch [0/100] Initial Loss: 0.1393, Training Loss: 0.1393, Initial Validation Loss: 0.1313, Validation Loss: 0.1313,V Acc: 0.2500, Top 70th Acc: 0.2763, Bottom 30th Acc: 0.1875
Fold [5/5] Epoch [10/100] Initial Loss: 0.1393, Training Loss: 0.0275, Initial Validation Loss: 0.1313, Validation Loss: 0.0369,V Acc: 0.8611, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.6875
Fold [5/5] Epoch [20/100] Initial Loss: 0.1393, Training Loss: 0.0132, Initial Validation Loss: 0.1313, Validation Loss: 0.0285,V Acc: 0.8611, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.6562
Fold [4/5] Epoch [10/100] Initial Loss: 0.1338, Training Loss: 0.0221, Initial Validation Loss: 0.1166, Validation Loss: 0.0268,V Acc: 0.8624, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.5938
Fold [4/5] Epoch [20/100] Initial Loss: 0.1338, Training Loss: 0.0166, Initial Validation Loss: 0.1166, Validation Loss: 0.0218,V Acc: 0.8899, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.6875
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.961038961038961
Fold [5/5] Epoch [0/100] Initial Loss: 0.1364, Training Loss: 0.1364, Initial Validation Loss: 0.1196, Validation Loss: 0.1196,V Acc: 0.5185, Top 70th Acc: 0.6053, Bottom 30th Acc: 0.3125
Fold [5/5] Epoch [10/100] Initial Loss: 0.1364, Training Loss: 0.0209, Initial Validation Loss: 0.1196, Validation Loss: 0.0295,V Acc: 0.8796, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.7188
Fold [5/5] Epoch [20/100] Initial Loss: 0.1364, Training Loss: 0.0175, Initial Validation Loss: 0.1196, Validation Loss: 0.0434,V Acc: 0.7593, Top 70th Acc: 0.9079, Bottom 30th Acc: 0.4062
Stopping early at Epoch (base 0): 20  Rolling back to Epoch (base 0): 15  Top Validation Acc: 0.9078947368421053
Running train_nn.py with seed 88
CUDA:False
Training samples count:  550
Training on 21 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1287, Training Loss: 0.1287, Initial Validation Loss: 0.1137, Validation Loss: 0.1137,V Acc: 0.5804, Top 70th Acc: 0.6962, Bottom 30th Acc: 0.3030
Fold [1/5] Epoch [10/100] Initial Loss: 0.1287, Training Loss: 0.0217, Initial Validation Loss: 0.1137, Validation Loss: 0.0322,V Acc: 0.8571, Top 70th Acc: 0.9367, Bottom 30th Acc: 0.6667
Fold [1/5] Epoch [20/100] Initial Loss: 0.1287, Training Loss: 0.0151, Initial Validation Loss: 0.1137, Validation Loss: 0.0323,V Acc: 0.8304, Top 70th Acc: 0.9494, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 20  Rolling back to Epoch (base 0): 15  Top Validation Acc: 0.9493670886075949
Fold [2/5] Epoch [0/100] Initial Loss: 0.1395, Training Loss: 0.1395, Initial Validation Loss: 0.1326, Validation Loss: 0.1326,V Acc: 0.3423, Top 70th Acc: 0.4615, Bottom 30th Acc: 0.0606
Fold [2/5] Epoch [10/100] Initial Loss: 0.1395, Training Loss: 0.0286, Initial Validation Loss: 0.1326, Validation Loss: 0.0236,V Acc: 0.9099, Top 70th Acc: 1.0000, Bottom 30th Acc: 0.6970
Fold [2/5] Epoch [20/100] Initial Loss: 0.1395, Training Loss: 0.0182, Initial Validation Loss: 0.1326, Validation Loss: 0.0181,V Acc: 0.9099, Top 70th Acc: 1.0000, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 20  Rolling back to Epoch (base 0): 15  Top Validation Acc: 1.0
Fold [3/5] Epoch [0/100] Initial Loss: 0.1389, Training Loss: 0.1389, Initial Validation Loss: 0.1298, Validation Loss: 0.1298,V Acc: 0.5000, Top 70th Acc: 0.5974, Bottom 30th Acc: 0.2727
Fold [3/5] Epoch [10/100] Initial Loss: 0.1389, Training Loss: 0.0235, Initial Validation Loss: 0.1298, Validation Loss: 0.0347,V Acc: 0.8545, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.6970
Fold [3/5] Epoch [20/100] Initial Loss: 0.1389, Training Loss: 0.0140, Initial Validation Loss: 0.1298, Validation Loss: 0.0295,V Acc: 0.8636, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 28  Rolling back to Epoch (base 0): 23  Top Validation Acc: 0.987012987012987
88 2 [array([0.77947676, 0.01622946, 0.02401228, 0.10007327, 0.08020826],
      dtype=float32)]
Fold [4/5] Epoch [0/100] Initial Loss: 0.1351, Training Loss: 0.1351, Initial Validation Loss: 0.1134, Validation Loss: 0.1134,V Acc: 0.4220, Top 70th Acc: 0.5325, Bottom 30th Acc: 0.1562
Fold [4/5] Epoch [10/100] Initial Loss: 0.1351, Training Loss: 0.0228, Initial Validation Loss: 0.1134, Validation Loss: 0.0315,V Acc: 0.8624, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.6875
Stopping early at Epoch (base 0): 19  Rolling back to Epoch (base 0): 14  Top Validation Acc: 0.922077922077922
Fold [5/5] Epoch [0/100] Initial Loss: 0.1341, Training Loss: 0.1341, Initial Validation Loss: 0.1234, Validation Loss: 0.1234,V Acc: 0.4722, Top 70th Acc: 0.5921, Bottom 30th Acc: 0.1875
Fold [5/5] Epoch [10/100] Initial Loss: 0.1341, Training Loss: 0.0230, Initial Validation Loss: 0.1234, Validation Loss: 0.0242,V Acc: 0.8796, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.6875
Fold [5/5] Epoch [20/100] Initial Loss: 0.1341, Training Loss: 0.0157, Initial Validation Loss: 0.1234, Validation Loss: 0.0205,V Acc: 0.9167, Top 70th Acc: 0.9737, Bottom 30th Acc: 0.7812
Stopping early at Epoch (base 0): 27  Rolling back to Epoch (base 0): 22  Top Validation Acc: 0.9868421052631579
Running train_nn.py with seed 89
CUDA:False
Training samples count:  550
Training on 21 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1315, Training Loss: 0.1315, Initial Validation Loss: 0.1224, Validation Loss: 0.1224,V Acc: 0.4196, Top 70th Acc: 0.5190, Bottom 30th Acc: 0.1818
Fold [1/5] Epoch [10/100] Initial Loss: 0.1315, Training Loss: 0.0216, Initial Validation Loss: 0.1224, Validation Loss: 0.0227,V Acc: 0.8839, Top 70th Acc: 0.9747, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 19  Rolling back to Epoch (base 0): 14  Top Validation Acc: 0.9746835443037974
Fold [2/5] Epoch [0/100] Initial Loss: 0.1408, Training Loss: 0.1408, Initial Validation Loss: 0.1262, Validation Loss: 0.1262,V Acc: 0.4234, Top 70th Acc: 0.5385, Bottom 30th Acc: 0.1515
Fold [2/5] Epoch [10/100] Initial Loss: 0.1408, Training Loss: 0.0247, Initial Validation Loss: 0.1262, Validation Loss: 0.0342,V Acc: 0.8198, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.4848
Fold [2/5] Epoch [20/100] Initial Loss: 0.1408, Training Loss: 0.0149, Initial Validation Loss: 0.1262, Validation Loss: 0.0319,V Acc: 0.8288, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.9487179487179487
Fold [3/5] Epoch [0/100] Initial Loss: 0.1378, Training Loss: 0.1378, Initial Validation Loss: 0.1347, Validation Loss: 0.1347,V Acc: 0.4000, Top 70th Acc: 0.5065, Bottom 30th Acc: 0.1515
Fold [3/5] Epoch [10/100] Initial Loss: 0.1378, Training Loss: 0.0223, Initial Validation Loss: 0.1347, Validation Loss: 0.0236,V Acc: 0.9000, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.7273
Fold [3/5] Epoch [20/100] Initial Loss: 0.1378, Training Loss: 0.0154, Initial Validation Loss: 0.1347, Validation Loss: 0.0201,V Acc: 0.9273, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.8182
Fold [3/5] Epoch [30/100] Initial Loss: 0.1378, Training Loss: 0.0130, Initial Validation Loss: 0.1347, Validation Loss: 0.0187,V Acc: 0.9091, Top 70th Acc: 0.9870, Bottom 30th Acc: 0.7273
Stopping early at Epoch (base 0): 30  Rolling back to Epoch (base 0): 25  Top Validation Acc: 0.987012987012987
Fold [4/5] Epoch [0/100] Initial Loss: 0.1344, Training Loss: 0.1344, Initial Validation Loss: 0.1207, Validation Loss: 0.1207,V Acc: 0.4679, Top 70th Acc: 0.5844, Bottom 30th Acc: 0.1875
Fold [4/5] Epoch [10/100] Initial Loss: 0.1344, Training Loss: 0.0204, Initial Validation Loss: 0.1207, Validation Loss: 0.0311,V Acc: 0.8532, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6250
Stopping early at Epoch (base 0): 18  Rolling back to Epoch (base 0): 13  Top Validation Acc: 0.961038961038961
89 3 [array([0.85192645, 0.01454826, 0.042052  , 0.05755993, 0.03391335],
      dtype=float32)]
Fold [5/5] Epoch [0/100] Initial Loss: 0.1299, Training Loss: 0.1299, Initial Validation Loss: 0.1143, Validation Loss: 0.1143,V Acc: 0.5926, Top 70th Acc: 0.6974, Bottom 30th Acc: 0.3438
Fold [5/5] Epoch [10/100] Initial Loss: 0.1299, Training Loss: 0.0196, Initial Validation Loss: 0.1143, Validation Loss: 0.0231,V Acc: 0.9074, Top 70th Acc: 0.9868, Bottom 30th Acc: 0.7188
Fold [5/5] Epoch [20/100] Initial Loss: 0.1299, Training Loss: 0.0140, Initial Validation Loss: 0.1143, Validation Loss: 0.0206,V Acc: 0.9074, Top 70th Acc: 0.9868, Bottom 30th Acc: 0.7188
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.9868421052631579
Running train_nn.py with seed 90
CUDA:False
Training samples count:  550
Training on 21 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1286, Training Loss: 0.1286, Initial Validation Loss: 0.1094, Validation Loss: 0.1094,V Acc: 0.5536, Top 70th Acc: 0.6456, Bottom 30th Acc: 0.3333
Fold [5/5] Epoch [10/100] Initial Loss: 0.1357, Training Loss: 0.0355, Initial Validation Loss: 0.1297, Validation Loss: 0.0385,V Acc: 0.8796, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.6875
Fold [5/5] Epoch [20/100] Initial Loss: 0.1357, Training Loss: 0.0239, Initial Validation Loss: 0.1297, Validation Loss: 0.0342,V Acc: 0.8333, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.5312
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.9605263157894737
63 4 [array([0.2512153 , 0.10653517, 0.20723145, 0.2695432 , 0.16547489],
      dtype=float32)]
Running train_nn.py with seed 64
CUDA:False
Training samples count:  550
Training on 20 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1432, Training Loss: 0.1432, Initial Validation Loss: 0.1343, Validation Loss: 0.1343,V Acc: 0.2768, Top 70th Acc: 0.3038, Bottom 30th Acc: 0.2121
Fold [1/5] Epoch [10/100] Initial Loss: 0.1432, Training Loss: 0.0333, Initial Validation Loss: 0.1343, Validation Loss: 0.0437,V Acc: 0.7679, Top 70th Acc: 0.8734, Bottom 30th Acc: 0.5152
Fold [1/5] Epoch [20/100] Initial Loss: 0.1432, Training Loss: 0.0222, Initial Validation Loss: 0.1343, Validation Loss: 0.0347,V Acc: 0.8036, Top 70th Acc: 0.9114, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 22  Rolling back to Epoch (base 0): 17  Top Validation Acc: 0.8860759493670886
64 0 [array([0.28865394, 0.1565469 , 0.15856194, 0.24056754, 0.15566966],
      dtype=float32)]
Fold [2/5] Epoch [0/100] Initial Loss: 0.1392, Training Loss: 0.1392, Initial Validation Loss: 0.1362, Validation Loss: 0.1362,V Acc: 0.2793, Top 70th Acc: 0.3205, Bottom 30th Acc: 0.1818
Fold [2/5] Epoch [10/100] Initial Loss: 0.1392, Training Loss: 0.0358, Initial Validation Loss: 0.1362, Validation Loss: 0.0345,V Acc: 0.8378, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.5455
Fold [2/5] Epoch [20/100] Initial Loss: 0.1392, Training Loss: 0.0223, Initial Validation Loss: 0.1362, Validation Loss: 0.0292,V Acc: 0.8378, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.5152
Stopping early at Epoch (base 0): 29  Rolling back to Epoch (base 0): 24  Top Validation Acc: 0.9743589743589743
Fold [3/5] Epoch [0/100] Initial Loss: 0.1411, Training Loss: 0.1411, Initial Validation Loss: 0.1348, Validation Loss: 0.1348,V Acc: 0.2545, Top 70th Acc: 0.2597, Bottom 30th Acc: 0.2424
Fold [3/5] Epoch [10/100] Initial Loss: 0.1411, Training Loss: 0.0318, Initial Validation Loss: 0.1348, Validation Loss: 0.0367,V Acc: 0.8545, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.6667
Fold [3/5] Epoch [20/100] Initial Loss: 0.1411, Training Loss: 0.0221, Initial Validation Loss: 0.1348, Validation Loss: 0.0316,V Acc: 0.8545, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.948051948051948
Fold [4/5] Epoch [0/100] Initial Loss: 0.1366, Training Loss: 0.1366, Initial Validation Loss: 0.1342, Validation Loss: 0.1342,V Acc: 0.3670, Top 70th Acc: 0.3377, Bottom 30th Acc: 0.4375
Fold [4/5] Epoch [10/100] Initial Loss: 0.1366, Training Loss: 0.0440, Initial Validation Loss: 0.1342, Validation Loss: 0.0401,V Acc: 0.8073, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.4688
Fold [4/5] Epoch [20/100] Initial Loss: 0.1366, Training Loss: 0.0264, Initial Validation Loss: 0.1342, Validation Loss: 0.0251,V Acc: 0.8807, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.6562
Fold [4/5] Epoch [30/100] Initial Loss: 0.1366, Training Loss: 0.0218, Initial Validation Loss: 0.1342, Validation Loss: 0.0234,V Acc: 0.8899, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.6875
Stopping early at Epoch (base 0): 35  Rolling back to Epoch (base 0): 30  Top Validation Acc: 0.974025974025974
Fold [5/5] Epoch [0/100] Initial Loss: 0.1414, Training Loss: 0.1414, Initial Validation Loss: 0.1319, Validation Loss: 0.1319,V Acc: 0.2685, Top 70th Acc: 0.2763, Bottom 30th Acc: 0.2500
Fold [5/5] Epoch [10/100] Initial Loss: 0.1414, Training Loss: 0.0374, Initial Validation Loss: 0.1319, Validation Loss: 0.0433,V Acc: 0.8241, Top 70th Acc: 0.8947, Bottom 30th Acc: 0.6562
Fold [5/5] Epoch [20/100] Initial Loss: 0.1414, Training Loss: 0.0207, Initial Validation Loss: 0.1319, Validation Loss: 0.0349,V Acc: 0.8519, Top 70th Acc: 0.9079, Bottom 30th Acc: 0.7188
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.9342105263157895
Running train_nn.py with seed 65
CUDA:False
Training samples count:  550
Training on 20 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1392, Training Loss: 0.1392, Initial Validation Loss: 0.1336, Validation Loss: 0.1336,V Acc: 0.2589, Top 70th Acc: 0.3038, Bottom 30th Acc: 0.1515
Fold [1/5] Epoch [10/100] Initial Loss: 0.1392, Training Loss: 0.0408, Initial Validation Loss: 0.1336, Validation Loss: 0.0478,V Acc: 0.7768, Top 70th Acc: 0.8734, Bottom 30th Acc: 0.5455
Fold [1/5] Epoch [20/100] Initial Loss: 0.1392, Training Loss: 0.0226, Initial Validation Loss: 0.1336, Validation Loss: 0.0370,V Acc: 0.8214, Top 70th Acc: 0.9241, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.9367088607594937
Fold [2/5] Epoch [0/100] Initial Loss: 0.1418, Training Loss: 0.1418, Initial Validation Loss: 0.1358, Validation Loss: 0.1358,V Acc: 0.3964, Top 70th Acc: 0.4359, Bottom 30th Acc: 0.3030
Fold [2/5] Epoch [10/100] Initial Loss: 0.1418, Training Loss: 0.0430, Initial Validation Loss: 0.1358, Validation Loss: 0.0523,V Acc: 0.7658, Top 70th Acc: 0.8205, Bottom 30th Acc: 0.6364
Fold [2/5] Epoch [20/100] Initial Loss: 0.1418, Training Loss: 0.0287, Initial Validation Loss: 0.1358, Validation Loss: 0.0406,V Acc: 0.7928, Top 70th Acc: 0.8718, Bottom 30th Acc: 0.6061
Fold [2/5] Epoch [30/100] Initial Loss: 0.1418, Training Loss: 0.0222, Initial Validation Loss: 0.1358, Validation Loss: 0.0363,V Acc: 0.8108, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.4848
Fold [2/5] Epoch [40/100] Initial Loss: 0.1418, Training Loss: 0.0194, Initial Validation Loss: 0.1358, Validation Loss: 0.0367,V Acc: 0.8018, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 41  Rolling back to Epoch (base 0): 36  Top Validation Acc: 0.9230769230769231
Fold [3/5] Epoch [0/100] Initial Loss: 0.1385, Training Loss: 0.1385, Initial Validation Loss: 0.1329, Validation Loss: 0.1329,V Acc: 0.3000, Top 70th Acc: 0.3636, Bottom 30th Acc: 0.1515
Fold [3/5] Epoch [10/100] Initial Loss: 0.1385, Training Loss: 0.0269, Initial Validation Loss: 0.1329, Validation Loss: 0.0425,V Acc: 0.8091, Top 70th Acc: 0.8961, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 18  Rolling back to Epoch (base 0): 13  Top Validation Acc: 0.8961038961038961
Fold [4/5] Epoch [0/100] Initial Loss: 0.1389, Training Loss: 0.1389, Initial Validation Loss: 0.1326, Validation Loss: 0.1326,V Acc: 0.2477, Top 70th Acc: 0.2727, Bottom 30th Acc: 0.1875
Fold [4/5] Epoch [10/100] Initial Loss: 0.1389, Training Loss: 0.0311, Initial Validation Loss: 0.1326, Validation Loss: 0.0291,V Acc: 0.8807, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.6875
Fold [4/5] Epoch [20/100] Initial Loss: 0.1389, Training Loss: 0.0237, Initial Validation Loss: 0.1326, Validation Loss: 0.0279,V Acc: 0.8624, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.6875
Stopping early at Epoch (base 0): 20  Rolling back to Epoch (base 0): 15  Top Validation Acc: 0.935064935064935
65 3 [array([0.4231568 , 0.0772324 , 0.1204915 , 0.18381533, 0.19530399],
      dtype=float32)]
Fold [5/5] Epoch [0/100] Initial Loss: 0.1372, Training Loss: 0.1372, Initial Validation Loss: 0.1281, Validation Loss: 0.1281,V Acc: 0.3148, Top 70th Acc: 0.3421, Bottom 30th Acc: 0.2500
Fold [5/5] Epoch [10/100] Initial Loss: 0.1372, Training Loss: 0.0433, Initial Validation Loss: 0.1281, Validation Loss: 0.0420,V Acc: 0.8056, Top 70th Acc: 0.8947, Bottom 30th Acc: 0.5938
Fold [5/5] Epoch [20/100] Initial Loss: 0.1372, Training Loss: 0.0253, Initial Validation Loss: 0.1281, Validation Loss: 0.0285,V Acc: 0.8519, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.6250
Stopping early at Epoch (base 0): 29  Rolling back to Epoch (base 0): 24  Top Validation Acc: 0.9473684210526315
Running train_nn.py with seed 66
CUDA:False
Training samples count: 
Fold [5/5] Epoch [20/100] Initial Loss: 0.1333, Training Loss: 0.0796, Initial Validation Loss: 0.1270, Validation Loss: 0.0767,V Acc: 0.6389, Top 70th Acc: 0.8026, Bottom 30th Acc: 0.2500
Fold [5/5] Epoch [30/100] Initial Loss: 0.1333, Training Loss: 0.0791, Initial Validation Loss: 0.1270, Validation Loss: 0.0760,V Acc: 0.6389, Top 70th Acc: 0.7895, Bottom 30th Acc: 0.2812
Fold [5/5] Epoch [40/100] Initial Loss: 0.1333, Training Loss: 0.0788, Initial Validation Loss: 0.1270, Validation Loss: 0.0760,V Acc: 0.6389, Top 70th Acc: 0.8026, Bottom 30th Acc: 0.2500
Fold [5/5] Epoch [50/100] Initial Loss: 0.1333, Training Loss: 0.0786, Initial Validation Loss: 0.1270, Validation Loss: 0.0756,V Acc: 0.6481, Top 70th Acc: 0.8026, Bottom 30th Acc: 0.2812
Fold [5/5] Epoch [60/100] Initial Loss: 0.1333, Training Loss: 0.0784, Initial Validation Loss: 0.1270, Validation Loss: 0.0749,V Acc: 0.6574, Top 70th Acc: 0.8158, Bottom 30th Acc: 0.2812
Fold [5/5] Epoch [70/100] Initial Loss: 0.1333, Training Loss: 0.0780, Initial Validation Loss: 0.1270, Validation Loss: 0.0745,V Acc: 0.6574, Top 70th Acc: 0.8026, Bottom 30th Acc: 0.3125
Stopping early at Epoch (base 0): 75  Rolling back to Epoch (base 0): 70  Top Validation Acc: 0.8157894736842105
63 4 [array([0.11764154, 0.34919336, 0.13783148, 0.21832186, 0.17701176],
      dtype=float32)]
Running train_nn.py with seed 64
CUDA:False
Training samples count:  550
Training on 2 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1380, Training Loss: 0.1380, Initial Validation Loss: 0.1276, Validation Loss: 0.1276,V Acc: 0.2946, Top 70th Acc: 0.3544, Bottom 30th Acc: 0.1515
Fold [1/5] Epoch [10/100] Initial Loss: 0.1380, Training Loss: 0.0779, Initial Validation Loss: 0.1276, Validation Loss: 0.0885,V Acc: 0.5357, Top 70th Acc: 0.6456, Bottom 30th Acc: 0.2727
Stopping early at Epoch (base 0): 19  Rolling back to Epoch (base 0): 14  Top Validation Acc: 0.6329113924050633
64 0 [array([0.10593708, 0.39664072, 0.15118347, 0.20464152, 0.14159723],
      dtype=float32)]
Fold [2/5] Epoch [0/100] Initial Loss: 0.1341, Training Loss: 0.1341, Initial Validation Loss: 0.1213, Validation Loss: 0.1213,V Acc: 0.5495, Top 70th Acc: 0.6923, Bottom 30th Acc: 0.2121
Fold [2/5] Epoch [10/100] Initial Loss: 0.1341, Training Loss: 0.0815, Initial Validation Loss: 0.1213, Validation Loss: 0.0762,V Acc: 0.6486, Top 70th Acc: 0.7821, Bottom 30th Acc: 0.3333
Fold [2/5] Epoch [20/100] Initial Loss: 0.1341, Training Loss: 0.0801, Initial Validation Loss: 0.1213, Validation Loss: 0.0749,V Acc: 0.6396, Top 70th Acc: 0.7821, Bottom 30th Acc: 0.3030
Fold [2/5] Epoch [30/100] Initial Loss: 0.1341, Training Loss: 0.0796, Initial Validation Loss: 0.1213, Validation Loss: 0.0738,V Acc: 0.6486, Top 70th Acc: 0.7821, Bottom 30th Acc: 0.3333
Stopping early at Epoch (base 0): 36  Rolling back to Epoch (base 0): 31  Top Validation Acc: 0.782051282051282
Fold [3/5] Epoch [0/100] Initial Loss: 0.1414, Training Loss: 0.1414, Initial Validation Loss: 0.1335, Validation Loss: 0.1335,V Acc: 0.2545, Top 70th Acc: 0.3506, Bottom 30th Acc: 0.0303
Fold [3/5] Epoch [10/100] Initial Loss: 0.1414, Training Loss: 0.0809, Initial Validation Loss: 0.1335, Validation Loss: 0.0796,V Acc: 0.6455, Top 70th Acc: 0.7662, Bottom 30th Acc: 0.3636
Fold [3/5] Epoch [20/100] Initial Loss: 0.1414, Training Loss: 0.0788, Initial Validation Loss: 0.1335, Validation Loss: 0.0786,V Acc: 0.6545, Top 70th Acc: 0.7532, Bottom 30th Acc: 0.4242
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.7532467532467533
Fold [4/5] Epoch [0/100] Initial Loss: 0.1366, Training Loss: 0.1366, Initial Validation Loss: 0.1337, Validation Loss: 0.1337,V Acc: 0.2569, Top 70th Acc: 0.3506, Bottom 30th Acc: 0.0312
Fold [4/5] Epoch [10/100] Initial Loss: 0.1366, Training Loss: 0.0844, Initial Validation Loss: 0.1337, Validation Loss: 0.0705,V Acc: 0.7339, Top 70th Acc: 0.7922, Bottom 30th Acc: 0.5938
Fold [4/5] Epoch [20/100] Initial Loss: 0.1366, Training Loss: 0.0819, Initial Validation Loss: 0.1337, Validation Loss: 0.0695,V Acc: 0.7339, Top 70th Acc: 0.7922, Bottom 30th Acc: 0.5938
Fold [4/5] Epoch [30/100] Initial Loss: 0.1366, Training Loss: 0.0814, Initial Validation Loss: 0.1337, Validation Loss: 0.0677,V Acc: 0.7523, Top 70th Acc: 0.8052, Bottom 30th Acc: 0.6250
Stopping early at Epoch (base 0): 31  Rolling back to Epoch (base 0): 26  Top Validation Acc: 0.8051948051948052
Fold [5/5] Epoch [0/100] Initial Loss: 0.1356, Training Loss: 0.1356, Initial Validation Loss: 0.1217, Validation Loss: 0.1217,V Acc: 0.4630, Top 70th Acc: 0.5132, Bottom 30th Acc: 0.3438
Fold [5/5] Epoch [10/100] Initial Loss: 0.1356, Training Loss: 0.0788, Initial Validation Loss: 0.1217, Validation Loss: 0.0829,V Acc: 0.5648, Top 70th Acc: 0.6842, Bottom 30th Acc: 0.2812
Fold [5/5] Epoch [20/100] Initial Loss: 0.1356, Training Loss: 0.0767, Initial Validation Loss: 0.1217, Validation Loss: 0.0812,V Acc: 0.6019, Top 70th Acc: 0.6974, Bottom 30th Acc: 0.3750
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.6842105263157895
Running train_nn.py with seed 65
CUDA:False
Training samples count:  550
Training on 2 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1354, Training Loss: 0.1354, Initial Validation Loss: 0.1206, Validation Loss: 0.1206,V Acc: 0.4464, Top 70th Acc: 0.4051, Bottom 30th Acc: 0.5455
Fold [1/5] Epoch [10/100] Initial Loss: 0.1354, Training Loss: 0.0804, Initial Validation Loss: 0.1206, Validation Loss: 0.0798,V Acc: 0.6250, Top 70th Acc: 0.7468, Bottom 30th Acc: 0.3333
Fold [1/5] Epoch [20/100] Initial Loss: 0.1354, Training Loss: 0.0785, Initial Validation Loss: 0.1206, Validation Loss: 0.0780,V Acc: 0.6161, Top 70th Acc: 0.7468, Bottom 30th Acc: 0.3030
Stopping early at Epoch (base 0): 20  Rolling back to Epoch (base 0): 15  Top Validation Acc: 0.7468354430379747
Fold [2/5] Epoch [0/100] Initial Loss: 0.1394, Training Loss: 0.1394, Initial Validation Loss: 0.1369, Validation Loss: 0.1369,V Acc: 0.2793, Top 70th Acc: 0.2821, Bottom 30th Acc: 0.2727
Fold [2/5] Epoch [10/100] Initial Loss: 0.1394, Training Loss: 0.0819, Initial Validation Loss: 0.1369, Validation Loss: 0.0803,V Acc: 0.6486, Top 70th Acc: 0.7564, Bottom 30th Acc: 0.3939
Fold [2/5] Epoch [20/100] Initial Loss: 0.1394, Training Loss: 0.0798, Initial Validation Loss: 0.1369, Validation Loss: 0.0784,V Acc: 0.6847, Top 70th Acc: 0.7821, Bottom 30th Acc: 0.4545
Fold [2/5] Epoch [30/100] Initial Loss: 0.1394, Training Loss: 0.0789, Initial Validation Loss: 0.1369, Validation Loss: 0.0790,V Acc: 0.6577, Top 70th Acc: 0.7692, Bottom 30th Acc: 0.3939
Stopping early at Epoch (base 0): 34  Rolling back to Epoch (base 0): 29  Top Validation Acc: 0.7692307692307693
Fold [3/5] Epoch [0/100] Initial Loss: 0.1333, Training Loss: 0.1333, Initial Validation Loss: 0.1227, Validation Loss: 0.1227,V Acc: 0.4091, Top 70th Acc: 0.4675, Bottom 30th Acc: 0.2727
Fold [3/5] Epoch [10/100] Initial Loss: 0.1333, Training Loss: 0.0798, Initial Validation Loss: 0.1227, Validation Loss: 0.0844,V Acc: 0.5818, Top 70th Acc: 0.7273, Bottom 30th Acc: 0.2424
Fold [3/5] Epoch [20/100] Initial Loss: 0.1333, Training Loss: 0.0780, Initial Validation Loss: 0.1227, Validation Loss: 0.0833,V Acc: 0.5909, Top 70th Acc: 0.7143, Bottom 30th Acc: 0.3030
Stopping early at Epoch (base 0): 21  Rolling back to Epoch (base 0): 16  Top Validation Acc: 0.7142857142857143
Fold [4/5] Epoch [0/100] Initial Loss: 0.1412, Training Loss: 0.1412, Initial Validation Loss: 0.1307, Validation Loss: 0.1307,V Acc: 0.3945, Top 70th Acc: 0.5325, Bottom 30th Acc: 0.0625
Fold [4/5] Epoch [10/100] Initial Loss: 0.1412, Training Loss: 0.0805, Initial Validation Loss: 0.1307, Validation Loss: 0.0777,V Acc: 0.6239, Top 70th Acc: 0.7273, Bottom 30th Acc: 0.3750
Fold [4/5] Epoch [20/100] Initial Loss: 0.1412, Training Loss: 0.0787, Initial Validation Loss: 0.1307, Validation Loss: 0.0759,V Acc: 0.6514, Top 70th Acc: 0.7273, Bottom 30th Acc: 0.4688
Fold [4/5] Epoch [30/100] Initial Loss: 0.1412, Training Loss: 0.0785, Initial Validation Loss: 0.1307, Validation Loss: 0.0760,V Acc: 0.6606, Top 70th Acc: 0.7532, Bottom 30th Acc: 0.4375
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.8831168831168831
Fold [5/5] Epoch [0/100] Initial Loss: 0.1392, Training Loss: 0.1392, Initial Validation Loss: 0.1377, Validation Loss: 0.1377,V Acc: 0.2963, Top 70th Acc: 0.3816, Bottom 30th Acc: 0.0938
Fold [5/5] Epoch [10/100] Initial Loss: 0.1392, Training Loss: 0.0398, Initial Validation Loss: 0.1377, Validation Loss: 0.0403,V Acc: 0.8519, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.6562
Fold [5/5] Epoch [20/100] Initial Loss: 0.1392, Training Loss: 0.0205, Initial Validation Loss: 0.1377, Validation Loss: 0.0282,V Acc: 0.8704, Top 70th Acc: 0.9737, Bottom 30th Acc: 0.6250
Fold [5/5] Epoch [30/100] Initial Loss: 0.1392, Training Loss: 0.0177, Initial Validation Loss: 0.1377, Validation Loss: 0.0273,V Acc: 0.8704, Top 70th Acc: 0.9737, Bottom 30th Acc: 0.6250
Stopping early at Epoch (base 0): 33  Rolling back to Epoch (base 0): 28  Top Validation Acc: 0.9736842105263158
63 4 [array([0.6453915 , 0.07287788, 0.04319711, 0.09891883, 0.13961464],
      dtype=float32)]
Running train_nn.py with seed 64
CUDA:False
Training samples count:  550
Training on 30 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1373, Training Loss: 0.1373, Initial Validation Loss: 0.1302, Validation Loss: 0.1302,V Acc: 0.3393, Top 70th Acc: 0.4304, Bottom 30th Acc: 0.1212
Fold [1/5] Epoch [10/100] Initial Loss: 0.1373, Training Loss: 0.0286, Initial Validation Loss: 0.1302, Validation Loss: 0.0386,V Acc: 0.8036, Top 70th Acc: 0.8734, Bottom 30th Acc: 0.6364
Fold [1/5] Epoch [20/100] Initial Loss: 0.1373, Training Loss: 0.0194, Initial Validation Loss: 0.1302, Validation Loss: 0.0323,V Acc: 0.8036, Top 70th Acc: 0.9367, Bottom 30th Acc: 0.4848
Stopping early at Epoch (base 0): 29  Rolling back to Epoch (base 0): 24  Top Validation Acc: 0.9240506329113924
64 0 [array([0.5102836 , 0.09731792, 0.08922936, 0.09808387, 0.20508528],
      dtype=float32)]
Fold [2/5] Epoch [0/100] Initial Loss: 0.1388, Training Loss: 0.1388, Initial Validation Loss: 0.1345, Validation Loss: 0.1345,V Acc: 0.2973, Top 70th Acc: 0.3590, Bottom 30th Acc: 0.1515
Fold [2/5] Epoch [10/100] Initial Loss: 0.1388, Training Loss: 0.0367, Initial Validation Loss: 0.1345, Validation Loss: 0.0367,V Acc: 0.8108, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.4848
Fold [2/5] Epoch [20/100] Initial Loss: 0.1388, Training Loss: 0.0198, Initial Validation Loss: 0.1345, Validation Loss: 0.0307,V Acc: 0.8018, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.3939
Fold [2/5] Epoch [30/100] Initial Loss: 0.1388, Training Loss: 0.0162, Initial Validation Loss: 0.1345, Validation Loss: 0.0310,V Acc: 0.7928, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.3939
Stopping early at Epoch (base 0): 32  Rolling back to Epoch (base 0): 27  Top Validation Acc: 0.9487179487179487
Fold [3/5] Epoch [0/100] Initial Loss: 0.1393, Training Loss: 0.1393, Initial Validation Loss: 0.1321, Validation Loss: 0.1321,V Acc: 0.3909, Top 70th Acc: 0.4805, Bottom 30th Acc: 0.1818
Fold [3/5] Epoch [10/100] Initial Loss: 0.1393, Training Loss: 0.0418, Initial Validation Loss: 0.1321, Validation Loss: 0.0474,V Acc: 0.7909, Top 70th Acc: 0.8701, Bottom 30th Acc: 0.6061
Fold [3/5] Epoch [20/100] Initial Loss: 0.1393, Training Loss: 0.0212, Initial Validation Loss: 0.1321, Validation Loss: 0.0356,V Acc: 0.8364, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.922077922077922
Fold [4/5] Epoch [0/100] Initial Loss: 0.1380, Training Loss: 0.1380, Initial Validation Loss: 0.1339, Validation Loss: 0.1339,V Acc: 0.4404, Top 70th Acc: 0.5195, Bottom 30th Acc: 0.2500
Fold [4/5] Epoch [10/100] Initial Loss: 0.1380, Training Loss: 0.0296, Initial Validation Loss: 0.1339, Validation Loss: 0.0315,V Acc: 0.8807, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.7188
Fold [4/5] Epoch [20/100] Initial Loss: 0.1380, Training Loss: 0.0195, Initial Validation Loss: 0.1339, Validation Loss: 0.0268,V Acc: 0.8991, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.7188
Fold [4/5] Epoch [30/100] Initial Loss: 0.1380, Training Loss: 0.0177, Initial Validation Loss: 0.1339, Validation Loss: 0.0238,V Acc: 0.8807, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.6562
Stopping early at Epoch (base 0): 30  Rolling back to Epoch (base 0): 25  Top Validation Acc: 0.974025974025974
Fold [5/5] Epoch [0/100] Initial Loss: 0.1435, Training Loss: 0.1435, Initial Validation Loss: 0.1330, Validation Loss: 0.1330,V Acc: 0.2407, Top 70th Acc: 0.2500, Bottom 30th Acc: 0.2188
Fold [5/5] Epoch [10/100] Initial Loss: 0.1435, Training Loss: 0.0310, Initial Validation Loss: 0.1330, Validation Loss: 0.0402,V Acc: 0.8148, Top 70th Acc: 0.9211, Bottom 30th Acc: 0.5625
Stopping early at Epoch (base 0): 19  Rolling back to Epoch (base 0): 14  Top Validation Acc: 0.9210526315789473
Running train_nn.py with seed 65
CUDA:False
Training samples count:  550
Training on 30 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1400, Training Loss: 0.1400, Initial Validation Loss: 0.1328, Validation Loss: 0.1328,V Acc: 0.3482, Top 70th Acc: 0.3924, Bottom 30th Acc: 0.2424
Fold [1/5] Epoch [10/100] Initial Loss: 0.1400, Training Loss: 0.0328, Initial Validation Loss: 0.1328, Validation Loss: 0.0434,V Acc: 0.8214, Top 70th Acc: 0.8734, Bottom 30th Acc: 0.6970
Fold [1/5] Epoch [20/100] Initial Loss: 0.1400, Training Loss: 0.0199, Initial Validation Loss: 0.1328, Validation Loss: 0.0386,V Acc: 0.8393, Top 70th Acc: 0.8987, Bottom 30th Acc: 0.6970
Fold [1/5] Epoch [30/100] Initial Loss: 0.1400, Training Loss: 0.0156, Initial Validation Loss: 0.1328, Validation Loss: 0.0371,V Acc: 0.8125, Top 70th Acc: 0.9241, Bottom 30th Acc: 0.5455
Fold [1/5] Epoch [40/100] Initial Loss: 0.1400, Training Loss: 0.0140, Initial Validation Loss: 0.1328, Validation Loss: 0.0353,V Acc: 0.8393, Top 70th Acc: 0.9241, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 46  Rolling back to Epoch (base 0): 41  Top Validation Acc: 0.9240506329113924
Fold [2/5] Epoch [0/100] Initial Loss: 0.1370, Training Loss: 0.1370, Initial Validation Loss: 0.1369, Validation Loss: 0.1369,V Acc: 0.2793, Top 70th Acc: 0.3077, Bottom 30th Acc: 0.2121
Fold [2/5] Epoch [10/100] Initial Loss: 0.1370, Training Loss: 0.0387, Initial Validation Loss: 0.1369, Validation Loss: 0.0512,V Acc: 0.7297, Top 70th Acc: 0.8974, Bottom 30th Acc: 0.3333
Fold [2/5] Epoch [20/100] Initial Loss: 0.1370, Training Loss: 0.0185, Initial Validation Loss: 0.1369, Validation Loss: 0.0284,V Acc: 0.8378, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.5758
Fold [2/5] Epoch [30/100] Initial Loss: 0.1370, Training Loss: 0.0146, Initial Validation Loss: 0.1369, Validation Loss: 0.0287,V Acc: 0.8378, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 31  Rolling back to Epoch (base 0): 26  Top Validation Acc: 0.9358974358974359
Fold [3/5] Epoch [0/100] Initial Loss: 0.1412, Training Loss: 0.1412, Initial Validation Loss: 0.1352, Validation Loss: 0.1352,V Acc: 0.3182, Top 70th Acc: 0.3117, Bottom 30th Acc: 0.3333
Fold [3/5] Epoch [10/100] Initial Loss: 0.1412, Training Loss: 0.0452, Initial Validation Loss: 0.1352, Validation Loss: 0.0584,V Acc: 0.7091, Top 70th Acc: 0.8312, Bottom 30th Acc: 0.4242
Fold [3/5] Epoch [20/100] Initial Loss: 0.1412, Training Loss: 0.0194, Initial Validation Loss: 0.1352, Validation Loss: 0.0394,V Acc: 0.7909, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.5152
Stopping early at Epoch (base 0): 29  Rolling back to Epoch (base 0): 24  Top Validation Acc: 0.9090909090909091
Fold [4/5] Epoch [0/100] Initial Loss: 0.1436, Training Loss: 0.1436, Initial Validation Loss: 0.1337, Validation Loss: 0.1337,V Acc: 0.3486, Top 70th Acc: 0.4286, Bottom 30th Acc: 0.1562
Fold [4/5] Epoch [10/100] Initial Loss: 0.1436, Training Loss: 0.0331, Initial Validation Loss: 0.1337, Validation Loss: 0.0349,V Acc: 0.8257, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.5625
Stopping early at Epoch (base 0): 18  Rolling back to Epoch (base 0): 13  Top Validation Acc: 0.935064935064935
65 3 [array([0.5408379 , 0.06858069, 0.05877573, 0.11719529, 0.21461034],
      dtype=float32)]
Fold [5/5] Epoch [0/100] Initial Loss: 0.1410, Training Loss: 0.1410, Initial Validation Loss: 0.1300, Validation Loss: 0.1300,V Acc: 0.3056, Top 70th Acc: 0.3158, Bottom 30th Acc: 0.2812
Stopping early at Epoch (base 0): 40  Rolling back to Epoch (base 0): 35  Top Validation Acc: 0.9746835443037974
Fold [2/5] Epoch [0/100] Initial Loss: 0.1413, Training Loss: 0.1413, Initial Validation Loss: 0.1317, Validation Loss: 0.1317,V Acc: 0.3243, Top 70th Acc: 0.2949, Bottom 30th Acc: 0.3939
Fold [2/5] Epoch [10/100] Initial Loss: 0.1413, Training Loss: 0.0185, Initial Validation Loss: 0.1317, Validation Loss: 0.0355,V Acc: 0.8378, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.6061
Fold [2/5] Epoch [20/100] Initial Loss: 0.1413, Training Loss: 0.0045, Initial Validation Loss: 0.1317, Validation Loss: 0.0317,V Acc: 0.8378, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 28  Rolling back to Epoch (base 0): 23  Top Validation Acc: 0.9358974358974359
Fold [3/5] Epoch [0/100] Initial Loss: 0.1391, Training Loss: 0.1391, Initial Validation Loss: 0.1341, Validation Loss: 0.1341,V Acc: 0.2545, Top 70th Acc: 0.3506, Bottom 30th Acc: 0.0303
Fold [3/5] Epoch [10/100] Initial Loss: 0.1391, Training Loss: 0.0212, Initial Validation Loss: 0.1341, Validation Loss: 0.0415,V Acc: 0.7909, Top 70th Acc: 0.8701, Bottom 30th Acc: 0.6061
Fold [3/5] Epoch [20/100] Initial Loss: 0.1391, Training Loss: 0.0068, Initial Validation Loss: 0.1341, Validation Loss: 0.0366,V Acc: 0.8182, Top 70th Acc: 0.8961, Bottom 30th Acc: 0.6364
Fold [3/5] Epoch [30/100] Initial Loss: 0.1391, Training Loss: 0.0050, Initial Validation Loss: 0.1341, Validation Loss: 0.0346,V Acc: 0.8091, Top 70th Acc: 0.8961, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 38  Rolling back to Epoch (base 0): 33  Top Validation Acc: 0.8961038961038961
50 2 [array([0.2054815 , 0.06557778, 0.1139337 , 0.21486944, 0.4001376 ],
      dtype=float32)]
Fold [4/5] Epoch [0/100] Initial Loss: 0.1400, Training Loss: 0.1400, Initial Validation Loss: 0.1361, Validation Loss: 0.1361,V Acc: 0.2661, Top 70th Acc: 0.3247, Bottom 30th Acc: 0.1250
Fold [4/5] Epoch [10/100] Initial Loss: 0.1400, Training Loss: 0.0189, Initial Validation Loss: 0.1361, Validation Loss: 0.0379,V Acc: 0.8349, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.6562
Fold [4/5] Epoch [20/100] Initial Loss: 0.1400, Training Loss: 0.0050, Initial Validation Loss: 0.1361, Validation Loss: 0.0320,V Acc: 0.8257, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.5000
Stopping early at Epoch (base 0): 20  Rolling back to Epoch (base 0): 15  Top Validation Acc: 0.961038961038961
Fold [5/5] Epoch [0/100] Initial Loss: 0.1375, Training Loss: 0.1375, Initial Validation Loss: 0.1338, Validation Loss: 0.1338,V Acc: 0.2500, Top 70th Acc: 0.3289, Bottom 30th Acc: 0.0625
Fold [5/5] Epoch [10/100] Initial Loss: 0.1375, Training Loss: 0.0138, Initial Validation Loss: 0.1338, Validation Loss: 0.0273,V Acc: 0.8704, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.6562
Fold [5/5] Epoch [20/100] Initial Loss: 0.1375, Training Loss: 0.0049, Initial Validation Loss: 0.1338, Validation Loss: 0.0231,V Acc: 0.9074, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.7812
Fold [5/5] Epoch [30/100] Initial Loss: 0.1375, Training Loss: 0.0040, Initial Validation Loss: 0.1338, Validation Loss: 0.0226,V Acc: 0.9167, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.8125
Stopping early at Epoch (base 0): 34  Rolling back to Epoch (base 0): 29  Top Validation Acc: 0.9605263157894737
Running train_nn.py with seed 51
CUDA:False
Training samples count:  550
Training on 162 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1401, Training Loss: 0.1401, Initial Validation Loss: 0.1339, Validation Loss: 0.1339,V Acc: 0.3214, Top 70th Acc: 0.4304, Bottom 30th Acc: 0.0606
Fold [1/5] Epoch [10/100] Initial Loss: 0.1401, Training Loss: 0.0183, Initial Validation Loss: 0.1339, Validation Loss: 0.0439,V Acc: 0.8125, Top 70th Acc: 0.9241, Bottom 30th Acc: 0.5455
Fold [1/5] Epoch [20/100] Initial Loss: 0.1401, Training Loss: 0.0057, Initial Validation Loss: 0.1339, Validation Loss: 0.0387,V Acc: 0.7946, Top 70th Acc: 0.9114, Bottom 30th Acc: 0.5152
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.9367088607594937
Fold [2/5] Epoch [0/100] Initial Loss: 0.1426, Training Loss: 0.1426, Initial Validation Loss: 0.1349, Validation Loss: 0.1349,V Acc: 0.2703, Top 70th Acc: 0.3462, Bottom 30th Acc: 0.0909
Fold [2/5] Epoch [10/100] Initial Loss: 0.1426, Training Loss: 0.0202, Initial Validation Loss: 0.1349, Validation Loss: 0.0407,V Acc: 0.8018, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.5152
Fold [2/5] Epoch [20/100] Initial Loss: 0.1426, Training Loss: 0.0050, Initial Validation Loss: 0.1349, Validation Loss: 0.0326,V Acc: 0.8378, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 29  Rolling back to Epoch (base 0): 24  Top Validation Acc: 0.9615384615384616
Fold [3/5] Epoch [0/100] Initial Loss: 0.1399, Training Loss: 0.1399, Initial Validation Loss: 0.1316, Validation Loss: 0.1316,V Acc: 0.3273, Top 70th Acc: 0.3636, Bottom 30th Acc: 0.2424
Fold [3/5] Epoch [10/100] Initial Loss: 0.1399, Training Loss: 0.0238, Initial Validation Loss: 0.1316, Validation Loss: 0.0418,V Acc: 0.7818, Top 70th Acc: 0.8961, Bottom 30th Acc: 0.5152
Fold [3/5] Epoch [20/100] Initial Loss: 0.1399, Training Loss: 0.0049, Initial Validation Loss: 0.1316, Validation Loss: 0.0310,V Acc: 0.8182, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.5455
Fold [3/5] Epoch [30/100] Initial Loss: 0.1399, Training Loss: 0.0040, Initial Validation Loss: 0.1316, Validation Loss: 0.0303,V Acc: 0.8273, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 30  Rolling back to Epoch (base 0): 25  Top Validation Acc: 0.948051948051948
51 2 [array([0.18407194, 0.07390842, 0.05942295, 0.1376878 , 0.54490894],
      dtype=float32)]
Fold [4/5] Epoch [0/100] Initial Loss: 0.1388, Training Loss: 0.1388, Initial Validation Loss: 0.1338, Validation Loss: 0.1338,V Acc: 0.2569, Top 70th Acc: 0.3506, Bottom 30th Acc: 0.0312
Fold [4/5] Epoch [10/100] Initial Loss: 0.1388, Training Loss: 0.0185, Initial Validation Loss: 0.1338, Validation Loss: 0.0440,V Acc: 0.7706, Top 70th Acc: 0.8961, Bottom 30th Acc: 0.4688
Fold [4/5] Epoch [20/100] Initial Loss: 0.1388, Training Loss: 0.0054, Initial Validation Loss: 0.1338, Validation Loss: 0.0348,V Acc: 0.8165, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.5312
Fold [4/5] Epoch [30/100] Initial Loss: 0.1388, Training Loss: 0.0043, Initial Validation Loss: 0.1338, Validation Loss: 0.0336,V Acc: 0.8349, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.6250
Fold [4/5] Epoch [40/100] Initial Loss: 0.1388, Training Loss: 0.0039, Initial Validation Loss: 0.1338, Validation Loss: 0.0324,V Acc: 0.8257, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.5625
Stopping early at Epoch (base 0): 41  Rolling back to Epoch (base 0): 36  Top Validation Acc: 0.935064935064935
Fold [5/5] Epoch [0/100] Initial Loss: 0.1412, Training Loss: 0.1412, Initial Validation Loss: 0.1345, Validation Loss: 0.1345,V Acc: 0.2222, Top 70th Acc: 0.2895, Bottom 30th Acc: 0.0625
Fold [5/5] Epoch [10/100] Initial Loss: 0.1412, Training Loss: 0.0207, Initial Validation Loss: 0.1345, Validation Loss: 0.0315,V Acc: 0.8796, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.7500
Stopping early at Epoch (base 0): 17  Rolling back to Epoch (base 0): 12  Top Validation Acc: 0.9605263157894737
Running train_nn.py with seed 52
CUDA:False
Training samples count:  550
Training on 162 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1414, Training Loss: 0.1414, Initial Validation Loss: 0.1359, Validation Loss: 0.1359,V Acc: 0.2589, Top 70th Acc: 0.3038, Bottom 30th Acc: 0.1515
Fold [1/5] Epoch [10/100] Initial Loss: 0.1414, Training Loss: 0.0290, Initial Validation Loss: 0.1359, Validation Loss: 0.0343,V Acc: 0.8304, Top 70th Acc: 0.9494, Bottom 30th Acc: 0.5455
Fold [1/5] Epoch [20/100] Initial Loss: 0.1414, Training Loss: 0.0063, Initial Validation Loss: 0.1359, Validation Loss: 0.0228,V Acc: 0.9107, Top 70th Acc: 0.9747, Bottom 30th Acc: 0.7576
Fold [1/5] Epoch [30/100] Initial Loss: 0.1414, Training Loss: 0.0043, Initial Validation Loss: 0.1359, Validation Loss: 0.0216,V Acc: 0.9196, Top 70th Acc: 0.9620, Bottom 30th Acc: 0.8182
Stopping early at Epoch (base 0): 30  Rolling back to Epoch (base 0): 25
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.9473684210526315
Running train_nn.py with seed 68
CUDA:False
Training samples count:  550
Training on 40 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1403, Training Loss: 0.1403, Initial Validation Loss: 0.1369, Validation Loss: 0.1369,V Acc: 0.3304, Top 70th Acc: 0.3797, Bottom 30th Acc: 0.2121
Fold [1/5] Epoch [10/100] Initial Loss: 0.1403, Training Loss: 0.0413, Initial Validation Loss: 0.1369, Validation Loss: 0.0490,V Acc: 0.7411, Top 70th Acc: 0.8987, Bottom 30th Acc: 0.3636
Fold [1/5] Epoch [20/100] Initial Loss: 0.1403, Training Loss: 0.0148, Initial Validation Loss: 0.1369, Validation Loss: 0.0295,V Acc: 0.8571, Top 70th Acc: 0.9494, Bottom 30th Acc: 0.6364
Fold [1/5] Epoch [30/100] Initial Loss: 0.1403, Training Loss: 0.0118, Initial Validation Loss: 0.1369, Validation Loss: 0.0286,V Acc: 0.8571, Top 70th Acc: 0.9367, Bottom 30th Acc: 0.6667
Fold [1/5] Epoch [40/100] Initial Loss: 0.1403, Training Loss: 0.0108, Initial Validation Loss: 0.1369, Validation Loss: 0.0289,V Acc: 0.8750, Top 70th Acc: 0.9494, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 41  Rolling back to Epoch (base 0): 36  Top Validation Acc: 0.9367088607594937
68 0 [array([0.5966674 , 0.16572338, 0.04152812, 0.07798092, 0.11810017],
      dtype=float32)]
Fold [2/5] Epoch [0/100] Initial Loss: 0.1389, Training Loss: 0.1389, Initial Validation Loss: 0.1389, Validation Loss: 0.1389,V Acc: 0.2523, Top 70th Acc: 0.3333, Bottom 30th Acc: 0.0606
Fold [2/5] Epoch [10/100] Initial Loss: 0.1389, Training Loss: 0.0292, Initial Validation Loss: 0.1389, Validation Loss: 0.0408,V Acc: 0.8378, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.6364
Fold [2/5] Epoch [20/100] Initial Loss: 0.1389, Training Loss: 0.0134, Initial Validation Loss: 0.1389, Validation Loss: 0.0323,V Acc: 0.8559, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.9487179487179487
Fold [3/5] Epoch [0/100] Initial Loss: 0.1402, Training Loss: 0.1402, Initial Validation Loss: 0.1318, Validation Loss: 0.1318,V Acc: 0.3273, Top 70th Acc: 0.3636, Bottom 30th Acc: 0.2424
Fold [3/5] Epoch [10/100] Initial Loss: 0.1402, Training Loss: 0.0344, Initial Validation Loss: 0.1318, Validation Loss: 0.0426,V Acc: 0.7727, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.4545
Fold [3/5] Epoch [20/100] Initial Loss: 0.1402, Training Loss: 0.0155, Initial Validation Loss: 0.1318, Validation Loss: 0.0299,V Acc: 0.8636, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6667
Fold [3/5] Epoch [30/100] Initial Loss: 0.1402, Training Loss: 0.0124, Initial Validation Loss: 0.1318, Validation Loss: 0.0289,V Acc: 0.8636, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.6970
Fold [3/5] Epoch [40/100] Initial Loss: 0.1402, Training Loss: 0.0113, Initial Validation Loss: 0.1318, Validation Loss: 0.0279,V Acc: 0.8727, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.7273
Stopping early at Epoch (base 0): 42  Rolling back to Epoch (base 0): 37  Top Validation Acc: 0.935064935064935
Fold [4/5] Epoch [0/100] Initial Loss: 0.1405, Training Loss: 0.1405, Initial Validation Loss: 0.1275, Validation Loss: 0.1275,V Acc: 0.2844, Top 70th Acc: 0.3506, Bottom 30th Acc: 0.1250
Fold [4/5] Epoch [10/100] Initial Loss: 0.1405, Training Loss: 0.0294, Initial Validation Loss: 0.1275, Validation Loss: 0.0351,V Acc: 0.7890, Top 70th Acc: 0.8961, Bottom 30th Acc: 0.5312
Fold [4/5] Epoch [20/100] Initial Loss: 0.1405, Training Loss: 0.0129, Initial Validation Loss: 0.1275, Validation Loss: 0.0291,V Acc: 0.8257, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.5312
Fold [4/5] Epoch [30/100] Initial Loss: 0.1405, Training Loss: 0.0107, Initial Validation Loss: 0.1275, Validation Loss: 0.0278,V Acc: 0.8165, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.5000
Stopping early at Epoch (base 0): 31  Rolling back to Epoch (base 0): 26  Top Validation Acc: 0.948051948051948
Fold [5/5] Epoch [0/100] Initial Loss: 0.1391, Training Loss: 0.1391, Initial Validation Loss: 0.1367, Validation Loss: 0.1367,V Acc: 0.2685, Top 70th Acc: 0.3026, Bottom 30th Acc: 0.1875
Fold [5/5] Epoch [10/100] Initial Loss: 0.1391, Training Loss: 0.0303, Initial Validation Loss: 0.1367, Validation Loss: 0.0368,V Acc: 0.8426, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.5625
Fold [5/5] Epoch [20/100] Initial Loss: 0.1391, Training Loss: 0.0155, Initial Validation Loss: 0.1367, Validation Loss: 0.0288,V Acc: 0.8611, Top 70th Acc: 0.9868, Bottom 30th Acc: 0.5625
Stopping early at Epoch (base 0): 29  Rolling back to Epoch (base 0): 24  Top Validation Acc: 0.9868421052631579
Running train_nn.py with seed 69
CUDA:False
Training samples count:  550
Training on 40 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1405, Training Loss: 0.1405, Initial Validation Loss: 0.1372, Validation Loss: 0.1372,V Acc: 0.2946, Top 70th Acc: 0.3165, Bottom 30th Acc: 0.2424
Fold [1/5] Epoch [10/100] Initial Loss: 0.1405, Training Loss: 0.0341, Initial Validation Loss: 0.1372, Validation Loss: 0.0442,V Acc: 0.7679, Top 70th Acc: 0.9367, Bottom 30th Acc: 0.3636
Fold [1/5] Epoch [20/100] Initial Loss: 0.1405, Training Loss: 0.0137, Initial Validation Loss: 0.1372, Validation Loss: 0.0322,V Acc: 0.8214, Top 70th Acc: 0.9494, Bottom 30th Acc: 0.5152
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.9493670886075949
Fold [2/5] Epoch [0/100] Initial Loss: 0.1392, Training Loss: 0.1392, Initial Validation Loss: 0.1339, Validation Loss: 0.1339,V Acc: 0.2523, Top 70th Acc: 0.3077, Bottom 30th Acc: 0.1212
Fold [2/5] Epoch [10/100] Initial Loss: 0.1392, Training Loss: 0.0295, Initial Validation Loss: 0.1339, Validation Loss: 0.0414,V Acc: 0.8468, Top 70th Acc: 0.8974, Bottom 30th Acc: 0.7273
Fold [2/5] Epoch [20/100] Initial Loss: 0.1392, Training Loss: 0.0138, Initial Validation Loss: 0.1339, Validation Loss: 0.0308,V Acc: 0.8649, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.9358974358974359
Fold [3/5] Epoch [0/100] Initial Loss: 0.1403, Training Loss: 0.1403, Initial Validation Loss: 0.1337, Validation Loss: 0.1337,V Acc: 0.2182, Top 70th Acc: 0.2078, Bottom 30th Acc: 0.2424
Fold [3/5] Epoch [10/100] Initial Loss: 0.1403, Training Loss: 0.0342, Initial Validation Loss: 0.1337, Validation Loss: 0.0444,V Acc: 0.7727, Top 70th Acc: 0.8961, Bottom 30th Acc: 0.4848
Fold [3/5] Epoch [20/100] Initial Loss: 0.1403, Training Loss: 0.0137, Initial Validation Loss: 0.1337, Validation Loss: 0.0338,V Acc: 0.8091, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.5152
Fold [3/5] Epoch [30/100] Initial Loss: 0.1403, Training Loss: 0.0108, Initial Validation Loss: 0.1337, Validation Loss: 0.0332,V Acc: 0.8273, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 32  Rolling back to Epoch (base 0): 27  Top Validation Acc: 0.948051948051948
Fold [4/5] Epoch [0/100] Initial Loss: 0.1404, Training Loss: 0.1404, Initial Validation Loss: 0.1360, Validation Loss: 0.1360,V Acc: 0.3028, Top 70th Acc: 0.3247, Bottom 30th Acc: 0.2500
Fold [4/5] Epoch [10/100] Initial Loss: 0.1404, Training Loss: 0.0458, Initial Validation Loss: 0.1360, Validation Loss: 0.0502,V Acc: 0.7890, Top 70th Acc: 0.8831, Bottom 30th Acc: 0.5625
Fold [4/5] Epoch [20/100] Initial Loss: 0.1404, Training Loss: 0.0160, Initial Validation Loss: 0.1360, Validation Loss: 0.0303,V Acc: 0.8532, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.5938
Fold [4/5] Epoch [30/100] Initial Loss: 0.1404, Training Loss: 0.0117, Initial Validation Loss: 0.1360, Validation Loss: 0.0298,V Acc: 0.8532, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6250
Stopping early at Epoch (base 0): 32  Rolling back to Epoch (base 0): 27  Top Validation Acc: 0.935064935064935
Fold [5/5] Epoch [0/100] Initial Loss: 0.1363, Training Loss: 0.1363, Initial Validation Loss: 0.1310, Validation Loss: 0.1310,V Acc: 0.2500, Top 70th Acc: 0.3421, Bottom 30th Acc: 0.0312
Fold [5/5] Epoch [10/100] Initial Loss: 0.1363, Training Loss: 0.0218, Initial Validation Loss: 0.1310, Validation Loss: 0.0282,V Acc: 0.9074, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.8125
Fold [1/5] Epoch [10/100] Initial Loss: 0.1286, Training Loss: 0.0238, Initial Validation Loss: 0.1094, Validation Loss: 0.0286,V Acc: 0.8661, Top 70th Acc: 0.9241, Bottom 30th Acc: 0.7273
Stopping early at Epoch (base 0): 19  Rolling back to Epoch (base 0): 14  Top Validation Acc: 0.9620253164556962
Fold [2/5] Epoch [0/100] Initial Loss: 0.1328, Training Loss: 0.1328, Initial Validation Loss: 0.1180, Validation Loss: 0.1180,V Acc: 0.4685, Top 70th Acc: 0.5385, Bottom 30th Acc: 0.3030
Fold [2/5] Epoch [10/100] Initial Loss: 0.1328, Training Loss: 0.0249, Initial Validation Loss: 0.1180, Validation Loss: 0.0317,V Acc: 0.8468, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.5758
Fold [2/5] Epoch [20/100] Initial Loss: 0.1328, Training Loss: 0.0165, Initial Validation Loss: 0.1180, Validation Loss: 0.0227,V Acc: 0.8739, Top 70th Acc: 0.9872, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.9743589743589743
90 1 [array([0.71721303, 0.01495824, 0.04201047, 0.14773601, 0.07808229],
      dtype=float32)]
Fold [3/5] Epoch [0/100] Initial Loss: 0.1325, Training Loss: 0.1325, Initial Validation Loss: 0.1165, Validation Loss: 0.1165,V Acc: 0.4182, Top 70th Acc: 0.5455, Bottom 30th Acc: 0.1212
Fold [3/5] Epoch [10/100] Initial Loss: 0.1325, Training Loss: 0.0229, Initial Validation Loss: 0.1165, Validation Loss: 0.0269,V Acc: 0.8909, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.7879
Fold [3/5] Epoch [20/100] Initial Loss: 0.1325, Training Loss: 0.0174, Initial Validation Loss: 0.1165, Validation Loss: 0.0301,V Acc: 0.8636, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 22  Rolling back to Epoch (base 0): 17  Top Validation Acc: 0.961038961038961
Fold [4/5] Epoch [0/100] Initial Loss: 0.1352, Training Loss: 0.1352, Initial Validation Loss: 0.1287, Validation Loss: 0.1287,V Acc: 0.4862, Top 70th Acc: 0.6104, Bottom 30th Acc: 0.1875
Fold [4/5] Epoch [10/100] Initial Loss: 0.1352, Training Loss: 0.0247, Initial Validation Loss: 0.1287, Validation Loss: 0.0230,V Acc: 0.8807, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.6562
Fold [4/5] Epoch [20/100] Initial Loss: 0.1352, Training Loss: 0.0166, Initial Validation Loss: 0.1287, Validation Loss: 0.0178,V Acc: 0.9174, Top 70th Acc: 0.9870, Bottom 30th Acc: 0.7500
Stopping early at Epoch (base 0): 21  Rolling back to Epoch (base 0): 16  Top Validation Acc: 0.974025974025974
Fold [5/5] Epoch [0/100] Initial Loss: 0.1288, Training Loss: 0.1288, Initial Validation Loss: 0.1151, Validation Loss: 0.1151,V Acc: 0.4444, Top 70th Acc: 0.5526, Bottom 30th Acc: 0.1875
Fold [5/5] Epoch [10/100] Initial Loss: 0.1288, Training Loss: 0.0225, Initial Validation Loss: 0.1151, Validation Loss: 0.0318,V Acc: 0.8519, Top 70th Acc: 0.9737, Bottom 30th Acc: 0.5625
Fold [5/5] Epoch [20/100] Initial Loss: 0.1288, Training Loss: 0.0153, Initial Validation Loss: 0.1151, Validation Loss: 0.0280,V Acc: 0.8519, Top 70th Acc: 0.9868, Bottom 30th Acc: 0.5312
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 1.0
Running train_nn.py with seed 91
CUDA:False
Training samples count:  550
Training on 21 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1338, Training Loss: 0.1338, Initial Validation Loss: 0.1232, Validation Loss: 0.1232,V Acc: 0.5000, Top 70th Acc: 0.6076, Bottom 30th Acc: 0.2424
Fold [1/5] Epoch [10/100] Initial Loss: 0.1338, Training Loss: 0.0248, Initial Validation Loss: 0.1232, Validation Loss: 0.0379,V Acc: 0.8214, Top 70th Acc: 0.9620, Bottom 30th Acc: 0.4848
Fold [1/5] Epoch [20/100] Initial Loss: 0.1338, Training Loss: 0.0168, Initial Validation Loss: 0.1232, Validation Loss: 0.0232,V Acc: 0.8750, Top 70th Acc: 0.9747, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.9873417721518988
91 0 [array([0.8101584 , 0.01668031, 0.02598909, 0.08379979, 0.0633724 ],
      dtype=float32)]
Fold [2/5] Epoch [0/100] Initial Loss: 0.1387, Training Loss: 0.1387, Initial Validation Loss: 0.1179, Validation Loss: 0.1179,V Acc: 0.4324, Top 70th Acc: 0.5769, Bottom 30th Acc: 0.0909
Fold [2/5] Epoch [10/100] Initial Loss: 0.1387, Training Loss: 0.0205, Initial Validation Loss: 0.1179, Validation Loss: 0.0274,V Acc: 0.8468, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 16  Rolling back to Epoch (base 0): 11  Top Validation Acc: 0.9358974358974359
Fold [3/5] Epoch [0/100] Initial Loss: 0.1248, Training Loss: 0.1248, Initial Validation Loss: 0.1118, Validation Loss: 0.1118,V Acc: 0.4455, Top 70th Acc: 0.5714, Bottom 30th Acc: 0.1515
Fold [3/5] Epoch [10/100] Initial Loss: 0.1248, Training Loss: 0.0272, Initial Validation Loss: 0.1118, Validation Loss: 0.0354,V Acc: 0.8273, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.5152
Fold [3/5] Epoch [20/100] Initial Loss: 0.1248, Training Loss: 0.0183, Initial Validation Loss: 0.1118, Validation Loss: 0.0190,V Acc: 0.9000, Top 70th Acc: 1.0000, Bottom 30th Acc: 0.6667
Fold [3/5] Epoch [30/100] Initial Loss: 0.1248, Training Loss: 0.0158, Initial Validation Loss: 0.1118, Validation Loss: 0.0262,V Acc: 0.8727, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 31  Rolling back to Epoch (base 0): 26  Top Validation Acc: 0.987012987012987
Fold [4/5] Epoch [0/100] Initial Loss: 0.1363, Training Loss: 0.1363, Initial Validation Loss: 0.1296, Validation Loss: 0.1296,V Acc: 0.4771, Top 70th Acc: 0.5974, Bottom 30th Acc: 0.1875
Fold [4/5] Epoch [10/100] Initial Loss: 0.1363, Training Loss: 0.0249, Initial Validation Loss: 0.1296, Validation Loss: 0.0304,V Acc: 0.8899, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.7500
Fold [4/5] Epoch [20/100] Initial Loss: 0.1363, Training Loss: 0.0169, Initial Validation Loss: 0.1296, Validation Loss: 0.0233,V Acc: 0.9083, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.7500
Stopping early at Epoch (base 0): 27  Rolling back to Epoch (base 0): 22  Top Validation Acc: 0.961038961038961
Fold [5/5] Epoch [0/100] Initial Loss: 0.1295, Training Loss: 0.1295, Initial Validation Loss: 0.1125, Validation Loss: 0.1125,V Acc: 0.5278, Top 70th Acc: 0.6316, Bottom 30th Acc: 0.2812
Fold [5/5] Epoch [10/100] Initial Loss: 0.1295, Training Loss: 0.0218, Initial Validation Loss: 0.1125, Validation Loss: 0.0298,V Acc: 0.8519, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.6250
Fold [5/5] Epoch [20/100] Initial Loss: 0.1295, Training Loss: 0.0142, Initial Validation Loss: 0.1125, Validation Loss: 0.0268,V Acc: 0.8611, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.6250
Stopping early at Epoch (base 0): 21  Rolling back to Epoch (base 0): 16  Top Validation Acc: 0.9473684210526315
Running train_nn.py with seed 92
CUDA:False
Training samples count:  550
Training on 21 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1376, Training Loss: 0.1376, Initial Validation Loss: 0.1315, Validation Loss: 0.1315,V Acc: 0.3214, Top 70th Acc: 0.3797, Bottom 30th Acc: 0.1818
Fold [1/5] Epoch [10/100] Initial Loss: 0.1376, Training Loss: 0.0240, Initial Validation Loss: 0.1315, Validation Loss: 0.0281,V Acc: 0.8571, Top 70th Acc: 0.9747, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 16  Rolling back to Epoch (base 0): 11  Top Validation Acc: 0.9493670886075949
Fold [2/5] Epoch [0/100] Initial Loss: 0.1377, Training Loss: 0.1377, Initial Validation Loss: 0.1215, Validation Loss: 0.1215,V Acc: 0.4414, Top 70th Acc: 0.5513, Bottom 30th Acc: 0.1818
Fold [2/5] Epoch [10/100] Initial Loss: 0.1377, Training Loss: 0.0199, Initial Validation Loss: 0.1215, Validation Loss: 0.0317,V Acc: 0.8559, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 16  Rolling back to Epoch (base 0): 11  Top Validation Acc: 0.8974358974358975
Fold [3/5] Epoch [0/100] Initial Loss: 0.1314, Training Loss: 0.1314, Initial Validation Loss: 0.1186, Validation Loss: 0.1186,V Acc: 0.5273, Top 70th Acc: 0.6234, Bottom 30th Acc: 0.3030
Fold [3/5] Epoch [10/100] Initial Loss: 0.1314, Training Loss: 0.0250, Initial Validation Loss: 0.1186, Validation Loss: 0.0259,V Acc: 0.8727, Top 70th Acc: 0.9870, Bottom 30th Acc: 0.6061
Fold [3/5] Epoch [20/100] Initial Loss: 0.1314, Training Loss: 0.0165, Initial Validation Loss: 0.1186, Validation Loss: 0.0229,V Acc: 0.8818, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.6667/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
 550
Training on 20 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1379, Training Loss: 0.1379, Initial Validation Loss: 0.1377, Validation Loss: 0.1377,V Acc: 0.3393, Top 70th Acc: 0.4557, Bottom 30th Acc: 0.0606
Fold [1/5] Epoch [10/100] Initial Loss: 0.1379, Training Loss: 0.0441, Initial Validation Loss: 0.1377, Validation Loss: 0.0429,V Acc: 0.8214, Top 70th Acc: 0.8987, Bottom 30th Acc: 0.6364
Fold [1/5] Epoch [20/100] Initial Loss: 0.1379, Training Loss: 0.0334, Initial Validation Loss: 0.1377, Validation Loss: 0.0361,V Acc: 0.8661, Top 70th Acc: 0.9114, Bottom 30th Acc: 0.7576
Fold [1/5] Epoch [30/100] Initial Loss: 0.1379, Training Loss: 0.0249, Initial Validation Loss: 0.1377, Validation Loss: 0.0277,V Acc: 0.8750, Top 70th Acc: 0.9494, Bottom 30th Acc: 0.6970
Fold [1/5] Epoch [40/100] Initial Loss: 0.1379, Training Loss: 0.0224, Initial Validation Loss: 0.1377, Validation Loss: 0.0270,V Acc: 0.9107, Top 70th Acc: 0.9367, Bottom 30th Acc: 0.8485
Stopping early at Epoch (base 0): 40  Rolling back to Epoch (base 0): 35  Top Validation Acc: 0.9367088607594937
Fold [2/5] Epoch [0/100] Initial Loss: 0.1387, Training Loss: 0.1387, Initial Validation Loss: 0.1311, Validation Loss: 0.1311,V Acc: 0.3694, Top 70th Acc: 0.3974, Bottom 30th Acc: 0.3030
Fold [2/5] Epoch [10/100] Initial Loss: 0.1387, Training Loss: 0.0329, Initial Validation Loss: 0.1311, Validation Loss: 0.0424,V Acc: 0.8108, Top 70th Acc: 0.8974, Bottom 30th Acc: 0.6061
Fold [2/5] Epoch [20/100] Initial Loss: 0.1387, Training Loss: 0.0231, Initial Validation Loss: 0.1311, Validation Loss: 0.0406,V Acc: 0.7838, Top 70th Acc: 0.8974, Bottom 30th Acc: 0.5152
Stopping early at Epoch (base 0): 22  Rolling back to Epoch (base 0): 17  Top Validation Acc: 0.8974358974358975
66 1 [array([0.30943736, 0.09238511, 0.16732319, 0.24972916, 0.18112515],
      dtype=float32)]
Fold [3/5] Epoch [0/100] Initial Loss: 0.1384, Training Loss: 0.1384, Initial Validation Loss: 0.1308, Validation Loss: 0.1308,V Acc: 0.3182, Top 70th Acc: 0.2987, Bottom 30th Acc: 0.3636
Fold [3/5] Epoch [10/100] Initial Loss: 0.1384, Training Loss: 0.0366, Initial Validation Loss: 0.1308, Validation Loss: 0.0430,V Acc: 0.7727, Top 70th Acc: 0.8961, Bottom 30th Acc: 0.4848
Fold [3/5] Epoch [20/100] Initial Loss: 0.1384, Training Loss: 0.0241, Initial Validation Loss: 0.1308, Validation Loss: 0.0382,V Acc: 0.7727, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.4242
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.935064935064935
Fold [4/5] Epoch [0/100] Initial Loss: 0.1385, Training Loss: 0.1385, Initial Validation Loss: 0.1321, Validation Loss: 0.1321,V Acc: 0.3486, Top 70th Acc: 0.3766, Bottom 30th Acc: 0.2812
Fold [4/5] Epoch [10/100] Initial Loss: 0.1385, Training Loss: 0.0303, Initial Validation Loss: 0.1321, Validation Loss: 0.0418,V Acc: 0.7890, Top 70th Acc: 0.8831, Bottom 30th Acc: 0.5625
Fold [4/5] Epoch [20/100] Initial Loss: 0.1385, Training Loss: 0.0227, Initial Validation Loss: 0.1321, Validation Loss: 0.0405,V Acc: 0.8073, Top 70th Acc: 0.8312, Bottom 30th Acc: 0.7500
Stopping early at Epoch (base 0): 20  Rolling back to Epoch (base 0): 15  Top Validation Acc: 0.8311688311688312
Fold [5/5] Epoch [0/100] Initial Loss: 0.1386, Training Loss: 0.1386, Initial Validation Loss: 0.1308, Validation Loss: 0.1308,V Acc: 0.3704, Top 70th Acc: 0.4605, Bottom 30th Acc: 0.1562
Fold [5/5] Epoch [10/100] Initial Loss: 0.1386, Training Loss: 0.0364, Initial Validation Loss: 0.1308, Validation Loss: 0.0452,V Acc: 0.7778, Top 70th Acc: 0.9079, Bottom 30th Acc: 0.4688
Fold [5/5] Epoch [20/100] Initial Loss: 0.1386, Training Loss: 0.0220, Initial Validation Loss: 0.1308, Validation Loss: 0.0400,V Acc: 0.7963, Top 70th Acc: 0.9079, Bottom 30th Acc: 0.5312
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.8947368421052632
Running train_nn.py with seed 67
CUDA:False
Training samples count:  550
Training on 20 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1351, Training Loss: 0.1351, Initial Validation Loss: 0.1334, Validation Loss: 0.1334,V Acc: 0.3214, Top 70th Acc: 0.3797, Bottom 30th Acc: 0.1818
Fold [1/5] Epoch [10/100] Initial Loss: 0.1351, Training Loss: 0.0364, Initial Validation Loss: 0.1334, Validation Loss: 0.0433,V Acc: 0.8125, Top 70th Acc: 0.8987, Bottom 30th Acc: 0.6061
Fold [1/5] Epoch [20/100] Initial Loss: 0.1351, Training Loss: 0.0241, Initial Validation Loss: 0.1334, Validation Loss: 0.0332,V Acc: 0.8214, Top 70th Acc: 0.9367, Bottom 30th Acc: 0.5455
Fold [1/5] Epoch [30/100] Initial Loss: 0.1351, Training Loss: 0.0216, Initial Validation Loss: 0.1334, Validation Loss: 0.0322,V Acc: 0.8125, Top 70th Acc: 0.9241, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 35  Rolling back to Epoch (base 0): 30  Top Validation Acc: 0.9367088607594937
Fold [2/5] Epoch [0/100] Initial Loss: 0.1434, Training Loss: 0.1434, Initial Validation Loss: 0.1349, Validation Loss: 0.1349,V Acc: 0.2523, Top 70th Acc: 0.2564, Bottom 30th Acc: 0.2424
Fold [2/5] Epoch [10/100] Initial Loss: 0.1434, Training Loss: 0.0496, Initial Validation Loss: 0.1349, Validation Loss: 0.0472,V Acc: 0.7568, Top 70th Acc: 0.8974, Bottom 30th Acc: 0.4242
Fold [2/5] Epoch [20/100] Initial Loss: 0.1434, Training Loss: 0.0251, Initial Validation Loss: 0.1349, Validation Loss: 0.0342,V Acc: 0.8018, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.9230769230769231
Fold [3/5] Epoch [0/100] Initial Loss: 0.1418, Training Loss: 0.1418, Initial Validation Loss: 0.1382, Validation Loss: 0.1382,V Acc: 0.3545, Top 70th Acc: 0.3247, Bottom 30th Acc: 0.4242
Fold [3/5] Epoch [10/100] Initial Loss: 0.1418, Training Loss: 0.0463, Initial Validation Loss: 0.1382, Validation Loss: 0.0463,V Acc: 0.8182, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.5455
Fold [3/5] Epoch [20/100] Initial Loss: 0.1418, Training Loss: 0.0254, Initial Validation Loss: 0.1382, Validation Loss: 0.0314,V Acc: 0.8818, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.7273
Fold [3/5] Epoch [30/100] Initial Loss: 0.1418, Training Loss: 0.0224, Initial Validation Loss: 0.1382, Validation Loss: 0.0311,V Acc: 0.8727, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6970
Fold [3/5] Epoch [40/100] Initial Loss: 0.1418, Training Loss: 0.0212, Initial Validation Loss: 0.1382, Validation Loss: 0.0301,V Acc: 0.8818, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 46  Rolling back to Epoch (base 0): 41  Top Validation Acc: 0.961038961038961
Fold [4/5] Epoch [0/100] Initial Loss: 0.1405, Training Loss: 0.1405, Initial Validation Loss: 0.1287, Validation Loss: 0.1287,V Acc: 0.3028, Top 70th Acc: 0.3506, Bottom 30th Acc: 0.1875
Fold [4/5] Epoch [10/100] Initial Loss: 0.1405, Training Loss: 0.0321, Initial Validation Loss: 0.1287, Validation Loss: 0.0413,V Acc: 0.7890, Top 70th Acc: 0.8831, Bottom 30th Acc: 0.5625
Stopping early at Epoch (base 0): 18  Rolling back to Epoch (base 0): 13  Top Validation Acc: 0.8571428571428571
67 3 [array([0.31666937, 0.08806106, 0.10082319, 0.26085386, 0.2335925 ],
      dtype=float32)]
Fold [5/5] Epoch [0/100] Initial Loss: 0.1428, Training Loss: 0.1428, Initial Validation Loss: 0.1274, Validation Loss: 0.1274,V Acc: 0.4167, Top 70th Acc: 0.4605, Bottom 30th Acc: 0.3125
Fold [5/5] Epoch [10/100] Initial Loss: 0.1428, Training Loss: 0.0372, Initial Validation Loss: 0.1274, Validation Loss: 0.0370,V Acc: 0.8333, Top 70th Acc: 0.9211, Bottom 30th Acc: 0.6250
Fold [5/5] Epoch [20/100] Initial Loss: 0.1428, Training Loss: 0.0265, Initial Validation Loss: 0.1274, Validation Loss: 0.0307,V Acc: 0.8611, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.6562
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.9736842105263158
Running train_nn.py with seed 68
CUDA:False
Training samples count:  550
Training on 20 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1380, Training Loss: 0.1380, Initial Validation Loss: 0.1320, Validation Loss: 0.1320,V Acc: 0.3929, Top 70th Acc: 0.5190, Bottom 30th Acc: 0.0909
Fold [1/5] Epoch [10/100] Initial Loss: 0.1380, Training Loss: 0.0352, Initial Validation Loss: 0.1320, Validation Loss: 0.0393,V Acc: 0.8125, Top 70th Acc: 0.9241, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 30  Rolling back to Epoch (base 0): 25  Top Validation Acc: 0.7532467532467533
65 3 [array([0.09986968, 0.3830371 , 0.1520516 , 0.20528884, 0.15975277],
      dtype=float32)]
Fold [5/5] Epoch [0/100] Initial Loss: 0.1376, Training Loss: 0.1376, Initial Validation Loss: 0.1217, Validation Loss: 0.1217,V Acc: 0.5093, Top 70th Acc: 0.5000, Bottom 30th Acc: 0.5312
Fold [5/5] Epoch [10/100] Initial Loss: 0.1376, Training Loss: 0.0804, Initial Validation Loss: 0.1217, Validation Loss: 0.0762,V Acc: 0.6389, Top 70th Acc: 0.7237, Bottom 30th Acc: 0.4375
Fold [5/5] Epoch [20/100] Initial Loss: 0.1376, Training Loss: 0.0789, Initial Validation Loss: 0.1217, Validation Loss: 0.0754,V Acc: 0.6389, Top 70th Acc: 0.7237, Bottom 30th Acc: 0.4375
Stopping early at Epoch (base 0): 28  Rolling back to Epoch (base 0): 23  Top Validation Acc: 0.7236842105263158
Running train_nn.py with seed 66
CUDA:False
Training samples count:  550
Training on 2 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1340, Training Loss: 0.1340, Initial Validation Loss: 0.1264, Validation Loss: 0.1264,V Acc: 0.4018, Top 70th Acc: 0.5190, Bottom 30th Acc: 0.1212
Fold [1/5] Epoch [10/100] Initial Loss: 0.1340, Training Loss: 0.0820, Initial Validation Loss: 0.1264, Validation Loss: 0.0761,V Acc: 0.6250, Top 70th Acc: 0.7722, Bottom 30th Acc: 0.2727
Fold [1/5] Epoch [20/100] Initial Loss: 0.1340, Training Loss: 0.0806, Initial Validation Loss: 0.1264, Validation Loss: 0.0754,V Acc: 0.6339, Top 70th Acc: 0.7848, Bottom 30th Acc: 0.2727
Stopping early at Epoch (base 0): 21  Rolling back to Epoch (base 0): 16  Top Validation Acc: 0.7721518987341772
Fold [2/5] Epoch [0/100] Initial Loss: 0.1384, Training Loss: 0.1384, Initial Validation Loss: 0.1304, Validation Loss: 0.1304,V Acc: 0.3333, Top 70th Acc: 0.4231, Bottom 30th Acc: 0.1212
Fold [2/5] Epoch [10/100] Initial Loss: 0.1384, Training Loss: 0.0808, Initial Validation Loss: 0.1304, Validation Loss: 0.0806,V Acc: 0.6577, Top 70th Acc: 0.7179, Bottom 30th Acc: 0.5152
Fold [2/5] Epoch [20/100] Initial Loss: 0.1384, Training Loss: 0.0792, Initial Validation Loss: 0.1304, Validation Loss: 0.0786,V Acc: 0.6306, Top 70th Acc: 0.7308, Bottom 30th Acc: 0.3939
Fold [2/5] Epoch [30/100] Initial Loss: 0.1384, Training Loss: 0.0786, Initial Validation Loss: 0.1304, Validation Loss: 0.0781,V Acc: 0.6486, Top 70th Acc: 0.7308, Bottom 30th Acc: 0.4545
Stopping early at Epoch (base 0): 37  Rolling back to Epoch (base 0): 32  Top Validation Acc: 0.7435897435897436
66 1 [array([0.12666915, 0.34693128, 0.16095774, 0.22227257, 0.14316924],
      dtype=float32)]
Fold [3/5] Epoch [0/100] Initial Loss: 0.1379, Training Loss: 0.1379, Initial Validation Loss: 0.1262, Validation Loss: 0.1262,V Acc: 0.3727, Top 70th Acc: 0.4545, Bottom 30th Acc: 0.1818
Fold [3/5] Epoch [10/100] Initial Loss: 0.1379, Training Loss: 0.0798, Initial Validation Loss: 0.1262, Validation Loss: 0.0811,V Acc: 0.5818, Top 70th Acc: 0.7273, Bottom 30th Acc: 0.2424
Fold [3/5] Epoch [20/100] Initial Loss: 0.1379, Training Loss: 0.0780, Initial Validation Loss: 0.1262, Validation Loss: 0.0809,V Acc: 0.6182, Top 70th Acc: 0.7143, Bottom 30th Acc: 0.3939
Stopping early at Epoch (base 0): 20  Rolling back to Epoch (base 0): 15  Top Validation Acc: 0.7142857142857143
Fold [4/5] Epoch [0/100] Initial Loss: 0.1448, Training Loss: 0.1448, Initial Validation Loss: 0.1328, Validation Loss: 0.1328,V Acc: 0.2752, Top 70th Acc: 0.3506, Bottom 30th Acc: 0.0938
Fold [4/5] Epoch [10/100] Initial Loss: 0.1448, Training Loss: 0.0814, Initial Validation Loss: 0.1328, Validation Loss: 0.0809,V Acc: 0.6514, Top 70th Acc: 0.7532, Bottom 30th Acc: 0.4062
Fold [4/5] Epoch [20/100] Initial Loss: 0.1448, Training Loss: 0.0787, Initial Validation Loss: 0.1328, Validation Loss: 0.0784,V Acc: 0.6422, Top 70th Acc: 0.7662, Bottom 30th Acc: 0.3438
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.7532467532467533
Fold [5/5] Epoch [0/100] Initial Loss: 0.1304, Training Loss: 0.1304, Initial Validation Loss: 0.1166, Validation Loss: 0.1166,V Acc: 0.5370, Top 70th Acc: 0.5658, Bottom 30th Acc: 0.4688
Fold [5/5] Epoch [10/100] Initial Loss: 0.1304, Training Loss: 0.0797, Initial Validation Loss: 0.1166, Validation Loss: 0.0803,V Acc: 0.6111, Top 70th Acc: 0.7237, Bottom 30th Acc: 0.3438
Fold [5/5] Epoch [20/100] Initial Loss: 0.1304, Training Loss: 0.0774, Initial Validation Loss: 0.1166, Validation Loss: 0.0796,V Acc: 0.6204, Top 70th Acc: 0.7105, Bottom 30th Acc: 0.4062
Fold [5/5] Epoch [30/100] Initial Loss: 0.1304, Training Loss: 0.0766, Initial Validation Loss: 0.1166, Validation Loss: 0.0791,V Acc: 0.6204, Top 70th Acc: 0.7368, Bottom 30th Acc: 0.3438
Stopping early at Epoch (base 0): 31  Rolling back to Epoch (base 0): 26  Top Validation Acc: 0.7236842105263158
Running train_nn.py with seed 67
CUDA:False
Training samples count:  550
Training on 2 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1397, Training Loss: 0.1397, Initial Validation Loss: 0.1367, Validation Loss: 0.1367,V Acc: 0.3393, Top 70th Acc: 0.4430, Bottom 30th Acc: 0.0909
Fold [1/5] Epoch [10/100] Initial Loss: 0.1397, Training Loss: 0.0800, Initial Validation Loss: 0.1367, Validation Loss: 0.0854,V Acc: 0.6071, Top 70th Acc: 0.7215, Bottom 30th Acc: 0.3333
Fold [1/5] Epoch [20/100] Initial Loss: 0.1397, Training Loss: 0.0779, Initial Validation Loss: 0.1367, Validation Loss: 0.0835,V Acc: 0.6250, Top 70th Acc: 0.7215, Bottom 30th Acc: 0.3939
Stopping early at Epoch (base 0): 29  Rolling back to Epoch (base 0): 24  Top Validation Acc: 0.7215189873417721
Fold [2/5] Epoch [0/100] Initial Loss: 0.1321, Training Loss: 0.1321, Initial Validation Loss: 0.1154, Validation Loss: 0.1154,V Acc: 0.5766, Top 70th Acc: 0.6795, Bottom 30th Acc: 0.3333
Fold [2/5] Epoch [10/100] Initial Loss: 0.1321, Training Loss: 0.0820, Initial Validation Loss: 0.1154, Validation Loss: 0.0744,V Acc: 0.6396, Top 70th Acc: 0.7821, Bottom 30th Acc: 0.3030
Stopping early at Epoch (base 0): 18  Rolling back to Epoch (base 0): 13  Top Validation Acc: 0.7564102564102564
Fold [3/5] Epoch [0/100] Initial Loss: 0.1410, Training Loss: 0.1410, Initial Validation Loss: 0.1376, Validation Loss: 0.1376,V Acc: 0.3727, Top 70th Acc: 0.5065, Bottom 30th Acc: 0.0606
Fold [3/5] Epoch [10/100] Initial Loss: 0.1410, Training Loss: 0.0815, Initial Validation Loss: 0.1376, Validation Loss: 0.0790,V Acc: 0.6818, Top 70th Acc: 0.7792, Bottom 30th Acc: 0.4545
Fold [3/5] Epoch [20/100] Initial Loss: 0.1410, Training Loss: 0.0794, Initial Validation Loss: 0.1376, Validation Loss: 0.0754,V Acc: 0.6818, Top 70th Acc: 0.7792, Bottom 30th Acc: 0.4545
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.7662337662337663
Fold [4/5] Epoch [0/100] Initial Loss: 0.1317, Training Loss: 0.1317, Initial Validation Loss: 0.1154, Validation Loss: 0.1154,V Acc: 0.4220, Top 70th Acc: 0.4805, Bottom 30th Acc: 0.2812
Fold [4/5] Epoch [10/100] Initial Loss: 0.1317, Training Loss: 0.0799, Initial Validation Loss: 0.1154, Validation Loss: 0.0819,V Acc: 0.5688, Top 70th Acc: 0.6753, Bottom 30th Acc: 0.3125
Fold [4/5] Epoch [20/100] Initial Loss: 0.1317, Training Loss: 0.0768, Initial Validation Loss: 0.1154, Validation Loss: 0.0828,V Acc: 0.5596, Top 70th Acc: 0.6753, Bottom 30th Acc: 0.2812
Stopping early at Epoch (base 0): 22  Rolling back to Epoch (base 0): 17  Top Validation Acc: 0.6753246753246753
67 3 [array([0.0861223 , 0.38725865, 0.16290389, 0.21243548, 0.1512797 ],
      dtype=float32)]
Fold [5/5] Epoch [0/100] Initial Loss: 0.1376, Training Loss: 0.1376, Initial Validation Loss: 0.1221, Validation Loss: 0.1221,V Acc: 0.4444, Top 70th Acc: 0.5000, Bottom 30th Acc: 0.3125
Fold [5/5] Epoch [10/100] Initial Loss: 0.1376, Training Loss: 0.0803, Initial Validation Loss: 0.1221, Validation Loss: 0.0804,V Acc: 0.5833, Top 70th Acc: 0.6974, Bottom 30th Acc: 0.3125
Fold [5/5] Epoch [20/100] Initial Loss: 0.1376, Training Loss: 0.0786, Initial Validation Loss: 0.1221, Validation Loss: 0.0788,V Acc: 0.6019, Top 70th Acc: 0.7237, Bottom 30th Acc: 0.3125
Fold [5/5] Epoch [30/100] Initial Loss: 0.1376, Training Loss: 0.0775, Initial Validation Loss: 0.1221, Validation Loss: 0.0790,V Acc: 0.6111, Top 70th Acc: 0.7368, Bottom 30th Acc: 0.3125
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 40 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 91
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 39 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 92
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 40 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 93
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 40 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 94
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 40 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 95
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 40 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 96
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 40 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 97
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 40 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 98
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 40 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 99
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 40 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 100
Training size: 438
Training size: 439
Training size: 440
Training size: 441
Training size: 442
Training on 40 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5

Fold [5/5] Epoch [10/100] Initial Loss: 0.1410, Training Loss: 0.0305, Initial Validation Loss: 0.1300, Validation Loss: 0.0307,V Acc: 0.8704, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.7188
Fold [5/5] Epoch [20/100] Initial Loss: 0.1410, Training Loss: 0.0184, Initial Validation Loss: 0.1300, Validation Loss: 0.0239,V Acc: 0.8426, Top 70th Acc: 0.9737, Bottom 30th Acc: 0.5312
Stopping early at Epoch (base 0): 28  Rolling back to Epoch (base 0): 23  Top Validation Acc: 0.9736842105263158
Running train_nn.py with seed 66
CUDA:False
Training samples count:  550
Training on 30 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1442, Training Loss: 0.1442, Initial Validation Loss: 0.1391, Validation Loss: 0.1391,V Acc: 0.2946, Top 70th Acc: 0.3797, Bottom 30th Acc: 0.0909
Fold [1/5] Epoch [10/100] Initial Loss: 0.1442, Training Loss: 0.0311, Initial Validation Loss: 0.1391, Validation Loss: 0.0294,V Acc: 0.9286, Top 70th Acc: 0.9494, Bottom 30th Acc: 0.8788
Fold [1/5] Epoch [20/100] Initial Loss: 0.1442, Training Loss: 0.0194, Initial Validation Loss: 0.1391, Validation Loss: 0.0242,V Acc: 0.9286, Top 70th Acc: 0.9494, Bottom 30th Acc: 0.8788
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.9493670886075949
Fold [2/5] Epoch [0/100] Initial Loss: 0.1397, Training Loss: 0.1397, Initial Validation Loss: 0.1353, Validation Loss: 0.1353,V Acc: 0.2523, Top 70th Acc: 0.3077, Bottom 30th Acc: 0.1212
Fold [2/5] Epoch [10/100] Initial Loss: 0.1397, Training Loss: 0.0287, Initial Validation Loss: 0.1353, Validation Loss: 0.0371,V Acc: 0.8288, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.5455
Fold [2/5] Epoch [20/100] Initial Loss: 0.1397, Training Loss: 0.0171, Initial Validation Loss: 0.1353, Validation Loss: 0.0314,V Acc: 0.8198, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.4848
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.9487179487179487
66 1 [array([0.69360286, 0.05659683, 0.06159564, 0.12124659, 0.0669581 ],
      dtype=float32)]
Fold [3/5] Epoch [0/100] Initial Loss: 0.1369, Training Loss: 0.1369, Initial Validation Loss: 0.1274, Validation Loss: 0.1274,V Acc: 0.4182, Top 70th Acc: 0.4935, Bottom 30th Acc: 0.2424
Fold [3/5] Epoch [10/100] Initial Loss: 0.1369, Training Loss: 0.0326, Initial Validation Loss: 0.1274, Validation Loss: 0.0372,V Acc: 0.8364, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.5455
Fold [3/5] Epoch [20/100] Initial Loss: 0.1369, Training Loss: 0.0174, Initial Validation Loss: 0.1274, Validation Loss: 0.0335,V Acc: 0.8091, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.4545
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.974025974025974
Fold [4/5] Epoch [0/100] Initial Loss: 0.1383, Training Loss: 0.1383, Initial Validation Loss: 0.1322, Validation Loss: 0.1322,V Acc: 0.3670, Top 70th Acc: 0.4675, Bottom 30th Acc: 0.1250
Fold [4/5] Epoch [10/100] Initial Loss: 0.1383, Training Loss: 0.0378, Initial Validation Loss: 0.1322, Validation Loss: 0.0439,V Acc: 0.7890, Top 70th Acc: 0.8701, Bottom 30th Acc: 0.5938
Fold [4/5] Epoch [20/100] Initial Loss: 0.1383, Training Loss: 0.0197, Initial Validation Loss: 0.1322, Validation Loss: 0.0350,V Acc: 0.7982, Top 70th Acc: 0.8961, Bottom 30th Acc: 0.5625
Stopping early at Epoch (base 0): 27  Rolling back to Epoch (base 0): 22  Top Validation Acc: 0.9090909090909091
Fold [5/5] Epoch [0/100] Initial Loss: 0.1380, Training Loss: 0.1380, Initial Validation Loss: 0.1314, Validation Loss: 0.1314,V Acc: 0.2500, Top 70th Acc: 0.3553, Bottom 30th Acc: 0.0000
Fold [5/5] Epoch [10/100] Initial Loss: 0.1380, Training Loss: 0.0455, Initial Validation Loss: 0.1314, Validation Loss: 0.0587,V Acc: 0.7130, Top 70th Acc: 0.8421, Bottom 30th Acc: 0.4062
Fold [5/5] Epoch [20/100] Initial Loss: 0.1380, Training Loss: 0.0183, Initial Validation Loss: 0.1314, Validation Loss: 0.0407,V Acc: 0.7870, Top 70th Acc: 0.9211, Bottom 30th Acc: 0.4688
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.9342105263157895
Running train_nn.py with seed 67
CUDA:False
Training samples count:  550
Training on 30 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1369, Training Loss: 0.1369, Initial Validation Loss: 0.1343, Validation Loss: 0.1343,V Acc: 0.3839, Top 70th Acc: 0.4684, Bottom 30th Acc: 0.1818
Fold [1/5] Epoch [10/100] Initial Loss: 0.1369, Training Loss: 0.0378, Initial Validation Loss: 0.1343, Validation Loss: 0.0468,V Acc: 0.7946, Top 70th Acc: 0.8481, Bottom 30th Acc: 0.6667
Fold [1/5] Epoch [20/100] Initial Loss: 0.1369, Training Loss: 0.0202, Initial Validation Loss: 0.1343, Validation Loss: 0.0323,V Acc: 0.8393, Top 70th Acc: 0.9241, Bottom 30th Acc: 0.6364
Fold [1/5] Epoch [30/100] Initial Loss: 0.1369, Training Loss: 0.0168, Initial Validation Loss: 0.1343, Validation Loss: 0.0305,V Acc: 0.8304, Top 70th Acc: 0.9367, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 35  Rolling back to Epoch (base 0): 30  Top Validation Acc: 0.9240506329113924
Fold [2/5] Epoch [0/100] Initial Loss: 0.1400, Training Loss: 0.1400, Initial Validation Loss: 0.1338, Validation Loss: 0.1338,V Acc: 0.2883, Top 70th Acc: 0.3333, Bottom 30th Acc: 0.1818
Fold [2/5] Epoch [10/100] Initial Loss: 0.1400, Training Loss: 0.0370, Initial Validation Loss: 0.1338, Validation Loss: 0.0424,V Acc: 0.7838, Top 70th Acc: 0.8974, Bottom 30th Acc: 0.5152
Fold [2/5] Epoch [20/100] Initial Loss: 0.1400, Training Loss: 0.0190, Initial Validation Loss: 0.1338, Validation Loss: 0.0352,V Acc: 0.8018, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.5455
Fold [2/5] Epoch [30/100] Initial Loss: 0.1400, Training Loss: 0.0153, Initial Validation Loss: 0.1338, Validation Loss: 0.0335,V Acc: 0.8198, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 35  Rolling back to Epoch (base 0): 30  Top Validation Acc: 0.9102564102564102
Fold [3/5] Epoch [0/100] Initial Loss: 0.1382, Training Loss: 0.1382, Initial Validation Loss: 0.1367, Validation Loss: 0.1367,V Acc: 0.2727, Top 70th Acc: 0.3506, Bottom 30th Acc: 0.0909
Fold [3/5] Epoch [10/100] Initial Loss: 0.1382, Training Loss: 0.0368, Initial Validation Loss: 0.1367, Validation Loss: 0.0413,V Acc: 0.8273, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.5152
Fold [3/5] Epoch [20/100] Initial Loss: 0.1382, Training Loss: 0.0205, Initial Validation Loss: 0.1367, Validation Loss: 0.0303,V Acc: 0.8545, Top 70th Acc: 0.9870, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 28  Rolling back to Epoch (base 0): 23  Top Validation Acc: 0.974025974025974
Fold [4/5] Epoch [0/100] Initial Loss: 0.1435, Training Loss: 0.1435, Initial Validation Loss: 0.1317, Validation Loss: 0.1317,V Acc: 0.3028, Top 70th Acc: 0.3766, Bottom 30th Acc: 0.1250
Fold [4/5] Epoch [10/100] Initial Loss: 0.1435, Training Loss: 0.0351, Initial Validation Loss: 0.1317, Validation Loss: 0.0425,V Acc: 0.7890, Top 70th Acc: 0.8701, Bottom 30th Acc: 0.5938
Fold [4/5] Epoch [20/100] Initial Loss: 0.1435, Training Loss: 0.0182, Initial Validation Loss: 0.1317, Validation Loss: 0.0358,V Acc: 0.8257, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.5938
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.922077922077922
67 3 [array([0.67969656, 0.04441243, 0.05858399, 0.04987236, 0.1674347 ],
      dtype=float32)]
Fold [5/5] Epoch [0/100] Initial Loss: 0.1408, Training Loss: 0.1408, Initial Validation Loss: 0.1308, Validation Loss: 0.1308,V Acc: 0.3611, Top 70th Acc: 0.3947, Bottom 30th Acc: 0.2812
Fold [5/5] Epoch [10/100] Initial Loss: 0.1408, Training Loss: 0.0504, Initial Validation Loss: 0.1308, Validation Loss: 0.0535,V Acc: 0.7778, Top 70th Acc: 0.8289, Bottom 30th Acc: 0.6562
Fold [5/5] Epoch [20/100] Initial Loss: 0.1408, Training Loss: 0.0220, Initial Validation Loss: 0.1308, Validation Loss: 0.0317,V Acc: 0.8426, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.5938
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.9210526315789473
Running train_nn.py with seed 68
CUDA:False
Training samples count:  550
Training on 30 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1353, Training Loss: 0.1353, Initial Validation Loss: 0.1311, Validation Loss: 0.1311,V Acc: 0.3571, Top 70th Acc: 0.4177, Bottom 30th Acc: 0.2121
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.961038961038961
Fold [4/5] Epoch [0/100] Initial Loss: 0.1320, Training Loss: 0.1320, Initial Validation Loss: 0.1193, Validation Loss: 0.1193,V Acc: 0.4862, Top 70th Acc: 0.6104, Bottom 30th Acc: 0.1875
Fold [4/5] Epoch [10/100] Initial Loss: 0.1320, Training Loss: 0.0230, Initial Validation Loss: 0.1193, Validation Loss: 0.0292,V Acc: 0.8624, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.6250
Fold [4/5] Epoch [20/100] Initial Loss: 0.1320, Training Loss: 0.0166, Initial Validation Loss: 0.1193, Validation Loss: 0.0257,V Acc: 0.8899, Top 70th Acc: 0.9870, Bottom 30th Acc: 0.6562
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.987012987012987
Fold [5/5] Epoch [0/100] Initial Loss: 0.1353, Training Loss: 0.1353, Initial Validation Loss: 0.1217, Validation Loss: 0.1217,V Acc: 0.4722, Top 70th Acc: 0.5395, Bottom 30th Acc: 0.3125
Fold [5/5] Epoch [10/100] Initial Loss: 0.1353, Training Loss: 0.0253, Initial Validation Loss: 0.1217, Validation Loss: 0.0220,V Acc: 0.8981, Top 70th Acc: 0.9868, Bottom 30th Acc: 0.6875
Stopping early at Epoch (base 0): 18  Rolling back to Epoch (base 0): 13  Top Validation Acc: 0.9868421052631579
92 4 [array([0.77349967, 0.02217911, 0.05027948, 0.07592151, 0.07812022],
      dtype=float32)]
Running train_nn.py with seed 93
CUDA:False
Training samples count:  550
Training on 21 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1407, Training Loss: 0.1407, Initial Validation Loss: 0.1333, Validation Loss: 0.1333,V Acc: 0.4911, Top 70th Acc: 0.5696, Bottom 30th Acc: 0.3030
Fold [1/5] Epoch [10/100] Initial Loss: 0.1407, Training Loss: 0.0290, Initial Validation Loss: 0.1333, Validation Loss: 0.0310,V Acc: 0.8750, Top 70th Acc: 0.9620, Bottom 30th Acc: 0.6667
Fold [1/5] Epoch [20/100] Initial Loss: 0.1407, Training Loss: 0.0172, Initial Validation Loss: 0.1333, Validation Loss: 0.0251,V Acc: 0.8929, Top 70th Acc: 0.9747, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 22  Rolling back to Epoch (base 0): 17  Top Validation Acc: 0.9873417721518988
Fold [2/5] Epoch [0/100] Initial Loss: 0.1416, Training Loss: 0.1416, Initial Validation Loss: 0.1298, Validation Loss: 0.1298,V Acc: 0.3514, Top 70th Acc: 0.4359, Bottom 30th Acc: 0.1515
Fold [2/5] Epoch [10/100] Initial Loss: 0.1416, Training Loss: 0.0251, Initial Validation Loss: 0.1298, Validation Loss: 0.0258,V Acc: 0.8919, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.7576
Fold [2/5] Epoch [20/100] Initial Loss: 0.1416, Training Loss: 0.0173, Initial Validation Loss: 0.1298, Validation Loss: 0.0249,V Acc: 0.8378, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 20  Rolling back to Epoch (base 0): 15  Top Validation Acc: 0.9615384615384616
Fold [3/5] Epoch [0/100] Initial Loss: 0.1362, Training Loss: 0.1362, Initial Validation Loss: 0.1306, Validation Loss: 0.1306,V Acc: 0.3000, Top 70th Acc: 0.3766, Bottom 30th Acc: 0.1212
Fold [3/5] Epoch [10/100] Initial Loss: 0.1362, Training Loss: 0.0222, Initial Validation Loss: 0.1306, Validation Loss: 0.0250,V Acc: 0.8727, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 18  Rolling back to Epoch (base 0): 13  Top Validation Acc: 0.987012987012987
93 2 [array([0.72917247, 0.02028108, 0.03394631, 0.08545066, 0.1311495 ],
      dtype=float32)]
Fold [4/5] Epoch [0/100] Initial Loss: 0.1296, Training Loss: 0.1296, Initial Validation Loss: 0.1099, Validation Loss: 0.1099,V Acc: 0.5596, Top 70th Acc: 0.7143, Bottom 30th Acc: 0.1875
Fold [4/5] Epoch [10/100] Initial Loss: 0.1296, Training Loss: 0.0239, Initial Validation Loss: 0.1099, Validation Loss: 0.0296,V Acc: 0.8716, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.7500
Fold [4/5] Epoch [20/100] Initial Loss: 0.1296, Training Loss: 0.0165, Initial Validation Loss: 0.1099, Validation Loss: 0.0315,V Acc: 0.8349, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.5938
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.922077922077922
Fold [5/5] Epoch [0/100] Initial Loss: 0.1363, Training Loss: 0.1363, Initial Validation Loss: 0.1175, Validation Loss: 0.1175,V Acc: 0.3796, Top 70th Acc: 0.4737, Bottom 30th Acc: 0.1562
Fold [5/5] Epoch [10/100] Initial Loss: 0.1363, Training Loss: 0.0234, Initial Validation Loss: 0.1175, Validation Loss: 0.0322,V Acc: 0.8611, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.6562
Stopping early at Epoch (base 0): 18  Rolling back to Epoch (base 0): 13  Top Validation Acc: 0.9736842105263158
Running train_nn.py with seed 94
CUDA:False
Training samples count:  550
Training on 21 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1310, Training Loss: 0.1310, Initial Validation Loss: 0.1241, Validation Loss: 0.1241,V Acc: 0.4018, Top 70th Acc: 0.4430, Bottom 30th Acc: 0.3030
Fold [1/5] Epoch [10/100] Initial Loss: 0.1310, Training Loss: 0.0210, Initial Validation Loss: 0.1241, Validation Loss: 0.0263,V Acc: 0.8929, Top 70th Acc: 0.9494, Bottom 30th Acc: 0.7576
Fold [1/5] Epoch [20/100] Initial Loss: 0.1310, Training Loss: 0.0152, Initial Validation Loss: 0.1241, Validation Loss: 0.0297,V Acc: 0.8304, Top 70th Acc: 0.9367, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 21  Rolling back to Epoch (base 0): 16  Top Validation Acc: 0.9746835443037974
Fold [2/5] Epoch [0/100] Initial Loss: 0.1338, Training Loss: 0.1338, Initial Validation Loss: 0.1197, Validation Loss: 0.1197,V Acc: 0.4865, Top 70th Acc: 0.6026, Bottom 30th Acc: 0.2121
Fold [2/5] Epoch [10/100] Initial Loss: 0.1338, Training Loss: 0.0229, Initial Validation Loss: 0.1197, Validation Loss: 0.0234,V Acc: 0.8829, Top 70th Acc: 0.9872, Bottom 30th Acc: 0.6364
Fold [2/5] Epoch [20/100] Initial Loss: 0.1338, Training Loss: 0.0152, Initial Validation Loss: 0.1197, Validation Loss: 0.0238,V Acc: 0.8829, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 21  Rolling back to Epoch (base 0): 16  Top Validation Acc: 0.9871794871794872
Fold [3/5] Epoch [0/100] Initial Loss: 0.1357, Training Loss: 0.1357, Initial Validation Loss: 0.1218, Validation Loss: 0.1218,V Acc: 0.5000, Top 70th Acc: 0.5195, Bottom 30th Acc: 0.4545
Fold [3/5] Epoch [10/100] Initial Loss: 0.1357, Training Loss: 0.0236, Initial Validation Loss: 0.1218, Validation Loss: 0.0229,V Acc: 0.9273, Top 70th Acc: 0.9870, Bottom 30th Acc: 0.7879
Stopping early at Epoch (base 0): 15  Rolling back to Epoch (base 0): 10  Top Validation Acc: 0.974025974025974
Fold [4/5] Epoch [0/100] Initial Loss: 0.1383, Training Loss: 0.1383, Initial Validation Loss: 0.1206, Validation Loss: 0.1206,V Acc: 0.4037, Top 70th Acc: 0.3896, Bottom 30th Acc: 0.4375
Fold [4/5] Epoch [10/100] Initial Loss: 0.1383, Training Loss: 0.0216, Initial Validation Loss: 0.1206, Validation Loss: 0.0340,V Acc: 0.8624, Top 70th Acc: 0.8961, Bottom 30th Acc: 0.7812
Fold [4/5] Epoch [20/100] Initial Loss: 0.1383, Training Loss: 0.0146, Initial Validation Loss: 0.1206, Validation Loss: 0.0309,V Acc: 0.8440, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.6250
Stopping early at Epoch (base 0): 21  Rolling back to Epoch (base 0): 16  Top Validation Acc: 0.9090909090909091
Fold [5/5] Epoch [0/100] Initial Loss: 0.1367, Training Loss: 0.1367, Initial Validation Loss: 0.1260, Validation Loss: 0.1260,V Acc: 0.4722, Top 70th Acc: 0.5526, Bottom 30th Acc: 0.2812
Fold [5/5] Epoch [10/100] Initial Loss: 0.1367, Training Loss: 0.0242, Initial Validation Loss: 0.1260, Validation Loss: 0.0261,V Acc: 0.8796, Top 70th Acc: 0.9737, Bottom 30th Acc: 0.6562
Stopping early at Epoch (base 0): 14  Rolling back to Epoch (base 0): 9  Top Validation Acc: 0.9605263157894737
94 4 [array([0.7038018 , 0.02492234, 0.07302475, 0.10440822, 0.09384288],
      dtype=float32)]
Running train_nn.py with seed 95
CUDA:False
Training samples count:  550
Training on 21 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1389, Training Loss: 0.1389, Initial Validation Loss: 0.1249, Validation Loss: 0.1249,V Acc: 0.4821, Top 70th Acc: 0.5823, Bottom 30th Acc: 0.2424
Fold [1/5] Epoch [10/100] Initial Loss: 0.1389, Training Loss: 0.0206, Initial Validation Loss: 0.1249, Validation Loss: 0.0433,V Acc: 0.8036, Top 70th Acc: 0.8861, Bottom 30th Acc: 0.6061
Fold [5/5] Epoch [20/100] Initial Loss: 0.1363, Training Loss: 0.0134, Initial Validation Loss: 0.1310, Validation Loss: 0.0264,V Acc: 0.8889, Top 70th Acc: 0.9737, Bottom 30th Acc: 0.6875
Stopping early at Epoch (base 0): 20  Rolling back to Epoch (base 0): 15  Top Validation Acc: 0.9736842105263158
69 4 [array([0.5102599 , 0.06852625, 0.07780597, 0.10354226, 0.23986566],
      dtype=float32)]
Running train_nn.py with seed 70
CUDA:False
Training samples count:  550
Training on 40 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1403, Training Loss: 0.1403, Initial Validation Loss: 0.1323, Validation Loss: 0.1323,V Acc: 0.2679, Top 70th Acc: 0.3165, Bottom 30th Acc: 0.1515
Fold [1/5] Epoch [10/100] Initial Loss: 0.1403, Training Loss: 0.0318, Initial Validation Loss: 0.1323, Validation Loss: 0.0387,V Acc: 0.8304, Top 70th Acc: 0.9241, Bottom 30th Acc: 0.6061
Fold [1/5] Epoch [20/100] Initial Loss: 0.1403, Training Loss: 0.0141, Initial Validation Loss: 0.1323, Validation Loss: 0.0295,V Acc: 0.8304, Top 70th Acc: 0.9494, Bottom 30th Acc: 0.5455
Fold [1/5] Epoch [30/100] Initial Loss: 0.1403, Training Loss: 0.0113, Initial Validation Loss: 0.1323, Validation Loss: 0.0283,V Acc: 0.8125, Top 70th Acc: 0.9747, Bottom 30th Acc: 0.4242
Stopping early at Epoch (base 0): 34  Rolling back to Epoch (base 0): 29  Top Validation Acc: 0.9620253164556962
70 0 [array([0.33483574, 0.06805289, 0.10491236, 0.07174739, 0.42045158],
      dtype=float32)]
Fold [2/5] Epoch [0/100] Initial Loss: 0.1426, Training Loss: 0.1426, Initial Validation Loss: 0.1355, Validation Loss: 0.1355,V Acc: 0.2613, Top 70th Acc: 0.3077, Bottom 30th Acc: 0.1515
Fold [2/5] Epoch [10/100] Initial Loss: 0.1426, Training Loss: 0.0245, Initial Validation Loss: 0.1355, Validation Loss: 0.0331,V Acc: 0.8378, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.5758
Fold [2/5] Epoch [20/100] Initial Loss: 0.1426, Training Loss: 0.0127, Initial Validation Loss: 0.1355, Validation Loss: 0.0288,V Acc: 0.8468, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.6061
Fold [2/5] Epoch [30/100] Initial Loss: 0.1426, Training Loss: 0.0108, Initial Validation Loss: 0.1355, Validation Loss: 0.0279,V Acc: 0.8559, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 39  Rolling back to Epoch (base 0): 34  Top Validation Acc: 0.9615384615384616
Fold [3/5] Epoch [0/100] Initial Loss: 0.1384, Training Loss: 0.1384, Initial Validation Loss: 0.1372, Validation Loss: 0.1372,V Acc: 0.2545, Top 70th Acc: 0.3506, Bottom 30th Acc: 0.0303
Fold [3/5] Epoch [10/100] Initial Loss: 0.1384, Training Loss: 0.0285, Initial Validation Loss: 0.1372, Validation Loss: 0.0334,V Acc: 0.8636, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.6364
Fold [3/5] Epoch [20/100] Initial Loss: 0.1384, Training Loss: 0.0147, Initial Validation Loss: 0.1372, Validation Loss: 0.0260,V Acc: 0.8818, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.7273
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.974025974025974
Fold [4/5] Epoch [0/100] Initial Loss: 0.1385, Training Loss: 0.1385, Initial Validation Loss: 0.1349, Validation Loss: 0.1349,V Acc: 0.3578, Top 70th Acc: 0.4416, Bottom 30th Acc: 0.1562
Fold [4/5] Epoch [10/100] Initial Loss: 0.1385, Training Loss: 0.0270, Initial Validation Loss: 0.1349, Validation Loss: 0.0295,V Acc: 0.8991, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.7188
Fold [4/5] Epoch [20/100] Initial Loss: 0.1385, Training Loss: 0.0156, Initial Validation Loss: 0.1349, Validation Loss: 0.0227,V Acc: 0.8899, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.6875
Fold [4/5] Epoch [30/100] Initial Loss: 0.1385, Training Loss: 0.0133, Initial Validation Loss: 0.1349, Validation Loss: 0.0208,V Acc: 0.8899, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.6875
Stopping early at Epoch (base 0): 35  Rolling back to Epoch (base 0): 30  Top Validation Acc: 0.974025974025974
Fold [5/5] Epoch [0/100] Initial Loss: 0.1401, Training Loss: 0.1401, Initial Validation Loss: 0.1312, Validation Loss: 0.1312,V Acc: 0.2500, Top 70th Acc: 0.2632, Bottom 30th Acc: 0.2188
Fold [5/5] Epoch [10/100] Initial Loss: 0.1401, Training Loss: 0.0411, Initial Validation Loss: 0.1312, Validation Loss: 0.0467,V Acc: 0.7870, Top 70th Acc: 0.8816, Bottom 30th Acc: 0.5625
Fold [5/5] Epoch [20/100] Initial Loss: 0.1401, Training Loss: 0.0161, Initial Validation Loss: 0.1312, Validation Loss: 0.0267,V Acc: 0.8611, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.6562
Fold [5/5] Epoch [30/100] Initial Loss: 0.1401, Training Loss: 0.0126, Initial Validation Loss: 0.1312, Validation Loss: 0.0259,V Acc: 0.8519, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.5938
Stopping early at Epoch (base 0): 30  Rolling back to Epoch (base 0): 25  Top Validation Acc: 0.9605263157894737
Running train_nn.py with seed 71
CUDA:False
Training samples count:  550
Training on 40 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1414, Training Loss: 0.1414, Initial Validation Loss: 0.1380, Validation Loss: 0.1380,V Acc: 0.2679, Top 70th Acc: 0.2658, Bottom 30th Acc: 0.2727
Fold [1/5] Epoch [10/100] Initial Loss: 0.1414, Training Loss: 0.0403, Initial Validation Loss: 0.1380, Validation Loss: 0.0469,V Acc: 0.8036, Top 70th Acc: 0.8861, Bottom 30th Acc: 0.6061
Fold [1/5] Epoch [20/100] Initial Loss: 0.1414, Training Loss: 0.0157, Initial Validation Loss: 0.1380, Validation Loss: 0.0260,V Acc: 0.8929, Top 70th Acc: 0.9367, Bottom 30th Acc: 0.7879
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.9367088607594937
Fold [2/5] Epoch [0/100] Initial Loss: 0.1390, Training Loss: 0.1390, Initial Validation Loss: 0.1335, Validation Loss: 0.1335,V Acc: 0.2793, Top 70th Acc: 0.3462, Bottom 30th Acc: 0.1212
Fold [2/5] Epoch [10/100] Initial Loss: 0.1390, Training Loss: 0.0291, Initial Validation Loss: 0.1335, Validation Loss: 0.0381,V Acc: 0.8018, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.5152
Fold [2/5] Epoch [20/100] Initial Loss: 0.1390, Training Loss: 0.0145, Initial Validation Loss: 0.1335, Validation Loss: 0.0316,V Acc: 0.8829, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.7273
Fold [2/5] Epoch [30/100] Initial Loss: 0.1390, Training Loss: 0.0120, Initial Validation Loss: 0.1335, Validation Loss: 0.0307,V Acc: 0.8559, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 30  Rolling back to Epoch (base 0): 25  Top Validation Acc: 0.9615384615384616
Fold [3/5] Epoch [0/100] Initial Loss: 0.1394, Training Loss: 0.1394, Initial Validation Loss: 0.1279, Validation Loss: 0.1279,V Acc: 0.4545, Top 70th Acc: 0.4805, Bottom 30th Acc: 0.3939
Fold [3/5] Epoch [10/100] Initial Loss: 0.1394, Training Loss: 0.0277, Initial Validation Loss: 0.1279, Validation Loss: 0.0315,V Acc: 0.8273, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.5758
Fold [3/5] Epoch [20/100] Initial Loss: 0.1394, Training Loss: 0.0134, Initial Validation Loss: 0.1279, Validation Loss: 0.0264,V Acc: 0.8727, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.935064935064935
71 2 [array([0.62937254, 0.06524312, 0.06845792, 0.08170167, 0.15522474],
      dtype=float32)]
Fold [4/5] Epoch [0/100] Initial Loss: 0.1389, Training Loss: 0.1389, Initial Validation Loss: 0.1393, Validation Loss: 0.1393,V Acc: 0.2477, Top 70th Acc: 0.3377, Bottom 30th Acc: 0.0312
Fold [4/5] Epoch [10/100] Initial Loss: 0.1389, Training Loss: 0.0347, Initial Validation Loss: 0.1393, Validation Loss: 0.0379,V Acc: 0.8349, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.5625
Fold [4/5] Epoch [20/100] Initial Loss: 0.1389, Training Loss: 0.0178, Initial Validation Loss: 0.1393, Validation Loss: 0.0285,V Acc: 0.8899, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.7188
Fold [4/5] Epoch [30/100] Initial Loss: 0.1389, Training Loss: 0.0130, Initial Validation Loss: 0.1393, Validation Loss: 0.0253,V Acc: 0.8991, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.7500
Fold [4/5] Epoch [40/100] Initial Loss: 0.1389, Training Loss: 0.0115, Initial Validation Loss: 0.1393, Validation Loss: 0.0246,V Acc: 0.9083, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.8125
Fold [4/5] Epoch [50/100] Initial Loss: 0.1389, Training Loss: 0.0107, Initial Validation Loss: 0.1393, Validation Loss: 0.0245,V Acc: 0.9083, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.8125  Top Validation Acc: 0.9620253164556962
52 0 [array([0.3911659 , 0.03096389, 0.04939225, 0.28618655, 0.2422913 ],
      dtype=float32)]
Fold [2/5] Epoch [0/100] Initial Loss: 0.1399, Training Loss: 0.1399, Initial Validation Loss: 0.1345, Validation Loss: 0.1345,V Acc: 0.2523, Top 70th Acc: 0.3333, Bottom 30th Acc: 0.0606
Fold [2/5] Epoch [10/100] Initial Loss: 0.1399, Training Loss: 0.0292, Initial Validation Loss: 0.1345, Validation Loss: 0.0413,V Acc: 0.7568, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.3636
Fold [2/5] Epoch [20/100] Initial Loss: 0.1399, Training Loss: 0.0079, Initial Validation Loss: 0.1345, Validation Loss: 0.0319,V Acc: 0.8198, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.5455
Fold [2/5] Epoch [30/100] Initial Loss: 0.1399, Training Loss: 0.0053, Initial Validation Loss: 0.1345, Validation Loss: 0.0311,V Acc: 0.8468, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 37  Rolling back to Epoch (base 0): 32  Top Validation Acc: 0.9487179487179487
Fold [3/5] Epoch [0/100] Initial Loss: 0.1425, Training Loss: 0.1425, Initial Validation Loss: 0.1353, Validation Loss: 0.1353,V Acc: 0.2273, Top 70th Acc: 0.2208, Bottom 30th Acc: 0.2424
Fold [3/5] Epoch [10/100] Initial Loss: 0.1425, Training Loss: 0.0145, Initial Validation Loss: 0.1353, Validation Loss: 0.0393,V Acc: 0.8000, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.5152
Fold [3/5] Epoch [20/100] Initial Loss: 0.1425, Training Loss: 0.0049, Initial Validation Loss: 0.1353, Validation Loss: 0.0356,V Acc: 0.8455, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 27  Rolling back to Epoch (base 0): 22  Top Validation Acc: 0.922077922077922
Fold [4/5] Epoch [0/100] Initial Loss: 0.1401, Training Loss: 0.1401, Initial Validation Loss: 0.1337, Validation Loss: 0.1337,V Acc: 0.3394, Top 70th Acc: 0.3506, Bottom 30th Acc: 0.3125
Fold [4/5] Epoch [10/100] Initial Loss: 0.1401, Training Loss: 0.0115, Initial Validation Loss: 0.1337, Validation Loss: 0.0390,V Acc: 0.8349, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.5938
Fold [4/5] Epoch [20/100] Initial Loss: 0.1401, Training Loss: 0.0041, Initial Validation Loss: 0.1337, Validation Loss: 0.0350,V Acc: 0.8257, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.5312
Stopping early at Epoch (base 0): 28  Rolling back to Epoch (base 0): 23  Top Validation Acc: 0.948051948051948
Fold [5/5] Epoch [0/100] Initial Loss: 0.1382, Training Loss: 0.1382, Initial Validation Loss: 0.1331, Validation Loss: 0.1331,V Acc: 0.2778, Top 70th Acc: 0.3289, Bottom 30th Acc: 0.1562
Fold [5/5] Epoch [10/100] Initial Loss: 0.1382, Training Loss: 0.0181, Initial Validation Loss: 0.1331, Validation Loss: 0.0367,V Acc: 0.8148, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.4688
Fold [5/5] Epoch [20/100] Initial Loss: 0.1382, Training Loss: 0.0049, Initial Validation Loss: 0.1331, Validation Loss: 0.0297,V Acc: 0.8611, Top 70th Acc: 0.9737, Bottom 30th Acc: 0.5938
Stopping early at Epoch (base 0): 29  Rolling back to Epoch (base 0): 24  Top Validation Acc: 0.9736842105263158
Running train_nn.py with seed 53
CUDA:False
Training samples count:  550
Training on 162 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1387, Training Loss: 0.1387, Initial Validation Loss: 0.1361, Validation Loss: 0.1361,V Acc: 0.2679, Top 70th Acc: 0.3418, Bottom 30th Acc: 0.0909
Fold [1/5] Epoch [10/100] Initial Loss: 0.1387, Training Loss: 0.0171, Initial Validation Loss: 0.1361, Validation Loss: 0.0391,V Acc: 0.8393, Top 70th Acc: 0.9367, Bottom 30th Acc: 0.6061
Fold [1/5] Epoch [20/100] Initial Loss: 0.1387, Training Loss: 0.0046, Initial Validation Loss: 0.1361, Validation Loss: 0.0342,V Acc: 0.8214, Top 70th Acc: 0.9367, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 21  Rolling back to Epoch (base 0): 16  Top Validation Acc: 0.9367088607594937
53 0 [array([0.09844989, 0.05535817, 0.07951012, 0.18132807, 0.5853538 ],
      dtype=float32)]
Fold [2/5] Epoch [0/100] Initial Loss: 0.1419, Training Loss: 0.1419, Initial Validation Loss: 0.1344, Validation Loss: 0.1344,V Acc: 0.2523, Top 70th Acc: 0.2692, Bottom 30th Acc: 0.2121
Fold [2/5] Epoch [10/100] Initial Loss: 0.1419, Training Loss: 0.0149, Initial Validation Loss: 0.1344, Validation Loss: 0.0356,V Acc: 0.8288, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.6061
Fold [2/5] Epoch [20/100] Initial Loss: 0.1419, Training Loss: 0.0045, Initial Validation Loss: 0.1344, Validation Loss: 0.0338,V Acc: 0.8198, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 28  Rolling back to Epoch (base 0): 23  Top Validation Acc: 0.9358974358974359
Fold [3/5] Epoch [0/100] Initial Loss: 0.1381, Training Loss: 0.1381, Initial Validation Loss: 0.1337, Validation Loss: 0.1337,V Acc: 0.3273, Top 70th Acc: 0.4026, Bottom 30th Acc: 0.1515
Fold [3/5] Epoch [10/100] Initial Loss: 0.1381, Training Loss: 0.0184, Initial Validation Loss: 0.1337, Validation Loss: 0.0319,V Acc: 0.8909, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.7273
Fold [3/5] Epoch [20/100] Initial Loss: 0.1381, Training Loss: 0.0053, Initial Validation Loss: 0.1337, Validation Loss: 0.0271,V Acc: 0.8727, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.6667
Fold [3/5] Epoch [30/100] Initial Loss: 0.1381, Training Loss: 0.0042, Initial Validation Loss: 0.1337, Validation Loss: 0.0264,V Acc: 0.8727, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 35  Rolling back to Epoch (base 0): 30  Top Validation Acc: 0.974025974025974
Fold [4/5] Epoch [0/100] Initial Loss: 0.1407, Training Loss: 0.1407, Initial Validation Loss: 0.1348, Validation Loss: 0.1348,V Acc: 0.3119, Top 70th Acc: 0.3506, Bottom 30th Acc: 0.2188
Fold [4/5] Epoch [10/100] Initial Loss: 0.1407, Training Loss: 0.0128, Initial Validation Loss: 0.1348, Validation Loss: 0.0316,V Acc: 0.8257, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.5000
Fold [4/5] Epoch [20/100] Initial Loss: 0.1407, Training Loss: 0.0048, Initial Validation Loss: 0.1348, Validation Loss: 0.0274,V Acc: 0.8257, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.4688
Fold [4/5] Epoch [30/100] Initial Loss: 0.1407, Training Loss: 0.0038, Initial Validation Loss: 0.1348, Validation Loss: 0.0271,V Acc: 0.8257, Top 70th Acc: 0.9870, Bottom 30th Acc: 0.4375
Stopping early at Epoch (base 0): 36  Rolling back to Epoch (base 0): 31  Top Validation Acc: 0.987012987012987
Fold [5/5] Epoch [0/100] Initial Loss: 0.1401, Training Loss: 0.1401, Initial Validation Loss: 0.1296, Validation Loss: 0.1296,V Acc: 0.2778, Top 70th Acc: 0.3158, Bottom 30th Acc: 0.1875
Fold [5/5] Epoch [10/100] Initial Loss: 0.1401, Training Loss: 0.0178, Initial Validation Loss: 0.1296, Validation Loss: 0.0376,V Acc: 0.8426, Top 70th Acc: 0.8816, Bottom 30th Acc: 0.7500
Fold [5/5] Epoch [20/100] Initial Loss: 0.1401, Training Loss: 0.0050, Initial Validation Loss: 0.1296, Validation Loss: 0.0306,V Acc: 0.8241, Top 70th Acc: 0.9211, Bottom 30th Acc: 0.5938
Stopping early at Epoch (base 0): 28  Rolling back to Epoch (base 0): 23  Top Validation Acc: 0.9078947368421053
Running train_nn.py with seed 54
CUDA:False
Training samples count:  550
Training on 162 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1397, Training Loss: 0.1397, Initial Validation Loss: 0.1349, Validation Loss: 0.1349,V Acc: 0.2679, Top 70th Acc: 0.3038, Bottom 30th Acc: 0.1818
Fold [1/5] Epoch [10/100] Initial Loss: 0.1397, Training Loss: 0.0139, Initial Validation Loss: 0.1349, Validation Loss: 0.0267,V Acc: 0.8393, Top 70th Acc: 0.9494, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 19  Rolling back to Epoch (base 0): 14  Top Validation Acc: 0.9367088607594937
54 0 [array([0.23106225, 0.04373606, 0.13935338, 0.18940681, 0.39644152],
      dtype=float32)]
Fold [2/5] Epoch [0/100] Initial Loss: 0.1366, Training Loss: 0.1366, Initial Validation Loss: 0.1314, Validation Loss: 0.1314,V Acc: 0.3063, Top 70th Acc: 0.3718, Bottom 30th Acc: 0.1515
Fold [2/5] Epoch [10/100] Initial Loss: 0.1366, Training Loss: 0.0183, Initial Validation Loss: 0.1314, Validation Loss: 0.0347,V Acc: 0.8468, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.6061
Fold [2/5] Epoch [20/100] Initial Loss: 0.1366, Training Loss: 0.0051, Initial Validation Loss: 0.1314, Validation Loss: 0.0267,V Acc: 0.8829, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.6970
Fold [1/5] Epoch [20/100] Initial Loss: 0.1380, Training Loss: 0.0225, Initial Validation Loss: 0.1320, Validation Loss: 0.0368,V Acc: 0.8125, Top 70th Acc: 0.9367, Bottom 30th Acc: 0.5152
Stopping early at Epoch (base 0): 20  Rolling back to Epoch (base 0): 15  Top Validation Acc: 0.9367088607594937
68 0 [array([0.3536747 , 0.08194013, 0.17858239, 0.27204362, 0.11375913],
      dtype=float32)]
Fold [2/5] Epoch [0/100] Initial Loss: 0.1384, Training Loss: 0.1384, Initial Validation Loss: 0.1356, Validation Loss: 0.1356,V Acc: 0.3063, Top 70th Acc: 0.3974, Bottom 30th Acc: 0.0909
Fold [2/5] Epoch [10/100] Initial Loss: 0.1384, Training Loss: 0.0334, Initial Validation Loss: 0.1356, Validation Loss: 0.0389,V Acc: 0.8559, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.6667
Fold [2/5] Epoch [20/100] Initial Loss: 0.1384, Training Loss: 0.0235, Initial Validation Loss: 0.1356, Validation Loss: 0.0344,V Acc: 0.8288, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.9358974358974359
Fold [3/5] Epoch [0/100] Initial Loss: 0.1419, Training Loss: 0.1419, Initial Validation Loss: 0.1329, Validation Loss: 0.1329,V Acc: 0.3545, Top 70th Acc: 0.4156, Bottom 30th Acc: 0.2121
Fold [3/5] Epoch [10/100] Initial Loss: 0.1419, Training Loss: 0.0399, Initial Validation Loss: 0.1329, Validation Loss: 0.0447,V Acc: 0.7727, Top 70th Acc: 0.8571, Bottom 30th Acc: 0.5758
Fold [3/5] Epoch [20/100] Initial Loss: 0.1419, Training Loss: 0.0241, Initial Validation Loss: 0.1329, Validation Loss: 0.0332,V Acc: 0.8273, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.9090909090909091
Fold [4/5] Epoch [0/100] Initial Loss: 0.1405, Training Loss: 0.1405, Initial Validation Loss: 0.1284, Validation Loss: 0.1284,V Acc: 0.3394, Top 70th Acc: 0.3766, Bottom 30th Acc: 0.2500
Fold [4/5] Epoch [10/100] Initial Loss: 0.1405, Training Loss: 0.0321, Initial Validation Loss: 0.1284, Validation Loss: 0.0354,V Acc: 0.7798, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.4062
Stopping early at Epoch (base 0): 16  Rolling back to Epoch (base 0): 11  Top Validation Acc: 0.9090909090909091
Fold [5/5] Epoch [0/100] Initial Loss: 0.1391, Training Loss: 0.1391, Initial Validation Loss: 0.1352, Validation Loss: 0.1352,V Acc: 0.2963, Top 70th Acc: 0.3158, Bottom 30th Acc: 0.2500
Fold [5/5] Epoch [10/100] Initial Loss: 0.1391, Training Loss: 0.0319, Initial Validation Loss: 0.1352, Validation Loss: 0.0375,V Acc: 0.8148, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.5312
Stopping early at Epoch (base 0): 18  Rolling back to Epoch (base 0): 13  Top Validation Acc: 0.9342105263157895
Running train_nn.py with seed 69
CUDA:False
Training samples count:  550
Training on 20 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1426, Training Loss: 0.1426, Initial Validation Loss: 0.1386, Validation Loss: 0.1386,V Acc: 0.2500, Top 70th Acc: 0.2532, Bottom 30th Acc: 0.2424
Fold [1/5] Epoch [10/100] Initial Loss: 0.1426, Training Loss: 0.0389, Initial Validation Loss: 0.1386, Validation Loss: 0.0395,V Acc: 0.8125, Top 70th Acc: 0.9367, Bottom 30th Acc: 0.5152
Fold [1/5] Epoch [20/100] Initial Loss: 0.1426, Training Loss: 0.0256, Initial Validation Loss: 0.1386, Validation Loss: 0.0323,V Acc: 0.8393, Top 70th Acc: 0.9241, Bottom 30th Acc: 0.6364
Fold [1/5] Epoch [30/100] Initial Loss: 0.1426, Training Loss: 0.0223, Initial Validation Loss: 0.1386, Validation Loss: 0.0320,V Acc: 0.8482, Top 70th Acc: 0.9494, Bottom 30th Acc: 0.6061
Fold [1/5] Epoch [40/100] Initial Loss: 0.1426, Training Loss: 0.0202, Initial Validation Loss: 0.1386, Validation Loss: 0.0319,V Acc: 0.8482, Top 70th Acc: 0.9367, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 43  Rolling back to Epoch (base 0): 38  Top Validation Acc: 0.9367088607594937
Fold [2/5] Epoch [0/100] Initial Loss: 0.1373, Training Loss: 0.1373, Initial Validation Loss: 0.1291, Validation Loss: 0.1291,V Acc: 0.4144, Top 70th Acc: 0.4872, Bottom 30th Acc: 0.2424
Fold [2/5] Epoch [10/100] Initial Loss: 0.1373, Training Loss: 0.0342, Initial Validation Loss: 0.1291, Validation Loss: 0.0466,V Acc: 0.7748, Top 70th Acc: 0.8718, Bottom 30th Acc: 0.5455
Fold [2/5] Epoch [20/100] Initial Loss: 0.1373, Training Loss: 0.0211, Initial Validation Loss: 0.1291, Validation Loss: 0.0382,V Acc: 0.8108, Top 70th Acc: 0.8974, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.9102564102564102
Fold [3/5] Epoch [0/100] Initial Loss: 0.1410, Training Loss: 0.1410, Initial Validation Loss: 0.1315, Validation Loss: 0.1315,V Acc: 0.2909, Top 70th Acc: 0.3506, Bottom 30th Acc: 0.1515
Fold [3/5] Epoch [10/100] Initial Loss: 0.1410, Training Loss: 0.0442, Initial Validation Loss: 0.1315, Validation Loss: 0.0460,V Acc: 0.7818, Top 70th Acc: 0.8831, Bottom 30th Acc: 0.5455
Fold [3/5] Epoch [20/100] Initial Loss: 0.1410, Training Loss: 0.0272, Initial Validation Loss: 0.1315, Validation Loss: 0.0355,V Acc: 0.8273, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.5758
Fold [3/5] Epoch [30/100] Initial Loss: 0.1410, Training Loss: 0.0233, Initial Validation Loss: 0.1315, Validation Loss: 0.0321,V Acc: 0.8364, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 35  Rolling back to Epoch (base 0): 30  Top Validation Acc: 0.961038961038961
Fold [4/5] Epoch [0/100] Initial Loss: 0.1389, Training Loss: 0.1389, Initial Validation Loss: 0.1339, Validation Loss: 0.1339,V Acc: 0.3028, Top 70th Acc: 0.3377, Bottom 30th Acc: 0.2188
Fold [4/5] Epoch [10/100] Initial Loss: 0.1389, Training Loss: 0.0356, Initial Validation Loss: 0.1339, Validation Loss: 0.0383,V Acc: 0.8349, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.6250
Fold [4/5] Epoch [20/100] Initial Loss: 0.1389, Training Loss: 0.0238, Initial Validation Loss: 0.1339, Validation Loss: 0.0375,V Acc: 0.7982, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.5312
Stopping early at Epoch (base 0): 21  Rolling back to Epoch (base 0): 16  Top Validation Acc: 0.9090909090909091
Fold [5/5] Epoch [0/100] Initial Loss: 0.1401, Training Loss: 0.1401, Initial Validation Loss: 0.1323, Validation Loss: 0.1323,V Acc: 0.2870, Top 70th Acc: 0.3421, Bottom 30th Acc: 0.1562
Fold [5/5] Epoch [10/100] Initial Loss: 0.1401, Training Loss: 0.0347, Initial Validation Loss: 0.1323, Validation Loss: 0.0348,V Acc: 0.8796, Top 70th Acc: 0.9211, Bottom 30th Acc: 0.7812
Fold [5/5] Epoch [20/100] Initial Loss: 0.1401, Training Loss: 0.0247, Initial Validation Loss: 0.1323, Validation Loss: 0.0283,V Acc: 0.8981, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.7500
Fold [5/5] Epoch [30/100] Initial Loss: 0.1401, Training Loss: 0.0226, Initial Validation Loss: 0.1323, Validation Loss: 0.0275,V Acc: 0.8889, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.7500
Stopping early at Epoch (base 0): 33  Rolling back to Epoch (base 0): 28  Top Validation Acc: 0.9473684210526315
69 4 [array([0.49711955, 0.13625342, 0.07163237, 0.13244651, 0.16254824],
      dtype=float32)]
Running train_nn.py with seed 70
CUDA:False
Training samples count:  550
Training on 20 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1367, Training Loss: 0.1367, Initial Validation Loss: 0.1269, Validation Loss: 0.1269,V Acc: 0.3839, Top 70th Acc: 0.4684, Bottom 30th Acc: 0.1818
Fold [1/5] Epoch [10/100] Initial Loss: 0.1367, Training Loss: 0.0345, Initial Validation Loss: 0.1269, Validation Loss: 0.0386,V Acc: 0.8214, Top 70th Acc: 0.9114, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 19  Rolling back to Epoch (base 0): 14  Top Validation Acc: 0.8860759493670886
70 0 [array([0.4554677 , 0.09595054, 0.04308655, 0.25054923, 0.15494595],
      dtype=float32)]
Fold [2/5] Epoch [0/100] Initial Loss: 0.1369, Training Loss: 0.1369, Initial Validation Loss: 0.1302, Validation Loss: 0.1302,V Acc: 0.3694, Top 70th Acc: 0.4359, Bottom 30th Acc: 0.2121
Fold [2/5] Epoch [10/100] Initial Loss: 0.1369, Training Loss: 0.0318, Initial Validation Loss: 0.1302, Validation Loss: 0.0349,V Acc: 0.8468, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.6061
Fold [2/5] Epoch [20/100] Initial Loss: 0.1369, Training Loss: 0.0229, Initial Validation Loss: 0.1302, Validation Loss: 0.0323,V Acc: 0.8649, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.7273
Stopping early at Epoch (base 0): 30  Rolling back to Epoch (base 0): 25  Top Validation Acc: 0.7368421052631579
Running train_nn.py with seed 68
CUDA:False
Training samples count:  550
Training on 2 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1322, Training Loss: 0.1322, Initial Validation Loss: 0.1206, Validation Loss: 0.1206,V Acc: 0.5000, Top 70th Acc: 0.6076, Bottom 30th Acc: 0.2424
Fold [1/5] Epoch [10/100] Initial Loss: 0.1322, Training Loss: 0.0806, Initial Validation Loss: 0.1206, Validation Loss: 0.0789,V Acc: 0.6429, Top 70th Acc: 0.6962, Bottom 30th Acc: 0.5152
Fold [1/5] Epoch [20/100] Initial Loss: 0.1322, Training Loss: 0.0789, Initial Validation Loss: 0.1206, Validation Loss: 0.0791,V Acc: 0.6161, Top 70th Acc: 0.7215, Bottom 30th Acc: 0.3636
Stopping early at Epoch (base 0): 20  Rolling back to Epoch (base 0): 15  Top Validation Acc: 0.7215189873417721
68 0 [array([0.14753255, 0.34039503, 0.13095373, 0.20238282, 0.17873596],
      dtype=float32)]
Fold [2/5] Epoch [0/100] Initial Loss: 0.1307, Training Loss: 0.1307, Initial Validation Loss: 0.1239, Validation Loss: 0.1239,V Acc: 0.4955, Top 70th Acc: 0.5513, Bottom 30th Acc: 0.3636
Fold [2/5] Epoch [10/100] Initial Loss: 0.1307, Training Loss: 0.0782, Initial Validation Loss: 0.1239, Validation Loss: 0.0887,V Acc: 0.5405, Top 70th Acc: 0.6923, Bottom 30th Acc: 0.1818
Fold [2/5] Epoch [20/100] Initial Loss: 0.1307, Training Loss: 0.0761, Initial Validation Loss: 0.1239, Validation Loss: 0.0879,V Acc: 0.5495, Top 70th Acc: 0.6923, Bottom 30th Acc: 0.2121
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.6923076923076923
Fold [3/5] Epoch [0/100] Initial Loss: 0.1386, Training Loss: 0.1386, Initial Validation Loss: 0.1260, Validation Loss: 0.1260,V Acc: 0.3455, Top 70th Acc: 0.4675, Bottom 30th Acc: 0.0606
Fold [3/5] Epoch [10/100] Initial Loss: 0.1386, Training Loss: 0.0823, Initial Validation Loss: 0.1260, Validation Loss: 0.0764,V Acc: 0.6545, Top 70th Acc: 0.7403, Bottom 30th Acc: 0.4545
Fold [3/5] Epoch [20/100] Initial Loss: 0.1386, Training Loss: 0.0803, Initial Validation Loss: 0.1260, Validation Loss: 0.0745,V Acc: 0.6636, Top 70th Acc: 0.7532, Bottom 30th Acc: 0.4545
Stopping early at Epoch (base 0): 27  Rolling back to Epoch (base 0): 22  Top Validation Acc: 0.7792207792207793
Fold [4/5] Epoch [0/100] Initial Loss: 0.1387, Training Loss: 0.1387, Initial Validation Loss: 0.1255, Validation Loss: 0.1255,V Acc: 0.4404, Top 70th Acc: 0.5325, Bottom 30th Acc: 0.2188
Fold [4/5] Epoch [10/100] Initial Loss: 0.1387, Training Loss: 0.0823, Initial Validation Loss: 0.1255, Validation Loss: 0.0731,V Acc: 0.6697, Top 70th Acc: 0.8052, Bottom 30th Acc: 0.3438
Fold [4/5] Epoch [20/100] Initial Loss: 0.1387, Training Loss: 0.0803, Initial Validation Loss: 0.1255, Validation Loss: 0.0718,V Acc: 0.6514, Top 70th Acc: 0.7792, Bottom 30th Acc: 0.3438
Fold [4/5] Epoch [30/100] Initial Loss: 0.1387, Training Loss: 0.0785, Initial Validation Loss: 0.1255, Validation Loss: 0.0763,V Acc: 0.6055, Top 70th Acc: 0.7143, Bottom 30th Acc: 0.3438
Stopping early at Epoch (base 0): 34  Rolling back to Epoch (base 0): 29  Top Validation Acc: 0.7792207792207793
Fold [5/5] Epoch [0/100] Initial Loss: 0.1395, Training Loss: 0.1395, Initial Validation Loss: 0.1278, Validation Loss: 0.1278,V Acc: 0.3704, Top 70th Acc: 0.3947, Bottom 30th Acc: 0.3125
Fold [5/5] Epoch [10/100] Initial Loss: 0.1395, Training Loss: 0.0810, Initial Validation Loss: 0.1278, Validation Loss: 0.0814,V Acc: 0.6204, Top 70th Acc: 0.7500, Bottom 30th Acc: 0.3125
Fold [5/5] Epoch [20/100] Initial Loss: 0.1395, Training Loss: 0.0786, Initial Validation Loss: 0.1278, Validation Loss: 0.0789,V Acc: 0.6111, Top 70th Acc: 0.7500, Bottom 30th Acc: 0.2812
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.7368421052631579
Running train_nn.py with seed 69
CUDA:False
Training samples count:  550
Training on 2 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1448, Training Loss: 0.1448, Initial Validation Loss: 0.1342, Validation Loss: 0.1342,V Acc: 0.3214, Top 70th Acc: 0.4177, Bottom 30th Acc: 0.0909
Fold [1/5] Epoch [10/100] Initial Loss: 0.1448, Training Loss: 0.0815, Initial Validation Loss: 0.1342, Validation Loss: 0.0780,V Acc: 0.6161, Top 70th Acc: 0.7468, Bottom 30th Acc: 0.3030
Fold [1/5] Epoch [20/100] Initial Loss: 0.1448, Training Loss: 0.0797, Initial Validation Loss: 0.1342, Validation Loss: 0.0758,V Acc: 0.6339, Top 70th Acc: 0.7595, Bottom 30th Acc: 0.3333
Fold [1/5] Epoch [30/100] Initial Loss: 0.1448, Training Loss: 0.0790, Initial Validation Loss: 0.1342, Validation Loss: 0.0758,V Acc: 0.6429, Top 70th Acc: 0.7975, Bottom 30th Acc: 0.2727
Stopping early at Epoch (base 0): 34  Rolling back to Epoch (base 0): 29  Top Validation Acc: 0.759493670886076
Fold [2/5] Epoch [0/100] Initial Loss: 0.1389, Training Loss: 0.1389, Initial Validation Loss: 0.1289, Validation Loss: 0.1289,V Acc: 0.2703, Top 70th Acc: 0.3462, Bottom 30th Acc: 0.0909
Fold [2/5] Epoch [10/100] Initial Loss: 0.1389, Training Loss: 0.0808, Initial Validation Loss: 0.1289, Validation Loss: 0.0838,V Acc: 0.6216, Top 70th Acc: 0.7436, Bottom 30th Acc: 0.3333
Fold [2/5] Epoch [20/100] Initial Loss: 0.1389, Training Loss: 0.0786, Initial Validation Loss: 0.1289, Validation Loss: 0.0816,V Acc: 0.6306, Top 70th Acc: 0.7179, Bottom 30th Acc: 0.4242
Fold [2/5] Epoch [30/100] Initial Loss: 0.1389, Training Loss: 0.0777, Initial Validation Loss: 0.1289, Validation Loss: 0.0807,V Acc: 0.6126, Top 70th Acc: 0.7436, Bottom 30th Acc: 0.3030
Stopping early at Epoch (base 0): 32  Rolling back to Epoch (base 0): 27  Top Validation Acc: 0.7307692307692307
Fold [3/5] Epoch [0/100] Initial Loss: 0.1389, Training Loss: 0.1389, Initial Validation Loss: 0.1252, Validation Loss: 0.1252,V Acc: 0.2909, Top 70th Acc: 0.3766, Bottom 30th Acc: 0.0909
Fold [3/5] Epoch [10/100] Initial Loss: 0.1389, Training Loss: 0.0814, Initial Validation Loss: 0.1252, Validation Loss: 0.0781,V Acc: 0.6000, Top 70th Acc: 0.7403, Bottom 30th Acc: 0.2727
Fold [3/5] Epoch [20/100] Initial Loss: 0.1389, Training Loss: 0.0795, Initial Validation Loss: 0.1252, Validation Loss: 0.0764,V Acc: 0.6091, Top 70th Acc: 0.7273, Bottom 30th Acc: 0.3333
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.7272727272727273
Fold [4/5] Epoch [0/100] Initial Loss: 0.1350, Training Loss: 0.1350, Initial Validation Loss: 0.1268, Validation Loss: 0.1268,V Acc: 0.4128, Top 70th Acc: 0.5325, Bottom 30th Acc: 0.1250
Fold [4/5] Epoch [10/100] Initial Loss: 0.1350, Training Loss: 0.0813, Initial Validation Loss: 0.1268, Validation Loss: 0.0751,V Acc: 0.6697, Top 70th Acc: 0.7532, Bottom 30th Acc: 0.4688
Fold [4/5] Epoch [20/100] Initial Loss: 0.1350, Training Loss: 0.0795, Initial Validation Loss: 0.1268, Validation Loss: 0.0737,V Acc: 0.6606, Top 70th Acc: 0.7662, Bottom 30th Acc: 0.4062
Fold [4/5] Epoch [30/100] Initial Loss: 0.1350, Training Loss: 0.0789, Initial Validation Loss: 0.1268, Validation Loss: 0.0732,V Acc: 0.6514, Top 70th Acc: 0.7532, Bottom 30th Acc: 0.4062
Fold [4/5] Epoch [40/100] Initial Loss: 0.1350, Training Loss: 0.0787, Initial Validation Loss: 0.1268, Validation Loss: 0.0728,V Acc: 0.6514, Top 70th Acc: 0.7532, Bottom 30th Acc: 0.4062
Stopping early at Epoch (base 0): 45  Rolling back to Epoch (base 0): 40  Top Validation Acc: 0.7532467532467533
Fold [5/5] Epoch [0/100] Initial Loss: 0.1332, Training Loss: 0.1332, Initial Validation Loss: 0.1216, Validation Loss: 0.1216,V Acc: 0.4630, Top 70th Acc: 0.5658, Bottom 30th Acc: 0.2188
Fold [5/5] Epoch [10/100] Initial Loss: 0.1332, Training Loss: 0.0782, Initial Validation Loss: 0.1216, Validation Loss: 0.0840,V Acc: 0.6204, Top 70th Acc: 0.7237, Bottom 30th Acc: 0.3750
Fold [5/5] Epoch [20/100] Initial Loss: 0.1332, Training Loss: 0.0767, Initial Validation Loss: 0.1216, Validation Loss: 0.0815,V Acc: 0.6389, Top 70th Acc: 0.7237, Bottom 30th Acc: 0.4375
Fold [5/5] Epoch [30/100] Initial Loss: 0.1332, Training Loss: 0.0765, Initial Validation Loss: 0.1216, Validation Loss: 0.0814,V Acc: 0.6389, Top 70th Acc: 0.7237, Bottom 30th Acc: 0.4375
Fold [1/5] Epoch [20/100] Initial Loss: 0.1389, Training Loss: 0.0140, Initial Validation Loss: 0.1249, Validation Loss: 0.0338,V Acc: 0.8482, Top 70th Acc: 0.9367, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 21  Rolling back to Epoch (base 0): 16  Top Validation Acc: 0.9620253164556962
Fold [2/5] Epoch [0/100] Initial Loss: 0.1328, Training Loss: 0.1328, Initial Validation Loss: 0.1231, Validation Loss: 0.1231,V Acc: 0.4505, Top 70th Acc: 0.4487, Bottom 30th Acc: 0.4545
Fold [2/5] Epoch [10/100] Initial Loss: 0.1328, Training Loss: 0.0213, Initial Validation Loss: 0.1231, Validation Loss: 0.0308,V Acc: 0.8829, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.7273
Stopping early at Epoch (base 0): 18  Rolling back to Epoch (base 0): 13  Top Validation Acc: 0.9615384615384616
Fold [3/5] Epoch [0/100] Initial Loss: 0.1332, Training Loss: 0.1332, Initial Validation Loss: 0.1169, Validation Loss: 0.1169,V Acc: 0.5636, Top 70th Acc: 0.6623, Bottom 30th Acc: 0.3333
Fold [3/5] Epoch [10/100] Initial Loss: 0.1332, Training Loss: 0.0219, Initial Validation Loss: 0.1169, Validation Loss: 0.0188,V Acc: 0.9545, Top 70th Acc: 1.0000, Bottom 30th Acc: 0.8485
Fold [3/5] Epoch [20/100] Initial Loss: 0.1332, Training Loss: 0.0162, Initial Validation Loss: 0.1169, Validation Loss: 0.0174,V Acc: 0.9273, Top 70th Acc: 0.9870, Bottom 30th Acc: 0.7879
Fold [3/5] Epoch [30/100] Initial Loss: 0.1332, Training Loss: 0.0125, Initial Validation Loss: 0.1169, Validation Loss: 0.0168,V Acc: 0.9364, Top 70th Acc: 0.9870, Bottom 30th Acc: 0.8182
Stopping early at Epoch (base 0): 30  Rolling back to Epoch (base 0): 25  Top Validation Acc: 0.987012987012987
Fold [4/5] Epoch [0/100] Initial Loss: 0.1366, Training Loss: 0.1366, Initial Validation Loss: 0.1238, Validation Loss: 0.1238,V Acc: 0.4037, Top 70th Acc: 0.4026, Bottom 30th Acc: 0.4062
Fold [4/5] Epoch [10/100] Initial Loss: 0.1366, Training Loss: 0.0245, Initial Validation Loss: 0.1238, Validation Loss: 0.0291,V Acc: 0.8532, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.6875
Fold [4/5] Epoch [20/100] Initial Loss: 0.1366, Training Loss: 0.0166, Initial Validation Loss: 0.1238, Validation Loss: 0.0228,V Acc: 0.8807, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.7188
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.961038961038961
Fold [5/5] Epoch [0/100] Initial Loss: 0.1415, Training Loss: 0.1415, Initial Validation Loss: 0.1321, Validation Loss: 0.1321,V Acc: 0.2593, Top 70th Acc: 0.3158, Bottom 30th Acc: 0.1250
Fold [5/5] Epoch [10/100] Initial Loss: 0.1415, Training Loss: 0.0316, Initial Validation Loss: 0.1321, Validation Loss: 0.0390,V Acc: 0.8241, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.5312
Fold [5/5] Epoch [20/100] Initial Loss: 0.1415, Training Loss: 0.0190, Initial Validation Loss: 0.1321, Validation Loss: 0.0259,V Acc: 0.8704, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.6562
Stopping early at Epoch (base 0): 20  Rolling back to Epoch (base 0): 15  Top Validation Acc: 0.9605263157894737
95 4 [array([0.8436495 , 0.01422191, 0.01341002, 0.06742816, 0.06129037],
      dtype=float32)]
Running train_nn.py with seed 96
CUDA:False
Training samples count:  550
Training on 21 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1334, Training Loss: 0.1334, Initial Validation Loss: 0.1253, Validation Loss: 0.1253,V Acc: 0.4286, Top 70th Acc: 0.5570, Bottom 30th Acc: 0.1212
Fold [1/5] Epoch [10/100] Initial Loss: 0.1334, Training Loss: 0.0229, Initial Validation Loss: 0.1253, Validation Loss: 0.0208,V Acc: 0.9018, Top 70th Acc: 1.0000, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 17  Rolling back to Epoch (base 0): 12  Top Validation Acc: 0.9873417721518988
Fold [2/5] Epoch [0/100] Initial Loss: 0.1348, Training Loss: 0.1348, Initial Validation Loss: 0.1197, Validation Loss: 0.1197,V Acc: 0.6126, Top 70th Acc: 0.6667, Bottom 30th Acc: 0.4848
Fold [2/5] Epoch [10/100] Initial Loss: 0.1348, Training Loss: 0.0200, Initial Validation Loss: 0.1197, Validation Loss: 0.0300,V Acc: 0.8378, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.5152
Fold [2/5] Epoch [20/100] Initial Loss: 0.1348, Training Loss: 0.0141, Initial Validation Loss: 0.1197, Validation Loss: 0.0305,V Acc: 0.8649, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 20  Rolling back to Epoch (base 0): 15  Top Validation Acc: 0.9487179487179487
Fold [3/5] Epoch [0/100] Initial Loss: 0.1292, Training Loss: 0.1292, Initial Validation Loss: 0.1130, Validation Loss: 0.1130,V Acc: 0.4182, Top 70th Acc: 0.5844, Bottom 30th Acc: 0.0303
Fold [3/5] Epoch [10/100] Initial Loss: 0.1292, Training Loss: 0.0284, Initial Validation Loss: 0.1130, Validation Loss: 0.0411,V Acc: 0.8091, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.5455
Fold [3/5] Epoch [20/100] Initial Loss: 0.1292, Training Loss: 0.0164, Initial Validation Loss: 0.1130, Validation Loss: 0.0236,V Acc: 0.9091, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.7576
Fold [3/5] Epoch [30/100] Initial Loss: 0.1292, Training Loss: 0.0156, Initial Validation Loss: 0.1130, Validation Loss: 0.0222,V Acc: 0.8727, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 38  Rolling back to Epoch (base 0): 33  Top Validation Acc: 0.961038961038961
Fold [4/5] Epoch [0/100] Initial Loss: 0.1344, Training Loss: 0.1344, Initial Validation Loss: 0.1232, Validation Loss: 0.1232,V Acc: 0.4404, Top 70th Acc: 0.4805, Bottom 30th Acc: 0.3438
Fold [4/5] Epoch [10/100] Initial Loss: 0.1344, Training Loss: 0.0199, Initial Validation Loss: 0.1232, Validation Loss: 0.0247,V Acc: 0.8532, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.5938
Stopping early at Epoch (base 0): 17  Rolling back to Epoch (base 0): 12  Top Validation Acc: 0.974025974025974
96 3 [array([0.78370064, 0.01640762, 0.04517847, 0.08270718, 0.072006  ],
      dtype=float32)]
Fold [5/5] Epoch [0/100] Initial Loss: 0.1294, Training Loss: 0.1294, Initial Validation Loss: 0.1142, Validation Loss: 0.1142,V Acc: 0.5741, Top 70th Acc: 0.6579, Bottom 30th Acc: 0.3750
Fold [5/5] Epoch [10/100] Initial Loss: 0.1294, Training Loss: 0.0186, Initial Validation Loss: 0.1142, Validation Loss: 0.0272,V Acc: 0.8704, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.6562
Stopping early at Epoch (base 0): 15  Rolling back to Epoch (base 0): 10  Top Validation Acc: 0.9736842105263158
Running train_nn.py with seed 97
CUDA:False
Training samples count:  550
Training on 21 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1398, Training Loss: 0.1398, Initial Validation Loss: 0.1302, Validation Loss: 0.1302,V Acc: 0.4196, Top 70th Acc: 0.4937, Bottom 30th Acc: 0.2424
Fold [1/5] Epoch [10/100] Initial Loss: 0.1398, Training Loss: 0.0245, Initial Validation Loss: 0.1302, Validation Loss: 0.0263,V Acc: 0.9018, Top 70th Acc: 0.9620, Bottom 30th Acc: 0.7576
Fold [1/5] Epoch [20/100] Initial Loss: 0.1398, Training Loss: 0.0172, Initial Validation Loss: 0.1302, Validation Loss: 0.0172,V Acc: 0.9286, Top 70th Acc: 0.9747, Bottom 30th Acc: 0.8182
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.9746835443037974
Fold [2/5] Epoch [0/100] Initial Loss: 0.1343, Training Loss: 0.1343, Initial Validation Loss: 0.1209, Validation Loss: 0.1209,V Acc: 0.5225, Top 70th Acc: 0.6282, Bottom 30th Acc: 0.2727
Fold [2/5] Epoch [10/100] Initial Loss: 0.1343, Training Loss: 0.0261, Initial Validation Loss: 0.1209, Validation Loss: 0.0362,V Acc: 0.8198, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.5152
Fold [2/5] Epoch [20/100] Initial Loss: 0.1343, Training Loss: 0.0180, Initial Validation Loss: 0.1209, Validation Loss: 0.0276,V Acc: 0.8829, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 28  Rolling back to Epoch (base 0): 23  Top Validation Acc: 0.9871794871794872
97 1 [array([0.75148356, 0.02284346, 0.03125516, 0.1229808 , 0.07143705],
      dtype=float32)]
Fold [3/5] Epoch [0/100] Initial Loss: 0.1380, Training Loss: 0.1380, Initial Validation Loss: 0.1247, Validation Loss: 0.1247,V Acc: 0.5273, Top 70th Acc: 0.5974, Bottom 30th Acc: 0.3636
Fold [3/5] Epoch [10/100] Initial Loss: 0.1380, Training Loss: 0.0263, Initial Validation Loss: 0.1247, Validation Loss: 0.0319,V Acc: 0.8455, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6061
Fold [1/5] Epoch [10/100] Initial Loss: 0.1353, Training Loss: 0.0330, Initial Validation Loss: 0.1311, Validation Loss: 0.0356,V Acc: 0.8304, Top 70th Acc: 0.9241, Bottom 30th Acc: 0.6061
Fold [1/5] Epoch [20/100] Initial Loss: 0.1353, Training Loss: 0.0185, Initial Validation Loss: 0.1311, Validation Loss: 0.0346,V Acc: 0.8482, Top 70th Acc: 0.9114, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 20  Rolling back to Epoch (base 0): 15  Top Validation Acc: 0.9113924050632911
68 0 [array([0.61179936, 0.11035462, 0.0922021 , 0.08619982, 0.09944411],
      dtype=float32)]
Fold [2/5] Epoch [0/100] Initial Loss: 0.1402, Training Loss: 0.1402, Initial Validation Loss: 0.1368, Validation Loss: 0.1368,V Acc: 0.3784, Top 70th Acc: 0.4615, Bottom 30th Acc: 0.1818
Fold [2/5] Epoch [10/100] Initial Loss: 0.1402, Training Loss: 0.0293, Initial Validation Loss: 0.1368, Validation Loss: 0.0385,V Acc: 0.8559, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.6970
Fold [2/5] Epoch [20/100] Initial Loss: 0.1402, Training Loss: 0.0178, Initial Validation Loss: 0.1368, Validation Loss: 0.0329,V Acc: 0.8559, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.9358974358974359
Fold [3/5] Epoch [0/100] Initial Loss: 0.1413, Training Loss: 0.1413, Initial Validation Loss: 0.1322, Validation Loss: 0.1322,V Acc: 0.2636, Top 70th Acc: 0.3247, Bottom 30th Acc: 0.1212
Fold [3/5] Epoch [10/100] Initial Loss: 0.1413, Training Loss: 0.0431, Initial Validation Loss: 0.1322, Validation Loss: 0.0485,V Acc: 0.7909, Top 70th Acc: 0.8571, Bottom 30th Acc: 0.6364
Fold [3/5] Epoch [20/100] Initial Loss: 0.1413, Training Loss: 0.0198, Initial Validation Loss: 0.1322, Validation Loss: 0.0321,V Acc: 0.8182, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.935064935064935
Fold [4/5] Epoch [0/100] Initial Loss: 0.1387, Training Loss: 0.1387, Initial Validation Loss: 0.1281, Validation Loss: 0.1281,V Acc: 0.3119, Top 70th Acc: 0.3377, Bottom 30th Acc: 0.2500
Fold [4/5] Epoch [10/100] Initial Loss: 0.1387, Training Loss: 0.0283, Initial Validation Loss: 0.1281, Validation Loss: 0.0341,V Acc: 0.7798, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.4375
Fold [4/5] Epoch [20/100] Initial Loss: 0.1387, Training Loss: 0.0172, Initial Validation Loss: 0.1281, Validation Loss: 0.0324,V Acc: 0.7890, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.4375
Stopping early at Epoch (base 0): 21  Rolling back to Epoch (base 0): 16  Top Validation Acc: 0.935064935064935
Fold [5/5] Epoch [0/100] Initial Loss: 0.1395, Training Loss: 0.1395, Initial Validation Loss: 0.1353, Validation Loss: 0.1353,V Acc: 0.4074, Top 70th Acc: 0.5526, Bottom 30th Acc: 0.0625
Fold [5/5] Epoch [10/100] Initial Loss: 0.1395, Training Loss: 0.0420, Initial Validation Loss: 0.1353, Validation Loss: 0.0447,V Acc: 0.7870, Top 70th Acc: 0.9211, Bottom 30th Acc: 0.4688
Fold [5/5] Epoch [20/100] Initial Loss: 0.1395, Training Loss: 0.0223, Initial Validation Loss: 0.1353, Validation Loss: 0.0299,V Acc: 0.8611, Top 70th Acc: 0.9868, Bottom 30th Acc: 0.5625
Fold [5/5] Epoch [30/100] Initial Loss: 0.1395, Training Loss: 0.0187, Initial Validation Loss: 0.1353, Validation Loss: 0.0295,V Acc: 0.8611, Top 70th Acc: 0.9737, Bottom 30th Acc: 0.5938
Stopping early at Epoch (base 0): 34  Rolling back to Epoch (base 0): 29  Top Validation Acc: 0.9605263157894737
Running train_nn.py with seed 69
CUDA:False
Training samples count:  550
Training on 30 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1384, Training Loss: 0.1384, Initial Validation Loss: 0.1329, Validation Loss: 0.1329,V Acc: 0.3661, Top 70th Acc: 0.4304, Bottom 30th Acc: 0.2121
Fold [1/5] Epoch [10/100] Initial Loss: 0.1384, Training Loss: 0.0269, Initial Validation Loss: 0.1329, Validation Loss: 0.0354,V Acc: 0.8304, Top 70th Acc: 0.9367, Bottom 30th Acc: 0.5758
Fold [1/5] Epoch [20/100] Initial Loss: 0.1384, Training Loss: 0.0180, Initial Validation Loss: 0.1329, Validation Loss: 0.0325,V Acc: 0.8393, Top 70th Acc: 0.9367, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 29  Rolling back to Epoch (base 0): 24  Top Validation Acc: 0.9367088607594937
Fold [2/5] Epoch [0/100] Initial Loss: 0.1381, Training Loss: 0.1381, Initial Validation Loss: 0.1274, Validation Loss: 0.1274,V Acc: 0.3694, Top 70th Acc: 0.4231, Bottom 30th Acc: 0.2424
Fold [2/5] Epoch [10/100] Initial Loss: 0.1381, Training Loss: 0.0483, Initial Validation Loss: 0.1274, Validation Loss: 0.0663,V Acc: 0.6757, Top 70th Acc: 0.8077, Bottom 30th Acc: 0.3636
Fold [2/5] Epoch [20/100] Initial Loss: 0.1381, Training Loss: 0.0224, Initial Validation Loss: 0.1274, Validation Loss: 0.0427,V Acc: 0.8018, Top 70th Acc: 0.8974, Bottom 30th Acc: 0.5758
Fold [2/5] Epoch [30/100] Initial Loss: 0.1381, Training Loss: 0.0176, Initial Validation Loss: 0.1274, Validation Loss: 0.0387,V Acc: 0.8108, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 38  Rolling back to Epoch (base 0): 33  Top Validation Acc: 0.8974358974358975
Fold [3/5] Epoch [0/100] Initial Loss: 0.1410, Training Loss: 0.1410, Initial Validation Loss: 0.1346, Validation Loss: 0.1346,V Acc: 0.2636, Top 70th Acc: 0.2338, Bottom 30th Acc: 0.3333
Fold [3/5] Epoch [10/100] Initial Loss: 0.1410, Training Loss: 0.0329, Initial Validation Loss: 0.1346, Validation Loss: 0.0367,V Acc: 0.8364, Top 70th Acc: 0.8961, Bottom 30th Acc: 0.6970
Fold [3/5] Epoch [20/100] Initial Loss: 0.1410, Training Loss: 0.0183, Initial Validation Loss: 0.1346, Validation Loss: 0.0302,V Acc: 0.8636, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 22  Rolling back to Epoch (base 0): 17  Top Validation Acc: 0.948051948051948
Fold [4/5] Epoch [0/100] Initial Loss: 0.1374, Training Loss: 0.1374, Initial Validation Loss: 0.1333, Validation Loss: 0.1333,V Acc: 0.2661, Top 70th Acc: 0.3247, Bottom 30th Acc: 0.1250
Fold [4/5] Epoch [10/100] Initial Loss: 0.1374, Training Loss: 0.0344, Initial Validation Loss: 0.1333, Validation Loss: 0.0422,V Acc: 0.7982, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.4375
Fold [4/5] Epoch [20/100] Initial Loss: 0.1374, Training Loss: 0.0224, Initial Validation Loss: 0.1333, Validation Loss: 0.0364,V Acc: 0.7982, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.3750
Fold [4/5] Epoch [30/100] Initial Loss: 0.1374, Training Loss: 0.0178, Initial Validation Loss: 0.1333, Validation Loss: 0.0349,V Acc: 0.8073, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.4688
Fold [4/5] Epoch [40/100] Initial Loss: 0.1374, Training Loss: 0.0157, Initial Validation Loss: 0.1333, Validation Loss: 0.0342,V Acc: 0.8073, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.5000
Fold [4/5] Epoch [50/100] Initial Loss: 0.1374, Training Loss: 0.0145, Initial Validation Loss: 0.1333, Validation Loss: 0.0345,V Acc: 0.8349, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.5938
Stopping early at Epoch (base 0): 52  Rolling back to Epoch (base 0): 47  Top Validation Acc: 0.935064935064935
Fold [5/5] Epoch [0/100] Initial Loss: 0.1372, Training Loss: 0.1372, Initial Validation Loss: 0.1321, Validation Loss: 0.1321,V Acc: 0.2500, Top 70th Acc: 0.3421, Bottom 30th Acc: 0.0312
Fold [5/5] Epoch [10/100] Initial Loss: 0.1372, Training Loss: 0.0433, Initial Validation Loss: 0.1321, Validation Loss: 0.0445,V Acc: 0.8148, Top 70th Acc: 0.8816, Bottom 30th Acc: 0.6562
Fold [5/5] Epoch [20/100] Initial Loss: 0.1372, Training Loss: 0.0211, Initial Validation Loss: 0.1321, Validation Loss: 0.0241,V Acc: 0.8981, Top 70th Acc: 0.9737, Bottom 30th Acc: 0.7188
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.9605263157894737
69 4 [array([0.687912  , 0.06319986, 0.03138338, 0.0984531 , 0.11905162],
      dtype=float32)]
Running train_nn.py with seed 70
CUDA:False
Training samples count:  550
Training on 30 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1420, Training Loss: 0.1420, Initial Validation Loss: 0.1333, Validation Loss: 0.1333,V Acc: 0.2946, Top 70th Acc: 0.3671, Bottom 30th Acc: 0.1212
Fold [1/5] Epoch [10/100] Initial Loss: 0.1420, Training Loss: 0.0397, Initial Validation Loss: 0.1333, Validation Loss: 0.0446,V Acc: 0.7946, Top 70th Acc: 0.8987, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 52  Rolling back to Epoch (base 0): 47  Top Validation Acc: 0.961038961038961
Fold [5/5] Epoch [0/100] Initial Loss: 0.1377, Training Loss: 0.1377, Initial Validation Loss: 0.1283, Validation Loss: 0.1283,V Acc: 0.3796, Top 70th Acc: 0.4737, Bottom 30th Acc: 0.1562
Fold [5/5] Epoch [10/100] Initial Loss: 0.1377, Training Loss: 0.0277, Initial Validation Loss: 0.1283, Validation Loss: 0.0374,V Acc: 0.8056, Top 70th Acc: 0.8947, Bottom 30th Acc: 0.5938
Fold [5/5] Epoch [20/100] Initial Loss: 0.1377, Training Loss: 0.0130, Initial Validation Loss: 0.1283, Validation Loss: 0.0320,V Acc: 0.8148, Top 70th Acc: 0.9211, Bottom 30th Acc: 0.5625
Stopping early at Epoch (base 0): 21  Rolling back to Epoch (base 0): 16  Top Validation Acc: 0.9210526315789473
Running train_nn.py with seed 72
CUDA:False
Training samples count:  550
Training on 40 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1397, Training Loss: 0.1397, Initial Validation Loss: 0.1341, Validation Loss: 0.1341,V Acc: 0.3214, Top 70th Acc: 0.3924, Bottom 30th Acc: 0.1515
Fold [1/5] Epoch [10/100] Initial Loss: 0.1397, Training Loss: 0.0262, Initial Validation Loss: 0.1341, Validation Loss: 0.0444,V Acc: 0.7857, Top 70th Acc: 0.8734, Bottom 30th Acc: 0.5758
Fold [1/5] Epoch [20/100] Initial Loss: 0.1397, Training Loss: 0.0124, Initial Validation Loss: 0.1341, Validation Loss: 0.0410,V Acc: 0.7589, Top 70th Acc: 0.8861, Bottom 30th Acc: 0.4545
Stopping early at Epoch (base 0): 28  Rolling back to Epoch (base 0): 23  Top Validation Acc: 0.8860759493670886
Fold [2/5] Epoch [0/100] Initial Loss: 0.1393, Training Loss: 0.1393, Initial Validation Loss: 0.1332, Validation Loss: 0.1332,V Acc: 0.3784, Top 70th Acc: 0.3718, Bottom 30th Acc: 0.3939
Fold [2/5] Epoch [10/100] Initial Loss: 0.1393, Training Loss: 0.0290, Initial Validation Loss: 0.1332, Validation Loss: 0.0302,V Acc: 0.8739, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.6970
Fold [2/5] Epoch [20/100] Initial Loss: 0.1393, Training Loss: 0.0141, Initial Validation Loss: 0.1332, Validation Loss: 0.0250,V Acc: 0.8649, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 27  Rolling back to Epoch (base 0): 22  Top Validation Acc: 0.9615384615384616
Fold [3/5] Epoch [0/100] Initial Loss: 0.1383, Training Loss: 0.1383, Initial Validation Loss: 0.1326, Validation Loss: 0.1326,V Acc: 0.3455, Top 70th Acc: 0.4026, Bottom 30th Acc: 0.2121
Fold [3/5] Epoch [10/100] Initial Loss: 0.1383, Training Loss: 0.0372, Initial Validation Loss: 0.1326, Validation Loss: 0.0423,V Acc: 0.8273, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.6364
Fold [3/5] Epoch [20/100] Initial Loss: 0.1383, Training Loss: 0.0154, Initial Validation Loss: 0.1326, Validation Loss: 0.0328,V Acc: 0.8273, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.935064935064935
Fold [4/5] Epoch [0/100] Initial Loss: 0.1394, Training Loss: 0.1394, Initial Validation Loss: 0.1354, Validation Loss: 0.1354,V Acc: 0.2752, Top 70th Acc: 0.2727, Bottom 30th Acc: 0.2812
Fold [4/5] Epoch [10/100] Initial Loss: 0.1394, Training Loss: 0.0248, Initial Validation Loss: 0.1354, Validation Loss: 0.0318,V Acc: 0.8165, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.4688
Fold [4/5] Epoch [20/100] Initial Loss: 0.1394, Training Loss: 0.0147, Initial Validation Loss: 0.1354, Validation Loss: 0.0243,V Acc: 0.8807, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.6562
Fold [4/5] Epoch [30/100] Initial Loss: 0.1394, Training Loss: 0.0124, Initial Validation Loss: 0.1354, Validation Loss: 0.0235,V Acc: 0.8991, Top 70th Acc: 0.9870, Bottom 30th Acc: 0.6875
Stopping early at Epoch (base 0): 36  Rolling back to Epoch (base 0): 31  Top Validation Acc: 0.974025974025974
Fold [5/5] Epoch [0/100] Initial Loss: 0.1390, Training Loss: 0.1390, Initial Validation Loss: 0.1330, Validation Loss: 0.1330,V Acc: 0.2963, Top 70th Acc: 0.3816, Bottom 30th Acc: 0.0938
Fold [5/5] Epoch [10/100] Initial Loss: 0.1390, Training Loss: 0.0287, Initial Validation Loss: 0.1330, Validation Loss: 0.0308,V Acc: 0.8796, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.6875
Fold [5/5] Epoch [20/100] Initial Loss: 0.1390, Training Loss: 0.0149, Initial Validation Loss: 0.1330, Validation Loss: 0.0219,V Acc: 0.9167, Top 70th Acc: 0.9868, Bottom 30th Acc: 0.7500
Stopping early at Epoch (base 0): 27  Rolling back to Epoch (base 0): 22  Top Validation Acc: 0.9736842105263158
72 4 [array([0.71227497, 0.04812646, 0.05339228, 0.08023269, 0.10597359],
      dtype=float32)]
Running train_nn.py with seed 73
CUDA:False
Training samples count:  550
Training on 40 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1399, Training Loss: 0.1399, Initial Validation Loss: 0.1358, Validation Loss: 0.1358,V Acc: 0.2768, Top 70th Acc: 0.3291, Bottom 30th Acc: 0.1515
Fold [1/5] Epoch [10/100] Initial Loss: 0.1399, Training Loss: 0.0247, Initial Validation Loss: 0.1358, Validation Loss: 0.0369,V Acc: 0.8214, Top 70th Acc: 0.9494, Bottom 30th Acc: 0.5152
Fold [1/5] Epoch [20/100] Initial Loss: 0.1399, Training Loss: 0.0136, Initial Validation Loss: 0.1358, Validation Loss: 0.0336,V Acc: 0.8393, Top 70th Acc: 0.9367, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 21  Rolling back to Epoch (base 0): 16  Top Validation Acc: 0.9493670886075949
Fold [2/5] Epoch [0/100] Initial Loss: 0.1380, Training Loss: 0.1380, Initial Validation Loss: 0.1351, Validation Loss: 0.1351,V Acc: 0.3153, Top 70th Acc: 0.3974, Bottom 30th Acc: 0.1212
Fold [2/5] Epoch [10/100] Initial Loss: 0.1380, Training Loss: 0.0286, Initial Validation Loss: 0.1351, Validation Loss: 0.0424,V Acc: 0.7748, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.4242
Fold [2/5] Epoch [20/100] Initial Loss: 0.1380, Training Loss: 0.0173, Initial Validation Loss: 0.1351, Validation Loss: 0.0389,V Acc: 0.8018, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.4848
Fold [2/5] Epoch [30/100] Initial Loss: 0.1380, Training Loss: 0.0135, Initial Validation Loss: 0.1351, Validation Loss: 0.0362,V Acc: 0.8198, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.5455
Fold [2/5] Epoch [40/100] Initial Loss: 0.1380, Training Loss: 0.0121, Initial Validation Loss: 0.1351, Validation Loss: 0.0330,V Acc: 0.8378, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.6061
Fold [2/5] Epoch [50/100] Initial Loss: 0.1380, Training Loss: 0.0113, Initial Validation Loss: 0.1351, Validation Loss: 0.0318,V Acc: 0.8468, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.5758
Fold [2/5] Epoch [60/100] Initial Loss: 0.1380, Training Loss: 0.0107, Initial Validation Loss: 0.1351, Validation Loss: 0.0306,V Acc: 0.8468, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 67  Rolling back to Epoch (base 0): 62  Top Validation Acc: 0.9487179487179487
73 1 [array([0.755877  , 0.02138653, 0.04276146, 0.10319057, 0.07678449],
      dtype=float32)]
Fold [3/5] Epoch [0/100] Initial Loss: 0.1414, Training Loss: 0.1414, Initial Validation Loss: 0.1345, Validation Loss: 0.1345,V Acc: 0.3000, Top 70th Acc: 0.3377, Bottom 30th Acc: 0.2121
Fold [3/5] Epoch [10/100] Initial Loss: 0.1414, Training Loss: 0.0427, Initial Validation Loss: 0.1345, Validation Loss: 0.0487,V Acc: 0.7727, Top 70th Acc: 0.8571, Bottom 30th Acc: 0.5758
Fold [3/5] Epoch [20/100] Initial Loss: 0.1414, Training Loss: 0.0197, Initial Validation Loss: 0.1345, Validation Loss: 0.0319,V Acc: 0.8364, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.6061
Fold [3/5] Epoch [30/100] Initial Loss: 0.1414, Training Loss: 0.0136, Initial Validation Loss: 0.1345, Validation Loss: 0.0292,V Acc: 0.8182, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.5455
Fold [3/5] Epoch [40/100] Initial Loss: 0.1414, Training Loss: 0.0114, Initial Validation Loss: 0.1345, Validation Loss: 0.0271,V Acc: 0.8364, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.5455
Fold [3/5] Epoch [50/100] Initial Loss: 0.1414, Training Loss: 0.0105, Initial Validation Loss: 0.1345, Validation Loss: 0.0256,V Acc: 0.8636, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 55  Rolling back to Epoch (base 0): 50  Top Validation Acc: 0.961038961038961
Fold [4/5] Epoch [0/100] Initial Loss: 0.1382, Training Loss: 0.1382, Initial Validation Loss: 0.1337, Validation Loss: 0.1337,V Acc: 0.2661, Top 70th Acc: 0.3377, Bottom 30th Acc: 0.0938
Stopping early at Epoch (base 0): 22  Rolling back to Epoch (base 0): 17  Top Validation Acc: 0.9358974358974359
Fold [3/5] Epoch [0/100] Initial Loss: 0.1367, Training Loss: 0.1367, Initial Validation Loss: 0.1322, Validation Loss: 0.1322,V Acc: 0.3364, Top 70th Acc: 0.4286, Bottom 30th Acc: 0.1212
Fold [3/5] Epoch [10/100] Initial Loss: 0.1367, Training Loss: 0.0365, Initial Validation Loss: 0.1322, Validation Loss: 0.0385,V Acc: 0.8364, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.6061
Fold [3/5] Epoch [20/100] Initial Loss: 0.1367, Training Loss: 0.0247, Initial Validation Loss: 0.1322, Validation Loss: 0.0333,V Acc: 0.8636, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 27  Rolling back to Epoch (base 0): 22  Top Validation Acc: 0.948051948051948
Fold [4/5] Epoch [0/100] Initial Loss: 0.1339, Training Loss: 0.1339, Initial Validation Loss: 0.1303, Validation Loss: 0.1303,V Acc: 0.3945, Top 70th Acc: 0.4416, Bottom 30th Acc: 0.2812
Fold [4/5] Epoch [10/100] Initial Loss: 0.1339, Training Loss: 0.0369, Initial Validation Loss: 0.1303, Validation Loss: 0.0407,V Acc: 0.8165, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.5312
Fold [4/5] Epoch [20/100] Initial Loss: 0.1339, Training Loss: 0.0248, Initial Validation Loss: 0.1303, Validation Loss: 0.0302,V Acc: 0.8991, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.7500
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.935064935064935
Fold [5/5] Epoch [0/100] Initial Loss: 0.1394, Training Loss: 0.1394, Initial Validation Loss: 0.1296, Validation Loss: 0.1296,V Acc: 0.2593, Top 70th Acc: 0.3421, Bottom 30th Acc: 0.0625
Fold [5/5] Epoch [10/100] Initial Loss: 0.1394, Training Loss: 0.0334, Initial Validation Loss: 0.1296, Validation Loss: 0.0386,V Acc: 0.7963, Top 70th Acc: 0.9079, Bottom 30th Acc: 0.5312
Fold [5/5] Epoch [20/100] Initial Loss: 0.1394, Training Loss: 0.0230, Initial Validation Loss: 0.1296, Validation Loss: 0.0353,V Acc: 0.8148, Top 70th Acc: 0.9079, Bottom 30th Acc: 0.5938
Stopping early at Epoch (base 0): 29  Rolling back to Epoch (base 0): 24  Top Validation Acc: 0.9342105263157895
Running train_nn.py with seed 71
CUDA:False
Training samples count:  550
Training on 20 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1408, Training Loss: 0.1408, Initial Validation Loss: 0.1374, Validation Loss: 0.1374,V Acc: 0.2500, Top 70th Acc: 0.2785, Bottom 30th Acc: 0.1818
Fold [1/5] Epoch [10/100] Initial Loss: 0.1408, Training Loss: 0.0393, Initial Validation Loss: 0.1374, Validation Loss: 0.0442,V Acc: 0.8304, Top 70th Acc: 0.8608, Bottom 30th Acc: 0.7576
Fold [1/5] Epoch [20/100] Initial Loss: 0.1408, Training Loss: 0.0236, Initial Validation Loss: 0.1374, Validation Loss: 0.0348,V Acc: 0.8482, Top 70th Acc: 0.9241, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 21  Rolling back to Epoch (base 0): 16  Top Validation Acc: 0.9113924050632911
Fold [2/5] Epoch [0/100] Initial Loss: 0.1394, Training Loss: 0.1394, Initial Validation Loss: 0.1337, Validation Loss: 0.1337,V Acc: 0.3333, Top 70th Acc: 0.4103, Bottom 30th Acc: 0.1515
Fold [2/5] Epoch [10/100] Initial Loss: 0.1394, Training Loss: 0.0345, Initial Validation Loss: 0.1337, Validation Loss: 0.0369,V Acc: 0.8649, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.6364
Fold [2/5] Epoch [20/100] Initial Loss: 0.1394, Training Loss: 0.0240, Initial Validation Loss: 0.1337, Validation Loss: 0.0318,V Acc: 0.8559, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.6061
Fold [2/5] Epoch [30/100] Initial Loss: 0.1394, Training Loss: 0.0218, Initial Validation Loss: 0.1337, Validation Loss: 0.0324,V Acc: 0.8559, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 30  Rolling back to Epoch (base 0): 25  Top Validation Acc: 0.9615384615384616
Fold [3/5] Epoch [0/100] Initial Loss: 0.1409, Training Loss: 0.1409, Initial Validation Loss: 0.1315, Validation Loss: 0.1315,V Acc: 0.2727, Top 70th Acc: 0.2597, Bottom 30th Acc: 0.3030
Fold [3/5] Epoch [10/100] Initial Loss: 0.1409, Training Loss: 0.0432, Initial Validation Loss: 0.1315, Validation Loss: 0.0417,V Acc: 0.7727, Top 70th Acc: 0.8961, Bottom 30th Acc: 0.4848
Fold [3/5] Epoch [20/100] Initial Loss: 0.1409, Training Loss: 0.0254, Initial Validation Loss: 0.1315, Validation Loss: 0.0319,V Acc: 0.8364, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.6364
Fold [3/5] Epoch [30/100] Initial Loss: 0.1409, Training Loss: 0.0223, Initial Validation Loss: 0.1315, Validation Loss: 0.0321,V Acc: 0.8364, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 30  Rolling back to Epoch (base 0): 25  Top Validation Acc: 0.9090909090909091
71 2 [array([0.30254573, 0.26049152, 0.20754236, 0.13503256, 0.09438777],
      dtype=float32)]
Fold [4/5] Epoch [0/100] Initial Loss: 0.1346, Training Loss: 0.1346, Initial Validation Loss: 0.1326, Validation Loss: 0.1326,V Acc: 0.3853, Top 70th Acc: 0.4545, Bottom 30th Acc: 0.2188
Fold [4/5] Epoch [10/100] Initial Loss: 0.1346, Training Loss: 0.0321, Initial Validation Loss: 0.1326, Validation Loss: 0.0363,V Acc: 0.8532, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.5938
Fold [4/5] Epoch [20/100] Initial Loss: 0.1346, Training Loss: 0.0240, Initial Validation Loss: 0.1326, Validation Loss: 0.0306,V Acc: 0.8716, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.6250
Stopping early at Epoch (base 0): 29  Rolling back to Epoch (base 0): 24  Top Validation Acc: 0.974025974025974
Fold [5/5] Epoch [0/100] Initial Loss: 0.1411, Training Loss: 0.1411, Initial Validation Loss: 0.1301, Validation Loss: 0.1301,V Acc: 0.3426, Top 70th Acc: 0.4342, Bottom 30th Acc: 0.1250
Fold [5/5] Epoch [10/100] Initial Loss: 0.1411, Training Loss: 0.0350, Initial Validation Loss: 0.1301, Validation Loss: 0.0462,V Acc: 0.7500, Top 70th Acc: 0.8553, Bottom 30th Acc: 0.5000
Fold [5/5] Epoch [20/100] Initial Loss: 0.1411, Training Loss: 0.0254, Initial Validation Loss: 0.1301, Validation Loss: 0.0374,V Acc: 0.8148, Top 70th Acc: 0.8947, Bottom 30th Acc: 0.6250
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.9078947368421053
Running train_nn.py with seed 72
CUDA:False
Training samples count:  550
Training on 20 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1388, Training Loss: 0.1388, Initial Validation Loss: 0.1328, Validation Loss: 0.1328,V Acc: 0.3839, Top 70th Acc: 0.4051, Bottom 30th Acc: 0.3333
Fold [1/5] Epoch [10/100] Initial Loss: 0.1388, Training Loss: 0.0308, Initial Validation Loss: 0.1328, Validation Loss: 0.0489,V Acc: 0.7500, Top 70th Acc: 0.8228, Bottom 30th Acc: 0.5758
Fold [1/5] Epoch [20/100] Initial Loss: 0.1388, Training Loss: 0.0226, Initial Validation Loss: 0.1328, Validation Loss: 0.0446,V Acc: 0.7768, Top 70th Acc: 0.8608, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 28  Rolling back to Epoch (base 0): 23  Top Validation Acc: 0.8607594936708861
Fold [2/5] Epoch [0/100] Initial Loss: 0.1385, Training Loss: 0.1385, Initial Validation Loss: 0.1310, Validation Loss: 0.1310,V Acc: 0.3964, Top 70th Acc: 0.4487, Bottom 30th Acc: 0.2727
Fold [2/5] Epoch [10/100] Initial Loss: 0.1385, Training Loss: 0.0432, Initial Validation Loss: 0.1310, Validation Loss: 0.0363,V Acc: 0.8468, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 19  Rolling back to Epoch (base 0): 14  Top Validation Acc: 0.9230769230769231
Fold [3/5] Epoch [0/100] Initial Loss: 0.1372, Training Loss: 0.1372, Initial Validation Loss: 0.1310, Validation Loss: 0.1310,V Acc: 0.4091, Top 70th Acc: 0.5195, Bottom 30th Acc: 0.1515
Fold [3/5] Epoch [10/100] Initial Loss: 0.1372, Training Loss: 0.0349, Initial Validation Loss: 0.1310, Validation Loss: 0.0406,V Acc: 0.8455, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.6667
Fold [3/5] Epoch [20/100] Initial Loss: 0.1372, Training Loss: 0.0252, Initial Validation Loss: 0.1310, Validation Loss: 0.0333,V Acc: 0.8727, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.7879
Stopping early at Epoch (base 0): 27  Rolling back to Epoch (base 0): 22  Top Validation Acc: 0.9090909090909091
Fold [4/5] Epoch [0/100] Initial Loss: 0.1382, Training Loss: 0.1382, Initial Validation Loss: 0.1313, Validation Loss: 0.1313,V Acc: 0.2752, Top 70th Acc: 0.3377, Bottom 30th Acc: 0.1250
Stopping early at Epoch (base 0): 30  Rolling back to Epoch (base 0): 25  Top Validation Acc: 0.7236842105263158
69 4 [array([0.12349994, 0.36895669, 0.11637092, 0.22944443, 0.16172804],
      dtype=float32)]
Running train_nn.py with seed 70
CUDA:False
Training samples count:  550
Training on 2 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1382, Training Loss: 0.1382, Initial Validation Loss: 0.1280, Validation Loss: 0.1280,V Acc: 0.3750, Top 70th Acc: 0.4430, Bottom 30th Acc: 0.2121
Fold [1/5] Epoch [10/100] Initial Loss: 0.1382, Training Loss: 0.0804, Initial Validation Loss: 0.1280, Validation Loss: 0.0794,V Acc: 0.6161, Top 70th Acc: 0.7215, Bottom 30th Acc: 0.3636
Fold [1/5] Epoch [20/100] Initial Loss: 0.1382, Training Loss: 0.0791, Initial Validation Loss: 0.1280, Validation Loss: 0.0786,V Acc: 0.6071, Top 70th Acc: 0.7342, Bottom 30th Acc: 0.3030
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.7215189873417721
70 0 [array([0.11649173, 0.36200482, 0.16348188, 0.20881201, 0.14920959],
      dtype=float32)]
Fold [2/5] Epoch [0/100] Initial Loss: 0.1318, Training Loss: 0.1318, Initial Validation Loss: 0.1209, Validation Loss: 0.1209,V Acc: 0.4955, Top 70th Acc: 0.6154, Bottom 30th Acc: 0.2121
Fold [2/5] Epoch [10/100] Initial Loss: 0.1318, Training Loss: 0.0795, Initial Validation Loss: 0.1209, Validation Loss: 0.0849,V Acc: 0.5946, Top 70th Acc: 0.7051, Bottom 30th Acc: 0.3333
Fold [2/5] Epoch [20/100] Initial Loss: 0.1318, Training Loss: 0.0772, Initial Validation Loss: 0.1209, Validation Loss: 0.0831,V Acc: 0.5946, Top 70th Acc: 0.7308, Bottom 30th Acc: 0.2727
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.7307692307692307
Fold [3/5] Epoch [0/100] Initial Loss: 0.1364, Training Loss: 0.1364, Initial Validation Loss: 0.1298, Validation Loss: 0.1298,V Acc: 0.4909, Top 70th Acc: 0.5065, Bottom 30th Acc: 0.4545
Fold [3/5] Epoch [10/100] Initial Loss: 0.1364, Training Loss: 0.0811, Initial Validation Loss: 0.1298, Validation Loss: 0.0767,V Acc: 0.6455, Top 70th Acc: 0.7403, Bottom 30th Acc: 0.4242
Fold [3/5] Epoch [20/100] Initial Loss: 0.1364, Training Loss: 0.0791, Initial Validation Loss: 0.1298, Validation Loss: 0.0753,V Acc: 0.6455, Top 70th Acc: 0.7532, Bottom 30th Acc: 0.3939
Fold [3/5] Epoch [30/100] Initial Loss: 0.1364, Training Loss: 0.0782, Initial Validation Loss: 0.1298, Validation Loss: 0.0746,V Acc: 0.6182, Top 70th Acc: 0.7792, Bottom 30th Acc: 0.2424
Fold [3/5] Epoch [40/100] Initial Loss: 0.1364, Training Loss: 0.0779, Initial Validation Loss: 0.1298, Validation Loss: 0.0741,V Acc: 0.6182, Top 70th Acc: 0.7922, Bottom 30th Acc: 0.2121
Stopping early at Epoch (base 0): 42  Rolling back to Epoch (base 0): 37  Top Validation Acc: 0.7662337662337663
Fold [4/5] Epoch [0/100] Initial Loss: 0.1294, Training Loss: 0.1294, Initial Validation Loss: 0.1193, Validation Loss: 0.1193,V Acc: 0.5413, Top 70th Acc: 0.6753, Bottom 30th Acc: 0.2188
Fold [4/5] Epoch [10/100] Initial Loss: 0.1294, Training Loss: 0.0813, Initial Validation Loss: 0.1193, Validation Loss: 0.0757,V Acc: 0.6789, Top 70th Acc: 0.7922, Bottom 30th Acc: 0.4062
Fold [4/5] Epoch [20/100] Initial Loss: 0.1294, Training Loss: 0.0798, Initial Validation Loss: 0.1193, Validation Loss: 0.0741,V Acc: 0.6789, Top 70th Acc: 0.7922, Bottom 30th Acc: 0.4062
Fold [4/5] Epoch [30/100] Initial Loss: 0.1294, Training Loss: 0.0792, Initial Validation Loss: 0.1193, Validation Loss: 0.0735,V Acc: 0.6881, Top 70th Acc: 0.8052, Bottom 30th Acc: 0.4062
Stopping early at Epoch (base 0): 37  Rolling back to Epoch (base 0): 32  Top Validation Acc: 0.8051948051948052
Fold [5/5] Epoch [0/100] Initial Loss: 0.1348, Training Loss: 0.1348, Initial Validation Loss: 0.1125, Validation Loss: 0.1125,V Acc: 0.4722, Top 70th Acc: 0.5789, Bottom 30th Acc: 0.2188
Fold [5/5] Epoch [10/100] Initial Loss: 0.1348, Training Loss: 0.0803, Initial Validation Loss: 0.1125, Validation Loss: 0.0809,V Acc: 0.5926, Top 70th Acc: 0.7105, Bottom 30th Acc: 0.3125
Fold [5/5] Epoch [20/100] Initial Loss: 0.1348, Training Loss: 0.0784, Initial Validation Loss: 0.1125, Validation Loss: 0.0779,V Acc: 0.6204, Top 70th Acc: 0.7105, Bottom 30th Acc: 0.4062
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.6973684210526315
Running train_nn.py with seed 71
CUDA:False
Training samples count:  550
Training on 2 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1406, Training Loss: 0.1406, Initial Validation Loss: 0.1375, Validation Loss: 0.1375,V Acc: 0.2589, Top 70th Acc: 0.3544, Bottom 30th Acc: 0.0303
Fold [1/5] Epoch [10/100] Initial Loss: 0.1406, Training Loss: 0.0810, Initial Validation Loss: 0.1375, Validation Loss: 0.0847,V Acc: 0.6339, Top 70th Acc: 0.7215, Bottom 30th Acc: 0.4242
Fold [1/5] Epoch [20/100] Initial Loss: 0.1406, Training Loss: 0.0783, Initial Validation Loss: 0.1375, Validation Loss: 0.0833,V Acc: 0.6429, Top 70th Acc: 0.6835, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 28  Rolling back to Epoch (base 0): 23  Top Validation Acc: 0.7215189873417721
Fold [2/5] Epoch [0/100] Initial Loss: 0.1372, Training Loss: 0.1372, Initial Validation Loss: 0.1265, Validation Loss: 0.1265,V Acc: 0.4054, Top 70th Acc: 0.4359, Bottom 30th Acc: 0.3333
Fold [2/5] Epoch [10/100] Initial Loss: 0.1372, Training Loss: 0.0805, Initial Validation Loss: 0.1265, Validation Loss: 0.0817,V Acc: 0.6036, Top 70th Acc: 0.6923, Bottom 30th Acc: 0.3939
Fold [2/5] Epoch [20/100] Initial Loss: 0.1372, Training Loss: 0.0786, Initial Validation Loss: 0.1265, Validation Loss: 0.0807,V Acc: 0.6036, Top 70th Acc: 0.6795, Bottom 30th Acc: 0.4242
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.6923076923076923
Fold [3/5] Epoch [0/100] Initial Loss: 0.1364, Training Loss: 0.1364, Initial Validation Loss: 0.1240, Validation Loss: 0.1240,V Acc: 0.4455, Top 70th Acc: 0.5714, Bottom 30th Acc: 0.1515
Fold [3/5] Epoch [10/100] Initial Loss: 0.1364, Training Loss: 0.0830, Initial Validation Loss: 0.1240, Validation Loss: 0.0718,V Acc: 0.6455, Top 70th Acc: 0.8052, Bottom 30th Acc: 0.2727
Fold [3/5] Epoch [20/100] Initial Loss: 0.1364, Training Loss: 0.0812, Initial Validation Loss: 0.1240, Validation Loss: 0.0696,V Acc: 0.6545, Top 70th Acc: 0.8182, Bottom 30th Acc: 0.2727
Fold [3/5] Epoch [30/100] Initial Loss: 0.1364, Training Loss: 0.0810, Initial Validation Loss: 0.1240, Validation Loss: 0.0683,V Acc: 0.6545, Top 70th Acc: 0.8182, Bottom 30th Acc: 0.2727
Fold [3/5] Epoch [40/100] Initial Loss: 0.1364, Training Loss: 0.0806, Initial Validation Loss: 0.1240, Validation Loss: 0.0678,V Acc: 0.6636, Top 70th Acc: 0.8052, Bottom 30th Acc: 0.3333
Fold [3/5] Epoch [50/100] Initial Loss: 0.1364, Training Loss: 0.0802, Initial Validation Loss: 0.1240, Validation Loss: 0.0684,V Acc: 0.6545, Top 70th Acc: 0.8052, Bottom 30th Acc: 0.3030
Stopping early at Epoch (base 0): 52  Rolling back to Epoch (base 0): 47  Top Validation Acc: 0.8181818181818182
71 2 [array([0.11915978, 0.31832787, 0.16346714, 0.23265229, 0.16639298],
      dtype=float32)]
Fold [4/5] Epoch [0/100] Initial Loss: 0.1390, Training Loss: 0.1390, Initial Validation Loss: 0.1355, Validation Loss: 0.1355,V Acc: 0.2844, Top 70th Acc: 0.3506, Bottom 30th Acc: 0.1250
Fold [4/5] Epoch [10/100] Initial Loss: 0.1390, Training Loss: 0.0816, Initial Validation Loss: 0.1355, Validation Loss: 0.0782,V Acc: 0.6789, Top 70th Acc: 0.8182, Bottom 30th Acc: 0.3438
Fold [4/5] Epoch [20/100] Initial Loss: 0.1390, Training Loss: 0.0798, Initial Validation Loss: 0.1355, Validation Loss: 0.0762,V Acc: 0.6972, Top 70th Acc: 0.8182, Bottom 30th Acc: 0.4062
Fold [4/5] Epoch [30/100] Initial Loss: 0.1390, Training Loss: 0.0793, Initial Validation Loss: 0.1355, Validation Loss: 0.0746,V Acc: 0.6972, Top 70th Acc: 0.8312, Bottom 30th Acc: 0.3750
Stopping early at Epoch (base 0): 39  Rolling back to Epoch (base 0): 34  Top Validation Acc: 0.8181818181818182
Fold [5/5] Epoch [0/100] Initial Loss: 0.1415, Training Loss: 0.1415, Initial Validation Loss: 0.1296, Validation Loss: 0.1296,V Acc: 0.3889, Top 70th Acc: 0.3289, Bottom 30th Acc: 0.5312
Fold [2/5] Epoch [30/100] Initial Loss: 0.1366, Training Loss: 0.0040, Initial Validation Loss: 0.1314, Validation Loss: 0.0249,V Acc: 0.8829, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 34  Rolling back to Epoch (base 0): 29  Top Validation Acc: 0.9615384615384616
Fold [3/5] Epoch [0/100] Initial Loss: 0.1380, Training Loss: 0.1380, Initial Validation Loss: 0.1393, Validation Loss: 0.1393,V Acc: 0.2545, Top 70th Acc: 0.2857, Bottom 30th Acc: 0.1818
Fold [3/5] Epoch [10/100] Initial Loss: 0.1380, Training Loss: 0.0283, Initial Validation Loss: 0.1393, Validation Loss: 0.0430,V Acc: 0.8364, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.6667
Fold [3/5] Epoch [20/100] Initial Loss: 0.1380, Training Loss: 0.0063, Initial Validation Loss: 0.1393, Validation Loss: 0.0253,V Acc: 0.8818, Top 70th Acc: 0.9870, Bottom 30th Acc: 0.6364
Fold [3/5] Epoch [30/100] Initial Loss: 0.1380, Training Loss: 0.0043, Initial Validation Loss: 0.1393, Validation Loss: 0.0233,V Acc: 0.9182, Top 70th Acc: 0.9870, Bottom 30th Acc: 0.7576
Fold [3/5] Epoch [40/100] Initial Loss: 0.1380, Training Loss: 0.0039, Initial Validation Loss: 0.1393, Validation Loss: 0.0218,V Acc: 0.9273, Top 70th Acc: 0.9870, Bottom 30th Acc: 0.7879
Fold [3/5] Epoch [50/100] Initial Loss: 0.1380, Training Loss: 0.0038, Initial Validation Loss: 0.1393, Validation Loss: 0.0210,V Acc: 0.9273, Top 70th Acc: 0.9870, Bottom 30th Acc: 0.7879
Fold [3/5] Epoch [60/100] Initial Loss: 0.1380, Training Loss: 0.0037, Initial Validation Loss: 0.1393, Validation Loss: 0.0210,V Acc: 0.9273, Top 70th Acc: 0.9870, Bottom 30th Acc: 0.7879
Stopping early at Epoch (base 0): 61  Rolling back to Epoch (base 0): 56  Top Validation Acc: 0.987012987012987
Fold [4/5] Epoch [0/100] Initial Loss: 0.1385, Training Loss: 0.1385, Initial Validation Loss: 0.1326, Validation Loss: 0.1326,V Acc: 0.3119, Top 70th Acc: 0.3636, Bottom 30th Acc: 0.1875
Fold [4/5] Epoch [10/100] Initial Loss: 0.1385, Training Loss: 0.0099, Initial Validation Loss: 0.1326, Validation Loss: 0.0332,V Acc: 0.8440, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.6562
Fold [4/5] Epoch [20/100] Initial Loss: 0.1385, Training Loss: 0.0046, Initial Validation Loss: 0.1326, Validation Loss: 0.0303,V Acc: 0.8624, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.6875
Fold [4/5] Epoch [30/100] Initial Loss: 0.1385, Training Loss: 0.0040, Initial Validation Loss: 0.1326, Validation Loss: 0.0301,V Acc: 0.8716, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6875
Stopping early at Epoch (base 0): 33  Rolling back to Epoch (base 0): 28  Top Validation Acc: 0.935064935064935
Fold [5/5] Epoch [0/100] Initial Loss: 0.1402, Training Loss: 0.1402, Initial Validation Loss: 0.1302, Validation Loss: 0.1302,V Acc: 0.2778, Top 70th Acc: 0.3158, Bottom 30th Acc: 0.1875
Fold [5/5] Epoch [10/100] Initial Loss: 0.1402, Training Loss: 0.0166, Initial Validation Loss: 0.1302, Validation Loss: 0.0424,V Acc: 0.7593, Top 70th Acc: 0.8816, Bottom 30th Acc: 0.4688
Fold [5/5] Epoch [20/100] Initial Loss: 0.1402, Training Loss: 0.0045, Initial Validation Loss: 0.1302, Validation Loss: 0.0370,V Acc: 0.7778, Top 70th Acc: 0.9211, Bottom 30th Acc: 0.4375
Fold [5/5] Epoch [30/100] Initial Loss: 0.1402, Training Loss: 0.0037, Initial Validation Loss: 0.1302, Validation Loss: 0.0366,V Acc: 0.7685, Top 70th Acc: 0.9211, Bottom 30th Acc: 0.4062
Fold [5/5] Epoch [40/100] Initial Loss: 0.1402, Training Loss: 0.0035, Initial Validation Loss: 0.1302, Validation Loss: 0.0358,V Acc: 0.7778, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.4062
Stopping early at Epoch (base 0): 44  Rolling back to Epoch (base 0): 39  Top Validation Acc: 0.9342105263157895
Running train_nn.py with seed 55
CUDA:False
Training samples count:  550
Training on 162 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1391, Training Loss: 0.1391, Initial Validation Loss: 0.1358, Validation Loss: 0.1358,V Acc: 0.3214, Top 70th Acc: 0.3797, Bottom 30th Acc: 0.1818
Fold [1/5] Epoch [10/100] Initial Loss: 0.1391, Training Loss: 0.0217, Initial Validation Loss: 0.1358, Validation Loss: 0.0368,V Acc: 0.8661, Top 70th Acc: 0.9241, Bottom 30th Acc: 0.7273
Fold [1/5] Epoch [20/100] Initial Loss: 0.1391, Training Loss: 0.0054, Initial Validation Loss: 0.1358, Validation Loss: 0.0273,V Acc: 0.8571, Top 70th Acc: 0.9747, Bottom 30th Acc: 0.5758
Fold [1/5] Epoch [30/100] Initial Loss: 0.1391, Training Loss: 0.0041, Initial Validation Loss: 0.1358, Validation Loss: 0.0256,V Acc: 0.8482, Top 70th Acc: 0.9747, Bottom 30th Acc: 0.5455
Fold [1/5] Epoch [40/100] Initial Loss: 0.1391, Training Loss: 0.0038, Initial Validation Loss: 0.1358, Validation Loss: 0.0249,V Acc: 0.8661, Top 70th Acc: 0.9747, Bottom 30th Acc: 0.6061
Fold [1/5] Epoch [50/100] Initial Loss: 0.1391, Training Loss: 0.0037, Initial Validation Loss: 0.1358, Validation Loss: 0.0239,V Acc: 0.8571, Top 70th Acc: 0.9873, Bottom 30th Acc: 0.5455
Fold [1/5] Epoch [60/100] Initial Loss: 0.1391, Training Loss: 0.0036, Initial Validation Loss: 0.1358, Validation Loss: 0.0234,V Acc: 0.8571, Top 70th Acc: 0.9873, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 65  Rolling back to Epoch (base 0): 60  Top Validation Acc: 0.9873417721518988
Fold [2/5] Epoch [0/100] Initial Loss: 0.1387, Training Loss: 0.1387, Initial Validation Loss: 0.1347, Validation Loss: 0.1347,V Acc: 0.3604, Top 70th Acc: 0.4359, Bottom 30th Acc: 0.1818
Fold [2/5] Epoch [10/100] Initial Loss: 0.1387, Training Loss: 0.0117, Initial Validation Loss: 0.1347, Validation Loss: 0.0306,V Acc: 0.8468, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.6364
Fold [2/5] Epoch [20/100] Initial Loss: 0.1387, Training Loss: 0.0041, Initial Validation Loss: 0.1347, Validation Loss: 0.0287,V Acc: 0.8829, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 21  Rolling back to Epoch (base 0): 16  Top Validation Acc: 0.9487179487179487
Fold [3/5] Epoch [0/100] Initial Loss: 0.1406, Training Loss: 0.1406, Initial Validation Loss: 0.1354, Validation Loss: 0.1354,V Acc: 0.2636, Top 70th Acc: 0.3377, Bottom 30th Acc: 0.0909
Fold [3/5] Epoch [10/100] Initial Loss: 0.1406, Training Loss: 0.0176, Initial Validation Loss: 0.1354, Validation Loss: 0.0418,V Acc: 0.8000, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.4848
Fold [3/5] Epoch [20/100] Initial Loss: 0.1406, Training Loss: 0.0046, Initial Validation Loss: 0.1354, Validation Loss: 0.0354,V Acc: 0.8182, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.5455
Fold [3/5] Epoch [30/100] Initial Loss: 0.1406, Training Loss: 0.0037, Initial Validation Loss: 0.1354, Validation Loss: 0.0336,V Acc: 0.8091, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.4848
Fold [3/5] Epoch [40/100] Initial Loss: 0.1406, Training Loss: 0.0035, Initial Validation Loss: 0.1354, Validation Loss: 0.0330,V Acc: 0.8182, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.4848
Fold [3/5] Epoch [50/100] Initial Loss: 0.1406, Training Loss: 0.0033, Initial Validation Loss: 0.1354, Validation Loss: 0.0327,V Acc: 0.8182, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.5152
Fold [3/5] Epoch [60/100] Initial Loss: 0.1406, Training Loss: 0.0032, Initial Validation Loss: 0.1354, Validation Loss: 0.0327,V Acc: 0.8182, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.5152
Stopping early at Epoch (base 0): 61  Rolling back to Epoch (base 0): 56  Top Validation Acc: 0.948051948051948
Fold [4/5] Epoch [0/100] Initial Loss: 0.1441, Training Loss: 0.1441, Initial Validation Loss: 0.1296, Validation Loss: 0.1296,V Acc: 0.4128, Top 70th Acc: 0.4935, Bottom 30th Acc: 0.2188
Fold [4/5] Epoch [10/100] Initial Loss: 0.1441, Training Loss: 0.0166, Initial Validation Loss: 0.1296, Validation Loss: 0.0300,V Acc: 0.8532, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.6562
Fold [4/5] Epoch [20/100] Initial Loss: 0.1441, Training Loss: 0.0049, Initial Validation Loss: 0.1296, Validation Loss: 0.0259,V Acc: 0.8716, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.6562
Fold [4/5] Epoch [30/100] Initial Loss: 0.1441, Training Loss: 0.0039, Initial Validation Loss: 0.1296, Validation Loss: 0.0249,V Acc: 0.8807, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.7188
Fold [4/5] Epoch [40/100] Initial Loss: 0.1441, Training Loss: 0.0037, Initial Validation Loss: 0.1296, Validation Loss: 0.0250,V Acc: 0.8807, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.7188
Fold [3/5] Epoch [20/100] Initial Loss: 0.1380, Training Loss: 0.0153, Initial Validation Loss: 0.1247, Validation Loss: 0.0272,V Acc: 0.8727, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.961038961038961
Fold [4/5] Epoch [0/100] Initial Loss: 0.1357, Training Loss: 0.1357, Initial Validation Loss: 0.1258, Validation Loss: 0.1258,V Acc: 0.4495, Top 70th Acc: 0.5714, Bottom 30th Acc: 0.1562
Fold [4/5] Epoch [10/100] Initial Loss: 0.1357, Training Loss: 0.0230, Initial Validation Loss: 0.1258, Validation Loss: 0.0271,V Acc: 0.8624, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.6875
Fold [4/5] Epoch [20/100] Initial Loss: 0.1357, Training Loss: 0.0151, Initial Validation Loss: 0.1258, Validation Loss: 0.0231,V Acc: 0.8716, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.6250
Stopping early at Epoch (base 0): 20  Rolling back to Epoch (base 0): 15  Top Validation Acc: 0.974025974025974
Fold [5/5] Epoch [0/100] Initial Loss: 0.1329, Training Loss: 0.1329, Initial Validation Loss: 0.1169, Validation Loss: 0.1169,V Acc: 0.4907, Top 70th Acc: 0.5921, Bottom 30th Acc: 0.2500
Fold [5/5] Epoch [10/100] Initial Loss: 0.1329, Training Loss: 0.0209, Initial Validation Loss: 0.1169, Validation Loss: 0.0303,V Acc: 0.8611, Top 70th Acc: 0.9211, Bottom 30th Acc: 0.7188
Fold [5/5] Epoch [20/100] Initial Loss: 0.1329, Training Loss: 0.0131, Initial Validation Loss: 0.1169, Validation Loss: 0.0276,V Acc: 0.8611, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.6562
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.9605263157894737
Running train_nn.py with seed 98
CUDA:False
Training samples count:  550
Training on 21 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1385, Training Loss: 0.1385, Initial Validation Loss: 0.1293, Validation Loss: 0.1293,V Acc: 0.4107, Top 70th Acc: 0.5570, Bottom 30th Acc: 0.0606
Fold [1/5] Epoch [10/100] Initial Loss: 0.1385, Training Loss: 0.0236, Initial Validation Loss: 0.1293, Validation Loss: 0.0304,V Acc: 0.8661, Top 70th Acc: 0.9494, Bottom 30th Acc: 0.6667
Fold [1/5] Epoch [20/100] Initial Loss: 0.1385, Training Loss: 0.0161, Initial Validation Loss: 0.1293, Validation Loss: 0.0259,V Acc: 0.9107, Top 70th Acc: 0.9494, Bottom 30th Acc: 0.8182
Stopping early at Epoch (base 0): 21  Rolling back to Epoch (base 0): 16  Top Validation Acc: 0.9493670886075949
Fold [2/5] Epoch [0/100] Initial Loss: 0.1270, Training Loss: 0.1270, Initial Validation Loss: 0.1137, Validation Loss: 0.1137,V Acc: 0.4595, Top 70th Acc: 0.6026, Bottom 30th Acc: 0.1212
Fold [2/5] Epoch [10/100] Initial Loss: 0.1270, Training Loss: 0.0269, Initial Validation Loss: 0.1137, Validation Loss: 0.0330,V Acc: 0.8739, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.6970
Fold [2/5] Epoch [20/100] Initial Loss: 0.1270, Training Loss: 0.0200, Initial Validation Loss: 0.1137, Validation Loss: 0.0297,V Acc: 0.8829, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 27  Rolling back to Epoch (base 0): 22  Top Validation Acc: 0.9615384615384616
Fold [3/5] Epoch [0/100] Initial Loss: 0.1298, Training Loss: 0.1298, Initial Validation Loss: 0.1112, Validation Loss: 0.1112,V Acc: 0.5909, Top 70th Acc: 0.6883, Bottom 30th Acc: 0.3636
Fold [3/5] Epoch [10/100] Initial Loss: 0.1298, Training Loss: 0.0203, Initial Validation Loss: 0.1112, Validation Loss: 0.0261,V Acc: 0.8364, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.5152
Stopping early at Epoch (base 0): 15  Rolling back to Epoch (base 0): 10  Top Validation Acc: 0.961038961038961
Fold [4/5] Epoch [0/100] Initial Loss: 0.1307, Training Loss: 0.1307, Initial Validation Loss: 0.1159, Validation Loss: 0.1159,V Acc: 0.4679, Top 70th Acc: 0.5325, Bottom 30th Acc: 0.3125
Fold [4/5] Epoch [10/100] Initial Loss: 0.1307, Training Loss: 0.0252, Initial Validation Loss: 0.1159, Validation Loss: 0.0292,V Acc: 0.8716, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6875
Stopping early at Epoch (base 0): 17  Rolling back to Epoch (base 0): 12  Top Validation Acc: 0.948051948051948
98 3 [array([0.832396  , 0.01529181, 0.03362267, 0.05986078, 0.05882868],
      dtype=float32)]
Fold [5/5] Epoch [0/100] Initial Loss: 0.1326, Training Loss: 0.1326, Initial Validation Loss: 0.1173, Validation Loss: 0.1173,V Acc: 0.4907, Top 70th Acc: 0.5263, Bottom 30th Acc: 0.4062
Fold [5/5] Epoch [10/100] Initial Loss: 0.1326, Training Loss: 0.0217, Initial Validation Loss: 0.1173, Validation Loss: 0.0228,V Acc: 0.8981, Top 70th Acc: 0.9868, Bottom 30th Acc: 0.6875
Fold [5/5] Epoch [20/100] Initial Loss: 0.1326, Training Loss: 0.0176, Initial Validation Loss: 0.1173, Validation Loss: 0.0262,V Acc: 0.8796, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.6875
Stopping early at Epoch (base 0): 21  Rolling back to Epoch (base 0): 16  Top Validation Acc: 0.9868421052631579
Running train_nn.py with seed 99
CUDA:False
Training samples count:  550
Training on 21 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1336, Training Loss: 0.1336, Initial Validation Loss: 0.1200, Validation Loss: 0.1200,V Acc: 0.5089, Top 70th Acc: 0.5949, Bottom 30th Acc: 0.3030
Fold [1/5] Epoch [10/100] Initial Loss: 0.1336, Training Loss: 0.0229, Initial Validation Loss: 0.1200, Validation Loss: 0.0222,V Acc: 0.8929, Top 70th Acc: 1.0000, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 17  Rolling back to Epoch (base 0): 12  Top Validation Acc: 0.9873417721518988
Fold [2/5] Epoch [0/100] Initial Loss: 0.1304, Training Loss: 0.1304, Initial Validation Loss: 0.1164, Validation Loss: 0.1164,V Acc: 0.5225, Top 70th Acc: 0.6282, Bottom 30th Acc: 0.2727
Fold [2/5] Epoch [10/100] Initial Loss: 0.1304, Training Loss: 0.0204, Initial Validation Loss: 0.1164, Validation Loss: 0.0270,V Acc: 0.8649, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 17  Rolling back to Epoch (base 0): 12  Top Validation Acc: 0.9615384615384616
99 1 [array([0.6026791 , 0.04884492, 0.05528817, 0.20717609, 0.08601178],
      dtype=float32)]
Fold [3/5] Epoch [0/100] Initial Loss: 0.1393, Training Loss: 0.1393, Initial Validation Loss: 0.1285, Validation Loss: 0.1285,V Acc: 0.4000, Top 70th Acc: 0.4156, Bottom 30th Acc: 0.3636
Fold [3/5] Epoch [10/100] Initial Loss: 0.1393, Training Loss: 0.0212, Initial Validation Loss: 0.1285, Validation Loss: 0.0258,V Acc: 0.8909, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.7879
Stopping early at Epoch (base 0): 18  Rolling back to Epoch (base 0): 13  Top Validation Acc: 0.935064935064935
Fold [4/5] Epoch [0/100] Initial Loss: 0.1358, Training Loss: 0.1358, Initial Validation Loss: 0.1231, Validation Loss: 0.1231,V Acc: 0.4037, Top 70th Acc: 0.4805, Bottom 30th Acc: 0.2188
Fold [4/5] Epoch [10/100] Initial Loss: 0.1358, Training Loss: 0.0232, Initial Validation Loss: 0.1231, Validation Loss: 0.0240,V Acc: 0.8899, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.6875
Fold [4/5] Epoch [20/100] Initial Loss: 0.1358, Training Loss: 0.0147, Initial Validation Loss: 0.1231, Validation Loss: 0.0302,V Acc: 0.8349, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.5625
Stopping early at Epoch (base 0): 21  Rolling back to Epoch (base 0): 16  Top Validation Acc: 0.974025974025974
Fold [5/5] Epoch [0/100] Initial Loss: 0.1375, Training Loss: 0.1375, Initial Validation Loss: 0.1301, Validation Loss: 0.1301,V Acc: 0.3796, Top 70th Acc: 0.4474, Bottom 30th Acc: 0.2188
Fold [5/5] Epoch [10/100] Initial Loss: 0.1375, Training Loss: 0.0285, Initial Validation Loss: 0.1301, Validation Loss: 0.0394,V Acc: 0.8333, Top 70th Acc: 0.8947, Bottom 30th Acc: 0.6875
Fold [5/5] Epoch [20/100] Initial Loss: 0.1375, Training Loss: 0.0164, Initial Validation Loss: 0.1301, Validation Loss: 0.0266,V Acc: 0.8796, Top 70th Acc: 0.9737, Bottom 30th Acc: 0.6562
Stopping early at Epoch (base 0): 29  Rolling back to Epoch (base 0): 24  Top Validation Acc: 0.9736842105263158
Running train_nn.py with seed 100
CUDA:False
Training samples count:  550
Training on 21 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1294, Training Loss: 0.1294, Initial Validation Loss: 0.1167, Validation Loss: 0.1167,V Acc: 0.4375, Top 70th Acc: 0.6203, Bottom 30th Acc: 0.0000
Fold [1/5] Epoch [10/100] Initial Loss: 0.1294, Training Loss: 0.0252, Initial Validation Loss: 0.1167, Validation Loss: 0.0332,V Acc: 0.8839, Top 70th Acc: 0.9494, Bottom 30th Acc: 0.7273
Fold [1/5] Epoch [20/100] Initial Loss: 0.1420, Training Loss: 0.0185, Initial Validation Loss: 0.1333, Validation Loss: 0.0310,V Acc: 0.8393, Top 70th Acc: 0.9241, Bottom 30th Acc: 0.6364
Fold [1/5] Epoch [30/100] Initial Loss: 0.1420, Training Loss: 0.0157, Initial Validation Loss: 0.1333, Validation Loss: 0.0311,V Acc: 0.8304, Top 70th Acc: 0.9367, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 31  Rolling back to Epoch (base 0): 26  Top Validation Acc: 0.9367088607594937
70 0 [array([0.6662477 , 0.05147478, 0.03983504, 0.11973126, 0.12271119],
      dtype=float32)]
Fold [2/5] Epoch [0/100] Initial Loss: 0.1407, Training Loss: 0.1407, Initial Validation Loss: 0.1313, Validation Loss: 0.1313,V Acc: 0.2883, Top 70th Acc: 0.3590, Bottom 30th Acc: 0.1212
Fold [2/5] Epoch [10/100] Initial Loss: 0.1407, Training Loss: 0.0438, Initial Validation Loss: 0.1313, Validation Loss: 0.0482,V Acc: 0.8018, Top 70th Acc: 0.8846, Bottom 30th Acc: 0.6061
Fold [2/5] Epoch [20/100] Initial Loss: 0.1407, Training Loss: 0.0201, Initial Validation Loss: 0.1313, Validation Loss: 0.0287,V Acc: 0.8739, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.6667
Fold [2/5] Epoch [30/100] Initial Loss: 0.1407, Training Loss: 0.0165, Initial Validation Loss: 0.1313, Validation Loss: 0.0287,V Acc: 0.8559, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 33  Rolling back to Epoch (base 0): 28  Top Validation Acc: 0.9615384615384616
Fold [3/5] Epoch [0/100] Initial Loss: 0.1411, Training Loss: 0.1411, Initial Validation Loss: 0.1357, Validation Loss: 0.1357,V Acc: 0.4000, Top 70th Acc: 0.4416, Bottom 30th Acc: 0.3030
Fold [3/5] Epoch [10/100] Initial Loss: 0.1411, Training Loss: 0.0389, Initial Validation Loss: 0.1357, Validation Loss: 0.0411,V Acc: 0.8364, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.6667
Fold [3/5] Epoch [20/100] Initial Loss: 0.1411, Training Loss: 0.0196, Initial Validation Loss: 0.1357, Validation Loss: 0.0301,V Acc: 0.8545, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 28  Rolling back to Epoch (base 0): 23  Top Validation Acc: 0.974025974025974
Fold [4/5] Epoch [0/100] Initial Loss: 0.1397, Training Loss: 0.1397, Initial Validation Loss: 0.1374, Validation Loss: 0.1374,V Acc: 0.2477, Top 70th Acc: 0.3247, Bottom 30th Acc: 0.0625
Fold [4/5] Epoch [10/100] Initial Loss: 0.1397, Training Loss: 0.0358, Initial Validation Loss: 0.1374, Validation Loss: 0.0368,V Acc: 0.8716, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.6562
Fold [4/5] Epoch [20/100] Initial Loss: 0.1397, Training Loss: 0.0210, Initial Validation Loss: 0.1374, Validation Loss: 0.0232,V Acc: 0.8991, Top 70th Acc: 0.9870, Bottom 30th Acc: 0.6875
Fold [4/5] Epoch [30/100] Initial Loss: 0.1397, Training Loss: 0.0186, Initial Validation Loss: 0.1374, Validation Loss: 0.0220,V Acc: 0.9174, Top 70th Acc: 0.9870, Bottom 30th Acc: 0.7500
Stopping early at Epoch (base 0): 32  Rolling back to Epoch (base 0): 27  Top Validation Acc: 0.987012987012987
Fold [5/5] Epoch [0/100] Initial Loss: 0.1386, Training Loss: 0.1386, Initial Validation Loss: 0.1296, Validation Loss: 0.1296,V Acc: 0.2500, Top 70th Acc: 0.3289, Bottom 30th Acc: 0.0625
Fold [5/5] Epoch [10/100] Initial Loss: 0.1386, Training Loss: 0.0283, Initial Validation Loss: 0.1296, Validation Loss: 0.0345,V Acc: 0.8333, Top 70th Acc: 0.9079, Bottom 30th Acc: 0.6562
Fold [5/5] Epoch [20/100] Initial Loss: 0.1386, Training Loss: 0.0164, Initial Validation Loss: 0.1296, Validation Loss: 0.0316,V Acc: 0.8426, Top 70th Acc: 0.9079, Bottom 30th Acc: 0.6875
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.9078947368421053
Running train_nn.py with seed 71
CUDA:False
Training samples count:  550
Training on 30 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1380, Training Loss: 0.1380, Initial Validation Loss: 0.1362, Validation Loss: 0.1362,V Acc: 0.3125, Top 70th Acc: 0.3671, Bottom 30th Acc: 0.1818
Fold [1/5] Epoch [10/100] Initial Loss: 0.1380, Training Loss: 0.0281, Initial Validation Loss: 0.1362, Validation Loss: 0.0345,V Acc: 0.8571, Top 70th Acc: 0.9114, Bottom 30th Acc: 0.7273
Fold [1/5] Epoch [20/100] Initial Loss: 0.1380, Training Loss: 0.0171, Initial Validation Loss: 0.1362, Validation Loss: 0.0316,V Acc: 0.8661, Top 70th Acc: 0.9494, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 21  Rolling back to Epoch (base 0): 16  Top Validation Acc: 0.9367088607594937
Fold [2/5] Epoch [0/100] Initial Loss: 0.1410, Training Loss: 0.1410, Initial Validation Loss: 0.1321, Validation Loss: 0.1321,V Acc: 0.4054, Top 70th Acc: 0.5385, Bottom 30th Acc: 0.0909
Fold [2/5] Epoch [10/100] Initial Loss: 0.1410, Training Loss: 0.0497, Initial Validation Loss: 0.1321, Validation Loss: 0.0508,V Acc: 0.7387, Top 70th Acc: 0.8974, Bottom 30th Acc: 0.3636
Fold [2/5] Epoch [20/100] Initial Loss: 0.1410, Training Loss: 0.0260, Initial Validation Loss: 0.1321, Validation Loss: 0.0327,V Acc: 0.8649, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.6364
Fold [2/5] Epoch [30/100] Initial Loss: 0.1410, Training Loss: 0.0179, Initial Validation Loss: 0.1321, Validation Loss: 0.0282,V Acc: 0.8739, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 37  Rolling back to Epoch (base 0): 32  Top Validation Acc: 0.9615384615384616
Fold [3/5] Epoch [0/100] Initial Loss: 0.1430, Training Loss: 0.1430, Initial Validation Loss: 0.1328, Validation Loss: 0.1328,V Acc: 0.2364, Top 70th Acc: 0.2987, Bottom 30th Acc: 0.0909
Fold [3/5] Epoch [10/100] Initial Loss: 0.1430, Training Loss: 0.0356, Initial Validation Loss: 0.1328, Validation Loss: 0.0364,V Acc: 0.8182, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.6061
Fold [3/5] Epoch [20/100] Initial Loss: 0.1430, Training Loss: 0.0187, Initial Validation Loss: 0.1328, Validation Loss: 0.0308,V Acc: 0.8364, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.935064935064935
71 2 [array([0.75893205, 0.04651844, 0.04533988, 0.03900747, 0.11020222],
      dtype=float32)]
Fold [4/5] Epoch [0/100] Initial Loss: 0.1364, Training Loss: 0.1364, Initial Validation Loss: 0.1320, Validation Loss: 0.1320,V Acc: 0.4771, Top 70th Acc: 0.5065, Bottom 30th Acc: 0.4062
Fold [4/5] Epoch [10/100] Initial Loss: 0.1364, Training Loss: 0.0268, Initial Validation Loss: 0.1320, Validation Loss: 0.0316,V Acc: 0.8716, Top 70th Acc: 0.9870, Bottom 30th Acc: 0.5938
Fold [4/5] Epoch [20/100] Initial Loss: 0.1364, Training Loss: 0.0171, Initial Validation Loss: 0.1320, Validation Loss: 0.0294,V Acc: 0.8440, Top 70th Acc: 0.9870, Bottom 30th Acc: 0.5000
Stopping early at Epoch (base 0): 29  Rolling back to Epoch (base 0): 24  Top Validation Acc: 0.974025974025974
Fold [5/5] Epoch [0/100] Initial Loss: 0.1389, Training Loss: 0.1389, Initial Validation Loss: 0.1303, Validation Loss: 0.1303,V Acc: 0.3704, Top 70th Acc: 0.3684, Bottom 30th Acc: 0.3750
Fold [5/5] Epoch [10/100] Initial Loss: 0.1389, Training Loss: 0.0320, Initial Validation Loss: 0.1303, Validation Loss: 0.0450,V Acc: 0.7407, Top 70th Acc: 0.8816, Bottom 30th Acc: 0.4062
Fold [5/5] Epoch [20/100] Initial Loss: 0.1389, Training Loss: 0.0178, Initial Validation Loss: 0.1303, Validation Loss: 0.0342,V Acc: 0.8241, Top 70th Acc: 0.9211, Bottom 30th Acc: 0.5938
Fold [5/5] Epoch [30/100] Initial Loss: 0.1389, Training Loss: 0.0150, Initial Validation Loss: 0.1303, Validation Loss: 0.0333,V Acc: 0.8241, Top 70th Acc: 0.9079, Bottom 30th Acc: 0.6250
Stopping early at Epoch (base 0): 30  Rolling back to Epoch (base 0): 25  Top Validation Acc: 0.9078947368421053
Running train_nn.py with seed 72
CUDA:False
Training samples count:  550
Training on 30 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1397, Training Loss: 0.1397, Initial Validation Loss: 0.1338, Validation Loss: 0.1338,V Acc: 0.3304, Top 70th Acc: 0.4304, Bottom 30th Acc: 0.0909
Fold [1/5] Epoch [10/100] Initial Loss: 0.1397, Training Loss: 0.0411, Initial Validation Loss: 0.1338, Validation Loss: 0.0594,V Acc: 0.6964, Top 70th Acc: 0.7848, Bottom 30th Acc: 0.4848
Fold [1/5] Epoch [20/100] Initial Loss: 0.1397, Training Loss: 0.0188, Initial Validation Loss: 0.1338, Validation Loss: 0.0440,V Acc: 0.7679, Top 70th Acc: 0.8481, Bottom 30th Acc: 0.5758/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)

Fold [1/5] Epoch [20/100] Initial Loss: 0.1294, Training Loss: 0.0158, Initial Validation Loss: 0.1167, Validation Loss: 0.0297,V Acc: 0.8482, Top 70th Acc: 0.9241, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.9493670886075949
Fold [2/5] Epoch [0/100] Initial Loss: 0.1384, Training Loss: 0.1384, Initial Validation Loss: 0.1195, Validation Loss: 0.1195,V Acc: 0.6486, Top 70th Acc: 0.7821, Bottom 30th Acc: 0.3333
Fold [2/5] Epoch [10/100] Initial Loss: 0.1384, Training Loss: 0.0262, Initial Validation Loss: 0.1195, Validation Loss: 0.0267,V Acc: 0.8919, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.7273
Fold [2/5] Epoch [20/100] Initial Loss: 0.1384, Training Loss: 0.0162, Initial Validation Loss: 0.1195, Validation Loss: 0.0210,V Acc: 0.9099, Top 70th Acc: 0.9872, Bottom 30th Acc: 0.7273
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.9743589743589743
Fold [3/5] Epoch [0/100] Initial Loss: 0.1302, Training Loss: 0.1302, Initial Validation Loss: 0.1157, Validation Loss: 0.1157,V Acc: 0.4818, Top 70th Acc: 0.5974, Bottom 30th Acc: 0.2121
Fold [3/5] Epoch [10/100] Initial Loss: 0.1302, Training Loss: 0.0233, Initial Validation Loss: 0.1157, Validation Loss: 0.0285,V Acc: 0.8636, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 15  Rolling back to Epoch (base 0): 10  Top Validation Acc: 0.948051948051948
100 2 [array([0.7659614 , 0.01759873, 0.02789519, 0.1514046 , 0.03713991],
      dtype=float32)]
Fold [4/5] Epoch [0/100] Initial Loss: 0.1257, Training Loss: 0.1257, Initial Validation Loss: 0.1055, Validation Loss: 0.1055,V Acc: 0.6055, Top 70th Acc: 0.6753, Bottom 30th Acc: 0.4375
Fold [4/5] Epoch [10/100] Initial Loss: 0.1257, Training Loss: 0.0303, Initial Validation Loss: 0.1055, Validation Loss: 0.0308,V Acc: 0.8349, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.5000
Fold [4/5] Epoch [20/100] Initial Loss: 0.1257, Training Loss: 0.0172, Initial Validation Loss: 0.1055, Validation Loss: 0.0271,V Acc: 0.8807, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.7188
Fold [4/5] Epoch [30/100] Initial Loss: 0.1257, Training Loss: 0.0141, Initial Validation Loss: 0.1055, Validation Loss: 0.0226,V Acc: 0.8991, Top 70th Acc: 0.9870, Bottom 30th Acc: 0.6875
Stopping early at Epoch (base 0): 38  Rolling back to Epoch (base 0): 33  Top Validation Acc: 0.987012987012987
Fold [5/5] Epoch [0/100] Initial Loss: 0.1429, Training Loss: 0.1429, Initial Validation Loss: 0.1332, Validation Loss: 0.1332,V Acc: 0.2407, Top 70th Acc: 0.3026, Bottom 30th Acc: 0.0938
Fold [5/5] Epoch [10/100] Initial Loss: 0.1429, Training Loss: 0.0253, Initial Validation Loss: 0.1332, Validation Loss: 0.0334,V Acc: 0.8611, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.6875
Fold [5/5] Epoch [20/100] Initial Loss: 0.1429, Training Loss: 0.0170, Initial Validation Loss: 0.1332, Validation Loss: 0.0279,V Acc: 0.8519, Top 70th Acc: 0.9737, Bottom 30th Acc: 0.5625
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.9605263157894737

Fold [4/5] Epoch [10/100] Initial Loss: 0.1382, Training Loss: 0.0294, Initial Validation Loss: 0.1337, Validation Loss: 0.0400,V Acc: 0.7890, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.4688
Fold [4/5] Epoch [20/100] Initial Loss: 0.1382, Training Loss: 0.0144, Initial Validation Loss: 0.1337, Validation Loss: 0.0310,V Acc: 0.8349, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.5938
Fold [4/5] Epoch [30/100] Initial Loss: 0.1382, Training Loss: 0.0116, Initial Validation Loss: 0.1337, Validation Loss: 0.0316,V Acc: 0.8440, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.6250
Fold [4/5] Epoch [40/100] Initial Loss: 0.1382, Training Loss: 0.0104, Initial Validation Loss: 0.1337, Validation Loss: 0.0308,V Acc: 0.8349, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.6250
Stopping early at Epoch (base 0): 41  Rolling back to Epoch (base 0): 36  Top Validation Acc: 0.935064935064935
Fold [5/5] Epoch [0/100] Initial Loss: 0.1394, Training Loss: 0.1394, Initial Validation Loss: 0.1313, Validation Loss: 0.1313,V Acc: 0.2407, Top 70th Acc: 0.3026, Bottom 30th Acc: 0.0938
Fold [5/5] Epoch [10/100] Initial Loss: 0.1394, Training Loss: 0.0340, Initial Validation Loss: 0.1313, Validation Loss: 0.0326,V Acc: 0.8611, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.6250
Fold [5/5] Epoch [20/100] Initial Loss: 0.1394, Training Loss: 0.0184, Initial Validation Loss: 0.1313, Validation Loss: 0.0275,V Acc: 0.8704, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.6875
Stopping early at Epoch (base 0): 29  Rolling back to Epoch (base 0): 24  Top Validation Acc: 0.9473684210526315
Running train_nn.py with seed 74
CUDA:False
Training samples count:  550
Training on 40 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1391, Training Loss: 0.1391, Initial Validation Loss: 0.1365, Validation Loss: 0.1365,V Acc: 0.2946, Top 70th Acc: 0.2911, Bottom 30th Acc: 0.3030
Fold [1/5] Epoch [10/100] Initial Loss: 0.1391, Training Loss: 0.0376, Initial Validation Loss: 0.1365, Validation Loss: 0.0471,V Acc: 0.7054, Top 70th Acc: 0.8608, Bottom 30th Acc: 0.3333
Fold [1/5] Epoch [20/100] Initial Loss: 0.1391, Training Loss: 0.0138, Initial Validation Loss: 0.1365, Validation Loss: 0.0334,V Acc: 0.8214, Top 70th Acc: 0.9494, Bottom 30th Acc: 0.5152
Fold [1/5] Epoch [30/100] Initial Loss: 0.1391, Training Loss: 0.0106, Initial Validation Loss: 0.1365, Validation Loss: 0.0321,V Acc: 0.8393, Top 70th Acc: 0.9620, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 35  Rolling back to Epoch (base 0): 30  Top Validation Acc: 0.9620253164556962
Fold [2/5] Epoch [0/100] Initial Loss: 0.1474, Training Loss: 0.1474, Initial Validation Loss: 0.1387, Validation Loss: 0.1387,V Acc: 0.3153, Top 70th Acc: 0.3590, Bottom 30th Acc: 0.2121
Fold [2/5] Epoch [10/100] Initial Loss: 0.1474, Training Loss: 0.0223, Initial Validation Loss: 0.1387, Validation Loss: 0.0292,V Acc: 0.8198, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.4848
Stopping early at Epoch (base 0): 18  Rolling back to Epoch (base 0): 13  Top Validation Acc: 0.9871794871794872
Fold [3/5] Epoch [0/100] Initial Loss: 0.1441, Training Loss: 0.1441, Initial Validation Loss: 0.1344, Validation Loss: 0.1344,V Acc: 0.2364, Top 70th Acc: 0.2078, Bottom 30th Acc: 0.3030
Fold [3/5] Epoch [10/100] Initial Loss: 0.1441, Training Loss: 0.0431, Initial Validation Loss: 0.1344, Validation Loss: 0.0476,V Acc: 0.7545, Top 70th Acc: 0.8831, Bottom 30th Acc: 0.4545
Fold [3/5] Epoch [20/100] Initial Loss: 0.1441, Training Loss: 0.0153, Initial Validation Loss: 0.1344, Validation Loss: 0.0281,V Acc: 0.8364, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.948051948051948
Fold [4/5] Epoch [0/100] Initial Loss: 0.1372, Training Loss: 0.1372, Initial Validation Loss: 0.1314, Validation Loss: 0.1314,V Acc: 0.3853, Top 70th Acc: 0.3896, Bottom 30th Acc: 0.3750
Fold [4/5] Epoch [10/100] Initial Loss: 0.1372, Training Loss: 0.0230, Initial Validation Loss: 0.1314, Validation Loss: 0.0337,V Acc: 0.8440, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.5938
Fold [4/5] Epoch [20/100] Initial Loss: 0.1372, Training Loss: 0.0139, Initial Validation Loss: 0.1314, Validation Loss: 0.0311,V Acc: 0.8532, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6250
Stopping early at Epoch (base 0): 22  Rolling back to Epoch (base 0): 17  Top Validation Acc: 0.948051948051948
74 3 [array([0.55290097, 0.1305208 , 0.06831431, 0.11718573, 0.1310782 ],
      dtype=float32)]
Fold [5/5] Epoch [0/100] Initial Loss: 0.1397, Training Loss: 0.1397, Initial Validation Loss: 0.1339, Validation Loss: 0.1339,V Acc: 0.2500, Top 70th Acc: 0.2368, Bottom 30th Acc: 0.2812
Fold [5/5] Epoch [10/100] Initial Loss: 0.1397, Training Loss: 0.0347, Initial Validation Loss: 0.1339, Validation Loss: 0.0408,V Acc: 0.7870, Top 70th Acc: 0.9079, Bottom 30th Acc: 0.5000
Fold [5/5] Epoch [20/100] Initial Loss: 0.1397, Training Loss: 0.0163, Initial Validation Loss: 0.1339, Validation Loss: 0.0253,V Acc: 0.8981, Top 70th Acc: 0.9737, Bottom 30th Acc: 0.7188
Fold [5/5] Epoch [30/100] Initial Loss: 0.1397, Training Loss: 0.0128, Initial Validation Loss: 0.1339, Validation Loss: 0.0249,V Acc: 0.8889, Top 70th Acc: 0.9737, Bottom 30th Acc: 0.6875
Stopping early at Epoch (base 0): 31  Rolling back to Epoch (base 0): 26  Top Validation Acc: 0.9868421052631579
Running train_nn.py with seed 75
CUDA:False
Training samples count:  550
Training on 40 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1420, Training Loss: 0.1420, Initial Validation Loss: 0.1375, Validation Loss: 0.1375,V Acc: 0.2589, Top 70th Acc: 0.2658, Bottom 30th Acc: 0.2424
Fold [1/5] Epoch [10/100] Initial Loss: 0.1420, Training Loss: 0.0395, Initial Validation Loss: 0.1375, Validation Loss: 0.0450,V Acc: 0.7857, Top 70th Acc: 0.9114, Bottom 30th Acc: 0.4848
Fold [1/5] Epoch [20/100] Initial Loss: 0.1420, Training Loss: 0.0172, Initial Validation Loss: 0.1375, Validation Loss: 0.0321,V Acc: 0.8482, Top 70th Acc: 0.9367, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 27  Rolling back to Epoch (base 0): 22  Top Validation Acc: 0.9493670886075949
Fold [2/5] Epoch [0/100] Initial Loss: 0.1375, Training Loss: 0.1375, Initial Validation Loss: 0.1405, Validation Loss: 0.1405,V Acc: 0.3514, Top 70th Acc: 0.3462, Bottom 30th Acc: 0.3636
Fold [2/5] Epoch [10/100] Initial Loss: 0.1375, Training Loss: 0.0357, Initial Validation Loss: 0.1405, Validation Loss: 0.0432,V Acc: 0.7928, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.4242
Fold [2/5] Epoch [20/100] Initial Loss: 0.1375, Training Loss: 0.0147, Initial Validation Loss: 0.1405, Validation Loss: 0.0270,V Acc: 0.9099, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.7576
Fold [2/5] Epoch [30/100] Initial Loss: 0.1375, Training Loss: 0.0112, Initial Validation Loss: 0.1405, Validation Loss: 0.0262,V Acc: 0.8739, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 31  Rolling back to Epoch (base 0): 26  Top Validation Acc: 0.9871794871794872
Fold [3/5] Epoch [0/100] Initial Loss: 0.1436, Training Loss: 0.1436, Initial Validation Loss: 0.1313, Validation Loss: 0.1313,V Acc: 0.2636, Top 70th Acc: 0.3636, Bottom 30th Acc: 0.0303
Fold [3/5] Epoch [10/100] Initial Loss: 0.1436, Training Loss: 0.0251, Initial Validation Loss: 0.1313, Validation Loss: 0.0351,V Acc: 0.8182, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.5455
Fold [3/5] Epoch [20/100] Initial Loss: 0.1436, Training Loss: 0.0123, Initial Validation Loss: 0.1313, Validation Loss: 0.0348,V Acc: 0.8091, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.5152
Stopping early at Epoch (base 0): 20  Rolling back to Epoch (base 0): 15  Top Validation Acc: 0.935064935064935
Fold [4/5] Epoch [0/100] Initial Loss: 0.1424, Training Loss: 0.1424, Initial Validation Loss: 0.1312, Validation Loss: 0.1312,V Acc: 0.3945, Top 70th Acc: 0.4416, Bottom 30th Acc: 0.2812
Fold [4/5] Epoch [10/100] Initial Loss: 0.1424, Training Loss: 0.0326, Initial Validation Loss: 0.1312, Validation Loss: 0.0389,V Acc: 0.8073, Top 70th Acc: 0.8961, Bottom 30th Acc: 0.5938
Fold [4/5] Epoch [20/100] Initial Loss: 0.1424, Training Loss: 0.0168, Initial Validation Loss: 0.1312, Validation Loss: 0.0308,V Acc: 0.8440, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.5938
Fold [5/5] Epoch [10/100] Initial Loss: 0.1415, Training Loss: 0.0789, Initial Validation Loss: 0.1296, Validation Loss: 0.0843,V Acc: 0.5648, Top 70th Acc: 0.6842, Bottom 30th Acc: 0.2812
Fold [5/5] Epoch [20/100] Initial Loss: 0.1415, Training Loss: 0.0764, Initial Validation Loss: 0.1296, Validation Loss: 0.0838,V Acc: 0.5833, Top 70th Acc: 0.6842, Bottom 30th Acc: 0.3438
Fold [5/5] Epoch [30/100] Initial Loss: 0.1415, Training Loss: 0.0753, Initial Validation Loss: 0.1296, Validation Loss: 0.0841,V Acc: 0.5833, Top 70th Acc: 0.6842, Bottom 30th Acc: 0.3438
Stopping early at Epoch (base 0): 32  Rolling back to Epoch (base 0): 27  Top Validation Acc: 0.6842105263157895
Running train_nn.py with seed 72
CUDA:False
Training samples count:  550
Training on 2 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1386, Training Loss: 0.1386, Initial Validation Loss: 0.1306, Validation Loss: 0.1306,V Acc: 0.2679, Top 70th Acc: 0.3291, Bottom 30th Acc: 0.1212
Fold [1/5] Epoch [10/100] Initial Loss: 0.1386, Training Loss: 0.0806, Initial Validation Loss: 0.1306, Validation Loss: 0.0871,V Acc: 0.5804, Top 70th Acc: 0.6962, Bottom 30th Acc: 0.3030
Fold [1/5] Epoch [20/100] Initial Loss: 0.1386, Training Loss: 0.0776, Initial Validation Loss: 0.1306, Validation Loss: 0.0842,V Acc: 0.5982, Top 70th Acc: 0.6962, Bottom 30th Acc: 0.3636
Fold [1/5] Epoch [30/100] Initial Loss: 0.1386, Training Loss: 0.0766, Initial Validation Loss: 0.1306, Validation Loss: 0.0833,V Acc: 0.6071, Top 70th Acc: 0.7089, Bottom 30th Acc: 0.3636
Fold [1/5] Epoch [40/100] Initial Loss: 0.1386, Training Loss: 0.0761, Initial Validation Loss: 0.1306, Validation Loss: 0.0836,V Acc: 0.5982, Top 70th Acc: 0.7089, Bottom 30th Acc: 0.3333
Stopping early at Epoch (base 0): 41  Rolling back to Epoch (base 0): 36  Top Validation Acc: 0.7088607594936709
Fold [2/5] Epoch [0/100] Initial Loss: 0.1377, Training Loss: 0.1377, Initial Validation Loss: 0.1258, Validation Loss: 0.1258,V Acc: 0.3694, Top 70th Acc: 0.4744, Bottom 30th Acc: 0.1212
Fold [2/5] Epoch [10/100] Initial Loss: 0.1377, Training Loss: 0.0814, Initial Validation Loss: 0.1258, Validation Loss: 0.0770,V Acc: 0.6306, Top 70th Acc: 0.7051, Bottom 30th Acc: 0.4545
Fold [2/5] Epoch [20/100] Initial Loss: 0.1377, Training Loss: 0.0794, Initial Validation Loss: 0.1258, Validation Loss: 0.0757,V Acc: 0.6306, Top 70th Acc: 0.7051, Bottom 30th Acc: 0.4545
Fold [2/5] Epoch [30/100] Initial Loss: 0.1377, Training Loss: 0.0788, Initial Validation Loss: 0.1258, Validation Loss: 0.0752,V Acc: 0.6126, Top 70th Acc: 0.7179, Bottom 30th Acc: 0.3636
Stopping early at Epoch (base 0): 37  Rolling back to Epoch (base 0): 32  Top Validation Acc: 0.7051282051282052
Fold [3/5] Epoch [0/100] Initial Loss: 0.1367, Training Loss: 0.1367, Initial Validation Loss: 0.1280, Validation Loss: 0.1280,V Acc: 0.4182, Top 70th Acc: 0.5455, Bottom 30th Acc: 0.1212
Fold [3/5] Epoch [10/100] Initial Loss: 0.1367, Training Loss: 0.0789, Initial Validation Loss: 0.1280, Validation Loss: 0.0834,V Acc: 0.5909, Top 70th Acc: 0.7273, Bottom 30th Acc: 0.2727
Stopping early at Epoch (base 0): 16  Rolling back to Epoch (base 0): 11  Top Validation Acc: 0.7532467532467533
Fold [4/5] Epoch [0/100] Initial Loss: 0.1324, Training Loss: 0.1324, Initial Validation Loss: 0.1183, Validation Loss: 0.1183,V Acc: 0.5688, Top 70th Acc: 0.6104, Bottom 30th Acc: 0.4688
Fold [4/5] Epoch [10/100] Initial Loss: 0.1324, Training Loss: 0.0837, Initial Validation Loss: 0.1183, Validation Loss: 0.0690,V Acc: 0.7248, Top 70th Acc: 0.7792, Bottom 30th Acc: 0.5938
Fold [4/5] Epoch [20/100] Initial Loss: 0.1324, Training Loss: 0.0819, Initial Validation Loss: 0.1183, Validation Loss: 0.0668,V Acc: 0.7156, Top 70th Acc: 0.8052, Bottom 30th Acc: 0.5000
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.7922077922077922
Fold [5/5] Epoch [0/100] Initial Loss: 0.1400, Training Loss: 0.1400, Initial Validation Loss: 0.1333, Validation Loss: 0.1333,V Acc: 0.2593, Top 70th Acc: 0.3289, Bottom 30th Acc: 0.0938
Fold [5/5] Epoch [10/100] Initial Loss: 0.1400, Training Loss: 0.0801, Initial Validation Loss: 0.1333, Validation Loss: 0.0826,V Acc: 0.6296, Top 70th Acc: 0.7500, Bottom 30th Acc: 0.3438
Fold [5/5] Epoch [20/100] Initial Loss: 0.1400, Training Loss: 0.0782, Initial Validation Loss: 0.1333, Validation Loss: 0.0795,V Acc: 0.6296, Top 70th Acc: 0.7632, Bottom 30th Acc: 0.3125
Fold [5/5] Epoch [30/100] Initial Loss: 0.1400, Training Loss: 0.0774, Initial Validation Loss: 0.1333, Validation Loss: 0.0795,V Acc: 0.6204, Top 70th Acc: 0.7500, Bottom 30th Acc: 0.3125
Stopping early at Epoch (base 0): 38  Rolling back to Epoch (base 0): 33  Top Validation Acc: 0.7763157894736842
72 4 [array([0.10021289, 0.35254708, 0.13983414, 0.22587042, 0.18153545],
      dtype=float32)]
Running train_nn.py with seed 73
CUDA:False
Training samples count:  550
Training on 2 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1351, Training Loss: 0.1351, Initial Validation Loss: 0.1203, Validation Loss: 0.1203,V Acc: 0.4464, Top 70th Acc: 0.5823, Bottom 30th Acc: 0.1212
Fold [1/5] Epoch [10/100] Initial Loss: 0.1351, Training Loss: 0.0786, Initial Validation Loss: 0.1203, Validation Loss: 0.0853,V Acc: 0.6161, Top 70th Acc: 0.6835, Bottom 30th Acc: 0.4545
Stopping early at Epoch (base 0): 13  Rolling back to Epoch (base 0): 8  Top Validation Acc: 0.6708860759493671
Fold [2/5] Epoch [0/100] Initial Loss: 0.1372, Training Loss: 0.1372, Initial Validation Loss: 0.1327, Validation Loss: 0.1327,V Acc: 0.3514, Top 70th Acc: 0.4487, Bottom 30th Acc: 0.1212
Fold [2/5] Epoch [10/100] Initial Loss: 0.1372, Training Loss: 0.0819, Initial Validation Loss: 0.1327, Validation Loss: 0.0825,V Acc: 0.6486, Top 70th Acc: 0.7436, Bottom 30th Acc: 0.4242
Fold [2/5] Epoch [20/100] Initial Loss: 0.1372, Training Loss: 0.0793, Initial Validation Loss: 0.1327, Validation Loss: 0.0808,V Acc: 0.6216, Top 70th Acc: 0.7564, Bottom 30th Acc: 0.3030
Fold [2/5] Epoch [30/100] Initial Loss: 0.1372, Training Loss: 0.0784, Initial Validation Loss: 0.1327, Validation Loss: 0.0783,V Acc: 0.6396, Top 70th Acc: 0.7821, Bottom 30th Acc: 0.3030
Stopping early at Epoch (base 0): 33  Rolling back to Epoch (base 0): 28  Top Validation Acc: 0.7435897435897436
73 1 [array([0.11243834, 0.37924898, 0.16385803, 0.20058425, 0.14387032],
      dtype=float32)]
Fold [3/5] Epoch [0/100] Initial Loss: 0.1324, Training Loss: 0.1324, Initial Validation Loss: 0.1175, Validation Loss: 0.1175,V Acc: 0.5091, Top 70th Acc: 0.5584, Bottom 30th Acc: 0.3939
Fold [3/5] Epoch [10/100] Initial Loss: 0.1324, Training Loss: 0.0799, Initial Validation Loss: 0.1175, Validation Loss: 0.0806,V Acc: 0.5818, Top 70th Acc: 0.7273, Bottom 30th Acc: 0.2424
Fold [3/5] Epoch [20/100] Initial Loss: 0.1324, Training Loss: 0.0778, Initial Validation Loss: 0.1175, Validation Loss: 0.0794,V Acc: 0.6091, Top 70th Acc: 0.7273, Bottom 30th Acc: 0.3333
Fold [3/5] Epoch [30/100] Initial Loss: 0.1324, Training Loss: 0.0773, Initial Validation Loss: 0.1175, Validation Loss: 0.0792,V Acc: 0.6000, Top 70th Acc: 0.7143, Bottom 30th Acc: 0.3333
Fold [3/5] Epoch [40/100] Initial Loss: 0.1324, Training Loss: 0.0770, Initial Validation Loss: 0.1175, Validation Loss: 0.0789,V Acc: 0.6091, Top 70th Acc: 0.7273, Bottom 30th Acc: 0.3333
Stopping early at Epoch (base 0): 41  Rolling back to Epoch (base 0): 36  Top Validation Acc: 0.7272727272727273
Fold [4/5] Epoch [0/100] Initial Loss: 0.1332, Training Loss: 0.1332, Initial Validation Loss: 0.1230, Validation Loss: 0.1230,V Acc: 0.5229, Top 70th Acc: 0.6104, Bottom 30th Acc: 0.3125
Fold [4/5] Epoch [10/100] Initial Loss: 0.1332, Training Loss: 0.0809, Initial Validation Loss: 0.1230, Validation Loss: 0.0816,V Acc: 0.6055, Top 70th Acc: 0.7013, Bottom 30th Acc: 0.3750
Fold [4/5] Epoch [20/100] Initial Loss: 0.1332, Training Loss: 0.0795, Initial Validation Loss: 0.1230, Validation Loss: 0.0780,V Acc: 0.6330, Top 70th Acc: 0.7403, Bottom 30th Acc: 0.3750
Fold [4/5] Epoch [30/100] Initial Loss: 0.1332, Training Loss: 0.0792, Initial Validation Loss: 0.1230, Validation Loss: 0.0769,V Acc: 0.6330, Top 70th Acc: 0.7532, Bottom 30th Acc: 0.3438
Fold [4/5] Epoch [10/100] Initial Loss: 0.1382, Training Loss: 0.0341, Initial Validation Loss: 0.1313, Validation Loss: 0.0405,V Acc: 0.7706, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.4062
Fold [4/5] Epoch [20/100] Initial Loss: 0.1382, Training Loss: 0.0246, Initial Validation Loss: 0.1313, Validation Loss: 0.0359,V Acc: 0.8073, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.4688
Stopping early at Epoch (base 0): 27  Rolling back to Epoch (base 0): 22  Top Validation Acc: 0.922077922077922
Fold [5/5] Epoch [0/100] Initial Loss: 0.1375, Training Loss: 0.1375, Initial Validation Loss: 0.1319, Validation Loss: 0.1319,V Acc: 0.2500, Top 70th Acc: 0.3289, Bottom 30th Acc: 0.0625
Fold [5/5] Epoch [10/100] Initial Loss: 0.1375, Training Loss: 0.0379, Initial Validation Loss: 0.1319, Validation Loss: 0.0423,V Acc: 0.8056, Top 70th Acc: 0.9079, Bottom 30th Acc: 0.5625
Fold [5/5] Epoch [20/100] Initial Loss: 0.1375, Training Loss: 0.0265, Initial Validation Loss: 0.1319, Validation Loss: 0.0349,V Acc: 0.8426, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.5625
Fold [5/5] Epoch [30/100] Initial Loss: 0.1375, Training Loss: 0.0242, Initial Validation Loss: 0.1319, Validation Loss: 0.0318,V Acc: 0.8519, Top 70th Acc: 0.9737, Bottom 30th Acc: 0.5625
Stopping early at Epoch (base 0): 39  Rolling back to Epoch (base 0): 34  Top Validation Acc: 0.9605263157894737
72 4 [array([0.5840465 , 0.04952782, 0.08239765, 0.14802308, 0.13600494],
      dtype=float32)]
Running train_nn.py with seed 73
CUDA:False
Training samples count:  550
Training on 20 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1382, Training Loss: 0.1382, Initial Validation Loss: 0.1346, Validation Loss: 0.1346,V Acc: 0.2589, Top 70th Acc: 0.3418, Bottom 30th Acc: 0.0606
Fold [1/5] Epoch [10/100] Initial Loss: 0.1382, Training Loss: 0.0482, Initial Validation Loss: 0.1346, Validation Loss: 0.0535,V Acc: 0.7589, Top 70th Acc: 0.8481, Bottom 30th Acc: 0.5455
Fold [1/5] Epoch [20/100] Initial Loss: 0.1382, Training Loss: 0.0321, Initial Validation Loss: 0.1346, Validation Loss: 0.0439,V Acc: 0.7857, Top 70th Acc: 0.8734, Bottom 30th Acc: 0.5758
Fold [1/5] Epoch [30/100] Initial Loss: 0.1382, Training Loss: 0.0234, Initial Validation Loss: 0.1346, Validation Loss: 0.0360,V Acc: 0.8214, Top 70th Acc: 0.9241, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 37  Rolling back to Epoch (base 0): 32  Top Validation Acc: 0.9113924050632911
Fold [2/5] Epoch [0/100] Initial Loss: 0.1365, Training Loss: 0.1365, Initial Validation Loss: 0.1341, Validation Loss: 0.1341,V Acc: 0.2703, Top 70th Acc: 0.3590, Bottom 30th Acc: 0.0606
Fold [2/5] Epoch [10/100] Initial Loss: 0.1365, Training Loss: 0.0377, Initial Validation Loss: 0.1341, Validation Loss: 0.0461,V Acc: 0.7477, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.3636
Fold [2/5] Epoch [20/100] Initial Loss: 0.1365, Training Loss: 0.0241, Initial Validation Loss: 0.1341, Validation Loss: 0.0392,V Acc: 0.7748, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.4242
Fold [2/5] Epoch [30/100] Initial Loss: 0.1365, Training Loss: 0.0198, Initial Validation Loss: 0.1341, Validation Loss: 0.0366,V Acc: 0.7928, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.4545
Stopping early at Epoch (base 0): 36  Rolling back to Epoch (base 0): 31  Top Validation Acc: 0.9358974358974359
73 1 [array([0.54330254, 0.05929534, 0.11269778, 0.16001481, 0.12468959],
      dtype=float32)]
Fold [3/5] Epoch [0/100] Initial Loss: 0.1387, Training Loss: 0.1387, Initial Validation Loss: 0.1272, Validation Loss: 0.1272,V Acc: 0.4000, Top 70th Acc: 0.5325, Bottom 30th Acc: 0.0909
Fold [3/5] Epoch [10/100] Initial Loss: 0.1387, Training Loss: 0.0329, Initial Validation Loss: 0.1272, Validation Loss: 0.0371,V Acc: 0.8273, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.5758
Fold [3/5] Epoch [20/100] Initial Loss: 0.1387, Training Loss: 0.0233, Initial Validation Loss: 0.1272, Validation Loss: 0.0291,V Acc: 0.8727, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6970
Fold [3/5] Epoch [30/100] Initial Loss: 0.1387, Training Loss: 0.0210, Initial Validation Loss: 0.1272, Validation Loss: 0.0297,V Acc: 0.8636, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.7273
Stopping early at Epoch (base 0): 30  Rolling back to Epoch (base 0): 25  Top Validation Acc: 0.922077922077922
Fold [4/5] Epoch [0/100] Initial Loss: 0.1418, Training Loss: 0.1418, Initial Validation Loss: 0.1344, Validation Loss: 0.1344,V Acc: 0.3394, Top 70th Acc: 0.4026, Bottom 30th Acc: 0.1875
Fold [4/5] Epoch [10/100] Initial Loss: 0.1418, Training Loss: 0.0335, Initial Validation Loss: 0.1344, Validation Loss: 0.0470,V Acc: 0.7890, Top 70th Acc: 0.8701, Bottom 30th Acc: 0.5938
Fold [4/5] Epoch [20/100] Initial Loss: 0.1418, Training Loss: 0.0209, Initial Validation Loss: 0.1344, Validation Loss: 0.0395,V Acc: 0.8165, Top 70th Acc: 0.8831, Bottom 30th Acc: 0.6562
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.8831168831168831
Fold [5/5] Epoch [0/100] Initial Loss: 0.1411, Training Loss: 0.1411, Initial Validation Loss: 0.1317, Validation Loss: 0.1317,V Acc: 0.3056, Top 70th Acc: 0.3684, Bottom 30th Acc: 0.1562
Fold [5/5] Epoch [10/100] Initial Loss: 0.1411, Training Loss: 0.0496, Initial Validation Loss: 0.1317, Validation Loss: 0.0439,V Acc: 0.7963, Top 70th Acc: 0.9079, Bottom 30th Acc: 0.5312
Fold [5/5] Epoch [20/100] Initial Loss: 0.1411, Training Loss: 0.0238, Initial Validation Loss: 0.1317, Validation Loss: 0.0261,V Acc: 0.8889, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.7500
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.9342105263157895
Running train_nn.py with seed 74
CUDA:False
Training samples count:  550
Training on 20 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1406, Training Loss: 0.1406, Initial Validation Loss: 0.1349, Validation Loss: 0.1349,V Acc: 0.3304, Top 70th Acc: 0.3291, Bottom 30th Acc: 0.3333
Fold [1/5] Epoch [10/100] Initial Loss: 0.1406, Training Loss: 0.0323, Initial Validation Loss: 0.1349, Validation Loss: 0.0371,V Acc: 0.7946, Top 70th Acc: 0.9494, Bottom 30th Acc: 0.4242
Stopping early at Epoch (base 0): 19  Rolling back to Epoch (base 0): 14  Top Validation Acc: 0.9367088607594937
Fold [2/5] Epoch [0/100] Initial Loss: 0.1412, Training Loss: 0.1412, Initial Validation Loss: 0.1368, Validation Loss: 0.1368,V Acc: 0.2523, Top 70th Acc: 0.3333, Bottom 30th Acc: 0.0606
Fold [2/5] Epoch [10/100] Initial Loss: 0.1412, Training Loss: 0.0473, Initial Validation Loss: 0.1368, Validation Loss: 0.0462,V Acc: 0.7928, Top 70th Acc: 0.8974, Bottom 30th Acc: 0.5455
Fold [2/5] Epoch [20/100] Initial Loss: 0.1412, Training Loss: 0.0260, Initial Validation Loss: 0.1368, Validation Loss: 0.0313,V Acc: 0.8468, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.6061
Fold [2/5] Epoch [30/100] Initial Loss: 0.1412, Training Loss: 0.0235, Initial Validation Loss: 0.1368, Validation Loss: 0.0305,V Acc: 0.8468, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 34  Rolling back to Epoch (base 0): 29  Top Validation Acc: 0.9487179487179487
Fold [3/5] Epoch [0/100] Initial Loss: 0.1355, Training Loss: 0.1355, Initial Validation Loss: 0.1248, Validation Loss: 0.1248,V Acc: 0.4000, Top 70th Acc: 0.4935, Bottom 30th Acc: 0.1818
Fold [3/5] Epoch [10/100] Initial Loss: 0.1355, Training Loss: 0.0299, Initial Validation Loss: 0.1248, Validation Loss: 0.0367,V Acc: 0.8364, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 17  Rolling back to Epoch (base 0): 12  Top Validation Acc: 0.8831168831168831
Fold [4/5] Epoch [0/100] Initial Loss: 0.1397, Training Loss: 0.1397, Initial Validation Loss: 0.1321, Validation Loss: 0.1321,V Acc: 0.3211, Top 70th Acc: 0.3506, Bottom 30th Acc: 0.2500
Fold [4/5] Epoch [10/100] Initial Loss: 0.1397, Training Loss: 0.0480, Initial Validation Loss: 0.1321, Validation Loss: 0.0611,V Acc: 0.7523, Top 70th Acc: 0.8182, Bottom 30th Acc: 0.5938
Fold [4/5] Epoch [20/100] Initial Loss: 0.1397, Training Loss: 0.0324, Initial Validation Loss: 0.1321, Validation Loss: 0.0500,V Acc: 0.7890, Top 70th Acc: 0.8961, Bottom 30th Acc: 0.5312
Fold [4/5] Epoch [30/100] Initial Loss: 0.1397, Training Loss: 0.0283, Initial Validation Loss: 0.1321, Validation Loss: 0.0475,V Acc: 0.7706, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.4062
Stopping early at Epoch (base 0): 40  Rolling back to Epoch (base 0): 35  Top Validation Acc: 0.948051948051948
Fold [5/5] Epoch [0/100] Initial Loss: 0.1401, Training Loss: 0.1401, Initial Validation Loss: 0.1343, Validation Loss: 0.1343,V Acc: 0.2500, Top 70th Acc: 0.3421, Bottom 30th Acc: 0.0312
Fold [5/5] Epoch [10/100] Initial Loss: 0.1401, Training Loss: 0.0305, Initial Validation Loss: 0.1343, Validation Loss: 0.0505,V Acc: 0.7778, Top 70th Acc: 0.8684, Bottom 30th Acc: 0.5625
Fold [5/5] Epoch [20/100] Initial Loss: 0.1401, Training Loss: 0.0062, Initial Validation Loss: 0.1343, Validation Loss: 0.0342,V Acc: 0.8611, Top 70th Acc: 0.9211, Bottom 30th Acc: 0.7188
Fold [5/5] Epoch [30/100] Initial Loss: 0.1401, Training Loss: 0.0045, Initial Validation Loss: 0.1343, Validation Loss: 0.0327,V Acc: 0.8426, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.5938
Fold [5/5] Epoch [40/100] Initial Loss: 0.1401, Training Loss: 0.0041, Initial Validation Loss: 0.1343, Validation Loss: 0.0323,V Acc: 0.8426, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.5938
Stopping early at Epoch (base 0): 48  Rolling back to Epoch (base 0): 43  Top Validation Acc: 0.9473684210526315
55 4 [array([0.22474597, 0.06798897, 0.1031096 , 0.41020513, 0.19395033],
      dtype=float32)]
Running train_nn.py with seed 56
CUDA:False
Training samples count:  550
Training on 162 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1398, Training Loss: 0.1398, Initial Validation Loss: 0.1354, Validation Loss: 0.1354,V Acc: 0.2768, Top 70th Acc: 0.3038, Bottom 30th Acc: 0.2121
Fold [1/5] Epoch [10/100] Initial Loss: 0.1398, Training Loss: 0.0178, Initial Validation Loss: 0.1354, Validation Loss: 0.0281,V Acc: 0.8571, Top 70th Acc: 0.9620, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 19  Rolling back to Epoch (base 0): 14  Top Validation Acc: 0.9620253164556962
Fold [2/5] Epoch [0/100] Initial Loss: 0.1371, Training Loss: 0.1371, Initial Validation Loss: 0.1301, Validation Loss: 0.1301,V Acc: 0.3784, Top 70th Acc: 0.4103, Bottom 30th Acc: 0.3030
Fold [2/5] Epoch [10/100] Initial Loss: 0.1371, Training Loss: 0.0191, Initial Validation Loss: 0.1301, Validation Loss: 0.0332,V Acc: 0.8288, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.5455
Fold [2/5] Epoch [20/100] Initial Loss: 0.1371, Training Loss: 0.0060, Initial Validation Loss: 0.1301, Validation Loss: 0.0278,V Acc: 0.8468, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.5455
Fold [2/5] Epoch [30/100] Initial Loss: 0.1371, Training Loss: 0.0045, Initial Validation Loss: 0.1301, Validation Loss: 0.0263,V Acc: 0.8468, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.5758
Fold [2/5] Epoch [40/100] Initial Loss: 0.1371, Training Loss: 0.0041, Initial Validation Loss: 0.1301, Validation Loss: 0.0257,V Acc: 0.8468, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.5455
Fold [2/5] Epoch [50/100] Initial Loss: 0.1371, Training Loss: 0.0040, Initial Validation Loss: 0.1301, Validation Loss: 0.0247,V Acc: 0.8559, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.5758
Fold [2/5] Epoch [60/100] Initial Loss: 0.1371, Training Loss: 0.0039, Initial Validation Loss: 0.1301, Validation Loss: 0.0243,V Acc: 0.8649, Top 70th Acc: 0.9872, Bottom 30th Acc: 0.5758
Fold [2/5] Epoch [70/100] Initial Loss: 0.1371, Training Loss: 0.0038, Initial Validation Loss: 0.1301, Validation Loss: 0.0241,V Acc: 0.8739, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 70  Rolling back to Epoch (base 0): 65  Top Validation Acc: 0.9743589743589743
Fold [3/5] Epoch [0/100] Initial Loss: 0.1388, Training Loss: 0.1388, Initial Validation Loss: 0.1314, Validation Loss: 0.1314,V Acc: 0.2545, Top 70th Acc: 0.3377, Bottom 30th Acc: 0.0606
Fold [3/5] Epoch [10/100] Initial Loss: 0.1388, Training Loss: 0.0141, Initial Validation Loss: 0.1314, Validation Loss: 0.0332,V Acc: 0.8455, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 18  Rolling back to Epoch (base 0): 13  Top Validation Acc: 0.948051948051948
Fold [4/5] Epoch [0/100] Initial Loss: 0.1383, Training Loss: 0.1383, Initial Validation Loss: 0.1348, Validation Loss: 0.1348,V Acc: 0.3761, Top 70th Acc: 0.4416, Bottom 30th Acc: 0.2188
Fold [4/5] Epoch [10/100] Initial Loss: 0.1383, Training Loss: 0.0129, Initial Validation Loss: 0.1348, Validation Loss: 0.0374,V Acc: 0.7982, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.5000
Fold [4/5] Epoch [20/100] Initial Loss: 0.1383, Training Loss: 0.0048, Initial Validation Loss: 0.1348, Validation Loss: 0.0354,V Acc: 0.8073, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.5312
Fold [4/5] Epoch [30/100] Initial Loss: 0.1383, Training Loss: 0.0038, Initial Validation Loss: 0.1348, Validation Loss: 0.0334,V Acc: 0.8165, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.5312
Fold [4/5] Epoch [40/100] Initial Loss: 0.1383, Training Loss: 0.0035, Initial Validation Loss: 0.1348, Validation Loss: 0.0324,V Acc: 0.8257, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.5312
Fold [4/5] Epoch [50/100] Initial Loss: 0.1383, Training Loss: 0.0033, Initial Validation Loss: 0.1348, Validation Loss: 0.0327,V Acc: 0.8349, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.5625
Stopping early at Epoch (base 0): 59  Rolling back to Epoch (base 0): 54  Top Validation Acc: 0.948051948051948
56 3 [array([0.14698733, 0.03746026, 0.06959887, 0.24895588, 0.49699762],
      dtype=float32)]
Fold [5/5] Epoch [0/100] Initial Loss: 0.1387, Training Loss: 0.1387, Initial Validation Loss: 0.1299, Validation Loss: 0.1299,V Acc: 0.3889, Top 70th Acc: 0.4342, Bottom 30th Acc: 0.2812
Fold [5/5] Epoch [10/100] Initial Loss: 0.1387, Training Loss: 0.0224, Initial Validation Loss: 0.1299, Validation Loss: 0.0453,V Acc: 0.7593, Top 70th Acc: 0.8816, Bottom 30th Acc: 0.4688
Fold [5/5] Epoch [20/100] Initial Loss: 0.1387, Training Loss: 0.0060, Initial Validation Loss: 0.1299, Validation Loss: 0.0352,V Acc: 0.8611, Top 70th Acc: 0.9211, Bottom 30th Acc: 0.7188
Fold [5/5] Epoch [30/100] Initial Loss: 0.1387, Training Loss: 0.0042, Initial Validation Loss: 0.1299, Validation Loss: 0.0340,V Acc: 0.8611, Top 70th Acc: 0.9211, Bottom 30th Acc: 0.7188
Fold [5/5] Epoch [40/100] Initial Loss: 0.1387, Training Loss: 0.0038, Initial Validation Loss: 0.1299, Validation Loss: 0.0332,V Acc: 0.8611, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.6875
Stopping early at Epoch (base 0): 41  Rolling back to Epoch (base 0): 36  Top Validation Acc: 0.9210526315789473
Running train_nn.py with seed 57
CUDA:False
Training samples count:  550
Training on 162 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1388, Training Loss: 0.1388, Initial Validation Loss: 0.1350, Validation Loss: 0.1350,V Acc: 0.3393, Top 70th Acc: 0.3544, Bottom 30th Acc: 0.3030
Fold [1/5] Epoch [10/100] Initial Loss: 0.1388, Training Loss: 0.0156, Initial Validation Loss: 0.1350, Validation Loss: 0.0372,V Acc: 0.8125, Top 70th Acc: 0.9114, Bottom 30th Acc: 0.5758
Fold [1/5] Epoch [20/100] Initial Loss: 0.1388, Training Loss: 0.0044, Initial Validation Loss: 0.1350, Validation Loss: 0.0322,V Acc: 0.8393, Top 70th Acc: 0.9620, Bottom 30th Acc: 0.5455
Fold [1/5] Epoch [30/100] Initial Loss: 0.1388, Training Loss: 0.0037, Initial Validation Loss: 0.1350, Validation Loss: 0.0325,V Acc: 0.8304, Top 70th Acc: 0.9620, Bottom 30th Acc: 0.5152
Stopping early at Epoch (base 0): 32  Rolling back to Epoch (base 0): 27  Top Validation Acc: 0.9620253164556962
Fold [2/5] Epoch [0/100] Initial Loss: 0.1390, Training Loss: 0.1390, Initial Validation Loss: 0.1343, Validation Loss: 0.1343,V Acc: 0.4414, Top 70th Acc: 0.5513, Bottom 30th Acc: 0.1818
Fold [2/5] Epoch [10/100] Initial Loss: 0.1390, Training Loss: 0.0226, Initial Validation Loss: 0.1343, Validation Loss: 0.0364,V Acc: 0.8559, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.6667
Fold [2/5] Epoch [20/100] Initial Loss: 0.1390, Training Loss: 0.0052, Initial Validation Loss: 0.1343, Validation Loss: 0.0283,V Acc: 0.8468, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.9487179487179487
Fold [3/5] Epoch [0/100] Initial Loss: 0.1409, Training Loss: 0.1409, Initial Validation Loss: 0.1314, Validation Loss: 0.1314,V Acc: 0.2909, Top 70th Acc: 0.3636, Bottom 30th Acc: 0.1212
Stopping early at Epoch (base 0): 28  Rolling back to Epoch (base 0): 23  Top Validation Acc: 0.8607594936708861
Fold [2/5] Epoch [0/100] Initial Loss: 0.1400, Training Loss: 0.1400, Initial Validation Loss: 0.1338, Validation Loss: 0.1338,V Acc: 0.3243, Top 70th Acc: 0.3333, Bottom 30th Acc: 0.3030
Fold [2/5] Epoch [10/100] Initial Loss: 0.1400, Training Loss: 0.0358, Initial Validation Loss: 0.1338, Validation Loss: 0.0341,V Acc: 0.8559, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.6364
Fold [2/5] Epoch [20/100] Initial Loss: 0.1400, Training Loss: 0.0201, Initial Validation Loss: 0.1338, Validation Loss: 0.0301,V Acc: 0.8288, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 21  Rolling back to Epoch (base 0): 16  Top Validation Acc: 0.9358974358974359
Fold [3/5] Epoch [0/100] Initial Loss: 0.1404, Training Loss: 0.1404, Initial Validation Loss: 0.1346, Validation Loss: 0.1346,V Acc: 0.3273, Top 70th Acc: 0.3636, Bottom 30th Acc: 0.2424
Fold [3/5] Epoch [10/100] Initial Loss: 0.1404, Training Loss: 0.0421, Initial Validation Loss: 0.1346, Validation Loss: 0.0476,V Acc: 0.8182, Top 70th Acc: 0.8571, Bottom 30th Acc: 0.7273
Fold [3/5] Epoch [20/100] Initial Loss: 0.1404, Training Loss: 0.0237, Initial Validation Loss: 0.1346, Validation Loss: 0.0367,V Acc: 0.8182, Top 70th Acc: 0.8961, Bottom 30th Acc: 0.6364
Fold [3/5] Epoch [30/100] Initial Loss: 0.1404, Training Loss: 0.0186, Initial Validation Loss: 0.1346, Validation Loss: 0.0333,V Acc: 0.8455, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 32  Rolling back to Epoch (base 0): 27  Top Validation Acc: 0.922077922077922
Fold [4/5] Epoch [0/100] Initial Loss: 0.1378, Training Loss: 0.1378, Initial Validation Loss: 0.1337, Validation Loss: 0.1337,V Acc: 0.3028, Top 70th Acc: 0.3766, Bottom 30th Acc: 0.1250
Fold [4/5] Epoch [10/100] Initial Loss: 0.1378, Training Loss: 0.0313, Initial Validation Loss: 0.1337, Validation Loss: 0.0404,V Acc: 0.7890, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.4688
Fold [4/5] Epoch [20/100] Initial Loss: 0.1378, Training Loss: 0.0201, Initial Validation Loss: 0.1337, Validation Loss: 0.0348,V Acc: 0.7890, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.4062
Fold [4/5] Epoch [30/100] Initial Loss: 0.1378, Training Loss: 0.0180, Initial Validation Loss: 0.1337, Validation Loss: 0.0346,V Acc: 0.7982, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.4688
Stopping early at Epoch (base 0): 39  Rolling back to Epoch (base 0): 34  Top Validation Acc: 0.935064935064935
Fold [5/5] Epoch [0/100] Initial Loss: 0.1414, Training Loss: 0.1414, Initial Validation Loss: 0.1345, Validation Loss: 0.1345,V Acc: 0.2963, Top 70th Acc: 0.3421, Bottom 30th Acc: 0.1875
Fold [5/5] Epoch [10/100] Initial Loss: 0.1414, Training Loss: 0.0447, Initial Validation Loss: 0.1345, Validation Loss: 0.0502,V Acc: 0.7685, Top 70th Acc: 0.8816, Bottom 30th Acc: 0.5000
Fold [5/5] Epoch [20/100] Initial Loss: 0.1414, Training Loss: 0.0228, Initial Validation Loss: 0.1345, Validation Loss: 0.0312,V Acc: 0.8889, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.7188
Fold [5/5] Epoch [30/100] Initial Loss: 0.1414, Training Loss: 0.0192, Initial Validation Loss: 0.1345, Validation Loss: 0.0287,V Acc: 0.9074, Top 70th Acc: 0.9868, Bottom 30th Acc: 0.7188
Stopping early at Epoch (base 0): 31  Rolling back to Epoch (base 0): 26  Top Validation Acc: 0.9868421052631579
72 4 [array([0.6976432 , 0.04504946, 0.07271302, 0.08987451, 0.09471976],
      dtype=float32)]
Running train_nn.py with seed 73
CUDA:False
Training samples count:  550
Training on 30 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1382, Training Loss: 0.1382, Initial Validation Loss: 0.1332, Validation Loss: 0.1332,V Acc: 0.3661, Top 70th Acc: 0.4557, Bottom 30th Acc: 0.1515
Fold [1/5] Epoch [10/100] Initial Loss: 0.1382, Training Loss: 0.0324, Initial Validation Loss: 0.1332, Validation Loss: 0.0385,V Acc: 0.8214, Top 70th Acc: 0.9494, Bottom 30th Acc: 0.5152
Fold [1/5] Epoch [20/100] Initial Loss: 0.1382, Training Loss: 0.0195, Initial Validation Loss: 0.1332, Validation Loss: 0.0306,V Acc: 0.8393, Top 70th Acc: 0.9494, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 28  Rolling back to Epoch (base 0): 23  Top Validation Acc: 0.9367088607594937
Fold [2/5] Epoch [0/100] Initial Loss: 0.1419, Training Loss: 0.1419, Initial Validation Loss: 0.1379, Validation Loss: 0.1379,V Acc: 0.2973, Top 70th Acc: 0.3205, Bottom 30th Acc: 0.2424
Fold [2/5] Epoch [10/100] Initial Loss: 0.1419, Training Loss: 0.0319, Initial Validation Loss: 0.1379, Validation Loss: 0.0382,V Acc: 0.8198, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.5152
Fold [2/5] Epoch [20/100] Initial Loss: 0.1419, Training Loss: 0.0185, Initial Validation Loss: 0.1379, Validation Loss: 0.0328,V Acc: 0.8288, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 27  Rolling back to Epoch (base 0): 22  Top Validation Acc: 0.9358974358974359
73 1 [array([0.7206036 , 0.08700459, 0.03828675, 0.10117675, 0.05292843],
      dtype=float32)]
Fold [3/5] Epoch [0/100] Initial Loss: 0.1406, Training Loss: 0.1406, Initial Validation Loss: 0.1319, Validation Loss: 0.1319,V Acc: 0.2455, Top 70th Acc: 0.3117, Bottom 30th Acc: 0.0909
Fold [3/5] Epoch [10/100] Initial Loss: 0.1406, Training Loss: 0.0274, Initial Validation Loss: 0.1319, Validation Loss: 0.0336,V Acc: 0.8364, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.6364
Fold [3/5] Epoch [20/100] Initial Loss: 0.1406, Training Loss: 0.0185, Initial Validation Loss: 0.1319, Validation Loss: 0.0302,V Acc: 0.8273, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.5455
Fold [3/5] Epoch [30/100] Initial Loss: 0.1406, Training Loss: 0.0164, Initial Validation Loss: 0.1319, Validation Loss: 0.0299,V Acc: 0.8455, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 31  Rolling back to Epoch (base 0): 26  Top Validation Acc: 0.935064935064935
Fold [4/5] Epoch [0/100] Initial Loss: 0.1391, Training Loss: 0.1391, Initial Validation Loss: 0.1343, Validation Loss: 0.1343,V Acc: 0.2477, Top 70th Acc: 0.3117, Bottom 30th Acc: 0.0938
Fold [4/5] Epoch [10/100] Initial Loss: 0.1391, Training Loss: 0.0314, Initial Validation Loss: 0.1343, Validation Loss: 0.0421,V Acc: 0.8165, Top 70th Acc: 0.8961, Bottom 30th Acc: 0.6250
Fold [4/5] Epoch [20/100] Initial Loss: 0.1391, Training Loss: 0.0190, Initial Validation Loss: 0.1343, Validation Loss: 0.0349,V Acc: 0.8073, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.5312
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.922077922077922
Fold [5/5] Epoch [0/100] Initial Loss: 0.1407, Training Loss: 0.1407, Initial Validation Loss: 0.1319, Validation Loss: 0.1319,V Acc: 0.3519, Top 70th Acc: 0.3947, Bottom 30th Acc: 0.2500
Fold [5/5] Epoch [10/100] Initial Loss: 0.1407, Training Loss: 0.0340, Initial Validation Loss: 0.1319, Validation Loss: 0.0323,V Acc: 0.8426, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.5625
Fold [5/5] Epoch [20/100] Initial Loss: 0.1407, Training Loss: 0.0192, Initial Validation Loss: 0.1319, Validation Loss: 0.0260,V Acc: 0.8889, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.7188
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.9605263157894737
Running train_nn.py with seed 74
CUDA:False
Training samples count:  550
Training on 30 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1433, Training Loss: 0.1433, Initial Validation Loss: 0.1355, Validation Loss: 0.1355,V Acc: 0.3482, Top 70th Acc: 0.4304, Bottom 30th Acc: 0.1515
Fold [1/5] Epoch [10/100] Initial Loss: 0.1433, Training Loss: 0.0413, Initial Validation Loss: 0.1355, Validation Loss: 0.0499,V Acc: 0.7500, Top 70th Acc: 0.8354, Bottom 30th Acc: 0.5455
Fold [1/5] Epoch [20/100] Initial Loss: 0.1433, Training Loss: 0.0186, Initial Validation Loss: 0.1355, Validation Loss: 0.0335,V Acc: 0.8125, Top 70th Acc: 0.9367, Bottom 30th Acc: 0.5152
Stopping early at Epoch (base 0): 28  Rolling back to Epoch (base 0): 23  Top Validation Acc: 0.9367088607594937
Fold [2/5] Epoch [0/100] Initial Loss: 0.1381, Training Loss: 0.1381, Initial Validation Loss: 0.1348, Validation Loss: 0.1348,V Acc: 0.3514, Top 70th Acc: 0.3590, Bottom 30th Acc: 0.3333
Fold [4/5] Epoch [30/100] Initial Loss: 0.1424, Training Loss: 0.0129, Initial Validation Loss: 0.1312, Validation Loss: 0.0285,V Acc: 0.8440, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.5938
Stopping early at Epoch (base 0): 38  Rolling back to Epoch (base 0): 33  Top Validation Acc: 0.961038961038961
75 3 [array([0.30885392, 0.08795875, 0.06744912, 0.10858261, 0.42715558],
      dtype=float32)]
Fold [5/5] Epoch [0/100] Initial Loss: 0.1401, Training Loss: 0.1401, Initial Validation Loss: 0.1258, Validation Loss: 0.1258,V Acc: 0.3148, Top 70th Acc: 0.3553, Bottom 30th Acc: 0.2188
Fold [5/5] Epoch [10/100] Initial Loss: 0.1401, Training Loss: 0.0248, Initial Validation Loss: 0.1258, Validation Loss: 0.0324,V Acc: 0.8426, Top 70th Acc: 0.9211, Bottom 30th Acc: 0.6562
Fold [5/5] Epoch [20/100] Initial Loss: 0.1401, Training Loss: 0.0143, Initial Validation Loss: 0.1258, Validation Loss: 0.0288,V Acc: 0.8333, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.5938
Stopping early at Epoch (base 0): 29  Rolling back to Epoch (base 0): 24  Top Validation Acc: 0.9210526315789473
Running train_nn.py with seed 76
CUDA:False
Training samples count:  550
Training on 40 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1374, Training Loss: 0.1374, Initial Validation Loss: 0.1341, Validation Loss: 0.1341,V Acc: 0.3929, Top 70th Acc: 0.4177, Bottom 30th Acc: 0.3333
Fold [1/5] Epoch [10/100] Initial Loss: 0.1374, Training Loss: 0.0299, Initial Validation Loss: 0.1341, Validation Loss: 0.0417,V Acc: 0.8125, Top 70th Acc: 0.9114, Bottom 30th Acc: 0.5758
Fold [1/5] Epoch [20/100] Initial Loss: 0.1374, Training Loss: 0.0153, Initial Validation Loss: 0.1341, Validation Loss: 0.0329,V Acc: 0.8482, Top 70th Acc: 0.9494, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 21  Rolling back to Epoch (base 0): 16  Top Validation Acc: 0.9367088607594937
Fold [2/5] Epoch [0/100] Initial Loss: 0.1416, Training Loss: 0.1416, Initial Validation Loss: 0.1293, Validation Loss: 0.1293,V Acc: 0.3423, Top 70th Acc: 0.4359, Bottom 30th Acc: 0.1212
Fold [2/5] Epoch [10/100] Initial Loss: 0.1416, Training Loss: 0.0265, Initial Validation Loss: 0.1293, Validation Loss: 0.0313,V Acc: 0.8378, Top 70th Acc: 0.9872, Bottom 30th Acc: 0.4848
Stopping early at Epoch (base 0): 19  Rolling back to Epoch (base 0): 14  Top Validation Acc: 0.9615384615384616
Fold [3/5] Epoch [0/100] Initial Loss: 0.1392, Training Loss: 0.1392, Initial Validation Loss: 0.1305, Validation Loss: 0.1305,V Acc: 0.4091, Top 70th Acc: 0.4675, Bottom 30th Acc: 0.2727
Fold [3/5] Epoch [10/100] Initial Loss: 0.1392, Training Loss: 0.0432, Initial Validation Loss: 0.1305, Validation Loss: 0.0425,V Acc: 0.7909, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.5152
Fold [3/5] Epoch [20/100] Initial Loss: 0.1392, Training Loss: 0.0155, Initial Validation Loss: 0.1305, Validation Loss: 0.0266,V Acc: 0.8455, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.5758
Fold [3/5] Epoch [30/100] Initial Loss: 0.1392, Training Loss: 0.0122, Initial Validation Loss: 0.1305, Validation Loss: 0.0263,V Acc: 0.8273, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 30  Rolling back to Epoch (base 0): 25  Top Validation Acc: 0.948051948051948
76 2 [array([0.45634794, 0.03435625, 0.04211076, 0.0912462 , 0.37593877],
      dtype=float32)]
Fold [4/5] Epoch [0/100] Initial Loss: 0.1378, Training Loss: 0.1378, Initial Validation Loss: 0.1335, Validation Loss: 0.1335,V Acc: 0.2569, Top 70th Acc: 0.3247, Bottom 30th Acc: 0.0938
Fold [4/5] Epoch [10/100] Initial Loss: 0.1378, Training Loss: 0.0339, Initial Validation Loss: 0.1335, Validation Loss: 0.0343,V Acc: 0.8532, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.5938
Fold [4/5] Epoch [20/100] Initial Loss: 0.1378, Training Loss: 0.0176, Initial Validation Loss: 0.1335, Validation Loss: 0.0237,V Acc: 0.8991, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.7188
Stopping early at Epoch (base 0): 27  Rolling back to Epoch (base 0): 22  Top Validation Acc: 0.974025974025974
Fold [5/5] Epoch [0/100] Initial Loss: 0.1404, Training Loss: 0.1404, Initial Validation Loss: 0.1328, Validation Loss: 0.1328,V Acc: 0.3889, Top 70th Acc: 0.4474, Bottom 30th Acc: 0.2500
Fold [5/5] Epoch [10/100] Initial Loss: 0.1404, Training Loss: 0.0287, Initial Validation Loss: 0.1328, Validation Loss: 0.0385,V Acc: 0.7963, Top 70th Acc: 0.9211, Bottom 30th Acc: 0.5000
Fold [5/5] Epoch [20/100] Initial Loss: 0.1404, Training Loss: 0.0128, Initial Validation Loss: 0.1328, Validation Loss: 0.0305,V Acc: 0.8333, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.5625
Stopping early at Epoch (base 0): 22  Rolling back to Epoch (base 0): 17  Top Validation Acc: 0.9473684210526315
Running train_nn.py with seed 77
CUDA:False
Training samples count:  550
Training on 40 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1391, Training Loss: 0.1391, Initial Validation Loss: 0.1366, Validation Loss: 0.1366,V Acc: 0.2500, Top 70th Acc: 0.3418, Bottom 30th Acc: 0.0303
Fold [1/5] Epoch [10/100] Initial Loss: 0.1391, Training Loss: 0.0336, Initial Validation Loss: 0.1366, Validation Loss: 0.0409,V Acc: 0.8036, Top 70th Acc: 0.9241, Bottom 30th Acc: 0.5152
Fold [1/5] Epoch [20/100] Initial Loss: 0.1391, Training Loss: 0.0166, Initial Validation Loss: 0.1366, Validation Loss: 0.0275,V Acc: 0.8482, Top 70th Acc: 0.9747, Bottom 30th Acc: 0.5455
Fold [1/5] Epoch [30/100] Initial Loss: 0.1391, Training Loss: 0.0122, Initial Validation Loss: 0.1366, Validation Loss: 0.0260,V Acc: 0.8661, Top 70th Acc: 0.9873, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 36  Rolling back to Epoch (base 0): 31  Top Validation Acc: 0.9746835443037974
Fold [2/5] Epoch [0/100] Initial Loss: 0.1397, Training Loss: 0.1397, Initial Validation Loss: 0.1368, Validation Loss: 0.1368,V Acc: 0.3604, Top 70th Acc: 0.4359, Bottom 30th Acc: 0.1818
Fold [2/5] Epoch [10/100] Initial Loss: 0.1397, Training Loss: 0.0237, Initial Validation Loss: 0.1368, Validation Loss: 0.0381,V Acc: 0.8198, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.6061
Fold [2/5] Epoch [20/100] Initial Loss: 0.1397, Training Loss: 0.0120, Initial Validation Loss: 0.1368, Validation Loss: 0.0330,V Acc: 0.8468, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.6667
Fold [2/5] Epoch [30/100] Initial Loss: 0.1397, Training Loss: 0.0099, Initial Validation Loss: 0.1368, Validation Loss: 0.0317,V Acc: 0.8378, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 35  Rolling back to Epoch (base 0): 30  Top Validation Acc: 0.9358974358974359
Fold [3/5] Epoch [0/100] Initial Loss: 0.1399, Training Loss: 0.1399, Initial Validation Loss: 0.1288, Validation Loss: 0.1288,V Acc: 0.3000, Top 70th Acc: 0.3636, Bottom 30th Acc: 0.1515
Fold [3/5] Epoch [10/100] Initial Loss: 0.1399, Training Loss: 0.0255, Initial Validation Loss: 0.1288, Validation Loss: 0.0362,V Acc: 0.8364, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.6364
Fold [3/5] Epoch [20/100] Initial Loss: 0.1399, Training Loss: 0.0136, Initial Validation Loss: 0.1288, Validation Loss: 0.0318,V Acc: 0.8273, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 27  Rolling back to Epoch (base 0): 22  Top Validation Acc: 0.922077922077922
Fold [4/5] Epoch [0/100] Initial Loss: 0.1374, Training Loss: 0.1374, Initial Validation Loss: 0.1274, Validation Loss: 0.1274,V Acc: 0.3578, Top 70th Acc: 0.4026, Bottom 30th Acc: 0.2500
Fold [4/5] Epoch [10/100] Initial Loss: 0.1374, Training Loss: 0.0244, Initial Validation Loss: 0.1274, Validation Loss: 0.0347,V Acc: 0.8073, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.5312
Fold [4/5] Epoch [20/100] Initial Loss: 0.1374, Training Loss: 0.0134, Initial Validation Loss: 0.1274, Validation Loss: 0.0295,V Acc: 0.8349, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.5938
Fold [4/5] Epoch [30/100] Initial Loss: 0.1374, Training Loss: 0.0113, Initial Validation Loss: 0.1274, Validation Loss: 0.0295,V Acc: 0.8440, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.6562
Stopping early at Epoch (base 0): 30  Rolling back to Epoch (base 0): 25  Top Validation Acc: 0.922077922077922
77 3 [array([0.5014062 , 0.06670666, 0.05862868, 0.0806526 , 0.2926059 ],
      dtype=float32)]
Fold [5/5] Epoch [0/100] Initial Loss: 0.1410, Training Loss: 0.1410, Initial Validation Loss: 0.1341, Validation Loss: 0.1341,V Acc: 0.2685, Top 70th Acc: 0.3289, Bottom 30th Acc: 0.1250/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)

Stopping early at Epoch (base 0): 38  Rolling back to Epoch (base 0): 33  Top Validation Acc: 0.7402597402597403
Fold [5/5] Epoch [0/100] Initial Loss: 0.1301, Training Loss: 0.1301, Initial Validation Loss: 0.1154, Validation Loss: 0.1154,V Acc: 0.4167, Top 70th Acc: 0.5789, Bottom 30th Acc: 0.0312
Fold [5/5] Epoch [10/100] Initial Loss: 0.1301, Training Loss: 0.0820, Initial Validation Loss: 0.1154, Validation Loss: 0.0725,V Acc: 0.6481, Top 70th Acc: 0.7763, Bottom 30th Acc: 0.3438
Stopping early at Epoch (base 0): 17  Rolling back to Epoch (base 0): 12  Top Validation Acc: 0.8026315789473685
Running train_nn.py with seed 74
CUDA:False
Training samples count:  550
Training on 2 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1332, Training Loss: 0.1332, Initial Validation Loss: 0.1247, Validation Loss: 0.1247,V Acc: 0.3929, Top 70th Acc: 0.4557, Bottom 30th Acc: 0.2424
Fold [1/5] Epoch [10/100] Initial Loss: 0.1332, Training Loss: 0.0820, Initial Validation Loss: 0.1247, Validation Loss: 0.0756,V Acc: 0.6518, Top 70th Acc: 0.7722, Bottom 30th Acc: 0.3636
Fold [1/5] Epoch [20/100] Initial Loss: 0.1332, Training Loss: 0.0799, Initial Validation Loss: 0.1247, Validation Loss: 0.0742,V Acc: 0.6607, Top 70th Acc: 0.7468, Bottom 30th Acc: 0.4545
Fold [1/5] Epoch [30/100] Initial Loss: 0.1332, Training Loss: 0.0795, Initial Validation Loss: 0.1247, Validation Loss: 0.0733,V Acc: 0.6429, Top 70th Acc: 0.7722, Bottom 30th Acc: 0.3333
Fold [1/5] Epoch [40/100] Initial Loss: 0.1332, Training Loss: 0.0788, Initial Validation Loss: 0.1247, Validation Loss: 0.0733,V Acc: 0.6518, Top 70th Acc: 0.7595, Bottom 30th Acc: 0.3939
Stopping early at Epoch (base 0): 48  Rolling back to Epoch (base 0): 43  Top Validation Acc: 0.7341772151898734
Fold [2/5] Epoch [0/100] Initial Loss: 0.1380, Training Loss: 0.1380, Initial Validation Loss: 0.1274, Validation Loss: 0.1274,V Acc: 0.4234, Top 70th Acc: 0.5513, Bottom 30th Acc: 0.1212
Fold [2/5] Epoch [10/100] Initial Loss: 0.1380, Training Loss: 0.0822, Initial Validation Loss: 0.1274, Validation Loss: 0.0756,V Acc: 0.6667, Top 70th Acc: 0.7692, Bottom 30th Acc: 0.4242
Fold [2/5] Epoch [20/100] Initial Loss: 0.1380, Training Loss: 0.0804, Initial Validation Loss: 0.1274, Validation Loss: 0.0739,V Acc: 0.6757, Top 70th Acc: 0.7949, Bottom 30th Acc: 0.3939
Stopping early at Epoch (base 0): 21  Rolling back to Epoch (base 0): 16  Top Validation Acc: 0.7692307692307693
Fold [3/5] Epoch [0/100] Initial Loss: 0.1402, Training Loss: 0.1402, Initial Validation Loss: 0.1298, Validation Loss: 0.1298,V Acc: 0.3364, Top 70th Acc: 0.4156, Bottom 30th Acc: 0.1515
Fold [3/5] Epoch [10/100] Initial Loss: 0.1402, Training Loss: 0.0810, Initial Validation Loss: 0.1298, Validation Loss: 0.0797,V Acc: 0.6000, Top 70th Acc: 0.7143, Bottom 30th Acc: 0.3333
Fold [3/5] Epoch [20/100] Initial Loss: 0.1402, Training Loss: 0.0794, Initial Validation Loss: 0.1298, Validation Loss: 0.0771,V Acc: 0.6000, Top 70th Acc: 0.7403, Bottom 30th Acc: 0.2727
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.7532467532467533
Fold [4/5] Epoch [0/100] Initial Loss: 0.1304, Training Loss: 0.1304, Initial Validation Loss: 0.1207, Validation Loss: 0.1207,V Acc: 0.5046, Top 70th Acc: 0.5325, Bottom 30th Acc: 0.4375
Fold [4/5] Epoch [10/100] Initial Loss: 0.1304, Training Loss: 0.0782, Initial Validation Loss: 0.1207, Validation Loss: 0.0855,V Acc: 0.6055, Top 70th Acc: 0.6883, Bottom 30th Acc: 0.4062
Fold [4/5] Epoch [20/100] Initial Loss: 0.1304, Training Loss: 0.0765, Initial Validation Loss: 0.1207, Validation Loss: 0.0840,V Acc: 0.6147, Top 70th Acc: 0.6883, Bottom 30th Acc: 0.4375
Fold [4/5] Epoch [30/100] Initial Loss: 0.1304, Training Loss: 0.0756, Initial Validation Loss: 0.1207, Validation Loss: 0.0836,V Acc: 0.5872, Top 70th Acc: 0.7143, Bottom 30th Acc: 0.2812
Stopping early at Epoch (base 0): 30  Rolling back to Epoch (base 0): 25  Top Validation Acc: 0.7142857142857143
74 3 [array([0.13080363, 0.37922233, 0.13509758, 0.2308328 , 0.12404367],
      dtype=float32)]
Fold [5/5] Epoch [0/100] Initial Loss: 0.1401, Training Loss: 0.1401, Initial Validation Loss: 0.1312, Validation Loss: 0.1312,V Acc: 0.2593, Top 70th Acc: 0.3421, Bottom 30th Acc: 0.0625
Fold [5/5] Epoch [10/100] Initial Loss: 0.1401, Training Loss: 0.0794, Initial Validation Loss: 0.1312, Validation Loss: 0.0814,V Acc: 0.6204, Top 70th Acc: 0.7105, Bottom 30th Acc: 0.4062
Fold [5/5] Epoch [20/100] Initial Loss: 0.1401, Training Loss: 0.0780, Initial Validation Loss: 0.1312, Validation Loss: 0.0804,V Acc: 0.6111, Top 70th Acc: 0.7237, Bottom 30th Acc: 0.3438
Stopping early at Epoch (base 0): 22  Rolling back to Epoch (base 0): 17  Top Validation Acc: 0.7236842105263158
Running train_nn.py with seed 75
CUDA:False
Training samples count:  550
Training on 2 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1377, Training Loss: 0.1377, Initial Validation Loss: 0.1271, Validation Loss: 0.1271,V Acc: 0.5536, Top 70th Acc: 0.6582, Bottom 30th Acc: 0.3030
Fold [1/5] Epoch [10/100] Initial Loss: 0.1377, Training Loss: 0.0794, Initial Validation Loss: 0.1271, Validation Loss: 0.0848,V Acc: 0.5714, Top 70th Acc: 0.7215, Bottom 30th Acc: 0.2121
Stopping early at Epoch (base 0): 14  Rolling back to Epoch (base 0): 9  Top Validation Acc: 0.6962025316455697
Fold [2/5] Epoch [0/100] Initial Loss: 0.1393, Training Loss: 0.1393, Initial Validation Loss: 0.1335, Validation Loss: 0.1335,V Acc: 0.4775, Top 70th Acc: 0.5128, Bottom 30th Acc: 0.3939
Fold [2/5] Epoch [10/100] Initial Loss: 0.1393, Training Loss: 0.0811, Initial Validation Loss: 0.1335, Validation Loss: 0.0785,V Acc: 0.6667, Top 70th Acc: 0.7564, Bottom 30th Acc: 0.4545
Fold [2/5] Epoch [20/100] Initial Loss: 0.1393, Training Loss: 0.0791, Initial Validation Loss: 0.1335, Validation Loss: 0.0759,V Acc: 0.6486, Top 70th Acc: 0.7949, Bottom 30th Acc: 0.3030
Stopping early at Epoch (base 0): 29  Rolling back to Epoch (base 0): 24  Top Validation Acc: 0.7564102564102564
Fold [3/5] Epoch [0/100] Initial Loss: 0.1399, Training Loss: 0.1399, Initial Validation Loss: 0.1268, Validation Loss: 0.1268,V Acc: 0.5455, Top 70th Acc: 0.6104, Bottom 30th Acc: 0.3939
Fold [3/5] Epoch [10/100] Initial Loss: 0.1399, Training Loss: 0.0799, Initial Validation Loss: 0.1268, Validation Loss: 0.0793,V Acc: 0.6091, Top 70th Acc: 0.7662, Bottom 30th Acc: 0.2424
Fold [3/5] Epoch [20/100] Initial Loss: 0.1399, Training Loss: 0.0780, Initial Validation Loss: 0.1268, Validation Loss: 0.0787,V Acc: 0.6364, Top 70th Acc: 0.7532, Bottom 30th Acc: 0.3636
Fold [3/5] Epoch [30/100] Initial Loss: 0.1399, Training Loss: 0.0775, Initial Validation Loss: 0.1268, Validation Loss: 0.0779,V Acc: 0.6273, Top 70th Acc: 0.7532, Bottom 30th Acc: 0.3333
Stopping early at Epoch (base 0): 39  Rolling back to Epoch (base 0): 34  Top Validation Acc: 0.7272727272727273
Fold [4/5] Epoch [0/100] Initial Loss: 0.1466, Training Loss: 0.1466, Initial Validation Loss: 0.1313, Validation Loss: 0.1313,V Acc: 0.3761, Top 70th Acc: 0.4416, Bottom 30th Acc: 0.2188
Fold [4/5] Epoch [10/100] Initial Loss: 0.1466, Training Loss: 0.0797, Initial Validation Loss: 0.1313, Validation Loss: 0.0833,V Acc: 0.6239, Top 70th Acc: 0.6883, Bottom 30th Acc: 0.4688
Fold [4/5] Epoch [20/100] Initial Loss: 0.1466, Training Loss: 0.0775, Initial Validation Loss: 0.1313, Validation Loss: 0.0815,V Acc: 0.6330, Top 70th Acc: 0.7273, Bottom 30th Acc: 0.4062
Fold [4/5] Epoch [30/100] Initial Loss: 0.1466, Training Loss: 0.0765, Initial Validation Loss: 0.1313, Validation Loss: 0.0802,V Acc: 0.6422, Top 70th Acc: 0.7273, Bottom 30th Acc: 0.4375
Stopping early at Epoch (base 0): 38  Rolling back to Epoch (base 0): 33  Top Validation Acc: 0.7142857142857143
75 3 [array([0.11611091, 0.34066513, 0.14399229, 0.24031574, 0.15891595],
      dtype=float32)]
Fold [5/5] Epoch [0/100] Initial Loss: 0.1401, Training Loss: 0.1401, Initial Validation Loss: 0.1248, Validation Loss: 0.1248,V Acc: 0.2315, Top 70th Acc: 0.2500, Bottom 30th Acc: 0.1875
Fold [5/5] Epoch [10/100] Initial Loss: 0.1401, Training Loss: 0.0826, Initial Validation Loss: 0.1248, Validation Loss: 0.0714,V Acc: 0.6574, Top 70th Acc: 0.7895, Bottom 30th Acc: 0.3438
Stopping early at Epoch (base 0): 30  Rolling back to Epoch (base 0): 25  Top Validation Acc: 0.922077922077922
74 3 [array([0.33478457, 0.12122831, 0.21349873, 0.16702284, 0.16346553],
      dtype=float32)]
Fold [5/5] Epoch [0/100] Initial Loss: 0.1385, Training Loss: 0.1385, Initial Validation Loss: 0.1315, Validation Loss: 0.1315,V Acc: 0.2778, Top 70th Acc: 0.3816, Bottom 30th Acc: 0.0312
Fold [5/5] Epoch [10/100] Initial Loss: 0.1385, Training Loss: 0.0389, Initial Validation Loss: 0.1315, Validation Loss: 0.0471,V Acc: 0.7593, Top 70th Acc: 0.8553, Bottom 30th Acc: 0.5312
Fold [5/5] Epoch [20/100] Initial Loss: 0.1385, Training Loss: 0.0294, Initial Validation Loss: 0.1315, Validation Loss: 0.0420,V Acc: 0.7870, Top 70th Acc: 0.8553, Bottom 30th Acc: 0.6250
Fold [5/5] Epoch [30/100] Initial Loss: 0.1385, Training Loss: 0.0243, Initial Validation Loss: 0.1315, Validation Loss: 0.0370,V Acc: 0.8056, Top 70th Acc: 0.8947, Bottom 30th Acc: 0.5938
Fold [5/5] Epoch [40/100] Initial Loss: 0.1385, Training Loss: 0.0224, Initial Validation Loss: 0.1315, Validation Loss: 0.0341,V Acc: 0.8333, Top 70th Acc: 0.8947, Bottom 30th Acc: 0.6875
Stopping early at Epoch (base 0): 45  Rolling back to Epoch (base 0): 40  Top Validation Acc: 0.8947368421052632
Running train_nn.py with seed 75
CUDA:False
Training samples count:  550
Training on 20 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1384, Training Loss: 0.1384, Initial Validation Loss: 0.1371, Validation Loss: 0.1371,V Acc: 0.3036, Top 70th Acc: 0.3165, Bottom 30th Acc: 0.2727
Fold [1/5] Epoch [10/100] Initial Loss: 0.1384, Training Loss: 0.0336, Initial Validation Loss: 0.1371, Validation Loss: 0.0366,V Acc: 0.8661, Top 70th Acc: 0.9620, Bottom 30th Acc: 0.6364
Fold [1/5] Epoch [20/100] Initial Loss: 0.1384, Training Loss: 0.0237, Initial Validation Loss: 0.1371, Validation Loss: 0.0327,V Acc: 0.8571, Top 70th Acc: 0.9494, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 28  Rolling back to Epoch (base 0): 23  Top Validation Acc: 0.9493670886075949
Fold [2/5] Epoch [0/100] Initial Loss: 0.1413, Training Loss: 0.1413, Initial Validation Loss: 0.1428, Validation Loss: 0.1428,V Acc: 0.2523, Top 70th Acc: 0.2692, Bottom 30th Acc: 0.2121
Fold [2/5] Epoch [10/100] Initial Loss: 0.1413, Training Loss: 0.0451, Initial Validation Loss: 0.1428, Validation Loss: 0.0502,V Acc: 0.7838, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.4848
Fold [2/5] Epoch [20/100] Initial Loss: 0.1413, Training Loss: 0.0237, Initial Validation Loss: 0.1428, Validation Loss: 0.0374,V Acc: 0.8378, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.6364
Fold [2/5] Epoch [30/100] Initial Loss: 0.1413, Training Loss: 0.0207, Initial Validation Loss: 0.1428, Validation Loss: 0.0365,V Acc: 0.8198, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 31  Rolling back to Epoch (base 0): 26  Top Validation Acc: 0.9358974358974359
Fold [3/5] Epoch [0/100] Initial Loss: 0.1395, Training Loss: 0.1395, Initial Validation Loss: 0.1326, Validation Loss: 0.1326,V Acc: 0.2909, Top 70th Acc: 0.3506, Bottom 30th Acc: 0.1515
Fold [3/5] Epoch [10/100] Initial Loss: 0.1395, Training Loss: 0.0445, Initial Validation Loss: 0.1326, Validation Loss: 0.0466,V Acc: 0.7091, Top 70th Acc: 0.8961, Bottom 30th Acc: 0.2727
Fold [3/5] Epoch [20/100] Initial Loss: 0.1395, Training Loss: 0.0303, Initial Validation Loss: 0.1326, Validation Loss: 0.0398,V Acc: 0.7545, Top 70th Acc: 0.8961, Bottom 30th Acc: 0.4242
Fold [3/5] Epoch [30/100] Initial Loss: 0.1395, Training Loss: 0.0232, Initial Validation Loss: 0.1326, Validation Loss: 0.0364,V Acc: 0.7727, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.4545
Stopping early at Epoch (base 0): 37  Rolling back to Epoch (base 0): 32  Top Validation Acc: 0.935064935064935
Fold [4/5] Epoch [0/100] Initial Loss: 0.1407, Training Loss: 0.1407, Initial Validation Loss: 0.1331, Validation Loss: 0.1331,V Acc: 0.2018, Top 70th Acc: 0.2468, Bottom 30th Acc: 0.0938
Fold [4/5] Epoch [10/100] Initial Loss: 0.1407, Training Loss: 0.0396, Initial Validation Loss: 0.1331, Validation Loss: 0.0497,V Acc: 0.7523, Top 70th Acc: 0.8442, Bottom 30th Acc: 0.5312
Fold [4/5] Epoch [20/100] Initial Loss: 0.1407, Training Loss: 0.0225, Initial Validation Loss: 0.1331, Validation Loss: 0.0377,V Acc: 0.8073, Top 70th Acc: 0.8831, Bottom 30th Acc: 0.6250
Stopping early at Epoch (base 0): 29  Rolling back to Epoch (base 0): 24  Top Validation Acc: 0.8831168831168831
75 3 [array([0.2748239 , 0.06806288, 0.16789047, 0.32576674, 0.16345604],
      dtype=float32)]
Fold [5/5] Epoch [0/100] Initial Loss: 0.1401, Training Loss: 0.1401, Initial Validation Loss: 0.1284, Validation Loss: 0.1284,V Acc: 0.2500, Top 70th Acc: 0.3026, Bottom 30th Acc: 0.1250
Fold [5/5] Epoch [10/100] Initial Loss: 0.1401, Training Loss: 0.0468, Initial Validation Loss: 0.1284, Validation Loss: 0.0484,V Acc: 0.7685, Top 70th Acc: 0.8289, Bottom 30th Acc: 0.6250
Fold [5/5] Epoch [20/100] Initial Loss: 0.1401, Training Loss: 0.0247, Initial Validation Loss: 0.1284, Validation Loss: 0.0345,V Acc: 0.8056, Top 70th Acc: 0.9079, Bottom 30th Acc: 0.5625
Stopping early at Epoch (base 0): 27  Rolling back to Epoch (base 0): 22  Top Validation Acc: 0.9078947368421053
Running train_nn.py with seed 76
CUDA:False
Training samples count:  550
Training on 20 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1390, Training Loss: 0.1390, Initial Validation Loss: 0.1375, Validation Loss: 0.1375,V Acc: 0.3929, Top 70th Acc: 0.3671, Bottom 30th Acc: 0.4545
Fold [1/5] Epoch [10/100] Initial Loss: 0.1390, Training Loss: 0.0325, Initial Validation Loss: 0.1375, Validation Loss: 0.0392,V Acc: 0.8125, Top 70th Acc: 0.9367, Bottom 30th Acc: 0.5152
Fold [1/5] Epoch [20/100] Initial Loss: 0.1390, Training Loss: 0.0236, Initial Validation Loss: 0.1375, Validation Loss: 0.0351,V Acc: 0.8393, Top 70th Acc: 0.9494, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.9493670886075949
Fold [2/5] Epoch [0/100] Initial Loss: 0.1400, Training Loss: 0.1400, Initial Validation Loss: 0.1310, Validation Loss: 0.1310,V Acc: 0.3874, Top 70th Acc: 0.4487, Bottom 30th Acc: 0.2424
Fold [2/5] Epoch [10/100] Initial Loss: 0.1400, Training Loss: 0.0379, Initial Validation Loss: 0.1310, Validation Loss: 0.0431,V Acc: 0.7928, Top 70th Acc: 0.8718, Bottom 30th Acc: 0.6061
Fold [2/5] Epoch [20/100] Initial Loss: 0.1400, Training Loss: 0.0250, Initial Validation Loss: 0.1310, Validation Loss: 0.0340,V Acc: 0.8198, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.6061
Fold [2/5] Epoch [30/100] Initial Loss: 0.1400, Training Loss: 0.0224, Initial Validation Loss: 0.1310, Validation Loss: 0.0332,V Acc: 0.8198, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.6061
Fold [2/5] Epoch [40/100] Initial Loss: 0.1400, Training Loss: 0.0210, Initial Validation Loss: 0.1310, Validation Loss: 0.0339,V Acc: 0.8198, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 47  Rolling back to Epoch (base 0): 42  Top Validation Acc: 0.9102564102564102
Fold [3/5] Epoch [0/100] Initial Loss: 0.1424, Training Loss: 0.1424, Initial Validation Loss: 0.1316, Validation Loss: 0.1316,V Acc: 0.2727, Top 70th Acc: 0.3377, Bottom 30th Acc: 0.1212
Fold [3/5] Epoch [10/100] Initial Loss: 0.1424, Training Loss: 0.0339, Initial Validation Loss: 0.1316, Validation Loss: 0.0354,V Acc: 0.8000, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.5455
Fold [3/5] Epoch [20/100] Initial Loss: 0.1424, Training Loss: 0.0247, Initial Validation Loss: 0.1316, Validation Loss: 0.0331,V Acc: 0.8091, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.5758
Fold [3/5] Epoch [30/100] Initial Loss: 0.1424, Training Loss: 0.0223, Initial Validation Loss: 0.1316, Validation Loss: 0.0306,V Acc: 0.8182, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 33  Rolling back to Epoch (base 0): 28  Top Validation Acc: 0.922077922077922
76 2 [array([0.41860223, 0.05478499, 0.14198819, 0.1787818 , 0.20584276],
      dtype=float32)]
Fold [4/5] Epoch [0/100] Initial Loss: 0.1398, Training Loss: 0.1398, Initial Validation Loss: 0.1351, Validation Loss: 0.1351,V Acc: 0.2477, Top 70th Acc: 0.3117, Bottom 30th Acc: 0.0938
Fold [3/5] Epoch [10/100] Initial Loss: 0.1409, Training Loss: 0.0138, Initial Validation Loss: 0.1314, Validation Loss: 0.0339,V Acc: 0.8364, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 19  Rolling back to Epoch (base 0): 14  Top Validation Acc: 0.935064935064935
57 2 [array([0.14745705, 0.04221959, 0.03974025, 0.18213846, 0.58844465],
      dtype=float32)]
Fold [4/5] Epoch [0/100] Initial Loss: 0.1413, Training Loss: 0.1413, Initial Validation Loss: 0.1313, Validation Loss: 0.1313,V Acc: 0.3119, Top 70th Acc: 0.3247, Bottom 30th Acc: 0.2812
Fold [4/5] Epoch [10/100] Initial Loss: 0.1413, Training Loss: 0.0169, Initial Validation Loss: 0.1313, Validation Loss: 0.0328,V Acc: 0.8349, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.5312
Fold [4/5] Epoch [20/100] Initial Loss: 0.1413, Training Loss: 0.0051, Initial Validation Loss: 0.1313, Validation Loss: 0.0272,V Acc: 0.8257, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.5000
Fold [4/5] Epoch [30/100] Initial Loss: 0.1413, Training Loss: 0.0041, Initial Validation Loss: 0.1313, Validation Loss: 0.0266,V Acc: 0.8440, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.5625
Stopping early at Epoch (base 0): 31  Rolling back to Epoch (base 0): 26  Top Validation Acc: 0.961038961038961
Fold [5/5] Epoch [0/100] Initial Loss: 0.1394, Training Loss: 0.1394, Initial Validation Loss: 0.1369, Validation Loss: 0.1369,V Acc: 0.3426, Top 70th Acc: 0.3421, Bottom 30th Acc: 0.3438
Fold [5/5] Epoch [10/100] Initial Loss: 0.1394, Training Loss: 0.0163, Initial Validation Loss: 0.1369, Validation Loss: 0.0349,V Acc: 0.8519, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.6250
Fold [5/5] Epoch [20/100] Initial Loss: 0.1394, Training Loss: 0.0044, Initial Validation Loss: 0.1369, Validation Loss: 0.0291,V Acc: 0.8426, Top 70th Acc: 0.9868, Bottom 30th Acc: 0.5000
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.9736842105263158
Running train_nn.py with seed 58
CUDA:False
Training samples count:  550
Training on 162 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1393, Training Loss: 0.1393, Initial Validation Loss: 0.1376, Validation Loss: 0.1376,V Acc: 0.2946, Top 70th Acc: 0.3291, Bottom 30th Acc: 0.2121
Fold [1/5] Epoch [10/100] Initial Loss: 0.1393, Training Loss: 0.0205, Initial Validation Loss: 0.1376, Validation Loss: 0.0508,V Acc: 0.8036, Top 70th Acc: 0.8861, Bottom 30th Acc: 0.6061
Fold [1/5] Epoch [20/100] Initial Loss: 0.1393, Training Loss: 0.0078, Initial Validation Loss: 0.1376, Validation Loss: 0.0443,V Acc: 0.8214, Top 70th Acc: 0.8861, Bottom 30th Acc: 0.6667
Fold [1/5] Epoch [30/100] Initial Loss: 0.1393, Training Loss: 0.0053, Initial Validation Loss: 0.1376, Validation Loss: 0.0413,V Acc: 0.8482, Top 70th Acc: 0.9114, Bottom 30th Acc: 0.6970
Fold [1/5] Epoch [40/100] Initial Loss: 0.1393, Training Loss: 0.0044, Initial Validation Loss: 0.1376, Validation Loss: 0.0400,V Acc: 0.8304, Top 70th Acc: 0.9114, Bottom 30th Acc: 0.6364
Fold [1/5] Epoch [50/100] Initial Loss: 0.1393, Training Loss: 0.0042, Initial Validation Loss: 0.1376, Validation Loss: 0.0383,V Acc: 0.8393, Top 70th Acc: 0.9114, Bottom 30th Acc: 0.6667
Fold [1/5] Epoch [60/100] Initial Loss: 0.1393, Training Loss: 0.0040, Initial Validation Loss: 0.1376, Validation Loss: 0.0370,V Acc: 0.8304, Top 70th Acc: 0.9241, Bottom 30th Acc: 0.6061
Fold [1/5] Epoch [70/100] Initial Loss: 0.1393, Training Loss: 0.0039, Initial Validation Loss: 0.1376, Validation Loss: 0.0349,V Acc: 0.8304, Top 70th Acc: 0.9494, Bottom 30th Acc: 0.5455
Fold [1/5] Epoch [80/100] Initial Loss: 0.1393, Training Loss: 0.0038, Initial Validation Loss: 0.1376, Validation Loss: 0.0341,V Acc: 0.8482, Top 70th Acc: 0.9494, Bottom 30th Acc: 0.6061
Fold [1/5] Epoch [90/100] Initial Loss: 0.1393, Training Loss: 0.0037, Initial Validation Loss: 0.1376, Validation Loss: 0.0341,V Acc: 0.8482, Top 70th Acc: 0.9494, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 90  Rolling back to Epoch (base 0): 85  Top Validation Acc: 0.9493670886075949
Fold [2/5] Epoch [0/100] Initial Loss: 0.1399, Training Loss: 0.1399, Initial Validation Loss: 0.1346, Validation Loss: 0.1346,V Acc: 0.2523, Top 70th Acc: 0.3077, Bottom 30th Acc: 0.1212
Fold [2/5] Epoch [10/100] Initial Loss: 0.1399, Training Loss: 0.0157, Initial Validation Loss: 0.1346, Validation Loss: 0.0321,V Acc: 0.8649, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.6364
Fold [2/5] Epoch [20/100] Initial Loss: 0.1399, Training Loss: 0.0053, Initial Validation Loss: 0.1346, Validation Loss: 0.0273,V Acc: 0.8468, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.9487179487179487
Fold [3/5] Epoch [0/100] Initial Loss: 0.1384, Training Loss: 0.1384, Initial Validation Loss: 0.1327, Validation Loss: 0.1327,V Acc: 0.3273, Top 70th Acc: 0.4286, Bottom 30th Acc: 0.0909
Fold [3/5] Epoch [10/100] Initial Loss: 0.1384, Training Loss: 0.0247, Initial Validation Loss: 0.1327, Validation Loss: 0.0389,V Acc: 0.8273, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.6061
Fold [3/5] Epoch [20/100] Initial Loss: 0.1384, Training Loss: 0.0060, Initial Validation Loss: 0.1327, Validation Loss: 0.0300,V Acc: 0.8455, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.6364
Fold [3/5] Epoch [30/100] Initial Loss: 0.1384, Training Loss: 0.0043, Initial Validation Loss: 0.1327, Validation Loss: 0.0270,V Acc: 0.8636, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.6364
Fold [3/5] Epoch [40/100] Initial Loss: 0.1384, Training Loss: 0.0039, Initial Validation Loss: 0.1327, Validation Loss: 0.0258,V Acc: 0.8636, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.6364
Fold [3/5] Epoch [50/100] Initial Loss: 0.1384, Training Loss: 0.0037, Initial Validation Loss: 0.1327, Validation Loss: 0.0253,V Acc: 0.8818, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.6970
Fold [3/5] Epoch [60/100] Initial Loss: 0.1384, Training Loss: 0.0036, Initial Validation Loss: 0.1327, Validation Loss: 0.0248,V Acc: 0.8727, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 68  Rolling back to Epoch (base 0): 63  Top Validation Acc: 0.961038961038961
Fold [4/5] Epoch [0/100] Initial Loss: 0.1393, Training Loss: 0.1393, Initial Validation Loss: 0.1316, Validation Loss: 0.1316,V Acc: 0.3945, Top 70th Acc: 0.5455, Bottom 30th Acc: 0.0312
Fold [4/5] Epoch [10/100] Initial Loss: 0.1393, Training Loss: 0.0132, Initial Validation Loss: 0.1316, Validation Loss: 0.0345,V Acc: 0.8257, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.5938
Fold [4/5] Epoch [20/100] Initial Loss: 0.1393, Training Loss: 0.0044, Initial Validation Loss: 0.1316, Validation Loss: 0.0341,V Acc: 0.8257, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.6250
Fold [4/5] Epoch [30/100] Initial Loss: 0.1393, Training Loss: 0.0036, Initial Validation Loss: 0.1316, Validation Loss: 0.0331,V Acc: 0.8349, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.6250
Fold [4/5] Epoch [40/100] Initial Loss: 0.1393, Training Loss: 0.0034, Initial Validation Loss: 0.1316, Validation Loss: 0.0328,V Acc: 0.8257, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.5938
Stopping early at Epoch (base 0): 46  Rolling back to Epoch (base 0): 41  Top Validation Acc: 0.935064935064935
58 3 [array([0.29419333, 0.08357664, 0.04821856, 0.23862164, 0.33538982],
      dtype=float32)]
Fold [5/5] Epoch [0/100] Initial Loss: 0.1406, Training Loss: 0.1406, Initial Validation Loss: 0.1321, Validation Loss: 0.1321,V Acc: 0.2685, Top 70th Acc: 0.3026, Bottom 30th Acc: 0.1875
Fold [5/5] Epoch [10/100] Initial Loss: 0.1406, Training Loss: 0.0163, Initial Validation Loss: 0.1321, Validation Loss: 0.0373,V Acc: 0.8241, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.5625
Fold [5/5] Epoch [20/100] Initial Loss: 0.1406, Training Loss: 0.0050, Initial Validation Loss: 0.1321, Validation Loss: 0.0321,V Acc: 0.8148, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.5000
Fold [5/5] Epoch [30/100] Initial Loss: 0.1406, Training Loss: 0.0039, Initial Validation Loss: 0.1321, Validation Loss: 0.0324,V Acc: 0.8056, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.4688
Stopping early at Epoch (base 0): 33  Rolling back to Epoch (base 0): 28  Top Validation Acc: 0.9605263157894737
Running train_nn.py with seed 59
Fold [2/5] Epoch [10/100] Initial Loss: 0.1381, Training Loss: 0.0345, Initial Validation Loss: 0.1348, Validation Loss: 0.0396,V Acc: 0.8288, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.6364
Fold [2/5] Epoch [20/100] Initial Loss: 0.1381, Training Loss: 0.0184, Initial Validation Loss: 0.1348, Validation Loss: 0.0309,V Acc: 0.8378, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.9487179487179487
Fold [3/5] Epoch [0/100] Initial Loss: 0.1395, Training Loss: 0.1395, Initial Validation Loss: 0.1317, Validation Loss: 0.1317,V Acc: 0.2727, Top 70th Acc: 0.3247, Bottom 30th Acc: 0.1515
Fold [3/5] Epoch [10/100] Initial Loss: 0.1395, Training Loss: 0.0318, Initial Validation Loss: 0.1317, Validation Loss: 0.0371,V Acc: 0.8455, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.6364
Fold [3/5] Epoch [20/100] Initial Loss: 0.1395, Training Loss: 0.0174, Initial Validation Loss: 0.1317, Validation Loss: 0.0319,V Acc: 0.8273, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.922077922077922
Fold [4/5] Epoch [0/100] Initial Loss: 0.1402, Training Loss: 0.1402, Initial Validation Loss: 0.1335, Validation Loss: 0.1335,V Acc: 0.3028, Top 70th Acc: 0.3766, Bottom 30th Acc: 0.1250
Fold [4/5] Epoch [10/100] Initial Loss: 0.1402, Training Loss: 0.0412, Initial Validation Loss: 0.1335, Validation Loss: 0.0536,V Acc: 0.7523, Top 70th Acc: 0.8701, Bottom 30th Acc: 0.4688
Fold [4/5] Epoch [20/100] Initial Loss: 0.1402, Training Loss: 0.0187, Initial Validation Loss: 0.1335, Validation Loss: 0.0328,V Acc: 0.8440, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.5938
Stopping early at Epoch (base 0): 28  Rolling back to Epoch (base 0): 23  Top Validation Acc: 0.935064935064935
74 3 [array([0.7073395 , 0.10039993, 0.03231161, 0.11354384, 0.04640511],
      dtype=float32)]
Fold [5/5] Epoch [0/100] Initial Loss: 0.1399, Training Loss: 0.1399, Initial Validation Loss: 0.1316, Validation Loss: 0.1316,V Acc: 0.2685, Top 70th Acc: 0.3816, Bottom 30th Acc: 0.0000
Fold [5/5] Epoch [10/100] Initial Loss: 0.1399, Training Loss: 0.0340, Initial Validation Loss: 0.1316, Validation Loss: 0.0393,V Acc: 0.8241, Top 70th Acc: 0.9211, Bottom 30th Acc: 0.5938
Fold [5/5] Epoch [20/100] Initial Loss: 0.1399, Training Loss: 0.0207, Initial Validation Loss: 0.1316, Validation Loss: 0.0267,V Acc: 0.8519, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.5938
Stopping early at Epoch (base 0): 27  Rolling back to Epoch (base 0): 22  Top Validation Acc: 0.9605263157894737
Running train_nn.py with seed 75
CUDA:False
Training samples count:  550
Training on 30 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1390, Training Loss: 0.1390, Initial Validation Loss: 0.1333, Validation Loss: 0.1333,V Acc: 0.3571, Top 70th Acc: 0.4557, Bottom 30th Acc: 0.1212
Fold [1/5] Epoch [10/100] Initial Loss: 0.1390, Training Loss: 0.0369, Initial Validation Loss: 0.1333, Validation Loss: 0.0468,V Acc: 0.7857, Top 70th Acc: 0.8734, Bottom 30th Acc: 0.5758
Fold [1/5] Epoch [20/100] Initial Loss: 0.1390, Training Loss: 0.0214, Initial Validation Loss: 0.1333, Validation Loss: 0.0381,V Acc: 0.7946, Top 70th Acc: 0.9241, Bottom 30th Acc: 0.4848
Fold [1/5] Epoch [30/100] Initial Loss: 0.1390, Training Loss: 0.0161, Initial Validation Loss: 0.1333, Validation Loss: 0.0350,V Acc: 0.8304, Top 70th Acc: 0.9367, Bottom 30th Acc: 0.5758
Fold [1/5] Epoch [40/100] Initial Loss: 0.1390, Training Loss: 0.0137, Initial Validation Loss: 0.1333, Validation Loss: 0.0333,V Acc: 0.8393, Top 70th Acc: 0.9620, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 42  Rolling back to Epoch (base 0): 37  Top Validation Acc: 0.9493670886075949
Fold [2/5] Epoch [0/100] Initial Loss: 0.1356, Training Loss: 0.1356, Initial Validation Loss: 0.1350, Validation Loss: 0.1350,V Acc: 0.4054, Top 70th Acc: 0.4615, Bottom 30th Acc: 0.2727
Fold [2/5] Epoch [10/100] Initial Loss: 0.1356, Training Loss: 0.0286, Initial Validation Loss: 0.1350, Validation Loss: 0.0367,V Acc: 0.8559, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.6364
Fold [2/5] Epoch [20/100] Initial Loss: 0.1356, Training Loss: 0.0178, Initial Validation Loss: 0.1350, Validation Loss: 0.0304,V Acc: 0.8739, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.6667
Fold [2/5] Epoch [30/100] Initial Loss: 0.1356, Training Loss: 0.0150, Initial Validation Loss: 0.1350, Validation Loss: 0.0297,V Acc: 0.8649, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 30  Rolling back to Epoch (base 0): 25  Top Validation Acc: 0.9615384615384616
Fold [3/5] Epoch [0/100] Initial Loss: 0.1393, Training Loss: 0.1393, Initial Validation Loss: 0.1304, Validation Loss: 0.1304,V Acc: 0.2727, Top 70th Acc: 0.3636, Bottom 30th Acc: 0.0606
Fold [3/5] Epoch [10/100] Initial Loss: 0.1393, Training Loss: 0.0272, Initial Validation Loss: 0.1304, Validation Loss: 0.0379,V Acc: 0.7909, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.4848
Stopping early at Epoch (base 0): 19  Rolling back to Epoch (base 0): 14  Top Validation Acc: 0.948051948051948
Fold [4/5] Epoch [0/100] Initial Loss: 0.1394, Training Loss: 0.1394, Initial Validation Loss: 0.1319, Validation Loss: 0.1319,V Acc: 0.2477, Top 70th Acc: 0.3247, Bottom 30th Acc: 0.0625
Fold [4/5] Epoch [10/100] Initial Loss: 0.1394, Training Loss: 0.0358, Initial Validation Loss: 0.1319, Validation Loss: 0.0481,V Acc: 0.7431, Top 70th Acc: 0.8701, Bottom 30th Acc: 0.4375
Fold [4/5] Epoch [20/100] Initial Loss: 0.1394, Training Loss: 0.0186, Initial Validation Loss: 0.1319, Validation Loss: 0.0357,V Acc: 0.7890, Top 70th Acc: 0.8961, Bottom 30th Acc: 0.5312
Fold [4/5] Epoch [30/100] Initial Loss: 0.1394, Training Loss: 0.0154, Initial Validation Loss: 0.1319, Validation Loss: 0.0335,V Acc: 0.8165, Top 70th Acc: 0.8961, Bottom 30th Acc: 0.6250
Stopping early at Epoch (base 0): 36  Rolling back to Epoch (base 0): 31  Top Validation Acc: 0.922077922077922
75 3 [array([0.66452044, 0.05668819, 0.05756197, 0.1128676 , 0.10836181],
      dtype=float32)]
Fold [5/5] Epoch [0/100] Initial Loss: 0.1406, Training Loss: 0.1406, Initial Validation Loss: 0.1283, Validation Loss: 0.1283,V Acc: 0.2685, Top 70th Acc: 0.2895, Bottom 30th Acc: 0.2188
Fold [5/5] Epoch [10/100] Initial Loss: 0.1406, Training Loss: 0.0323, Initial Validation Loss: 0.1283, Validation Loss: 0.0290,V Acc: 0.8611, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.6562
Fold [5/5] Epoch [20/100] Initial Loss: 0.1406, Training Loss: 0.0182, Initial Validation Loss: 0.1283, Validation Loss: 0.0241,V Acc: 0.8611, Top 70th Acc: 0.9737, Bottom 30th Acc: 0.5938
Stopping early at Epoch (base 0): 20  Rolling back to Epoch (base 0): 15  Top Validation Acc: 0.9736842105263158
Running train_nn.py with seed 76
CUDA:False
Training samples count:  550
Training on 30 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1350, Training Loss: 0.1350, Initial Validation Loss: 0.1303, Validation Loss: 0.1303,V Acc: 0.4464, Top 70th Acc: 0.5316, Bottom 30th Acc: 0.2424
Fold [1/5] Epoch [10/100] Initial Loss: 0.1350, Training Loss: 0.0259, Initial Validation Loss: 0.1303, Validation Loss: 0.0392,V Acc: 0.8214, Top 70th Acc: 0.9367, Bottom 30th Acc: 0.5455
Fold [1/5] Epoch [20/100] Initial Loss: 0.1350, Training Loss: 0.0178, Initial Validation Loss: 0.1303, Validation Loss: 0.0362,V Acc: 0.8304, Top 70th Acc: 0.9367, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 21  Rolling back to Epoch (base 0): 16  Top Validation Acc: 0.9367088607594937
Fold [2/5] Epoch [0/100] Initial Loss: 0.1397, Training Loss: 0.1397, Initial Validation Loss: 0.1312, Validation Loss: 0.1312,V Acc: 0.3874, Top 70th Acc: 0.4103, Bottom 30th Acc: 0.3333
Fold [2/5] Epoch [10/100] Initial Loss: 0.1397, Training Loss: 0.0398, Initial Validation Loss: 0.1312, Validation Loss: 0.0411,V Acc: 0.7928, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.4848
Fold [2/5] Epoch [20/100] Initial Loss: 0.1397, Training Loss: 0.0207, Initial Validation Loss: 0.1312, Validation Loss: 0.0312,V Acc: 0.8198, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.4848
Fold [2/5] Epoch [30/100] Initial Loss: 0.1397, Training Loss: 0.0175, Initial Validation Loss: 0.1312, Validation Loss: 0.0310,V Acc: 0.8288, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.5758
Fold [5/5] Epoch [10/100] Initial Loss: 0.1410, Training Loss: 0.0351, Initial Validation Loss: 0.1341, Validation Loss: 0.0416,V Acc: 0.8333, Top 70th Acc: 0.9079, Bottom 30th Acc: 0.6562
Fold [5/5] Epoch [20/100] Initial Loss: 0.1410, Training Loss: 0.0157, Initial Validation Loss: 0.1341, Validation Loss: 0.0280,V Acc: 0.8704, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.6562
Stopping early at Epoch (base 0): 27  Rolling back to Epoch (base 0): 22  Top Validation Acc: 0.9473684210526315
Running train_nn.py with seed 78
CUDA:False
Training samples count:  550
Training on 40 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1376, Training Loss: 0.1376, Initial Validation Loss: 0.1385, Validation Loss: 0.1385,V Acc: 0.3304, Top 70th Acc: 0.3291, Bottom 30th Acc: 0.3333
Fold [1/5] Epoch [10/100] Initial Loss: 0.1376, Training Loss: 0.0256, Initial Validation Loss: 0.1385, Validation Loss: 0.0336,V Acc: 0.9018, Top 70th Acc: 0.9620, Bottom 30th Acc: 0.7576
Fold [1/5] Epoch [20/100] Initial Loss: 0.1376, Training Loss: 0.0152, Initial Validation Loss: 0.1385, Validation Loss: 0.0290,V Acc: 0.8571, Top 70th Acc: 0.9620, Bottom 30th Acc: 0.6061
Fold [1/5] Epoch [30/100] Initial Loss: 0.1376, Training Loss: 0.0128, Initial Validation Loss: 0.1385, Validation Loss: 0.0276,V Acc: 0.8929, Top 70th Acc: 0.9494, Bottom 30th Acc: 0.7576
Stopping early at Epoch (base 0): 33  Rolling back to Epoch (base 0): 28  Top Validation Acc: 0.9493670886075949
Fold [2/5] Epoch [0/100] Initial Loss: 0.1387, Training Loss: 0.1387, Initial Validation Loss: 0.1318, Validation Loss: 0.1318,V Acc: 0.3153, Top 70th Acc: 0.3462, Bottom 30th Acc: 0.2424
Fold [2/5] Epoch [10/100] Initial Loss: 0.1387, Training Loss: 0.0254, Initial Validation Loss: 0.1318, Validation Loss: 0.0310,V Acc: 0.8378, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.5758
Fold [2/5] Epoch [20/100] Initial Loss: 0.1387, Training Loss: 0.0146, Initial Validation Loss: 0.1318, Validation Loss: 0.0253,V Acc: 0.8829, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.9743589743589743
Fold [3/5] Epoch [0/100] Initial Loss: 0.1389, Training Loss: 0.1389, Initial Validation Loss: 0.1336, Validation Loss: 0.1336,V Acc: 0.2545, Top 70th Acc: 0.3117, Bottom 30th Acc: 0.1212
Fold [3/5] Epoch [10/100] Initial Loss: 0.1389, Training Loss: 0.0239, Initial Validation Loss: 0.1336, Validation Loss: 0.0372,V Acc: 0.8455, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.5758
Fold [3/5] Epoch [20/100] Initial Loss: 0.1389, Training Loss: 0.0130, Initial Validation Loss: 0.1336, Validation Loss: 0.0341,V Acc: 0.8455, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.961038961038961
Fold [4/5] Epoch [0/100] Initial Loss: 0.1395, Training Loss: 0.1395, Initial Validation Loss: 0.1340, Validation Loss: 0.1340,V Acc: 0.2477, Top 70th Acc: 0.3377, Bottom 30th Acc: 0.0312
Fold [4/5] Epoch [10/100] Initial Loss: 0.1395, Training Loss: 0.0250, Initial Validation Loss: 0.1340, Validation Loss: 0.0319,V Acc: 0.8807, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.7500
Fold [4/5] Epoch [20/100] Initial Loss: 0.1395, Training Loss: 0.0136, Initial Validation Loss: 0.1340, Validation Loss: 0.0274,V Acc: 0.8716, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.6562
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.961038961038961
Fold [5/5] Epoch [0/100] Initial Loss: 0.1376, Training Loss: 0.1376, Initial Validation Loss: 0.1259, Validation Loss: 0.1259,V Acc: 0.2685, Top 70th Acc: 0.3421, Bottom 30th Acc: 0.0938
Fold [5/5] Epoch [10/100] Initial Loss: 0.1376, Training Loss: 0.0282, Initial Validation Loss: 0.1259, Validation Loss: 0.0396,V Acc: 0.7778, Top 70th Acc: 0.8947, Bottom 30th Acc: 0.5000
Fold [5/5] Epoch [20/100] Initial Loss: 0.1376, Training Loss: 0.0131, Initial Validation Loss: 0.1259, Validation Loss: 0.0370,V Acc: 0.7685, Top 70th Acc: 0.8816, Bottom 30th Acc: 0.5000
Fold [5/5] Epoch [30/100] Initial Loss: 0.1376, Training Loss: 0.0109, Initial Validation Loss: 0.1259, Validation Loss: 0.0360,V Acc: 0.7778, Top 70th Acc: 0.8947, Bottom 30th Acc: 0.5000
Stopping early at Epoch (base 0): 39  Rolling back to Epoch (base 0): 34  Top Validation Acc: 0.881578947368421
78 4 [array([0.3858983 , 0.02514821, 0.12921955, 0.1397669 , 0.31996694],
      dtype=float32)]
Running train_nn.py with seed 79
CUDA:False
Training samples count:  550
Training on 40 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1393, Training Loss: 0.1393, Initial Validation Loss: 0.1316, Validation Loss: 0.1316,V Acc: 0.3393, Top 70th Acc: 0.3418, Bottom 30th Acc: 0.3333
Fold [1/5] Epoch [10/100] Initial Loss: 0.1393, Training Loss: 0.0276, Initial Validation Loss: 0.1316, Validation Loss: 0.0320,V Acc: 0.8571, Top 70th Acc: 0.9494, Bottom 30th Acc: 0.6364
Fold [1/5] Epoch [20/100] Initial Loss: 0.1393, Training Loss: 0.0171, Initial Validation Loss: 0.1316, Validation Loss: 0.0282,V Acc: 0.8750, Top 70th Acc: 0.9620, Bottom 30th Acc: 0.6667
Fold [1/5] Epoch [30/100] Initial Loss: 0.1393, Training Loss: 0.0136, Initial Validation Loss: 0.1316, Validation Loss: 0.0260,V Acc: 0.8839, Top 70th Acc: 0.9620, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 35  Rolling back to Epoch (base 0): 30  Top Validation Acc: 0.9620253164556962
Fold [2/5] Epoch [0/100] Initial Loss: 0.1370, Training Loss: 0.1370, Initial Validation Loss: 0.1383, Validation Loss: 0.1383,V Acc: 0.3694, Top 70th Acc: 0.4103, Bottom 30th Acc: 0.2727
Fold [2/5] Epoch [10/100] Initial Loss: 0.1370, Training Loss: 0.0290, Initial Validation Loss: 0.1383, Validation Loss: 0.0386,V Acc: 0.8559, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.6667
Fold [2/5] Epoch [20/100] Initial Loss: 0.1370, Training Loss: 0.0162, Initial Validation Loss: 0.1383, Validation Loss: 0.0321,V Acc: 0.8739, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.6970
Fold [2/5] Epoch [30/100] Initial Loss: 0.1370, Training Loss: 0.0134, Initial Validation Loss: 0.1383, Validation Loss: 0.0304,V Acc: 0.8919, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.7576
Stopping early at Epoch (base 0): 38  Rolling back to Epoch (base 0): 33  Top Validation Acc: 0.9487179487179487
Fold [3/5] Epoch [0/100] Initial Loss: 0.1377, Training Loss: 0.1377, Initial Validation Loss: 0.1266, Validation Loss: 0.1266,V Acc: 0.4545, Top 70th Acc: 0.5325, Bottom 30th Acc: 0.2727
Fold [3/5] Epoch [10/100] Initial Loss: 0.1377, Training Loss: 0.0269, Initial Validation Loss: 0.1266, Validation Loss: 0.0393,V Acc: 0.8000, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.5455
Fold [3/5] Epoch [20/100] Initial Loss: 0.1377, Training Loss: 0.0145, Initial Validation Loss: 0.1266, Validation Loss: 0.0317,V Acc: 0.8273, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 21  Rolling back to Epoch (base 0): 16  Top Validation Acc: 0.948051948051948
79 2 [array([0.4859739 , 0.20001099, 0.12000369, 0.06936432, 0.12464718],
      dtype=float32)]
Fold [4/5] Epoch [0/100] Initial Loss: 0.1409, Training Loss: 0.1409, Initial Validation Loss: 0.1321, Validation Loss: 0.1321,V Acc: 0.2936, Top 70th Acc: 0.3506, Bottom 30th Acc: 0.1562
Fold [4/5] Epoch [10/100] Initial Loss: 0.1409, Training Loss: 0.0261, Initial Validation Loss: 0.1321, Validation Loss: 0.0390,V Acc: 0.7982, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.5312
Fold [4/5] Epoch [20/100] Initial Loss: 0.1409, Training Loss: 0.0140, Initial Validation Loss: 0.1321, Validation Loss: 0.0385,V Acc: 0.7890, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.5000
Stopping early at Epoch (base 0): 21  Rolling back to Epoch (base 0): 16  Top Validation Acc: 0.9090909090909091
Fold [5/5] Epoch [0/100] Initial Loss: 0.1413, Training Loss: 0.1413, Initial Validation Loss: 0.1333, Validation Loss: 0.1333,V Acc: 0.2500, Top 70th Acc: 0.3289, Bottom 30th Acc: 0.0625
Fold [5/5] Epoch [10/100] Initial Loss: 0.1413, Training Loss: 0.0272, Initial Validation Loss: 0.1333, Validation Loss: 0.0368,V Acc: 0.8056, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.4688
Fold [5/5] Epoch [20/100] Initial Loss: 0.1413, Training Loss: 0.0145, Initial Validation Loss: 0.1333, Validation Loss: 0.0323,V Acc: 0.8056, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.4688/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)

Fold [5/5] Epoch [20/100] Initial Loss: 0.1401, Training Loss: 0.0804, Initial Validation Loss: 0.1248, Validation Loss: 0.0701,V Acc: 0.6389, Top 70th Acc: 0.7500, Bottom 30th Acc: 0.3750
Fold [5/5] Epoch [30/100] Initial Loss: 0.1401, Training Loss: 0.0797, Initial Validation Loss: 0.1248, Validation Loss: 0.0693,V Acc: 0.6389, Top 70th Acc: 0.7500, Bottom 30th Acc: 0.3750
Stopping early at Epoch (base 0): 32  Rolling back to Epoch (base 0): 27  Top Validation Acc: 0.75
Running train_nn.py with seed 76
CUDA:False
Training samples count:  550
Training on 2 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1327, Training Loss: 0.1327, Initial Validation Loss: 0.1247, Validation Loss: 0.1247,V Acc: 0.5982, Top 70th Acc: 0.6456, Bottom 30th Acc: 0.4848
Fold [1/5] Epoch [10/100] Initial Loss: 0.1327, Training Loss: 0.0799, Initial Validation Loss: 0.1247, Validation Loss: 0.0829,V Acc: 0.6250, Top 70th Acc: 0.7215, Bottom 30th Acc: 0.3939
Stopping early at Epoch (base 0): 18  Rolling back to Epoch (base 0): 13  Top Validation Acc: 0.759493670886076
Fold [2/5] Epoch [0/100] Initial Loss: 0.1351, Training Loss: 0.1351, Initial Validation Loss: 0.1215, Validation Loss: 0.1215,V Acc: 0.4775, Top 70th Acc: 0.5256, Bottom 30th Acc: 0.3636
Fold [2/5] Epoch [10/100] Initial Loss: 0.1351, Training Loss: 0.0796, Initial Validation Loss: 0.1215, Validation Loss: 0.0834,V Acc: 0.5676, Top 70th Acc: 0.6667, Bottom 30th Acc: 0.3333
Stopping early at Epoch (base 0): 16  Rolling back to Epoch (base 0): 11  Top Validation Acc: 0.6666666666666666
Fold [3/5] Epoch [0/100] Initial Loss: 0.1323, Training Loss: 0.1323, Initial Validation Loss: 0.1194, Validation Loss: 0.1194,V Acc: 0.4182, Top 70th Acc: 0.5584, Bottom 30th Acc: 0.0909
Fold [3/5] Epoch [10/100] Initial Loss: 0.1323, Training Loss: 0.0842, Initial Validation Loss: 0.1194, Validation Loss: 0.0689,V Acc: 0.7091, Top 70th Acc: 0.8701, Bottom 30th Acc: 0.3333
Fold [3/5] Epoch [20/100] Initial Loss: 0.1323, Training Loss: 0.0826, Initial Validation Loss: 0.1194, Validation Loss: 0.0651,V Acc: 0.6909, Top 70th Acc: 0.8571, Bottom 30th Acc: 0.3030
Fold [3/5] Epoch [30/100] Initial Loss: 0.1323, Training Loss: 0.0821, Initial Validation Loss: 0.1194, Validation Loss: 0.0645,V Acc: 0.7273, Top 70th Acc: 0.8442, Bottom 30th Acc: 0.4545
Fold [3/5] Epoch [40/100] Initial Loss: 0.1323, Training Loss: 0.0816, Initial Validation Loss: 0.1194, Validation Loss: 0.0640,V Acc: 0.7273, Top 70th Acc: 0.8571, Bottom 30th Acc: 0.4242
Stopping early at Epoch (base 0): 43  Rolling back to Epoch (base 0): 38  Top Validation Acc: 0.8571428571428571
76 2 [array([0.15619111, 0.3111113 , 0.17081067, 0.20656416, 0.1553228 ],
      dtype=float32)]
Fold [4/5] Epoch [0/100] Initial Loss: 0.1359, Training Loss: 0.1359, Initial Validation Loss: 0.1286, Validation Loss: 0.1286,V Acc: 0.4771, Top 70th Acc: 0.5195, Bottom 30th Acc: 0.3750
Fold [4/5] Epoch [10/100] Initial Loss: 0.1359, Training Loss: 0.0820, Initial Validation Loss: 0.1286, Validation Loss: 0.0754,V Acc: 0.6789, Top 70th Acc: 0.8312, Bottom 30th Acc: 0.3125
Fold [4/5] Epoch [20/100] Initial Loss: 0.1359, Training Loss: 0.0802, Initial Validation Loss: 0.1286, Validation Loss: 0.0738,V Acc: 0.6972, Top 70th Acc: 0.8312, Bottom 30th Acc: 0.3750
Stopping early at Epoch (base 0): 20  Rolling back to Epoch (base 0): 15  Top Validation Acc: 0.8311688311688312
Fold [5/5] Epoch [0/100] Initial Loss: 0.1328, Training Loss: 0.1328, Initial Validation Loss: 0.1240, Validation Loss: 0.1240,V Acc: 0.4167, Top 70th Acc: 0.5526, Bottom 30th Acc: 0.0938
Fold [5/5] Epoch [10/100] Initial Loss: 0.1328, Training Loss: 0.0768, Initial Validation Loss: 0.1240, Validation Loss: 0.0897,V Acc: 0.5463, Top 70th Acc: 0.6579, Bottom 30th Acc: 0.2812
Stopping early at Epoch (base 0): 11  Rolling back to Epoch (base 0): 6  Top Validation Acc: 0.6710526315789473
Running train_nn.py with seed 77
CUDA:False
Training samples count:  550
Training on 2 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1370, Training Loss: 0.1370, Initial Validation Loss: 0.1355, Validation Loss: 0.1355,V Acc: 0.3125, Top 70th Acc: 0.3544, Bottom 30th Acc: 0.2121
Fold [1/5] Epoch [10/100] Initial Loss: 0.1370, Training Loss: 0.0791, Initial Validation Loss: 0.1355, Validation Loss: 0.0897,V Acc: 0.5804, Top 70th Acc: 0.6835, Bottom 30th Acc: 0.3333
Fold [1/5] Epoch [20/100] Initial Loss: 0.1370, Training Loss: 0.0767, Initial Validation Loss: 0.1355, Validation Loss: 0.0884,V Acc: 0.5982, Top 70th Acc: 0.7089, Bottom 30th Acc: 0.3333
Fold [1/5] Epoch [30/100] Initial Loss: 0.1370, Training Loss: 0.0761, Initial Validation Loss: 0.1355, Validation Loss: 0.0874,V Acc: 0.6071, Top 70th Acc: 0.7215, Bottom 30th Acc: 0.3333
Stopping early at Epoch (base 0): 35  Rolling back to Epoch (base 0): 30  Top Validation Acc: 0.6962025316455697
Fold [2/5] Epoch [0/100] Initial Loss: 0.1342, Training Loss: 0.1342, Initial Validation Loss: 0.1282, Validation Loss: 0.1282,V Acc: 0.3333, Top 70th Acc: 0.3718, Bottom 30th Acc: 0.2424
Fold [2/5] Epoch [10/100] Initial Loss: 0.1342, Training Loss: 0.0810, Initial Validation Loss: 0.1282, Validation Loss: 0.0818,V Acc: 0.6577, Top 70th Acc: 0.7436, Bottom 30th Acc: 0.4545
Fold [2/5] Epoch [20/100] Initial Loss: 0.1342, Training Loss: 0.0787, Initial Validation Loss: 0.1282, Validation Loss: 0.0797,V Acc: 0.6396, Top 70th Acc: 0.7308, Bottom 30th Acc: 0.4242
Fold [2/5] Epoch [30/100] Initial Loss: 0.1342, Training Loss: 0.0784, Initial Validation Loss: 0.1282, Validation Loss: 0.0779,V Acc: 0.6306, Top 70th Acc: 0.7308, Bottom 30th Acc: 0.3939
Fold [2/5] Epoch [40/100] Initial Loss: 0.1342, Training Loss: 0.0778, Initial Validation Loss: 0.1282, Validation Loss: 0.0778,V Acc: 0.6486, Top 70th Acc: 0.7436, Bottom 30th Acc: 0.4242
Stopping early at Epoch (base 0): 47  Rolling back to Epoch (base 0): 42  Top Validation Acc: 0.7435897435897436
Fold [3/5] Epoch [0/100] Initial Loss: 0.1392, Training Loss: 0.1392, Initial Validation Loss: 0.1274, Validation Loss: 0.1274,V Acc: 0.4000, Top 70th Acc: 0.3766, Bottom 30th Acc: 0.4545
Fold [3/5] Epoch [10/100] Initial Loss: 0.1392, Training Loss: 0.0825, Initial Validation Loss: 0.1274, Validation Loss: 0.0767,V Acc: 0.6000, Top 70th Acc: 0.7143, Bottom 30th Acc: 0.3333
Fold [3/5] Epoch [20/100] Initial Loss: 0.1392, Training Loss: 0.0796, Initial Validation Loss: 0.1274, Validation Loss: 0.0742,V Acc: 0.6273, Top 70th Acc: 0.7143, Bottom 30th Acc: 0.4242
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.7142857142857143
Fold [4/5] Epoch [0/100] Initial Loss: 0.1423, Training Loss: 0.1423, Initial Validation Loss: 0.1287, Validation Loss: 0.1287,V Acc: 0.5596, Top 70th Acc: 0.4935, Bottom 30th Acc: 0.7188
Fold [4/5] Epoch [10/100] Initial Loss: 0.1423, Training Loss: 0.0850, Initial Validation Loss: 0.1287, Validation Loss: 0.0685,V Acc: 0.6972, Top 70th Acc: 0.8312, Bottom 30th Acc: 0.3750
Fold [4/5] Epoch [20/100] Initial Loss: 0.1423, Training Loss: 0.0830, Initial Validation Loss: 0.1287, Validation Loss: 0.0667,V Acc: 0.6789, Top 70th Acc: 0.8182, Bottom 30th Acc: 0.3438
Fold [4/5] Epoch [30/100] Initial Loss: 0.1423, Training Loss: 0.0825, Initial Validation Loss: 0.1287, Validation Loss: 0.0650,V Acc: 0.7064, Top 70th Acc: 0.8182, Bottom 30th Acc: 0.4375
Fold [4/5] Epoch [40/100] Initial Loss: 0.1423, Training Loss: 0.0821, Initial Validation Loss: 0.1287, Validation Loss: 0.0651,V Acc: 0.6972, Top 70th Acc: 0.8312, Bottom 30th Acc: 0.3750
Stopping early at Epoch (base 0): 43  Rolling back to Epoch (base 0): 38  Top Validation Acc: 0.8311688311688312
77 3 [array([0.12994863, 0.33849016, 0.16567194, 0.20960349, 0.15628578],
      dtype=float32)]
Fold [5/5] Epoch [0/100] Initial Loss: 0.1387, Training Loss: 0.1387, Initial Validation Loss: 0.1312, Validation Loss: 0.1312,V Acc: 0.3704, Top 70th Acc: 0.4211, Bottom 30th Acc: 0.2500
Fold [5/5] Epoch [10/100] Initial Loss: 0.1387, Training Loss: 0.0792, Initial Validation Loss: 0.1312, Validation Loss: 0.0854,V Acc: 0.6019, Top 70th Acc: 0.7237, Bottom 30th Acc: 0.3125
Fold [5/5] Epoch [20/100] Initial Loss: 0.1387, Training Loss: 0.0767, Initial Validation Loss: 0.1312, Validation Loss: 0.0849,V Acc: 0.6019, Top 70th Acc: 0.7237, Bottom 30th Acc: 0.3125/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)

Fold [4/5] Epoch [10/100] Initial Loss: 0.1398, Training Loss: 0.0384, Initial Validation Loss: 0.1351, Validation Loss: 0.0420,V Acc: 0.7890, Top 70th Acc: 0.8701, Bottom 30th Acc: 0.5938
Fold [4/5] Epoch [20/100] Initial Loss: 0.1398, Training Loss: 0.0252, Initial Validation Loss: 0.1351, Validation Loss: 0.0320,V Acc: 0.8440, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.6562
Fold [4/5] Epoch [30/100] Initial Loss: 0.1398, Training Loss: 0.0225, Initial Validation Loss: 0.1351, Validation Loss: 0.0309,V Acc: 0.8624, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.6875
Stopping early at Epoch (base 0): 33  Rolling back to Epoch (base 0): 28  Top Validation Acc: 0.9090909090909091
Fold [5/5] Epoch [0/100] Initial Loss: 0.1427, Training Loss: 0.1427, Initial Validation Loss: 0.1357, Validation Loss: 0.1357,V Acc: 0.2315, Top 70th Acc: 0.2632, Bottom 30th Acc: 0.1562
Fold [5/5] Epoch [10/100] Initial Loss: 0.1427, Training Loss: 0.0449, Initial Validation Loss: 0.1357, Validation Loss: 0.0520,V Acc: 0.7870, Top 70th Acc: 0.8553, Bottom 30th Acc: 0.6250
Fold [5/5] Epoch [20/100] Initial Loss: 0.1427, Training Loss: 0.0260, Initial Validation Loss: 0.1357, Validation Loss: 0.0339,V Acc: 0.8704, Top 70th Acc: 0.9211, Bottom 30th Acc: 0.7500
Fold [5/5] Epoch [30/100] Initial Loss: 0.1427, Training Loss: 0.0233, Initial Validation Loss: 0.1357, Validation Loss: 0.0324,V Acc: 0.8796, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.7500
Stopping early at Epoch (base 0): 33  Rolling back to Epoch (base 0): 28  Top Validation Acc: 0.9210526315789473
Running train_nn.py with seed 77
CUDA:False
Training samples count:  550
Training on 20 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1401, Training Loss: 0.1401, Initial Validation Loss: 0.1376, Validation Loss: 0.1376,V Acc: 0.3661, Top 70th Acc: 0.3797, Bottom 30th Acc: 0.3333
Fold [1/5] Epoch [10/100] Initial Loss: 0.1401, Training Loss: 0.0382, Initial Validation Loss: 0.1376, Validation Loss: 0.0397,V Acc: 0.8036, Top 70th Acc: 0.9241, Bottom 30th Acc: 0.5152
Fold [1/5] Epoch [20/100] Initial Loss: 0.1401, Training Loss: 0.0248, Initial Validation Loss: 0.1376, Validation Loss: 0.0316,V Acc: 0.8125, Top 70th Acc: 0.9494, Bottom 30th Acc: 0.4848
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.9620253164556962
Fold [2/5] Epoch [0/100] Initial Loss: 0.1394, Training Loss: 0.1394, Initial Validation Loss: 0.1349, Validation Loss: 0.1349,V Acc: 0.3784, Top 70th Acc: 0.3846, Bottom 30th Acc: 0.3636
Fold [2/5] Epoch [10/100] Initial Loss: 0.1394, Training Loss: 0.0352, Initial Validation Loss: 0.1349, Validation Loss: 0.0387,V Acc: 0.8559, Top 70th Acc: 0.8974, Bottom 30th Acc: 0.7576
Fold [2/5] Epoch [20/100] Initial Loss: 0.1394, Training Loss: 0.0227, Initial Validation Loss: 0.1349, Validation Loss: 0.0357,V Acc: 0.8288, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.9102564102564102
Fold [3/5] Epoch [0/100] Initial Loss: 0.1387, Training Loss: 0.1387, Initial Validation Loss: 0.1274, Validation Loss: 0.1274,V Acc: 0.4273, Top 70th Acc: 0.4675, Bottom 30th Acc: 0.3333
Fold [3/5] Epoch [10/100] Initial Loss: 0.1387, Training Loss: 0.0330, Initial Validation Loss: 0.1274, Validation Loss: 0.0378,V Acc: 0.8273, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.6364
Fold [3/5] Epoch [20/100] Initial Loss: 0.1387, Training Loss: 0.0238, Initial Validation Loss: 0.1274, Validation Loss: 0.0341,V Acc: 0.8273, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.6364
Fold [3/5] Epoch [30/100] Initial Loss: 0.1387, Training Loss: 0.0213, Initial Validation Loss: 0.1274, Validation Loss: 0.0345,V Acc: 0.8364, Top 70th Acc: 0.8961, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 33  Rolling back to Epoch (base 0): 28  Top Validation Acc: 0.9090909090909091
Fold [4/5] Epoch [0/100] Initial Loss: 0.1397, Training Loss: 0.1397, Initial Validation Loss: 0.1288, Validation Loss: 0.1288,V Acc: 0.2936, Top 70th Acc: 0.3636, Bottom 30th Acc: 0.1250
Fold [4/5] Epoch [10/100] Initial Loss: 0.1397, Training Loss: 0.0412, Initial Validation Loss: 0.1288, Validation Loss: 0.0415,V Acc: 0.8349, Top 70th Acc: 0.8701, Bottom 30th Acc: 0.7500
Fold [4/5] Epoch [20/100] Initial Loss: 0.1397, Training Loss: 0.0250, Initial Validation Loss: 0.1288, Validation Loss: 0.0331,V Acc: 0.8532, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.7188
Stopping early at Epoch (base 0): 28  Rolling back to Epoch (base 0): 23  Top Validation Acc: 0.922077922077922
77 3 [array([0.53789204, 0.10070805, 0.08489811, 0.17128721, 0.10521451],
      dtype=float32)]
Fold [5/5] Epoch [0/100] Initial Loss: 0.1401, Training Loss: 0.1401, Initial Validation Loss: 0.1354, Validation Loss: 0.1354,V Acc: 0.2500, Top 70th Acc: 0.3158, Bottom 30th Acc: 0.0938
Fold [5/5] Epoch [10/100] Initial Loss: 0.1401, Training Loss: 0.0381, Initial Validation Loss: 0.1354, Validation Loss: 0.0412,V Acc: 0.8333, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.5938
Fold [5/5] Epoch [20/100] Initial Loss: 0.1401, Training Loss: 0.0230, Initial Validation Loss: 0.1354, Validation Loss: 0.0348,V Acc: 0.8333, Top 70th Acc: 0.9211, Bottom 30th Acc: 0.6250
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.9078947368421053
Running train_nn.py with seed 78
CUDA:False
Training samples count:  550
Training on 20 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1373, Training Loss: 0.1373, Initial Validation Loss: 0.1388, Validation Loss: 0.1388,V Acc: 0.3214, Top 70th Acc: 0.3418, Bottom 30th Acc: 0.2727
Fold [1/5] Epoch [10/100] Initial Loss: 0.1373, Training Loss: 0.0432, Initial Validation Loss: 0.1388, Validation Loss: 0.0525,V Acc: 0.7946, Top 70th Acc: 0.8481, Bottom 30th Acc: 0.6667
Fold [1/5] Epoch [20/100] Initial Loss: 0.1373, Training Loss: 0.0300, Initial Validation Loss: 0.1388, Validation Loss: 0.0405,V Acc: 0.8304, Top 70th Acc: 0.9114, Bottom 30th Acc: 0.6364
Fold [1/5] Epoch [30/100] Initial Loss: 0.1373, Training Loss: 0.0250, Initial Validation Loss: 0.1388, Validation Loss: 0.0341,V Acc: 0.8661, Top 70th Acc: 0.9241, Bottom 30th Acc: 0.7273
Fold [1/5] Epoch [40/100] Initial Loss: 0.1373, Training Loss: 0.0234, Initial Validation Loss: 0.1388, Validation Loss: 0.0316,V Acc: 0.8661, Top 70th Acc: 0.9241, Bottom 30th Acc: 0.7273
Fold [1/5] Epoch [50/100] Initial Loss: 0.1373, Training Loss: 0.0226, Initial Validation Loss: 0.1388, Validation Loss: 0.0300,V Acc: 0.9018, Top 70th Acc: 0.9241, Bottom 30th Acc: 0.8485
Fold [1/5] Epoch [60/100] Initial Loss: 0.1373, Training Loss: 0.0222, Initial Validation Loss: 0.1388, Validation Loss: 0.0303,V Acc: 0.8929, Top 70th Acc: 0.9494, Bottom 30th Acc: 0.7576
Stopping early at Epoch (base 0): 61  Rolling back to Epoch (base 0): 56  Top Validation Acc: 0.9240506329113924
Fold [2/5] Epoch [0/100] Initial Loss: 0.1396, Training Loss: 0.1396, Initial Validation Loss: 0.1314, Validation Loss: 0.1314,V Acc: 0.3153, Top 70th Acc: 0.2949, Bottom 30th Acc: 0.3636
Fold [2/5] Epoch [10/100] Initial Loss: 0.1396, Training Loss: 0.0361, Initial Validation Loss: 0.1314, Validation Loss: 0.0427,V Acc: 0.7928, Top 70th Acc: 0.8846, Bottom 30th Acc: 0.5758
Fold [2/5] Epoch [20/100] Initial Loss: 0.1396, Training Loss: 0.0235, Initial Validation Loss: 0.1314, Validation Loss: 0.0391,V Acc: 0.7658, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.3939
Fold [2/5] Epoch [30/100] Initial Loss: 0.1396, Training Loss: 0.0210, Initial Validation Loss: 0.1314, Validation Loss: 0.0346,V Acc: 0.7838, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.4545
Stopping early at Epoch (base 0): 37  Rolling back to Epoch (base 0): 32  Top Validation Acc: 0.9230769230769231
Fold [3/5] Epoch [0/100] Initial Loss: 0.1373, Training Loss: 0.1373, Initial Validation Loss: 0.1328, Validation Loss: 0.1328,V Acc: 0.2909, Top 70th Acc: 0.3636, Bottom 30th Acc: 0.1212
Fold [3/5] Epoch [10/100] Initial Loss: 0.1373, Training Loss: 0.0336, Initial Validation Loss: 0.1328, Validation Loss: 0.0401,V Acc: 0.8818, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.7273
Fold [3/5] Epoch [20/100] Initial Loss: 0.1373, Training Loss: 0.0230, Initial Validation Loss: 0.1328, Validation Loss: 0.0337,V Acc: 0.8818, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.7273/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)

CUDA:False
Training samples count:  550
Training on 162 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1395, Training Loss: 0.1395, Initial Validation Loss: 0.1380, Validation Loss: 0.1380,V Acc: 0.2857, Top 70th Acc: 0.3544, Bottom 30th Acc: 0.1212
Fold [1/5] Epoch [10/100] Initial Loss: 0.1395, Training Loss: 0.0278, Initial Validation Loss: 0.1380, Validation Loss: 0.0533,V Acc: 0.7411, Top 70th Acc: 0.8734, Bottom 30th Acc: 0.4242
Fold [1/5] Epoch [20/100] Initial Loss: 0.1395, Training Loss: 0.0068, Initial Validation Loss: 0.1380, Validation Loss: 0.0499,V Acc: 0.7589, Top 70th Acc: 0.8481, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 22  Rolling back to Epoch (base 0): 17  Top Validation Acc: 0.8481012658227848
Fold [2/5] Epoch [0/100] Initial Loss: 0.1406, Training Loss: 0.1406, Initial Validation Loss: 0.1346, Validation Loss: 0.1346,V Acc: 0.2523, Top 70th Acc: 0.2949, Bottom 30th Acc: 0.1515
Fold [2/5] Epoch [10/100] Initial Loss: 0.1406, Training Loss: 0.0250, Initial Validation Loss: 0.1346, Validation Loss: 0.0391,V Acc: 0.8198, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.6061
Fold [2/5] Epoch [20/100] Initial Loss: 0.1406, Training Loss: 0.0055, Initial Validation Loss: 0.1346, Validation Loss: 0.0256,V Acc: 0.9009, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.7576
Fold [2/5] Epoch [30/100] Initial Loss: 0.1406, Training Loss: 0.0041, Initial Validation Loss: 0.1346, Validation Loss: 0.0251,V Acc: 0.8919, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.7576
Stopping early at Epoch (base 0): 32  Rolling back to Epoch (base 0): 27  Top Validation Acc: 0.9487179487179487
Fold [3/5] Epoch [0/100] Initial Loss: 0.1407, Training Loss: 0.1407, Initial Validation Loss: 0.1330, Validation Loss: 0.1330,V Acc: 0.3818, Top 70th Acc: 0.4156, Bottom 30th Acc: 0.3030
Fold [3/5] Epoch [10/100] Initial Loss: 0.1407, Training Loss: 0.0132, Initial Validation Loss: 0.1330, Validation Loss: 0.0268,V Acc: 0.8818, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.6970
Fold [3/5] Epoch [20/100] Initial Loss: 0.1407, Training Loss: 0.0050, Initial Validation Loss: 0.1330, Validation Loss: 0.0236,V Acc: 0.8818, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.6667
Fold [3/5] Epoch [30/100] Initial Loss: 0.1407, Training Loss: 0.0040, Initial Validation Loss: 0.1330, Validation Loss: 0.0235,V Acc: 0.8727, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 32  Rolling back to Epoch (base 0): 27  Top Validation Acc: 0.961038961038961
Fold [4/5] Epoch [0/100] Initial Loss: 0.1387, Training Loss: 0.1387, Initial Validation Loss: 0.1327, Validation Loss: 0.1327,V Acc: 0.3394, Top 70th Acc: 0.4026, Bottom 30th Acc: 0.1875
Fold [4/5] Epoch [10/100] Initial Loss: 0.1387, Training Loss: 0.0143, Initial Validation Loss: 0.1327, Validation Loss: 0.0263,V Acc: 0.8807, Top 70th Acc: 0.9870, Bottom 30th Acc: 0.6250
Fold [4/5] Epoch [20/100] Initial Loss: 0.1387, Training Loss: 0.0051, Initial Validation Loss: 0.1327, Validation Loss: 0.0230,V Acc: 0.9083, Top 70th Acc: 0.9870, Bottom 30th Acc: 0.7188
Stopping early at Epoch (base 0): 27  Rolling back to Epoch (base 0): 22  Top Validation Acc: 0.987012987012987
59 3 [array([0.34134173, 0.04117242, 0.09971784, 0.2738514 , 0.24391669],
      dtype=float32)]
Fold [5/5] Epoch [0/100] Initial Loss: 0.1397, Training Loss: 0.1397, Initial Validation Loss: 0.1300, Validation Loss: 0.1300,V Acc: 0.3148, Top 70th Acc: 0.4079, Bottom 30th Acc: 0.0938
Fold [5/5] Epoch [10/100] Initial Loss: 0.1397, Training Loss: 0.0176, Initial Validation Loss: 0.1300, Validation Loss: 0.0378,V Acc: 0.8056, Top 70th Acc: 0.9079, Bottom 30th Acc: 0.5625
Fold [5/5] Epoch [20/100] Initial Loss: 0.1397, Training Loss: 0.0057, Initial Validation Loss: 0.1300, Validation Loss: 0.0349,V Acc: 0.8241, Top 70th Acc: 0.9211, Bottom 30th Acc: 0.5938
Fold [5/5] Epoch [30/100] Initial Loss: 0.1397, Training Loss: 0.0043, Initial Validation Loss: 0.1300, Validation Loss: 0.0338,V Acc: 0.8148, Top 70th Acc: 0.9211, Bottom 30th Acc: 0.5625
Fold [5/5] Epoch [40/100] Initial Loss: 0.1397, Training Loss: 0.0040, Initial Validation Loss: 0.1300, Validation Loss: 0.0332,V Acc: 0.8426, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.6250
Fold [5/5] Epoch [50/100] Initial Loss: 0.1397, Training Loss: 0.0038, Initial Validation Loss: 0.1300, Validation Loss: 0.0327,V Acc: 0.8426, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.6250
Stopping early at Epoch (base 0): 51  Rolling back to Epoch (base 0): 46  Top Validation Acc: 0.9210526315789473
Running train_nn.py with seed 60
CUDA:False
Training samples count:  550
Training on 162 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1395, Training Loss: 0.1395, Initial Validation Loss: 0.1329, Validation Loss: 0.1329,V Acc: 0.4375, Top 70th Acc: 0.5570, Bottom 30th Acc: 0.1515
Fold [1/5] Epoch [10/100] Initial Loss: 0.1395, Training Loss: 0.0131, Initial Validation Loss: 0.1329, Validation Loss: 0.0341,V Acc: 0.8482, Top 70th Acc: 0.9494, Bottom 30th Acc: 0.6061
Fold [1/5] Epoch [20/100] Initial Loss: 0.1395, Training Loss: 0.0050, Initial Validation Loss: 0.1329, Validation Loss: 0.0335,V Acc: 0.8304, Top 70th Acc: 0.9620, Bottom 30th Acc: 0.5152
Fold [1/5] Epoch [30/100] Initial Loss: 0.1395, Training Loss: 0.0041, Initial Validation Loss: 0.1329, Validation Loss: 0.0326,V Acc: 0.8304, Top 70th Acc: 0.9494, Bottom 30th Acc: 0.5455
Fold [1/5] Epoch [40/100] Initial Loss: 0.1395, Training Loss: 0.0038, Initial Validation Loss: 0.1329, Validation Loss: 0.0317,V Acc: 0.8482, Top 70th Acc: 0.9494, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 46  Rolling back to Epoch (base 0): 41  Top Validation Acc: 0.9493670886075949
Fold [2/5] Epoch [0/100] Initial Loss: 0.1389, Training Loss: 0.1389, Initial Validation Loss: 0.1348, Validation Loss: 0.1348,V Acc: 0.3243, Top 70th Acc: 0.4487, Bottom 30th Acc: 0.0303
Fold [2/5] Epoch [10/100] Initial Loss: 0.1389, Training Loss: 0.0160, Initial Validation Loss: 0.1348, Validation Loss: 0.0425,V Acc: 0.8198, Top 70th Acc: 0.8974, Bottom 30th Acc: 0.6364
Fold [2/5] Epoch [20/100] Initial Loss: 0.1389, Training Loss: 0.0056, Initial Validation Loss: 0.1348, Validation Loss: 0.0388,V Acc: 0.8108, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.5758
Fold [2/5] Epoch [30/100] Initial Loss: 0.1389, Training Loss: 0.0044, Initial Validation Loss: 0.1348, Validation Loss: 0.0384,V Acc: 0.8198, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.6061
Fold [2/5] Epoch [40/100] Initial Loss: 0.1389, Training Loss: 0.0040, Initial Validation Loss: 0.1348, Validation Loss: 0.0373,V Acc: 0.8198, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 40  Rolling back to Epoch (base 0): 35  Top Validation Acc: 0.9230769230769231
Fold [3/5] Epoch [0/100] Initial Loss: 0.1412, Training Loss: 0.1412, Initial Validation Loss: 0.1301, Validation Loss: 0.1301,V Acc: 0.3545, Top 70th Acc: 0.4156, Bottom 30th Acc: 0.2121
Fold [3/5] Epoch [10/100] Initial Loss: 0.1412, Training Loss: 0.0165, Initial Validation Loss: 0.1301, Validation Loss: 0.0314,V Acc: 0.8455, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.5758
Fold [3/5] Epoch [20/100] Initial Loss: 0.1412, Training Loss: 0.0045, Initial Validation Loss: 0.1301, Validation Loss: 0.0290,V Acc: 0.8273, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.5152
Stopping early at Epoch (base 0): 20  Rolling back to Epoch (base 0): 15  Top Validation Acc: 0.961038961038961
Fold [4/5] Epoch [0/100] Initial Loss: 0.1369, Training Loss: 0.1369, Initial Validation Loss: 0.1312, Validation Loss: 0.1312,V Acc: 0.3670, Top 70th Acc: 0.4286, Bottom 30th Acc: 0.2188
Fold [4/5] Epoch [10/100] Initial Loss: 0.1369, Training Loss: 0.0144, Initial Validation Loss: 0.1312, Validation Loss: 0.0324,V Acc: 0.8716, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.6562
Fold [4/5] Epoch [20/100] Initial Loss: 0.1369, Training Loss: 0.0054, Initial Validation Loss: 0.1312, Validation Loss: 0.0277,V Acc: 0.8899, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.7500
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.961038961038961
Fold [5/5] Epoch [0/100] Initial Loss: 0.1385, Training Loss: 0.1385, Initial Validation Loss: 0.1307, Validation Loss: 0.1307,V Acc: 0.2870, Top 70th Acc: 0.3158, Bottom 30th Acc: 0.2188
Stopping early at Epoch (base 0): 32  Rolling back to Epoch (base 0): 27  Top Validation Acc: 0.9230769230769231
Fold [3/5] Epoch [0/100] Initial Loss: 0.1403, Training Loss: 0.1403, Initial Validation Loss: 0.1325, Validation Loss: 0.1325,V Acc: 0.3818, Top 70th Acc: 0.3896, Bottom 30th Acc: 0.3636
Fold [3/5] Epoch [10/100] Initial Loss: 0.1403, Training Loss: 0.0388, Initial Validation Loss: 0.1325, Validation Loss: 0.0375,V Acc: 0.8182, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.5152
Fold [3/5] Epoch [20/100] Initial Loss: 0.1403, Training Loss: 0.0197, Initial Validation Loss: 0.1325, Validation Loss: 0.0306,V Acc: 0.8182, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 27  Rolling back to Epoch (base 0): 22  Top Validation Acc: 0.948051948051948
76 2 [array([0.68426245, 0.0845591 , 0.02256529, 0.07953674, 0.12907644],
      dtype=float32)]
Fold [4/5] Epoch [0/100] Initial Loss: 0.1386, Training Loss: 0.1386, Initial Validation Loss: 0.1346, Validation Loss: 0.1346,V Acc: 0.3211, Top 70th Acc: 0.3247, Bottom 30th Acc: 0.3125
Fold [4/5] Epoch [10/100] Initial Loss: 0.1386, Training Loss: 0.0362, Initial Validation Loss: 0.1346, Validation Loss: 0.0454,V Acc: 0.7615, Top 70th Acc: 0.8701, Bottom 30th Acc: 0.5000
Fold [4/5] Epoch [20/100] Initial Loss: 0.1386, Training Loss: 0.0218, Initial Validation Loss: 0.1346, Validation Loss: 0.0317,V Acc: 0.8532, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.6562
Stopping early at Epoch (base 0): 29  Rolling back to Epoch (base 0): 24  Top Validation Acc: 0.948051948051948
Fold [5/5] Epoch [0/100] Initial Loss: 0.1380, Training Loss: 0.1380, Initial Validation Loss: 0.1340, Validation Loss: 0.1340,V Acc: 0.3056, Top 70th Acc: 0.3684, Bottom 30th Acc: 0.1562
Fold [5/5] Epoch [10/100] Initial Loss: 0.1380, Training Loss: 0.0284, Initial Validation Loss: 0.1340, Validation Loss: 0.0355,V Acc: 0.8333, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.5938
Fold [5/5] Epoch [20/100] Initial Loss: 0.1380, Training Loss: 0.0199, Initial Validation Loss: 0.1340, Validation Loss: 0.0281,V Acc: 0.8611, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.6562
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.9605263157894737
Running train_nn.py with seed 77
CUDA:False
Training samples count:  550
Training on 30 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1398, Training Loss: 0.1398, Initial Validation Loss: 0.1362, Validation Loss: 0.1362,V Acc: 0.3214, Top 70th Acc: 0.3671, Bottom 30th Acc: 0.2121
Fold [1/5] Epoch [10/100] Initial Loss: 0.1398, Training Loss: 0.0364, Initial Validation Loss: 0.1362, Validation Loss: 0.0415,V Acc: 0.7857, Top 70th Acc: 0.9114, Bottom 30th Acc: 0.4848
Fold [1/5] Epoch [20/100] Initial Loss: 0.1398, Training Loss: 0.0211, Initial Validation Loss: 0.1362, Validation Loss: 0.0304,V Acc: 0.8661, Top 70th Acc: 0.9494, Bottom 30th Acc: 0.6667
Fold [1/5] Epoch [30/100] Initial Loss: 0.1398, Training Loss: 0.0166, Initial Validation Loss: 0.1362, Validation Loss: 0.0258,V Acc: 0.9018, Top 70th Acc: 0.9747, Bottom 30th Acc: 0.7273
Stopping early at Epoch (base 0): 36  Rolling back to Epoch (base 0): 31  Top Validation Acc: 0.9746835443037974
Fold [2/5] Epoch [0/100] Initial Loss: 0.1394, Training Loss: 0.1394, Initial Validation Loss: 0.1373, Validation Loss: 0.1373,V Acc: 0.3784, Top 70th Acc: 0.4359, Bottom 30th Acc: 0.2424
Fold [2/5] Epoch [10/100] Initial Loss: 0.1394, Training Loss: 0.0411, Initial Validation Loss: 0.1373, Validation Loss: 0.0467,V Acc: 0.8108, Top 70th Acc: 0.8974, Bottom 30th Acc: 0.6061
Fold [2/5] Epoch [20/100] Initial Loss: 0.1394, Training Loss: 0.0171, Initial Validation Loss: 0.1373, Validation Loss: 0.0352,V Acc: 0.8108, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.5152
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.9487179487179487
Fold [3/5] Epoch [0/100] Initial Loss: 0.1406, Training Loss: 0.1406, Initial Validation Loss: 0.1311, Validation Loss: 0.1311,V Acc: 0.3000, Top 70th Acc: 0.3377, Bottom 30th Acc: 0.2121
Fold [3/5] Epoch [10/100] Initial Loss: 0.1406, Training Loss: 0.0431, Initial Validation Loss: 0.1311, Validation Loss: 0.0482,V Acc: 0.7364, Top 70th Acc: 0.8442, Bottom 30th Acc: 0.4848
Fold [3/5] Epoch [20/100] Initial Loss: 0.1406, Training Loss: 0.0201, Initial Validation Loss: 0.1311, Validation Loss: 0.0295,V Acc: 0.8455, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.935064935064935
Fold [4/5] Epoch [0/100] Initial Loss: 0.1387, Training Loss: 0.1387, Initial Validation Loss: 0.1296, Validation Loss: 0.1296,V Acc: 0.2477, Top 70th Acc: 0.3247, Bottom 30th Acc: 0.0625
Fold [4/5] Epoch [10/100] Initial Loss: 0.1387, Training Loss: 0.0347, Initial Validation Loss: 0.1296, Validation Loss: 0.0326,V Acc: 0.8440, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.5625
Fold [4/5] Epoch [20/100] Initial Loss: 0.1387, Training Loss: 0.0210, Initial Validation Loss: 0.1296, Validation Loss: 0.0265,V Acc: 0.8716, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.6562
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.961038961038961
77 3 [array([0.7542562 , 0.07957271, 0.0277154 , 0.07331594, 0.0651397 ],
      dtype=float32)]
Fold [5/5] Epoch [0/100] Initial Loss: 0.1394, Training Loss: 0.1394, Initial Validation Loss: 0.1333, Validation Loss: 0.1333,V Acc: 0.3056, Top 70th Acc: 0.3816, Bottom 30th Acc: 0.1250
Fold [5/5] Epoch [10/100] Initial Loss: 0.1394, Training Loss: 0.0302, Initial Validation Loss: 0.1333, Validation Loss: 0.0400,V Acc: 0.8056, Top 70th Acc: 0.9079, Bottom 30th Acc: 0.5625
Fold [5/5] Epoch [20/100] Initial Loss: 0.1394, Training Loss: 0.0194, Initial Validation Loss: 0.1333, Validation Loss: 0.0343,V Acc: 0.8333, Top 70th Acc: 0.9211, Bottom 30th Acc: 0.6250
Stopping early at Epoch (base 0): 22  Rolling back to Epoch (base 0): 17  Top Validation Acc: 0.9342105263157895
Running train_nn.py with seed 78
CUDA:False
Training samples count:  550
Training on 30 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1482, Training Loss: 0.1482, Initial Validation Loss: 0.1422, Validation Loss: 0.1422,V Acc: 0.2857, Top 70th Acc: 0.3165, Bottom 30th Acc: 0.2121
Fold [1/5] Epoch [10/100] Initial Loss: 0.1482, Training Loss: 0.0390, Initial Validation Loss: 0.1422, Validation Loss: 0.0452,V Acc: 0.7946, Top 70th Acc: 0.8987, Bottom 30th Acc: 0.5455
Fold [1/5] Epoch [20/100] Initial Loss: 0.1482, Training Loss: 0.0206, Initial Validation Loss: 0.1422, Validation Loss: 0.0295,V Acc: 0.8661, Top 70th Acc: 0.9747, Bottom 30th Acc: 0.6061
Fold [1/5] Epoch [30/100] Initial Loss: 0.1482, Training Loss: 0.0172, Initial Validation Loss: 0.1422, Validation Loss: 0.0269,V Acc: 0.8839, Top 70th Acc: 0.9747, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 31  Rolling back to Epoch (base 0): 26  Top Validation Acc: 0.9620253164556962
Fold [2/5] Epoch [0/100] Initial Loss: 0.1417, Training Loss: 0.1417, Initial Validation Loss: 0.1332, Validation Loss: 0.1332,V Acc: 0.2613, Top 70th Acc: 0.2436, Bottom 30th Acc: 0.3030
Fold [2/5] Epoch [10/100] Initial Loss: 0.1417, Training Loss: 0.0306, Initial Validation Loss: 0.1332, Validation Loss: 0.0352,V Acc: 0.8378, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.6061
Fold [2/5] Epoch [20/100] Initial Loss: 0.1417, Training Loss: 0.0183, Initial Validation Loss: 0.1332, Validation Loss: 0.0277,V Acc: 0.8378, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.9615384615384616
Fold [3/5] Epoch [0/100] Initial Loss: 0.1394, Training Loss: 0.1394, Initial Validation Loss: 0.1319, Validation Loss: 0.1319,V Acc: 0.4000, Top 70th Acc: 0.5065, Bottom 30th Acc: 0.1515
Fold [3/5] Epoch [10/100] Initial Loss: 0.1394, Training Loss: 0.0356, Initial Validation Loss: 0.1319, Validation Loss: 0.0480,V Acc: 0.8000, Top 70th Acc: 0.8831, Bottom 30th Acc: 0.6061
Fold [3/5] Epoch [20/100] Initial Loss: 0.1394, Training Loss: 0.0186, Initial Validation Loss: 0.1319, Validation Loss: 0.0319,V Acc: 0.8727, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.7273
Stopping early at Epoch (base 0): 22  Rolling back to Epoch (base 0): 17  Top Validation Acc: 0.9473684210526315
Running train_nn.py with seed 80
CUDA:False
Training samples count:  550
Training on 40 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1422, Training Loss: 0.1422, Initial Validation Loss: 0.1412, Validation Loss: 0.1412,V Acc: 0.2857, Top 70th Acc: 0.2532, Bottom 30th Acc: 0.3636
Fold [1/5] Epoch [10/100] Initial Loss: 0.1422, Training Loss: 0.0392, Initial Validation Loss: 0.1412, Validation Loss: 0.0481,V Acc: 0.8125, Top 70th Acc: 0.9114, Bottom 30th Acc: 0.5758
Fold [1/5] Epoch [20/100] Initial Loss: 0.1422, Training Loss: 0.0188, Initial Validation Loss: 0.1412, Validation Loss: 0.0315,V Acc: 0.8750, Top 70th Acc: 0.9620, Bottom 30th Acc: 0.6667
Fold [1/5] Epoch [30/100] Initial Loss: 0.1422, Training Loss: 0.0134, Initial Validation Loss: 0.1412, Validation Loss: 0.0304,V Acc: 0.8661, Top 70th Acc: 0.9494, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 32  Rolling back to Epoch (base 0): 27  Top Validation Acc: 0.9493670886075949
Fold [2/5] Epoch [0/100] Initial Loss: 0.1405, Training Loss: 0.1405, Initial Validation Loss: 0.1350, Validation Loss: 0.1350,V Acc: 0.3063, Top 70th Acc: 0.3590, Bottom 30th Acc: 0.1818
Fold [2/5] Epoch [10/100] Initial Loss: 0.1405, Training Loss: 0.0325, Initial Validation Loss: 0.1350, Validation Loss: 0.0433,V Acc: 0.7928, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.5152
Fold [2/5] Epoch [20/100] Initial Loss: 0.1405, Training Loss: 0.0149, Initial Validation Loss: 0.1350, Validation Loss: 0.0337,V Acc: 0.8468, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 28  Rolling back to Epoch (base 0): 23  Top Validation Acc: 0.9358974358974359
80 1 [array([0.8246965 , 0.02294347, 0.01798674, 0.06196043, 0.07241293],
      dtype=float32)]
Fold [3/5] Epoch [0/100] Initial Loss: 0.1405, Training Loss: 0.1405, Initial Validation Loss: 0.1333, Validation Loss: 0.1333,V Acc: 0.3545, Top 70th Acc: 0.4675, Bottom 30th Acc: 0.0909
Fold [3/5] Epoch [10/100] Initial Loss: 0.1405, Training Loss: 0.0358, Initial Validation Loss: 0.1333, Validation Loss: 0.0453,V Acc: 0.7909, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.4848
Fold [3/5] Epoch [20/100] Initial Loss: 0.1405, Training Loss: 0.0168, Initial Validation Loss: 0.1333, Validation Loss: 0.0305,V Acc: 0.8636, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.6364
Fold [3/5] Epoch [30/100] Initial Loss: 0.1405, Training Loss: 0.0128, Initial Validation Loss: 0.1333, Validation Loss: 0.0295,V Acc: 0.8545, Top 70th Acc: 1.0000, Bottom 30th Acc: 0.5152
Fold [3/5] Epoch [40/100] Initial Loss: 0.1405, Training Loss: 0.0114, Initial Validation Loss: 0.1333, Validation Loss: 0.0292,V Acc: 0.8364, Top 70th Acc: 1.0000, Bottom 30th Acc: 0.4545
Stopping early at Epoch (base 0): 42  Rolling back to Epoch (base 0): 37  Top Validation Acc: 0.987012987012987
Fold [4/5] Epoch [0/100] Initial Loss: 0.1425, Training Loss: 0.1425, Initial Validation Loss: 0.1289, Validation Loss: 0.1289,V Acc: 0.2661, Top 70th Acc: 0.3506, Bottom 30th Acc: 0.0625
Fold [4/5] Epoch [10/100] Initial Loss: 0.1425, Training Loss: 0.0312, Initial Validation Loss: 0.1289, Validation Loss: 0.0413,V Acc: 0.7798, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.4688
Fold [4/5] Epoch [20/100] Initial Loss: 0.1425, Training Loss: 0.0143, Initial Validation Loss: 0.1289, Validation Loss: 0.0332,V Acc: 0.7890, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.4375
Fold [4/5] Epoch [30/100] Initial Loss: 0.1425, Training Loss: 0.0117, Initial Validation Loss: 0.1289, Validation Loss: 0.0329,V Acc: 0.8165, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.5312
Stopping early at Epoch (base 0): 32  Rolling back to Epoch (base 0): 27  Top Validation Acc: 0.935064935064935
Fold [5/5] Epoch [0/100] Initial Loss: 0.1409, Training Loss: 0.1409, Initial Validation Loss: 0.1332, Validation Loss: 0.1332,V Acc: 0.2500, Top 70th Acc: 0.3158, Bottom 30th Acc: 0.0938
Fold [5/5] Epoch [10/100] Initial Loss: 0.1409, Training Loss: 0.0314, Initial Validation Loss: 0.1332, Validation Loss: 0.0372,V Acc: 0.8333, Top 70th Acc: 0.9079, Bottom 30th Acc: 0.6562
Fold [5/5] Epoch [20/100] Initial Loss: 0.1409, Training Loss: 0.0161, Initial Validation Loss: 0.1332, Validation Loss: 0.0321,V Acc: 0.8241, Top 70th Acc: 0.9079, Bottom 30th Acc: 0.6250
Stopping early at Epoch (base 0): 22  Rolling back to Epoch (base 0): 17  Top Validation Acc: 0.9078947368421053
Running train_nn.py with seed 81
CUDA:False
Training samples count:  550
Training on 40 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1412, Training Loss: 0.1412, Initial Validation Loss: 0.1354, Validation Loss: 0.1354,V Acc: 0.2589, Top 70th Acc: 0.3418, Bottom 30th Acc: 0.0606
Fold [1/5] Epoch [10/100] Initial Loss: 0.1412, Training Loss: 0.0259, Initial Validation Loss: 0.1354, Validation Loss: 0.0296,V Acc: 0.8482, Top 70th Acc: 0.9494, Bottom 30th Acc: 0.6061
Fold [1/5] Epoch [20/100] Initial Loss: 0.1412, Training Loss: 0.0155, Initial Validation Loss: 0.1354, Validation Loss: 0.0251,V Acc: 0.8929, Top 70th Acc: 0.9494, Bottom 30th Acc: 0.7576
Stopping early at Epoch (base 0): 21  Rolling back to Epoch (base 0): 16  Top Validation Acc: 0.9493670886075949
Fold [2/5] Epoch [0/100] Initial Loss: 0.1410, Training Loss: 0.1410, Initial Validation Loss: 0.1347, Validation Loss: 0.1347,V Acc: 0.2883, Top 70th Acc: 0.3333, Bottom 30th Acc: 0.1818
Fold [2/5] Epoch [10/100] Initial Loss: 0.1410, Training Loss: 0.0386, Initial Validation Loss: 0.1347, Validation Loss: 0.0475,V Acc: 0.8108, Top 70th Acc: 0.8974, Bottom 30th Acc: 0.6061
Fold [2/5] Epoch [20/100] Initial Loss: 0.1410, Training Loss: 0.0151, Initial Validation Loss: 0.1347, Validation Loss: 0.0304,V Acc: 0.8559, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.6364
Fold [2/5] Epoch [30/100] Initial Loss: 0.1410, Training Loss: 0.0119, Initial Validation Loss: 0.1347, Validation Loss: 0.0303,V Acc: 0.8468, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 30  Rolling back to Epoch (base 0): 25  Top Validation Acc: 0.9487179487179487
Fold [3/5] Epoch [0/100] Initial Loss: 0.1397, Training Loss: 0.1397, Initial Validation Loss: 0.1335, Validation Loss: 0.1335,V Acc: 0.3636, Top 70th Acc: 0.4416, Bottom 30th Acc: 0.1818
Fold [3/5] Epoch [10/100] Initial Loss: 0.1397, Training Loss: 0.0250, Initial Validation Loss: 0.1335, Validation Loss: 0.0295,V Acc: 0.8727, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.6364
Fold [3/5] Epoch [20/100] Initial Loss: 0.1397, Training Loss: 0.0146, Initial Validation Loss: 0.1335, Validation Loss: 0.0231,V Acc: 0.8909, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.7576
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.948051948051948
Fold [4/5] Epoch [0/100] Initial Loss: 0.1383, Training Loss: 0.1383, Initial Validation Loss: 0.1360, Validation Loss: 0.1360,V Acc: 0.2752, Top 70th Acc: 0.2857, Bottom 30th Acc: 0.2500
Fold [4/5] Epoch [10/100] Initial Loss: 0.1383, Training Loss: 0.0322, Initial Validation Loss: 0.1360, Validation Loss: 0.0460,V Acc: 0.7982, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.4688
Fold [4/5] Epoch [20/100] Initial Loss: 0.1383, Training Loss: 0.0141, Initial Validation Loss: 0.1360, Validation Loss: 0.0364,V Acc: 0.8165, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.5312
Fold [4/5] Epoch [30/100] Initial Loss: 0.1383, Training Loss: 0.0105, Initial Validation Loss: 0.1360, Validation Loss: 0.0378,V Acc: 0.8073, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.5000
Stopping early at Epoch (base 0): 31  Rolling back to Epoch (base 0): 26  Top Validation Acc: 0.948051948051948
Fold [5/5] Epoch [0/100] Initial Loss: 0.1427, Training Loss: 0.1427, Initial Validation Loss: 0.1340, Validation Loss: 0.1340,V Acc: 0.2500, Top 70th Acc: 0.1711, Bottom 30th Acc: 0.4375
Fold [5/5] Epoch [10/100] Initial Loss: 0.1427, Training Loss: 0.0328, Initial Validation Loss: 0.1340, Validation Loss: 0.0319,V Acc: 0.8241, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.5312
Fold [5/5] Epoch [20/100] Initial Loss: 0.1427, Training Loss: 0.0148, Initial Validation Loss: 0.1340, Validation Loss: 0.0256,V Acc: 0.8611, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.6562
Stopping early at Epoch (base 0): 21  Rolling back to Epoch (base 0): 16  Top Validation Acc: 0.7368421052631579
Running train_nn.py with seed 78
CUDA:False
Training samples count:  550
Training on 2 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1440, Training Loss: 0.1440, Initial Validation Loss: 0.1386, Validation Loss: 0.1386,V Acc: 0.4286, Top 70th Acc: 0.5696, Bottom 30th Acc: 0.0909
Fold [1/5] Epoch [10/100] Initial Loss: 0.1440, Training Loss: 0.0802, Initial Validation Loss: 0.1386, Validation Loss: 0.0819,V Acc: 0.6250, Top 70th Acc: 0.7089, Bottom 30th Acc: 0.4242
Fold [1/5] Epoch [20/100] Initial Loss: 0.1440, Training Loss: 0.0777, Initial Validation Loss: 0.1386, Validation Loss: 0.0817,V Acc: 0.6250, Top 70th Acc: 0.7215, Bottom 30th Acc: 0.3939
Fold [1/5] Epoch [30/100] Initial Loss: 0.1440, Training Loss: 0.0767, Initial Validation Loss: 0.1386, Validation Loss: 0.0814,V Acc: 0.6161, Top 70th Acc: 0.7089, Bottom 30th Acc: 0.3939
Fold [1/5] Epoch [40/100] Initial Loss: 0.1440, Training Loss: 0.0765, Initial Validation Loss: 0.1386, Validation Loss: 0.0811,V Acc: 0.6339, Top 70th Acc: 0.7215, Bottom 30th Acc: 0.4242
Stopping early at Epoch (base 0): 42  Rolling back to Epoch (base 0): 37  Top Validation Acc: 0.7088607594936709
Fold [2/5] Epoch [0/100] Initial Loss: 0.1368, Training Loss: 0.1368, Initial Validation Loss: 0.1253, Validation Loss: 0.1253,V Acc: 0.4505, Top 70th Acc: 0.4744, Bottom 30th Acc: 0.3939
Fold [2/5] Epoch [10/100] Initial Loss: 0.1368, Training Loss: 0.0797, Initial Validation Loss: 0.1253, Validation Loss: 0.0811,V Acc: 0.5946, Top 70th Acc: 0.7179, Bottom 30th Acc: 0.3030
Fold [2/5] Epoch [20/100] Initial Loss: 0.1368, Training Loss: 0.0782, Initial Validation Loss: 0.1253, Validation Loss: 0.0803,V Acc: 0.6126, Top 70th Acc: 0.7308, Bottom 30th Acc: 0.3333
Fold [2/5] Epoch [30/100] Initial Loss: 0.1368, Training Loss: 0.0775, Initial Validation Loss: 0.1253, Validation Loss: 0.0803,V Acc: 0.6126, Top 70th Acc: 0.7308, Bottom 30th Acc: 0.3333
Stopping early at Epoch (base 0): 38  Rolling back to Epoch (base 0): 33  Top Validation Acc: 0.7435897435897436
Fold [3/5] Epoch [0/100] Initial Loss: 0.1428, Training Loss: 0.1428, Initial Validation Loss: 0.1336, Validation Loss: 0.1336,V Acc: 0.3545, Top 70th Acc: 0.4545, Bottom 30th Acc: 0.1212
Fold [3/5] Epoch [10/100] Initial Loss: 0.1428, Training Loss: 0.0815, Initial Validation Loss: 0.1336, Validation Loss: 0.0799,V Acc: 0.6364, Top 70th Acc: 0.7792, Bottom 30th Acc: 0.3030
Fold [3/5] Epoch [20/100] Initial Loss: 0.1428, Training Loss: 0.0795, Initial Validation Loss: 0.1336, Validation Loss: 0.0773,V Acc: 0.6545, Top 70th Acc: 0.7792, Bottom 30th Acc: 0.3636
Fold [3/5] Epoch [30/100] Initial Loss: 0.1428, Training Loss: 0.0788, Initial Validation Loss: 0.1336, Validation Loss: 0.0773,V Acc: 0.6636, Top 70th Acc: 0.7922, Bottom 30th Acc: 0.3636
Stopping early at Epoch (base 0): 30  Rolling back to Epoch (base 0): 25  Top Validation Acc: 0.7922077922077922
Fold [4/5] Epoch [0/100] Initial Loss: 0.1389, Training Loss: 0.1389, Initial Validation Loss: 0.1297, Validation Loss: 0.1297,V Acc: 0.3761, Top 70th Acc: 0.4545, Bottom 30th Acc: 0.1875
Fold [4/5] Epoch [10/100] Initial Loss: 0.1389, Training Loss: 0.0795, Initial Validation Loss: 0.1297, Validation Loss: 0.0829,V Acc: 0.6330, Top 70th Acc: 0.7532, Bottom 30th Acc: 0.3438
Fold [4/5] Epoch [20/100] Initial Loss: 0.1389, Training Loss: 0.0771, Initial Validation Loss: 0.1297, Validation Loss: 0.0805,V Acc: 0.6147, Top 70th Acc: 0.7532, Bottom 30th Acc: 0.2812
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.7402597402597403
Fold [5/5] Epoch [0/100] Initial Loss: 0.1464, Training Loss: 0.1464, Initial Validation Loss: 0.1314, Validation Loss: 0.1314,V Acc: 0.3519, Top 70th Acc: 0.3684, Bottom 30th Acc: 0.3125
Fold [5/5] Epoch [10/100] Initial Loss: 0.1464, Training Loss: 0.0825, Initial Validation Loss: 0.1314, Validation Loss: 0.0720,V Acc: 0.6389, Top 70th Acc: 0.7368, Bottom 30th Acc: 0.4062
Fold [5/5] Epoch [20/100] Initial Loss: 0.1464, Training Loss: 0.0800, Initial Validation Loss: 0.1314, Validation Loss: 0.0693,V Acc: 0.6296, Top 70th Acc: 0.7500, Bottom 30th Acc: 0.3438
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.75
78 4 [array([0.11611933, 0.38893285, 0.1443466 , 0.2101437 , 0.14045754],
      dtype=float32)]
Running train_nn.py with seed 79
CUDA:False
Training samples count:  550
Training on 2 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1384, Training Loss: 0.1384, Initial Validation Loss: 0.1268, Validation Loss: 0.1268,V Acc: 0.5446, Top 70th Acc: 0.6203, Bottom 30th Acc: 0.3636
Fold [1/5] Epoch [10/100] Initial Loss: 0.1384, Training Loss: 0.0823, Initial Validation Loss: 0.1268, Validation Loss: 0.0767,V Acc: 0.6429, Top 70th Acc: 0.7468, Bottom 30th Acc: 0.3939
Fold [1/5] Epoch [20/100] Initial Loss: 0.1384, Training Loss: 0.0798, Initial Validation Loss: 0.1268, Validation Loss: 0.0762,V Acc: 0.6518, Top 70th Acc: 0.7342, Bottom 30th Acc: 0.4545
Fold [1/5] Epoch [30/100] Initial Loss: 0.1384, Training Loss: 0.0794, Initial Validation Loss: 0.1268, Validation Loss: 0.0753,V Acc: 0.6518, Top 70th Acc: 0.7342, Bottom 30th Acc: 0.4545
Stopping early at Epoch (base 0): 31  Rolling back to Epoch (base 0): 26  Top Validation Acc: 0.7215189873417721
Fold [2/5] Epoch [0/100] Initial Loss: 0.1264, Training Loss: 0.1264, Initial Validation Loss: 0.1207, Validation Loss: 0.1207,V Acc: 0.4685, Top 70th Acc: 0.5000, Bottom 30th Acc: 0.3939
Fold [2/5] Epoch [10/100] Initial Loss: 0.1264, Training Loss: 0.0782, Initial Validation Loss: 0.1207, Validation Loss: 0.0890,V Acc: 0.6036, Top 70th Acc: 0.7179, Bottom 30th Acc: 0.3333
Fold [2/5] Epoch [20/100] Initial Loss: 0.1264, Training Loss: 0.0765, Initial Validation Loss: 0.1207, Validation Loss: 0.0866,V Acc: 0.6486, Top 70th Acc: 0.7308, Bottom 30th Acc: 0.4545
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.7307692307692307
Fold [3/5] Epoch [0/100] Initial Loss: 0.1395, Training Loss: 0.1395, Initial Validation Loss: 0.1291, Validation Loss: 0.1291,V Acc: 0.4818, Top 70th Acc: 0.4805, Bottom 30th Acc: 0.4848
Fold [3/5] Epoch [10/100] Initial Loss: 0.1395, Training Loss: 0.0821, Initial Validation Loss: 0.1291, Validation Loss: 0.0769,V Acc: 0.6364, Top 70th Acc: 0.7532, Bottom 30th Acc: 0.3636
Fold [3/5] Epoch [20/100] Initial Loss: 0.1395, Training Loss: 0.0798, Initial Validation Loss: 0.1291, Validation Loss: 0.0748,V Acc: 0.6455, Top 70th Acc: 0.7403, Bottom 30th Acc: 0.4242
Fold [3/5] Epoch [30/100] Initial Loss: 0.1395, Training Loss: 0.0793, Initial Validation Loss: 0.1291, Validation Loss: 0.0743,V Acc: 0.6455, Top 70th Acc: 0.7532, Bottom 30th Acc: 0.3939
Stopping early at Epoch (base 0): 35  Rolling back to Epoch (base 0): 30  Top Validation Acc: 0.7402597402597403
79 2 [array([0.10755498, 0.36762193, 0.1437925 , 0.22204013, 0.15899059],
      dtype=float32)]
Fold [4/5] Epoch [0/100] Initial Loss: 0.1373, Training Loss: 0.1373, Initial Validation Loss: 0.1248, Validation Loss: 0.1248,V Acc: 0.2752, Top 70th Acc: 0.3377, Bottom 30th Acc: 0.1250
Fold [4/5] Epoch [10/100] Initial Loss: 0.1373, Training Loss: 0.0801, Initial Validation Loss: 0.1248, Validation Loss: 0.0767,V Acc: 0.6055, Top 70th Acc: 0.7013, Bottom 30th Acc: 0.3750
Fold [4/5] Epoch [20/100] Initial Loss: 0.1373, Training Loss: 0.0781, Initial Validation Loss: 0.1248, Validation Loss: 0.0751,V Acc: 0.6147, Top 70th Acc: 0.7013, Bottom 30th Acc: 0.4062
Fold [4/5] Epoch [30/100] Initial Loss: 0.1373, Training Loss: 0.0778, Initial Validation Loss: 0.1248, Validation Loss: 0.0749,V Acc: 0.6330, Top 70th Acc: 0.7273, Bottom 30th Acc: 0.4062
Stopping early at Epoch (base 0): 31  Rolling back to Epoch (base 0): 26  Top Validation Acc: 0.7142857142857143
Fold [5/5] Epoch [0/100] Initial Loss: 0.1373, Training Loss: 0.1373, Initial Validation Loss: 0.1271, Validation Loss: 0.1271,V Acc: 0.3704, Top 70th Acc: 0.4342, Bottom 30th Acc: 0.2188
Fold [5/5] Epoch [10/100] Initial Loss: 0.1373, Training Loss: 0.0805, Initial Validation Loss: 0.1271, Validation Loss: 0.0793,V Acc: 0.6019, Top 70th Acc: 0.7368, Bottom 30th Acc: 0.2812/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)

Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.948051948051948
Fold [4/5] Epoch [0/100] Initial Loss: 0.1348, Training Loss: 0.1348, Initial Validation Loss: 0.1282, Validation Loss: 0.1282,V Acc: 0.3945, Top 70th Acc: 0.4935, Bottom 30th Acc: 0.1562
Fold [4/5] Epoch [10/100] Initial Loss: 0.1348, Training Loss: 0.0341, Initial Validation Loss: 0.1282, Validation Loss: 0.0337,V Acc: 0.8532, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.5938
Stopping early at Epoch (base 0): 19  Rolling back to Epoch (base 0): 14  Top Validation Acc: 0.948051948051948
Fold [5/5] Epoch [0/100] Initial Loss: 0.1432, Training Loss: 0.1432, Initial Validation Loss: 0.1287, Validation Loss: 0.1287,V Acc: 0.3981, Top 70th Acc: 0.3947, Bottom 30th Acc: 0.4062
Fold [5/5] Epoch [10/100] Initial Loss: 0.1432, Training Loss: 0.0312, Initial Validation Loss: 0.1287, Validation Loss: 0.0392,V Acc: 0.7870, Top 70th Acc: 0.8684, Bottom 30th Acc: 0.5938
Fold [5/5] Epoch [20/100] Initial Loss: 0.1432, Training Loss: 0.0219, Initial Validation Loss: 0.1287, Validation Loss: 0.0368,V Acc: 0.7963, Top 70th Acc: 0.8684, Bottom 30th Acc: 0.6250
Stopping early at Epoch (base 0): 21  Rolling back to Epoch (base 0): 16  Top Validation Acc: 0.868421052631579
78 4 [array([0.15753703, 0.0853502 , 0.21965115, 0.28359976, 0.25386187],
      dtype=float32)]
Running train_nn.py with seed 79
CUDA:False
Training samples count:  550
Training on 20 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1367, Training Loss: 0.1367, Initial Validation Loss: 0.1303, Validation Loss: 0.1303,V Acc: 0.3839, Top 70th Acc: 0.4430, Bottom 30th Acc: 0.2424
Fold [1/5] Epoch [10/100] Initial Loss: 0.1367, Training Loss: 0.0362, Initial Validation Loss: 0.1303, Validation Loss: 0.0351,V Acc: 0.8839, Top 70th Acc: 0.9367, Bottom 30th Acc: 0.7576
Fold [1/5] Epoch [20/100] Initial Loss: 0.1367, Training Loss: 0.0239, Initial Validation Loss: 0.1303, Validation Loss: 0.0300,V Acc: 0.8839, Top 70th Acc: 0.9620, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 21  Rolling back to Epoch (base 0): 16  Top Validation Acc: 0.9620253164556962
Fold [2/5] Epoch [0/100] Initial Loss: 0.1403, Training Loss: 0.1403, Initial Validation Loss: 0.1396, Validation Loss: 0.1396,V Acc: 0.3333, Top 70th Acc: 0.3590, Bottom 30th Acc: 0.2727
Fold [2/5] Epoch [10/100] Initial Loss: 0.1403, Training Loss: 0.0401, Initial Validation Loss: 0.1396, Validation Loss: 0.0439,V Acc: 0.8198, Top 70th Acc: 0.8974, Bottom 30th Acc: 0.6364
Fold [2/5] Epoch [20/100] Initial Loss: 0.1403, Training Loss: 0.0237, Initial Validation Loss: 0.1396, Validation Loss: 0.0326,V Acc: 0.8468, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.9358974358974359
Fold [3/5] Epoch [0/100] Initial Loss: 0.1404, Training Loss: 0.1404, Initial Validation Loss: 0.1319, Validation Loss: 0.1319,V Acc: 0.2545, Top 70th Acc: 0.2987, Bottom 30th Acc: 0.1515
Fold [3/5] Epoch [10/100] Initial Loss: 0.1404, Training Loss: 0.0420, Initial Validation Loss: 0.1319, Validation Loss: 0.0445,V Acc: 0.8000, Top 70th Acc: 0.8961, Bottom 30th Acc: 0.5758
Fold [3/5] Epoch [20/100] Initial Loss: 0.1404, Training Loss: 0.0236, Initial Validation Loss: 0.1319, Validation Loss: 0.0330,V Acc: 0.8273, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.935064935064935
79 2 [array([0.26655197, 0.20674527, 0.17503217, 0.16976301, 0.18190755],
      dtype=float32)]
Fold [4/5] Epoch [0/100] Initial Loss: 0.1400, Training Loss: 0.1400, Initial Validation Loss: 0.1303, Validation Loss: 0.1303,V Acc: 0.3303, Top 70th Acc: 0.4545, Bottom 30th Acc: 0.0312
Fold [4/5] Epoch [10/100] Initial Loss: 0.1400, Training Loss: 0.0416, Initial Validation Loss: 0.1303, Validation Loss: 0.0416,V Acc: 0.8073, Top 70th Acc: 0.8571, Bottom 30th Acc: 0.6875
Fold [4/5] Epoch [20/100] Initial Loss: 0.1400, Training Loss: 0.0239, Initial Validation Loss: 0.1303, Validation Loss: 0.0300,V Acc: 0.8532, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.6875
Stopping early at Epoch (base 0): 20  Rolling back to Epoch (base 0): 15  Top Validation Acc: 0.922077922077922
Fold [5/5] Epoch [0/100] Initial Loss: 0.1400, Training Loss: 0.1400, Initial Validation Loss: 0.1327, Validation Loss: 0.1327,V Acc: 0.3611, Top 70th Acc: 0.3816, Bottom 30th Acc: 0.3125
Fold [5/5] Epoch [10/100] Initial Loss: 0.1400, Training Loss: 0.0417, Initial Validation Loss: 0.1327, Validation Loss: 0.0478,V Acc: 0.7778, Top 70th Acc: 0.8816, Bottom 30th Acc: 0.5312
Fold [5/5] Epoch [20/100] Initial Loss: 0.1400, Training Loss: 0.0247, Initial Validation Loss: 0.1327, Validation Loss: 0.0380,V Acc: 0.7870, Top 70th Acc: 0.8947, Bottom 30th Acc: 0.5312
Fold [5/5] Epoch [30/100] Initial Loss: 0.1400, Training Loss: 0.0211, Initial Validation Loss: 0.1327, Validation Loss: 0.0373,V Acc: 0.7870, Top 70th Acc: 0.9079, Bottom 30th Acc: 0.5000
Stopping early at Epoch (base 0): 32  Rolling back to Epoch (base 0): 27  Top Validation Acc: 0.9078947368421053
Running train_nn.py with seed 80
CUDA:False
Training samples count:  550
Training on 20 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1398, Training Loss: 0.1398, Initial Validation Loss: 0.1391, Validation Loss: 0.1391,V Acc: 0.4107, Top 70th Acc: 0.4051, Bottom 30th Acc: 0.4242
Fold [1/5] Epoch [10/100] Initial Loss: 0.1398, Training Loss: 0.0422, Initial Validation Loss: 0.1391, Validation Loss: 0.0481,V Acc: 0.8036, Top 70th Acc: 0.8734, Bottom 30th Acc: 0.6364
Fold [1/5] Epoch [20/100] Initial Loss: 0.1398, Training Loss: 0.0267, Initial Validation Loss: 0.1391, Validation Loss: 0.0360,V Acc: 0.8304, Top 70th Acc: 0.9114, Bottom 30th Acc: 0.6364
Fold [1/5] Epoch [30/100] Initial Loss: 0.1398, Training Loss: 0.0234, Initial Validation Loss: 0.1391, Validation Loss: 0.0334,V Acc: 0.8482, Top 70th Acc: 0.9241, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 32  Rolling back to Epoch (base 0): 27  Top Validation Acc: 0.9240506329113924
Fold [2/5] Epoch [0/100] Initial Loss: 0.1441, Training Loss: 0.1441, Initial Validation Loss: 0.1373, Validation Loss: 0.1373,V Acc: 0.2613, Top 70th Acc: 0.2436, Bottom 30th Acc: 0.3030
Fold [2/5] Epoch [10/100] Initial Loss: 0.1441, Training Loss: 0.0353, Initial Validation Loss: 0.1373, Validation Loss: 0.0387,V Acc: 0.8468, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.6364
Fold [2/5] Epoch [20/100] Initial Loss: 0.1441, Training Loss: 0.0234, Initial Validation Loss: 0.1373, Validation Loss: 0.0335,V Acc: 0.8378, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 28  Rolling back to Epoch (base 0): 23  Top Validation Acc: 0.9230769230769231
80 1 [array([0.45796543, 0.0660846 , 0.05403406, 0.18824872, 0.23366717],
      dtype=float32)]
Fold [3/5] Epoch [0/100] Initial Loss: 0.1374, Training Loss: 0.1374, Initial Validation Loss: 0.1293, Validation Loss: 0.1293,V Acc: 0.4182, Top 70th Acc: 0.5195, Bottom 30th Acc: 0.1818
Fold [3/5] Epoch [10/100] Initial Loss: 0.1374, Training Loss: 0.0375, Initial Validation Loss: 0.1293, Validation Loss: 0.0435,V Acc: 0.8455, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.6667
Fold [3/5] Epoch [20/100] Initial Loss: 0.1374, Training Loss: 0.0233, Initial Validation Loss: 0.1293, Validation Loss: 0.0347,V Acc: 0.8545, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6364
Fold [3/5] Epoch [30/100] Initial Loss: 0.1374, Training Loss: 0.0215, Initial Validation Loss: 0.1293, Validation Loss: 0.0343,V Acc: 0.8545, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 31  Rolling back to Epoch (base 0): 26  Top Validation Acc: 0.935064935064935
Fold [4/5] Epoch [0/100] Initial Loss: 0.1388, Training Loss: 0.1388, Initial Validation Loss: 0.1252, Validation Loss: 0.1252,V Acc: 0.3303, Top 70th Acc: 0.3896, Bottom 30th Acc: 0.1875
Fold [4/5] Epoch [10/100] Initial Loss: 0.1388, Training Loss: 0.0304, Initial Validation Loss: 0.1252, Validation Loss: 0.0373,V Acc: 0.7982, Top 70th Acc: 0.8831, Bottom 30th Acc: 0.5938
Fold [4/5] Epoch [20/100] Initial Loss: 0.1388, Training Loss: 0.0236, Initial Validation Loss: 0.1252, Validation Loss: 0.0350,V Acc: 0.8257, Top 70th Acc: 0.8961, Bottom 30th Acc: 0.6562
Fold [3/5] Epoch [30/100] Initial Loss: 0.1394, Training Loss: 0.0154, Initial Validation Loss: 0.1319, Validation Loss: 0.0305,V Acc: 0.8727, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 31  Rolling back to Epoch (base 0): 26  Top Validation Acc: 0.961038961038961
Fold [4/5] Epoch [0/100] Initial Loss: 0.1392, Training Loss: 0.1392, Initial Validation Loss: 0.1350, Validation Loss: 0.1350,V Acc: 0.2844, Top 70th Acc: 0.3377, Bottom 30th Acc: 0.1562
Fold [4/5] Epoch [10/100] Initial Loss: 0.1392, Training Loss: 0.0295, Initial Validation Loss: 0.1350, Validation Loss: 0.0351,V Acc: 0.8440, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.5625
Fold [4/5] Epoch [20/100] Initial Loss: 0.1392, Training Loss: 0.0182, Initial Validation Loss: 0.1350, Validation Loss: 0.0275,V Acc: 0.8624, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6562
Fold [4/5] Epoch [30/100] Initial Loss: 0.1392, Training Loss: 0.0163, Initial Validation Loss: 0.1350, Validation Loss: 0.0262,V Acc: 0.8716, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.6562
Stopping early at Epoch (base 0): 36  Rolling back to Epoch (base 0): 31  Top Validation Acc: 0.961038961038961
Fold [5/5] Epoch [0/100] Initial Loss: 0.1403, Training Loss: 0.1403, Initial Validation Loss: 0.1283, Validation Loss: 0.1283,V Acc: 0.3056, Top 70th Acc: 0.3421, Bottom 30th Acc: 0.2188
Fold [5/5] Epoch [10/100] Initial Loss: 0.1403, Training Loss: 0.0389, Initial Validation Loss: 0.1283, Validation Loss: 0.0373,V Acc: 0.7870, Top 70th Acc: 0.9211, Bottom 30th Acc: 0.4688
Fold [5/5] Epoch [20/100] Initial Loss: 0.1403, Training Loss: 0.0178, Initial Validation Loss: 0.1283, Validation Loss: 0.0315,V Acc: 0.8056, Top 70th Acc: 0.9211, Bottom 30th Acc: 0.5312
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.9078947368421053
78 4 [array([0.506243  , 0.04860859, 0.04878014, 0.15580742, 0.24056084],
      dtype=float32)]
Running train_nn.py with seed 79
CUDA:False
Training samples count:  550
Training on 30 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1391, Training Loss: 0.1391, Initial Validation Loss: 0.1352, Validation Loss: 0.1352,V Acc: 0.2500, Top 70th Acc: 0.3544, Bottom 30th Acc: 0.0000
Fold [1/5] Epoch [10/100] Initial Loss: 0.1391, Training Loss: 0.0405, Initial Validation Loss: 0.1352, Validation Loss: 0.0441,V Acc: 0.7946, Top 70th Acc: 0.8987, Bottom 30th Acc: 0.5455
Fold [1/5] Epoch [20/100] Initial Loss: 0.1391, Training Loss: 0.0235, Initial Validation Loss: 0.1352, Validation Loss: 0.0328,V Acc: 0.8482, Top 70th Acc: 0.9367, Bottom 30th Acc: 0.6364
Fold [1/5] Epoch [30/100] Initial Loss: 0.1391, Training Loss: 0.0184, Initial Validation Loss: 0.1352, Validation Loss: 0.0278,V Acc: 0.8661, Top 70th Acc: 0.9620, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 37  Rolling back to Epoch (base 0): 32  Top Validation Acc: 0.9620253164556962
Fold [2/5] Epoch [0/100] Initial Loss: 0.1345, Training Loss: 0.1345, Initial Validation Loss: 0.1338, Validation Loss: 0.1338,V Acc: 0.4685, Top 70th Acc: 0.5769, Bottom 30th Acc: 0.2121
Fold [2/5] Epoch [10/100] Initial Loss: 0.1345, Training Loss: 0.0275, Initial Validation Loss: 0.1338, Validation Loss: 0.0369,V Acc: 0.8468, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.6364
Fold [2/5] Epoch [20/100] Initial Loss: 0.1345, Training Loss: 0.0166, Initial Validation Loss: 0.1338, Validation Loss: 0.0312,V Acc: 0.8739, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.7576
Stopping early at Epoch (base 0): 21  Rolling back to Epoch (base 0): 16  Top Validation Acc: 0.9230769230769231
Fold [3/5] Epoch [0/100] Initial Loss: 0.1422, Training Loss: 0.1422, Initial Validation Loss: 0.1333, Validation Loss: 0.1333,V Acc: 0.2364, Top 70th Acc: 0.2078, Bottom 30th Acc: 0.3030
Fold [3/5] Epoch [10/100] Initial Loss: 0.1422, Training Loss: 0.0373, Initial Validation Loss: 0.1333, Validation Loss: 0.0415,V Acc: 0.7909, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.5152
Fold [3/5] Epoch [20/100] Initial Loss: 0.1422, Training Loss: 0.0168, Initial Validation Loss: 0.1333, Validation Loss: 0.0279,V Acc: 0.8545, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.948051948051948
79 2 [array([0.75630355, 0.06572195, 0.03657829, 0.07106657, 0.07032967],
      dtype=float32)]
Fold [4/5] Epoch [0/100] Initial Loss: 0.1466, Training Loss: 0.1466, Initial Validation Loss: 0.1331, Validation Loss: 0.1331,V Acc: 0.2477, Top 70th Acc: 0.2987, Bottom 30th Acc: 0.1250
Fold [4/5] Epoch [10/100] Initial Loss: 0.1466, Training Loss: 0.0380, Initial Validation Loss: 0.1331, Validation Loss: 0.0385,V Acc: 0.7615, Top 70th Acc: 0.8831, Bottom 30th Acc: 0.4688
Fold [4/5] Epoch [20/100] Initial Loss: 0.1466, Training Loss: 0.0169, Initial Validation Loss: 0.1331, Validation Loss: 0.0319,V Acc: 0.8165, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.5000
Stopping early at Epoch (base 0): 22  Rolling back to Epoch (base 0): 17  Top Validation Acc: 0.948051948051948
Fold [5/5] Epoch [0/100] Initial Loss: 0.1438, Training Loss: 0.1438, Initial Validation Loss: 0.1354, Validation Loss: 0.1354,V Acc: 0.2315, Top 70th Acc: 0.1974, Bottom 30th Acc: 0.3125
Fold [5/5] Epoch [10/100] Initial Loss: 0.1438, Training Loss: 0.0422, Initial Validation Loss: 0.1354, Validation Loss: 0.0465,V Acc: 0.7500, Top 70th Acc: 0.8947, Bottom 30th Acc: 0.4062
Fold [5/5] Epoch [20/100] Initial Loss: 0.1438, Training Loss: 0.0171, Initial Validation Loss: 0.1354, Validation Loss: 0.0346,V Acc: 0.7963, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.4375
Stopping early at Epoch (base 0): 22  Rolling back to Epoch (base 0): 17  Top Validation Acc: 0.9473684210526315
Running train_nn.py with seed 80
CUDA:False
Training samples count:  550
Training on 30 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1415, Training Loss: 0.1415, Initial Validation Loss: 0.1394, Validation Loss: 0.1394,V Acc: 0.3125, Top 70th Acc: 0.4051, Bottom 30th Acc: 0.0909
Fold [1/5] Epoch [10/100] Initial Loss: 0.1415, Training Loss: 0.0274, Initial Validation Loss: 0.1394, Validation Loss: 0.0339,V Acc: 0.8571, Top 70th Acc: 0.9494, Bottom 30th Acc: 0.6364
Fold [1/5] Epoch [20/100] Initial Loss: 0.1415, Training Loss: 0.0175, Initial Validation Loss: 0.1394, Validation Loss: 0.0322,V Acc: 0.8482, Top 70th Acc: 0.9367, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 21  Rolling back to Epoch (base 0): 16  Top Validation Acc: 0.9367088607594937
Fold [2/5] Epoch [0/100] Initial Loss: 0.1402, Training Loss: 0.1402, Initial Validation Loss: 0.1358, Validation Loss: 0.1358,V Acc: 0.2703, Top 70th Acc: 0.3077, Bottom 30th Acc: 0.1818
Fold [2/5] Epoch [10/100] Initial Loss: 0.1402, Training Loss: 0.0310, Initial Validation Loss: 0.1358, Validation Loss: 0.0337,V Acc: 0.8468, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.5758
Fold [2/5] Epoch [20/100] Initial Loss: 0.1402, Training Loss: 0.0176, Initial Validation Loss: 0.1358, Validation Loss: 0.0311,V Acc: 0.8378, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 21  Rolling back to Epoch (base 0): 16  Top Validation Acc: 0.9487179487179487
80 1 [array([0.5976754 , 0.06840766, 0.0624585 , 0.09438616, 0.17707232],
      dtype=float32)]
Fold [3/5] Epoch [0/100] Initial Loss: 0.1421, Training Loss: 0.1421, Initial Validation Loss: 0.1362, Validation Loss: 0.1362,V Acc: 0.2364, Top 70th Acc: 0.3117, Bottom 30th Acc: 0.0606
Fold [3/5] Epoch [10/100] Initial Loss: 0.1421, Training Loss: 0.0411, Initial Validation Loss: 0.1362, Validation Loss: 0.0453,V Acc: 0.7636, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.4242
Fold [3/5] Epoch [20/100] Initial Loss: 0.1421, Training Loss: 0.0199, Initial Validation Loss: 0.1362, Validation Loss: 0.0313,V Acc: 0.8636, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.6364
Fold [3/5] Epoch [30/100] Initial Loss: 0.1421, Training Loss: 0.0159, Initial Validation Loss: 0.1362, Validation Loss: 0.0282,V Acc: 0.8727, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.6364
Fold [3/5] Epoch [40/100] Initial Loss: 0.1421, Training Loss: 0.0148, Initial Validation Loss: 0.1362, Validation Loss: 0.0275,V Acc: 0.8818, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.6667
Fold [5/5] Epoch [10/100] Initial Loss: 0.1385, Training Loss: 0.0260, Initial Validation Loss: 0.1307, Validation Loss: 0.0418,V Acc: 0.7963, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.4375
Fold [5/5] Epoch [20/100] Initial Loss: 0.1385, Training Loss: 0.0075, Initial Validation Loss: 0.1307, Validation Loss: 0.0310,V Acc: 0.8426, Top 70th Acc: 0.9737, Bottom 30th Acc: 0.5312
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.9605263157894737
60 4 [array([0.4479467 , 0.08317004, 0.05295399, 0.19961248, 0.21631673],
      dtype=float32)]
Running train_nn.py with seed 61
CUDA:False
Training samples count:  550
Training on 162 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1388, Training Loss: 0.1388, Initial Validation Loss: 0.1328, Validation Loss: 0.1328,V Acc: 0.3304, Top 70th Acc: 0.4177, Bottom 30th Acc: 0.1212
Fold [1/5] Epoch [10/100] Initial Loss: 0.1388, Training Loss: 0.0120, Initial Validation Loss: 0.1328, Validation Loss: 0.0323,V Acc: 0.8304, Top 70th Acc: 0.9494, Bottom 30th Acc: 0.5455
Fold [1/5] Epoch [20/100] Initial Loss: 0.1388, Training Loss: 0.0044, Initial Validation Loss: 0.1328, Validation Loss: 0.0317,V Acc: 0.8125, Top 70th Acc: 0.9367, Bottom 30th Acc: 0.5152
Stopping early at Epoch (base 0): 20  Rolling back to Epoch (base 0): 15  Top Validation Acc: 0.9367088607594937
Fold [2/5] Epoch [0/100] Initial Loss: 0.1401, Training Loss: 0.1401, Initial Validation Loss: 0.1325, Validation Loss: 0.1325,V Acc: 0.3694, Top 70th Acc: 0.4231, Bottom 30th Acc: 0.2424
Fold [2/5] Epoch [10/100] Initial Loss: 0.1401, Training Loss: 0.0293, Initial Validation Loss: 0.1325, Validation Loss: 0.0548,V Acc: 0.7027, Top 70th Acc: 0.7949, Bottom 30th Acc: 0.4848
Fold [2/5] Epoch [20/100] Initial Loss: 0.1401, Training Loss: 0.0060, Initial Validation Loss: 0.1325, Validation Loss: 0.0399,V Acc: 0.7838, Top 70th Acc: 0.8718, Bottom 30th Acc: 0.5758
Fold [2/5] Epoch [30/100] Initial Loss: 0.1401, Training Loss: 0.0041, Initial Validation Loss: 0.1325, Validation Loss: 0.0371,V Acc: 0.8198, Top 70th Acc: 0.8718, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 30  Rolling back to Epoch (base 0): 25  Top Validation Acc: 0.8717948717948718
Fold [3/5] Epoch [0/100] Initial Loss: 0.1430, Training Loss: 0.1430, Initial Validation Loss: 0.1348, Validation Loss: 0.1348,V Acc: 0.2727, Top 70th Acc: 0.3636, Bottom 30th Acc: 0.0606
Fold [3/5] Epoch [10/100] Initial Loss: 0.1430, Training Loss: 0.0328, Initial Validation Loss: 0.1348, Validation Loss: 0.0510,V Acc: 0.7545, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.3939
Fold [3/5] Epoch [20/100] Initial Loss: 0.1430, Training Loss: 0.0056, Initial Validation Loss: 0.1348, Validation Loss: 0.0308,V Acc: 0.8364, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.5455
Fold [3/5] Epoch [30/100] Initial Loss: 0.1430, Training Loss: 0.0040, Initial Validation Loss: 0.1348, Validation Loss: 0.0285,V Acc: 0.8364, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.5152
Fold [3/5] Epoch [40/100] Initial Loss: 0.1430, Training Loss: 0.0036, Initial Validation Loss: 0.1348, Validation Loss: 0.0278,V Acc: 0.8545, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.5758
Fold [3/5] Epoch [50/100] Initial Loss: 0.1430, Training Loss: 0.0035, Initial Validation Loss: 0.1348, Validation Loss: 0.0278,V Acc: 0.8364, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.5152
Stopping early at Epoch (base 0): 52  Rolling back to Epoch (base 0): 47  Top Validation Acc: 0.974025974025974
61 2 [array([0.1668459 , 0.04554369, 0.07056862, 0.34803087, 0.3690109 ],
      dtype=float32)]
Fold [4/5] Epoch [0/100] Initial Loss: 0.1386, Training Loss: 0.1386, Initial Validation Loss: 0.1330, Validation Loss: 0.1330,V Acc: 0.2477, Top 70th Acc: 0.3247, Bottom 30th Acc: 0.0625
Fold [4/5] Epoch [10/100] Initial Loss: 0.1386, Training Loss: 0.0112, Initial Validation Loss: 0.1330, Validation Loss: 0.0308,V Acc: 0.8899, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.7188
Fold [4/5] Epoch [20/100] Initial Loss: 0.1386, Training Loss: 0.0046, Initial Validation Loss: 0.1330, Validation Loss: 0.0284,V Acc: 0.8807, Top 70th Acc: 0.9870, Bottom 30th Acc: 0.6250
Stopping early at Epoch (base 0): 20  Rolling back to Epoch (base 0): 15  Top Validation Acc: 0.987012987012987
Fold [5/5] Epoch [0/100] Initial Loss: 0.1374, Training Loss: 0.1374, Initial Validation Loss: 0.1325, Validation Loss: 0.1325,V Acc: 0.3241, Top 70th Acc: 0.3816, Bottom 30th Acc: 0.1875
Fold [5/5] Epoch [10/100] Initial Loss: 0.1374, Training Loss: 0.0181, Initial Validation Loss: 0.1325, Validation Loss: 0.0310,V Acc: 0.8519, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.5938
Fold [5/5] Epoch [20/100] Initial Loss: 0.1374, Training Loss: 0.0050, Initial Validation Loss: 0.1325, Validation Loss: 0.0262,V Acc: 0.8981, Top 70th Acc: 0.9868, Bottom 30th Acc: 0.6875
Stopping early at Epoch (base 0): 27  Rolling back to Epoch (base 0): 22  Top Validation Acc: 0.9736842105263158
Running train_nn.py with seed 62
CUDA:False
Training samples count:  550
Training on 162 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1379, Training Loss: 0.1379, Initial Validation Loss: 0.1390, Validation Loss: 0.1390,V Acc: 0.3482, Top 70th Acc: 0.3924, Bottom 30th Acc: 0.2424
Fold [1/5] Epoch [10/100] Initial Loss: 0.1379, Training Loss: 0.0223, Initial Validation Loss: 0.1390, Validation Loss: 0.0249,V Acc: 0.9107, Top 70th Acc: 1.0000, Bottom 30th Acc: 0.6970
Fold [1/5] Epoch [20/100] Initial Loss: 0.1379, Training Loss: 0.0057, Initial Validation Loss: 0.1390, Validation Loss: 0.0159,V Acc: 0.9464, Top 70th Acc: 1.0000, Bottom 30th Acc: 0.8182
Fold [1/5] Epoch [30/100] Initial Loss: 0.1379, Training Loss: 0.0043, Initial Validation Loss: 0.1390, Validation Loss: 0.0158,V Acc: 0.9375, Top 70th Acc: 0.9747, Bottom 30th Acc: 0.8485
Stopping early at Epoch (base 0): 30  Rolling back to Epoch (base 0): 25  Top Validation Acc: 0.9746835443037974
Fold [2/5] Epoch [0/100] Initial Loss: 0.1383, Training Loss: 0.1383, Initial Validation Loss: 0.1337, Validation Loss: 0.1337,V Acc: 0.2523, Top 70th Acc: 0.3590, Bottom 30th Acc: 0.0000
Fold [2/5] Epoch [10/100] Initial Loss: 0.1383, Training Loss: 0.0154, Initial Validation Loss: 0.1337, Validation Loss: 0.0401,V Acc: 0.7928, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.4848
Fold [2/5] Epoch [20/100] Initial Loss: 0.1383, Training Loss: 0.0044, Initial Validation Loss: 0.1337, Validation Loss: 0.0339,V Acc: 0.8288, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.5152
Fold [2/5] Epoch [30/100] Initial Loss: 0.1383, Training Loss: 0.0035, Initial Validation Loss: 0.1337, Validation Loss: 0.0338,V Acc: 0.8288, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.5152
Stopping early at Epoch (base 0): 33  Rolling back to Epoch (base 0): 28  Top Validation Acc: 0.9615384615384616
Fold [3/5] Epoch [0/100] Initial Loss: 0.1379, Training Loss: 0.1379, Initial Validation Loss: 0.1327, Validation Loss: 0.1327,V Acc: 0.4364, Top 70th Acc: 0.4935, Bottom 30th Acc: 0.3030
Fold [3/5] Epoch [10/100] Initial Loss: 0.1379, Training Loss: 0.0140, Initial Validation Loss: 0.1327, Validation Loss: 0.0366,V Acc: 0.8545, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.6970
Fold [3/5] Epoch [20/100] Initial Loss: 0.1379, Training Loss: 0.0044, Initial Validation Loss: 0.1327, Validation Loss: 0.0338,V Acc: 0.8545, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 22  Rolling back to Epoch (base 0): 17  Top Validation Acc: 0.922077922077922
Fold [4/5] Epoch [0/100] Initial Loss: 0.1388, Training Loss: 0.1388, Initial Validation Loss: 0.1323, Validation Loss: 0.1323,V Acc: 0.3394, Top 70th Acc: 0.3506, Bottom 30th Acc: 0.3125
Fold [4/5] Epoch [10/100] Initial Loss: 0.1388, Training Loss: 0.0154, Initial Validation Loss: 0.1323, Validation Loss: 0.0471,V Acc: 0.7431, Top 70th Acc: 0.8831, Bottom 30th Acc: 0.4062
Fold [4/5] Epoch [20/100] Initial Loss: 0.1388, Training Loss: 0.0048, Initial Validation Loss: 0.1323, Validation Loss: 0.0423,V Acc: 0.7706, Top 70th Acc: 0.8831, Bottom 30th Acc: 0.5000
Fold [4/5] Epoch [30/100] Initial Loss: 0.1388, Training Loss: 0.0038, Initial Validation Loss: 0.1323, Validation Loss: 0.0404,V Acc: 0.7890, Top 70th Acc: 0.8961, Bottom 30th Acc: 0.5312
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.9342105263157895
81 4 [array([0.57593906, 0.08284883, 0.07779052, 0.14523047, 0.11819102],
      dtype=float32)]
Running train_nn.py with seed 82
CUDA:False
Training samples count:  550
Training on 40 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1407, Training Loss: 0.1407, Initial Validation Loss: 0.1326, Validation Loss: 0.1326,V Acc: 0.2500, Top 70th Acc: 0.2911, Bottom 30th Acc: 0.1515
Fold [1/5] Epoch [10/100] Initial Loss: 0.1407, Training Loss: 0.0330, Initial Validation Loss: 0.1326, Validation Loss: 0.0415,V Acc: 0.8036, Top 70th Acc: 0.8987, Bottom 30th Acc: 0.5758
Fold [1/5] Epoch [20/100] Initial Loss: 0.1407, Training Loss: 0.0173, Initial Validation Loss: 0.1326, Validation Loss: 0.0395,V Acc: 0.7857, Top 70th Acc: 0.8861, Bottom 30th Acc: 0.5455
Fold [1/5] Epoch [30/100] Initial Loss: 0.1407, Training Loss: 0.0125, Initial Validation Loss: 0.1326, Validation Loss: 0.0380,V Acc: 0.8036, Top 70th Acc: 0.8861, Bottom 30th Acc: 0.6061
Fold [1/5] Epoch [40/100] Initial Loss: 0.1407, Training Loss: 0.0110, Initial Validation Loss: 0.1326, Validation Loss: 0.0367,V Acc: 0.8214, Top 70th Acc: 0.8987, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 48  Rolling back to Epoch (base 0): 43  Top Validation Acc: 0.8987341772151899
Fold [2/5] Epoch [0/100] Initial Loss: 0.1384, Training Loss: 0.1384, Initial Validation Loss: 0.1371, Validation Loss: 0.1371,V Acc: 0.3063, Top 70th Acc: 0.3590, Bottom 30th Acc: 0.1818
Fold [2/5] Epoch [10/100] Initial Loss: 0.1384, Training Loss: 0.0333, Initial Validation Loss: 0.1371, Validation Loss: 0.0448,V Acc: 0.7928, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.5152
Fold [2/5] Epoch [20/100] Initial Loss: 0.1384, Training Loss: 0.0144, Initial Validation Loss: 0.1371, Validation Loss: 0.0333,V Acc: 0.8739, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.7273
Stopping early at Epoch (base 0): 29  Rolling back to Epoch (base 0): 24  Top Validation Acc: 0.9615384615384616
Fold [3/5] Epoch [0/100] Initial Loss: 0.1385, Training Loss: 0.1385, Initial Validation Loss: 0.1385, Validation Loss: 0.1385,V Acc: 0.3000, Top 70th Acc: 0.3247, Bottom 30th Acc: 0.2424
Fold [3/5] Epoch [10/100] Initial Loss: 0.1385, Training Loss: 0.0323, Initial Validation Loss: 0.1385, Validation Loss: 0.0411,V Acc: 0.8636, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.6970
Fold [3/5] Epoch [20/100] Initial Loss: 0.1385, Training Loss: 0.0143, Initial Validation Loss: 0.1385, Validation Loss: 0.0286,V Acc: 0.8727, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.974025974025974
Fold [4/5] Epoch [0/100] Initial Loss: 0.1401, Training Loss: 0.1401, Initial Validation Loss: 0.1349, Validation Loss: 0.1349,V Acc: 0.2385, Top 70th Acc: 0.2857, Bottom 30th Acc: 0.1250
Fold [4/5] Epoch [10/100] Initial Loss: 0.1401, Training Loss: 0.0410, Initial Validation Loss: 0.1349, Validation Loss: 0.0460,V Acc: 0.7706, Top 70th Acc: 0.8701, Bottom 30th Acc: 0.5312
Fold [4/5] Epoch [20/100] Initial Loss: 0.1401, Training Loss: 0.0202, Initial Validation Loss: 0.1349, Validation Loss: 0.0336,V Acc: 0.8257, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.6250
Fold [4/5] Epoch [30/100] Initial Loss: 0.1401, Training Loss: 0.0132, Initial Validation Loss: 0.1349, Validation Loss: 0.0298,V Acc: 0.8257, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.5625
Stopping early at Epoch (base 0): 35  Rolling back to Epoch (base 0): 30  Top Validation Acc: 0.948051948051948
Fold [5/5] Epoch [0/100] Initial Loss: 0.1381, Training Loss: 0.1381, Initial Validation Loss: 0.1267, Validation Loss: 0.1267,V Acc: 0.3519, Top 70th Acc: 0.3684, Bottom 30th Acc: 0.3125
Fold [5/5] Epoch [10/100] Initial Loss: 0.1381, Training Loss: 0.0303, Initial Validation Loss: 0.1267, Validation Loss: 0.0411,V Acc: 0.7593, Top 70th Acc: 0.8816, Bottom 30th Acc: 0.4688
Fold [5/5] Epoch [20/100] Initial Loss: 0.1381, Training Loss: 0.0129, Initial Validation Loss: 0.1267, Validation Loss: 0.0362,V Acc: 0.7685, Top 70th Acc: 0.8947, Bottom 30th Acc: 0.4688
Stopping early at Epoch (base 0): 20  Rolling back to Epoch (base 0): 15  Top Validation Acc: 0.8947368421052632
82 4 [array([0.3839144 , 0.07106211, 0.1265934 , 0.13995022, 0.27847978],
      dtype=float32)]
Running train_nn.py with seed 83
CUDA:False
Training samples count:  550
Training on 40 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1374, Training Loss: 0.1374, Initial Validation Loss: 0.1342, Validation Loss: 0.1342,V Acc: 0.3750, Top 70th Acc: 0.4810, Bottom 30th Acc: 0.1212
Fold [1/5] Epoch [10/100] Initial Loss: 0.1374, Training Loss: 0.0271, Initial Validation Loss: 0.1342, Validation Loss: 0.0300,V Acc: 0.8839, Top 70th Acc: 0.9620, Bottom 30th Acc: 0.6970
Fold [1/5] Epoch [20/100] Initial Loss: 0.1374, Training Loss: 0.0147, Initial Validation Loss: 0.1342, Validation Loss: 0.0244,V Acc: 0.8929, Top 70th Acc: 0.9747, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 21  Rolling back to Epoch (base 0): 16  Top Validation Acc: 0.9746835443037974
Fold [2/5] Epoch [0/100] Initial Loss: 0.1425, Training Loss: 0.1425, Initial Validation Loss: 0.1368, Validation Loss: 0.1368,V Acc: 0.2703, Top 70th Acc: 0.3205, Bottom 30th Acc: 0.1515
Fold [2/5] Epoch [10/100] Initial Loss: 0.1425, Training Loss: 0.0351, Initial Validation Loss: 0.1368, Validation Loss: 0.0336,V Acc: 0.8559, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.6364
Fold [2/5] Epoch [20/100] Initial Loss: 0.1425, Training Loss: 0.0159, Initial Validation Loss: 0.1368, Validation Loss: 0.0252,V Acc: 0.8468, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.6061
Fold [2/5] Epoch [30/100] Initial Loss: 0.1425, Training Loss: 0.0129, Initial Validation Loss: 0.1368, Validation Loss: 0.0250,V Acc: 0.8649, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 36  Rolling back to Epoch (base 0): 31  Top Validation Acc: 0.9487179487179487
Fold [3/5] Epoch [0/100] Initial Loss: 0.1382, Training Loss: 0.1382, Initial Validation Loss: 0.1301, Validation Loss: 0.1301,V Acc: 0.3545, Top 70th Acc: 0.3636, Bottom 30th Acc: 0.3333
Fold [3/5] Epoch [10/100] Initial Loss: 0.1382, Training Loss: 0.0282, Initial Validation Loss: 0.1301, Validation Loss: 0.0494,V Acc: 0.7455, Top 70th Acc: 0.8961, Bottom 30th Acc: 0.3939
Fold [3/5] Epoch [20/100] Initial Loss: 0.1382, Training Loss: 0.0125, Initial Validation Loss: 0.1301, Validation Loss: 0.0439,V Acc: 0.7364, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.2727
Stopping early at Epoch (base 0): 22  Rolling back to Epoch (base 0): 17  Top Validation Acc: 0.935064935064935
Fold [4/5] Epoch [0/100] Initial Loss: 0.1415, Training Loss: 0.1415, Initial Validation Loss: 0.1327, Validation Loss: 0.1327,V Acc: 0.2385, Top 70th Acc: 0.2468, Bottom 30th Acc: 0.2188
Fold [4/5] Epoch [10/100] Initial Loss: 0.1415, Training Loss: 0.0258, Initial Validation Loss: 0.1327, Validation Loss: 0.0407,V Acc: 0.8257, Top 70th Acc: 0.8961, Bottom 30th Acc: 0.6562
Fold [4/5] Epoch [20/100] Initial Loss: 0.1415, Training Loss: 0.0142, Initial Validation Loss: 0.1327, Validation Loss: 0.0375,V Acc: 0.7982, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.4688
Stopping early at Epoch (base 0): 29  Rolling back to Epoch (base 0): 24  Top Validation Acc: 0.935064935064935
83 3 [array([0.68429846, 0.02958719, 0.05086693, 0.07660679, 0.15864068],
      dtype=float32)]
Fold [5/5] Epoch [0/100] Initial Loss: 0.1397, Training Loss: 0.1397, Initial Validation Loss: 0.1319, Validation Loss: 0.1319,V Acc: 0.3241, Top 70th Acc: 0.3816, Bottom 30th Acc: 0.1875
Fold [5/5] Epoch [10/100] Initial Loss: 0.1397, Training Loss: 0.0272, Initial Validation Loss: 0.1319, Validation Loss: 0.0323,V Acc: 0.8426, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.6250
Fold [5/5] Epoch [20/100] Initial Loss: 0.1397, Training Loss: 0.0140, Initial Validation Loss: 0.1319, Validation Loss: 0.0253,V Acc: 0.8704, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.6562
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.9605263157894737
Running train_nn.py with seed 84
CUDA:False
Training samples count: 
Fold [5/5] Epoch [20/100] Initial Loss: 0.1373, Training Loss: 0.0786, Initial Validation Loss: 0.1271, Validation Loss: 0.0781,V Acc: 0.6204, Top 70th Acc: 0.7368, Bottom 30th Acc: 0.3438
Fold [5/5] Epoch [30/100] Initial Loss: 0.1373, Training Loss: 0.0780, Initial Validation Loss: 0.1271, Validation Loss: 0.0776,V Acc: 0.6111, Top 70th Acc: 0.7500, Bottom 30th Acc: 0.2812
Stopping early at Epoch (base 0): 35  Rolling back to Epoch (base 0): 30  Top Validation Acc: 0.75
Running train_nn.py with seed 80
CUDA:False
Training samples count:  550
Training on 2 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1330, Training Loss: 0.1330, Initial Validation Loss: 0.1277, Validation Loss: 0.1277,V Acc: 0.4464, Top 70th Acc: 0.5316, Bottom 30th Acc: 0.2424
Fold [1/5] Epoch [10/100] Initial Loss: 0.1330, Training Loss: 0.0802, Initial Validation Loss: 0.1277, Validation Loss: 0.0801,V Acc: 0.6339, Top 70th Acc: 0.7342, Bottom 30th Acc: 0.3939
Fold [1/5] Epoch [20/100] Initial Loss: 0.1330, Training Loss: 0.0784, Initial Validation Loss: 0.1277, Validation Loss: 0.0786,V Acc: 0.6250, Top 70th Acc: 0.7342, Bottom 30th Acc: 0.3636
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.7215189873417721
Fold [2/5] Epoch [0/100] Initial Loss: 0.1353, Training Loss: 0.1353, Initial Validation Loss: 0.1286, Validation Loss: 0.1286,V Acc: 0.3874, Top 70th Acc: 0.4103, Bottom 30th Acc: 0.3333
Fold [2/5] Epoch [10/100] Initial Loss: 0.1353, Training Loss: 0.0803, Initial Validation Loss: 0.1286, Validation Loss: 0.0810,V Acc: 0.6306, Top 70th Acc: 0.7436, Bottom 30th Acc: 0.3636
Stopping early at Epoch (base 0): 18  Rolling back to Epoch (base 0): 13  Top Validation Acc: 0.7435897435897436
80 1 [array([0.12990148, 0.39398503, 0.13224931, 0.17880674, 0.1650574 ],
      dtype=float32)]
Fold [3/5] Epoch [0/100] Initial Loss: 0.1332, Training Loss: 0.1332, Initial Validation Loss: 0.1233, Validation Loss: 0.1233,V Acc: 0.4182, Top 70th Acc: 0.5325, Bottom 30th Acc: 0.1515
Fold [3/5] Epoch [10/100] Initial Loss: 0.1332, Training Loss: 0.0779, Initial Validation Loss: 0.1233, Validation Loss: 0.0863,V Acc: 0.6273, Top 70th Acc: 0.7273, Bottom 30th Acc: 0.3939
Stopping early at Epoch (base 0): 14  Rolling back to Epoch (base 0): 9  Top Validation Acc: 0.7532467532467533
Fold [4/5] Epoch [0/100] Initial Loss: 0.1442, Training Loss: 0.1442, Initial Validation Loss: 0.1276, Validation Loss: 0.1276,V Acc: 0.3303, Top 70th Acc: 0.3506, Bottom 30th Acc: 0.2812
Fold [4/5] Epoch [10/100] Initial Loss: 0.1442, Training Loss: 0.0839, Initial Validation Loss: 0.1276, Validation Loss: 0.0718,V Acc: 0.6330, Top 70th Acc: 0.7403, Bottom 30th Acc: 0.3750
Fold [4/5] Epoch [20/100] Initial Loss: 0.1442, Training Loss: 0.0814, Initial Validation Loss: 0.1276, Validation Loss: 0.0694,V Acc: 0.6422, Top 70th Acc: 0.7403, Bottom 30th Acc: 0.4062
Fold [4/5] Epoch [30/100] Initial Loss: 0.1442, Training Loss: 0.0808, Initial Validation Loss: 0.1276, Validation Loss: 0.0687,V Acc: 0.6330, Top 70th Acc: 0.7273, Bottom 30th Acc: 0.4062
Stopping early at Epoch (base 0): 32  Rolling back to Epoch (base 0): 27  Top Validation Acc: 0.7272727272727273
Fold [5/5] Epoch [0/100] Initial Loss: 0.1403, Training Loss: 0.1403, Initial Validation Loss: 0.1330, Validation Loss: 0.1330,V Acc: 0.2407, Top 70th Acc: 0.3421, Bottom 30th Acc: 0.0000
Fold [5/5] Epoch [10/100] Initial Loss: 0.1403, Training Loss: 0.0817, Initial Validation Loss: 0.1330, Validation Loss: 0.0789,V Acc: 0.6296, Top 70th Acc: 0.7368, Bottom 30th Acc: 0.3750
Fold [5/5] Epoch [20/100] Initial Loss: 0.1403, Training Loss: 0.0797, Initial Validation Loss: 0.1330, Validation Loss: 0.0767,V Acc: 0.6389, Top 70th Acc: 0.7500, Bottom 30th Acc: 0.3750
Fold [5/5] Epoch [30/100] Initial Loss: 0.1403, Training Loss: 0.0793, Initial Validation Loss: 0.1330, Validation Loss: 0.0761,V Acc: 0.6481, Top 70th Acc: 0.7500, Bottom 30th Acc: 0.4062
Stopping early at Epoch (base 0): 36  Rolling back to Epoch (base 0): 31  Top Validation Acc: 0.7631578947368421
Running train_nn.py with seed 81
CUDA:False
Training samples count:  550
Training on 2 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1400, Training Loss: 0.1400, Initial Validation Loss: 0.1308, Validation Loss: 0.1308,V Acc: 0.3929, Top 70th Acc: 0.4937, Bottom 30th Acc: 0.1515
Fold [1/5] Epoch [10/100] Initial Loss: 0.1400, Training Loss: 0.0792, Initial Validation Loss: 0.1308, Validation Loss: 0.0849,V Acc: 0.5982, Top 70th Acc: 0.7342, Bottom 30th Acc: 0.2727
Fold [1/5] Epoch [20/100] Initial Loss: 0.1400, Training Loss: 0.0774, Initial Validation Loss: 0.1308, Validation Loss: 0.0844,V Acc: 0.5893, Top 70th Acc: 0.7342, Bottom 30th Acc: 0.2424
Fold [1/5] Epoch [30/100] Initial Loss: 0.1400, Training Loss: 0.0772, Initial Validation Loss: 0.1308, Validation Loss: 0.0836,V Acc: 0.6071, Top 70th Acc: 0.7342, Bottom 30th Acc: 0.3030
Stopping early at Epoch (base 0): 32  Rolling back to Epoch (base 0): 27  Top Validation Acc: 0.7215189873417721
Fold [2/5] Epoch [0/100] Initial Loss: 0.1328, Training Loss: 0.1328, Initial Validation Loss: 0.1207, Validation Loss: 0.1207,V Acc: 0.4595, Top 70th Acc: 0.5769, Bottom 30th Acc: 0.1818
Fold [2/5] Epoch [10/100] Initial Loss: 0.1328, Training Loss: 0.0793, Initial Validation Loss: 0.1207, Validation Loss: 0.0883,V Acc: 0.5676, Top 70th Acc: 0.6282, Bottom 30th Acc: 0.4242
Stopping early at Epoch (base 0): 16  Rolling back to Epoch (base 0): 11  Top Validation Acc: 0.6282051282051282
Fold [3/5] Epoch [0/100] Initial Loss: 0.1365, Training Loss: 0.1365, Initial Validation Loss: 0.1262, Validation Loss: 0.1262,V Acc: 0.3727, Top 70th Acc: 0.3636, Bottom 30th Acc: 0.3939
Fold [3/5] Epoch [10/100] Initial Loss: 0.1365, Training Loss: 0.0820, Initial Validation Loss: 0.1262, Validation Loss: 0.0760,V Acc: 0.6727, Top 70th Acc: 0.7792, Bottom 30th Acc: 0.4242
Fold [3/5] Epoch [20/100] Initial Loss: 0.1365, Training Loss: 0.0803, Initial Validation Loss: 0.1262, Validation Loss: 0.0738,V Acc: 0.6727, Top 70th Acc: 0.7922, Bottom 30th Acc: 0.3939
Stopping early at Epoch (base 0): 21  Rolling back to Epoch (base 0): 16  Top Validation Acc: 0.7792207792207793
Fold [4/5] Epoch [0/100] Initial Loss: 0.1397, Training Loss: 0.1397, Initial Validation Loss: 0.1348, Validation Loss: 0.1348,V Acc: 0.2385, Top 70th Acc: 0.3247, Bottom 30th Acc: 0.0312
Fold [4/5] Epoch [10/100] Initial Loss: 0.1397, Training Loss: 0.0803, Initial Validation Loss: 0.1348, Validation Loss: 0.0818,V Acc: 0.6239, Top 70th Acc: 0.7013, Bottom 30th Acc: 0.4375
Stopping early at Epoch (base 0): 17  Rolling back to Epoch (base 0): 12  Top Validation Acc: 0.7142857142857143
Fold [5/5] Epoch [0/100] Initial Loss: 0.1388, Training Loss: 0.1388, Initial Validation Loss: 0.1261, Validation Loss: 0.1261,V Acc: 0.3889, Top 70th Acc: 0.4737, Bottom 30th Acc: 0.1875
Fold [5/5] Epoch [10/100] Initial Loss: 0.1388, Training Loss: 0.0832, Initial Validation Loss: 0.1261, Validation Loss: 0.0712,V Acc: 0.6944, Top 70th Acc: 0.8026, Bottom 30th Acc: 0.4375
Fold [5/5] Epoch [20/100] Initial Loss: 0.1388, Training Loss: 0.0808, Initial Validation Loss: 0.1261, Validation Loss: 0.0692,V Acc: 0.6574, Top 70th Acc: 0.7895, Bottom 30th Acc: 0.3438
Fold [5/5] Epoch [30/100] Initial Loss: 0.1388, Training Loss: 0.0801, Initial Validation Loss: 0.1261, Validation Loss: 0.0685,V Acc: 0.6667, Top 70th Acc: 0.8026, Bottom 30th Acc: 0.3438
Fold [5/5] Epoch [40/100] Initial Loss: 0.1388, Training Loss: 0.0797, Initial Validation Loss: 0.1261, Validation Loss: 0.0674,V Acc: 0.6759, Top 70th Acc: 0.8158, Bottom 30th Acc: 0.3438
Stopping early at Epoch (base 0): 46  Rolling back to Epoch (base 0): 41  Top Validation Acc: 0.8026315789473685
81 4 [array([0.11344829, 0.36621657, 0.1326755 , 0.21973665, 0.16792299],
      dtype=float32)]
Running train_nn.py with seed 82
CUDA:False
Training samples count:  550
Training on 2 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1377, Training Loss: 0.1377, Initial Validation Loss: 0.1260, Validation Loss: 0.1260,V Acc: 0.3214, Top 70th Acc: 0.3671, Bottom 30th Acc: 0.2121
Fold [1/5] Epoch [10/100] Initial Loss: 0.1377, Training Loss: 0.0807, Initial Validation Loss: 0.1260, Validation Loss: 0.0810,V Acc: 0.5982, Top 70th Acc: 0.7342, Bottom 30th Acc: 0.2727
Stopping early at Epoch (base 0): 21  Rolling back to Epoch (base 0): 16  Top Validation Acc: 0.8961038961038961
Fold [5/5] Epoch [0/100] Initial Loss: 0.1382, Training Loss: 0.1382, Initial Validation Loss: 0.1284, Validation Loss: 0.1284,V Acc: 0.4167, Top 70th Acc: 0.5000, Bottom 30th Acc: 0.2188
Fold [5/5] Epoch [10/100] Initial Loss: 0.1382, Training Loss: 0.0437, Initial Validation Loss: 0.1284, Validation Loss: 0.0459,V Acc: 0.7870, Top 70th Acc: 0.8684, Bottom 30th Acc: 0.5938
Fold [5/5] Epoch [20/100] Initial Loss: 0.1382, Training Loss: 0.0250, Initial Validation Loss: 0.1284, Validation Loss: 0.0328,V Acc: 0.8241, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.5625
Stopping early at Epoch (base 0): 22  Rolling back to Epoch (base 0): 17  Top Validation Acc: 0.9473684210526315
Running train_nn.py with seed 81
CUDA:False
Training samples count:  550
Training on 20 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1385, Training Loss: 0.1385, Initial Validation Loss: 0.1326, Validation Loss: 0.1326,V Acc: 0.3839, Top 70th Acc: 0.4304, Bottom 30th Acc: 0.2727
Fold [1/5] Epoch [10/100] Initial Loss: 0.1385, Training Loss: 0.0344, Initial Validation Loss: 0.1326, Validation Loss: 0.0376,V Acc: 0.8125, Top 70th Acc: 0.9114, Bottom 30th Acc: 0.5758
Fold [1/5] Epoch [20/100] Initial Loss: 0.1385, Training Loss: 0.0242, Initial Validation Loss: 0.1326, Validation Loss: 0.0279,V Acc: 0.8750, Top 70th Acc: 0.9747, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.9367088607594937
Fold [2/5] Epoch [0/100] Initial Loss: 0.1402, Training Loss: 0.1402, Initial Validation Loss: 0.1342, Validation Loss: 0.1342,V Acc: 0.3063, Top 70th Acc: 0.3590, Bottom 30th Acc: 0.1818
Fold [2/5] Epoch [10/100] Initial Loss: 0.1402, Training Loss: 0.0366, Initial Validation Loss: 0.1342, Validation Loss: 0.0418,V Acc: 0.8288, Top 70th Acc: 0.8974, Bottom 30th Acc: 0.6667
Fold [2/5] Epoch [20/100] Initial Loss: 0.1402, Training Loss: 0.0215, Initial Validation Loss: 0.1342, Validation Loss: 0.0382,V Acc: 0.8198, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.8974358974358975
Fold [3/5] Epoch [0/100] Initial Loss: 0.1419, Training Loss: 0.1419, Initial Validation Loss: 0.1324, Validation Loss: 0.1324,V Acc: 0.3727, Top 70th Acc: 0.4675, Bottom 30th Acc: 0.1515
Fold [3/5] Epoch [10/100] Initial Loss: 0.1419, Training Loss: 0.0325, Initial Validation Loss: 0.1324, Validation Loss: 0.0366,V Acc: 0.8545, Top 70th Acc: 0.8961, Bottom 30th Acc: 0.7576
Fold [3/5] Epoch [20/100] Initial Loss: 0.1419, Training Loss: 0.0240, Initial Validation Loss: 0.1324, Validation Loss: 0.0350,V Acc: 0.8273, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 29  Rolling back to Epoch (base 0): 24  Top Validation Acc: 0.922077922077922
Fold [4/5] Epoch [0/100] Initial Loss: 0.1424, Training Loss: 0.1424, Initial Validation Loss: 0.1337, Validation Loss: 0.1337,V Acc: 0.3853, Top 70th Acc: 0.5195, Bottom 30th Acc: 0.0625
Fold [4/5] Epoch [10/100] Initial Loss: 0.1424, Training Loss: 0.0401, Initial Validation Loss: 0.1337, Validation Loss: 0.0491,V Acc: 0.7890, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.5000
Fold [4/5] Epoch [20/100] Initial Loss: 0.1424, Training Loss: 0.0251, Initial Validation Loss: 0.1337, Validation Loss: 0.0363,V Acc: 0.8073, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.4375
Stopping early at Epoch (base 0): 29  Rolling back to Epoch (base 0): 24  Top Validation Acc: 0.948051948051948
Fold [5/5] Epoch [0/100] Initial Loss: 0.1396, Training Loss: 0.1396, Initial Validation Loss: 0.1275, Validation Loss: 0.1275,V Acc: 0.3426, Top 70th Acc: 0.4342, Bottom 30th Acc: 0.1250
Fold [5/5] Epoch [10/100] Initial Loss: 0.1396, Training Loss: 0.0316, Initial Validation Loss: 0.1275, Validation Loss: 0.0335,V Acc: 0.8148, Top 70th Acc: 0.9079, Bottom 30th Acc: 0.5938
Fold [5/5] Epoch [20/100] Initial Loss: 0.1396, Training Loss: 0.0233, Initial Validation Loss: 0.1275, Validation Loss: 0.0302,V Acc: 0.8333, Top 70th Acc: 0.9211, Bottom 30th Acc: 0.6250
Stopping early at Epoch (base 0): 27  Rolling back to Epoch (base 0): 22  Top Validation Acc: 0.9078947368421053
81 4 [array([0.32861006, 0.1079074 , 0.19477394, 0.23839046, 0.13031803],
      dtype=float32)]
Running train_nn.py with seed 82
CUDA:False
Training samples count:  550
Training on 20 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1431, Training Loss: 0.1431, Initial Validation Loss: 0.1338, Validation Loss: 0.1338,V Acc: 0.2500, Top 70th Acc: 0.3291, Bottom 30th Acc: 0.0606
Fold [1/5] Epoch [10/100] Initial Loss: 0.1431, Training Loss: 0.0358, Initial Validation Loss: 0.1338, Validation Loss: 0.0468,V Acc: 0.7946, Top 70th Acc: 0.8608, Bottom 30th Acc: 0.6364
Fold [1/5] Epoch [20/100] Initial Loss: 0.1431, Training Loss: 0.0228, Initial Validation Loss: 0.1338, Validation Loss: 0.0423,V Acc: 0.7857, Top 70th Acc: 0.8481, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 20  Rolling back to Epoch (base 0): 15  Top Validation Acc: 0.8481012658227848
Fold [2/5] Epoch [0/100] Initial Loss: 0.1363, Training Loss: 0.1363, Initial Validation Loss: 0.1331, Validation Loss: 0.1331,V Acc: 0.3694, Top 70th Acc: 0.3846, Bottom 30th Acc: 0.3333
Fold [2/5] Epoch [10/100] Initial Loss: 0.1363, Training Loss: 0.0356, Initial Validation Loss: 0.1331, Validation Loss: 0.0380,V Acc: 0.8919, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.7273
Fold [2/5] Epoch [20/100] Initial Loss: 0.1363, Training Loss: 0.0264, Initial Validation Loss: 0.1331, Validation Loss: 0.0358,V Acc: 0.8468, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.9358974358974359
Fold [3/5] Epoch [0/100] Initial Loss: 0.1401, Training Loss: 0.1401, Initial Validation Loss: 0.1368, Validation Loss: 0.1368,V Acc: 0.2909, Top 70th Acc: 0.3247, Bottom 30th Acc: 0.2121
Fold [3/5] Epoch [10/100] Initial Loss: 0.1401, Training Loss: 0.0372, Initial Validation Loss: 0.1368, Validation Loss: 0.0366,V Acc: 0.8545, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.5758
Fold [3/5] Epoch [20/100] Initial Loss: 0.1401, Training Loss: 0.0251, Initial Validation Loss: 0.1368, Validation Loss: 0.0293,V Acc: 0.8909, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.974025974025974
Fold [4/5] Epoch [0/100] Initial Loss: 0.1387, Training Loss: 0.1387, Initial Validation Loss: 0.1333, Validation Loss: 0.1333,V Acc: 0.3578, Top 70th Acc: 0.3766, Bottom 30th Acc: 0.3125
Fold [4/5] Epoch [10/100] Initial Loss: 0.1387, Training Loss: 0.0432, Initial Validation Loss: 0.1333, Validation Loss: 0.0426,V Acc: 0.7890, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.4688
Fold [4/5] Epoch [20/100] Initial Loss: 0.1387, Training Loss: 0.0296, Initial Validation Loss: 0.1333, Validation Loss: 0.0346,V Acc: 0.8349, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.5625
Fold [4/5] Epoch [30/100] Initial Loss: 0.1387, Training Loss: 0.0242, Initial Validation Loss: 0.1333, Validation Loss: 0.0313,V Acc: 0.8532, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6250
Stopping early at Epoch (base 0): 33  Rolling back to Epoch (base 0): 28  Top Validation Acc: 0.935064935064935
Fold [5/5] Epoch [0/100] Initial Loss: 0.1387, Training Loss: 0.1387, Initial Validation Loss: 0.1274, Validation Loss: 0.1274,V Acc: 0.3796, Top 70th Acc: 0.3947, Bottom 30th Acc: 0.3438
Fold [5/5] Epoch [10/100] Initial Loss: 0.1387, Training Loss: 0.0396, Initial Validation Loss: 0.1274, Validation Loss: 0.0468,V Acc: 0.7407, Top 70th Acc: 0.8816, Bottom 30th Acc: 0.4062
Fold [5/5] Epoch [20/100] Initial Loss: 0.1387, Training Loss: 0.0241, Initial Validation Loss: 0.1274, Validation Loss: 0.0380,V Acc: 0.7593, Top 70th Acc: 0.8816, Bottom 30th Acc: 0.4688
Stopping early at Epoch (base 0): 22  Rolling back to Epoch (base 0): 17  Top Validation Acc: 0.8947368421052632
82 4 [array([0.39204684, 0.07663108, 0.09101311, 0.1880499 , 0.2522591 ],
      dtype=float32)]
Running train_nn.py with seed 83
CUDA:False
Stopping early at Epoch (base 0): 45  Rolling back to Epoch (base 0): 40  Top Validation Acc: 0.974025974025974
Fold [4/5] Epoch [0/100] Initial Loss: 0.1423, Training Loss: 0.1423, Initial Validation Loss: 0.1290, Validation Loss: 0.1290,V Acc: 0.2385, Top 70th Acc: 0.2468, Bottom 30th Acc: 0.2188
Fold [4/5] Epoch [10/100] Initial Loss: 0.1423, Training Loss: 0.0349, Initial Validation Loss: 0.1290, Validation Loss: 0.0377,V Acc: 0.7982, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.5312
Fold [4/5] Epoch [20/100] Initial Loss: 0.1423, Training Loss: 0.0172, Initial Validation Loss: 0.1290, Validation Loss: 0.0323,V Acc: 0.7798, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.4062
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.948051948051948
Fold [5/5] Epoch [0/100] Initial Loss: 0.1367, Training Loss: 0.1367, Initial Validation Loss: 0.1283, Validation Loss: 0.1283,V Acc: 0.4907, Top 70th Acc: 0.5395, Bottom 30th Acc: 0.3750
Fold [5/5] Epoch [10/100] Initial Loss: 0.1367, Training Loss: 0.0369, Initial Validation Loss: 0.1283, Validation Loss: 0.0381,V Acc: 0.8241, Top 70th Acc: 0.9211, Bottom 30th Acc: 0.5938
Fold [5/5] Epoch [20/100] Initial Loss: 0.1367, Training Loss: 0.0190, Initial Validation Loss: 0.1283, Validation Loss: 0.0270,V Acc: 0.8611, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.6875
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.9342105263157895
Running train_nn.py with seed 81
CUDA:False
Training samples count:  550
Training on 30 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1392, Training Loss: 0.1392, Initial Validation Loss: 0.1331, Validation Loss: 0.1331,V Acc: 0.2768, Top 70th Acc: 0.3418, Bottom 30th Acc: 0.1212
Fold [1/5] Epoch [10/100] Initial Loss: 0.1392, Training Loss: 0.0347, Initial Validation Loss: 0.1331, Validation Loss: 0.0369,V Acc: 0.8571, Top 70th Acc: 0.9241, Bottom 30th Acc: 0.6970
Fold [1/5] Epoch [20/100] Initial Loss: 0.1392, Training Loss: 0.0209, Initial Validation Loss: 0.1331, Validation Loss: 0.0295,V Acc: 0.8482, Top 70th Acc: 0.9620, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.9493670886075949
Fold [2/5] Epoch [0/100] Initial Loss: 0.1395, Training Loss: 0.1395, Initial Validation Loss: 0.1327, Validation Loss: 0.1327,V Acc: 0.2793, Top 70th Acc: 0.3462, Bottom 30th Acc: 0.1212
Fold [2/5] Epoch [10/100] Initial Loss: 0.1395, Training Loss: 0.0321, Initial Validation Loss: 0.1327, Validation Loss: 0.0384,V Acc: 0.8559, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.6667
Fold [2/5] Epoch [20/100] Initial Loss: 0.1395, Training Loss: 0.0180, Initial Validation Loss: 0.1327, Validation Loss: 0.0331,V Acc: 0.8468, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 28  Rolling back to Epoch (base 0): 23  Top Validation Acc: 0.9358974358974359
Fold [3/5] Epoch [0/100] Initial Loss: 0.1409, Training Loss: 0.1409, Initial Validation Loss: 0.1366, Validation Loss: 0.1366,V Acc: 0.2455, Top 70th Acc: 0.1948, Bottom 30th Acc: 0.3636
Fold [3/5] Epoch [10/100] Initial Loss: 0.1409, Training Loss: 0.0387, Initial Validation Loss: 0.1366, Validation Loss: 0.0398,V Acc: 0.8364, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.6364
Fold [3/5] Epoch [20/100] Initial Loss: 0.1409, Training Loss: 0.0201, Initial Validation Loss: 0.1366, Validation Loss: 0.0271,V Acc: 0.8818, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.6667
Fold [3/5] Epoch [30/100] Initial Loss: 0.1409, Training Loss: 0.0177, Initial Validation Loss: 0.1366, Validation Loss: 0.0269,V Acc: 0.8636, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 30  Rolling back to Epoch (base 0): 25  Top Validation Acc: 0.948051948051948
Fold [4/5] Epoch [0/100] Initial Loss: 0.1398, Training Loss: 0.1398, Initial Validation Loss: 0.1361, Validation Loss: 0.1361,V Acc: 0.2661, Top 70th Acc: 0.3247, Bottom 30th Acc: 0.1250
Fold [4/5] Epoch [10/100] Initial Loss: 0.1398, Training Loss: 0.0344, Initial Validation Loss: 0.1361, Validation Loss: 0.0438,V Acc: 0.8349, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.5938
Fold [4/5] Epoch [20/100] Initial Loss: 0.1398, Training Loss: 0.0178, Initial Validation Loss: 0.1361, Validation Loss: 0.0381,V Acc: 0.8257, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.5938
Stopping early at Epoch (base 0): 20  Rolling back to Epoch (base 0): 15  Top Validation Acc: 0.922077922077922
Fold [5/5] Epoch [0/100] Initial Loss: 0.1399, Training Loss: 0.1399, Initial Validation Loss: 0.1272, Validation Loss: 0.1272,V Acc: 0.4444, Top 70th Acc: 0.5000, Bottom 30th Acc: 0.3125
Fold [5/5] Epoch [10/100] Initial Loss: 0.1399, Training Loss: 0.0309, Initial Validation Loss: 0.1272, Validation Loss: 0.0319,V Acc: 0.8333, Top 70th Acc: 0.9211, Bottom 30th Acc: 0.6250
Fold [5/5] Epoch [20/100] Initial Loss: 0.1399, Training Loss: 0.0189, Initial Validation Loss: 0.1272, Validation Loss: 0.0266,V Acc: 0.8333, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.5625
Fold [5/5] Epoch [30/100] Initial Loss: 0.1399, Training Loss: 0.0161, Initial Validation Loss: 0.1272, Validation Loss: 0.0253,V Acc: 0.8426, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.5625
Stopping early at Epoch (base 0): 30  Rolling back to Epoch (base 0): 25  Top Validation Acc: 0.9605263157894737
81 4 [array([0.69125986, 0.09416141, 0.06738671, 0.0738822 , 0.07330978],
      dtype=float32)]
Running train_nn.py with seed 82
CUDA:False
Training samples count:  550
Training on 30 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1420, Training Loss: 0.1420, Initial Validation Loss: 0.1338, Validation Loss: 0.1338,V Acc: 0.2500, Top 70th Acc: 0.3038, Bottom 30th Acc: 0.1212
Fold [1/5] Epoch [10/100] Initial Loss: 0.1420, Training Loss: 0.0377, Initial Validation Loss: 0.1338, Validation Loss: 0.0434,V Acc: 0.7768, Top 70th Acc: 0.9114, Bottom 30th Acc: 0.4545
Fold [1/5] Epoch [20/100] Initial Loss: 0.1420, Training Loss: 0.0179, Initial Validation Loss: 0.1338, Validation Loss: 0.0349,V Acc: 0.8125, Top 70th Acc: 0.9241, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 22  Rolling back to Epoch (base 0): 17  Top Validation Acc: 0.9113924050632911
Fold [2/5] Epoch [0/100] Initial Loss: 0.1412, Training Loss: 0.1412, Initial Validation Loss: 0.1375, Validation Loss: 0.1375,V Acc: 0.3333, Top 70th Acc: 0.4103, Bottom 30th Acc: 0.1515
Fold [2/5] Epoch [10/100] Initial Loss: 0.1412, Training Loss: 0.0422, Initial Validation Loss: 0.1375, Validation Loss: 0.0516,V Acc: 0.7748, Top 70th Acc: 0.8590, Bottom 30th Acc: 0.5758
Fold [2/5] Epoch [20/100] Initial Loss: 0.1412, Training Loss: 0.0198, Initial Validation Loss: 0.1375, Validation Loss: 0.0393,V Acc: 0.8288, Top 70th Acc: 0.8974, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 22  Rolling back to Epoch (base 0): 17  Top Validation Acc: 0.9230769230769231
Fold [3/5] Epoch [0/100] Initial Loss: 0.1376, Training Loss: 0.1376, Initial Validation Loss: 0.1366, Validation Loss: 0.1366,V Acc: 0.2727, Top 70th Acc: 0.3636, Bottom 30th Acc: 0.0606
Fold [3/5] Epoch [10/100] Initial Loss: 0.1376, Training Loss: 0.0448, Initial Validation Loss: 0.1366, Validation Loss: 0.0467,V Acc: 0.8000, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.4848
Fold [3/5] Epoch [20/100] Initial Loss: 0.1376, Training Loss: 0.0208, Initial Validation Loss: 0.1366, Validation Loss: 0.0286,V Acc: 0.8727, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.974025974025974
Fold [4/5] Epoch [0/100] Initial Loss: 0.1390, Training Loss: 0.1390, Initial Validation Loss: 0.1348, Validation Loss: 0.1348,V Acc: 0.2844, Top 70th Acc: 0.3636, Bottom 30th Acc: 0.0938
Fold [4/5] Epoch [10/100] Initial Loss: 0.1390, Training Loss: 0.0374, Initial Validation Loss: 0.1348, Validation Loss: 0.0362,V Acc: 0.8440, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.5938
Fold [4/5] Epoch [20/100] Initial Loss: 0.1390, Training Loss: 0.0190, Initial Validation Loss: 0.1348, Validation Loss: 0.0274,V Acc: 0.8440, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.5625
Stopping early at Epoch (base 0): 22  Rolling back to Epoch (base 0): 550
Training on 40 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1388, Training Loss: 0.1388, Initial Validation Loss: 0.1339, Validation Loss: 0.1339,V Acc: 0.3304, Top 70th Acc: 0.3924, Bottom 30th Acc: 0.1818
Fold [1/5] Epoch [10/100] Initial Loss: 0.1388, Training Loss: 0.0205, Initial Validation Loss: 0.1339, Validation Loss: 0.0338,V Acc: 0.8482, Top 70th Acc: 0.9367, Bottom 30th Acc: 0.6364
Fold [1/5] Epoch [20/100] Initial Loss: 0.1388, Training Loss: 0.0124, Initial Validation Loss: 0.1339, Validation Loss: 0.0321,V Acc: 0.8304, Top 70th Acc: 0.9241, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 21  Rolling back to Epoch (base 0): 16  Top Validation Acc: 0.9367088607594937
Fold [2/5] Epoch [0/100] Initial Loss: 0.1397, Training Loss: 0.1397, Initial Validation Loss: 0.1363, Validation Loss: 0.1363,V Acc: 0.3153, Top 70th Acc: 0.3333, Bottom 30th Acc: 0.2727
Fold [2/5] Epoch [10/100] Initial Loss: 0.1397, Training Loss: 0.0417, Initial Validation Loss: 0.1363, Validation Loss: 0.0474,V Acc: 0.7838, Top 70th Acc: 0.8974, Bottom 30th Acc: 0.5152
Fold [2/5] Epoch [20/100] Initial Loss: 0.1397, Training Loss: 0.0158, Initial Validation Loss: 0.1363, Validation Loss: 0.0314,V Acc: 0.8288, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.4848
Stopping early at Epoch (base 0): 27  Rolling back to Epoch (base 0): 22  Top Validation Acc: 0.9743589743589743
84 1 [array([0.41347194, 0.04844471, 0.1970728 , 0.2053674 , 0.13564306],
      dtype=float32)]
Fold [3/5] Epoch [0/100] Initial Loss: 0.1411, Training Loss: 0.1411, Initial Validation Loss: 0.1337, Validation Loss: 0.1337,V Acc: 0.2727, Top 70th Acc: 0.2987, Bottom 30th Acc: 0.2121
Fold [3/5] Epoch [10/100] Initial Loss: 0.1411, Training Loss: 0.0338, Initial Validation Loss: 0.1337, Validation Loss: 0.0401,V Acc: 0.7636, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.3939
Fold [3/5] Epoch [20/100] Initial Loss: 0.1411, Training Loss: 0.0141, Initial Validation Loss: 0.1337, Validation Loss: 0.0314,V Acc: 0.8000, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.4848
Stopping early at Epoch (base 0): 27  Rolling back to Epoch (base 0): 22  Top Validation Acc: 0.935064935064935
Fold [4/5] Epoch [0/100] Initial Loss: 0.1398, Training Loss: 0.1398, Initial Validation Loss: 0.1346, Validation Loss: 0.1346,V Acc: 0.3394, Top 70th Acc: 0.4026, Bottom 30th Acc: 0.1875
Fold [4/5] Epoch [10/100] Initial Loss: 0.1398, Training Loss: 0.0254, Initial Validation Loss: 0.1346, Validation Loss: 0.0325,V Acc: 0.8899, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.7500
Fold [4/5] Epoch [20/100] Initial Loss: 0.1398, Training Loss: 0.0141, Initial Validation Loss: 0.1346, Validation Loss: 0.0227,V Acc: 0.9174, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.7812
Fold [4/5] Epoch [30/100] Initial Loss: 0.1398, Training Loss: 0.0116, Initial Validation Loss: 0.1346, Validation Loss: 0.0235,V Acc: 0.8899, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.6875
Stopping early at Epoch (base 0): 33  Rolling back to Epoch (base 0): 28  Top Validation Acc: 0.974025974025974
Fold [5/5] Epoch [0/100] Initial Loss: 0.1396, Training Loss: 0.1396, Initial Validation Loss: 0.1332, Validation Loss: 0.1332,V Acc: 0.2778, Top 70th Acc: 0.2763, Bottom 30th Acc: 0.2812
Fold [5/5] Epoch [10/100] Initial Loss: 0.1396, Training Loss: 0.0270, Initial Validation Loss: 0.1332, Validation Loss: 0.0292,V Acc: 0.8796, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.6875
Fold [5/5] Epoch [20/100] Initial Loss: 0.1396, Training Loss: 0.0144, Initial Validation Loss: 0.1332, Validation Loss: 0.0259,V Acc: 0.8889, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.7500
Stopping early at Epoch (base 0): 28  Rolling back to Epoch (base 0): 23  Top Validation Acc: 0.9605263157894737
Running train_nn.py with seed 85
CUDA:False
Training samples count:  550
Training on 40 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1389, Training Loss: 0.1389, Initial Validation Loss: 0.1346, Validation Loss: 0.1346,V Acc: 0.3036, Top 70th Acc: 0.3544, Bottom 30th Acc: 0.1818
Fold [1/5] Epoch [10/100] Initial Loss: 0.1389, Training Loss: 0.0388, Initial Validation Loss: 0.1346, Validation Loss: 0.0482,V Acc: 0.7589, Top 70th Acc: 0.9114, Bottom 30th Acc: 0.3939
Fold [1/5] Epoch [20/100] Initial Loss: 0.1389, Training Loss: 0.0195, Initial Validation Loss: 0.1346, Validation Loss: 0.0378,V Acc: 0.8036, Top 70th Acc: 0.9494, Bottom 30th Acc: 0.4545
Fold [1/5] Epoch [30/100] Initial Loss: 0.1389, Training Loss: 0.0124, Initial Validation Loss: 0.1346, Validation Loss: 0.0319,V Acc: 0.8036, Top 70th Acc: 0.9620, Bottom 30th Acc: 0.4242
Stopping early at Epoch (base 0): 36  Rolling back to Epoch (base 0): 31  Top Validation Acc: 0.9746835443037974
Fold [2/5] Epoch [0/100] Initial Loss: 0.1377, Training Loss: 0.1377, Initial Validation Loss: 0.1361, Validation Loss: 0.1361,V Acc: 0.3153, Top 70th Acc: 0.3205, Bottom 30th Acc: 0.3030
Fold [2/5] Epoch [10/100] Initial Loss: 0.1377, Training Loss: 0.0349, Initial Validation Loss: 0.1361, Validation Loss: 0.0425,V Acc: 0.8559, Top 70th Acc: 0.8974, Bottom 30th Acc: 0.7576
Fold [2/5] Epoch [20/100] Initial Loss: 0.1377, Training Loss: 0.0158, Initial Validation Loss: 0.1361, Validation Loss: 0.0310,V Acc: 0.8739, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.6970
Fold [2/5] Epoch [30/100] Initial Loss: 0.1377, Training Loss: 0.0128, Initial Validation Loss: 0.1361, Validation Loss: 0.0298,V Acc: 0.8739, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 34  Rolling back to Epoch (base 0): 29  Top Validation Acc: 0.9487179487179487
Fold [3/5] Epoch [0/100] Initial Loss: 0.1382, Training Loss: 0.1382, Initial Validation Loss: 0.1306, Validation Loss: 0.1306,V Acc: 0.3727, Top 70th Acc: 0.4805, Bottom 30th Acc: 0.1212
Fold [3/5] Epoch [10/100] Initial Loss: 0.1382, Training Loss: 0.0390, Initial Validation Loss: 0.1306, Validation Loss: 0.0396,V Acc: 0.8000, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.4848
Fold [3/5] Epoch [20/100] Initial Loss: 0.1382, Training Loss: 0.0153, Initial Validation Loss: 0.1306, Validation Loss: 0.0283,V Acc: 0.8727, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.7273
Stopping early at Epoch (base 0): 27  Rolling back to Epoch (base 0): 22  Top Validation Acc: 0.935064935064935
85 2 [array([0.41740593, 0.02625453, 0.04616251, 0.09197789, 0.41819915],
      dtype=float32)]
Fold [4/5] Epoch [0/100] Initial Loss: 0.1398, Training Loss: 0.1398, Initial Validation Loss: 0.1367, Validation Loss: 0.1367,V Acc: 0.2477, Top 70th Acc: 0.2987, Bottom 30th Acc: 0.1250
Fold [4/5] Epoch [10/100] Initial Loss: 0.1398, Training Loss: 0.0294, Initial Validation Loss: 0.1367, Validation Loss: 0.0317,V Acc: 0.8991, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.7188
Fold [4/5] Epoch [20/100] Initial Loss: 0.1398, Training Loss: 0.0151, Initial Validation Loss: 0.1367, Validation Loss: 0.0248,V Acc: 0.8807, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.6875
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.974025974025974
Fold [5/5] Epoch [0/100] Initial Loss: 0.1394, Training Loss: 0.1394, Initial Validation Loss: 0.1240, Validation Loss: 0.1240,V Acc: 0.3148, Top 70th Acc: 0.4079, Bottom 30th Acc: 0.0938
Fold [5/5] Epoch [10/100] Initial Loss: 0.1394, Training Loss: 0.0248, Initial Validation Loss: 0.1240, Validation Loss: 0.0388,V Acc: 0.7963, Top 70th Acc: 0.8947, Bottom 30th Acc: 0.5625
Fold [5/5] Epoch [20/100] Initial Loss: 0.1394, Training Loss: 0.0138, Initial Validation Loss: 0.1240, Validation Loss: 0.0321,V Acc: 0.8333, Top 70th Acc: 0.9079, Bottom 30th Acc: 0.6562
Fold [5/5] Epoch [30/100] Initial Loss: 0.1394, Training Loss: 0.0115, Initial Validation Loss: 0.1240, Validation Loss: 0.0319,V Acc: 0.8333, Top 70th Acc: 0.9211, Bottom 30th Acc: 0.6250
Stopping early at Epoch (base 0): 33  Rolling back to Epoch (base 0): 28  Top Validation Acc: 0.9210526315789473
Running train_nn.py with seed 86
CUDA:False
Training samples count:  550
Training on 40 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1358, Training Loss: 0.1358, Initial Validation Loss: 0.1271, Validation Loss: 0.1271,V Acc: 0.4196, Top 70th Acc: 0.4937, Bottom 30th Acc: 0.2424
Fold [1/5] Epoch [10/100] Initial Loss: 0.1358, Training Loss: 0.0368, Initial Validation Loss: 0.1271, Validation Loss: 0.0499,V Acc: 0.7768, Top 70th Acc: 0.8608, Bottom 30th Acc: 0.5758
Fold [1/5] Epoch [20/100] Initial Loss: 0.1377, Training Loss: 0.0785, Initial Validation Loss: 0.1260, Validation Loss: 0.0796,V Acc: 0.6250, Top 70th Acc: 0.7215, Bottom 30th Acc: 0.3939
Fold [1/5] Epoch [30/100] Initial Loss: 0.1377, Training Loss: 0.0777, Initial Validation Loss: 0.1260, Validation Loss: 0.0792,V Acc: 0.6161, Top 70th Acc: 0.7342, Bottom 30th Acc: 0.3333
Stopping early at Epoch (base 0): 35  Rolling back to Epoch (base 0): 30  Top Validation Acc: 0.7215189873417721
Fold [2/5] Epoch [0/100] Initial Loss: 0.1367, Training Loss: 0.1367, Initial Validation Loss: 0.1250, Validation Loss: 0.1250,V Acc: 0.4324, Top 70th Acc: 0.6026, Bottom 30th Acc: 0.0303
Fold [2/5] Epoch [10/100] Initial Loss: 0.1367, Training Loss: 0.0808, Initial Validation Loss: 0.1250, Validation Loss: 0.0786,V Acc: 0.6306, Top 70th Acc: 0.7564, Bottom 30th Acc: 0.3333
Fold [2/5] Epoch [20/100] Initial Loss: 0.1367, Training Loss: 0.0792, Initial Validation Loss: 0.1250, Validation Loss: 0.0772,V Acc: 0.6306, Top 70th Acc: 0.7821, Bottom 30th Acc: 0.2727
Fold [2/5] Epoch [30/100] Initial Loss: 0.1367, Training Loss: 0.0788, Initial Validation Loss: 0.1250, Validation Loss: 0.0777,V Acc: 0.6306, Top 70th Acc: 0.7436, Bottom 30th Acc: 0.3636
Fold [2/5] Epoch [40/100] Initial Loss: 0.1367, Training Loss: 0.0785, Initial Validation Loss: 0.1250, Validation Loss: 0.0768,V Acc: 0.6216, Top 70th Acc: 0.7564, Bottom 30th Acc: 0.3030
Stopping early at Epoch (base 0): 40  Rolling back to Epoch (base 0): 35  Top Validation Acc: 0.7564102564102564
Fold [3/5] Epoch [0/100] Initial Loss: 0.1324, Training Loss: 0.1324, Initial Validation Loss: 0.1276, Validation Loss: 0.1276,V Acc: 0.6000, Top 70th Acc: 0.7013, Bottom 30th Acc: 0.3636
Fold [3/5] Epoch [10/100] Initial Loss: 0.1324, Training Loss: 0.0810, Initial Validation Loss: 0.1276, Validation Loss: 0.0794,V Acc: 0.6455, Top 70th Acc: 0.7662, Bottom 30th Acc: 0.3636
Fold [3/5] Epoch [20/100] Initial Loss: 0.1324, Training Loss: 0.0794, Initial Validation Loss: 0.1276, Validation Loss: 0.0767,V Acc: 0.6636, Top 70th Acc: 0.8052, Bottom 30th Acc: 0.3333
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.7922077922077922
Fold [4/5] Epoch [0/100] Initial Loss: 0.1360, Training Loss: 0.1360, Initial Validation Loss: 0.1274, Validation Loss: 0.1274,V Acc: 0.3394, Top 70th Acc: 0.4675, Bottom 30th Acc: 0.0312
Fold [4/5] Epoch [10/100] Initial Loss: 0.1360, Training Loss: 0.0813, Initial Validation Loss: 0.1274, Validation Loss: 0.0787,V Acc: 0.6606, Top 70th Acc: 0.7273, Bottom 30th Acc: 0.5000
Fold [4/5] Epoch [20/100] Initial Loss: 0.1360, Training Loss: 0.0794, Initial Validation Loss: 0.1274, Validation Loss: 0.0766,V Acc: 0.6881, Top 70th Acc: 0.7403, Bottom 30th Acc: 0.5625
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.7402597402597403
Fold [5/5] Epoch [0/100] Initial Loss: 0.1402, Training Loss: 0.1402, Initial Validation Loss: 0.1283, Validation Loss: 0.1283,V Acc: 0.3241, Top 70th Acc: 0.2500, Bottom 30th Acc: 0.5000
Fold [5/5] Epoch [10/100] Initial Loss: 0.1402, Training Loss: 0.0802, Initial Validation Loss: 0.1283, Validation Loss: 0.0792,V Acc: 0.5648, Top 70th Acc: 0.7105, Bottom 30th Acc: 0.2188
Fold [5/5] Epoch [20/100] Initial Loss: 0.1402, Training Loss: 0.0779, Initial Validation Loss: 0.1283, Validation Loss: 0.0783,V Acc: 0.5556, Top 70th Acc: 0.6974, Bottom 30th Acc: 0.2188
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.6842105263157895
82 4 [array([0.12130689, 0.36755648, 0.14862838, 0.22725853, 0.13524973],
      dtype=float32)]
Running train_nn.py with seed 83
CUDA:False
Training samples count:  550
Training on 2 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1358, Training Loss: 0.1358, Initial Validation Loss: 0.1317, Validation Loss: 0.1317,V Acc: 0.5089, Top 70th Acc: 0.6203, Bottom 30th Acc: 0.2424
Fold [1/5] Epoch [10/100] Initial Loss: 0.1358, Training Loss: 0.0833, Initial Validation Loss: 0.1317, Validation Loss: 0.0720,V Acc: 0.6696, Top 70th Acc: 0.7848, Bottom 30th Acc: 0.3939
Fold [1/5] Epoch [20/100] Initial Loss: 0.1358, Training Loss: 0.0809, Initial Validation Loss: 0.1317, Validation Loss: 0.0706,V Acc: 0.6786, Top 70th Acc: 0.7722, Bottom 30th Acc: 0.4545
Fold [1/5] Epoch [30/100] Initial Loss: 0.1358, Training Loss: 0.0795, Initial Validation Loss: 0.1317, Validation Loss: 0.0697,V Acc: 0.6786, Top 70th Acc: 0.7848, Bottom 30th Acc: 0.4242
Stopping early at Epoch (base 0): 32  Rolling back to Epoch (base 0): 27  Top Validation Acc: 0.7848101265822784
Fold [2/5] Epoch [0/100] Initial Loss: 0.1400, Training Loss: 0.1400, Initial Validation Loss: 0.1332, Validation Loss: 0.1332,V Acc: 0.2523, Top 70th Acc: 0.3590, Bottom 30th Acc: 0.0000
Fold [2/5] Epoch [10/100] Initial Loss: 0.1400, Training Loss: 0.0840, Initial Validation Loss: 0.1332, Validation Loss: 0.0687,V Acc: 0.7117, Top 70th Acc: 0.8333, Bottom 30th Acc: 0.4242
Stopping early at Epoch (base 0): 19  Rolling back to Epoch (base 0): 14  Top Validation Acc: 0.8461538461538461
Fold [3/5] Epoch [0/100] Initial Loss: 0.1342, Training Loss: 0.1342, Initial Validation Loss: 0.1244, Validation Loss: 0.1244,V Acc: 0.4273, Top 70th Acc: 0.5455, Bottom 30th Acc: 0.1515
Fold [3/5] Epoch [10/100] Initial Loss: 0.1342, Training Loss: 0.0785, Initial Validation Loss: 0.1244, Validation Loss: 0.0862,V Acc: 0.5727, Top 70th Acc: 0.6494, Bottom 30th Acc: 0.3939
Fold [3/5] Epoch [20/100] Initial Loss: 0.1342, Training Loss: 0.0755, Initial Validation Loss: 0.1244, Validation Loss: 0.0858,V Acc: 0.5636, Top 70th Acc: 0.6883, Bottom 30th Acc: 0.2727
Stopping early at Epoch (base 0): 21  Rolling back to Epoch (base 0): 16  Top Validation Acc: 0.6753246753246753
Fold [4/5] Epoch [0/100] Initial Loss: 0.1412, Training Loss: 0.1412, Initial Validation Loss: 0.1312, Validation Loss: 0.1312,V Acc: 0.3853, Top 70th Acc: 0.4286, Bottom 30th Acc: 0.2812
Fold [4/5] Epoch [10/100] Initial Loss: 0.1412, Training Loss: 0.0790, Initial Validation Loss: 0.1312, Validation Loss: 0.0857,V Acc: 0.5872, Top 70th Acc: 0.6883, Bottom 30th Acc: 0.3438
Fold [4/5] Epoch [20/100] Initial Loss: 0.1412, Training Loss: 0.0773, Initial Validation Loss: 0.1312, Validation Loss: 0.0840,V Acc: 0.6055, Top 70th Acc: 0.7013, Bottom 30th Acc: 0.3750
Stopping early at Epoch (base 0): 22  Rolling back to Epoch (base 0): 17  Top Validation Acc: 0.6883116883116883
83 3 [array([0.10080384, 0.40001068, 0.17511337, 0.18490365, 0.13916847],
      dtype=float32)]
Fold [5/5] Epoch [0/100] Initial Loss: 0.1394, Training Loss: 0.1394, Initial Validation Loss: 0.1307, Validation Loss: 0.1307,V Acc: 0.3148, Top 70th Acc: 0.3947, Bottom 30th Acc: 0.1250
Fold [5/5] Epoch [10/100] Initial Loss: 0.1394, Training Loss: 0.0785, Initial Validation Loss: 0.1307, Validation Loss: 0.0843,V Acc: 0.5926, Top 70th Acc: 0.6974, Bottom 30th Acc: 0.3438
Fold [5/5] Epoch [20/100] Initial Loss: 0.1394, Training Loss: 0.0761, Initial Validation Loss: 0.1307, Validation Loss: 0.0829,V Acc: 0.6019, Top 70th Acc: 0.6842, Bottom 30th Acc: 0.4062
Stopping early at Epoch (base 0): 27  Rolling back to Epoch (base 0): 22  Top Validation Acc: 0.6973684210526315
Running train_nn.py with seed 84
CUDA:False
Training samples count:  550
Training on 2 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1308, Training Loss: 0.1308, Initial Validation Loss: 0.1187, Validation Loss: 0.1187,V Acc: 0.5089, Top 70th Acc: 0.5443, Bottom 30th Acc: 0.4242
Fold [1/5] Epoch [10/100] Initial Loss: 0.1308, Training Loss: 0.0806, Initial Validation Loss: 0.1187, Validation Loss: 0.0826,V Acc: 0.6071, Top 70th Acc: 0.7089, Bottom 30th Acc: 0.3636
Fold [1/5] Epoch [20/100] Initial Loss: 0.1308, Training Loss: 0.0785, Initial Validation Loss: 0.1187, Validation Loss: 0.0818,V Acc: 0.6161, Top 70th Acc: 0.6962, Bottom 30th Acc: 0.4242
Stopping early at Epoch (base 0): 27  Rolling back to Epoch (base 0): 22  Top Validation Acc: 0.6962025316455697
Fold [2/5] Epoch [0/100] Initial Loss: 0.1337, Training Loss: 0.1337, Initial Validation Loss: 0.1259, Validation Loss: 0.1259,V Acc: 0.4685, Top 70th Acc: 0.5641, Bottom 30th Acc: 0.2424
Fold [4/5] Epoch [40/100] Initial Loss: 0.1388, Training Loss: 0.0036, Initial Validation Loss: 0.1323, Validation Loss: 0.0388,V Acc: 0.8073, Top 70th Acc: 0.8961, Bottom 30th Acc: 0.5938
Fold [4/5] Epoch [50/100] Initial Loss: 0.1388, Training Loss: 0.0035, Initial Validation Loss: 0.1323, Validation Loss: 0.0377,V Acc: 0.8165, Top 70th Acc: 0.8961, Bottom 30th Acc: 0.6250
Fold [4/5] Epoch [60/100] Initial Loss: 0.1388, Training Loss: 0.0034, Initial Validation Loss: 0.1323, Validation Loss: 0.0369,V Acc: 0.8257, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.6250
Stopping early at Epoch (base 0): 69  Rolling back to Epoch (base 0): 64  Top Validation Acc: 0.9090909090909091
62 3 [array([0.21094717, 0.02966046, 0.05949146, 0.39837232, 0.3015286 ],
      dtype=float32)]
Fold [5/5] Epoch [0/100] Initial Loss: 0.1407, Training Loss: 0.1407, Initial Validation Loss: 0.1302, Validation Loss: 0.1302,V Acc: 0.3519, Top 70th Acc: 0.3684, Bottom 30th Acc: 0.3125
Fold [5/5] Epoch [10/100] Initial Loss: 0.1407, Training Loss: 0.0301, Initial Validation Loss: 0.1302, Validation Loss: 0.0390,V Acc: 0.8056, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.4688
Fold [5/5] Epoch [20/100] Initial Loss: 0.1407, Training Loss: 0.0079, Initial Validation Loss: 0.1302, Validation Loss: 0.0301,V Acc: 0.8333, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.5938
Fold [5/5] Epoch [30/100] Initial Loss: 0.1407, Training Loss: 0.0047, Initial Validation Loss: 0.1302, Validation Loss: 0.0272,V Acc: 0.8333, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.5938
Fold [5/5] Epoch [40/100] Initial Loss: 0.1407, Training Loss: 0.0041, Initial Validation Loss: 0.1302, Validation Loss: 0.0268,V Acc: 0.8333, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.5938
Stopping early at Epoch (base 0): 41  Rolling back to Epoch (base 0): 36  Top Validation Acc: 0.9342105263157895
Running train_nn.py with seed 63
CUDA:False
Training samples count:  550
Training on 162 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1385, Training Loss: 0.1385, Initial Validation Loss: 0.1332, Validation Loss: 0.1332,V Acc: 0.3482, Top 70th Acc: 0.3544, Bottom 30th Acc: 0.3333
Fold [1/5] Epoch [10/100] Initial Loss: 0.1385, Training Loss: 0.0213, Initial Validation Loss: 0.1332, Validation Loss: 0.0376,V Acc: 0.8036, Top 70th Acc: 0.9494, Bottom 30th Acc: 0.4545
Fold [1/5] Epoch [20/100] Initial Loss: 0.1385, Training Loss: 0.0050, Initial Validation Loss: 0.1332, Validation Loss: 0.0310,V Acc: 0.8571, Top 70th Acc: 0.9367, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 27  Rolling back to Epoch (base 0): 22  Top Validation Acc: 0.9367088607594937
Fold [2/5] Epoch [0/100] Initial Loss: 0.1383, Training Loss: 0.1383, Initial Validation Loss: 0.1347, Validation Loss: 0.1347,V Acc: 0.2523, Top 70th Acc: 0.3205, Bottom 30th Acc: 0.0909
Fold [2/5] Epoch [10/100] Initial Loss: 0.1383, Training Loss: 0.0176, Initial Validation Loss: 0.1347, Validation Loss: 0.0349,V Acc: 0.8468, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.5758
Fold [2/5] Epoch [20/100] Initial Loss: 0.1383, Training Loss: 0.0050, Initial Validation Loss: 0.1347, Validation Loss: 0.0287,V Acc: 0.8739, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.6364
Fold [2/5] Epoch [30/100] Initial Loss: 0.1383, Training Loss: 0.0038, Initial Validation Loss: 0.1347, Validation Loss: 0.0273,V Acc: 0.8649, Top 70th Acc: 0.9872, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 37  Rolling back to Epoch (base 0): 32  Top Validation Acc: 1.0
Fold [3/5] Epoch [0/100] Initial Loss: 0.1408, Training Loss: 0.1408, Initial Validation Loss: 0.1313, Validation Loss: 0.1313,V Acc: 0.3091, Top 70th Acc: 0.3506, Bottom 30th Acc: 0.2121
Fold [3/5] Epoch [10/100] Initial Loss: 0.1408, Training Loss: 0.0121, Initial Validation Loss: 0.1313, Validation Loss: 0.0301,V Acc: 0.8636, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.6970
Fold [3/5] Epoch [20/100] Initial Loss: 0.1408, Training Loss: 0.0046, Initial Validation Loss: 0.1313, Validation Loss: 0.0265,V Acc: 0.8545, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6364
Fold [3/5] Epoch [30/100] Initial Loss: 0.1408, Training Loss: 0.0036, Initial Validation Loss: 0.1313, Validation Loss: 0.0263,V Acc: 0.8636, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6667
Fold [3/5] Epoch [40/100] Initial Loss: 0.1408, Training Loss: 0.0034, Initial Validation Loss: 0.1313, Validation Loss: 0.0270,V Acc: 0.8545, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 42  Rolling back to Epoch (base 0): 37  Top Validation Acc: 0.948051948051948
Fold [4/5] Epoch [0/100] Initial Loss: 0.1376, Training Loss: 0.1376, Initial Validation Loss: 0.1234, Validation Loss: 0.1234,V Acc: 0.4404, Top 70th Acc: 0.5325, Bottom 30th Acc: 0.2188
Fold [4/5] Epoch [10/100] Initial Loss: 0.1376, Training Loss: 0.0181, Initial Validation Loss: 0.1234, Validation Loss: 0.0453,V Acc: 0.7798, Top 70th Acc: 0.8571, Bottom 30th Acc: 0.5938
Fold [4/5] Epoch [20/100] Initial Loss: 0.1376, Training Loss: 0.0055, Initial Validation Loss: 0.1234, Validation Loss: 0.0404,V Acc: 0.8165, Top 70th Acc: 0.8961, Bottom 30th Acc: 0.6250
Fold [4/5] Epoch [30/100] Initial Loss: 0.1376, Training Loss: 0.0043, Initial Validation Loss: 0.1234, Validation Loss: 0.0403,V Acc: 0.8440, Top 70th Acc: 0.8961, Bottom 30th Acc: 0.7188
Fold [4/5] Epoch [40/100] Initial Loss: 0.1376, Training Loss: 0.0039, Initial Validation Loss: 0.1234, Validation Loss: 0.0392,V Acc: 0.8165, Top 70th Acc: 0.8961, Bottom 30th Acc: 0.6250
Fold [4/5] Epoch [50/100] Initial Loss: 0.1376, Training Loss: 0.0037, Initial Validation Loss: 0.1234, Validation Loss: 0.0386,V Acc: 0.8073, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.5625
Fold [4/5] Epoch [60/100] Initial Loss: 0.1376, Training Loss: 0.0036, Initial Validation Loss: 0.1234, Validation Loss: 0.0376,V Acc: 0.8073, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.5312
Fold [4/5] Epoch [70/100] Initial Loss: 0.1376, Training Loss: 0.0034, Initial Validation Loss: 0.1234, Validation Loss: 0.0371,V Acc: 0.8073, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.5312
Fold [4/5] Epoch [80/100] Initial Loss: 0.1376, Training Loss: 0.0034, Initial Validation Loss: 0.1234, Validation Loss: 0.0361,V Acc: 0.8073, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.5000
Stopping early at Epoch (base 0): 80  Rolling back to Epoch (base 0): 75  Top Validation Acc: 0.935064935064935
Fold [5/5] Epoch [0/100] Initial Loss: 0.1389, Training Loss: 0.1389, Initial Validation Loss: 0.1369, Validation Loss: 0.1369,V Acc: 0.2778, Top 70th Acc: 0.3289, Bottom 30th Acc: 0.1562
Fold [5/5] Epoch [10/100] Initial Loss: 0.1389, Training Loss: 0.0197, Initial Validation Loss: 0.1369, Validation Loss: 0.0330,V Acc: 0.9074, Top 70th Acc: 0.9737, Bottom 30th Acc: 0.7500
Fold [5/5] Epoch [20/100] Initial Loss: 0.1389, Training Loss: 0.0055, Initial Validation Loss: 0.1369, Validation Loss: 0.0280,V Acc: 0.8611, Top 70th Acc: 0.9737, Bottom 30th Acc: 0.5938
Stopping early at Epoch (base 0): 29  Rolling back to Epoch (base 0): 24  Top Validation Acc: 0.9736842105263158
63 4 [array([0.3346451 , 0.03060182, 0.07066752, 0.32156953, 0.2425161 ],
      dtype=float32)]
Running train_nn.py with seed 64
CUDA:False
Training samples count:  550
Training on 162 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1387, Training Loss: 0.1387, Initial Validation Loss: 0.1306, Validation Loss: 0.1306,V Acc: 0.3661, Top 70th Acc: 0.4051, Bottom 30th Acc: 0.2727
Fold [1/5] Epoch [10/100] Initial Loss: 0.1387, Training Loss: 0.0139, Initial Validation Loss: 0.1306, Validation Loss: 0.0354,V Acc: 0.8482, Top 70th Acc: 0.9114, Bottom 30th Acc: 0.6970
Fold [1/5] Epoch [20/100] Initial Loss: 0.1387, Training Loss: 0.0049, Initial Validation Loss: 0.1306, Validation Loss: 0.0315,V Acc: 0.8482, Top 70th Acc: 0.9367, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 21  Rolling back to Epoch (base 0): 16  Top Validation Acc: 0.9367088607594937
64 0 [array([0.2785883 , 0.06922217, 0.09263652, 0.20656765, 0.35298535],
      dtype=float32)]
Fold [2/5] Epoch [0/100] Initial Loss: 0.1383, Training Loss: 0.1383, Initial Validation Loss: 0.1348, Validation Loss: 0.1348,V Acc: 0.3423, Top 70th Acc: 0.4359, Bottom 30th Acc: 0.1212
Fold [2/5] Epoch [10/100] Initial Loss: 0.1383, Training Loss: 0.0131, Initial Validation Loss: 0.1348, Validation Loss: 0.0288,V Acc: 0.8739, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.6667
Training samples count:  550
Training on 20 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1367, Training Loss: 0.1367, Initial Validation Loss: 0.1304, Validation Loss: 0.1304,V Acc: 0.4018, Top 70th Acc: 0.4937, Bottom 30th Acc: 0.1818
Fold [1/5] Epoch [10/100] Initial Loss: 0.1367, Training Loss: 0.0327, Initial Validation Loss: 0.1304, Validation Loss: 0.0296,V Acc: 0.8929, Top 70th Acc: 0.9747, Bottom 30th Acc: 0.6970
Fold [1/5] Epoch [20/100] Initial Loss: 0.1367, Training Loss: 0.0240, Initial Validation Loss: 0.1304, Validation Loss: 0.0261,V Acc: 0.8929, Top 70th Acc: 0.9747, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.9746835443037974
Fold [2/5] Epoch [0/100] Initial Loss: 0.1375, Training Loss: 0.1375, Initial Validation Loss: 0.1321, Validation Loss: 0.1321,V Acc: 0.4234, Top 70th Acc: 0.4744, Bottom 30th Acc: 0.3030
Fold [2/5] Epoch [10/100] Initial Loss: 0.1375, Training Loss: 0.0333, Initial Validation Loss: 0.1321, Validation Loss: 0.0329,V Acc: 0.8468, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.6970
Fold [2/5] Epoch [20/100] Initial Loss: 0.1375, Training Loss: 0.0246, Initial Validation Loss: 0.1321, Validation Loss: 0.0301,V Acc: 0.8018, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.4545
Stopping early at Epoch (base 0): 29  Rolling back to Epoch (base 0): 24  Top Validation Acc: 0.9487179487179487
Fold [3/5] Epoch [0/100] Initial Loss: 0.1407, Training Loss: 0.1407, Initial Validation Loss: 0.1332, Validation Loss: 0.1332,V Acc: 0.2727, Top 70th Acc: 0.2727, Bottom 30th Acc: 0.2727
Fold [3/5] Epoch [10/100] Initial Loss: 0.1407, Training Loss: 0.0346, Initial Validation Loss: 0.1332, Validation Loss: 0.0597,V Acc: 0.7182, Top 70th Acc: 0.7922, Bottom 30th Acc: 0.5455
Fold [3/5] Epoch [20/100] Initial Loss: 0.1407, Training Loss: 0.0216, Initial Validation Loss: 0.1332, Validation Loss: 0.0531,V Acc: 0.7455, Top 70th Acc: 0.8442, Bottom 30th Acc: 0.5152
Fold [3/5] Epoch [30/100] Initial Loss: 0.1407, Training Loss: 0.0190, Initial Validation Loss: 0.1332, Validation Loss: 0.0494,V Acc: 0.7455, Top 70th Acc: 0.8442, Bottom 30th Acc: 0.5152
Stopping early at Epoch (base 0): 37  Rolling back to Epoch (base 0): 32  Top Validation Acc: 0.8441558441558441
Fold [4/5] Epoch [0/100] Initial Loss: 0.1419, Training Loss: 0.1419, Initial Validation Loss: 0.1300, Validation Loss: 0.1300,V Acc: 0.3670, Top 70th Acc: 0.4416, Bottom 30th Acc: 0.1875
Fold [4/5] Epoch [10/100] Initial Loss: 0.1419, Training Loss: 0.0379, Initial Validation Loss: 0.1300, Validation Loss: 0.0461,V Acc: 0.7706, Top 70th Acc: 0.8571, Bottom 30th Acc: 0.5625
Fold [4/5] Epoch [20/100] Initial Loss: 0.1419, Training Loss: 0.0257, Initial Validation Loss: 0.1300, Validation Loss: 0.0376,V Acc: 0.8257, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.6250
Fold [4/5] Epoch [30/100] Initial Loss: 0.1419, Training Loss: 0.0216, Initial Validation Loss: 0.1300, Validation Loss: 0.0356,V Acc: 0.8165, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.5938
Stopping early at Epoch (base 0): 34  Rolling back to Epoch (base 0): 29  Top Validation Acc: 0.922077922077922
83 3 [array([0.35766166, 0.03051638, 0.13820797, 0.28937012, 0.18424392],
      dtype=float32)]
Fold [5/5] Epoch [0/100] Initial Loss: 0.1422, Training Loss: 0.1422, Initial Validation Loss: 0.1330, Validation Loss: 0.1330,V Acc: 0.3333, Top 70th Acc: 0.3816, Bottom 30th Acc: 0.2188
Fold [5/5] Epoch [10/100] Initial Loss: 0.1422, Training Loss: 0.0391, Initial Validation Loss: 0.1330, Validation Loss: 0.0424,V Acc: 0.8056, Top 70th Acc: 0.8816, Bottom 30th Acc: 0.6250
Fold [5/5] Epoch [20/100] Initial Loss: 0.1422, Training Loss: 0.0262, Initial Validation Loss: 0.1330, Validation Loss: 0.0312,V Acc: 0.8704, Top 70th Acc: 0.9079, Bottom 30th Acc: 0.7812
Fold [5/5] Epoch [30/100] Initial Loss: 0.1422, Training Loss: 0.0232, Initial Validation Loss: 0.1330, Validation Loss: 0.0303,V Acc: 0.8519, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.6562
Stopping early at Epoch (base 0): 34  Rolling back to Epoch (base 0): 29  Top Validation Acc: 0.9342105263157895
Running train_nn.py with seed 84
CUDA:False
Training samples count:  550
Training on 20 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1394, Training Loss: 0.1394, Initial Validation Loss: 0.1361, Validation Loss: 0.1361,V Acc: 0.2500, Top 70th Acc: 0.2532, Bottom 30th Acc: 0.2424
Fold [1/5] Epoch [10/100] Initial Loss: 0.1394, Training Loss: 0.0290, Initial Validation Loss: 0.1361, Validation Loss: 0.0376,V Acc: 0.8036, Top 70th Acc: 0.8987, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 18  Rolling back to Epoch (base 0): 13  Top Validation Acc: 0.9113924050632911
Fold [2/5] Epoch [0/100] Initial Loss: 0.1392, Training Loss: 0.1392, Initial Validation Loss: 0.1367, Validation Loss: 0.1367,V Acc: 0.2613, Top 70th Acc: 0.3333, Bottom 30th Acc: 0.0909
Fold [2/5] Epoch [10/100] Initial Loss: 0.1392, Training Loss: 0.0435, Initial Validation Loss: 0.1367, Validation Loss: 0.0427,V Acc: 0.8108, Top 70th Acc: 0.8718, Bottom 30th Acc: 0.6667
Fold [2/5] Epoch [20/100] Initial Loss: 0.1392, Training Loss: 0.0234, Initial Validation Loss: 0.1367, Validation Loss: 0.0294,V Acc: 0.8468, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.9358974358974359
84 1 [array([0.419086  , 0.0650136 , 0.13870017, 0.20483263, 0.17236757],
      dtype=float32)]
Fold [3/5] Epoch [0/100] Initial Loss: 0.1410, Training Loss: 0.1410, Initial Validation Loss: 0.1332, Validation Loss: 0.1332,V Acc: 0.2636, Top 70th Acc: 0.2987, Bottom 30th Acc: 0.1818
Fold [3/5] Epoch [10/100] Initial Loss: 0.1410, Training Loss: 0.0450, Initial Validation Loss: 0.1332, Validation Loss: 0.0455,V Acc: 0.7818, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.4242
Fold [3/5] Epoch [20/100] Initial Loss: 0.1410, Training Loss: 0.0247, Initial Validation Loss: 0.1332, Validation Loss: 0.0338,V Acc: 0.8364, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.935064935064935
Fold [4/5] Epoch [0/100] Initial Loss: 0.1400, Training Loss: 0.1400, Initial Validation Loss: 0.1351, Validation Loss: 0.1351,V Acc: 0.3394, Top 70th Acc: 0.3896, Bottom 30th Acc: 0.2188
Fold [4/5] Epoch [10/100] Initial Loss: 0.1400, Training Loss: 0.0345, Initial Validation Loss: 0.1351, Validation Loss: 0.0381,V Acc: 0.8807, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.7500
Fold [4/5] Epoch [20/100] Initial Loss: 0.1400, Training Loss: 0.0222, Initial Validation Loss: 0.1351, Validation Loss: 0.0305,V Acc: 0.8440, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.5938
Fold [4/5] Epoch [30/100] Initial Loss: 0.1400, Training Loss: 0.0208, Initial Validation Loss: 0.1351, Validation Loss: 0.0298,V Acc: 0.8716, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.7188
Stopping early at Epoch (base 0): 30  Rolling back to Epoch (base 0): 25  Top Validation Acc: 0.935064935064935
Fold [5/5] Epoch [0/100] Initial Loss: 0.1396, Training Loss: 0.1396, Initial Validation Loss: 0.1322, Validation Loss: 0.1322,V Acc: 0.2500, Top 70th Acc: 0.3158, Bottom 30th Acc: 0.0938
Fold [5/5] Epoch [10/100] Initial Loss: 0.1396, Training Loss: 0.0313, Initial Validation Loss: 0.1322, Validation Loss: 0.0303,V Acc: 0.8981, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.7812
Fold [5/5] Epoch [20/100] Initial Loss: 0.1396, Training Loss: 0.0235, Initial Validation Loss: 0.1322, Validation Loss: 0.0261,V Acc: 0.8889, Top 70th Acc: 0.9737, Bottom 30th Acc: 0.6875
Stopping early at Epoch (base 0): 21  Rolling back to Epoch (base 0): 16  Top Validation Acc: 0.9736842105263158
Running train_nn.py with seed 85
CUDA:False
Training samples count:  550
Training on 19 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1452, Training Loss: 0.1452, Initial Validation Loss: 0.1378, Validation Loss: 0.1378,V Acc: 0.2768, Top 70th Acc: 0.3291, Bottom 30th Acc: 0.1515
Fold [1/5] Epoch [10/100] Initial Loss: 0.1452, Training Loss: 0.0429, Initial Validation Loss: 0.1378, Validation Loss: 0.0468,V Acc: 0.8214, Top 70th Acc: 0.9114, Bottom 30th Acc: 0.6061
Fold [1/5] Epoch [20/100] Initial Loss: 0.1452, Training Loss: 0.0255, Initial Validation Loss: 0.1378, Validation Loss: 0.0368,V Acc: 0.8214, Top 70th Acc: 0.9367, Bottom 30th Acc: 0.5455 17  Top Validation Acc: 0.948051948051948
Fold [5/5] Epoch [0/100] Initial Loss: 0.1410, Training Loss: 0.1410, Initial Validation Loss: 0.1295, Validation Loss: 0.1295,V Acc: 0.2593, Top 70th Acc: 0.3421, Bottom 30th Acc: 0.0625
Fold [5/5] Epoch [10/100] Initial Loss: 0.1410, Training Loss: 0.0380, Initial Validation Loss: 0.1295, Validation Loss: 0.0454,V Acc: 0.7778, Top 70th Acc: 0.8947, Bottom 30th Acc: 0.5000
Fold [5/5] Epoch [20/100] Initial Loss: 0.1410, Training Loss: 0.0225, Initial Validation Loss: 0.1295, Validation Loss: 0.0373,V Acc: 0.8056, Top 70th Acc: 0.9079, Bottom 30th Acc: 0.5625
Fold [5/5] Epoch [30/100] Initial Loss: 0.1410, Training Loss: 0.0171, Initial Validation Loss: 0.1295, Validation Loss: 0.0347,V Acc: 0.8056, Top 70th Acc: 0.8947, Bottom 30th Acc: 0.5938
Stopping early at Epoch (base 0): 31  Rolling back to Epoch (base 0): 26  Top Validation Acc: 0.8947368421052632
82 4 [array([0.59848565, 0.06556328, 0.04916261, 0.14473428, 0.14205414],
      dtype=float32)]
Running train_nn.py with seed 83
CUDA:False
Training samples count:  550
Training on 30 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1398, Training Loss: 0.1398, Initial Validation Loss: 0.1371, Validation Loss: 0.1371,V Acc: 0.3214, Top 70th Acc: 0.3291, Bottom 30th Acc: 0.3030
Fold [1/5] Epoch [10/100] Initial Loss: 0.1398, Training Loss: 0.0361, Initial Validation Loss: 0.1371, Validation Loss: 0.0298,V Acc: 0.8839, Top 70th Acc: 0.9747, Bottom 30th Acc: 0.6667
Fold [1/5] Epoch [20/100] Initial Loss: 0.1398, Training Loss: 0.0200, Initial Validation Loss: 0.1371, Validation Loss: 0.0241,V Acc: 0.8839, Top 70th Acc: 0.9873, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 21  Rolling back to Epoch (base 0): 16  Top Validation Acc: 0.9873417721518988
Fold [2/5] Epoch [0/100] Initial Loss: 0.1386, Training Loss: 0.1386, Initial Validation Loss: 0.1341, Validation Loss: 0.1341,V Acc: 0.3694, Top 70th Acc: 0.4359, Bottom 30th Acc: 0.2121
Fold [2/5] Epoch [10/100] Initial Loss: 0.1386, Training Loss: 0.0320, Initial Validation Loss: 0.1341, Validation Loss: 0.0347,V Acc: 0.7928, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.3939
Fold [2/5] Epoch [20/100] Initial Loss: 0.1386, Training Loss: 0.0199, Initial Validation Loss: 0.1341, Validation Loss: 0.0280,V Acc: 0.8198, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.4545
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.9743589743589743
Fold [3/5] Epoch [0/100] Initial Loss: 0.1360, Training Loss: 0.1360, Initial Validation Loss: 0.1308, Validation Loss: 0.1308,V Acc: 0.3364, Top 70th Acc: 0.3896, Bottom 30th Acc: 0.2121
Fold [3/5] Epoch [10/100] Initial Loss: 0.1360, Training Loss: 0.0307, Initial Validation Loss: 0.1308, Validation Loss: 0.0504,V Acc: 0.7545, Top 70th Acc: 0.8701, Bottom 30th Acc: 0.4848
Stopping early at Epoch (base 0): 18  Rolling back to Epoch (base 0): 13  Top Validation Acc: 0.8961038961038961
Fold [4/5] Epoch [0/100] Initial Loss: 0.1407, Training Loss: 0.1407, Initial Validation Loss: 0.1296, Validation Loss: 0.1296,V Acc: 0.3028, Top 70th Acc: 0.3766, Bottom 30th Acc: 0.1250
Fold [4/5] Epoch [10/100] Initial Loss: 0.1407, Training Loss: 0.0250, Initial Validation Loss: 0.1296, Validation Loss: 0.0368,V Acc: 0.8440, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.6562
Fold [4/5] Epoch [20/100] Initial Loss: 0.1407, Training Loss: 0.0178, Initial Validation Loss: 0.1296, Validation Loss: 0.0353,V Acc: 0.8165, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.5312
Fold [4/5] Epoch [30/100] Initial Loss: 0.1407, Training Loss: 0.0160, Initial Validation Loss: 0.1296, Validation Loss: 0.0351,V Acc: 0.8349, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.5312
Stopping early at Epoch (base 0): 31  Rolling back to Epoch (base 0): 26  Top Validation Acc: 0.948051948051948
83 3 [array([0.5799467 , 0.07243774, 0.0619933 , 0.07424641, 0.2113758 ],
      dtype=float32)]
Fold [5/5] Epoch [0/100] Initial Loss: 0.1414, Training Loss: 0.1414, Initial Validation Loss: 0.1335, Validation Loss: 0.1335,V Acc: 0.2500, Top 70th Acc: 0.3158, Bottom 30th Acc: 0.0938
Fold [5/5] Epoch [10/100] Initial Loss: 0.1414, Training Loss: 0.0434, Initial Validation Loss: 0.1335, Validation Loss: 0.0482,V Acc: 0.7407, Top 70th Acc: 0.8816, Bottom 30th Acc: 0.4062
Fold [5/5] Epoch [20/100] Initial Loss: 0.1414, Training Loss: 0.0203, Initial Validation Loss: 0.1335, Validation Loss: 0.0302,V Acc: 0.8148, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.5312
Fold [5/5] Epoch [30/100] Initial Loss: 0.1414, Training Loss: 0.0170, Initial Validation Loss: 0.1335, Validation Loss: 0.0291,V Acc: 0.8519, Top 70th Acc: 0.9211, Bottom 30th Acc: 0.6875
Fold [5/5] Epoch [40/100] Initial Loss: 0.1414, Training Loss: 0.0153, Initial Validation Loss: 0.1335, Validation Loss: 0.0288,V Acc: 0.8333, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.5625
Stopping early at Epoch (base 0): 40  Rolling back to Epoch (base 0): 35  Top Validation Acc: 0.9473684210526315
Running train_nn.py with seed 84
CUDA:False
Training samples count:  550
Training on 30 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1412, Training Loss: 0.1412, Initial Validation Loss: 0.1381, Validation Loss: 0.1381,V Acc: 0.2500, Top 70th Acc: 0.3165, Bottom 30th Acc: 0.0909
Fold [1/5] Epoch [10/100] Initial Loss: 0.1412, Training Loss: 0.0438, Initial Validation Loss: 0.1381, Validation Loss: 0.0548,V Acc: 0.7500, Top 70th Acc: 0.8481, Bottom 30th Acc: 0.5152
Fold [1/5] Epoch [20/100] Initial Loss: 0.1412, Training Loss: 0.0188, Initial Validation Loss: 0.1381, Validation Loss: 0.0417,V Acc: 0.7679, Top 70th Acc: 0.8861, Bottom 30th Acc: 0.4848
Fold [1/5] Epoch [30/100] Initial Loss: 0.1412, Training Loss: 0.0153, Initial Validation Loss: 0.1381, Validation Loss: 0.0397,V Acc: 0.7857, Top 70th Acc: 0.9241, Bottom 30th Acc: 0.4545
Fold [1/5] Epoch [40/100] Initial Loss: 0.1412, Training Loss: 0.0139, Initial Validation Loss: 0.1381, Validation Loss: 0.0385,V Acc: 0.7857, Top 70th Acc: 0.8987, Bottom 30th Acc: 0.5152
Fold [1/5] Epoch [50/100] Initial Loss: 0.1412, Training Loss: 0.0132, Initial Validation Loss: 0.1381, Validation Loss: 0.0391,V Acc: 0.7946, Top 70th Acc: 0.8987, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 50  Rolling back to Epoch (base 0): 45  Top Validation Acc: 0.8987341772151899
Fold [2/5] Epoch [0/100] Initial Loss: 0.1390, Training Loss: 0.1390, Initial Validation Loss: 0.1356, Validation Loss: 0.1356,V Acc: 0.2613, Top 70th Acc: 0.3333, Bottom 30th Acc: 0.0909
Fold [2/5] Epoch [10/100] Initial Loss: 0.1390, Training Loss: 0.0315, Initial Validation Loss: 0.1356, Validation Loss: 0.0365,V Acc: 0.8559, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.6970
Fold [2/5] Epoch [20/100] Initial Loss: 0.1390, Training Loss: 0.0175, Initial Validation Loss: 0.1356, Validation Loss: 0.0286,V Acc: 0.8649, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.6667
Fold [2/5] Epoch [30/100] Initial Loss: 0.1390, Training Loss: 0.0153, Initial Validation Loss: 0.1356, Validation Loss: 0.0300,V Acc: 0.8468, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 30  Rolling back to Epoch (base 0): 25  Top Validation Acc: 0.9487179487179487
84 1 [array([0.7371191 , 0.04569136, 0.03719865, 0.07164203, 0.10834891],
      dtype=float32)]
Fold [3/5] Epoch [0/100] Initial Loss: 0.1379, Training Loss: 0.1379, Initial Validation Loss: 0.1296, Validation Loss: 0.1296,V Acc: 0.3273, Top 70th Acc: 0.3636, Bottom 30th Acc: 0.2424
Fold [3/5] Epoch [10/100] Initial Loss: 0.1379, Training Loss: 0.0428, Initial Validation Loss: 0.1296, Validation Loss: 0.0427,V Acc: 0.8273, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.6061
Fold [3/5] Epoch [20/100] Initial Loss: 0.1379, Training Loss: 0.0185, Initial Validation Loss: 0.1296, Validation Loss: 0.0309,V Acc: 0.8273, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 22  Rolling back to Epoch (base 0): 17  Top Validation Acc: 0.922077922077922
Fold [4/5] Epoch [0/100] Initial Loss: 0.1357, Training Loss: 0.1357, Initial Validation Loss: 0.1312, Validation Loss: 0.1312,V Acc: 0.4312, Top 70th Acc: 0.4805, Bottom 30th Acc: 0.3125
Fold [4/5] Epoch [10/100] Initial Loss: 0.1357, Training Loss: 0.0378, Initial Validation Loss: 0.1312, Validation Loss: 0.0417,V Acc: 0.8624, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.6875
Fold [2/5] Epoch [10/100] Initial Loss: 0.1337, Training Loss: 0.0826, Initial Validation Loss: 0.1259, Validation Loss: 0.0765,V Acc: 0.6396, Top 70th Acc: 0.7692, Bottom 30th Acc: 0.3333
Fold [2/5] Epoch [20/100] Initial Loss: 0.1337, Training Loss: 0.0811, Initial Validation Loss: 0.1259, Validation Loss: 0.0743,V Acc: 0.6577, Top 70th Acc: 0.7949, Bottom 30th Acc: 0.3333
Fold [2/5] Epoch [30/100] Initial Loss: 0.1337, Training Loss: 0.0806, Initial Validation Loss: 0.1259, Validation Loss: 0.0731,V Acc: 0.6847, Top 70th Acc: 0.7692, Bottom 30th Acc: 0.4848
Stopping early at Epoch (base 0): 38  Rolling back to Epoch (base 0): 33  Top Validation Acc: 0.782051282051282
84 1 [array([0.12937704, 0.37012163, 0.14673112, 0.19777833, 0.15599199],
      dtype=float32)]
Fold [3/5] Epoch [0/100] Initial Loss: 0.1357, Training Loss: 0.1357, Initial Validation Loss: 0.1248, Validation Loss: 0.1248,V Acc: 0.4091, Top 70th Acc: 0.4545, Bottom 30th Acc: 0.3030
Fold [3/5] Epoch [10/100] Initial Loss: 0.1357, Training Loss: 0.0785, Initial Validation Loss: 0.1248, Validation Loss: 0.0848,V Acc: 0.5818, Top 70th Acc: 0.6753, Bottom 30th Acc: 0.3636
Fold [3/5] Epoch [20/100] Initial Loss: 0.1357, Training Loss: 0.0767, Initial Validation Loss: 0.1248, Validation Loss: 0.0841,V Acc: 0.5727, Top 70th Acc: 0.6883, Bottom 30th Acc: 0.3030
Fold [3/5] Epoch [30/100] Initial Loss: 0.1357, Training Loss: 0.0760, Initial Validation Loss: 0.1248, Validation Loss: 0.0841,V Acc: 0.5636, Top 70th Acc: 0.6883, Bottom 30th Acc: 0.2727
Stopping early at Epoch (base 0): 37  Rolling back to Epoch (base 0): 32  Top Validation Acc: 0.6883116883116883
Fold [4/5] Epoch [0/100] Initial Loss: 0.1400, Training Loss: 0.1400, Initial Validation Loss: 0.1352, Validation Loss: 0.1352,V Acc: 0.2294, Top 70th Acc: 0.1688, Bottom 30th Acc: 0.3750
Fold [4/5] Epoch [10/100] Initial Loss: 0.1400, Training Loss: 0.0806, Initial Validation Loss: 0.1352, Validation Loss: 0.0832,V Acc: 0.6147, Top 70th Acc: 0.7403, Bottom 30th Acc: 0.3125
Fold [4/5] Epoch [20/100] Initial Loss: 0.1400, Training Loss: 0.0778, Initial Validation Loss: 0.1352, Validation Loss: 0.0815,V Acc: 0.6239, Top 70th Acc: 0.7403, Bottom 30th Acc: 0.3438
Stopping early at Epoch (base 0): 27  Rolling back to Epoch (base 0): 22  Top Validation Acc: 0.7272727272727273
Fold [5/5] Epoch [0/100] Initial Loss: 0.1350, Training Loss: 0.1350, Initial Validation Loss: 0.1234, Validation Loss: 0.1234,V Acc: 0.4630, Top 70th Acc: 0.5921, Bottom 30th Acc: 0.1562
Fold [5/5] Epoch [10/100] Initial Loss: 0.1350, Training Loss: 0.0822, Initial Validation Loss: 0.1234, Validation Loss: 0.0715,V Acc: 0.6944, Top 70th Acc: 0.7895, Bottom 30th Acc: 0.4688
Fold [5/5] Epoch [20/100] Initial Loss: 0.1350, Training Loss: 0.0806, Initial Validation Loss: 0.1234, Validation Loss: 0.0706,V Acc: 0.6852, Top 70th Acc: 0.7895, Bottom 30th Acc: 0.4375
Fold [5/5] Epoch [30/100] Initial Loss: 0.1350, Training Loss: 0.0802, Initial Validation Loss: 0.1234, Validation Loss: 0.0696,V Acc: 0.6852, Top 70th Acc: 0.7763, Bottom 30th Acc: 0.4688
Stopping early at Epoch (base 0): 31  Rolling back to Epoch (base 0): 26  Top Validation Acc: 0.7763157894736842
Running train_nn.py with seed 85
CUDA:False
Training samples count:  550
Training on 2 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1386, Training Loss: 0.1386, Initial Validation Loss: 0.1323, Validation Loss: 0.1323,V Acc: 0.4018, Top 70th Acc: 0.4177, Bottom 30th Acc: 0.3636
Fold [1/5] Epoch [10/100] Initial Loss: 0.1386, Training Loss: 0.0824, Initial Validation Loss: 0.1323, Validation Loss: 0.0762,V Acc: 0.6161, Top 70th Acc: 0.7722, Bottom 30th Acc: 0.2424
Fold [1/5] Epoch [20/100] Initial Loss: 0.1386, Training Loss: 0.0811, Initial Validation Loss: 0.1323, Validation Loss: 0.0747,V Acc: 0.6339, Top 70th Acc: 0.7975, Bottom 30th Acc: 0.2424
Stopping early at Epoch (base 0): 29  Rolling back to Epoch (base 0): 24  Top Validation Acc: 0.759493670886076
Fold [2/5] Epoch [0/100] Initial Loss: 0.1363, Training Loss: 0.1363, Initial Validation Loss: 0.1298, Validation Loss: 0.1298,V Acc: 0.3874, Top 70th Acc: 0.4744, Bottom 30th Acc: 0.1818
Fold [2/5] Epoch [10/100] Initial Loss: 0.1363, Training Loss: 0.0780, Initial Validation Loss: 0.1298, Validation Loss: 0.0889,V Acc: 0.5766, Top 70th Acc: 0.7051, Bottom 30th Acc: 0.2727
Fold [2/5] Epoch [20/100] Initial Loss: 0.1363, Training Loss: 0.0765, Initial Validation Loss: 0.1298, Validation Loss: 0.0874,V Acc: 0.5856, Top 70th Acc: 0.6795, Bottom 30th Acc: 0.3636
Stopping early at Epoch (base 0): 20  Rolling back to Epoch (base 0): 15  Top Validation Acc: 0.6794871794871795
Fold [3/5] Epoch [0/100] Initial Loss: 0.1342, Training Loss: 0.1342, Initial Validation Loss: 0.1262, Validation Loss: 0.1262,V Acc: 0.3727, Top 70th Acc: 0.3896, Bottom 30th Acc: 0.3333
Fold [3/5] Epoch [10/100] Initial Loss: 0.1342, Training Loss: 0.0798, Initial Validation Loss: 0.1262, Validation Loss: 0.0811,V Acc: 0.6727, Top 70th Acc: 0.7403, Bottom 30th Acc: 0.5152
Stopping early at Epoch (base 0): 19  Rolling back to Epoch (base 0): 14  Top Validation Acc: 0.7402597402597403
85 2 [array([0.11676688, 0.35236734, 0.14795911, 0.20359908, 0.17930758],
      dtype=float32)]
Fold [4/5] Epoch [0/100] Initial Loss: 0.1371, Training Loss: 0.1371, Initial Validation Loss: 0.1276, Validation Loss: 0.1276,V Acc: 0.3945, Top 70th Acc: 0.3506, Bottom 30th Acc: 0.5000
Fold [4/5] Epoch [10/100] Initial Loss: 0.1371, Training Loss: 0.0816, Initial Validation Loss: 0.1276, Validation Loss: 0.0773,V Acc: 0.6606, Top 70th Acc: 0.7792, Bottom 30th Acc: 0.3750
Stopping early at Epoch (base 0): 19  Rolling back to Epoch (base 0): 14  Top Validation Acc: 0.7922077922077922
Fold [5/5] Epoch [0/100] Initial Loss: 0.1432, Training Loss: 0.1432, Initial Validation Loss: 0.1227, Validation Loss: 0.1227,V Acc: 0.3241, Top 70th Acc: 0.4211, Bottom 30th Acc: 0.0938
Fold [5/5] Epoch [10/100] Initial Loss: 0.1432, Training Loss: 0.0821, Initial Validation Loss: 0.1227, Validation Loss: 0.0759,V Acc: 0.6204, Top 70th Acc: 0.7237, Bottom 30th Acc: 0.3750
Fold [5/5] Epoch [20/100] Initial Loss: 0.1432, Training Loss: 0.0789, Initial Validation Loss: 0.1227, Validation Loss: 0.0739,V Acc: 0.6019, Top 70th Acc: 0.7105, Bottom 30th Acc: 0.3438
Fold [5/5] Epoch [30/100] Initial Loss: 0.1432, Training Loss: 0.0780, Initial Validation Loss: 0.1227, Validation Loss: 0.0733,V Acc: 0.5926, Top 70th Acc: 0.7237, Bottom 30th Acc: 0.2812
Stopping early at Epoch (base 0): 34  Rolling back to Epoch (base 0): 29  Top Validation Acc: 0.7368421052631579
Running train_nn.py with seed 86
CUDA:False
Training samples count:  550
Training on 2 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1380, Training Loss: 0.1380, Initial Validation Loss: 0.1240, Validation Loss: 0.1240,V Acc: 0.3839, Top 70th Acc: 0.4304, Bottom 30th Acc: 0.2727
Fold [1/5] Epoch [10/100] Initial Loss: 0.1380, Training Loss: 0.0806, Initial Validation Loss: 0.1240, Validation Loss: 0.0788,V Acc: 0.6429, Top 70th Acc: 0.7342, Bottom 30th Acc: 0.4242
Fold [1/5] Epoch [20/100] Initial Loss: 0.1380, Training Loss: 0.0782, Initial Validation Loss: 0.1240, Validation Loss: 0.0777,V Acc: 0.6250, Top 70th Acc: 0.7215, Bottom 30th Acc: 0.3939
Fold [1/5] Epoch [30/100] Initial Loss: 0.1380, Training Loss: 0.0774, Initial Validation Loss: 0.1240, Validation Loss: 0.0774,V Acc: 0.6339, Top 70th Acc: 0.7215, Bottom 30th Acc: 0.4242
Stopping early at Epoch (base 0): 30  Rolling back to Epoch (base 0): 25  Top Validation Acc: 0.7215189873417721
86 0 [array([0.09872721, 0.37726164, 0.1389714 , 0.22874063, 0.15629914],
      dtype=float32)]
Fold [2/5] Epoch [0/100] Initial Loss: 0.1311, Training Loss: 0.1311, Initial Validation Loss: 0.1205, Validation Loss: 0.1205,V Acc: 0.5315, Top 70th Acc: 0.6282, Bottom 30th Acc: 0.3030
Fold [2/5] Epoch [10/100] Initial Loss: 0.1311, Training Loss: 0.0801, Initial Validation Loss: 0.1205, Validation Loss: 0.0800,V Acc: 0.6126, Top 70th Acc: 0.7564, Bottom 30th Acc: 0.2727
Fold [2/5] Epoch [20/100] Initial Loss: 0.1311, Training Loss: 0.0790, Initial Validation Loss: 0.1205, Validation Loss: 0.0792,V Acc: 0.6126, Top 70th Acc: 0.7436, Bottom 30th Acc: 0.3030
Fold [1/5] Epoch [20/100] Initial Loss: 0.1358, Training Loss: 0.0175, Initial Validation Loss: 0.1271, Validation Loss: 0.0320,V Acc: 0.8482, Top 70th Acc: 0.9367, Bottom 30th Acc: 0.6364
Fold [1/5] Epoch [30/100] Initial Loss: 0.1358, Training Loss: 0.0135, Initial Validation Loss: 0.1271, Validation Loss: 0.0289,V Acc: 0.8482, Top 70th Acc: 0.9494, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 39  Rolling back to Epoch (base 0): 34  Top Validation Acc: 0.9493670886075949
86 0 [array([0.71510345, 0.0268829 , 0.05992053, 0.10775861, 0.09033454],
      dtype=float32)]
Fold [2/5] Epoch [0/100] Initial Loss: 0.1394, Training Loss: 0.1394, Initial Validation Loss: 0.1384, Validation Loss: 0.1384,V Acc: 0.2703, Top 70th Acc: 0.3205, Bottom 30th Acc: 0.1515
Fold [2/5] Epoch [10/100] Initial Loss: 0.1394, Training Loss: 0.0380, Initial Validation Loss: 0.1384, Validation Loss: 0.0414,V Acc: 0.8288, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.5455
Fold [2/5] Epoch [20/100] Initial Loss: 0.1394, Training Loss: 0.0167, Initial Validation Loss: 0.1384, Validation Loss: 0.0288,V Acc: 0.8829, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.6667
Fold [2/5] Epoch [30/100] Initial Loss: 0.1394, Training Loss: 0.0133, Initial Validation Loss: 0.1384, Validation Loss: 0.0269,V Acc: 0.8739, Top 70th Acc: 0.9872, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 39  Rolling back to Epoch (base 0): 34  Top Validation Acc: 0.9871794871794872
Fold [3/5] Epoch [0/100] Initial Loss: 0.1397, Training Loss: 0.1397, Initial Validation Loss: 0.1367, Validation Loss: 0.1367,V Acc: 0.2455, Top 70th Acc: 0.3377, Bottom 30th Acc: 0.0303
Fold [3/5] Epoch [10/100] Initial Loss: 0.1397, Training Loss: 0.0402, Initial Validation Loss: 0.1367, Validation Loss: 0.0337,V Acc: 0.8818, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.6970
Fold [3/5] Epoch [20/100] Initial Loss: 0.1397, Training Loss: 0.0170, Initial Validation Loss: 0.1367, Validation Loss: 0.0204,V Acc: 0.9000, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.7273
Fold [3/5] Epoch [30/100] Initial Loss: 0.1397, Training Loss: 0.0137, Initial Validation Loss: 0.1367, Validation Loss: 0.0194,V Acc: 0.9000, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.7273
Stopping early at Epoch (base 0): 31  Rolling back to Epoch (base 0): 26  Top Validation Acc: 0.974025974025974
Fold [4/5] Epoch [0/100] Initial Loss: 0.1387, Training Loss: 0.1387, Initial Validation Loss: 0.1311, Validation Loss: 0.1311,V Acc: 0.2844, Top 70th Acc: 0.3247, Bottom 30th Acc: 0.1875
Fold [4/5] Epoch [10/100] Initial Loss: 0.1387, Training Loss: 0.0261, Initial Validation Loss: 0.1311, Validation Loss: 0.0453,V Acc: 0.7615, Top 70th Acc: 0.8831, Bottom 30th Acc: 0.4688
Stopping early at Epoch (base 0): 18  Rolling back to Epoch (base 0): 13  Top Validation Acc: 0.8701298701298701
Fold [5/5] Epoch [0/100] Initial Loss: 0.1413, Training Loss: 0.1413, Initial Validation Loss: 0.1306, Validation Loss: 0.1306,V Acc: 0.3056, Top 70th Acc: 0.3421, Bottom 30th Acc: 0.2188
Fold [5/5] Epoch [10/100] Initial Loss: 0.1413, Training Loss: 0.0402, Initial Validation Loss: 0.1306, Validation Loss: 0.0546,V Acc: 0.7037, Top 70th Acc: 0.7895, Bottom 30th Acc: 0.5000
Fold [5/5] Epoch [20/100] Initial Loss: 0.1413, Training Loss: 0.0153, Initial Validation Loss: 0.1306, Validation Loss: 0.0408,V Acc: 0.7685, Top 70th Acc: 0.8553, Bottom 30th Acc: 0.5625
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.868421052631579
Running train_nn.py with seed 87
CUDA:False
Training samples count:  550
Training on 40 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1340, Training Loss: 0.1340, Initial Validation Loss: 0.1327, Validation Loss: 0.1327,V Acc: 0.3482, Top 70th Acc: 0.4177, Bottom 30th Acc: 0.1818
Fold [1/5] Epoch [10/100] Initial Loss: 0.1340, Training Loss: 0.0269, Initial Validation Loss: 0.1327, Validation Loss: 0.0365,V Acc: 0.8661, Top 70th Acc: 0.9494, Bottom 30th Acc: 0.6667
Fold [1/5] Epoch [20/100] Initial Loss: 0.1340, Training Loss: 0.0152, Initial Validation Loss: 0.1327, Validation Loss: 0.0306,V Acc: 0.8482, Top 70th Acc: 0.9620, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 29  Rolling back to Epoch (base 0): 24  Top Validation Acc: 0.9620253164556962
Fold [2/5] Epoch [0/100] Initial Loss: 0.1404, Training Loss: 0.1404, Initial Validation Loss: 0.1371, Validation Loss: 0.1371,V Acc: 0.2523, Top 70th Acc: 0.2308, Bottom 30th Acc: 0.3030
Fold [2/5] Epoch [10/100] Initial Loss: 0.1404, Training Loss: 0.0401, Initial Validation Loss: 0.1371, Validation Loss: 0.0495,V Acc: 0.7658, Top 70th Acc: 0.8462, Bottom 30th Acc: 0.5758
Fold [2/5] Epoch [20/100] Initial Loss: 0.1404, Training Loss: 0.0154, Initial Validation Loss: 0.1371, Validation Loss: 0.0329,V Acc: 0.8559, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.7273
Fold [2/5] Epoch [30/100] Initial Loss: 0.1404, Training Loss: 0.0114, Initial Validation Loss: 0.1371, Validation Loss: 0.0312,V Acc: 0.8559, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 34  Rolling back to Epoch (base 0): 29  Top Validation Acc: 0.9358974358974359
87 1 [array([0.56923324, 0.02477911, 0.10566859, 0.07614519, 0.22417389],
      dtype=float32)]
Fold [3/5] Epoch [0/100] Initial Loss: 0.1392, Training Loss: 0.1392, Initial Validation Loss: 0.1329, Validation Loss: 0.1329,V Acc: 0.2545, Top 70th Acc: 0.3247, Bottom 30th Acc: 0.0909
Fold [3/5] Epoch [10/100] Initial Loss: 0.1392, Training Loss: 0.0397, Initial Validation Loss: 0.1329, Validation Loss: 0.0500,V Acc: 0.7909, Top 70th Acc: 0.8571, Bottom 30th Acc: 0.6364
Fold [3/5] Epoch [20/100] Initial Loss: 0.1392, Training Loss: 0.0163, Initial Validation Loss: 0.1329, Validation Loss: 0.0310,V Acc: 0.8455, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.6364
Fold [3/5] Epoch [30/100] Initial Loss: 0.1392, Training Loss: 0.0125, Initial Validation Loss: 0.1329, Validation Loss: 0.0300,V Acc: 0.8364, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 30  Rolling back to Epoch (base 0): 25  Top Validation Acc: 0.922077922077922
Fold [4/5] Epoch [0/100] Initial Loss: 0.1382, Training Loss: 0.1382, Initial Validation Loss: 0.1310, Validation Loss: 0.1310,V Acc: 0.3028, Top 70th Acc: 0.3506, Bottom 30th Acc: 0.1875
Fold [4/5] Epoch [10/100] Initial Loss: 0.1382, Training Loss: 0.0249, Initial Validation Loss: 0.1310, Validation Loss: 0.0270,V Acc: 0.8716, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.6250
Fold [4/5] Epoch [20/100] Initial Loss: 0.1382, Training Loss: 0.0148, Initial Validation Loss: 0.1310, Validation Loss: 0.0245,V Acc: 0.8624, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.6250
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.974025974025974
Fold [5/5] Epoch [0/100] Initial Loss: 0.1394, Training Loss: 0.1394, Initial Validation Loss: 0.1286, Validation Loss: 0.1286,V Acc: 0.3519, Top 70th Acc: 0.3158, Bottom 30th Acc: 0.4375
Fold [5/5] Epoch [10/100] Initial Loss: 0.1394, Training Loss: 0.0280, Initial Validation Loss: 0.1286, Validation Loss: 0.0348,V Acc: 0.8333, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.5625
Fold [5/5] Epoch [20/100] Initial Loss: 0.1394, Training Loss: 0.0143, Initial Validation Loss: 0.1286, Validation Loss: 0.0289,V Acc: 0.8519, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.6250
Stopping early at Epoch (base 0): 28  Rolling back to Epoch (base 0): 23  Top Validation Acc: 0.9605263157894737
Running train_nn.py with seed 88
CUDA:False
Training samples count:  550
Training on 40 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1420, Training Loss: 0.1420, Initial Validation Loss: 0.1397, Validation Loss: 0.1397,V Acc: 0.3839, Top 70th Acc: 0.4430, Bottom 30th Acc: 0.2424
Fold [1/5] Epoch [10/100] Initial Loss: 0.1420, Training Loss: 0.0300, Initial Validation Loss: 0.1397, Validation Loss: 0.0380,V Acc: 0.8571, Top 70th Acc: 0.9114, Bottom 30th Acc: 0.7273
Fold [1/5] Epoch [20/100] Initial Loss: 0.1420, Training Loss: 0.0141, Initial Validation Loss: 0.1397, Validation Loss: 0.0304,V Acc: 0.8571, Top 70th Acc: 0.9620, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 27  Rolling back to Epoch (base 0): 22  Top Validation Acc:
Fold [2/5] Epoch [20/100] Initial Loss: 0.1383, Training Loss: 0.0043, Initial Validation Loss: 0.1348, Validation Loss: 0.0245,V Acc: 0.8829, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 29  Rolling back to Epoch (base 0): 24  Top Validation Acc: 0.9743589743589743
Fold [3/5] Epoch [0/100] Initial Loss: 0.1409, Training Loss: 0.1409, Initial Validation Loss: 0.1321, Validation Loss: 0.1321,V Acc: 0.3455, Top 70th Acc: 0.4545, Bottom 30th Acc: 0.0909
Fold [3/5] Epoch [10/100] Initial Loss: 0.1409, Training Loss: 0.0207, Initial Validation Loss: 0.1321, Validation Loss: 0.0421,V Acc: 0.8091, Top 70th Acc: 0.8831, Bottom 30th Acc: 0.6364
Fold [3/5] Epoch [20/100] Initial Loss: 0.1409, Training Loss: 0.0048, Initial Validation Loss: 0.1321, Validation Loss: 0.0319,V Acc: 0.8273, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.6061
Fold [3/5] Epoch [30/100] Initial Loss: 0.1409, Training Loss: 0.0039, Initial Validation Loss: 0.1321, Validation Loss: 0.0313,V Acc: 0.8455, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 33  Rolling back to Epoch (base 0): 28  Top Validation Acc: 0.935064935064935
Fold [4/5] Epoch [0/100] Initial Loss: 0.1399, Training Loss: 0.1399, Initial Validation Loss: 0.1352, Validation Loss: 0.1352,V Acc: 0.2477, Top 70th Acc: 0.3506, Bottom 30th Acc: 0.0000
Fold [4/5] Epoch [10/100] Initial Loss: 0.1399, Training Loss: 0.0152, Initial Validation Loss: 0.1352, Validation Loss: 0.0270,V Acc: 0.8899, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.7188
Fold [4/5] Epoch [20/100] Initial Loss: 0.1399, Training Loss: 0.0051, Initial Validation Loss: 0.1352, Validation Loss: 0.0211,V Acc: 0.9174, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.7812
Stopping early at Epoch (base 0): 29  Rolling back to Epoch (base 0): 24  Top Validation Acc: 0.987012987012987
Fold [5/5] Epoch [0/100] Initial Loss: 0.1410, Training Loss: 0.1410, Initial Validation Loss: 0.1309, Validation Loss: 0.1309,V Acc: 0.3889, Top 70th Acc: 0.4342, Bottom 30th Acc: 0.2812
Fold [5/5] Epoch [10/100] Initial Loss: 0.1410, Training Loss: 0.0195, Initial Validation Loss: 0.1309, Validation Loss: 0.0379,V Acc: 0.8426, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.6250
Fold [5/5] Epoch [20/100] Initial Loss: 0.1410, Training Loss: 0.0047, Initial Validation Loss: 0.1309, Validation Loss: 0.0321,V Acc: 0.7870, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.3750
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.9342105263157895
Running train_nn.py with seed 65
CUDA:False
Training samples count:  550
Training on 162 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1394, Training Loss: 0.1394, Initial Validation Loss: 0.1317, Validation Loss: 0.1317,V Acc: 0.2679, Top 70th Acc: 0.3544, Bottom 30th Acc: 0.0606
Fold [1/5] Epoch [10/100] Initial Loss: 0.1394, Training Loss: 0.0196, Initial Validation Loss: 0.1317, Validation Loss: 0.0394,V Acc: 0.8304, Top 70th Acc: 0.9241, Bottom 30th Acc: 0.6061
Fold [1/5] Epoch [20/100] Initial Loss: 0.1394, Training Loss: 0.0053, Initial Validation Loss: 0.1317, Validation Loss: 0.0311,V Acc: 0.8304, Top 70th Acc: 0.9494, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.9493670886075949
Fold [2/5] Epoch [0/100] Initial Loss: 0.1379, Training Loss: 0.1379, Initial Validation Loss: 0.1371, Validation Loss: 0.1371,V Acc: 0.3333, Top 70th Acc: 0.3718, Bottom 30th Acc: 0.2424
Fold [2/5] Epoch [10/100] Initial Loss: 0.1379, Training Loss: 0.0120, Initial Validation Loss: 0.1371, Validation Loss: 0.0323,V Acc: 0.8829, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.7879
Fold [2/5] Epoch [20/100] Initial Loss: 0.1379, Training Loss: 0.0047, Initial Validation Loss: 0.1371, Validation Loss: 0.0295,V Acc: 0.8649, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.7273
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.9358974358974359
Fold [3/5] Epoch [0/100] Initial Loss: 0.1420, Training Loss: 0.1420, Initial Validation Loss: 0.1320, Validation Loss: 0.1320,V Acc: 0.4091, Top 70th Acc: 0.4675, Bottom 30th Acc: 0.2727
Fold [3/5] Epoch [10/100] Initial Loss: 0.1420, Training Loss: 0.0183, Initial Validation Loss: 0.1320, Validation Loss: 0.0433,V Acc: 0.7818, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.4848
Fold [3/5] Epoch [20/100] Initial Loss: 0.1420, Training Loss: 0.0058, Initial Validation Loss: 0.1320, Validation Loss: 0.0351,V Acc: 0.8000, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.4848
Fold [3/5] Epoch [30/100] Initial Loss: 0.1420, Training Loss: 0.0043, Initial Validation Loss: 0.1320, Validation Loss: 0.0343,V Acc: 0.8182, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.5455
Fold [3/5] Epoch [40/100] Initial Loss: 0.1420, Training Loss: 0.0039, Initial Validation Loss: 0.1320, Validation Loss: 0.0337,V Acc: 0.8455, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6061
Fold [3/5] Epoch [50/100] Initial Loss: 0.1420, Training Loss: 0.0037, Initial Validation Loss: 0.1320, Validation Loss: 0.0333,V Acc: 0.8455, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 54  Rolling back to Epoch (base 0): 49  Top Validation Acc: 0.935064935064935
Fold [4/5] Epoch [0/100] Initial Loss: 0.1387, Training Loss: 0.1387, Initial Validation Loss: 0.1337, Validation Loss: 0.1337,V Acc: 0.3119, Top 70th Acc: 0.3377, Bottom 30th Acc: 0.2500
Fold [4/5] Epoch [10/100] Initial Loss: 0.1387, Training Loss: 0.0246, Initial Validation Loss: 0.1337, Validation Loss: 0.0358,V Acc: 0.8165, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.5625
Fold [4/5] Epoch [20/100] Initial Loss: 0.1387, Training Loss: 0.0057, Initial Validation Loss: 0.1337, Validation Loss: 0.0260,V Acc: 0.8807, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.6875
Fold [4/5] Epoch [30/100] Initial Loss: 0.1387, Training Loss: 0.0041, Initial Validation Loss: 0.1337, Validation Loss: 0.0259,V Acc: 0.8807, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.6875
Stopping early at Epoch (base 0): 31  Rolling back to Epoch (base 0): 26  Top Validation Acc: 0.961038961038961
65 3 [array([0.2992662 , 0.05764556, 0.05498781, 0.3237795 , 0.2643209 ],
      dtype=float32)]
Fold [5/5] Epoch [0/100] Initial Loss: 0.1405, Training Loss: 0.1405, Initial Validation Loss: 0.1313, Validation Loss: 0.1313,V Acc: 0.2500, Top 70th Acc: 0.3421, Bottom 30th Acc: 0.0312
Fold [5/5] Epoch [10/100] Initial Loss: 0.1405, Training Loss: 0.0193, Initial Validation Loss: 0.1313, Validation Loss: 0.0337,V Acc: 0.8148, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.5000
Fold [5/5] Epoch [20/100] Initial Loss: 0.1405, Training Loss: 0.0052, Initial Validation Loss: 0.1313, Validation Loss: 0.0270,V Acc: 0.8333, Top 70th Acc: 0.9868, Bottom 30th Acc: 0.4688
Fold [5/5] Epoch [30/100] Initial Loss: 0.1405, Training Loss: 0.0038, Initial Validation Loss: 0.1313, Validation Loss: 0.0260,V Acc: 0.8519, Top 70th Acc: 0.9868, Bottom 30th Acc: 0.5312
Fold [5/5] Epoch [40/100] Initial Loss: 0.1405, Training Loss: 0.0036, Initial Validation Loss: 0.1313, Validation Loss: 0.0261,V Acc: 0.8426, Top 70th Acc: 0.9737, Bottom 30th Acc: 0.5312
Stopping early at Epoch (base 0): 42  Rolling back to Epoch (base 0): 37  Top Validation Acc: 0.9736842105263158
Running train_nn.py with seed 66
CUDA:False
Training samples count:  550
Training on 162 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1376, Training Loss: 0.1376, Initial Validation Loss: 0.1385, Validation Loss: 0.1385,V Acc: 0.3125, Top 70th Acc: 0.3671, Bottom 30th Acc: 0.1818
Fold [1/5] Epoch [10/100] Initial Loss: 0.1376, Training Loss: 0.0345, Initial Validation Loss: 0.1385, Validation Loss: 0.0386,V Acc: 0.8661, Top 70th Acc: 0.9494, Bottom 30th Acc: 0.6667
Fold [1/5] Epoch [20/100] Initial Loss: 0.1376, Training Loss: 0.0059, Initial Validation Loss: 0.1385, Validation Loss: 0.0194,V Acc: 0.9375, Top 70th Acc: 0.9747, Bottom 30th Acc: 0.8485
Fold [1/5] Epoch [30/100] Initial Loss: 0.1376, Training Loss: 0.0043, Initial Validation Loss: 0.1385, Validation Loss: 0.0184,V Acc: 0.9286, Top 70th Acc: 0.9620, Bottom 30th Acc: 0.8485
Fold [1/5] Epoch [40/100] Initial Loss: 0.1376, Training Loss: 0.0040, Initial Validation Loss: 0.1385, Validation Loss: 0.0186,V Acc: 0.9286, Top 70th Acc: 0.9620, Bottom 30th Acc: 0.8485
Fold [1/5] Epoch [30/100] Initial Loss: 0.1452, Training Loss: 0.0216, Initial Validation Loss: 0.1378, Validation Loss: 0.0346,V Acc: 0.8036, Top 70th Acc: 0.9367, Bottom 30th Acc: 0.4848
Stopping early at Epoch (base 0): 36  Rolling back to Epoch (base 0): 31  Top Validation Acc: 0.9113924050632911
Fold [2/5] Epoch [0/100] Initial Loss: 0.1392, Training Loss: 0.1392, Initial Validation Loss: 0.1354, Validation Loss: 0.1354,V Acc: 0.4054, Top 70th Acc: 0.4615, Bottom 30th Acc: 0.2727
Fold [2/5] Epoch [10/100] Initial Loss: 0.1392, Training Loss: 0.0339, Initial Validation Loss: 0.1354, Validation Loss: 0.0362,V Acc: 0.8468, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.6364
Fold [2/5] Epoch [20/100] Initial Loss: 0.1392, Training Loss: 0.0244, Initial Validation Loss: 0.1354, Validation Loss: 0.0316,V Acc: 0.8649, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.7273
Fold [2/5] Epoch [30/100] Initial Loss: 0.1392, Training Loss: 0.0219, Initial Validation Loss: 0.1354, Validation Loss: 0.0306,V Acc: 0.8829, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.8182
Stopping early at Epoch (base 0): 34  Rolling back to Epoch (base 0): 29  Top Validation Acc: 0.9102564102564102
Fold [3/5] Epoch [0/100] Initial Loss: 0.1365, Training Loss: 0.1365, Initial Validation Loss: 0.1308, Validation Loss: 0.1308,V Acc: 0.3273, Top 70th Acc: 0.4286, Bottom 30th Acc: 0.0909
Fold [3/5] Epoch [10/100] Initial Loss: 0.1365, Training Loss: 0.0349, Initial Validation Loss: 0.1308, Validation Loss: 0.0392,V Acc: 0.8182, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.6061
Fold [3/5] Epoch [20/100] Initial Loss: 0.1365, Training Loss: 0.0245, Initial Validation Loss: 0.1308, Validation Loss: 0.0340,V Acc: 0.8273, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 29  Rolling back to Epoch (base 0): 24  Top Validation Acc: 0.935064935064935
85 2 [array([0.34092677, 0.06094987, 0.15828249, 0.19393283, 0.24590813],
      dtype=float32)]
Fold [4/5] Epoch [0/100] Initial Loss: 0.1388, Training Loss: 0.1388, Initial Validation Loss: 0.1359, Validation Loss: 0.1359,V Acc: 0.2477, Top 70th Acc: 0.3377, Bottom 30th Acc: 0.0312
Fold [4/5] Epoch [10/100] Initial Loss: 0.1388, Training Loss: 0.0422, Initial Validation Loss: 0.1359, Validation Loss: 0.0448,V Acc: 0.8624, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.7500
Fold [4/5] Epoch [20/100] Initial Loss: 0.1388, Training Loss: 0.0262, Initial Validation Loss: 0.1359, Validation Loss: 0.0301,V Acc: 0.8716, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.7188
Fold [4/5] Epoch [30/100] Initial Loss: 0.1388, Training Loss: 0.0240, Initial Validation Loss: 0.1359, Validation Loss: 0.0281,V Acc: 0.8807, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.7188
Fold [4/5] Epoch [40/100] Initial Loss: 0.1388, Training Loss: 0.0227, Initial Validation Loss: 0.1359, Validation Loss: 0.0276,V Acc: 0.8807, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.6875
Stopping early at Epoch (base 0): 41  Rolling back to Epoch (base 0): 36  Top Validation Acc: 0.961038961038961
Fold [5/5] Epoch [0/100] Initial Loss: 0.1426, Training Loss: 0.1426, Initial Validation Loss: 0.1266, Validation Loss: 0.1266,V Acc: 0.2778, Top 70th Acc: 0.3158, Bottom 30th Acc: 0.1875
Fold [5/5] Epoch [10/100] Initial Loss: 0.1426, Training Loss: 0.0363, Initial Validation Loss: 0.1266, Validation Loss: 0.0390,V Acc: 0.7870, Top 70th Acc: 0.8947, Bottom 30th Acc: 0.5312
Fold [5/5] Epoch [20/100] Initial Loss: 0.1426, Training Loss: 0.0232, Initial Validation Loss: 0.1266, Validation Loss: 0.0352,V Acc: 0.7963, Top 70th Acc: 0.8816, Bottom 30th Acc: 0.5938
Stopping early at Epoch (base 0): 20  Rolling back to Epoch (base 0): 15  Top Validation Acc: 0.881578947368421
Running train_nn.py with seed 86
CUDA:False
Training samples count:  550
Training on 20 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1400, Training Loss: 0.1400, Initial Validation Loss: 0.1352, Validation Loss: 0.1352,V Acc: 0.2679, Top 70th Acc: 0.3291, Bottom 30th Acc: 0.1212
Fold [1/5] Epoch [10/100] Initial Loss: 0.1400, Training Loss: 0.0355, Initial Validation Loss: 0.1352, Validation Loss: 0.0410,V Acc: 0.8393, Top 70th Acc: 0.9114, Bottom 30th Acc: 0.6667
Fold [1/5] Epoch [20/100] Initial Loss: 0.1400, Training Loss: 0.0251, Initial Validation Loss: 0.1352, Validation Loss: 0.0312,V Acc: 0.9018, Top 70th Acc: 0.9367, Bottom 30th Acc: 0.8182
Fold [1/5] Epoch [30/100] Initial Loss: 0.1400, Training Loss: 0.0223, Initial Validation Loss: 0.1352, Validation Loss: 0.0310,V Acc: 0.8750, Top 70th Acc: 0.9367, Bottom 30th Acc: 0.7273
Stopping early at Epoch (base 0): 33  Rolling back to Epoch (base 0): 28  Top Validation Acc: 0.9240506329113924
86 0 [array([0.36465177, 0.05357749, 0.10448788, 0.19547944, 0.28180343],
      dtype=float32)]
Fold [2/5] Epoch [0/100] Initial Loss: 0.1379, Training Loss: 0.1379, Initial Validation Loss: 0.1361, Validation Loss: 0.1361,V Acc: 0.3423, Top 70th Acc: 0.4359, Bottom 30th Acc: 0.1212
Fold [2/5] Epoch [10/100] Initial Loss: 0.1379, Training Loss: 0.0312, Initial Validation Loss: 0.1361, Validation Loss: 0.0365,V Acc: 0.8559, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.6667
Fold [2/5] Epoch [20/100] Initial Loss: 0.1379, Training Loss: 0.0225, Initial Validation Loss: 0.1361, Validation Loss: 0.0327,V Acc: 0.8559, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.6061
Fold [2/5] Epoch [30/100] Initial Loss: 0.1379, Training Loss: 0.0204, Initial Validation Loss: 0.1361, Validation Loss: 0.0328,V Acc: 0.8559, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.6364
Fold [2/5] Epoch [40/100] Initial Loss: 0.1379, Training Loss: 0.0192, Initial Validation Loss: 0.1361, Validation Loss: 0.0311,V Acc: 0.8559, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 44  Rolling back to Epoch (base 0): 39  Top Validation Acc: 0.9615384615384616
Fold [3/5] Epoch [0/100] Initial Loss: 0.1395, Training Loss: 0.1395, Initial Validation Loss: 0.1355, Validation Loss: 0.1355,V Acc: 0.2909, Top 70th Acc: 0.2987, Bottom 30th Acc: 0.2727
Fold [3/5] Epoch [10/100] Initial Loss: 0.1395, Training Loss: 0.0473, Initial Validation Loss: 0.1355, Validation Loss: 0.0447,V Acc: 0.7818, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.4848
Fold [3/5] Epoch [20/100] Initial Loss: 0.1395, Training Loss: 0.0276, Initial Validation Loss: 0.1355, Validation Loss: 0.0297,V Acc: 0.8545, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6364
Fold [3/5] Epoch [30/100] Initial Loss: 0.1395, Training Loss: 0.0238, Initial Validation Loss: 0.1355, Validation Loss: 0.0280,V Acc: 0.8545, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 32  Rolling back to Epoch (base 0): 27  Top Validation Acc: 0.961038961038961
Fold [4/5] Epoch [0/100] Initial Loss: 0.1390, Training Loss: 0.1390, Initial Validation Loss: 0.1306, Validation Loss: 0.1306,V Acc: 0.3853, Top 70th Acc: 0.3896, Bottom 30th Acc: 0.3750
Fold [4/5] Epoch [10/100] Initial Loss: 0.1390, Training Loss: 0.0295, Initial Validation Loss: 0.1306, Validation Loss: 0.0439,V Acc: 0.8073, Top 70th Acc: 0.8961, Bottom 30th Acc: 0.5938
Stopping early at Epoch (base 0): 19  Rolling back to Epoch (base 0): 14  Top Validation Acc: 0.9090909090909091
Fold [5/5] Epoch [0/100] Initial Loss: 0.1415, Training Loss: 0.1415, Initial Validation Loss: 0.1306, Validation Loss: 0.1306,V Acc: 0.3056, Top 70th Acc: 0.3026, Bottom 30th Acc: 0.3125
Fold [5/5] Epoch [10/100] Initial Loss: 0.1415, Training Loss: 0.0369, Initial Validation Loss: 0.1306, Validation Loss: 0.0451,V Acc: 0.7593, Top 70th Acc: 0.8816, Bottom 30th Acc: 0.4688
Fold [5/5] Epoch [20/100] Initial Loss: 0.1415, Training Loss: 0.0222, Initial Validation Loss: 0.1306, Validation Loss: 0.0374,V Acc: 0.8148, Top 70th Acc: 0.9079, Bottom 30th Acc: 0.5938
Stopping early at Epoch (base 0): 27  Rolling back to Epoch (base 0): 22  Top Validation Acc: 0.9078947368421053
Running train_nn.py with seed 87
CUDA:False
Training samples count:  550
Training on 20 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1389, Training Loss: 0.1389, Initial Validation Loss: 0.1375, Validation Loss: 0.1375,V Acc: 0.2679, Top 70th Acc: 0.2658, Bottom 30th Acc: 0.2727
Fold [1/5] Epoch [10/100] Initial Loss: 0.1389, Training Loss: 0.0392, Initial Validation Loss: 0.1375, Validation Loss: 0.0505,V Acc: 0.7857, Top 70th Acc: 0.8734, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 21  Rolling back to Epoch (base 0): 16  Top Validation Acc: 0.7435897435897436
Fold [3/5] Epoch [0/100] Initial Loss: 0.1351, Training Loss: 0.1351, Initial Validation Loss: 0.1281, Validation Loss: 0.1281,V Acc: 0.4182, Top 70th Acc: 0.5714, Bottom 30th Acc: 0.0606
Fold [3/5] Epoch [10/100] Initial Loss: 0.1351, Training Loss: 0.0823, Initial Validation Loss: 0.1281, Validation Loss: 0.0763,V Acc: 0.6818, Top 70th Acc: 0.7532, Bottom 30th Acc: 0.5152
Fold [3/5] Epoch [20/100] Initial Loss: 0.1351, Training Loss: 0.0799, Initial Validation Loss: 0.1281, Validation Loss: 0.0740,V Acc: 0.6727, Top 70th Acc: 0.7792, Bottom 30th Acc: 0.4242
Stopping early at Epoch (base 0): 29  Rolling back to Epoch (base 0): 24  Top Validation Acc: 0.7922077922077922
Fold [4/5] Epoch [0/100] Initial Loss: 0.1394, Training Loss: 0.1394, Initial Validation Loss: 0.1227, Validation Loss: 0.1227,V Acc: 0.4404, Top 70th Acc: 0.5584, Bottom 30th Acc: 0.1562
Fold [4/5] Epoch [10/100] Initial Loss: 0.1394, Training Loss: 0.0826, Initial Validation Loss: 0.1227, Validation Loss: 0.0781,V Acc: 0.6055, Top 70th Acc: 0.7403, Bottom 30th Acc: 0.2812
Fold [4/5] Epoch [20/100] Initial Loss: 0.1394, Training Loss: 0.0804, Initial Validation Loss: 0.1227, Validation Loss: 0.0758,V Acc: 0.6239, Top 70th Acc: 0.7532, Bottom 30th Acc: 0.3125
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.7532467532467533
Fold [5/5] Epoch [0/100] Initial Loss: 0.1419, Training Loss: 0.1419, Initial Validation Loss: 0.1259, Validation Loss: 0.1259,V Acc: 0.4167, Top 70th Acc: 0.4737, Bottom 30th Acc: 0.2812
Fold [5/5] Epoch [10/100] Initial Loss: 0.1419, Training Loss: 0.0780, Initial Validation Loss: 0.1259, Validation Loss: 0.0876,V Acc: 0.5463, Top 70th Acc: 0.6711, Bottom 30th Acc: 0.2500
Fold [5/5] Epoch [20/100] Initial Loss: 0.1419, Training Loss: 0.0754, Initial Validation Loss: 0.1259, Validation Loss: 0.0874,V Acc: 0.5741, Top 70th Acc: 0.6842, Bottom 30th Acc: 0.3125
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.6578947368421053
Running train_nn.py with seed 87
CUDA:False
Training samples count:  550
Training on 2 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1397, Training Loss: 0.1397, Initial Validation Loss: 0.1367, Validation Loss: 0.1367,V Acc: 0.3750, Top 70th Acc: 0.4430, Bottom 30th Acc: 0.2121
Fold [1/5] Epoch [10/100] Initial Loss: 0.1397, Training Loss: 0.0774, Initial Validation Loss: 0.1367, Validation Loss: 0.0913,V Acc: 0.6071, Top 70th Acc: 0.6835, Bottom 30th Acc: 0.4242
Stopping early at Epoch (base 0): 19  Rolling back to Epoch (base 0): 14  Top Validation Acc: 0.6835443037974683
Fold [2/5] Epoch [0/100] Initial Loss: 0.1366, Training Loss: 0.1366, Initial Validation Loss: 0.1291, Validation Loss: 0.1291,V Acc: 0.2883, Top 70th Acc: 0.3590, Bottom 30th Acc: 0.1212
Fold [2/5] Epoch [10/100] Initial Loss: 0.1366, Training Loss: 0.0831, Initial Validation Loss: 0.1291, Validation Loss: 0.0753,V Acc: 0.6396, Top 70th Acc: 0.8077, Bottom 30th Acc: 0.2424
Fold [2/5] Epoch [20/100] Initial Loss: 0.1366, Training Loss: 0.0814, Initial Validation Loss: 0.1291, Validation Loss: 0.0725,V Acc: 0.6577, Top 70th Acc: 0.7949, Bottom 30th Acc: 0.3333
Fold [2/5] Epoch [30/100] Initial Loss: 0.1366, Training Loss: 0.0805, Initial Validation Loss: 0.1291, Validation Loss: 0.0715,V Acc: 0.6486, Top 70th Acc: 0.7821, Bottom 30th Acc: 0.3333
Stopping early at Epoch (base 0): 34  Rolling back to Epoch (base 0): 29  Top Validation Acc: 0.782051282051282
87 1 [array([0.13346957, 0.37752396, 0.12435435, 0.1931512 , 0.17150097],
      dtype=float32)]
Fold [3/5] Epoch [0/100] Initial Loss: 0.1350, Training Loss: 0.1350, Initial Validation Loss: 0.1189, Validation Loss: 0.1189,V Acc: 0.5182, Top 70th Acc: 0.6623, Bottom 30th Acc: 0.1818
Fold [3/5] Epoch [10/100] Initial Loss: 0.1350, Training Loss: 0.0813, Initial Validation Loss: 0.1189, Validation Loss: 0.0771,V Acc: 0.6364, Top 70th Acc: 0.7273, Bottom 30th Acc: 0.4242
Fold [3/5] Epoch [20/100] Initial Loss: 0.1350, Training Loss: 0.0798, Initial Validation Loss: 0.1189, Validation Loss: 0.0760,V Acc: 0.6273, Top 70th Acc: 0.7273, Bottom 30th Acc: 0.3939
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.7012987012987013
Fold [4/5] Epoch [0/100] Initial Loss: 0.1363, Training Loss: 0.1363, Initial Validation Loss: 0.1278, Validation Loss: 0.1278,V Acc: 0.3761, Top 70th Acc: 0.3766, Bottom 30th Acc: 0.3750
Fold [4/5] Epoch [10/100] Initial Loss: 0.1363, Training Loss: 0.0818, Initial Validation Loss: 0.1278, Validation Loss: 0.0715,V Acc: 0.6697, Top 70th Acc: 0.7662, Bottom 30th Acc: 0.4375
Stopping early at Epoch (base 0): 18  Rolling back to Epoch (base 0): 13  Top Validation Acc: 0.7662337662337663
Fold [5/5] Epoch [0/100] Initial Loss: 0.1352, Training Loss: 0.1352, Initial Validation Loss: 0.1229, Validation Loss: 0.1229,V Acc: 0.4537, Top 70th Acc: 0.5789, Bottom 30th Acc: 0.1562
Fold [5/5] Epoch [10/100] Initial Loss: 0.1352, Training Loss: 0.0788, Initial Validation Loss: 0.1229, Validation Loss: 0.0814,V Acc: 0.6019, Top 70th Acc: 0.6974, Bottom 30th Acc: 0.3750
Fold [5/5] Epoch [20/100] Initial Loss: 0.1352, Training Loss: 0.0772, Initial Validation Loss: 0.1229, Validation Loss: 0.0803,V Acc: 0.6111, Top 70th Acc: 0.7237, Bottom 30th Acc: 0.3438
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.7105263157894737
Running train_nn.py with seed 88
CUDA:False
Training samples count:  550
Training on 2 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1315, Training Loss: 0.1315, Initial Validation Loss: 0.1257, Validation Loss: 0.1257,V Acc: 0.4375, Top 70th Acc: 0.5443, Bottom 30th Acc: 0.1818
Fold [1/5] Epoch [10/100] Initial Loss: 0.1315, Training Loss: 0.0803, Initial Validation Loss: 0.1257, Validation Loss: 0.0794,V Acc: 0.6518, Top 70th Acc: 0.7468, Bottom 30th Acc: 0.4242
Fold [1/5] Epoch [20/100] Initial Loss: 0.1315, Training Loss: 0.0782, Initial Validation Loss: 0.1257, Validation Loss: 0.0775,V Acc: 0.6607, Top 70th Acc: 0.7468, Bottom 30th Acc: 0.4545
Stopping early at Epoch (base 0): 21  Rolling back to Epoch (base 0): 16  Top Validation Acc: 0.759493670886076
Fold [2/5] Epoch [0/100] Initial Loss: 0.1298, Training Loss: 0.1298, Initial Validation Loss: 0.1178, Validation Loss: 0.1178,V Acc: 0.4865, Top 70th Acc: 0.6026, Bottom 30th Acc: 0.2121
Fold [2/5] Epoch [10/100] Initial Loss: 0.1298, Training Loss: 0.0832, Initial Validation Loss: 0.1178, Validation Loss: 0.0701,V Acc: 0.6847, Top 70th Acc: 0.7821, Bottom 30th Acc: 0.4545
Fold [2/5] Epoch [20/100] Initial Loss: 0.1298, Training Loss: 0.0816, Initial Validation Loss: 0.1178, Validation Loss: 0.0675,V Acc: 0.7117, Top 70th Acc: 0.7821, Bottom 30th Acc: 0.5455
Fold [2/5] Epoch [30/100] Initial Loss: 0.1298, Training Loss: 0.0812, Initial Validation Loss: 0.1178, Validation Loss: 0.0671,V Acc: 0.6937, Top 70th Acc: 0.7821, Bottom 30th Acc: 0.4848
Stopping early at Epoch (base 0): 30  Rolling back to Epoch (base 0): 25  Top Validation Acc: 0.782051282051282
Fold [3/5] Epoch [0/100] Initial Loss: 0.1393, Training Loss: 0.1393, Initial Validation Loss: 0.1288, Validation Loss: 0.1288,V Acc: 0.3818, Top 70th Acc: 0.4545, Bottom 30th Acc: 0.2121
Fold [3/5] Epoch [10/100] Initial Loss: 0.1393, Training Loss: 0.0767, Initial Validation Loss: 0.1288, Validation Loss: 0.0904,V Acc: 0.5545, Top 70th Acc: 0.6753, Bottom 30th Acc: 0.2727
Fold [3/5] Epoch [20/100] Initial Loss: 0.1393, Training Loss: 0.0749, Initial Validation Loss: 0.1288, Validation Loss: 0.0890,V Acc: 0.5455, Top 70th Acc: 0.6883, Bottom 30th Acc: 0.2121
Fold [3/5] Epoch [30/100] Initial Loss: 0.1393, Training Loss: 0.0743, Initial Validation Loss: 0.1288, Validation Loss: 0.0885,V Acc: 0.5364, Top 70th Acc: 0.6753, Bottom 30th Acc: 0.2121
Stopping early at Epoch (base 0): 33  Rolling back to Epoch (base 0): 28  Top Validation Acc: 0.6753246753246753
88 2 [array([0.09036415, 0.38157552, 0.13769075, 0.2388774 , 0.15149216],
      dtype=float32)]
Fold [4/5] Epoch [0/100] Initial Loss: 0.1378, Training Loss: 0.1378, Initial Validation Loss: 0.1179, Validation Loss: 0.1179,V Acc: 0.3945, Top 70th Acc: 0.4545, Bottom 30th Acc: 0.2500 0.9620253164556962
Fold [2/5] Epoch [0/100] Initial Loss: 0.1386, Training Loss: 0.1386, Initial Validation Loss: 0.1355, Validation Loss: 0.1355,V Acc: 0.2793, Top 70th Acc: 0.3590, Bottom 30th Acc: 0.0909
Fold [2/5] Epoch [10/100] Initial Loss: 0.1386, Training Loss: 0.0272, Initial Validation Loss: 0.1355, Validation Loss: 0.0257,V Acc: 0.8559, Top 70th Acc: 0.9872, Bottom 30th Acc: 0.5455
Fold [2/5] Epoch [20/100] Initial Loss: 0.1386, Training Loss: 0.0154, Initial Validation Loss: 0.1355, Validation Loss: 0.0240,V Acc: 0.8739, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 21  Rolling back to Epoch (base 0): 16  Top Validation Acc: 0.9743589743589743
Fold [3/5] Epoch [0/100] Initial Loss: 0.1410, Training Loss: 0.1410, Initial Validation Loss: 0.1348, Validation Loss: 0.1348,V Acc: 0.2545, Top 70th Acc: 0.3117, Bottom 30th Acc: 0.1212
Fold [3/5] Epoch [10/100] Initial Loss: 0.1410, Training Loss: 0.0351, Initial Validation Loss: 0.1348, Validation Loss: 0.0541,V Acc: 0.7727, Top 70th Acc: 0.8442, Bottom 30th Acc: 0.6061
Fold [3/5] Epoch [20/100] Initial Loss: 0.1410, Training Loss: 0.0196, Initial Validation Loss: 0.1348, Validation Loss: 0.0406,V Acc: 0.8364, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.6364
Fold [3/5] Epoch [30/100] Initial Loss: 0.1410, Training Loss: 0.0134, Initial Validation Loss: 0.1348, Validation Loss: 0.0352,V Acc: 0.8545, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 35  Rolling back to Epoch (base 0): 30  Top Validation Acc: 0.922077922077922
88 2 [array([0.4980262 , 0.07579862, 0.1029554 , 0.14257036, 0.18064947],
      dtype=float32)]
Fold [4/5] Epoch [0/100] Initial Loss: 0.1419, Training Loss: 0.1419, Initial Validation Loss: 0.1276, Validation Loss: 0.1276,V Acc: 0.2385, Top 70th Acc: 0.2468, Bottom 30th Acc: 0.2188
Fold [4/5] Epoch [10/100] Initial Loss: 0.1419, Training Loss: 0.0401, Initial Validation Loss: 0.1276, Validation Loss: 0.0472,V Acc: 0.7339, Top 70th Acc: 0.8312, Bottom 30th Acc: 0.5000
Fold [4/5] Epoch [20/100] Initial Loss: 0.1419, Training Loss: 0.0150, Initial Validation Loss: 0.1276, Validation Loss: 0.0311,V Acc: 0.8257, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.5938
Fold [4/5] Epoch [30/100] Initial Loss: 0.1419, Training Loss: 0.0114, Initial Validation Loss: 0.1276, Validation Loss: 0.0305,V Acc: 0.8165, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.5625
Stopping early at Epoch (base 0): 34  Rolling back to Epoch (base 0): 29  Top Validation Acc: 0.935064935064935
Fold [5/5] Epoch [0/100] Initial Loss: 0.1375, Training Loss: 0.1375, Initial Validation Loss: 0.1357, Validation Loss: 0.1357,V Acc: 0.3148, Top 70th Acc: 0.3553, Bottom 30th Acc: 0.2188
Fold [5/5] Epoch [10/100] Initial Loss: 0.1375, Training Loss: 0.0366, Initial Validation Loss: 0.1357, Validation Loss: 0.0448,V Acc: 0.8241, Top 70th Acc: 0.9211, Bottom 30th Acc: 0.5938
Fold [5/5] Epoch [20/100] Initial Loss: 0.1375, Training Loss: 0.0186, Initial Validation Loss: 0.1357, Validation Loss: 0.0290,V Acc: 0.8796, Top 70th Acc: 0.9737, Bottom 30th Acc: 0.6562
Fold [5/5] Epoch [30/100] Initial Loss: 0.1375, Training Loss: 0.0128, Initial Validation Loss: 0.1357, Validation Loss: 0.0271,V Acc: 0.8704, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.6562
Stopping early at Epoch (base 0): 33  Rolling back to Epoch (base 0): 28  Top Validation Acc: 0.9736842105263158
Running train_nn.py with seed 89
CUDA:False
Training samples count:  550
Training on 40 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1393, Training Loss: 0.1393, Initial Validation Loss: 0.1358, Validation Loss: 0.1358,V Acc: 0.2321, Top 70th Acc: 0.3038, Bottom 30th Acc: 0.0606
Fold [1/5] Epoch [10/100] Initial Loss: 0.1393, Training Loss: 0.0318, Initial Validation Loss: 0.1358, Validation Loss: 0.0406,V Acc: 0.7946, Top 70th Acc: 0.9114, Bottom 30th Acc: 0.5152
Fold [1/5] Epoch [20/100] Initial Loss: 0.1393, Training Loss: 0.0161, Initial Validation Loss: 0.1358, Validation Loss: 0.0322,V Acc: 0.8304, Top 70th Acc: 0.9367, Bottom 30th Acc: 0.5758
Fold [1/5] Epoch [30/100] Initial Loss: 0.1393, Training Loss: 0.0126, Initial Validation Loss: 0.1358, Validation Loss: 0.0304,V Acc: 0.8571, Top 70th Acc: 0.9494, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 34  Rolling back to Epoch (base 0): 29  Top Validation Acc: 0.9240506329113924
Fold [2/5] Epoch [0/100] Initial Loss: 0.1410, Training Loss: 0.1410, Initial Validation Loss: 0.1319, Validation Loss: 0.1319,V Acc: 0.2523, Top 70th Acc: 0.3077, Bottom 30th Acc: 0.1212
Fold [2/5] Epoch [10/100] Initial Loss: 0.1410, Training Loss: 0.0377, Initial Validation Loss: 0.1319, Validation Loss: 0.0472,V Acc: 0.7568, Top 70th Acc: 0.8718, Bottom 30th Acc: 0.4848
Fold [2/5] Epoch [20/100] Initial Loss: 0.1410, Training Loss: 0.0144, Initial Validation Loss: 0.1319, Validation Loss: 0.0325,V Acc: 0.8108, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.9230769230769231
Fold [3/5] Epoch [0/100] Initial Loss: 0.1389, Training Loss: 0.1389, Initial Validation Loss: 0.1374, Validation Loss: 0.1374,V Acc: 0.3818, Top 70th Acc: 0.4026, Bottom 30th Acc: 0.3333
Fold [3/5] Epoch [10/100] Initial Loss: 0.1389, Training Loss: 0.0270, Initial Validation Loss: 0.1374, Validation Loss: 0.0356,V Acc: 0.8727, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.6667
Fold [3/5] Epoch [20/100] Initial Loss: 0.1389, Training Loss: 0.0138, Initial Validation Loss: 0.1374, Validation Loss: 0.0306,V Acc: 0.8636, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.948051948051948
Fold [4/5] Epoch [0/100] Initial Loss: 0.1403, Training Loss: 0.1403, Initial Validation Loss: 0.1318, Validation Loss: 0.1318,V Acc: 0.3211, Top 70th Acc: 0.3506, Bottom 30th Acc: 0.2500
Fold [4/5] Epoch [10/100] Initial Loss: 0.1403, Training Loss: 0.0318, Initial Validation Loss: 0.1318, Validation Loss: 0.0403,V Acc: 0.8073, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.5625
Fold [4/5] Epoch [20/100] Initial Loss: 0.1403, Training Loss: 0.0139, Initial Validation Loss: 0.1318, Validation Loss: 0.0321,V Acc: 0.8073, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.5000
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.935064935064935
89 3 [array([0.6047732 , 0.06158166, 0.10308453, 0.11765547, 0.11290511],
      dtype=float32)]
Fold [5/5] Epoch [0/100] Initial Loss: 0.1393, Training Loss: 0.1393, Initial Validation Loss: 0.1307, Validation Loss: 0.1307,V Acc: 0.2870, Top 70th Acc: 0.3421, Bottom 30th Acc: 0.1562
Fold [5/5] Epoch [10/100] Initial Loss: 0.1393, Training Loss: 0.0252, Initial Validation Loss: 0.1307, Validation Loss: 0.0319,V Acc: 0.8611, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.6562
Fold [5/5] Epoch [20/100] Initial Loss: 0.1393, Training Loss: 0.0137, Initial Validation Loss: 0.1307, Validation Loss: 0.0280,V Acc: 0.8611, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.6875
Stopping early at Epoch (base 0): 20  Rolling back to Epoch (base 0): 15  Top Validation Acc: 0.9342105263157895
Running train_nn.py with seed 90
CUDA:False
Training samples count:  550
Training on 40 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1384, Training Loss: 0.1384, Initial Validation Loss: 0.1328, Validation Loss: 0.1328,V Acc: 0.2589, Top 70th Acc: 0.3418, Bottom 30th Acc: 0.0606
Fold [1/5] Epoch [10/100] Initial Loss: 0.1384, Training Loss: 0.0351, Initial Validation Loss: 0.1328, Validation Loss: 0.0424,V Acc: 0.7768, Top 70th Acc: 0.8861, Bottom 30th Acc: 0.5152
Fold [1/5] Epoch [20/100] Initial Loss: 0.1384, Training Loss: 0.0153, Initial Validation Loss: 0.1328, Validation Loss: 0.0322,V Acc: 0.8125, Top 70th Acc: 0.9367, Bottom 30th Acc: 0.5152
Fold [1/5] Epoch [30/100] Initial Loss: 0.1384, Training Loss: 0.0129, Initial Validation Loss: 0.1328, Validation Loss: 0.0319,V Acc: 0.8214, Top 70th Acc: 0.9241, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 32  Rolling back to Epoch (base 0): 27  Top Validation Acc: 0.9240506329113924
Fold [2/5] Epoch [0/100] Initial Loss: 0.1392, Training Loss: 0.1392, Initial Validation Loss: 0.1314, Validation Loss: 0.1314,V Acc: 0.2973, Top 70th Acc: 0.3846, Bottom 30th Acc: 0.0909
Fold [4/5] Epoch [20/100] Initial Loss: 0.1357, Training Loss: 0.0189, Initial Validation Loss: 0.1312, Validation Loss: 0.0243,V Acc: 0.9083, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.8125
Fold [4/5] Epoch [30/100] Initial Loss: 0.1357, Training Loss: 0.0168, Initial Validation Loss: 0.1312, Validation Loss: 0.0240,V Acc: 0.9083, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.8125
Fold [4/5] Epoch [40/100] Initial Loss: 0.1357, Training Loss: 0.0158, Initial Validation Loss: 0.1312, Validation Loss: 0.0231,V Acc: 0.9266, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.8438
Fold [4/5] Epoch [50/100] Initial Loss: 0.1357, Training Loss: 0.0149, Initial Validation Loss: 0.1312, Validation Loss: 0.0225,V Acc: 0.9174, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.8125
Stopping early at Epoch (base 0): 57  Rolling back to Epoch (base 0): 52  Top Validation Acc: 0.974025974025974
Fold [5/5] Epoch [0/100] Initial Loss: 0.1393, Training Loss: 0.1393, Initial Validation Loss: 0.1310, Validation Loss: 0.1310,V Acc: 0.3241, Top 70th Acc: 0.3553, Bottom 30th Acc: 0.2500
Fold [5/5] Epoch [10/100] Initial Loss: 0.1393, Training Loss: 0.0390, Initial Validation Loss: 0.1310, Validation Loss: 0.0401,V Acc: 0.8241, Top 70th Acc: 0.9079, Bottom 30th Acc: 0.6250
Fold [5/5] Epoch [20/100] Initial Loss: 0.1393, Training Loss: 0.0195, Initial Validation Loss: 0.1310, Validation Loss: 0.0272,V Acc: 0.8704, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.6562
Fold [5/5] Epoch [30/100] Initial Loss: 0.1393, Training Loss: 0.0156, Initial Validation Loss: 0.1310, Validation Loss: 0.0262,V Acc: 0.8704, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.6875
Stopping early at Epoch (base 0): 31  Rolling back to Epoch (base 0): 26  Top Validation Acc: 0.9473684210526315
Running train_nn.py with seed 85
CUDA:False
Training samples count:  550
Training on 30 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1432, Training Loss: 0.1432, Initial Validation Loss: 0.1373, Validation Loss: 0.1373,V Acc: 0.2500, Top 70th Acc: 0.3418, Bottom 30th Acc: 0.0303
Fold [1/5] Epoch [10/100] Initial Loss: 0.1432, Training Loss: 0.0445, Initial Validation Loss: 0.1373, Validation Loss: 0.0542,V Acc: 0.6964, Top 70th Acc: 0.8734, Bottom 30th Acc: 0.2727
Fold [1/5] Epoch [20/100] Initial Loss: 0.1432, Training Loss: 0.0196, Initial Validation Loss: 0.1373, Validation Loss: 0.0389,V Acc: 0.7679, Top 70th Acc: 0.9367, Bottom 30th Acc: 0.3636
Fold [1/5] Epoch [30/100] Initial Loss: 0.1432, Training Loss: 0.0147, Initial Validation Loss: 0.1373, Validation Loss: 0.0351,V Acc: 0.8036, Top 70th Acc: 0.9620, Bottom 30th Acc: 0.4242
Stopping early at Epoch (base 0): 37  Rolling back to Epoch (base 0): 32  Top Validation Acc: 0.9493670886075949
Fold [2/5] Epoch [0/100] Initial Loss: 0.1388, Training Loss: 0.1388, Initial Validation Loss: 0.1346, Validation Loss: 0.1346,V Acc: 0.3964, Top 70th Acc: 0.4231, Bottom 30th Acc: 0.3333
Fold [2/5] Epoch [10/100] Initial Loss: 0.1388, Training Loss: 0.0391, Initial Validation Loss: 0.1346, Validation Loss: 0.0402,V Acc: 0.8108, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.4848
Fold [2/5] Epoch [20/100] Initial Loss: 0.1388, Training Loss: 0.0188, Initial Validation Loss: 0.1346, Validation Loss: 0.0285,V Acc: 0.8559, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.9743589743589743
Fold [3/5] Epoch [0/100] Initial Loss: 0.1373, Training Loss: 0.1373, Initial Validation Loss: 0.1331, Validation Loss: 0.1331,V Acc: 0.3455, Top 70th Acc: 0.4156, Bottom 30th Acc: 0.1818
Fold [3/5] Epoch [10/100] Initial Loss: 0.1373, Training Loss: 0.0331, Initial Validation Loss: 0.1331, Validation Loss: 0.0346,V Acc: 0.8182, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.5152
Fold [3/5] Epoch [20/100] Initial Loss: 0.1373, Training Loss: 0.0187, Initial Validation Loss: 0.1331, Validation Loss: 0.0297,V Acc: 0.8455, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 29  Rolling back to Epoch (base 0): 24  Top Validation Acc: 0.948051948051948
85 2 [array([0.63982785, 0.04359003, 0.06402805, 0.0988015 , 0.15375267],
      dtype=float32)]
Fold [4/5] Epoch [0/100] Initial Loss: 0.1395, Training Loss: 0.1395, Initial Validation Loss: 0.1346, Validation Loss: 0.1346,V Acc: 0.3211, Top 70th Acc: 0.4026, Bottom 30th Acc: 0.1250
Fold [4/5] Epoch [10/100] Initial Loss: 0.1395, Training Loss: 0.0330, Initial Validation Loss: 0.1346, Validation Loss: 0.0419,V Acc: 0.8073, Top 70th Acc: 0.8961, Bottom 30th Acc: 0.5938
Fold [4/5] Epoch [20/100] Initial Loss: 0.1395, Training Loss: 0.0224, Initial Validation Loss: 0.1346, Validation Loss: 0.0296,V Acc: 0.8807, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.6875
Fold [4/5] Epoch [30/100] Initial Loss: 0.1395, Training Loss: 0.0182, Initial Validation Loss: 0.1346, Validation Loss: 0.0227,V Acc: 0.8991, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.7188
Fold [4/5] Epoch [40/100] Initial Loss: 0.1395, Training Loss: 0.0163, Initial Validation Loss: 0.1346, Validation Loss: 0.0225,V Acc: 0.8991, Top 70th Acc: 0.9870, Bottom 30th Acc: 0.6875
Stopping early at Epoch (base 0): 44  Rolling back to Epoch (base 0): 39  Top Validation Acc: 0.987012987012987
Fold [5/5] Epoch [0/100] Initial Loss: 0.1393, Training Loss: 0.1393, Initial Validation Loss: 0.1243, Validation Loss: 0.1243,V Acc: 0.4444, Top 70th Acc: 0.4868, Bottom 30th Acc: 0.3438
Fold [5/5] Epoch [10/100] Initial Loss: 0.1393, Training Loss: 0.0266, Initial Validation Loss: 0.1243, Validation Loss: 0.0358,V Acc: 0.7870, Top 70th Acc: 0.8816, Bottom 30th Acc: 0.5625
Fold [5/5] Epoch [20/100] Initial Loss: 0.1393, Training Loss: 0.0166, Initial Validation Loss: 0.1243, Validation Loss: 0.0331,V Acc: 0.7963, Top 70th Acc: 0.9079, Bottom 30th Acc: 0.5312
Stopping early at Epoch (base 0): 29  Rolling back to Epoch (base 0): 24  Top Validation Acc: 0.9210526315789473
Running train_nn.py with seed 86
CUDA:False
Training samples count:  550
Training on 30 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1402, Training Loss: 0.1402, Initial Validation Loss: 0.1349, Validation Loss: 0.1349,V Acc: 0.2857, Top 70th Acc: 0.3165, Bottom 30th Acc: 0.2121
Fold [1/5] Epoch [10/100] Initial Loss: 0.1402, Training Loss: 0.0306, Initial Validation Loss: 0.1349, Validation Loss: 0.0371,V Acc: 0.8304, Top 70th Acc: 0.9114, Bottom 30th Acc: 0.6364
Fold [1/5] Epoch [20/100] Initial Loss: 0.1402, Training Loss: 0.0188, Initial Validation Loss: 0.1349, Validation Loss: 0.0297,V Acc: 0.8482, Top 70th Acc: 0.9367, Bottom 30th Acc: 0.6364
Fold [1/5] Epoch [30/100] Initial Loss: 0.1402, Training Loss: 0.0161, Initial Validation Loss: 0.1349, Validation Loss: 0.0290,V Acc: 0.8393, Top 70th Acc: 0.9620, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 34  Rolling back to Epoch (base 0): 29  Top Validation Acc: 0.9620253164556962
86 0 [array([0.65661824, 0.09859201, 0.05014019, 0.1147214 , 0.07992819],
      dtype=float32)]
Fold [2/5] Epoch [0/100] Initial Loss: 0.1396, Training Loss: 0.1396, Initial Validation Loss: 0.1386, Validation Loss: 0.1386,V Acc: 0.2793, Top 70th Acc: 0.3462, Bottom 30th Acc: 0.1212
Fold [2/5] Epoch [10/100] Initial Loss: 0.1396, Training Loss: 0.0417, Initial Validation Loss: 0.1386, Validation Loss: 0.0464,V Acc: 0.7658, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.3939
Fold [2/5] Epoch [20/100] Initial Loss: 0.1396, Training Loss: 0.0194, Initial Validation Loss: 0.1386, Validation Loss: 0.0313,V Acc: 0.8468, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 27  Rolling back to Epoch (base 0): 22  Top Validation Acc: 0.9615384615384616
Fold [3/5] Epoch [0/100] Initial Loss: 0.1395, Training Loss: 0.1395, Initial Validation Loss: 0.1374, Validation Loss: 0.1374,V Acc: 0.3000, Top 70th Acc: 0.2597, Bottom 30th Acc: 0.3939
Fold [3/5] Epoch [10/100] Initial Loss: 0.1395, Training Loss: 0.0373, Initial Validation Loss: 0.1374, Validation Loss: 0.0348,V Acc: 0.8364, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.5758
Fold [3/5] Epoch [20/100] Initial Loss: 0.1395, Training Loss: 0.0212, Initial Validation Loss: 0.1374, Validation Loss: 0.0258,V Acc: 0.8545, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 40  Rolling back to Epoch (base 0): 35  Top Validation Acc: 0.9620253164556962
Fold [2/5] Epoch [0/100] Initial Loss: 0.1389, Training Loss: 0.1389, Initial Validation Loss: 0.1334, Validation Loss: 0.1334,V Acc: 0.2973, Top 70th Acc: 0.3462, Bottom 30th Acc: 0.1818
Fold [2/5] Epoch [10/100] Initial Loss: 0.1389, Training Loss: 0.0147, Initial Validation Loss: 0.1334, Validation Loss: 0.0355,V Acc: 0.8288, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.6061
Fold [2/5] Epoch [20/100] Initial Loss: 0.1389, Training Loss: 0.0045, Initial Validation Loss: 0.1334, Validation Loss: 0.0323,V Acc: 0.8378, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 29  Rolling back to Epoch (base 0): 24  Top Validation Acc: 0.9358974358974359
66 1 [array([0.21483503, 0.08064233, 0.12142286, 0.33996353, 0.24313623],
      dtype=float32)]
Fold [3/5] Epoch [0/100] Initial Loss: 0.1413, Training Loss: 0.1413, Initial Validation Loss: 0.1325, Validation Loss: 0.1325,V Acc: 0.3364, Top 70th Acc: 0.4156, Bottom 30th Acc: 0.1515
Fold [3/5] Epoch [10/100] Initial Loss: 0.1413, Training Loss: 0.0180, Initial Validation Loss: 0.1325, Validation Loss: 0.0384,V Acc: 0.8091, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.4545
Fold [3/5] Epoch [20/100] Initial Loss: 0.1413, Training Loss: 0.0046, Initial Validation Loss: 0.1325, Validation Loss: 0.0338,V Acc: 0.8182, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.5152
Fold [3/5] Epoch [30/100] Initial Loss: 0.1413, Training Loss: 0.0037, Initial Validation Loss: 0.1325, Validation Loss: 0.0336,V Acc: 0.8091, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.4848
Stopping early at Epoch (base 0): 33  Rolling back to Epoch (base 0): 28  Top Validation Acc: 0.948051948051948
Fold [4/5] Epoch [0/100] Initial Loss: 0.1375, Training Loss: 0.1375, Initial Validation Loss: 0.1285, Validation Loss: 0.1285,V Acc: 0.3028, Top 70th Acc: 0.3636, Bottom 30th Acc: 0.1562
Fold [4/5] Epoch [10/100] Initial Loss: 0.1375, Training Loss: 0.0126, Initial Validation Loss: 0.1285, Validation Loss: 0.0340,V Acc: 0.8257, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.5312
Fold [4/5] Epoch [20/100] Initial Loss: 0.1375, Training Loss: 0.0050, Initial Validation Loss: 0.1285, Validation Loss: 0.0282,V Acc: 0.8624, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.5938
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.974025974025974
Fold [5/5] Epoch [0/100] Initial Loss: 0.1411, Training Loss: 0.1411, Initial Validation Loss: 0.1317, Validation Loss: 0.1317,V Acc: 0.3056, Top 70th Acc: 0.3553, Bottom 30th Acc: 0.1875
Fold [5/5] Epoch [10/100] Initial Loss: 0.1411, Training Loss: 0.0244, Initial Validation Loss: 0.1317, Validation Loss: 0.0455,V Acc: 0.7685, Top 70th Acc: 0.8421, Bottom 30th Acc: 0.5938
Fold [5/5] Epoch [20/100] Initial Loss: 0.1411, Training Loss: 0.0043, Initial Validation Loss: 0.1317, Validation Loss: 0.0352,V Acc: 0.8056, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.5000
Stopping early at Epoch (base 0): 27  Rolling back to Epoch (base 0): 22  Top Validation Acc: 0.9342105263157895
Running train_nn.py with seed 67
CUDA:False
Training samples count:  550
Training on 162 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1397, Training Loss: 0.1397, Initial Validation Loss: 0.1383, Validation Loss: 0.1383,V Acc: 0.2768, Top 70th Acc: 0.3291, Bottom 30th Acc: 0.1515
Fold [1/5] Epoch [10/100] Initial Loss: 0.1397, Training Loss: 0.0340, Initial Validation Loss: 0.1383, Validation Loss: 0.0504,V Acc: 0.7946, Top 70th Acc: 0.9367, Bottom 30th Acc: 0.4545
Fold [1/5] Epoch [20/100] Initial Loss: 0.1397, Training Loss: 0.0067, Initial Validation Loss: 0.1383, Validation Loss: 0.0285,V Acc: 0.8482, Top 70th Acc: 0.9747, Bottom 30th Acc: 0.5455
Fold [1/5] Epoch [30/100] Initial Loss: 0.1397, Training Loss: 0.0046, Initial Validation Loss: 0.1383, Validation Loss: 0.0270,V Acc: 0.8393, Top 70th Acc: 0.9747, Bottom 30th Acc: 0.5152
Stopping early at Epoch (base 0): 35  Rolling back to Epoch (base 0): 30  Top Validation Acc: 0.9746835443037974
Fold [2/5] Epoch [0/100] Initial Loss: 0.1368, Training Loss: 0.1368, Initial Validation Loss: 0.1296, Validation Loss: 0.1296,V Acc: 0.3333, Top 70th Acc: 0.3718, Bottom 30th Acc: 0.2424
Fold [2/5] Epoch [10/100] Initial Loss: 0.1368, Training Loss: 0.0209, Initial Validation Loss: 0.1296, Validation Loss: 0.0388,V Acc: 0.8288, Top 70th Acc: 0.8974, Bottom 30th Acc: 0.6667
Fold [2/5] Epoch [20/100] Initial Loss: 0.1368, Training Loss: 0.0051, Initial Validation Loss: 0.1296, Validation Loss: 0.0335,V Acc: 0.8288, Top 70th Acc: 0.8974, Bottom 30th Acc: 0.6667
Fold [2/5] Epoch [30/100] Initial Loss: 0.1368, Training Loss: 0.0040, Initial Validation Loss: 0.1296, Validation Loss: 0.0317,V Acc: 0.8378, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.6364
Fold [2/5] Epoch [40/100] Initial Loss: 0.1368, Training Loss: 0.0038, Initial Validation Loss: 0.1296, Validation Loss: 0.0306,V Acc: 0.8468, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 47  Rolling back to Epoch (base 0): 42  Top Validation Acc: 0.9230769230769231
Fold [3/5] Epoch [0/100] Initial Loss: 0.1380, Training Loss: 0.1380, Initial Validation Loss: 0.1371, Validation Loss: 0.1371,V Acc: 0.2545, Top 70th Acc: 0.3377, Bottom 30th Acc: 0.0606
Fold [3/5] Epoch [10/100] Initial Loss: 0.1380, Training Loss: 0.0227, Initial Validation Loss: 0.1371, Validation Loss: 0.0408,V Acc: 0.8182, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.5152
Fold [3/5] Epoch [20/100] Initial Loss: 0.1380, Training Loss: 0.0076, Initial Validation Loss: 0.1371, Validation Loss: 0.0405,V Acc: 0.8000, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.4545
Stopping early at Epoch (base 0): 21  Rolling back to Epoch (base 0): 16  Top Validation Acc: 0.948051948051948
Fold [4/5] Epoch [0/100] Initial Loss: 0.1404, Training Loss: 0.1404, Initial Validation Loss: 0.1308, Validation Loss: 0.1308,V Acc: 0.2936, Top 70th Acc: 0.3636, Bottom 30th Acc: 0.1250
Fold [4/5] Epoch [10/100] Initial Loss: 0.1404, Training Loss: 0.0172, Initial Validation Loss: 0.1308, Validation Loss: 0.0406,V Acc: 0.7706, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.4375
Stopping early at Epoch (base 0): 17  Rolling back to Epoch (base 0): 12  Top Validation Acc: 0.8961038961038961
67 3 [array([0.12952432, 0.03980273, 0.07053649, 0.2872168 , 0.4729197 ],
      dtype=float32)]
Fold [5/5] Epoch [0/100] Initial Loss: 0.1399, Training Loss: 0.1399, Initial Validation Loss: 0.1308, Validation Loss: 0.1308,V Acc: 0.2500, Top 70th Acc: 0.3158, Bottom 30th Acc: 0.0938
Fold [5/5] Epoch [10/100] Initial Loss: 0.1399, Training Loss: 0.0115, Initial Validation Loss: 0.1308, Validation Loss: 0.0355,V Acc: 0.8241, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.5625
Fold [5/5] Epoch [20/100] Initial Loss: 0.1399, Training Loss: 0.0042, Initial Validation Loss: 0.1308, Validation Loss: 0.0331,V Acc: 0.8333, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.5625
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.9342105263157895
Running train_nn.py with seed 68
CUDA:False
Training samples count:  550
Training on 162 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1392, Training Loss: 0.1392, Initial Validation Loss: 0.1361, Validation Loss: 0.1361,V Acc: 0.3036, Top 70th Acc: 0.3671, Bottom 30th Acc: 0.1515
Fold [1/5] Epoch [10/100] Initial Loss: 0.1392, Training Loss: 0.0183, Initial Validation Loss: 0.1361, Validation Loss: 0.0337,V Acc: 0.8750, Top 70th Acc: 0.9241, Bottom 30th Acc: 0.7576
Fold [1/5] Epoch [20/100] Initial Loss: 0.1392, Training Loss: 0.0049, Initial Validation Loss: 0.1361, Validation Loss: 0.0287,V Acc: 0.8750, Top 70th Acc: 0.9494, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 21  Rolling back to Epoch (base 0): 16  Top Validation Acc: 0.9620253164556962
68 0 [array([0.1028391 , 0.10795774, 0.09036483, 0.2764089 , 0.42242938],
      dtype=float32)]
Fold [2/5] Epoch [0/100] Initial Loss: 0.1384, Training Loss: 0.1384, Initial Validation Loss: 0.1371, Validation Loss: 0.1371,V Acc: 0.2613, Top 70th Acc: 0.3077, Bottom 30th Acc: 0.1515
Fold [2/5] Epoch [10/100] Initial Loss: 0.1384, Training Loss: 0.0180, Initial Validation Loss: 0.1371, Validation Loss: 0.0413,V Acc: 0.8108, Top 70th Acc: 0.8974, Bottom 30th Acc: 0.6061
Fold [1/5] Epoch [20/100] Initial Loss: 0.1389, Training Loss: 0.0263, Initial Validation Loss: 0.1375, Validation Loss: 0.0441,V Acc: 0.8125, Top 70th Acc: 0.9114, Bottom 30th Acc: 0.5758
Fold [1/5] Epoch [30/100] Initial Loss: 0.1389, Training Loss: 0.0213, Initial Validation Loss: 0.1375, Validation Loss: 0.0392,V Acc: 0.8214, Top 70th Acc: 0.9367, Bottom 30th Acc: 0.5455
Fold [1/5] Epoch [40/100] Initial Loss: 0.1389, Training Loss: 0.0192, Initial Validation Loss: 0.1375, Validation Loss: 0.0393,V Acc: 0.8125, Top 70th Acc: 0.9114, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 43  Rolling back to Epoch (base 0): 38  Top Validation Acc: 0.9240506329113924
Fold [2/5] Epoch [0/100] Initial Loss: 0.1402, Training Loss: 0.1402, Initial Validation Loss: 0.1357, Validation Loss: 0.1357,V Acc: 0.2703, Top 70th Acc: 0.2821, Bottom 30th Acc: 0.2424
Fold [2/5] Epoch [10/100] Initial Loss: 0.1402, Training Loss: 0.0301, Initial Validation Loss: 0.1357, Validation Loss: 0.0332,V Acc: 0.8649, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.6667
Fold [2/5] Epoch [20/100] Initial Loss: 0.1402, Training Loss: 0.0214, Initial Validation Loss: 0.1357, Validation Loss: 0.0287,V Acc: 0.8739, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.6970
Fold [2/5] Epoch [30/100] Initial Loss: 0.1402, Training Loss: 0.0198, Initial Validation Loss: 0.1357, Validation Loss: 0.0284,V Acc: 0.8829, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.7273
Stopping early at Epoch (base 0): 36  Rolling back to Epoch (base 0): 31  Top Validation Acc: 0.9358974358974359
87 1 [array([0.23394713, 0.03847544, 0.13493156, 0.3888358 , 0.20381014],
      dtype=float32)]
Fold [3/5] Epoch [0/100] Initial Loss: 0.1383, Training Loss: 0.1383, Initial Validation Loss: 0.1303, Validation Loss: 0.1303,V Acc: 0.3545, Top 70th Acc: 0.4416, Bottom 30th Acc: 0.1515
Fold [3/5] Epoch [10/100] Initial Loss: 0.1383, Training Loss: 0.0330, Initial Validation Loss: 0.1303, Validation Loss: 0.0350,V Acc: 0.8727, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.7273
Fold [3/5] Epoch [20/100] Initial Loss: 0.1383, Training Loss: 0.0235, Initial Validation Loss: 0.1303, Validation Loss: 0.0317,V Acc: 0.8273, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.922077922077922
Fold [4/5] Epoch [0/100] Initial Loss: 0.1426, Training Loss: 0.1426, Initial Validation Loss: 0.1349, Validation Loss: 0.1349,V Acc: 0.2477, Top 70th Acc: 0.2987, Bottom 30th Acc: 0.1250
Fold [4/5] Epoch [10/100] Initial Loss: 0.1426, Training Loss: 0.0418, Initial Validation Loss: 0.1349, Validation Loss: 0.0322,V Acc: 0.8716, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.6250
Fold [4/5] Epoch [20/100] Initial Loss: 0.1426, Training Loss: 0.0247, Initial Validation Loss: 0.1349, Validation Loss: 0.0251,V Acc: 0.8899, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.6875
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.974025974025974
Fold [5/5] Epoch [0/100] Initial Loss: 0.1411, Training Loss: 0.1411, Initial Validation Loss: 0.1297, Validation Loss: 0.1297,V Acc: 0.2963, Top 70th Acc: 0.3816, Bottom 30th Acc: 0.0938
Fold [5/5] Epoch [10/100] Initial Loss: 0.1411, Training Loss: 0.0342, Initial Validation Loss: 0.1297, Validation Loss: 0.0401,V Acc: 0.8148, Top 70th Acc: 0.8816, Bottom 30th Acc: 0.6562
Fold [5/5] Epoch [20/100] Initial Loss: 0.1411, Training Loss: 0.0203, Initial Validation Loss: 0.1297, Validation Loss: 0.0364,V Acc: 0.8148, Top 70th Acc: 0.8816, Bottom 30th Acc: 0.6562
Stopping early at Epoch (base 0): 22  Rolling back to Epoch (base 0): 17  Top Validation Acc: 0.9078947368421053
Running train_nn.py with seed 88
CUDA:False
Training samples count:  550
Training on 20 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1362, Training Loss: 0.1362, Initial Validation Loss: 0.1349, Validation Loss: 0.1349,V Acc: 0.3125, Top 70th Acc: 0.3797, Bottom 30th Acc: 0.1515
Fold [1/5] Epoch [10/100] Initial Loss: 0.1362, Training Loss: 0.0364, Initial Validation Loss: 0.1349, Validation Loss: 0.0428,V Acc: 0.8304, Top 70th Acc: 0.9114, Bottom 30th Acc: 0.6364
Fold [1/5] Epoch [20/100] Initial Loss: 0.1362, Training Loss: 0.0251, Initial Validation Loss: 0.1349, Validation Loss: 0.0328,V Acc: 0.8482, Top 70th Acc: 0.9494, Bottom 30th Acc: 0.6061
Fold [1/5] Epoch [30/100] Initial Loss: 0.1362, Training Loss: 0.0213, Initial Validation Loss: 0.1349, Validation Loss: 0.0305,V Acc: 0.8661, Top 70th Acc: 0.9241, Bottom 30th Acc: 0.7273
Stopping early at Epoch (base 0): 34  Rolling back to Epoch (base 0): 29  Top Validation Acc: 0.9367088607594937
Fold [2/5] Epoch [0/100] Initial Loss: 0.1362, Training Loss: 0.1362, Initial Validation Loss: 0.1316, Validation Loss: 0.1316,V Acc: 0.4144, Top 70th Acc: 0.5000, Bottom 30th Acc: 0.2121
Fold [2/5] Epoch [10/100] Initial Loss: 0.1362, Training Loss: 0.0309, Initial Validation Loss: 0.1316, Validation Loss: 0.0283,V Acc: 0.8559, Top 70th Acc: 0.9872, Bottom 30th Acc: 0.5455
Fold [2/5] Epoch [20/100] Initial Loss: 0.1362, Training Loss: 0.0242, Initial Validation Loss: 0.1316, Validation Loss: 0.0244,V Acc: 0.8919, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 22  Rolling back to Epoch (base 0): 17  Top Validation Acc: 0.9743589743589743
Fold [3/5] Epoch [0/100] Initial Loss: 0.1417, Training Loss: 0.1417, Initial Validation Loss: 0.1350, Validation Loss: 0.1350,V Acc: 0.2545, Top 70th Acc: 0.2468, Bottom 30th Acc: 0.2727
Fold [3/5] Epoch [10/100] Initial Loss: 0.1417, Training Loss: 0.0339, Initial Validation Loss: 0.1350, Validation Loss: 0.0463,V Acc: 0.8182, Top 70th Acc: 0.8831, Bottom 30th Acc: 0.6667
Fold [3/5] Epoch [20/100] Initial Loss: 0.1417, Training Loss: 0.0221, Initial Validation Loss: 0.1350, Validation Loss: 0.0379,V Acc: 0.8455, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.9090909090909091
88 2 [array([0.34716707, 0.07813226, 0.17600608, 0.19241884, 0.20627576],
      dtype=float32)]
Fold [4/5] Epoch [0/100] Initial Loss: 0.1355, Training Loss: 0.1355, Initial Validation Loss: 0.1202, Validation Loss: 0.1202,V Acc: 0.3486, Top 70th Acc: 0.3896, Bottom 30th Acc: 0.2500
Fold [4/5] Epoch [10/100] Initial Loss: 0.1355, Training Loss: 0.0320, Initial Validation Loss: 0.1202, Validation Loss: 0.0377,V Acc: 0.7890, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.5000
Fold [4/5] Epoch [20/100] Initial Loss: 0.1355, Training Loss: 0.0228, Initial Validation Loss: 0.1202, Validation Loss: 0.0338,V Acc: 0.8073, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.5000
Fold [4/5] Epoch [30/100] Initial Loss: 0.1355, Training Loss: 0.0204, Initial Validation Loss: 0.1202, Validation Loss: 0.0339,V Acc: 0.7982, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.5000
Stopping early at Epoch (base 0): 30  Rolling back to Epoch (base 0): 25  Top Validation Acc: 0.922077922077922
Fold [5/5] Epoch [0/100] Initial Loss: 0.1394, Training Loss: 0.1394, Initial Validation Loss: 0.1371, Validation Loss: 0.1371,V Acc: 0.2870, Top 70th Acc: 0.3684, Bottom 30th Acc: 0.0938
Fold [5/5] Epoch [10/100] Initial Loss: 0.1394, Training Loss: 0.0370, Initial Validation Loss: 0.1371, Validation Loss: 0.0362,V Acc: 0.8426, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.5938
Fold [5/5] Epoch [20/100] Initial Loss: 0.1394, Training Loss: 0.0237, Initial Validation Loss: 0.1371, Validation Loss: 0.0278,V Acc: 0.8426, Top 70th Acc: 0.9737, Bottom 30th Acc: 0.5312
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.9605263157894737
Running train_nn.py with seed 89
CUDA:False
Training samples count:  550
Training on 20 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1383, Training Loss: 0.1383, Initial Validation Loss: 0.1341, Validation Loss: 0.1341,V Acc: 0.2768, Top 70th Acc: 0.3291, Bottom 30th Acc: 0.1515
Fold [1/5] Epoch [10/100] Initial Loss: 0.1383, Training Loss: 0.0374, Initial Validation Loss: 0.1341, Validation Loss: 0.0366,V Acc: 0.8304, Top 70th Acc: 0.9494, Bottom 30th Acc: 0.5455
Fold [1/5] Epoch [20/100] Initial Loss: 0.1383, Training Loss: 0.0249, Initial Validation Loss: 0.1341, Validation Loss: 0.0322,V Acc: 0.8750, Top 70th Acc: 0.9241, Bottom 30th Acc: 0.7576
Fold [4/5] Epoch [10/100] Initial Loss: 0.1378, Training Loss: 0.0822, Initial Validation Loss: 0.1179, Validation Loss: 0.0743,V Acc: 0.6330, Top 70th Acc: 0.7532, Bottom 30th Acc: 0.3438
Fold [4/5] Epoch [20/100] Initial Loss: 0.1378, Training Loss: 0.0802, Initial Validation Loss: 0.1179, Validation Loss: 0.0740,V Acc: 0.6147, Top 70th Acc: 0.7792, Bottom 30th Acc: 0.2188
Fold [4/5] Epoch [30/100] Initial Loss: 0.1378, Training Loss: 0.0795, Initial Validation Loss: 0.1179, Validation Loss: 0.0726,V Acc: 0.6147, Top 70th Acc: 0.7532, Bottom 30th Acc: 0.2812
Fold [4/5] Epoch [40/100] Initial Loss: 0.1378, Training Loss: 0.0792, Initial Validation Loss: 0.1179, Validation Loss: 0.0729,V Acc: 0.6697, Top 70th Acc: 0.7662, Bottom 30th Acc: 0.4375
Stopping early at Epoch (base 0): 43  Rolling back to Epoch (base 0): 38  Top Validation Acc: 0.7272727272727273
Fold [5/5] Epoch [0/100] Initial Loss: 0.1341, Training Loss: 0.1341, Initial Validation Loss: 0.1272, Validation Loss: 0.1272,V Acc: 0.4074, Top 70th Acc: 0.5000, Bottom 30th Acc: 0.1875
Fold [5/5] Epoch [10/100] Initial Loss: 0.1341, Training Loss: 0.0786, Initial Validation Loss: 0.1272, Validation Loss: 0.0852,V Acc: 0.6111, Top 70th Acc: 0.7237, Bottom 30th Acc: 0.3438
Fold [5/5] Epoch [20/100] Initial Loss: 0.1341, Training Loss: 0.0770, Initial Validation Loss: 0.1272, Validation Loss: 0.0847,V Acc: 0.6111, Top 70th Acc: 0.7105, Bottom 30th Acc: 0.3750
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.7368421052631579
Running train_nn.py with seed 89
CUDA:False
Training samples count:  550
Training on 2 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1382, Training Loss: 0.1382, Initial Validation Loss: 0.1335, Validation Loss: 0.1335,V Acc: 0.3929, Top 70th Acc: 0.5316, Bottom 30th Acc: 0.0606
Fold [1/5] Epoch [10/100] Initial Loss: 0.1382, Training Loss: 0.0813, Initial Validation Loss: 0.1335, Validation Loss: 0.0792,V Acc: 0.6518, Top 70th Acc: 0.7468, Bottom 30th Acc: 0.4242
Stopping early at Epoch (base 0): 19  Rolling back to Epoch (base 0): 14  Top Validation Acc: 0.7341772151898734
Fold [2/5] Epoch [0/100] Initial Loss: 0.1428, Training Loss: 0.1428, Initial Validation Loss: 0.1308, Validation Loss: 0.1308,V Acc: 0.2793, Top 70th Acc: 0.2949, Bottom 30th Acc: 0.2424
Fold [2/5] Epoch [10/100] Initial Loss: 0.1428, Training Loss: 0.0812, Initial Validation Loss: 0.1308, Validation Loss: 0.0789,V Acc: 0.6126, Top 70th Acc: 0.7308, Bottom 30th Acc: 0.3333
Fold [2/5] Epoch [20/100] Initial Loss: 0.1428, Training Loss: 0.0799, Initial Validation Loss: 0.1308, Validation Loss: 0.0771,V Acc: 0.6216, Top 70th Acc: 0.7308, Bottom 30th Acc: 0.3636
Fold [2/5] Epoch [30/100] Initial Loss: 0.1428, Training Loss: 0.0795, Initial Validation Loss: 0.1308, Validation Loss: 0.0763,V Acc: 0.6306, Top 70th Acc: 0.7436, Bottom 30th Acc: 0.3636
Stopping early at Epoch (base 0): 31  Rolling back to Epoch (base 0): 26  Top Validation Acc: 0.7435897435897436
Fold [3/5] Epoch [0/100] Initial Loss: 0.1350, Training Loss: 0.1350, Initial Validation Loss: 0.1293, Validation Loss: 0.1293,V Acc: 0.5545, Top 70th Acc: 0.6364, Bottom 30th Acc: 0.3636
Fold [3/5] Epoch [10/100] Initial Loss: 0.1350, Training Loss: 0.0810, Initial Validation Loss: 0.1293, Validation Loss: 0.0780,V Acc: 0.6818, Top 70th Acc: 0.7143, Bottom 30th Acc: 0.6061
Fold [3/5] Epoch [20/100] Initial Loss: 0.1350, Training Loss: 0.0792, Initial Validation Loss: 0.1293, Validation Loss: 0.0769,V Acc: 0.6818, Top 70th Acc: 0.7273, Bottom 30th Acc: 0.5758
Fold [3/5] Epoch [30/100] Initial Loss: 0.1350, Training Loss: 0.0784, Initial Validation Loss: 0.1293, Validation Loss: 0.0757,V Acc: 0.7000, Top 70th Acc: 0.7273, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 32  Rolling back to Epoch (base 0): 27  Top Validation Acc: 0.7272727272727273
Fold [4/5] Epoch [0/100] Initial Loss: 0.1399, Training Loss: 0.1399, Initial Validation Loss: 0.1309, Validation Loss: 0.1309,V Acc: 0.2569, Top 70th Acc: 0.3506, Bottom 30th Acc: 0.0312
Fold [4/5] Epoch [10/100] Initial Loss: 0.1399, Training Loss: 0.0793, Initial Validation Loss: 0.1309, Validation Loss: 0.0861,V Acc: 0.5688, Top 70th Acc: 0.7143, Bottom 30th Acc: 0.2188
Fold [4/5] Epoch [20/100] Initial Loss: 0.1399, Training Loss: 0.0768, Initial Validation Loss: 0.1309, Validation Loss: 0.0855,V Acc: 0.5780, Top 70th Acc: 0.7403, Bottom 30th Acc: 0.1875
Stopping early at Epoch (base 0): 28  Rolling back to Epoch (base 0): 23  Top Validation Acc: 0.7272727272727273
89 3 [array([0.11050066, 0.38968894, 0.13273916, 0.20982218, 0.15724897],
      dtype=float32)]
Fold [5/5] Epoch [0/100] Initial Loss: 0.1347, Training Loss: 0.1347, Initial Validation Loss: 0.1210, Validation Loss: 0.1210,V Acc: 0.5556, Top 70th Acc: 0.6184, Bottom 30th Acc: 0.4062
Fold [5/5] Epoch [10/100] Initial Loss: 0.1347, Training Loss: 0.0812, Initial Validation Loss: 0.1210, Validation Loss: 0.0773,V Acc: 0.6204, Top 70th Acc: 0.7632, Bottom 30th Acc: 0.2812
Fold [5/5] Epoch [20/100] Initial Loss: 0.1347, Training Loss: 0.0795, Initial Validation Loss: 0.1210, Validation Loss: 0.0757,V Acc: 0.6296, Top 70th Acc: 0.7632, Bottom 30th Acc: 0.3125
Stopping early at Epoch (base 0): 27  Rolling back to Epoch (base 0): 22  Top Validation Acc: 0.7631578947368421
Running train_nn.py with seed 90
CUDA:False
Training samples count:  550
Training on 2 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1397, Training Loss: 0.1397, Initial Validation Loss: 0.1297, Validation Loss: 0.1297,V Acc: 0.4554, Top 70th Acc: 0.5063, Bottom 30th Acc: 0.3333
Fold [1/5] Epoch [10/100] Initial Loss: 0.1397, Training Loss: 0.0802, Initial Validation Loss: 0.1297, Validation Loss: 0.0815,V Acc: 0.6071, Top 70th Acc: 0.7215, Bottom 30th Acc: 0.3333
Fold [1/5] Epoch [20/100] Initial Loss: 0.1397, Training Loss: 0.0781, Initial Validation Loss: 0.1297, Validation Loss: 0.0800,V Acc: 0.6250, Top 70th Acc: 0.7089, Bottom 30th Acc: 0.4242
Fold [1/5] Epoch [30/100] Initial Loss: 0.1397, Training Loss: 0.0771, Initial Validation Loss: 0.1297, Validation Loss: 0.0798,V Acc: 0.6250, Top 70th Acc: 0.7089, Bottom 30th Acc: 0.4242
Fold [1/5] Epoch [40/100] Initial Loss: 0.1397, Training Loss: 0.0770, Initial Validation Loss: 0.1297, Validation Loss: 0.0788,V Acc: 0.6250, Top 70th Acc: 0.7342, Bottom 30th Acc: 0.3636
Stopping early at Epoch (base 0): 44  Rolling back to Epoch (base 0): 39  Top Validation Acc: 0.7215189873417721
Fold [2/5] Epoch [0/100] Initial Loss: 0.1380, Training Loss: 0.1380, Initial Validation Loss: 0.1285, Validation Loss: 0.1285,V Acc: 0.4054, Top 70th Acc: 0.4359, Bottom 30th Acc: 0.3333
Fold [2/5] Epoch [10/100] Initial Loss: 0.1380, Training Loss: 0.0783, Initial Validation Loss: 0.1285, Validation Loss: 0.0863,V Acc: 0.5946, Top 70th Acc: 0.6282, Bottom 30th Acc: 0.5152
Stopping early at Epoch (base 0): 19  Rolling back to Epoch (base 0): 14  Top Validation Acc: 0.6282051282051282
90 1 [array([0.11884666, 0.38281903, 0.16046838, 0.1954203 , 0.14244568],
      dtype=float32)]
Fold [3/5] Epoch [0/100] Initial Loss: 0.1383, Training Loss: 0.1383, Initial Validation Loss: 0.1289, Validation Loss: 0.1289,V Acc: 0.2727, Top 70th Acc: 0.3506, Bottom 30th Acc: 0.0909
Fold [3/5] Epoch [10/100] Initial Loss: 0.1383, Training Loss: 0.0822, Initial Validation Loss: 0.1289, Validation Loss: 0.0765,V Acc: 0.6273, Top 70th Acc: 0.7532, Bottom 30th Acc: 0.3333
Fold [3/5] Epoch [20/100] Initial Loss: 0.1383, Training Loss: 0.0802, Initial Validation Loss: 0.1289, Validation Loss: 0.0749,V Acc: 0.6455, Top 70th Acc: 0.7662, Bottom 30th Acc: 0.3636
Stopping early at Epoch (base 0): 21  Rolling back to Epoch (base 0): 16  Top Validation Acc: 0.7662337662337663
Fold [4/5] Epoch [0/100] Initial Loss: 0.1368, Training Loss: 0.1368, Initial Validation Loss: 0.1302, Validation Loss: 0.1302,V Acc: 0.3486, Top 70th Acc: 0.4026, Bottom 30th Acc: 0.2188
Fold [4/5] Epoch [10/100] Initial Loss: 0.1368, Training Loss: 0.0819, Initial Validation Loss: 0.1302, Validation Loss: 0.0768,V Acc: 0.6697, Top 70th Acc: 0.8182, Bottom 30th Acc: 0.3125
Fold [4/5] Epoch [20/100] Initial Loss: 0.1368, Training Loss: 0.0804, Initial Validation Loss: 0.1302, Validation Loss: 0.0741,V Acc: 0.6606, Top 70th Acc: 0.8052, Bottom 30th Acc: 0.3125
Fold [2/5] Epoch [10/100] Initial Loss: 0.1392, Training Loss: 0.0339, Initial Validation Loss: 0.1314, Validation Loss: 0.0500,V Acc: 0.7748, Top 70th Acc: 0.8590, Bottom 30th Acc: 0.5758
Fold [2/5] Epoch [20/100] Initial Loss: 0.1392, Training Loss: 0.0187, Initial Validation Loss: 0.1314, Validation Loss: 0.0441,V Acc: 0.8018, Top 70th Acc: 0.8718, Bottom 30th Acc: 0.6364
Fold [2/5] Epoch [30/100] Initial Loss: 0.1392, Training Loss: 0.0143, Initial Validation Loss: 0.1314, Validation Loss: 0.0428,V Acc: 0.7838, Top 70th Acc: 0.8974, Bottom 30th Acc: 0.5152
Fold [2/5] Epoch [40/100] Initial Loss: 0.1392, Training Loss: 0.0119, Initial Validation Loss: 0.1314, Validation Loss: 0.0418,V Acc: 0.8198, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.6061
Fold [2/5] Epoch [50/100] Initial Loss: 0.1392, Training Loss: 0.0107, Initial Validation Loss: 0.1314, Validation Loss: 0.0412,V Acc: 0.8018, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 50  Rolling back to Epoch (base 0): 45  Top Validation Acc: 0.9102564102564102
90 1 [array([0.38090256, 0.1867904 , 0.01531132, 0.02122597, 0.39576972],
      dtype=float32)]
Fold [3/5] Epoch [0/100] Initial Loss: 0.1423, Training Loss: 0.1423, Initial Validation Loss: 0.1323, Validation Loss: 0.1323,V Acc: 0.2909, Top 70th Acc: 0.3247, Bottom 30th Acc: 0.2121
Fold [3/5] Epoch [10/100] Initial Loss: 0.1423, Training Loss: 0.0267, Initial Validation Loss: 0.1323, Validation Loss: 0.0292,V Acc: 0.8727, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.6667
Fold [3/5] Epoch [20/100] Initial Loss: 0.1423, Training Loss: 0.0160, Initial Validation Loss: 0.1323, Validation Loss: 0.0225,V Acc: 0.8727, Top 70th Acc: 0.9870, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 27  Rolling back to Epoch (base 0): 22  Top Validation Acc: 0.974025974025974
Fold [4/5] Epoch [0/100] Initial Loss: 0.1390, Training Loss: 0.1390, Initial Validation Loss: 0.1373, Validation Loss: 0.1373,V Acc: 0.2385, Top 70th Acc: 0.2597, Bottom 30th Acc: 0.1875
Fold [4/5] Epoch [10/100] Initial Loss: 0.1390, Training Loss: 0.0360, Initial Validation Loss: 0.1373, Validation Loss: 0.0373,V Acc: 0.8257, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.5000
Fold [4/5] Epoch [20/100] Initial Loss: 0.1390, Training Loss: 0.0149, Initial Validation Loss: 0.1373, Validation Loss: 0.0241,V Acc: 0.8991, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.7188
Fold [4/5] Epoch [30/100] Initial Loss: 0.1390, Training Loss: 0.0122, Initial Validation Loss: 0.1373, Validation Loss: 0.0245,V Acc: 0.8716, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.6250
Stopping early at Epoch (base 0): 30  Rolling back to Epoch (base 0): 25  Top Validation Acc: 0.974025974025974
Fold [5/5] Epoch [0/100] Initial Loss: 0.1370, Training Loss: 0.1370, Initial Validation Loss: 0.1322, Validation Loss: 0.1322,V Acc: 0.3241, Top 70th Acc: 0.3684, Bottom 30th Acc: 0.2188
Fold [5/5] Epoch [10/100] Initial Loss: 0.1370, Training Loss: 0.0359, Initial Validation Loss: 0.1322, Validation Loss: 0.0422,V Acc: 0.8611, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.6875
Fold [5/5] Epoch [20/100] Initial Loss: 0.1370, Training Loss: 0.0200, Initial Validation Loss: 0.1322, Validation Loss: 0.0295,V Acc: 0.8796, Top 70th Acc: 0.9868, Bottom 30th Acc: 0.6250
Fold [5/5] Epoch [30/100] Initial Loss: 0.1370, Training Loss: 0.0146, Initial Validation Loss: 0.1322, Validation Loss: 0.0258,V Acc: 0.8796, Top 70th Acc: 0.9868, Bottom 30th Acc: 0.6250
Stopping early at Epoch (base 0): 33  Rolling back to Epoch (base 0): 28  Top Validation Acc: 0.9868421052631579
Running train_nn.py with seed 91
CUDA:False
Training samples count:  550
Training on 39 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1377, Training Loss: 0.1377, Initial Validation Loss: 0.1291, Validation Loss: 0.1291,V Acc: 0.3571, Top 70th Acc: 0.4051, Bottom 30th Acc: 0.2424
Fold [1/5] Epoch [10/100] Initial Loss: 0.1377, Training Loss: 0.0279, Initial Validation Loss: 0.1291, Validation Loss: 0.0347,V Acc: 0.8304, Top 70th Acc: 0.9367, Bottom 30th Acc: 0.5758
Fold [1/5] Epoch [20/100] Initial Loss: 0.1377, Training Loss: 0.0139, Initial Validation Loss: 0.1291, Validation Loss: 0.0313,V Acc: 0.8482, Top 70th Acc: 0.9367, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.9240506329113924
91 0 [array([0.40299335, 0.04199905, 0.05902199, 0.21671753, 0.27926812],
      dtype=float32)]
Fold [2/5] Epoch [0/100] Initial Loss: 0.1395, Training Loss: 0.1395, Initial Validation Loss: 0.1272, Validation Loss: 0.1272,V Acc: 0.2793, Top 70th Acc: 0.3333, Bottom 30th Acc: 0.1515
Fold [2/5] Epoch [10/100] Initial Loss: 0.1395, Training Loss: 0.0338, Initial Validation Loss: 0.1272, Validation Loss: 0.0487,V Acc: 0.7477, Top 70th Acc: 0.8205, Bottom 30th Acc: 0.5758
Fold [2/5] Epoch [20/100] Initial Loss: 0.1395, Training Loss: 0.0172, Initial Validation Loss: 0.1272, Validation Loss: 0.0385,V Acc: 0.7748, Top 70th Acc: 0.8718, Bottom 30th Acc: 0.5455
Fold [2/5] Epoch [30/100] Initial Loss: 0.1395, Training Loss: 0.0122, Initial Validation Loss: 0.1272, Validation Loss: 0.0328,V Acc: 0.8198, Top 70th Acc: 0.8974, Bottom 30th Acc: 0.6364
Fold [2/5] Epoch [40/100] Initial Loss: 0.1395, Training Loss: 0.0103, Initial Validation Loss: 0.1272, Validation Loss: 0.0318,V Acc: 0.8378, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 45  Rolling back to Epoch (base 0): 40  Top Validation Acc: 0.8974358974358975
Fold [3/5] Epoch [0/100] Initial Loss: 0.1372, Training Loss: 0.1372, Initial Validation Loss: 0.1355, Validation Loss: 0.1355,V Acc: 0.3000, Top 70th Acc: 0.3377, Bottom 30th Acc: 0.2121
Fold [3/5] Epoch [10/100] Initial Loss: 0.1372, Training Loss: 0.0289, Initial Validation Loss: 0.1355, Validation Loss: 0.0344,V Acc: 0.8545, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.6061
Fold [3/5] Epoch [20/100] Initial Loss: 0.1372, Training Loss: 0.0158, Initial Validation Loss: 0.1355, Validation Loss: 0.0274,V Acc: 0.8364, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.5152
Fold [3/5] Epoch [30/100] Initial Loss: 0.1372, Training Loss: 0.0127, Initial Validation Loss: 0.1355, Validation Loss: 0.0253,V Acc: 0.8636, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 38  Rolling back to Epoch (base 0): 33  Top Validation Acc: 0.974025974025974
Fold [4/5] Epoch [0/100] Initial Loss: 0.1390, Training Loss: 0.1390, Initial Validation Loss: 0.1339, Validation Loss: 0.1339,V Acc: 0.3578, Top 70th Acc: 0.4416, Bottom 30th Acc: 0.1562
Fold [4/5] Epoch [10/100] Initial Loss: 0.1390, Training Loss: 0.0417, Initial Validation Loss: 0.1339, Validation Loss: 0.0440,V Acc: 0.7982, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.4688
Fold [4/5] Epoch [20/100] Initial Loss: 0.1390, Training Loss: 0.0161, Initial Validation Loss: 0.1339, Validation Loss: 0.0308,V Acc: 0.8440, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.5625
Stopping early at Epoch (base 0): 28  Rolling back to Epoch (base 0): 23  Top Validation Acc: 0.961038961038961
Fold [5/5] Epoch [0/100] Initial Loss: 0.1379, Training Loss: 0.1379, Initial Validation Loss: 0.1307, Validation Loss: 0.1307,V Acc: 0.2963, Top 70th Acc: 0.3421, Bottom 30th Acc: 0.1875
Fold [5/5] Epoch [10/100] Initial Loss: 0.1379, Training Loss: 0.0227, Initial Validation Loss: 0.1307, Validation Loss: 0.0280,V Acc: 0.8796, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.6875
Fold [5/5] Epoch [20/100] Initial Loss: 0.1379, Training Loss: 0.0144, Initial Validation Loss: 0.1307, Validation Loss: 0.0260,V Acc: 0.8611, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.6250
Stopping early at Epoch (base 0): 29  Rolling back to Epoch (base 0): 24  Top Validation Acc: 0.9473684210526315
Running train_nn.py with seed 92
CUDA:False
Training samples count:  550
Training on 40 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1387, Training Loss: 0.1387, Initial Validation Loss: 0.1373, Validation Loss: 0.1373,V Acc: 0.2500, Top 70th Acc: 0.3418, Bottom 30th Acc: 0.0303
Fold [1/5] Epoch [10/100] Initial Loss: 0.1387, Training Loss: 0.0271, Initial Validation Loss: 0.1373, Validation Loss: 0.0351,V Acc: 0.8661, Top 70th Acc: 0.9620, Bottom 30th Acc: 0.6364
Fold [3/5] Epoch [30/100] Initial Loss: 0.1395, Training Loss: 0.0184, Initial Validation Loss: 0.1374, Validation Loss: 0.0245,V Acc: 0.8727, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 39  Rolling back to Epoch (base 0): 34  Top Validation Acc: 0.987012987012987
Fold [4/5] Epoch [0/100] Initial Loss: 0.1426, Training Loss: 0.1426, Initial Validation Loss: 0.1332, Validation Loss: 0.1332,V Acc: 0.2294, Top 70th Acc: 0.2338, Bottom 30th Acc: 0.2188
Fold [4/5] Epoch [10/100] Initial Loss: 0.1426, Training Loss: 0.0377, Initial Validation Loss: 0.1332, Validation Loss: 0.0486,V Acc: 0.7706, Top 70th Acc: 0.8831, Bottom 30th Acc: 0.5000
Fold [4/5] Epoch [20/100] Initial Loss: 0.1426, Training Loss: 0.0163, Initial Validation Loss: 0.1332, Validation Loss: 0.0382,V Acc: 0.7982, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.5000
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.922077922077922
Fold [5/5] Epoch [0/100] Initial Loss: 0.1409, Training Loss: 0.1409, Initial Validation Loss: 0.1310, Validation Loss: 0.1310,V Acc: 0.2685, Top 70th Acc: 0.2500, Bottom 30th Acc: 0.3125
Fold [5/5] Epoch [10/100] Initial Loss: 0.1409, Training Loss: 0.0381, Initial Validation Loss: 0.1310, Validation Loss: 0.0479,V Acc: 0.7685, Top 70th Acc: 0.8158, Bottom 30th Acc: 0.6562
Fold [5/5] Epoch [20/100] Initial Loss: 0.1409, Training Loss: 0.0197, Initial Validation Loss: 0.1310, Validation Loss: 0.0383,V Acc: 0.7778, Top 70th Acc: 0.8816, Bottom 30th Acc: 0.5312
Fold [5/5] Epoch [30/100] Initial Loss: 0.1409, Training Loss: 0.0157, Initial Validation Loss: 0.1310, Validation Loss: 0.0362,V Acc: 0.8056, Top 70th Acc: 0.9079, Bottom 30th Acc: 0.5625
Stopping early at Epoch (base 0): 30  Rolling back to Epoch (base 0): 25  Top Validation Acc: 0.9078947368421053
Running train_nn.py with seed 87
CUDA:False
Training samples count:  550
Training on 30 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1430, Training Loss: 0.1430, Initial Validation Loss: 0.1383, Validation Loss: 0.1383,V Acc: 0.2679, Top 70th Acc: 0.2405, Bottom 30th Acc: 0.3333
Fold [1/5] Epoch [10/100] Initial Loss: 0.1430, Training Loss: 0.0291, Initial Validation Loss: 0.1383, Validation Loss: 0.0377,V Acc: 0.8214, Top 70th Acc: 0.9494, Bottom 30th Acc: 0.5152
Fold [1/5] Epoch [20/100] Initial Loss: 0.1430, Training Loss: 0.0184, Initial Validation Loss: 0.1383, Validation Loss: 0.0311,V Acc: 0.8482, Top 70th Acc: 0.9494, Bottom 30th Acc: 0.6061
Fold [1/5] Epoch [30/100] Initial Loss: 0.1430, Training Loss: 0.0159, Initial Validation Loss: 0.1383, Validation Loss: 0.0311,V Acc: 0.8393, Top 70th Acc: 0.9620, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 33  Rolling back to Epoch (base 0): 28  Top Validation Acc: 0.9620253164556962
Fold [2/5] Epoch [0/100] Initial Loss: 0.1375, Training Loss: 0.1375, Initial Validation Loss: 0.1332, Validation Loss: 0.1332,V Acc: 0.2883, Top 70th Acc: 0.3590, Bottom 30th Acc: 0.1212
Fold [2/5] Epoch [10/100] Initial Loss: 0.1375, Training Loss: 0.0373, Initial Validation Loss: 0.1332, Validation Loss: 0.0468,V Acc: 0.7838, Top 70th Acc: 0.8846, Bottom 30th Acc: 0.5455
Fold [2/5] Epoch [20/100] Initial Loss: 0.1375, Training Loss: 0.0190, Initial Validation Loss: 0.1332, Validation Loss: 0.0358,V Acc: 0.8108, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.9230769230769231
87 1 [array([0.38734943, 0.09973031, 0.08359126, 0.12256213, 0.30676687],
      dtype=float32)]
Fold [3/5] Epoch [0/100] Initial Loss: 0.1400, Training Loss: 0.1400, Initial Validation Loss: 0.1332, Validation Loss: 0.1332,V Acc: 0.2000, Top 70th Acc: 0.2468, Bottom 30th Acc: 0.0909
Fold [3/5] Epoch [10/100] Initial Loss: 0.1400, Training Loss: 0.0315, Initial Validation Loss: 0.1332, Validation Loss: 0.0396,V Acc: 0.8091, Top 70th Acc: 0.8831, Bottom 30th Acc: 0.6364
Fold [3/5] Epoch [20/100] Initial Loss: 0.1400, Training Loss: 0.0201, Initial Validation Loss: 0.1332, Validation Loss: 0.0330,V Acc: 0.8182, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.922077922077922
Fold [4/5] Epoch [0/100] Initial Loss: 0.1364, Training Loss: 0.1364, Initial Validation Loss: 0.1321, Validation Loss: 0.1321,V Acc: 0.3211, Top 70th Acc: 0.3377, Bottom 30th Acc: 0.2812
Fold [4/5] Epoch [10/100] Initial Loss: 0.1364, Training Loss: 0.0505, Initial Validation Loss: 0.1321, Validation Loss: 0.0450,V Acc: 0.8073, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.5000
Fold [4/5] Epoch [20/100] Initial Loss: 0.1364, Training Loss: 0.0196, Initial Validation Loss: 0.1321, Validation Loss: 0.0249,V Acc: 0.8716, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.6562
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.961038961038961
Fold [5/5] Epoch [0/100] Initial Loss: 0.1381, Training Loss: 0.1381, Initial Validation Loss: 0.1288, Validation Loss: 0.1288,V Acc: 0.3056, Top 70th Acc: 0.3553, Bottom 30th Acc: 0.1875
Fold [5/5] Epoch [10/100] Initial Loss: 0.1381, Training Loss: 0.0399, Initial Validation Loss: 0.1288, Validation Loss: 0.0442,V Acc: 0.7963, Top 70th Acc: 0.8816, Bottom 30th Acc: 0.5938
Fold [5/5] Epoch [20/100] Initial Loss: 0.1381, Training Loss: 0.0179, Initial Validation Loss: 0.1288, Validation Loss: 0.0342,V Acc: 0.8519, Top 70th Acc: 0.9079, Bottom 30th Acc: 0.7188
Fold [5/5] Epoch [30/100] Initial Loss: 0.1381, Training Loss: 0.0143, Initial Validation Loss: 0.1288, Validation Loss: 0.0341,V Acc: 0.8611, Top 70th Acc: 0.9079, Bottom 30th Acc: 0.7500
Stopping early at Epoch (base 0): 33  Rolling back to Epoch (base 0): 28  Top Validation Acc: 0.9210526315789473
Running train_nn.py with seed 88
CUDA:False
Training samples count:  550
Training on 30 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1364, Training Loss: 0.1364, Initial Validation Loss: 0.1353, Validation Loss: 0.1353,V Acc: 0.3750, Top 70th Acc: 0.4810, Bottom 30th Acc: 0.1212
Fold [1/5] Epoch [10/100] Initial Loss: 0.1364, Training Loss: 0.0255, Initial Validation Loss: 0.1353, Validation Loss: 0.0346,V Acc: 0.8304, Top 70th Acc: 0.9747, Bottom 30th Acc: 0.4848
Stopping early at Epoch (base 0): 17  Rolling back to Epoch (base 0): 12  Top Validation Acc: 0.9493670886075949
Fold [2/5] Epoch [0/100] Initial Loss: 0.1385, Training Loss: 0.1385, Initial Validation Loss: 0.1349, Validation Loss: 0.1349,V Acc: 0.3423, Top 70th Acc: 0.3205, Bottom 30th Acc: 0.3939
Fold [2/5] Epoch [10/100] Initial Loss: 0.1385, Training Loss: 0.0319, Initial Validation Loss: 0.1349, Validation Loss: 0.0298,V Acc: 0.8649, Top 70th Acc: 1.0000, Bottom 30th Acc: 0.5455
Fold [2/5] Epoch [20/100] Initial Loss: 0.1385, Training Loss: 0.0195, Initial Validation Loss: 0.1349, Validation Loss: 0.0232,V Acc: 0.8739, Top 70th Acc: 0.9872, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.9871794871794872
Fold [3/5] Epoch [0/100] Initial Loss: 0.1390, Training Loss: 0.1390, Initial Validation Loss: 0.1311, Validation Loss: 0.1311,V Acc: 0.3545, Top 70th Acc: 0.4286, Bottom 30th Acc: 0.1818
Fold [3/5] Epoch [10/100] Initial Loss: 0.1390, Training Loss: 0.0335, Initial Validation Loss: 0.1311, Validation Loss: 0.0473,V Acc: 0.8000, Top 70th Acc: 0.8701, Bottom 30th Acc: 0.6364
Fold [3/5] Epoch [20/100] Initial Loss: 0.1390, Training Loss: 0.0226, Initial Validation Loss: 0.1311, Validation Loss: 0.0443,V Acc: 0.8182, Top 70th Acc: 0.8701, Bottom 30th Acc: 0.6970
Fold [3/5] Epoch [30/100] Initial Loss: 0.1390, Training Loss: 0.0172, Initial Validation Loss: 0.1311, Validation Loss: 0.0394,V Acc: 0.8091, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.5758
Fold [3/5] Epoch [40/100] Initial Loss: 0.1390, Training Loss: 0.0149, Initial Validation Loss: 0.1311, Validation Loss: 0.0370,V Acc: 0.8364, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.6667
Fold [3/5] Epoch [50/100] Initial Loss: 0.1390, Training Loss: 0.0136, Initial Validation Loss: 0.1311, Validation Loss: 0.0352,V Acc: 0.8818, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.8182/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)

Stopping early at Epoch (base 0): 20  Rolling back to Epoch (base 0): 15  Top Validation Acc: 0.9240506329113924
Fold [2/5] Epoch [0/100] Initial Loss: 0.1388, Training Loss: 0.1388, Initial Validation Loss: 0.1270, Validation Loss: 0.1270,V Acc: 0.3514, Top 70th Acc: 0.4103, Bottom 30th Acc: 0.2121
Fold [2/5] Epoch [10/100] Initial Loss: 0.1388, Training Loss: 0.0376, Initial Validation Loss: 0.1270, Validation Loss: 0.0478,V Acc: 0.7928, Top 70th Acc: 0.8462, Bottom 30th Acc: 0.6667
Fold [2/5] Epoch [20/100] Initial Loss: 0.1388, Training Loss: 0.0245, Initial Validation Loss: 0.1270, Validation Loss: 0.0371,V Acc: 0.8198, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.6061
Fold [2/5] Epoch [30/100] Initial Loss: 0.1388, Training Loss: 0.0216, Initial Validation Loss: 0.1270, Validation Loss: 0.0343,V Acc: 0.8198, Top 70th Acc: 0.8974, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 31  Rolling back to Epoch (base 0): 26  Top Validation Acc: 0.8974358974358975
Fold [3/5] Epoch [0/100] Initial Loss: 0.1366, Training Loss: 0.1366, Initial Validation Loss: 0.1356, Validation Loss: 0.1356,V Acc: 0.3273, Top 70th Acc: 0.3636, Bottom 30th Acc: 0.2424
Fold [3/5] Epoch [10/100] Initial Loss: 0.1366, Training Loss: 0.0434, Initial Validation Loss: 0.1356, Validation Loss: 0.0437,V Acc: 0.8273, Top 70th Acc: 0.8961, Bottom 30th Acc: 0.6667
Fold [3/5] Epoch [20/100] Initial Loss: 0.1366, Training Loss: 0.0254, Initial Validation Loss: 0.1356, Validation Loss: 0.0327,V Acc: 0.8455, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6061
Fold [3/5] Epoch [30/100] Initial Loss: 0.1366, Training Loss: 0.0229, Initial Validation Loss: 0.1356, Validation Loss: 0.0308,V Acc: 0.8364, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.5455
Fold [3/5] Epoch [40/100] Initial Loss: 0.1366, Training Loss: 0.0216, Initial Validation Loss: 0.1356, Validation Loss: 0.0317,V Acc: 0.8455, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 41  Rolling back to Epoch (base 0): 36  Top Validation Acc: 0.961038961038961
Fold [4/5] Epoch [0/100] Initial Loss: 0.1342, Training Loss: 0.1342, Initial Validation Loss: 0.1254, Validation Loss: 0.1254,V Acc: 0.3761, Top 70th Acc: 0.4675, Bottom 30th Acc: 0.1562
Fold [4/5] Epoch [10/100] Initial Loss: 0.1342, Training Loss: 0.0312, Initial Validation Loss: 0.1254, Validation Loss: 0.0379,V Acc: 0.8073, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.5625
Fold [4/5] Epoch [20/100] Initial Loss: 0.1342, Training Loss: 0.0222, Initial Validation Loss: 0.1254, Validation Loss: 0.0346,V Acc: 0.8349, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.6562
Fold [4/5] Epoch [30/100] Initial Loss: 0.1342, Training Loss: 0.0200, Initial Validation Loss: 0.1254, Validation Loss: 0.0341,V Acc: 0.8257, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.6250
Stopping early at Epoch (base 0): 31  Rolling back to Epoch (base 0): 26  Top Validation Acc: 0.9090909090909091
89 3 [array([0.43609172, 0.09290666, 0.11727446, 0.18219659, 0.17153062],
      dtype=float32)]
Fold [5/5] Epoch [0/100] Initial Loss: 0.1390, Training Loss: 0.1390, Initial Validation Loss: 0.1331, Validation Loss: 0.1331,V Acc: 0.2685, Top 70th Acc: 0.3158, Bottom 30th Acc: 0.1562
Fold [5/5] Epoch [10/100] Initial Loss: 0.1390, Training Loss: 0.0394, Initial Validation Loss: 0.1331, Validation Loss: 0.0401,V Acc: 0.8241, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.5625
Fold [5/5] Epoch [20/100] Initial Loss: 0.1390, Training Loss: 0.0249, Initial Validation Loss: 0.1331, Validation Loss: 0.0329,V Acc: 0.8148, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.5000
Stopping early at Epoch (base 0): 29  Rolling back to Epoch (base 0): 24  Top Validation Acc: 0.9342105263157895
Running train_nn.py with seed 90
CUDA:False
Training samples count:  550
Training on 20 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1391, Training Loss: 0.1391, Initial Validation Loss: 0.1319, Validation Loss: 0.1319,V Acc: 0.3661, Top 70th Acc: 0.3924, Bottom 30th Acc: 0.3030
Fold [1/5] Epoch [10/100] Initial Loss: 0.1391, Training Loss: 0.0338, Initial Validation Loss: 0.1319, Validation Loss: 0.0372,V Acc: 0.8036, Top 70th Acc: 0.9367, Bottom 30th Acc: 0.4848
Fold [1/5] Epoch [20/100] Initial Loss: 0.1391, Training Loss: 0.0228, Initial Validation Loss: 0.1319, Validation Loss: 0.0327,V Acc: 0.8393, Top 70th Acc: 0.9367, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 21  Rolling back to Epoch (base 0): 16  Top Validation Acc: 0.9367088607594937
Fold [2/5] Epoch [0/100] Initial Loss: 0.1386, Training Loss: 0.1386, Initial Validation Loss: 0.1299, Validation Loss: 0.1299,V Acc: 0.3874, Top 70th Acc: 0.5256, Bottom 30th Acc: 0.0606
Fold [2/5] Epoch [10/100] Initial Loss: 0.1386, Training Loss: 0.0429, Initial Validation Loss: 0.1299, Validation Loss: 0.0503,V Acc: 0.7658, Top 70th Acc: 0.8462, Bottom 30th Acc: 0.5758
Fold [2/5] Epoch [20/100] Initial Loss: 0.1386, Training Loss: 0.0228, Initial Validation Loss: 0.1299, Validation Loss: 0.0356,V Acc: 0.8378, Top 70th Acc: 0.8974, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.8846153846153846
90 1 [array([0.2346321 , 0.12618412, 0.13799751, 0.22297455, 0.27821165],
      dtype=float32)]
Fold [3/5] Epoch [0/100] Initial Loss: 0.1361, Training Loss: 0.1361, Initial Validation Loss: 0.1272, Validation Loss: 0.1272,V Acc: 0.4000, Top 70th Acc: 0.3896, Bottom 30th Acc: 0.4242
Fold [3/5] Epoch [10/100] Initial Loss: 0.1361, Training Loss: 0.0340, Initial Validation Loss: 0.1272, Validation Loss: 0.0407,V Acc: 0.8273, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.6061
Fold [3/5] Epoch [20/100] Initial Loss: 0.1361, Training Loss: 0.0221, Initial Validation Loss: 0.1272, Validation Loss: 0.0328,V Acc: 0.8273, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.922077922077922
Fold [4/5] Epoch [0/100] Initial Loss: 0.1408, Training Loss: 0.1408, Initial Validation Loss: 0.1387, Validation Loss: 0.1387,V Acc: 0.2569, Top 70th Acc: 0.3247, Bottom 30th Acc: 0.0938
Fold [4/5] Epoch [10/100] Initial Loss: 0.1408, Training Loss: 0.0370, Initial Validation Loss: 0.1387, Validation Loss: 0.0361,V Acc: 0.8532, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.6562
Fold [4/5] Epoch [20/100] Initial Loss: 0.1408, Training Loss: 0.0244, Initial Validation Loss: 0.1387, Validation Loss: 0.0268,V Acc: 0.8716, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.6562
Fold [4/5] Epoch [30/100] Initial Loss: 0.1408, Training Loss: 0.0217, Initial Validation Loss: 0.1387, Validation Loss: 0.0261,V Acc: 0.8716, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.6562
Stopping early at Epoch (base 0): 38  Rolling back to Epoch (base 0): 33  Top Validation Acc: 0.961038961038961
Fold [5/5] Epoch [0/100] Initial Loss: 0.1407, Training Loss: 0.1407, Initial Validation Loss: 0.1349, Validation Loss: 0.1349,V Acc: 0.2500, Top 70th Acc: 0.1974, Bottom 30th Acc: 0.3750
Fold [5/5] Epoch [10/100] Initial Loss: 0.1407, Training Loss: 0.0357, Initial Validation Loss: 0.1349, Validation Loss: 0.0307,V Acc: 0.8889, Top 70th Acc: 0.9737, Bottom 30th Acc: 0.6875
Fold [5/5] Epoch [20/100] Initial Loss: 0.1407, Training Loss: 0.0249, Initial Validation Loss: 0.1349, Validation Loss: 0.0249,V Acc: 0.9074, Top 70th Acc: 0.9868, Bottom 30th Acc: 0.7188
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.9736842105263158
Running train_nn.py with seed 91
CUDA:False
Training samples count:  550
Training on 20 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1394, Training Loss: 0.1394, Initial Validation Loss: 0.1351, Validation Loss: 0.1351,V Acc: 0.2500, Top 70th Acc: 0.3418, Bottom 30th Acc: 0.0303
Fold [1/5] Epoch [10/100] Initial Loss: 0.1394, Training Loss: 0.0437, Initial Validation Loss: 0.1351, Validation Loss: 0.0459,V Acc: 0.7857, Top 70th Acc: 0.8608, Bottom 30th Acc: 0.6061
Fold [1/5] Epoch [20/100] Initial Loss: 0.1394, Training Loss: 0.0259, Initial Validation Loss: 0.1351, Validation Loss: 0.0350,V Acc: 0.8661, Top 70th Acc: 0.9241, Bottom 30th Acc: 0.7273
Fold [1/5] Epoch [30/100] Initial Loss: 0.1394, Training Loss: 0.0225, Initial Validation Loss: 0.1351, Validation Loss: 0.0330,V Acc: 0.8750, Top 70th Acc: 0.9114, Bottom 30th Acc: 0.7879
Fold [2/5] Epoch [20/100] Initial Loss: 0.1384, Training Loss: 0.0056, Initial Validation Loss: 0.1371, Validation Loss: 0.0334,V Acc: 0.8108, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.4848
Fold [2/5] Epoch [30/100] Initial Loss: 0.1384, Training Loss: 0.0044, Initial Validation Loss: 0.1371, Validation Loss: 0.0323,V Acc: 0.8108, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.4545
Stopping early at Epoch (base 0): 34  Rolling back to Epoch (base 0): 29  Top Validation Acc: 0.9615384615384616
Fold [3/5] Epoch [0/100] Initial Loss: 0.1422, Training Loss: 0.1422, Initial Validation Loss: 0.1316, Validation Loss: 0.1316,V Acc: 0.2545, Top 70th Acc: 0.3247, Bottom 30th Acc: 0.0909
Fold [3/5] Epoch [10/100] Initial Loss: 0.1422, Training Loss: 0.0135, Initial Validation Loss: 0.1316, Validation Loss: 0.0299,V Acc: 0.8636, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6667
Fold [3/5] Epoch [20/100] Initial Loss: 0.1422, Training Loss: 0.0044, Initial Validation Loss: 0.1316, Validation Loss: 0.0275,V Acc: 0.8364, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 22  Rolling back to Epoch (base 0): 17  Top Validation Acc: 0.948051948051948
Fold [4/5] Epoch [0/100] Initial Loss: 0.1402, Training Loss: 0.1402, Initial Validation Loss: 0.1297, Validation Loss: 0.1297,V Acc: 0.2477, Top 70th Acc: 0.2857, Bottom 30th Acc: 0.1562
Fold [4/5] Epoch [10/100] Initial Loss: 0.1402, Training Loss: 0.0238, Initial Validation Loss: 0.1297, Validation Loss: 0.0354,V Acc: 0.8440, Top 70th Acc: 0.8961, Bottom 30th Acc: 0.7188
Fold [4/5] Epoch [20/100] Initial Loss: 0.1402, Training Loss: 0.0054, Initial Validation Loss: 0.1297, Validation Loss: 0.0310,V Acc: 0.8257, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.5938
Fold [4/5] Epoch [30/100] Initial Loss: 0.1402, Training Loss: 0.0039, Initial Validation Loss: 0.1297, Validation Loss: 0.0297,V Acc: 0.8440, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.6250
Stopping early at Epoch (base 0): 35  Rolling back to Epoch (base 0): 30  Top Validation Acc: 0.922077922077922
Fold [5/5] Epoch [0/100] Initial Loss: 0.1386, Training Loss: 0.1386, Initial Validation Loss: 0.1351, Validation Loss: 0.1351,V Acc: 0.2500, Top 70th Acc: 0.3421, Bottom 30th Acc: 0.0312
Fold [5/5] Epoch [10/100] Initial Loss: 0.1386, Training Loss: 0.0182, Initial Validation Loss: 0.1351, Validation Loss: 0.0302,V Acc: 0.8519, Top 70th Acc: 0.9868, Bottom 30th Acc: 0.5312
Fold [5/5] Epoch [20/100] Initial Loss: 0.1386, Training Loss: 0.0050, Initial Validation Loss: 0.1351, Validation Loss: 0.0253,V Acc: 0.8611, Top 70th Acc: 0.9868, Bottom 30th Acc: 0.5625
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.9736842105263158
Running train_nn.py with seed 69
CUDA:False
Training samples count:  550
Training on 162 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1384, Training Loss: 0.1384, Initial Validation Loss: 0.1353, Validation Loss: 0.1353,V Acc: 0.2768, Top 70th Acc: 0.3418, Bottom 30th Acc: 0.1212
Fold [1/5] Epoch [10/100] Initial Loss: 0.1384, Training Loss: 0.0164, Initial Validation Loss: 0.1353, Validation Loss: 0.0330,V Acc: 0.8750, Top 70th Acc: 0.9873, Bottom 30th Acc: 0.6061
Fold [1/5] Epoch [20/100] Initial Loss: 0.1384, Training Loss: 0.0049, Initial Validation Loss: 0.1353, Validation Loss: 0.0240,V Acc: 0.9018, Top 70th Acc: 0.9747, Bottom 30th Acc: 0.7273
Fold [1/5] Epoch [30/100] Initial Loss: 0.1384, Training Loss: 0.0041, Initial Validation Loss: 0.1353, Validation Loss: 0.0231,V Acc: 0.8839, Top 70th Acc: 0.9747, Bottom 30th Acc: 0.6667
Fold [1/5] Epoch [40/100] Initial Loss: 0.1384, Training Loss: 0.0038, Initial Validation Loss: 0.1353, Validation Loss: 0.0230,V Acc: 0.8661, Top 70th Acc: 0.9873, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 41  Rolling back to Epoch (base 0): 36  Top Validation Acc: 0.9873417721518988
Fold [2/5] Epoch [0/100] Initial Loss: 0.1434, Training Loss: 0.1434, Initial Validation Loss: 0.1355, Validation Loss: 0.1355,V Acc: 0.3423, Top 70th Acc: 0.3462, Bottom 30th Acc: 0.3333
Fold [2/5] Epoch [10/100] Initial Loss: 0.1434, Training Loss: 0.0175, Initial Validation Loss: 0.1355, Validation Loss: 0.0472,V Acc: 0.7477, Top 70th Acc: 0.8718, Bottom 30th Acc: 0.4545
Fold [2/5] Epoch [20/100] Initial Loss: 0.1434, Training Loss: 0.0054, Initial Validation Loss: 0.1355, Validation Loss: 0.0433,V Acc: 0.7838, Top 70th Acc: 0.8846, Bottom 30th Acc: 0.5455
Fold [2/5] Epoch [30/100] Initial Loss: 0.1434, Training Loss: 0.0042, Initial Validation Loss: 0.1355, Validation Loss: 0.0414,V Acc: 0.7658, Top 70th Acc: 0.8846, Bottom 30th Acc: 0.4848
Fold [2/5] Epoch [40/100] Initial Loss: 0.1434, Training Loss: 0.0039, Initial Validation Loss: 0.1355, Validation Loss: 0.0401,V Acc: 0.7658, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.4242
Fold [2/5] Epoch [50/100] Initial Loss: 0.1434, Training Loss: 0.0038, Initial Validation Loss: 0.1355, Validation Loss: 0.0396,V Acc: 0.7658, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.4242
Stopping early at Epoch (base 0): 58  Rolling back to Epoch (base 0): 53  Top Validation Acc: 0.9230769230769231
Fold [3/5] Epoch [0/100] Initial Loss: 0.1392, Training Loss: 0.1392, Initial Validation Loss: 0.1317, Validation Loss: 0.1317,V Acc: 0.2545, Top 70th Acc: 0.3506, Bottom 30th Acc: 0.0303
Fold [3/5] Epoch [10/100] Initial Loss: 0.1392, Training Loss: 0.0264, Initial Validation Loss: 0.1317, Validation Loss: 0.0404,V Acc: 0.7818, Top 70th Acc: 0.8831, Bottom 30th Acc: 0.5455
Fold [3/5] Epoch [20/100] Initial Loss: 0.1392, Training Loss: 0.0048, Initial Validation Loss: 0.1317, Validation Loss: 0.0287,V Acc: 0.8909, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.7273
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.961038961038961
Fold [4/5] Epoch [0/100] Initial Loss: 0.1412, Training Loss: 0.1412, Initial Validation Loss: 0.1361, Validation Loss: 0.1361,V Acc: 0.2477, Top 70th Acc: 0.3247, Bottom 30th Acc: 0.0625
Fold [4/5] Epoch [10/100] Initial Loss: 0.1412, Training Loss: 0.0195, Initial Validation Loss: 0.1361, Validation Loss: 0.0310,V Acc: 0.8991, Top 70th Acc: 0.9870, Bottom 30th Acc: 0.6875
Fold [4/5] Epoch [20/100] Initial Loss: 0.1412, Training Loss: 0.0052, Initial Validation Loss: 0.1361, Validation Loss: 0.0272,V Acc: 0.8716, Top 70th Acc: 0.9870, Bottom 30th Acc: 0.5938
Stopping early at Epoch (base 0): 22  Rolling back to Epoch (base 0): 17  Top Validation Acc: 0.974025974025974
Fold [5/5] Epoch [0/100] Initial Loss: 0.1389, Training Loss: 0.1389, Initial Validation Loss: 0.1317, Validation Loss: 0.1317,V Acc: 0.3148, Top 70th Acc: 0.3684, Bottom 30th Acc: 0.1875
Fold [5/5] Epoch [10/100] Initial Loss: 0.1389, Training Loss: 0.0132, Initial Validation Loss: 0.1317, Validation Loss: 0.0319,V Acc: 0.8519, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.6562
Fold [5/5] Epoch [20/100] Initial Loss: 0.1389, Training Loss: 0.0046, Initial Validation Loss: 0.1317, Validation Loss: 0.0297,V Acc: 0.8611, Top 70th Acc: 0.9079, Bottom 30th Acc: 0.7500
Stopping early at Epoch (base 0): 22  Rolling back to Epoch (base 0): 17  Top Validation Acc: 0.9078947368421053
69 4 [array([0.16340396, 0.03467789, 0.05313313, 0.21028171, 0.53850335],
      dtype=float32)]
Running train_nn.py with seed 70
CUDA:False
Training samples count:  550
Training on 162 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1386, Training Loss: 0.1386, Initial Validation Loss: 0.1291, Validation Loss: 0.1291,V Acc: 0.3214, Top 70th Acc: 0.3797, Bottom 30th Acc: 0.1818
Fold [1/5] Epoch [10/100] Initial Loss: 0.1386, Training Loss: 0.0132, Initial Validation Loss: 0.1291, Validation Loss: 0.0296,V Acc: 0.8393, Top 70th Acc: 0.9620, Bottom 30th Acc: 0.5455
Fold [1/5] Epoch [20/100] Initial Loss: 0.1386, Training Loss: 0.0040, Initial Validation Loss: 0.1291, Validation Loss: 0.0266,V Acc: 0.8482, Top 70th Acc: 0.9367, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 20  Rolling back to Epoch (base 0): 15  Top Validation Acc: 0.9367088607594937
70 0 [array([0.17016257, 0.08596134, 0.07263202, 0.2135575 , 0.4576866 ],
      dtype=float32)]
Fold [2/5] Epoch [0/100] Initial Loss: 0.1392, Training Loss: 0.1392, Initial Validation Loss: 0.1327, Validation Loss: 0.1327,V Acc: 0.4234, Top 70th Acc: 0.5128, Bottom 30th Acc: 0.2121
Fold [4/5] Epoch [30/100] Initial Loss: 0.1368, Training Loss: 0.0796, Initial Validation Loss: 0.1302, Validation Loss: 0.0729,V Acc: 0.6697, Top 70th Acc: 0.8182, Bottom 30th Acc: 0.3125
Stopping early at Epoch (base 0): 37  Rolling back to Epoch (base 0): 32  Top Validation Acc: 0.7922077922077922
Fold [5/5] Epoch [0/100] Initial Loss: 0.1396, Training Loss: 0.1396, Initial Validation Loss: 0.1340, Validation Loss: 0.1340,V Acc: 0.3796, Top 70th Acc: 0.5000, Bottom 30th Acc: 0.0938
Fold [5/5] Epoch [10/100] Initial Loss: 0.1396, Training Loss: 0.0823, Initial Validation Loss: 0.1340, Validation Loss: 0.0769,V Acc: 0.6389, Top 70th Acc: 0.7895, Bottom 30th Acc: 0.2812
Fold [5/5] Epoch [20/100] Initial Loss: 0.1396, Training Loss: 0.0802, Initial Validation Loss: 0.1340, Validation Loss: 0.0745,V Acc: 0.6481, Top 70th Acc: 0.7895, Bottom 30th Acc: 0.3125
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.8157894736842105
Running train_nn.py with seed 91
CUDA:False
Training samples count:  550
Training on 2 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1425, Training Loss: 0.1425, Initial Validation Loss: 0.1375, Validation Loss: 0.1375,V Acc: 0.2500, Top 70th Acc: 0.3038, Bottom 30th Acc: 0.1212
Fold [1/5] Epoch [10/100] Initial Loss: 0.1425, Training Loss: 0.0810, Initial Validation Loss: 0.1375, Validation Loss: 0.0841,V Acc: 0.5893, Top 70th Acc: 0.6835, Bottom 30th Acc: 0.3636
Fold [1/5] Epoch [20/100] Initial Loss: 0.1425, Training Loss: 0.0785, Initial Validation Loss: 0.1375, Validation Loss: 0.0820,V Acc: 0.5982, Top 70th Acc: 0.6835, Bottom 30th Acc: 0.3939
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.6962025316455697
91 0 [array([0.11939298, 0.410625  , 0.12352227, 0.18835728, 0.15810254],
      dtype=float32)]
Fold [2/5] Epoch [0/100] Initial Loss: 0.1391, Training Loss: 0.1391, Initial Validation Loss: 0.1261, Validation Loss: 0.1261,V Acc: 0.3694, Top 70th Acc: 0.4231, Bottom 30th Acc: 0.2424
Fold [2/5] Epoch [10/100] Initial Loss: 0.1391, Training Loss: 0.0823, Initial Validation Loss: 0.1261, Validation Loss: 0.0785,V Acc: 0.6216, Top 70th Acc: 0.7564, Bottom 30th Acc: 0.3030
Fold [2/5] Epoch [20/100] Initial Loss: 0.1391, Training Loss: 0.0800, Initial Validation Loss: 0.1261, Validation Loss: 0.0765,V Acc: 0.6486, Top 70th Acc: 0.7564, Bottom 30th Acc: 0.3939
Fold [2/5] Epoch [30/100] Initial Loss: 0.1391, Training Loss: 0.0793, Initial Validation Loss: 0.1261, Validation Loss: 0.0762,V Acc: 0.6396, Top 70th Acc: 0.7564, Bottom 30th Acc: 0.3636
Fold [2/5] Epoch [40/100] Initial Loss: 0.1391, Training Loss: 0.0788, Initial Validation Loss: 0.1261, Validation Loss: 0.0756,V Acc: 0.6306, Top 70th Acc: 0.7692, Bottom 30th Acc: 0.3030
Stopping early at Epoch (base 0): 40  Rolling back to Epoch (base 0): 35  Top Validation Acc: 0.7692307692307693
Fold [3/5] Epoch [0/100] Initial Loss: 0.1311, Training Loss: 0.1311, Initial Validation Loss: 0.1221, Validation Loss: 0.1221,V Acc: 0.4455, Top 70th Acc: 0.5584, Bottom 30th Acc: 0.1818
Fold [3/5] Epoch [10/100] Initial Loss: 0.1311, Training Loss: 0.0795, Initial Validation Loss: 0.1221, Validation Loss: 0.0802,V Acc: 0.6091, Top 70th Acc: 0.7532, Bottom 30th Acc: 0.2727
Fold [3/5] Epoch [20/100] Initial Loss: 0.1311, Training Loss: 0.0782, Initial Validation Loss: 0.1221, Validation Loss: 0.0792,V Acc: 0.6273, Top 70th Acc: 0.7532, Bottom 30th Acc: 0.3333
Fold [3/5] Epoch [30/100] Initial Loss: 0.1311, Training Loss: 0.0781, Initial Validation Loss: 0.1221, Validation Loss: 0.0792,V Acc: 0.6364, Top 70th Acc: 0.7403, Bottom 30th Acc: 0.3939
Stopping early at Epoch (base 0): 31  Rolling back to Epoch (base 0): 26  Top Validation Acc: 0.7532467532467533
Fold [4/5] Epoch [0/100] Initial Loss: 0.1276, Training Loss: 0.1276, Initial Validation Loss: 0.1148, Validation Loss: 0.1148,V Acc: 0.5046, Top 70th Acc: 0.5714, Bottom 30th Acc: 0.3438
Fold [4/5] Epoch [10/100] Initial Loss: 0.1276, Training Loss: 0.0820, Initial Validation Loss: 0.1148, Validation Loss: 0.0745,V Acc: 0.6697, Top 70th Acc: 0.8052, Bottom 30th Acc: 0.3438
Stopping early at Epoch (base 0): 16  Rolling back to Epoch (base 0): 11  Top Validation Acc: 0.7792207792207793
Fold [5/5] Epoch [0/100] Initial Loss: 0.1335, Training Loss: 0.1335, Initial Validation Loss: 0.1194, Validation Loss: 0.1194,V Acc: 0.5093, Top 70th Acc: 0.6053, Bottom 30th Acc: 0.2812
Fold [5/5] Epoch [10/100] Initial Loss: 0.1335, Training Loss: 0.0804, Initial Validation Loss: 0.1194, Validation Loss: 0.0803,V Acc: 0.6019, Top 70th Acc: 0.7237, Bottom 30th Acc: 0.3125
Fold [5/5] Epoch [20/100] Initial Loss: 0.1335, Training Loss: 0.0781, Initial Validation Loss: 0.1194, Validation Loss: 0.0792,V Acc: 0.6019, Top 70th Acc: 0.7237, Bottom 30th Acc: 0.3125
Fold [5/5] Epoch [30/100] Initial Loss: 0.1335, Training Loss: 0.0769, Initial Validation Loss: 0.1194, Validation Loss: 0.0791,V Acc: 0.5926, Top 70th Acc: 0.7237, Bottom 30th Acc: 0.2812
Fold [5/5] Epoch [40/100] Initial Loss: 0.1335, Training Loss: 0.0761, Initial Validation Loss: 0.1194, Validation Loss: 0.0786,V Acc: 0.6019, Top 70th Acc: 0.7237, Bottom 30th Acc: 0.3125
Fold [5/5] Epoch [50/100] Initial Loss: 0.1335, Training Loss: 0.0757, Initial Validation Loss: 0.1194, Validation Loss: 0.0784,V Acc: 0.6019, Top 70th Acc: 0.7368, Bottom 30th Acc: 0.2812
Stopping early at Epoch (base 0): 50  Rolling back to Epoch (base 0): 45  Top Validation Acc: 0.7368421052631579
Running train_nn.py with seed 92
CUDA:False
Training samples count:  550
Training on 2 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1402, Training Loss: 0.1402, Initial Validation Loss: 0.1352, Validation Loss: 0.1352,V Acc: 0.2589, Top 70th Acc: 0.3544, Bottom 30th Acc: 0.0303
Fold [1/5] Epoch [10/100] Initial Loss: 0.1402, Training Loss: 0.0806, Initial Validation Loss: 0.1352, Validation Loss: 0.0797,V Acc: 0.6339, Top 70th Acc: 0.7722, Bottom 30th Acc: 0.3030
Fold [1/5] Epoch [20/100] Initial Loss: 0.1402, Training Loss: 0.0788, Initial Validation Loss: 0.1352, Validation Loss: 0.0782,V Acc: 0.6339, Top 70th Acc: 0.7722, Bottom 30th Acc: 0.3030
Fold [1/5] Epoch [30/100] Initial Loss: 0.1402, Training Loss: 0.0781, Initial Validation Loss: 0.1352, Validation Loss: 0.0779,V Acc: 0.6339, Top 70th Acc: 0.7722, Bottom 30th Acc: 0.3030
Stopping early at Epoch (base 0): 33  Rolling back to Epoch (base 0): 28  Top Validation Acc: 0.7974683544303798
Fold [2/5] Epoch [0/100] Initial Loss: 0.1301, Training Loss: 0.1301, Initial Validation Loss: 0.1167, Validation Loss: 0.1167,V Acc: 0.4054, Top 70th Acc: 0.4872, Bottom 30th Acc: 0.2121
Fold [2/5] Epoch [10/100] Initial Loss: 0.1301, Training Loss: 0.0807, Initial Validation Loss: 0.1167, Validation Loss: 0.0783,V Acc: 0.6216, Top 70th Acc: 0.7564, Bottom 30th Acc: 0.3030
Fold [2/5] Epoch [20/100] Initial Loss: 0.1301, Training Loss: 0.0785, Initial Validation Loss: 0.1167, Validation Loss: 0.0774,V Acc: 0.6306, Top 70th Acc: 0.7179, Bottom 30th Acc: 0.4242
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.7564102564102564
Fold [3/5] Epoch [0/100] Initial Loss: 0.1405, Training Loss: 0.1405, Initial Validation Loss: 0.1360, Validation Loss: 0.1360,V Acc: 0.2636, Top 70th Acc: 0.1169, Bottom 30th Acc: 0.6061
Fold [3/5] Epoch [10/100] Initial Loss: 0.1405, Training Loss: 0.0808, Initial Validation Loss: 0.1360, Validation Loss: 0.0829,V Acc: 0.5909, Top 70th Acc: 0.7273, Bottom 30th Acc: 0.2727
Fold [3/5] Epoch [20/100] Initial Loss: 0.1405, Training Loss: 0.0785, Initial Validation Loss: 0.1360, Validation Loss: 0.0814,V Acc: 0.6000, Top 70th Acc: 0.7273, Bottom 30th Acc: 0.3030
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.7272727272727273
Fold [4/5] Epoch [0/100] Initial Loss: 0.1389, Training Loss: 0.1389, Initial Validation Loss: 0.1334, Validation Loss: 0.1334,V Acc: 0.2477, Top 70th Acc: 0.3506, Bottom 30th Acc: 0.0000
Fold [4/5] Epoch [10/100] Initial Loss: 0.1389, Training Loss: 0.0801, Initial Validation Loss: 0.1334, Validation Loss: 0.0837,V Acc: 0.6239, Top 70th Acc: 0.7273, Bottom 30th Acc: 0.3750/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)

Fold [1/5] Epoch [20/100] Initial Loss: 0.1387, Training Loss: 0.0134, Initial Validation Loss: 0.1373, Validation Loss: 0.0317,V Acc: 0.8304, Top 70th Acc: 0.9494, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 22  Rolling back to Epoch (base 0): 17  Top Validation Acc: 0.9620253164556962
Fold [2/5] Epoch [0/100] Initial Loss: 0.1410, Training Loss: 0.1410, Initial Validation Loss: 0.1324, Validation Loss: 0.1324,V Acc: 0.2523, Top 70th Acc: 0.2821, Bottom 30th Acc: 0.1818
Fold [2/5] Epoch [10/100] Initial Loss: 0.1410, Training Loss: 0.0251, Initial Validation Loss: 0.1324, Validation Loss: 0.0367,V Acc: 0.8288, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.5758
Fold [2/5] Epoch [20/100] Initial Loss: 0.1410, Training Loss: 0.0126, Initial Validation Loss: 0.1324, Validation Loss: 0.0374,V Acc: 0.7838, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.3636
Stopping early at Epoch (base 0): 21  Rolling back to Epoch (base 0): 16  Top Validation Acc: 0.9615384615384616
Fold [3/5] Epoch [0/100] Initial Loss: 0.1367, Training Loss: 0.1367, Initial Validation Loss: 0.1318, Validation Loss: 0.1318,V Acc: 0.4000, Top 70th Acc: 0.4675, Bottom 30th Acc: 0.2424
Fold [3/5] Epoch [10/100] Initial Loss: 0.1367, Training Loss: 0.0327, Initial Validation Loss: 0.1318, Validation Loss: 0.0383,V Acc: 0.8364, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.6364
Fold [3/5] Epoch [20/100] Initial Loss: 0.1367, Training Loss: 0.0193, Initial Validation Loss: 0.1318, Validation Loss: 0.0309,V Acc: 0.8636, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.6364
Fold [3/5] Epoch [30/100] Initial Loss: 0.1367, Training Loss: 0.0135, Initial Validation Loss: 0.1318, Validation Loss: 0.0299,V Acc: 0.8545, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 31  Rolling back to Epoch (base 0): 26  Top Validation Acc: 0.961038961038961
Fold [4/5] Epoch [0/100] Initial Loss: 0.1376, Training Loss: 0.1376, Initial Validation Loss: 0.1327, Validation Loss: 0.1327,V Acc: 0.3119, Top 70th Acc: 0.3377, Bottom 30th Acc: 0.2500
Fold [4/5] Epoch [10/100] Initial Loss: 0.1376, Training Loss: 0.0237, Initial Validation Loss: 0.1327, Validation Loss: 0.0358,V Acc: 0.8440, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.6250
Fold [4/5] Epoch [20/100] Initial Loss: 0.1376, Training Loss: 0.0127, Initial Validation Loss: 0.1327, Validation Loss: 0.0307,V Acc: 0.8807, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.7812
Fold [4/5] Epoch [30/100] Initial Loss: 0.1376, Training Loss: 0.0107, Initial Validation Loss: 0.1327, Validation Loss: 0.0298,V Acc: 0.8624, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.6875
Stopping early at Epoch (base 0): 35  Rolling back to Epoch (base 0): 30  Top Validation Acc: 0.935064935064935
Fold [5/5] Epoch [0/100] Initial Loss: 0.1434, Training Loss: 0.1434, Initial Validation Loss: 0.1328, Validation Loss: 0.1328,V Acc: 0.2963, Top 70th Acc: 0.3684, Bottom 30th Acc: 0.1250
Fold [5/5] Epoch [10/100] Initial Loss: 0.1434, Training Loss: 0.0344, Initial Validation Loss: 0.1328, Validation Loss: 0.0385,V Acc: 0.7778, Top 70th Acc: 0.9079, Bottom 30th Acc: 0.4688
Fold [5/5] Epoch [20/100] Initial Loss: 0.1434, Training Loss: 0.0179, Initial Validation Loss: 0.1328, Validation Loss: 0.0298,V Acc: 0.8333, Top 70th Acc: 0.9211, Bottom 30th Acc: 0.6250
Fold [5/5] Epoch [30/100] Initial Loss: 0.1434, Training Loss: 0.0126, Initial Validation Loss: 0.1328, Validation Loss: 0.0269,V Acc: 0.8611, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.6875
Stopping early at Epoch (base 0): 34  Rolling back to Epoch (base 0): 29  Top Validation Acc: 0.9473684210526315
92 4 [array([0.53931564, 0.08062787, 0.03794778, 0.1157711 , 0.22633761],
      dtype=float32)]
Running train_nn.py with seed 93
CUDA:False
Training samples count:  550
Training on 40 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1401, Training Loss: 0.1401, Initial Validation Loss: 0.1389, Validation Loss: 0.1389,V Acc: 0.2589, Top 70th Acc: 0.3165, Bottom 30th Acc: 0.1212
Fold [1/5] Epoch [10/100] Initial Loss: 0.1401, Training Loss: 0.0342, Initial Validation Loss: 0.1389, Validation Loss: 0.0367,V Acc: 0.8839, Top 70th Acc: 0.9494, Bottom 30th Acc: 0.7273
Fold [1/5] Epoch [20/100] Initial Loss: 0.1401, Training Loss: 0.0155, Initial Validation Loss: 0.1389, Validation Loss: 0.0257,V Acc: 0.8929, Top 70th Acc: 0.9620, Bottom 30th Acc: 0.7273
Stopping early at Epoch (base 0): 29  Rolling back to Epoch (base 0): 24  Top Validation Acc: 0.9493670886075949
Fold [2/5] Epoch [0/100] Initial Loss: 0.1396, Training Loss: 0.1396, Initial Validation Loss: 0.1339, Validation Loss: 0.1339,V Acc: 0.2703, Top 70th Acc: 0.3333, Bottom 30th Acc: 0.1212
Fold [2/5] Epoch [10/100] Initial Loss: 0.1396, Training Loss: 0.0315, Initial Validation Loss: 0.1339, Validation Loss: 0.0413,V Acc: 0.8108, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.5758
Fold [2/5] Epoch [20/100] Initial Loss: 0.1396, Training Loss: 0.0123, Initial Validation Loss: 0.1339, Validation Loss: 0.0361,V Acc: 0.7928, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.4545
Stopping early at Epoch (base 0): 20  Rolling back to Epoch (base 0): 15  Top Validation Acc: 0.9358974358974359
Fold [3/5] Epoch [0/100] Initial Loss: 0.1409, Training Loss: 0.1409, Initial Validation Loss: 0.1358, Validation Loss: 0.1358,V Acc: 0.2636, Top 70th Acc: 0.3247, Bottom 30th Acc: 0.1212
Fold [3/5] Epoch [10/100] Initial Loss: 0.1409, Training Loss: 0.0304, Initial Validation Loss: 0.1358, Validation Loss: 0.0351,V Acc: 0.8727, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.7273
Fold [3/5] Epoch [20/100] Initial Loss: 0.1409, Training Loss: 0.0144, Initial Validation Loss: 0.1358, Validation Loss: 0.0242,V Acc: 0.8818, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.6970
Fold [3/5] Epoch [30/100] Initial Loss: 0.1409, Training Loss: 0.0121, Initial Validation Loss: 0.1358, Validation Loss: 0.0250,V Acc: 0.8636, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 37  Rolling back to Epoch (base 0): 32  Top Validation Acc: 0.935064935064935
93 2 [array([0.54951465, 0.03269367, 0.08758191, 0.10415123, 0.2260586 ],
      dtype=float32)]
Fold [4/5] Epoch [0/100] Initial Loss: 0.1381, Training Loss: 0.1381, Initial Validation Loss: 0.1304, Validation Loss: 0.1304,V Acc: 0.3853, Top 70th Acc: 0.4675, Bottom 30th Acc: 0.1875
Fold [4/5] Epoch [10/100] Initial Loss: 0.1381, Training Loss: 0.0269, Initial Validation Loss: 0.1304, Validation Loss: 0.0353,V Acc: 0.8165, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.5938
Fold [4/5] Epoch [20/100] Initial Loss: 0.1381, Training Loss: 0.0146, Initial Validation Loss: 0.1304, Validation Loss: 0.0306,V Acc: 0.8257, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.5625
Stopping early at Epoch (base 0): 21  Rolling back to Epoch (base 0): 16  Top Validation Acc: 0.922077922077922
Fold [5/5] Epoch [0/100] Initial Loss: 0.1403, Training Loss: 0.1403, Initial Validation Loss: 0.1314, Validation Loss: 0.1314,V Acc: 0.4722, Top 70th Acc: 0.5395, Bottom 30th Acc: 0.3125
Fold [5/5] Epoch [10/100] Initial Loss: 0.1403, Training Loss: 0.0384, Initial Validation Loss: 0.1314, Validation Loss: 0.0395,V Acc: 0.7870, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.4375
Fold [5/5] Epoch [20/100] Initial Loss: 0.1403, Training Loss: 0.0157, Initial Validation Loss: 0.1314, Validation Loss: 0.0253,V Acc: 0.8889, Top 70th Acc: 0.9737, Bottom 30th Acc: 0.6875
Stopping early at Epoch (base 0): 28  Rolling back to Epoch (base 0): 23  Top Validation Acc: 0.9736842105263158
Running train_nn.py with seed 94
CUDA:False
Training samples count:  550
Training on 40 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1408, Training Loss: 0.1408, Initial Validation Loss: 0.1396, Validation Loss: 0.1396,V Acc: 0.2589, Top 70th Acc: 0.2532, Bottom 30th Acc: 0.2727
Fold [1/5] Epoch [10/100] Initial Loss: 0.1408, Training Loss: 0.0389, Initial Validation Loss: 0.1396, Validation Loss: 0.0447,V Acc: 0.8304, Top 70th Acc: 0.9114, Bottom 30th Acc: 0.6364
Fold [1/5] Epoch [20/100] Initial Loss: 0.1408, Training Loss: 0.0148, Initial Validation Loss: 0.1396, Validation Loss: 0.0305,V Acc: 0.8482, Top 70th Acc: 0.9620, Bottom 30th Acc: 0.5758
Fold [1/5] Epoch [30/100] Initial Loss: 0.1408, Training Loss: 0.0119, Initial Validation Loss: 0.1396, Validation Loss: 0.0299,V Acc: 0.8393, Top 70th Acc: 0.9494, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 59  Rolling back to Epoch (base 0): 54  Top Validation Acc: 0.922077922077922
88 2 [array([0.65533066, 0.05575545, 0.10246155, 0.0648108 , 0.12164161],
      dtype=float32)]
Fold [4/5] Epoch [0/100] Initial Loss: 0.1414, Training Loss: 0.1414, Initial Validation Loss: 0.1230, Validation Loss: 0.1230,V Acc: 0.4679, Top 70th Acc: 0.5195, Bottom 30th Acc: 0.3438
Fold [4/5] Epoch [10/100] Initial Loss: 0.1414, Training Loss: 0.0263, Initial Validation Loss: 0.1230, Validation Loss: 0.0350,V Acc: 0.7798, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.4688
Fold [4/5] Epoch [20/100] Initial Loss: 0.1414, Training Loss: 0.0175, Initial Validation Loss: 0.1230, Validation Loss: 0.0327,V Acc: 0.7890, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.4688
Stopping early at Epoch (base 0): 22  Rolling back to Epoch (base 0): 17  Top Validation Acc: 0.9090909090909091
Fold [5/5] Epoch [0/100] Initial Loss: 0.1380, Training Loss: 0.1380, Initial Validation Loss: 0.1345, Validation Loss: 0.1345,V Acc: 0.3241, Top 70th Acc: 0.3947, Bottom 30th Acc: 0.1562
Fold [5/5] Epoch [10/100] Initial Loss: 0.1380, Training Loss: 0.0372, Initial Validation Loss: 0.1345, Validation Loss: 0.0403,V Acc: 0.8148, Top 70th Acc: 0.9211, Bottom 30th Acc: 0.5625
Fold [5/5] Epoch [20/100] Initial Loss: 0.1380, Training Loss: 0.0196, Initial Validation Loss: 0.1345, Validation Loss: 0.0275,V Acc: 0.8519, Top 70th Acc: 0.9737, Bottom 30th Acc: 0.5625
Stopping early at Epoch (base 0): 22  Rolling back to Epoch (base 0): 17  Top Validation Acc: 0.9605263157894737
Running train_nn.py with seed 89
CUDA:False
Training samples count:  550
Training on 30 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1387, Training Loss: 0.1387, Initial Validation Loss: 0.1348, Validation Loss: 0.1348,V Acc: 0.4732, Top 70th Acc: 0.4684, Bottom 30th Acc: 0.4848
Fold [1/5] Epoch [10/100] Initial Loss: 0.1387, Training Loss: 0.0282, Initial Validation Loss: 0.1348, Validation Loss: 0.0318,V Acc: 0.8304, Top 70th Acc: 0.9620, Bottom 30th Acc: 0.5152
Fold [1/5] Epoch [20/100] Initial Loss: 0.1387, Training Loss: 0.0183, Initial Validation Loss: 0.1348, Validation Loss: 0.0303,V Acc: 0.8482, Top 70th Acc: 0.9620, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 21  Rolling back to Epoch (base 0): 16  Top Validation Acc: 0.9620253164556962
Fold [2/5] Epoch [0/100] Initial Loss: 0.1432, Training Loss: 0.1432, Initial Validation Loss: 0.1314, Validation Loss: 0.1314,V Acc: 0.2523, Top 70th Acc: 0.3462, Bottom 30th Acc: 0.0303
Fold [2/5] Epoch [10/100] Initial Loss: 0.1432, Training Loss: 0.0407, Initial Validation Loss: 0.1314, Validation Loss: 0.0501,V Acc: 0.7387, Top 70th Acc: 0.8846, Bottom 30th Acc: 0.3939
Fold [2/5] Epoch [20/100] Initial Loss: 0.1432, Training Loss: 0.0201, Initial Validation Loss: 0.1314, Validation Loss: 0.0340,V Acc: 0.8198, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 28  Rolling back to Epoch (base 0): 23  Top Validation Acc: 0.9102564102564102
Fold [3/5] Epoch [0/100] Initial Loss: 0.1420, Training Loss: 0.1420, Initial Validation Loss: 0.1401, Validation Loss: 0.1401,V Acc: 0.3364, Top 70th Acc: 0.3766, Bottom 30th Acc: 0.2424
Fold [3/5] Epoch [10/100] Initial Loss: 0.1420, Training Loss: 0.0417, Initial Validation Loss: 0.1401, Validation Loss: 0.0442,V Acc: 0.8455, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.6667
Fold [3/5] Epoch [20/100] Initial Loss: 0.1420, Training Loss: 0.0193, Initial Validation Loss: 0.1401, Validation Loss: 0.0317,V Acc: 0.8545, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.961038961038961
Fold [4/5] Epoch [0/100] Initial Loss: 0.1381, Training Loss: 0.1381, Initial Validation Loss: 0.1268, Validation Loss: 0.1268,V Acc: 0.3761, Top 70th Acc: 0.4675, Bottom 30th Acc: 0.1562
Fold [4/5] Epoch [10/100] Initial Loss: 0.1381, Training Loss: 0.0262, Initial Validation Loss: 0.1268, Validation Loss: 0.0337,V Acc: 0.8165, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.5000
Stopping early at Epoch (base 0): 19  Rolling back to Epoch (base 0): 14  Top Validation Acc: 0.961038961038961
89 3 [array([0.74837816, 0.08369141, 0.05247639, 0.06950587, 0.04594825],
      dtype=float32)]
Fold [5/5] Epoch [0/100] Initial Loss: 0.1367, Training Loss: 0.1367, Initial Validation Loss: 0.1345, Validation Loss: 0.1345,V Acc: 0.3148, Top 70th Acc: 0.3421, Bottom 30th Acc: 0.2500
Fold [5/5] Epoch [10/100] Initial Loss: 0.1367, Training Loss: 0.0358, Initial Validation Loss: 0.1345, Validation Loss: 0.0369,V Acc: 0.8519, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.5938
Fold [5/5] Epoch [20/100] Initial Loss: 0.1367, Training Loss: 0.0218, Initial Validation Loss: 0.1345, Validation Loss: 0.0325,V Acc: 0.8426, Top 70th Acc: 0.9211, Bottom 30th Acc: 0.6562
Fold [5/5] Epoch [30/100] Initial Loss: 0.1367, Training Loss: 0.0167, Initial Validation Loss: 0.1345, Validation Loss: 0.0325,V Acc: 0.8241, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.5625
Stopping early at Epoch (base 0): 35  Rolling back to Epoch (base 0): 30  Top Validation Acc: 0.9342105263157895
Running train_nn.py with seed 90
CUDA:False
Training samples count:  550
Training on 30 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1416, Training Loss: 0.1416, Initial Validation Loss: 0.1309, Validation Loss: 0.1309,V Acc: 0.4107, Top 70th Acc: 0.3924, Bottom 30th Acc: 0.4545
Fold [1/5] Epoch [10/100] Initial Loss: 0.1416, Training Loss: 0.0378, Initial Validation Loss: 0.1309, Validation Loss: 0.0457,V Acc: 0.7679, Top 70th Acc: 0.8608, Bottom 30th Acc: 0.5455
Fold [1/5] Epoch [20/100] Initial Loss: 0.1416, Training Loss: 0.0181, Initial Validation Loss: 0.1309, Validation Loss: 0.0334,V Acc: 0.8571, Top 70th Acc: 0.9241, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 28  Rolling back to Epoch (base 0): 23  Top Validation Acc: 0.9240506329113924
Fold [2/5] Epoch [0/100] Initial Loss: 0.1395, Training Loss: 0.1395, Initial Validation Loss: 0.1322, Validation Loss: 0.1322,V Acc: 0.3243, Top 70th Acc: 0.3462, Bottom 30th Acc: 0.2727
Fold [2/5] Epoch [10/100] Initial Loss: 0.1395, Training Loss: 0.0347, Initial Validation Loss: 0.1322, Validation Loss: 0.0445,V Acc: 0.8018, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.5455
Fold [2/5] Epoch [20/100] Initial Loss: 0.1395, Training Loss: 0.0167, Initial Validation Loss: 0.1322, Validation Loss: 0.0331,V Acc: 0.8468, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.6364
Fold [2/5] Epoch [30/100] Initial Loss: 0.1395, Training Loss: 0.0144, Initial Validation Loss: 0.1322, Validation Loss: 0.0326,V Acc: 0.8288, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 31  Rolling back to Epoch (base 0): 26  Top Validation Acc: 0.9358974358974359
90 1 [array([0.64203435, 0.08080672, 0.02482648, 0.07699738, 0.17533508],
      dtype=float32)]
Fold [3/5] Epoch [0/100] Initial Loss: 0.1372, Training Loss: 0.1372, Initial Validation Loss: 0.1275, Validation Loss: 0.1275,V Acc: 0.3727, Top 70th Acc: 0.5065, Bottom 30th Acc: 0.0606
Fold [3/5] Epoch [10/100] Initial Loss: 0.1372, Training Loss: 0.0284, Initial Validation Loss: 0.1275, Validation Loss: 0.0305,V Acc: 0.8545, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.6667
Fold [3/5] Epoch [20/100] Initial Loss: 0.1372, Training Loss: 0.0167, Initial Validation Loss: 0.1275, Validation Loss: 0.0270,V Acc: 0.8636, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 22  Rolling back to Epoch (base 0): 17  Top Validation Acc: 0.961038961038961
Fold [4/5] Epoch [0/100] Initial Loss: 0.1406, Training Loss: 0.1406, Initial Validation Loss: 0.1361, Validation Loss: 0.1361,V Acc: 0.4495, Top 70th Acc: 0.5455, Bottom 30th Acc: 0.2188
Fold [4/5] Epoch [10/100] Initial Loss: 0.1406, Training Loss: 0.0284, Initial Validation Loss: 0.1361, Validation Loss: 0.0287,V Acc: 0.8716, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.6562
Fold [4/5] Epoch [20/100] Initial Loss: 0.1406, Training Loss: 0.0187, Initial Validation Loss: 0.1361, Validation Loss: 0.0234,V Acc: 0.9083, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.7500
Fold [4/5] Epoch [30/100] Initial Loss: 0.1406, Training Loss: 0.0165, Initial Validation Loss: 0.1361, Validation Loss: 0.0225,V Acc: 0.8899, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.6875/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)

Fold [1/5] Epoch [40/100] Initial Loss: 0.1394, Training Loss: 0.0209, Initial Validation Loss: 0.1351, Validation Loss: 0.0331,V Acc: 0.8571, Top 70th Acc: 0.9241, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 40  Rolling back to Epoch (base 0): 35  Top Validation Acc: 0.9240506329113924
91 0 [array([0.31122777, 0.0444173 , 0.05122063, 0.21824205, 0.3748923 ],
      dtype=float32)]
Fold [2/5] Epoch [0/100] Initial Loss: 0.1428, Training Loss: 0.1428, Initial Validation Loss: 0.1294, Validation Loss: 0.1294,V Acc: 0.2793, Top 70th Acc: 0.2949, Bottom 30th Acc: 0.2424
Fold [2/5] Epoch [10/100] Initial Loss: 0.1428, Training Loss: 0.0377, Initial Validation Loss: 0.1294, Validation Loss: 0.0450,V Acc: 0.8018, Top 70th Acc: 0.8462, Bottom 30th Acc: 0.6970
Fold [2/5] Epoch [20/100] Initial Loss: 0.1428, Training Loss: 0.0223, Initial Validation Loss: 0.1294, Validation Loss: 0.0402,V Acc: 0.8108, Top 70th Acc: 0.8718, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 21  Rolling back to Epoch (base 0): 16  Top Validation Acc: 0.8717948717948718
Fold [3/5] Epoch [0/100] Initial Loss: 0.1354, Training Loss: 0.1354, Initial Validation Loss: 0.1301, Validation Loss: 0.1301,V Acc: 0.4273, Top 70th Acc: 0.5065, Bottom 30th Acc: 0.2424
Fold [3/5] Epoch [10/100] Initial Loss: 0.1354, Training Loss: 0.0465, Initial Validation Loss: 0.1301, Validation Loss: 0.0496,V Acc: 0.7727, Top 70th Acc: 0.8831, Bottom 30th Acc: 0.5152
Fold [3/5] Epoch [20/100] Initial Loss: 0.1354, Training Loss: 0.0261, Initial Validation Loss: 0.1301, Validation Loss: 0.0322,V Acc: 0.8727, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.6667
Fold [3/5] Epoch [30/100] Initial Loss: 0.1354, Training Loss: 0.0234, Initial Validation Loss: 0.1301, Validation Loss: 0.0299,V Acc: 0.8545, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 35  Rolling back to Epoch (base 0): 30  Top Validation Acc: 0.948051948051948
Fold [4/5] Epoch [0/100] Initial Loss: 0.1379, Training Loss: 0.1379, Initial Validation Loss: 0.1364, Validation Loss: 0.1364,V Acc: 0.3211, Top 70th Acc: 0.3506, Bottom 30th Acc: 0.2500
Fold [4/5] Epoch [10/100] Initial Loss: 0.1379, Training Loss: 0.0428, Initial Validation Loss: 0.1364, Validation Loss: 0.0416,V Acc: 0.8257, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.5938
Fold [4/5] Epoch [20/100] Initial Loss: 0.1379, Training Loss: 0.0312, Initial Validation Loss: 0.1364, Validation Loss: 0.0366,V Acc: 0.8349, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.5938
Fold [4/5] Epoch [30/100] Initial Loss: 0.1379, Training Loss: 0.0255, Initial Validation Loss: 0.1364, Validation Loss: 0.0311,V Acc: 0.8624, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.6250
Fold [4/5] Epoch [40/100] Initial Loss: 0.1379, Training Loss: 0.0226, Initial Validation Loss: 0.1364, Validation Loss: 0.0302,V Acc: 0.8440, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.5625
Stopping early at Epoch (base 0): 43  Rolling back to Epoch (base 0): 38  Top Validation Acc: 0.961038961038961
Fold [5/5] Epoch [0/100] Initial Loss: 0.1373, Training Loss: 0.1373, Initial Validation Loss: 0.1290, Validation Loss: 0.1290,V Acc: 0.3889, Top 70th Acc: 0.5132, Bottom 30th Acc: 0.0938
Fold [5/5] Epoch [10/100] Initial Loss: 0.1373, Training Loss: 0.0310, Initial Validation Loss: 0.1290, Validation Loss: 0.0361,V Acc: 0.8241, Top 70th Acc: 0.9211, Bottom 30th Acc: 0.5938
Fold [5/5] Epoch [20/100] Initial Loss: 0.1373, Training Loss: 0.0238, Initial Validation Loss: 0.1290, Validation Loss: 0.0327,V Acc: 0.8333, Top 70th Acc: 0.9079, Bottom 30th Acc: 0.6562
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.9078947368421053
Running train_nn.py with seed 92
CUDA:False
Training samples count:  550
Training on 20 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1362, Training Loss: 0.1362, Initial Validation Loss: 0.1334, Validation Loss: 0.1334,V Acc: 0.3750, Top 70th Acc: 0.4684, Bottom 30th Acc: 0.1515
Fold [1/5] Epoch [10/100] Initial Loss: 0.1362, Training Loss: 0.0533, Initial Validation Loss: 0.1334, Validation Loss: 0.0589,V Acc: 0.7232, Top 70th Acc: 0.8481, Bottom 30th Acc: 0.4242
Fold [1/5] Epoch [20/100] Initial Loss: 0.1362, Training Loss: 0.0314, Initial Validation Loss: 0.1334, Validation Loss: 0.0400,V Acc: 0.7946, Top 70th Acc: 0.9494, Bottom 30th Acc: 0.4242
Fold [1/5] Epoch [30/100] Initial Loss: 0.1362, Training Loss: 0.0249, Initial Validation Loss: 0.1334, Validation Loss: 0.0344,V Acc: 0.8214, Top 70th Acc: 0.9114, Bottom 30th Acc: 0.6061
Fold [1/5] Epoch [40/100] Initial Loss: 0.1362, Training Loss: 0.0228, Initial Validation Loss: 0.1334, Validation Loss: 0.0312,V Acc: 0.8661, Top 70th Acc: 0.9747, Bottom 30th Acc: 0.6061
Fold [1/5] Epoch [50/100] Initial Loss: 0.1362, Training Loss: 0.0214, Initial Validation Loss: 0.1334, Validation Loss: 0.0297,V Acc: 0.8482, Top 70th Acc: 0.9747, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 54  Rolling back to Epoch (base 0): 49  Top Validation Acc: 0.9493670886075949
Fold [2/5] Epoch [0/100] Initial Loss: 0.1396, Training Loss: 0.1396, Initial Validation Loss: 0.1289, Validation Loss: 0.1289,V Acc: 0.3604, Top 70th Acc: 0.4231, Bottom 30th Acc: 0.2121
Fold [2/5] Epoch [10/100] Initial Loss: 0.1396, Training Loss: 0.0347, Initial Validation Loss: 0.1289, Validation Loss: 0.0427,V Acc: 0.8018, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.4848
Fold [2/5] Epoch [20/100] Initial Loss: 0.1396, Training Loss: 0.0231, Initial Validation Loss: 0.1289, Validation Loss: 0.0352,V Acc: 0.8649, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 28  Rolling back to Epoch (base 0): 23  Top Validation Acc: 0.9358974358974359
Fold [3/5] Epoch [0/100] Initial Loss: 0.1379, Training Loss: 0.1379, Initial Validation Loss: 0.1314, Validation Loss: 0.1314,V Acc: 0.4091, Top 70th Acc: 0.4935, Bottom 30th Acc: 0.2121
Fold [3/5] Epoch [10/100] Initial Loss: 0.1379, Training Loss: 0.0393, Initial Validation Loss: 0.1314, Validation Loss: 0.0460,V Acc: 0.8182, Top 70th Acc: 0.8701, Bottom 30th Acc: 0.6970
Fold [3/5] Epoch [20/100] Initial Loss: 0.1379, Training Loss: 0.0254, Initial Validation Loss: 0.1314, Validation Loss: 0.0351,V Acc: 0.8273, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.5455
Fold [3/5] Epoch [30/100] Initial Loss: 0.1379, Training Loss: 0.0215, Initial Validation Loss: 0.1314, Validation Loss: 0.0326,V Acc: 0.8182, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.4848
Stopping early at Epoch (base 0): 34  Rolling back to Epoch (base 0): 29  Top Validation Acc: 0.948051948051948
Fold [4/5] Epoch [0/100] Initial Loss: 0.1425, Training Loss: 0.1425, Initial Validation Loss: 0.1332, Validation Loss: 0.1332,V Acc: 0.3761, Top 70th Acc: 0.4286, Bottom 30th Acc: 0.2500
Fold [4/5] Epoch [10/100] Initial Loss: 0.1425, Training Loss: 0.0337, Initial Validation Loss: 0.1332, Validation Loss: 0.0424,V Acc: 0.7982, Top 70th Acc: 0.8961, Bottom 30th Acc: 0.5625
Fold [4/5] Epoch [20/100] Initial Loss: 0.1425, Training Loss: 0.0235, Initial Validation Loss: 0.1332, Validation Loss: 0.0365,V Acc: 0.8349, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.6250
Stopping early at Epoch (base 0): 28  Rolling back to Epoch (base 0): 23  Top Validation Acc: 0.9090909090909091
Fold [5/5] Epoch [0/100] Initial Loss: 0.1382, Training Loss: 0.1382, Initial Validation Loss: 0.1303, Validation Loss: 0.1303,V Acc: 0.2500, Top 70th Acc: 0.3421, Bottom 30th Acc: 0.0312
Fold [5/5] Epoch [10/100] Initial Loss: 0.1382, Training Loss: 0.0327, Initial Validation Loss: 0.1303, Validation Loss: 0.0328,V Acc: 0.8426, Top 70th Acc: 0.9211, Bottom 30th Acc: 0.6562
Stopping early at Epoch (base 0): 18  Rolling back to Epoch (base 0): 13  Top Validation Acc: 0.9210526315789473
92 4 [array([0.3462297 , 0.12699038, 0.15020283, 0.23191603, 0.14466108],
      dtype=float32)]
Running train_nn.py with seed 93
CUDA:False
Training samples count:  550
Training on 20 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1405, Training Loss: 0.1405, Initial Validation Loss: 0.1366, Validation Loss: 0.1366,V Acc: 0.3929, Top 70th Acc: 0.5063, Bottom 30th Acc: 0.1212
Fold [1/5] Epoch [10/100] Initial Loss: 0.1405, Training Loss: 0.0395, Initial Validation Loss: 0.1366, Validation Loss: 0.0365,V Acc: 0.8750, Top 70th Acc: 0.9241, Bottom 30th Acc: 0.7576
Fold [2/5] Epoch [10/100] Initial Loss: 0.1392, Training Loss: 0.0301, Initial Validation Loss: 0.1327, Validation Loss: 0.0495,V Acc: 0.7568, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.3939
Fold [2/5] Epoch [20/100] Initial Loss: 0.1392, Training Loss: 0.0048, Initial Validation Loss: 0.1327, Validation Loss: 0.0296,V Acc: 0.8649, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.6364
Fold [2/5] Epoch [30/100] Initial Loss: 0.1392, Training Loss: 0.0036, Initial Validation Loss: 0.1327, Validation Loss: 0.0280,V Acc: 0.8739, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 35  Rolling back to Epoch (base 0): 30  Top Validation Acc: 0.9487179487179487
Fold [3/5] Epoch [0/100] Initial Loss: 0.1378, Training Loss: 0.1378, Initial Validation Loss: 0.1362, Validation Loss: 0.1362,V Acc: 0.2545, Top 70th Acc: 0.3636, Bottom 30th Acc: 0.0000
Fold [3/5] Epoch [10/100] Initial Loss: 0.1378, Training Loss: 0.0193, Initial Validation Loss: 0.1362, Validation Loss: 0.0360,V Acc: 0.8636, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.7273
Fold [3/5] Epoch [20/100] Initial Loss: 0.1378, Training Loss: 0.0048, Initial Validation Loss: 0.1362, Validation Loss: 0.0320,V Acc: 0.8818, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.7576
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.9090909090909091
Fold [4/5] Epoch [0/100] Initial Loss: 0.1399, Training Loss: 0.1399, Initial Validation Loss: 0.1366, Validation Loss: 0.1366,V Acc: 0.3945, Top 70th Acc: 0.4675, Bottom 30th Acc: 0.2188
Fold [4/5] Epoch [10/100] Initial Loss: 0.1399, Training Loss: 0.0129, Initial Validation Loss: 0.1366, Validation Loss: 0.0278,V Acc: 0.8899, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.7188
Fold [4/5] Epoch [20/100] Initial Loss: 0.1399, Training Loss: 0.0048, Initial Validation Loss: 0.1366, Validation Loss: 0.0225,V Acc: 0.8991, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.7188
Fold [4/5] Epoch [30/100] Initial Loss: 0.1399, Training Loss: 0.0040, Initial Validation Loss: 0.1366, Validation Loss: 0.0225,V Acc: 0.9174, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.8125
Stopping early at Epoch (base 0): 34  Rolling back to Epoch (base 0): 29  Top Validation Acc: 0.961038961038961
Fold [5/5] Epoch [0/100] Initial Loss: 0.1402, Training Loss: 0.1402, Initial Validation Loss: 0.1316, Validation Loss: 0.1316,V Acc: 0.2500, Top 70th Acc: 0.3158, Bottom 30th Acc: 0.0938
Fold [5/5] Epoch [10/100] Initial Loss: 0.1402, Training Loss: 0.0282, Initial Validation Loss: 0.1316, Validation Loss: 0.0392,V Acc: 0.8426, Top 70th Acc: 0.9079, Bottom 30th Acc: 0.6875
Fold [5/5] Epoch [20/100] Initial Loss: 0.1402, Training Loss: 0.0056, Initial Validation Loss: 0.1316, Validation Loss: 0.0269,V Acc: 0.8704, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.6875
Fold [5/5] Epoch [30/100] Initial Loss: 0.1402, Training Loss: 0.0041, Initial Validation Loss: 0.1316, Validation Loss: 0.0268,V Acc: 0.8796, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.7188
Fold [5/5] Epoch [40/100] Initial Loss: 0.1402, Training Loss: 0.0039, Initial Validation Loss: 0.1316, Validation Loss: 0.0268,V Acc: 0.8796, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.7188
Stopping early at Epoch (base 0): 40  Rolling back to Epoch (base 0): 35  Top Validation Acc: 0.9473684210526315
Running train_nn.py with seed 71
CUDA:False
Training samples count:  550
Training on 162 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1364, Training Loss: 0.1364, Initial Validation Loss: 0.1326, Validation Loss: 0.1326,V Acc: 0.3482, Top 70th Acc: 0.4051, Bottom 30th Acc: 0.2121
Fold [1/5] Epoch [10/100] Initial Loss: 0.1364, Training Loss: 0.0223, Initial Validation Loss: 0.1326, Validation Loss: 0.0352,V Acc: 0.8304, Top 70th Acc: 0.9367, Bottom 30th Acc: 0.5758
Fold [1/5] Epoch [20/100] Initial Loss: 0.1364, Training Loss: 0.0051, Initial Validation Loss: 0.1326, Validation Loss: 0.0247,V Acc: 0.8661, Top 70th Acc: 0.9620, Bottom 30th Acc: 0.6364
Fold [1/5] Epoch [30/100] Initial Loss: 0.1364, Training Loss: 0.0039, Initial Validation Loss: 0.1326, Validation Loss: 0.0255,V Acc: 0.8839, Top 70th Acc: 0.9494, Bottom 30th Acc: 0.7273
Stopping early at Epoch (base 0): 32  Rolling back to Epoch (base 0): 27  Top Validation Acc: 0.9493670886075949
Fold [2/5] Epoch [0/100] Initial Loss: 0.1391, Training Loss: 0.1391, Initial Validation Loss: 0.1313, Validation Loss: 0.1313,V Acc: 0.2793, Top 70th Acc: 0.3974, Bottom 30th Acc: 0.0000
Fold [2/5] Epoch [10/100] Initial Loss: 0.1391, Training Loss: 0.0173, Initial Validation Loss: 0.1313, Validation Loss: 0.0403,V Acc: 0.7748, Top 70th Acc: 0.8846, Bottom 30th Acc: 0.5152
Fold [2/5] Epoch [20/100] Initial Loss: 0.1391, Training Loss: 0.0056, Initial Validation Loss: 0.1313, Validation Loss: 0.0364,V Acc: 0.7838, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.3939
Fold [2/5] Epoch [30/100] Initial Loss: 0.1391, Training Loss: 0.0044, Initial Validation Loss: 0.1313, Validation Loss: 0.0336,V Acc: 0.8108, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.5152
Fold [2/5] Epoch [40/100] Initial Loss: 0.1391, Training Loss: 0.0039, Initial Validation Loss: 0.1313, Validation Loss: 0.0318,V Acc: 0.8198, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.5455
Fold [2/5] Epoch [50/100] Initial Loss: 0.1391, Training Loss: 0.0037, Initial Validation Loss: 0.1313, Validation Loss: 0.0305,V Acc: 0.8288, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.5758
Fold [2/5] Epoch [60/100] Initial Loss: 0.1391, Training Loss: 0.0036, Initial Validation Loss: 0.1313, Validation Loss: 0.0296,V Acc: 0.8468, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.6061
Fold [2/5] Epoch [70/100] Initial Loss: 0.1391, Training Loss: 0.0036, Initial Validation Loss: 0.1313, Validation Loss: 0.0288,V Acc: 0.8468, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 73  Rolling back to Epoch (base 0): 68  Top Validation Acc: 0.9487179487179487
Fold [3/5] Epoch [0/100] Initial Loss: 0.1396, Training Loss: 0.1396, Initial Validation Loss: 0.1305, Validation Loss: 0.1305,V Acc: 0.2545, Top 70th Acc: 0.3506, Bottom 30th Acc: 0.0303
Fold [3/5] Epoch [10/100] Initial Loss: 0.1396, Training Loss: 0.0211, Initial Validation Loss: 0.1305, Validation Loss: 0.0321,V Acc: 0.8545, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.6061
Fold [3/5] Epoch [20/100] Initial Loss: 0.1396, Training Loss: 0.0051, Initial Validation Loss: 0.1305, Validation Loss: 0.0228,V Acc: 0.8636, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.6061
Fold [3/5] Epoch [30/100] Initial Loss: 0.1396, Training Loss: 0.0040, Initial Validation Loss: 0.1305, Validation Loss: 0.0220,V Acc: 0.8636, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 36  Rolling back to Epoch (base 0): 31  Top Validation Acc: 0.974025974025974
71 2 [array([0.29326245, 0.07761048, 0.07549439, 0.26361066, 0.2900221 ],
      dtype=float32)]
Fold [4/5] Epoch [0/100] Initial Loss: 0.1372, Training Loss: 0.1372, Initial Validation Loss: 0.1380, Validation Loss: 0.1380,V Acc: 0.3578, Top 70th Acc: 0.4675, Bottom 30th Acc: 0.0938
Fold [4/5] Epoch [10/100] Initial Loss: 0.1372, Training Loss: 0.0274, Initial Validation Loss: 0.1380, Validation Loss: 0.0470,V Acc: 0.7706, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.4375
Fold [4/5] Epoch [20/100] Initial Loss: 0.1372, Training Loss: 0.0060, Initial Validation Loss: 0.1380, Validation Loss: 0.0328,V Acc: 0.8716, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6875
Fold [4/5] Epoch [30/100] Initial Loss: 0.1372, Training Loss: 0.0040, Initial Validation Loss: 0.1380, Validation Loss: 0.0304,V Acc: 0.8716, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6875
Fold [4/5] Epoch [40/100] Initial Loss: 0.1372, Training Loss: 0.0035, Initial Validation Loss: 0.1380, Validation Loss: 0.0298,V Acc: 0.8716, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.6250
Fold [4/5] Epoch [50/100] Initial Loss: 0.1372, Training Loss: 0.0033, Initial Validation Loss: 0.1380, Validation Loss: 0.0295,V Acc: 0.8716, Top 70th Acc: 0.9870, Bottom 30th Acc: 0.5938
Fold [4/5] Epoch [60/100] Initial Loss: 0.1372, Training Loss: 0.0032, Initial Validation Loss: 0.1380, Validation Loss: 0.0293,V Acc: 0.8624, Top 70th Acc: 0.9870, Bottom 30th Acc: 0.5625
Stopping early at Epoch (base 0): 
Fold [4/5] Epoch [20/100] Initial Loss: 0.1389, Training Loss: 0.0778, Initial Validation Loss: 0.1334, Validation Loss: 0.0822,V Acc: 0.6330, Top 70th Acc: 0.7403, Bottom 30th Acc: 0.3750
Fold [4/5] Epoch [30/100] Initial Loss: 0.1389, Training Loss: 0.0774, Initial Validation Loss: 0.1334, Validation Loss: 0.0817,V Acc: 0.6239, Top 70th Acc: 0.7403, Bottom 30th Acc: 0.3438
Stopping early at Epoch (base 0): 34  Rolling back to Epoch (base 0): 29  Top Validation Acc: 0.7532467532467533
Fold [5/5] Epoch [0/100] Initial Loss: 0.1332, Training Loss: 0.1332, Initial Validation Loss: 0.1191, Validation Loss: 0.1191,V Acc: 0.3426, Top 70th Acc: 0.3816, Bottom 30th Acc: 0.2500
Fold [5/5] Epoch [10/100] Initial Loss: 0.1332, Training Loss: 0.0833, Initial Validation Loss: 0.1191, Validation Loss: 0.0739,V Acc: 0.6574, Top 70th Acc: 0.6842, Bottom 30th Acc: 0.5938
Fold [5/5] Epoch [20/100] Initial Loss: 0.1332, Training Loss: 0.0804, Initial Validation Loss: 0.1191, Validation Loss: 0.0724,V Acc: 0.6389, Top 70th Acc: 0.7105, Bottom 30th Acc: 0.4688
Fold [5/5] Epoch [30/100] Initial Loss: 0.1332, Training Loss: 0.0799, Initial Validation Loss: 0.1191, Validation Loss: 0.0711,V Acc: 0.6574, Top 70th Acc: 0.7105, Bottom 30th Acc: 0.5312
Stopping early at Epoch (base 0): 32  Rolling back to Epoch (base 0): 27  Top Validation Acc: 0.7236842105263158
92 4 [array([0.13341519, 0.35243687, 0.14636977, 0.21568418, 0.15209396],
      dtype=float32)]
Running train_nn.py with seed 93
CUDA:False
Training samples count:  550
Training on 2 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1372, Training Loss: 0.1372, Initial Validation Loss: 0.1286, Validation Loss: 0.1286,V Acc: 0.6161, Top 70th Acc: 0.6456, Bottom 30th Acc: 0.5455
Fold [1/5] Epoch [10/100] Initial Loss: 0.1372, Training Loss: 0.0830, Initial Validation Loss: 0.1286, Validation Loss: 0.0688,V Acc: 0.6786, Top 70th Acc: 0.8734, Bottom 30th Acc: 0.2121
Fold [1/5] Epoch [20/100] Initial Loss: 0.1372, Training Loss: 0.0820, Initial Validation Loss: 0.1286, Validation Loss: 0.0682,V Acc: 0.6786, Top 70th Acc: 0.8101, Bottom 30th Acc: 0.3636
Fold [1/5] Epoch [30/100] Initial Loss: 0.1372, Training Loss: 0.0814, Initial Validation Loss: 0.1286, Validation Loss: 0.0664,V Acc: 0.6875, Top 70th Acc: 0.8734, Bottom 30th Acc: 0.2424
Stopping early at Epoch (base 0): 39  Rolling back to Epoch (base 0): 34  Top Validation Acc: 0.8354430379746836
Fold [2/5] Epoch [0/100] Initial Loss: 0.1383, Training Loss: 0.1383, Initial Validation Loss: 0.1276, Validation Loss: 0.1276,V Acc: 0.4775, Top 70th Acc: 0.5513, Bottom 30th Acc: 0.3030
Fold [2/5] Epoch [10/100] Initial Loss: 0.1383, Training Loss: 0.0786, Initial Validation Loss: 0.1276, Validation Loss: 0.0865,V Acc: 0.5586, Top 70th Acc: 0.6923, Bottom 30th Acc: 0.2424
Fold [2/5] Epoch [20/100] Initial Loss: 0.1383, Training Loss: 0.0768, Initial Validation Loss: 0.1276, Validation Loss: 0.0845,V Acc: 0.6216, Top 70th Acc: 0.6923, Bottom 30th Acc: 0.4545
Stopping early at Epoch (base 0): 22  Rolling back to Epoch (base 0): 17  Top Validation Acc: 0.6923076923076923
Fold [3/5] Epoch [0/100] Initial Loss: 0.1322, Training Loss: 0.1322, Initial Validation Loss: 0.1226, Validation Loss: 0.1226,V Acc: 0.3909, Top 70th Acc: 0.4805, Bottom 30th Acc: 0.1818
Fold [3/5] Epoch [10/100] Initial Loss: 0.1322, Training Loss: 0.0784, Initial Validation Loss: 0.1226, Validation Loss: 0.0856,V Acc: 0.6091, Top 70th Acc: 0.7273, Bottom 30th Acc: 0.3333
Fold [3/5] Epoch [20/100] Initial Loss: 0.1322, Training Loss: 0.0762, Initial Validation Loss: 0.1226, Validation Loss: 0.0842,V Acc: 0.5909, Top 70th Acc: 0.7273, Bottom 30th Acc: 0.2727
Fold [3/5] Epoch [30/100] Initial Loss: 0.1322, Training Loss: 0.0756, Initial Validation Loss: 0.1226, Validation Loss: 0.0846,V Acc: 0.5818, Top 70th Acc: 0.7143, Bottom 30th Acc: 0.2727
Stopping early at Epoch (base 0): 38  Rolling back to Epoch (base 0): 33  Top Validation Acc: 0.7272727272727273
93 2 [array([0.15577948, 0.33937007, 0.10729802, 0.23674124, 0.16081119],
      dtype=float32)]
Fold [4/5] Epoch [0/100] Initial Loss: 0.1406, Training Loss: 0.1406, Initial Validation Loss: 0.1264, Validation Loss: 0.1264,V Acc: 0.3670, Top 70th Acc: 0.3506, Bottom 30th Acc: 0.4062
Fold [4/5] Epoch [10/100] Initial Loss: 0.1406, Training Loss: 0.0799, Initial Validation Loss: 0.1264, Validation Loss: 0.0786,V Acc: 0.6239, Top 70th Acc: 0.7013, Bottom 30th Acc: 0.4375
Stopping early at Epoch (base 0): 17  Rolling back to Epoch (base 0): 12  Top Validation Acc: 0.7012987012987013
Fold [5/5] Epoch [0/100] Initial Loss: 0.1379, Training Loss: 0.1379, Initial Validation Loss: 0.1299, Validation Loss: 0.1299,V Acc: 0.3519, Top 70th Acc: 0.3421, Bottom 30th Acc: 0.3750
Fold [5/5] Epoch [10/100] Initial Loss: 0.1379, Training Loss: 0.0821, Initial Validation Loss: 0.1299, Validation Loss: 0.0781,V Acc: 0.6481, Top 70th Acc: 0.7368, Bottom 30th Acc: 0.4375
Fold [5/5] Epoch [20/100] Initial Loss: 0.1379, Training Loss: 0.0797, Initial Validation Loss: 0.1299, Validation Loss: 0.0751,V Acc: 0.6481, Top 70th Acc: 0.7368, Bottom 30th Acc: 0.4375
Fold [5/5] Epoch [30/100] Initial Loss: 0.1379, Training Loss: 0.0791, Initial Validation Loss: 0.1299, Validation Loss: 0.0751,V Acc: 0.6481, Top 70th Acc: 0.7500, Bottom 30th Acc: 0.4062
Stopping early at Epoch (base 0): 34  Rolling back to Epoch (base 0): 29  Top Validation Acc: 0.75
Running train_nn.py with seed 94
CUDA:False
Training samples count:  550
Training on 2 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1340, Training Loss: 0.1340, Initial Validation Loss: 0.1303, Validation Loss: 0.1303,V Acc: 0.3929, Top 70th Acc: 0.5063, Bottom 30th Acc: 0.1212
Fold [1/5] Epoch [10/100] Initial Loss: 0.1340, Training Loss: 0.0799, Initial Validation Loss: 0.1303, Validation Loss: 0.0830,V Acc: 0.6250, Top 70th Acc: 0.7468, Bottom 30th Acc: 0.3333
Fold [1/5] Epoch [20/100] Initial Loss: 0.1340, Training Loss: 0.0784, Initial Validation Loss: 0.1303, Validation Loss: 0.0811,V Acc: 0.6429, Top 70th Acc: 0.7468, Bottom 30th Acc: 0.3939
Stopping early at Epoch (base 0): 28  Rolling back to Epoch (base 0): 23  Top Validation Acc: 0.759493670886076
Fold [2/5] Epoch [0/100] Initial Loss: 0.1310, Training Loss: 0.1310, Initial Validation Loss: 0.1153, Validation Loss: 0.1153,V Acc: 0.4324, Top 70th Acc: 0.5513, Bottom 30th Acc: 0.1515
Fold [2/5] Epoch [10/100] Initial Loss: 0.1310, Training Loss: 0.0809, Initial Validation Loss: 0.1153, Validation Loss: 0.0789,V Acc: 0.6036, Top 70th Acc: 0.7179, Bottom 30th Acc: 0.3333
Fold [2/5] Epoch [20/100] Initial Loss: 0.1310, Training Loss: 0.0789, Initial Validation Loss: 0.1153, Validation Loss: 0.0772,V Acc: 0.6126, Top 70th Acc: 0.7051, Bottom 30th Acc: 0.3939
Fold [2/5] Epoch [30/100] Initial Loss: 0.1310, Training Loss: 0.0780, Initial Validation Loss: 0.1153, Validation Loss: 0.0769,V Acc: 0.6306, Top 70th Acc: 0.7051, Bottom 30th Acc: 0.4545
Stopping early at Epoch (base 0): 32  Rolling back to Epoch (base 0): 27  Top Validation Acc: 0.6923076923076923
Fold [3/5] Epoch [0/100] Initial Loss: 0.1392, Training Loss: 0.1392, Initial Validation Loss: 0.1266, Validation Loss: 0.1266,V Acc: 0.4182, Top 70th Acc: 0.5455, Bottom 30th Acc: 0.1212
Fold [3/5] Epoch [10/100] Initial Loss: 0.1392, Training Loss: 0.0819, Initial Validation Loss: 0.1266, Validation Loss: 0.0760,V Acc: 0.6455, Top 70th Acc: 0.7922, Bottom 30th Acc: 0.3030
Fold [3/5] Epoch [20/100] Initial Loss: 0.1392, Training Loss: 0.0803, Initial Validation Loss: 0.1266, Validation Loss: 0.0742,V Acc: 0.6727, Top 70th Acc: 0.8052, Bottom 30th Acc: 0.3636
Stopping early at Epoch (base 0): 27  Rolling back to Epoch (base 0): 22  Top Validation Acc: 0.8051948051948052
Fold [4/5] Epoch [0/100] Initial Loss: 0.1393, Training Loss: 0.1393, Initial Validation Loss: 0.1235, Validation Loss: 0.1235,V Acc: 0.3119, Top 70th Acc: 0.3896, Bottom 30th Acc: 0.1250
Fold [4/5] Epoch [10/100] Initial Loss: 0.1393, Training Loss: 0.0822, Initial Validation Loss: 0.1235, Validation Loss: 0.0750,V Acc: 0.6330, Top 70th Acc: 0.7532, Bottom 30th Acc: 0.3438
Fold [4/5] Epoch [20/100] Initial Loss: 0.1393, Training Loss: 0.0802, Initial Validation Loss: 0.1235, Validation Loss: 0.0723,V Acc: 0.6330, Top 70th Acc: 0.7532, Bottom 30th Acc: 0.3438
Stopping early at Epoch (base 0): 36  Rolling back to Epoch (base 0): 31  Top Validation Acc: 0.9493670886075949
Fold [2/5] Epoch [0/100] Initial Loss: 0.1372, Training Loss: 0.1372, Initial Validation Loss: 0.1294, Validation Loss: 0.1294,V Acc: 0.3423, Top 70th Acc: 0.3462, Bottom 30th Acc: 0.3333
Fold [2/5] Epoch [10/100] Initial Loss: 0.1372, Training Loss: 0.0338, Initial Validation Loss: 0.1294, Validation Loss: 0.0354,V Acc: 0.8108, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.4848
Fold [2/5] Epoch [20/100] Initial Loss: 0.1372, Training Loss: 0.0160, Initial Validation Loss: 0.1294, Validation Loss: 0.0229,V Acc: 0.8559, Top 70th Acc: 1.0000, Bottom 30th Acc: 0.5152
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 1.0
Fold [3/5] Epoch [0/100] Initial Loss: 0.1400, Training Loss: 0.1400, Initial Validation Loss: 0.1344, Validation Loss: 0.1344,V Acc: 0.2636, Top 70th Acc: 0.2987, Bottom 30th Acc: 0.1818
Fold [3/5] Epoch [10/100] Initial Loss: 0.1400, Training Loss: 0.0295, Initial Validation Loss: 0.1344, Validation Loss: 0.0341,V Acc: 0.8636, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.6061
Fold [3/5] Epoch [20/100] Initial Loss: 0.1400, Training Loss: 0.0145, Initial Validation Loss: 0.1344, Validation Loss: 0.0288,V Acc: 0.8909, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.7273
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.948051948051948
Fold [4/5] Epoch [0/100] Initial Loss: 0.1406, Training Loss: 0.1406, Initial Validation Loss: 0.1294, Validation Loss: 0.1294,V Acc: 0.2936, Top 70th Acc: 0.3247, Bottom 30th Acc: 0.2188
Fold [4/5] Epoch [10/100] Initial Loss: 0.1406, Training Loss: 0.0251, Initial Validation Loss: 0.1294, Validation Loss: 0.0364,V Acc: 0.7706, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.4375
Fold [4/5] Epoch [20/100] Initial Loss: 0.1406, Training Loss: 0.0124, Initial Validation Loss: 0.1294, Validation Loss: 0.0323,V Acc: 0.8073, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.5312
Stopping early at Epoch (base 0): 22  Rolling back to Epoch (base 0): 17  Top Validation Acc: 0.9090909090909091
Fold [5/5] Epoch [0/100] Initial Loss: 0.1372, Training Loss: 0.1372, Initial Validation Loss: 0.1370, Validation Loss: 0.1370,V Acc: 0.3241, Top 70th Acc: 0.3158, Bottom 30th Acc: 0.3438
Fold [5/5] Epoch [10/100] Initial Loss: 0.1372, Training Loss: 0.0290, Initial Validation Loss: 0.1370, Validation Loss: 0.0406,V Acc: 0.8241, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.5625
Fold [5/5] Epoch [20/100] Initial Loss: 0.1372, Training Loss: 0.0151, Initial Validation Loss: 0.1370, Validation Loss: 0.0304,V Acc: 0.8796, Top 70th Acc: 0.9737, Bottom 30th Acc: 0.6562
Fold [5/5] Epoch [30/100] Initial Loss: 0.1372, Training Loss: 0.0122, Initial Validation Loss: 0.1370, Validation Loss: 0.0314,V Acc: 0.8519, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.5938
Stopping early at Epoch (base 0): 30  Rolling back to Epoch (base 0): 25  Top Validation Acc: 0.9605263157894737
94 4 [array([0.42600343, 0.04595885, 0.03105947, 0.08584309, 0.4111352 ],
      dtype=float32)]
Running train_nn.py with seed 95
CUDA:False
Training samples count:  550
Training on 40 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1412, Training Loss: 0.1412, Initial Validation Loss: 0.1317, Validation Loss: 0.1317,V Acc: 0.2857, Top 70th Acc: 0.2911, Bottom 30th Acc: 0.2727
Fold [1/5] Epoch [10/100] Initial Loss: 0.1412, Training Loss: 0.0261, Initial Validation Loss: 0.1317, Validation Loss: 0.0479,V Acc: 0.7411, Top 70th Acc: 0.8481, Bottom 30th Acc: 0.4848
Fold [1/5] Epoch [20/100] Initial Loss: 0.1412, Training Loss: 0.0126, Initial Validation Loss: 0.1317, Validation Loss: 0.0381,V Acc: 0.8125, Top 70th Acc: 0.8987, Bottom 30th Acc: 0.6061
Fold [1/5] Epoch [30/100] Initial Loss: 0.1412, Training Loss: 0.0102, Initial Validation Loss: 0.1317, Validation Loss: 0.0379,V Acc: 0.8214, Top 70th Acc: 0.9114, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 31  Rolling back to Epoch (base 0): 26  Top Validation Acc: 0.9113924050632911
Fold [2/5] Epoch [0/100] Initial Loss: 0.1356, Training Loss: 0.1356, Initial Validation Loss: 0.1331, Validation Loss: 0.1331,V Acc: 0.3964, Top 70th Acc: 0.4872, Bottom 30th Acc: 0.1818
Fold [2/5] Epoch [10/100] Initial Loss: 0.1356, Training Loss: 0.0320, Initial Validation Loss: 0.1331, Validation Loss: 0.0364,V Acc: 0.8378, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.6364
Fold [2/5] Epoch [20/100] Initial Loss: 0.1356, Training Loss: 0.0152, Initial Validation Loss: 0.1331, Validation Loss: 0.0294,V Acc: 0.8288, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.4848
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.9615384615384616
Fold [3/5] Epoch [0/100] Initial Loss: 0.1378, Training Loss: 0.1378, Initial Validation Loss: 0.1371, Validation Loss: 0.1371,V Acc: 0.2818, Top 70th Acc: 0.3506, Bottom 30th Acc: 0.1212
Fold [3/5] Epoch [10/100] Initial Loss: 0.1378, Training Loss: 0.0320, Initial Validation Loss: 0.1371, Validation Loss: 0.0334,V Acc: 0.8909, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.7576
Fold [3/5] Epoch [20/100] Initial Loss: 0.1378, Training Loss: 0.0158, Initial Validation Loss: 0.1371, Validation Loss: 0.0255,V Acc: 0.8909, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.7273
Fold [3/5] Epoch [30/100] Initial Loss: 0.1378, Training Loss: 0.0128, Initial Validation Loss: 0.1371, Validation Loss: 0.0236,V Acc: 0.8818, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.6667
Fold [3/5] Epoch [40/100] Initial Loss: 0.1378, Training Loss: 0.0118, Initial Validation Loss: 0.1371, Validation Loss: 0.0235,V Acc: 0.8818, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 49  Rolling back to Epoch (base 0): 44  Top Validation Acc: 0.974025974025974
Fold [4/5] Epoch [0/100] Initial Loss: 0.1398, Training Loss: 0.1398, Initial Validation Loss: 0.1327, Validation Loss: 0.1327,V Acc: 0.2936, Top 70th Acc: 0.3117, Bottom 30th Acc: 0.2500
Fold [4/5] Epoch [10/100] Initial Loss: 0.1398, Training Loss: 0.0385, Initial Validation Loss: 0.1327, Validation Loss: 0.0417,V Acc: 0.7982, Top 70th Acc: 0.8961, Bottom 30th Acc: 0.5625
Fold [4/5] Epoch [20/100] Initial Loss: 0.1398, Training Loss: 0.0162, Initial Validation Loss: 0.1327, Validation Loss: 0.0257,V Acc: 0.8257, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.5312
Fold [4/5] Epoch [30/100] Initial Loss: 0.1398, Training Loss: 0.0131, Initial Validation Loss: 0.1327, Validation Loss: 0.0250,V Acc: 0.8532, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6250
Fold [4/5] Epoch [40/100] Initial Loss: 0.1398, Training Loss: 0.0118, Initial Validation Loss: 0.1327, Validation Loss: 0.0245,V Acc: 0.8532, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.5938
Stopping early at Epoch (base 0): 47  Rolling back to Epoch (base 0): 42  Top Validation Acc: 0.961038961038961
Fold [5/5] Epoch [0/100] Initial Loss: 0.1369, Training Loss: 0.1369, Initial Validation Loss: 0.1259, Validation Loss: 0.1259,V Acc: 0.4167, Top 70th Acc: 0.4605, Bottom 30th Acc: 0.3125
Fold [5/5] Epoch [10/100] Initial Loss: 0.1369, Training Loss: 0.0363, Initial Validation Loss: 0.1259, Validation Loss: 0.0499,V Acc: 0.6944, Top 70th Acc: 0.8816, Bottom 30th Acc: 0.2500
Fold [5/5] Epoch [20/100] Initial Loss: 0.1369, Training Loss: 0.0146, Initial Validation Loss: 0.1259, Validation Loss: 0.0372,V Acc: 0.7778, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.3750
Fold [5/5] Epoch [30/100] Initial Loss: 0.1369, Training Loss: 0.0110, Initial Validation Loss: 0.1259, Validation Loss: 0.0366,V Acc: 0.7778, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.4062
Stopping early at Epoch (base 0): 34  Rolling back to Epoch (base 0): 29  Top Validation Acc: 0.9342105263157895
95 4 [array([0.8110238 , 0.01467579, 0.02970918, 0.09180432, 0.0527869 ],
      dtype=float32)]
Running train_nn.py with seed 96
CUDA:False
Training samples count:  550
Training on 40 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1377, Training Loss: 0.1377, Initial Validation Loss: 0.1380, Validation Loss: 0.1380,V Acc: 0.3482, Top 70th Acc: 0.3924, Bottom 30th Acc: 0.2424
Fold [1/5] Epoch [10/100] Initial Loss: 0.1377, Training Loss: 0.0389, Initial Validation Loss: 0.1380, Validation Loss: 0.0390,V Acc: 0.8304, Top 70th Acc: 0.9241, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 33  Rolling back to Epoch (base 0): 28  Top Validation Acc: 0.974025974025974
Fold [5/5] Epoch [0/100] Initial Loss: 0.1401, Training Loss: 0.1401, Initial Validation Loss: 0.1339, Validation Loss: 0.1339,V Acc: 0.2407, Top 70th Acc: 0.2632, Bottom 30th Acc: 0.1875
Fold [5/5] Epoch [10/100] Initial Loss: 0.1401, Training Loss: 0.0360, Initial Validation Loss: 0.1339, Validation Loss: 0.0387,V Acc: 0.8519, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.6250
Fold [5/5] Epoch [20/100] Initial Loss: 0.1401, Training Loss: 0.0183, Initial Validation Loss: 0.1339, Validation Loss: 0.0237,V Acc: 0.8981, Top 70th Acc: 0.9868, Bottom 30th Acc: 0.6875
Stopping early at Epoch (base 0): 28  Rolling back to Epoch (base 0): 23  Top Validation Acc: 0.9868421052631579
Running train_nn.py with seed 91
CUDA:False
Training samples count:  550
Training on 30 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1416, Training Loss: 0.1416, Initial Validation Loss: 0.1350, Validation Loss: 0.1350,V Acc: 0.2946, Top 70th Acc: 0.3418, Bottom 30th Acc: 0.1818
Fold [1/5] Epoch [10/100] Initial Loss: 0.1416, Training Loss: 0.0387, Initial Validation Loss: 0.1350, Validation Loss: 0.0433,V Acc: 0.8125, Top 70th Acc: 0.8987, Bottom 30th Acc: 0.6061
Fold [1/5] Epoch [20/100] Initial Loss: 0.1416, Training Loss: 0.0193, Initial Validation Loss: 0.1350, Validation Loss: 0.0341,V Acc: 0.8036, Top 70th Acc: 0.9620, Bottom 30th Acc: 0.4242
Stopping early at Epoch (base 0): 22  Rolling back to Epoch (base 0): 17  Top Validation Acc: 0.9493670886075949
91 0 [array([0.62210166, 0.06073413, 0.06095546, 0.15626973, 0.09993901],
      dtype=float32)]
Fold [2/5] Epoch [0/100] Initial Loss: 0.1408, Training Loss: 0.1408, Initial Validation Loss: 0.1287, Validation Loss: 0.1287,V Acc: 0.2613, Top 70th Acc: 0.3205, Bottom 30th Acc: 0.1212
Fold [2/5] Epoch [10/100] Initial Loss: 0.1408, Training Loss: 0.0291, Initial Validation Loss: 0.1287, Validation Loss: 0.0413,V Acc: 0.7928, Top 70th Acc: 0.8590, Bottom 30th Acc: 0.6364
Fold [2/5] Epoch [20/100] Initial Loss: 0.1408, Training Loss: 0.0175, Initial Validation Loss: 0.1287, Validation Loss: 0.0377,V Acc: 0.8018, Top 70th Acc: 0.8846, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.8589743589743589
Fold [3/5] Epoch [0/100] Initial Loss: 0.1396, Training Loss: 0.1396, Initial Validation Loss: 0.1369, Validation Loss: 0.1369,V Acc: 0.3273, Top 70th Acc: 0.3117, Bottom 30th Acc: 0.3636
Fold [3/5] Epoch [10/100] Initial Loss: 0.1396, Training Loss: 0.0347, Initial Validation Loss: 0.1369, Validation Loss: 0.0413,V Acc: 0.8273, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.6061
Fold [3/5] Epoch [20/100] Initial Loss: 0.1396, Training Loss: 0.0196, Initial Validation Loss: 0.1369, Validation Loss: 0.0321,V Acc: 0.8545, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.961038961038961
Fold [4/5] Epoch [0/100] Initial Loss: 0.1392, Training Loss: 0.1392, Initial Validation Loss: 0.1371, Validation Loss: 0.1371,V Acc: 0.2477, Top 70th Acc: 0.3247, Bottom 30th Acc: 0.0625
Fold [4/5] Epoch [10/100] Initial Loss: 0.1392, Training Loss: 0.0352, Initial Validation Loss: 0.1371, Validation Loss: 0.0387,V Acc: 0.8165, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.5000
Fold [4/5] Epoch [20/100] Initial Loss: 0.1392, Training Loss: 0.0214, Initial Validation Loss: 0.1371, Validation Loss: 0.0312,V Acc: 0.8532, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.5625
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.974025974025974
Fold [5/5] Epoch [0/100] Initial Loss: 0.1382, Training Loss: 0.1382, Initial Validation Loss: 0.1298, Validation Loss: 0.1298,V Acc: 0.4074, Top 70th Acc: 0.4474, Bottom 30th Acc: 0.3125
Fold [5/5] Epoch [10/100] Initial Loss: 0.1382, Training Loss: 0.0346, Initial Validation Loss: 0.1298, Validation Loss: 0.0376,V Acc: 0.8148, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.5000
Fold [5/5] Epoch [20/100] Initial Loss: 0.1382, Training Loss: 0.0204, Initial Validation Loss: 0.1298, Validation Loss: 0.0288,V Acc: 0.8519, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.6250
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.9342105263157895
Running train_nn.py with seed 92
CUDA:False
Training samples count:  550
Training on 30 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1394, Training Loss: 0.1394, Initial Validation Loss: 0.1367, Validation Loss: 0.1367,V Acc: 0.2500, Top 70th Acc: 0.3544, Bottom 30th Acc: 0.0000
Fold [1/5] Epoch [10/100] Initial Loss: 0.1394, Training Loss: 0.0490, Initial Validation Loss: 0.1367, Validation Loss: 0.0484,V Acc: 0.7500, Top 70th Acc: 0.8861, Bottom 30th Acc: 0.4242
Fold [1/5] Epoch [20/100] Initial Loss: 0.1394, Training Loss: 0.0244, Initial Validation Loss: 0.1367, Validation Loss: 0.0311,V Acc: 0.8393, Top 70th Acc: 0.9620, Bottom 30th Acc: 0.5455
Fold [1/5] Epoch [30/100] Initial Loss: 0.1394, Training Loss: 0.0168, Initial Validation Loss: 0.1367, Validation Loss: 0.0287,V Acc: 0.8482, Top 70th Acc: 0.9873, Bottom 30th Acc: 0.5152
Stopping early at Epoch (base 0): 37  Rolling back to Epoch (base 0): 32  Top Validation Acc: 0.9620253164556962
Fold [2/5] Epoch [0/100] Initial Loss: 0.1414, Training Loss: 0.1414, Initial Validation Loss: 0.1326, Validation Loss: 0.1326,V Acc: 0.3333, Top 70th Acc: 0.3718, Bottom 30th Acc: 0.2424
Fold [2/5] Epoch [10/100] Initial Loss: 0.1414, Training Loss: 0.0439, Initial Validation Loss: 0.1326, Validation Loss: 0.0557,V Acc: 0.7297, Top 70th Acc: 0.8590, Bottom 30th Acc: 0.4242
Fold [2/5] Epoch [20/100] Initial Loss: 0.1414, Training Loss: 0.0201, Initial Validation Loss: 0.1326, Validation Loss: 0.0340,V Acc: 0.8559, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 29  Rolling back to Epoch (base 0): 24  Top Validation Acc: 0.9358974358974359
Fold [3/5] Epoch [0/100] Initial Loss: 0.1362, Training Loss: 0.1362, Initial Validation Loss: 0.1310, Validation Loss: 0.1310,V Acc: 0.4455, Top 70th Acc: 0.5195, Bottom 30th Acc: 0.2727
Fold [3/5] Epoch [10/100] Initial Loss: 0.1362, Training Loss: 0.0278, Initial Validation Loss: 0.1310, Validation Loss: 0.0319,V Acc: 0.8455, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.5455
Fold [3/5] Epoch [20/100] Initial Loss: 0.1362, Training Loss: 0.0191, Initial Validation Loss: 0.1310, Validation Loss: 0.0267,V Acc: 0.8636, Top 70th Acc: 0.9870, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 27  Rolling back to Epoch (base 0): 22  Top Validation Acc: 0.987012987012987
Fold [4/5] Epoch [0/100] Initial Loss: 0.1389, Training Loss: 0.1389, Initial Validation Loss: 0.1345, Validation Loss: 0.1345,V Acc: 0.2936, Top 70th Acc: 0.3506, Bottom 30th Acc: 0.1562
Fold [4/5] Epoch [10/100] Initial Loss: 0.1389, Training Loss: 0.0229, Initial Validation Loss: 0.1345, Validation Loss: 0.0376,V Acc: 0.8440, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.6250
Stopping early at Epoch (base 0): 19  Rolling back to Epoch (base 0): 14  Top Validation Acc: 0.922077922077922
Fold [5/5] Epoch [0/100] Initial Loss: 0.1418, Training Loss: 0.1418, Initial Validation Loss: 0.1331, Validation Loss: 0.1331,V Acc: 0.3426, Top 70th Acc: 0.3553, Bottom 30th Acc: 0.3125
Fold [5/5] Epoch [10/100] Initial Loss: 0.1418, Training Loss: 0.0380, Initial Validation Loss: 0.1331, Validation Loss: 0.0386,V Acc: 0.7685, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.3750
Fold [5/5] Epoch [20/100] Initial Loss: 0.1418, Training Loss: 0.0199, Initial Validation Loss: 0.1331, Validation Loss: 0.0240,V Acc: 0.8704, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.6562
Fold [5/5] Epoch [30/100] Initial Loss: 0.1418, Training Loss: 0.0165, Initial Validation Loss: 0.1331, Validation Loss: 0.0238,V Acc: 0.8519, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.5938
Stopping early at Epoch (base 0): 34  Rolling back to Epoch (base 0): 29  Top Validation Acc: 0.9736842105263158
92 4 [array([0.71162117, 0.06458604, 0.02980707, 0.05952289, 0.1344629 ],
      dtype=float32)]
Running train_nn.py with seed 93
CUDA:False/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)

Fold [1/5] Epoch [20/100] Initial Loss: 0.1405, Training Loss: 0.0256, Initial Validation Loss: 0.1366, Validation Loss: 0.0257,V Acc: 0.8929, Top 70th Acc: 0.9494, Bottom 30th Acc: 0.7576
Fold [1/5] Epoch [30/100] Initial Loss: 0.1405, Training Loss: 0.0223, Initial Validation Loss: 0.1366, Validation Loss: 0.0248,V Acc: 0.9107, Top 70th Acc: 0.9620, Bottom 30th Acc: 0.7879
Stopping early at Epoch (base 0): 34  Rolling back to Epoch (base 0): 29  Top Validation Acc: 0.9746835443037974
Fold [2/5] Epoch [0/100] Initial Loss: 0.1369, Training Loss: 0.1369, Initial Validation Loss: 0.1293, Validation Loss: 0.1293,V Acc: 0.3694, Top 70th Acc: 0.4615, Bottom 30th Acc: 0.1515
Fold [2/5] Epoch [10/100] Initial Loss: 0.1369, Training Loss: 0.0463, Initial Validation Loss: 0.1293, Validation Loss: 0.0599,V Acc: 0.6937, Top 70th Acc: 0.8205, Bottom 30th Acc: 0.3939
Fold [2/5] Epoch [20/100] Initial Loss: 0.1369, Training Loss: 0.0272, Initial Validation Loss: 0.1293, Validation Loss: 0.0416,V Acc: 0.8018, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.5152
Fold [2/5] Epoch [30/100] Initial Loss: 0.1369, Training Loss: 0.0203, Initial Validation Loss: 0.1293, Validation Loss: 0.0377,V Acc: 0.8198, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.5758
Fold [2/5] Epoch [40/100] Initial Loss: 0.1369, Training Loss: 0.0181, Initial Validation Loss: 0.1293, Validation Loss: 0.0383,V Acc: 0.8288, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 41  Rolling back to Epoch (base 0): 36  Top Validation Acc: 0.9102564102564102
Fold [3/5] Epoch [0/100] Initial Loss: 0.1417, Training Loss: 0.1417, Initial Validation Loss: 0.1341, Validation Loss: 0.1341,V Acc: 0.2636, Top 70th Acc: 0.3636, Bottom 30th Acc: 0.0303
Fold [3/5] Epoch [10/100] Initial Loss: 0.1417, Training Loss: 0.0326, Initial Validation Loss: 0.1341, Validation Loss: 0.0364,V Acc: 0.8545, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.6970
Fold [3/5] Epoch [20/100] Initial Loss: 0.1417, Training Loss: 0.0243, Initial Validation Loss: 0.1341, Validation Loss: 0.0325,V Acc: 0.8364, Top 70th Acc: 0.8961, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 28  Rolling back to Epoch (base 0): 23  Top Validation Acc: 0.9090909090909091
93 2 [array([0.4676588 , 0.109125  , 0.0704679 , 0.19080837, 0.16193996],
      dtype=float32)]
Fold [4/5] Epoch [0/100] Initial Loss: 0.1386, Training Loss: 0.1386, Initial Validation Loss: 0.1290, Validation Loss: 0.1290,V Acc: 0.3945, Top 70th Acc: 0.5065, Bottom 30th Acc: 0.1250
Fold [4/5] Epoch [10/100] Initial Loss: 0.1386, Training Loss: 0.0370, Initial Validation Loss: 0.1290, Validation Loss: 0.0445,V Acc: 0.7615, Top 70th Acc: 0.8571, Bottom 30th Acc: 0.5312
Fold [4/5] Epoch [20/100] Initial Loss: 0.1386, Training Loss: 0.0225, Initial Validation Loss: 0.1290, Validation Loss: 0.0371,V Acc: 0.7798, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.4688
Fold [4/5] Epoch [30/100] Initial Loss: 0.1386, Training Loss: 0.0201, Initial Validation Loss: 0.1290, Validation Loss: 0.0371,V Acc: 0.7890, Top 70th Acc: 0.8961, Bottom 30th Acc: 0.5312
Stopping early at Epoch (base 0): 36  Rolling back to Epoch (base 0): 31  Top Validation Acc: 0.922077922077922
Fold [5/5] Epoch [0/100] Initial Loss: 0.1396, Training Loss: 0.1396, Initial Validation Loss: 0.1307, Validation Loss: 0.1307,V Acc: 0.3241, Top 70th Acc: 0.3816, Bottom 30th Acc: 0.1875
Fold [5/5] Epoch [10/100] Initial Loss: 0.1396, Training Loss: 0.0395, Initial Validation Loss: 0.1307, Validation Loss: 0.0402,V Acc: 0.8148, Top 70th Acc: 0.9079, Bottom 30th Acc: 0.5938
Fold [5/5] Epoch [20/100] Initial Loss: 0.1396, Training Loss: 0.0241, Initial Validation Loss: 0.1307, Validation Loss: 0.0324,V Acc: 0.8241, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.5625
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.9342105263157895
Running train_nn.py with seed 94
CUDA:False
Training samples count:  550
Training on 20 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1366, Training Loss: 0.1366, Initial Validation Loss: 0.1334, Validation Loss: 0.1334,V Acc: 0.4018, Top 70th Acc: 0.4430, Bottom 30th Acc: 0.3030
Fold [1/5] Epoch [10/100] Initial Loss: 0.1366, Training Loss: 0.0344, Initial Validation Loss: 0.1334, Validation Loss: 0.0366,V Acc: 0.8482, Top 70th Acc: 0.9367, Bottom 30th Acc: 0.6364
Fold [1/5] Epoch [20/100] Initial Loss: 0.1366, Training Loss: 0.0245, Initial Validation Loss: 0.1334, Validation Loss: 0.0336,V Acc: 0.8393, Top 70th Acc: 0.9367, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.9367088607594937
Fold [2/5] Epoch [0/100] Initial Loss: 0.1423, Training Loss: 0.1423, Initial Validation Loss: 0.1332, Validation Loss: 0.1332,V Acc: 0.2523, Top 70th Acc: 0.2949, Bottom 30th Acc: 0.1515
Fold [2/5] Epoch [10/100] Initial Loss: 0.1423, Training Loss: 0.0396, Initial Validation Loss: 0.1332, Validation Loss: 0.0371,V Acc: 0.8468, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.6364
Fold [2/5] Epoch [20/100] Initial Loss: 0.1423, Training Loss: 0.0272, Initial Validation Loss: 0.1332, Validation Loss: 0.0304,V Acc: 0.8649, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.9358974358974359
Fold [3/5] Epoch [0/100] Initial Loss: 0.1382, Training Loss: 0.1382, Initial Validation Loss: 0.1341, Validation Loss: 0.1341,V Acc: 0.3545, Top 70th Acc: 0.4416, Bottom 30th Acc: 0.1515
Fold [3/5] Epoch [10/100] Initial Loss: 0.1382, Training Loss: 0.0353, Initial Validation Loss: 0.1341, Validation Loss: 0.0328,V Acc: 0.8727, Top 70th Acc: 0.9870, Bottom 30th Acc: 0.6061
Fold [3/5] Epoch [20/100] Initial Loss: 0.1382, Training Loss: 0.0269, Initial Validation Loss: 0.1341, Validation Loss: 0.0291,V Acc: 0.8545, Top 70th Acc: 0.9870, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.961038961038961
Fold [4/5] Epoch [0/100] Initial Loss: 0.1414, Training Loss: 0.1414, Initial Validation Loss: 0.1298, Validation Loss: 0.1298,V Acc: 0.2477, Top 70th Acc: 0.3117, Bottom 30th Acc: 0.0938
Fold [4/5] Epoch [10/100] Initial Loss: 0.1414, Training Loss: 0.0353, Initial Validation Loss: 0.1298, Validation Loss: 0.0386,V Acc: 0.8165, Top 70th Acc: 0.8961, Bottom 30th Acc: 0.6250
Fold [4/5] Epoch [20/100] Initial Loss: 0.1414, Training Loss: 0.0245, Initial Validation Loss: 0.1298, Validation Loss: 0.0367,V Acc: 0.7798, Top 70th Acc: 0.8831, Bottom 30th Acc: 0.5312
Stopping early at Epoch (base 0): 20  Rolling back to Epoch (base 0): 15  Top Validation Acc: 0.8831168831168831
Fold [5/5] Epoch [0/100] Initial Loss: 0.1400, Training Loss: 0.1400, Initial Validation Loss: 0.1387, Validation Loss: 0.1387,V Acc: 0.2130, Top 70th Acc: 0.2105, Bottom 30th Acc: 0.2188
Fold [5/5] Epoch [10/100] Initial Loss: 0.1400, Training Loss: 0.0499, Initial Validation Loss: 0.1387, Validation Loss: 0.0531,V Acc: 0.7778, Top 70th Acc: 0.8947, Bottom 30th Acc: 0.5000
Fold [5/5] Epoch [20/100] Initial Loss: 0.1400, Training Loss: 0.0269, Initial Validation Loss: 0.1387, Validation Loss: 0.0365,V Acc: 0.8519, Top 70th Acc: 0.9211, Bottom 30th Acc: 0.6875
Fold [5/5] Epoch [30/100] Initial Loss: 0.1400, Training Loss: 0.0236, Initial Validation Loss: 0.1387, Validation Loss: 0.0340,V Acc: 0.8611, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.6875
Stopping early at Epoch (base 0): 32  Rolling back to Epoch (base 0): 27  Top Validation Acc: 0.9342105263157895
94 4 [array([0.4988407 , 0.1010116 , 0.13258104, 0.1516837 , 0.11588293],
      dtype=float32)]
Running train_nn.py with seed 95
CUDA:False
Training samples count:  550
Training on 20 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1384, Training Loss: 0.1384, Initial Validation Loss: 0.1299, Validation Loss: 0.1299,V Acc: 0.3304, Top 70th Acc: 0.3671, Bottom 30th Acc: 0.2424
Fold [1/5] Epoch [10/100] Initial Loss: 0.1384, Training Loss: 0.0352, Initial Validation Loss: 0.1299, Validation Loss: 0.0514,V Acc: 0.7143, Top 70th Acc: 0.8481, Bottom 30th Acc: 0.3939
Fold [1/5] Epoch [20/100] Initial Loss: 0.1384, Training Loss: 0.0250, Initial Validation Loss: 0.1299, Validation Loss: 0.0442,V Acc: 0.7857, Top 70th Acc: 0.8734, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.7532467532467533
Fold [5/5] Epoch [0/100] Initial Loss: 0.1291, Training Loss: 0.1291, Initial Validation Loss: 0.1163, Validation Loss: 0.1163,V Acc: 0.4259, Top 70th Acc: 0.5395, Bottom 30th Acc: 0.1562
Fold [5/5] Epoch [10/100] Initial Loss: 0.1291, Training Loss: 0.0784, Initial Validation Loss: 0.1163, Validation Loss: 0.0830,V Acc: 0.6019, Top 70th Acc: 0.6842, Bottom 30th Acc: 0.4062
Fold [5/5] Epoch [20/100] Initial Loss: 0.1291, Training Loss: 0.0764, Initial Validation Loss: 0.1163, Validation Loss: 0.0822,V Acc: 0.6296, Top 70th Acc: 0.6974, Bottom 30th Acc: 0.4688
Stopping early at Epoch (base 0): 22  Rolling back to Epoch (base 0): 17  Top Validation Acc: 0.6973684210526315
94 4 [array([0.1138507 , 0.40059847, 0.13039747, 0.21531467, 0.13983871],
      dtype=float32)]
Running train_nn.py with seed 95
CUDA:False
Training samples count:  550
Training on 2 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1424, Training Loss: 0.1424, Initial Validation Loss: 0.1295, Validation Loss: 0.1295,V Acc: 0.3661, Top 70th Acc: 0.4684, Bottom 30th Acc: 0.1212
Fold [1/5] Epoch [10/100] Initial Loss: 0.1424, Training Loss: 0.0792, Initial Validation Loss: 0.1295, Validation Loss: 0.0866,V Acc: 0.5804, Top 70th Acc: 0.6835, Bottom 30th Acc: 0.3333
Fold [1/5] Epoch [20/100] Initial Loss: 0.1424, Training Loss: 0.0771, Initial Validation Loss: 0.1295, Validation Loss: 0.0853,V Acc: 0.5893, Top 70th Acc: 0.6835, Bottom 30th Acc: 0.3636
Fold [1/5] Epoch [30/100] Initial Loss: 0.1424, Training Loss: 0.0761, Initial Validation Loss: 0.1295, Validation Loss: 0.0848,V Acc: 0.5893, Top 70th Acc: 0.6835, Bottom 30th Acc: 0.3636
Stopping early at Epoch (base 0): 39  Rolling back to Epoch (base 0): 34  Top Validation Acc: 0.6835443037974683
Fold [2/5] Epoch [0/100] Initial Loss: 0.1263, Training Loss: 0.1263, Initial Validation Loss: 0.1099, Validation Loss: 0.1099,V Acc: 0.5946, Top 70th Acc: 0.7179, Bottom 30th Acc: 0.3030
Fold [2/5] Epoch [10/100] Initial Loss: 0.1263, Training Loss: 0.0821, Initial Validation Loss: 0.1099, Validation Loss: 0.0725,V Acc: 0.6937, Top 70th Acc: 0.7564, Bottom 30th Acc: 0.5455
Fold [2/5] Epoch [20/100] Initial Loss: 0.1263, Training Loss: 0.0801, Initial Validation Loss: 0.1099, Validation Loss: 0.0709,V Acc: 0.7027, Top 70th Acc: 0.7436, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 20  Rolling back to Epoch (base 0): 15  Top Validation Acc: 0.7435897435897436
Fold [3/5] Epoch [0/100] Initial Loss: 0.1277, Training Loss: 0.1277, Initial Validation Loss: 0.1162, Validation Loss: 0.1162,V Acc: 0.5545, Top 70th Acc: 0.5714, Bottom 30th Acc: 0.5152
Fold [3/5] Epoch [10/100] Initial Loss: 0.1277, Training Loss: 0.0811, Initial Validation Loss: 0.1162, Validation Loss: 0.0748,V Acc: 0.6727, Top 70th Acc: 0.7662, Bottom 30th Acc: 0.4545
Fold [3/5] Epoch [20/100] Initial Loss: 0.1277, Training Loss: 0.0796, Initial Validation Loss: 0.1162, Validation Loss: 0.0721,V Acc: 0.6636, Top 70th Acc: 0.7922, Bottom 30th Acc: 0.3636
Stopping early at Epoch (base 0): 29  Rolling back to Epoch (base 0): 24  Top Validation Acc: 0.8051948051948052
Fold [4/5] Epoch [0/100] Initial Loss: 0.1383, Training Loss: 0.1383, Initial Validation Loss: 0.1258, Validation Loss: 0.1258,V Acc: 0.2752, Top 70th Acc: 0.3377, Bottom 30th Acc: 0.1250
Fold [4/5] Epoch [10/100] Initial Loss: 0.1383, Training Loss: 0.0794, Initial Validation Loss: 0.1258, Validation Loss: 0.0811,V Acc: 0.6055, Top 70th Acc: 0.7662, Bottom 30th Acc: 0.2188
Fold [4/5] Epoch [20/100] Initial Loss: 0.1383, Training Loss: 0.0777, Initial Validation Loss: 0.1258, Validation Loss: 0.0793,V Acc: 0.6239, Top 70th Acc: 0.7532, Bottom 30th Acc: 0.3125
Fold [4/5] Epoch [30/100] Initial Loss: 0.1383, Training Loss: 0.0770, Initial Validation Loss: 0.1258, Validation Loss: 0.0791,V Acc: 0.6239, Top 70th Acc: 0.7662, Bottom 30th Acc: 0.2812
Stopping early at Epoch (base 0): 38  Rolling back to Epoch (base 0): 33  Top Validation Acc: 0.7662337662337663
Fold [5/5] Epoch [0/100] Initial Loss: 0.1379, Training Loss: 0.1379, Initial Validation Loss: 0.1255, Validation Loss: 0.1255,V Acc: 0.3519, Top 70th Acc: 0.4342, Bottom 30th Acc: 0.1562
Fold [5/5] Epoch [10/100] Initial Loss: 0.1379, Training Loss: 0.0801, Initial Validation Loss: 0.1255, Validation Loss: 0.0817,V Acc: 0.6019, Top 70th Acc: 0.7105, Bottom 30th Acc: 0.3438
Fold [5/5] Epoch [20/100] Initial Loss: 0.1379, Training Loss: 0.0783, Initial Validation Loss: 0.1255, Validation Loss: 0.0801,V Acc: 0.5926, Top 70th Acc: 0.6974, Bottom 30th Acc: 0.3438
Fold [5/5] Epoch [30/100] Initial Loss: 0.1379, Training Loss: 0.0774, Initial Validation Loss: 0.1255, Validation Loss: 0.0804,V Acc: 0.5926, Top 70th Acc: 0.6974, Bottom 30th Acc: 0.3438
Stopping early at Epoch (base 0): 32  Rolling back to Epoch (base 0): 27  Top Validation Acc: 0.6973684210526315
95 4 [array([0.13225795, 0.3496594 , 0.14065167, 0.2284019 , 0.14902902],
      dtype=float32)]
Running train_nn.py with seed 96
CUDA:False
Training samples count:  550
Training on 2 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1344, Training Loss: 0.1344, Initial Validation Loss: 0.1246, Validation Loss: 0.1246,V Acc: 0.4643, Top 70th Acc: 0.5190, Bottom 30th Acc: 0.3333
Fold [1/5] Epoch [10/100] Initial Loss: 0.1344, Training Loss: 0.0822, Initial Validation Loss: 0.1246, Validation Loss: 0.0783,V Acc: 0.6429, Top 70th Acc: 0.7848, Bottom 30th Acc: 0.3030
Fold [1/5] Epoch [20/100] Initial Loss: 0.1344, Training Loss: 0.0804, Initial Validation Loss: 0.1246, Validation Loss: 0.0755,V Acc: 0.6607, Top 70th Acc: 0.7848, Bottom 30th Acc: 0.3636
Fold [1/5] Epoch [30/100] Initial Loss: 0.1344, Training Loss: 0.0795, Initial Validation Loss: 0.1246, Validation Loss: 0.0745,V Acc: 0.6607, Top 70th Acc: 0.7975, Bottom 30th Acc: 0.3333
Stopping early at Epoch (base 0): 36  Rolling back to Epoch (base 0): 31  Top Validation Acc: 0.7848101265822784
Fold [2/5] Epoch [0/100] Initial Loss: 0.1400, Training Loss: 0.1400, Initial Validation Loss: 0.1299, Validation Loss: 0.1299,V Acc: 0.3063, Top 70th Acc: 0.3590, Bottom 30th Acc: 0.1818
Fold [2/5] Epoch [10/100] Initial Loss: 0.1400, Training Loss: 0.0799, Initial Validation Loss: 0.1299, Validation Loss: 0.0849,V Acc: 0.5856, Top 70th Acc: 0.7179, Bottom 30th Acc: 0.2727
Fold [2/5] Epoch [20/100] Initial Loss: 0.1400, Training Loss: 0.0774, Initial Validation Loss: 0.1299, Validation Loss: 0.0841,V Acc: 0.5946, Top 70th Acc: 0.7179, Bottom 30th Acc: 0.3030
Fold [2/5] Epoch [30/100] Initial Loss: 0.1400, Training Loss: 0.0768, Initial Validation Loss: 0.1299, Validation Loss: 0.0846,V Acc: 0.5766, Top 70th Acc: 0.7051, Bottom 30th Acc: 0.2727
Stopping early at Epoch (base 0): 31  Rolling back to Epoch (base 0): 26  Top Validation Acc: 0.717948717948718
Fold [3/5] Epoch [0/100] Initial Loss: 0.1309, Training Loss: 0.1309, Initial Validation Loss: 0.1209, Validation Loss: 0.1209,V Acc: 0.4000, Top 70th Acc: 0.4935, Bottom 30th Acc: 0.1818
Fold [3/5] Epoch [10/100] Initial Loss: 0.1309, Training Loss: 0.0818, Initial Validation Loss: 0.1209, Validation Loss: 0.0786,V Acc: 0.6182, Top 70th Acc: 0.7532, Bottom 30th Acc: 0.3030
Fold [3/5] Epoch [20/100] Initial Loss: 0.1309, Training Loss: 0.0797, Initial Validation Loss: 0.1209, Validation Loss: 0.0772,V Acc: 0.6273, Top 70th Acc: 0.7532, Bottom 30th Acc: 0.3333
Stopping early at Epoch (base 0): 29  Rolling back to Epoch (base 0): 24  Top Validation Acc: 0.7662337662337663
Fold [4/5] Epoch [0/100] Initial Loss: 0.1407, Training Loss: 0.1407, Initial Validation Loss: 0.1316, Validation Loss: 0.1316,V Acc: 0.2661, Top 70th Acc: 0.3506, Bottom 30th Acc: 0.0625
Fold [4/5] Epoch [10/100] Initial Loss: 0.1407, Training Loss: 0.0795, Initial Validation Loss: 0.1316, Validation Loss: 0.0795,V Acc: 0.6147, Top 70th Acc: 0.7013, Bottom 30th Acc: 0.4062
Fold [4/5] Epoch [20/100] Initial Loss: 0.1407, Training Loss: 0.0780, Initial Validation Loss: 0.1316, Validation Loss: 0.0786,V Acc: 0.6147, Top 70th Acc: 0.7143, Bottom 30th Acc: 0.3750
Fold [4/5] Epoch [30/100] Initial Loss: 0.1407, Training Loss: 0.0770, Initial Validation Loss: 0.1316, Validation Loss: 0.0782,V Acc: 0.5963, Top 70th Acc: 0.7273, Bottom 30th Acc: 0.281262  Rolling back to Epoch (base 0): 57  Top Validation Acc: 0.987012987012987
Fold [5/5] Epoch [0/100] Initial Loss: 0.1388, Training Loss: 0.1388, Initial Validation Loss: 0.1276, Validation Loss: 0.1276,V Acc: 0.2870, Top 70th Acc: 0.3553, Bottom 30th Acc: 0.1250
Fold [5/5] Epoch [10/100] Initial Loss: 0.1388, Training Loss: 0.0173, Initial Validation Loss: 0.1276, Validation Loss: 0.0383,V Acc: 0.8148, Top 70th Acc: 0.9211, Bottom 30th Acc: 0.5625
Fold [5/5] Epoch [20/100] Initial Loss: 0.1388, Training Loss: 0.0051, Initial Validation Loss: 0.1276, Validation Loss: 0.0318,V Acc: 0.8426, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.6250
Fold [5/5] Epoch [30/100] Initial Loss: 0.1388, Training Loss: 0.0040, Initial Validation Loss: 0.1276, Validation Loss: 0.0303,V Acc: 0.8519, Top 70th Acc: 0.9211, Bottom 30th Acc: 0.6875
Fold [5/5] Epoch [40/100] Initial Loss: 0.1388, Training Loss: 0.0037, Initial Validation Loss: 0.1276, Validation Loss: 0.0295,V Acc: 0.8704, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.7188
Fold [5/5] Epoch [50/100] Initial Loss: 0.1388, Training Loss: 0.0036, Initial Validation Loss: 0.1276, Validation Loss: 0.0289,V Acc: 0.8611, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.6875
Fold [5/5] Epoch [60/100] Initial Loss: 0.1388, Training Loss: 0.0035, Initial Validation Loss: 0.1276, Validation Loss: 0.0282,V Acc: 0.8796, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.7188
Stopping early at Epoch (base 0): 61  Rolling back to Epoch (base 0): 56  Top Validation Acc: 0.9342105263157895
Running train_nn.py with seed 72
CUDA:False
Training samples count:  550
Training on 162 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1395, Training Loss: 0.1395, Initial Validation Loss: 0.1353, Validation Loss: 0.1353,V Acc: 0.2500, Top 70th Acc: 0.2911, Bottom 30th Acc: 0.1515
Fold [1/5] Epoch [10/100] Initial Loss: 0.1395, Training Loss: 0.0167, Initial Validation Loss: 0.1353, Validation Loss: 0.0445,V Acc: 0.7946, Top 70th Acc: 0.8987, Bottom 30th Acc: 0.5455
Fold [1/5] Epoch [20/100] Initial Loss: 0.1395, Training Loss: 0.0049, Initial Validation Loss: 0.1353, Validation Loss: 0.0372,V Acc: 0.7946, Top 70th Acc: 0.9114, Bottom 30th Acc: 0.5152
Fold [1/5] Epoch [30/100] Initial Loss: 0.1395, Training Loss: 0.0040, Initial Validation Loss: 0.1353, Validation Loss: 0.0358,V Acc: 0.7946, Top 70th Acc: 0.9241, Bottom 30th Acc: 0.4848
Fold [1/5] Epoch [40/100] Initial Loss: 0.1395, Training Loss: 0.0038, Initial Validation Loss: 0.1353, Validation Loss: 0.0354,V Acc: 0.7946, Top 70th Acc: 0.9241, Bottom 30th Acc: 0.4848
Fold [1/5] Epoch [50/100] Initial Loss: 0.1395, Training Loss: 0.0036, Initial Validation Loss: 0.1353, Validation Loss: 0.0349,V Acc: 0.8304, Top 70th Acc: 0.9367, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 54  Rolling back to Epoch (base 0): 49  Top Validation Acc: 0.9240506329113924
Fold [2/5] Epoch [0/100] Initial Loss: 0.1410, Training Loss: 0.1410, Initial Validation Loss: 0.1291, Validation Loss: 0.1291,V Acc: 0.3694, Top 70th Acc: 0.4615, Bottom 30th Acc: 0.1515
Fold [2/5] Epoch [10/100] Initial Loss: 0.1410, Training Loss: 0.0185, Initial Validation Loss: 0.1291, Validation Loss: 0.0312,V Acc: 0.8468, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.6667
Fold [2/5] Epoch [20/100] Initial Loss: 0.1410, Training Loss: 0.0048, Initial Validation Loss: 0.1291, Validation Loss: 0.0262,V Acc: 0.8468, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.6364
Fold [2/5] Epoch [30/100] Initial Loss: 0.1410, Training Loss: 0.0037, Initial Validation Loss: 0.1291, Validation Loss: 0.0272,V Acc: 0.8378, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 32  Rolling back to Epoch (base 0): 27  Top Validation Acc: 0.9487179487179487
Fold [3/5] Epoch [0/100] Initial Loss: 0.1410, Training Loss: 0.1410, Initial Validation Loss: 0.1332, Validation Loss: 0.1332,V Acc: 0.3636, Top 70th Acc: 0.4545, Bottom 30th Acc: 0.1515
Fold [3/5] Epoch [10/100] Initial Loss: 0.1410, Training Loss: 0.0155, Initial Validation Loss: 0.1332, Validation Loss: 0.0384,V Acc: 0.8091, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.5455
Fold [3/5] Epoch [20/100] Initial Loss: 0.1410, Training Loss: 0.0057, Initial Validation Loss: 0.1332, Validation Loss: 0.0347,V Acc: 0.8182, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.5152
Fold [3/5] Epoch [30/100] Initial Loss: 0.1410, Training Loss: 0.0045, Initial Validation Loss: 0.1332, Validation Loss: 0.0338,V Acc: 0.8273, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 37  Rolling back to Epoch (base 0): 32  Top Validation Acc: 0.948051948051948
Fold [4/5] Epoch [0/100] Initial Loss: 0.1423, Training Loss: 0.1423, Initial Validation Loss: 0.1374, Validation Loss: 0.1374,V Acc: 0.2385, Top 70th Acc: 0.2597, Bottom 30th Acc: 0.1875
Fold [4/5] Epoch [10/100] Initial Loss: 0.1423, Training Loss: 0.0156, Initial Validation Loss: 0.1374, Validation Loss: 0.0356,V Acc: 0.8257, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.5625
Fold [4/5] Epoch [20/100] Initial Loss: 0.1423, Training Loss: 0.0049, Initial Validation Loss: 0.1374, Validation Loss: 0.0305,V Acc: 0.8532, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6250
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.948051948051948
Fold [5/5] Epoch [0/100] Initial Loss: 0.1379, Training Loss: 0.1379, Initial Validation Loss: 0.1326, Validation Loss: 0.1326,V Acc: 0.3426, Top 70th Acc: 0.4211, Bottom 30th Acc: 0.1562
Fold [5/5] Epoch [10/100] Initial Loss: 0.1379, Training Loss: 0.0154, Initial Validation Loss: 0.1326, Validation Loss: 0.0342,V Acc: 0.8519, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.6250
Fold [5/5] Epoch [20/100] Initial Loss: 0.1379, Training Loss: 0.0055, Initial Validation Loss: 0.1326, Validation Loss: 0.0295,V Acc: 0.8981, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.7812
Fold [5/5] Epoch [30/100] Initial Loss: 0.1379, Training Loss: 0.0041, Initial Validation Loss: 0.1326, Validation Loss: 0.0283,V Acc: 0.8796, Top 70th Acc: 0.9737, Bottom 30th Acc: 0.6562
Stopping early at Epoch (base 0): 36  Rolling back to Epoch (base 0): 31  Top Validation Acc: 0.9736842105263158
72 4 [array([0.42313674, 0.01340694, 0.0700611 , 0.24969864, 0.24369656],
      dtype=float32)]
Running train_nn.py with seed 73
CUDA:False
Training samples count:  550
Training on 162 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1407, Training Loss: 0.1407, Initial Validation Loss: 0.1346, Validation Loss: 0.1346,V Acc: 0.3214, Top 70th Acc: 0.3544, Bottom 30th Acc: 0.2424
Fold [1/5] Epoch [10/100] Initial Loss: 0.1407, Training Loss: 0.0114, Initial Validation Loss: 0.1346, Validation Loss: 0.0332,V Acc: 0.8482, Top 70th Acc: 0.9494, Bottom 30th Acc: 0.6061
Fold [1/5] Epoch [20/100] Initial Loss: 0.1407, Training Loss: 0.0046, Initial Validation Loss: 0.1346, Validation Loss: 0.0306,V Acc: 0.8482, Top 70th Acc: 0.9620, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.9493670886075949
Fold [2/5] Epoch [0/100] Initial Loss: 0.1373, Training Loss: 0.1373, Initial Validation Loss: 0.1354, Validation Loss: 0.1354,V Acc: 0.3784, Top 70th Acc: 0.4744, Bottom 30th Acc: 0.1515
Fold [2/5] Epoch [10/100] Initial Loss: 0.1373, Training Loss: 0.0130, Initial Validation Loss: 0.1354, Validation Loss: 0.0324,V Acc: 0.8739, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.6970
Fold [2/5] Epoch [20/100] Initial Loss: 0.1373, Training Loss: 0.0048, Initial Validation Loss: 0.1354, Validation Loss: 0.0287,V Acc: 0.8829, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 28  Rolling back to Epoch (base 0): 23  Top Validation Acc: 0.9615384615384616
73 1 [array([0.41621232, 0.07325729, 0.07245395, 0.2237223 , 0.21435413],
      dtype=float32)]
Fold [3/5] Epoch [0/100] Initial Loss: 0.1382, Training Loss: 0.1382, Initial Validation Loss: 0.1290, Validation Loss: 0.1290,V Acc: 0.3545, Top 70th Acc: 0.4545, Bottom 30th Acc: 0.1212
Fold [3/5] Epoch [10/100] Initial Loss: 0.1382, Training Loss: 0.0196, Initial Validation Loss: 0.1290, Validation Loss: 0.0434,V Acc: 0.8091, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.5758
Fold [3/5] Epoch [20/100] Initial Loss: 0.1382, Training Loss: 0.0062, Initial Validation Loss: 0.1290, Validation Loss: 0.0395,V Acc: 0.8182, Top 70th Acc: 0.8961, Bottom 30th Acc: 0.6364
Fold [1/5] Epoch [20/100] Initial Loss: 0.1377, Training Loss: 0.0165, Initial Validation Loss: 0.1380, Validation Loss: 0.0235,V Acc: 0.8839, Top 70th Acc: 0.9747, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 1.0
Fold [2/5] Epoch [0/100] Initial Loss: 0.1413, Training Loss: 0.1413, Initial Validation Loss: 0.1344, Validation Loss: 0.1344,V Acc: 0.3153, Top 70th Acc: 0.3590, Bottom 30th Acc: 0.2121
Fold [2/5] Epoch [10/100] Initial Loss: 0.1413, Training Loss: 0.0313, Initial Validation Loss: 0.1344, Validation Loss: 0.0446,V Acc: 0.7748, Top 70th Acc: 0.8846, Bottom 30th Acc: 0.5152
Fold [2/5] Epoch [20/100] Initial Loss: 0.1413, Training Loss: 0.0139, Initial Validation Loss: 0.1344, Validation Loss: 0.0377,V Acc: 0.7838, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.4545
Stopping early at Epoch (base 0): 28  Rolling back to Epoch (base 0): 23  Top Validation Acc: 0.9102564102564102
Fold [3/5] Epoch [0/100] Initial Loss: 0.1447, Training Loss: 0.1447, Initial Validation Loss: 0.1352, Validation Loss: 0.1352,V Acc: 0.1909, Top 70th Acc: 0.2208, Bottom 30th Acc: 0.1212
Fold [3/5] Epoch [10/100] Initial Loss: 0.1447, Training Loss: 0.0411, Initial Validation Loss: 0.1352, Validation Loss: 0.0458,V Acc: 0.7636, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.3939
Fold [3/5] Epoch [20/100] Initial Loss: 0.1447, Training Loss: 0.0166, Initial Validation Loss: 0.1352, Validation Loss: 0.0322,V Acc: 0.8455, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.6667
Fold [3/5] Epoch [30/100] Initial Loss: 0.1447, Training Loss: 0.0130, Initial Validation Loss: 0.1352, Validation Loss: 0.0298,V Acc: 0.8727, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.7273
Stopping early at Epoch (base 0): 34  Rolling back to Epoch (base 0): 29  Top Validation Acc: 0.935064935064935
Fold [4/5] Epoch [0/100] Initial Loss: 0.1405, Training Loss: 0.1405, Initial Validation Loss: 0.1345, Validation Loss: 0.1345,V Acc: 0.2752, Top 70th Acc: 0.2857, Bottom 30th Acc: 0.2500
Fold [4/5] Epoch [10/100] Initial Loss: 0.1405, Training Loss: 0.0352, Initial Validation Loss: 0.1345, Validation Loss: 0.0441,V Acc: 0.8440, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.6875
Fold [4/5] Epoch [20/100] Initial Loss: 0.1405, Training Loss: 0.0179, Initial Validation Loss: 0.1345, Validation Loss: 0.0318,V Acc: 0.8440, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.5312
Fold [4/5] Epoch [30/100] Initial Loss: 0.1405, Training Loss: 0.0139, Initial Validation Loss: 0.1345, Validation Loss: 0.0310,V Acc: 0.8532, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.5625
Stopping early at Epoch (base 0): 31  Rolling back to Epoch (base 0): 26  Top Validation Acc: 0.974025974025974
96 3 [array([0.62395257, 0.13748027, 0.02308168, 0.0432975 , 0.17218804],
      dtype=float32)]
Fold [5/5] Epoch [0/100] Initial Loss: 0.1399, Training Loss: 0.1399, Initial Validation Loss: 0.1313, Validation Loss: 0.1313,V Acc: 0.3426, Top 70th Acc: 0.3289, Bottom 30th Acc: 0.3750
Fold [5/5] Epoch [10/100] Initial Loss: 0.1399, Training Loss: 0.0269, Initial Validation Loss: 0.1313, Validation Loss: 0.0377,V Acc: 0.8333, Top 70th Acc: 0.9211, Bottom 30th Acc: 0.6250
Fold [5/5] Epoch [20/100] Initial Loss: 0.1399, Training Loss: 0.0144, Initial Validation Loss: 0.1313, Validation Loss: 0.0296,V Acc: 0.8611, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.6562
Stopping early at Epoch (base 0): 29  Rolling back to Epoch (base 0): 24  Top Validation Acc: 0.9605263157894737
Running train_nn.py with seed 97
CUDA:False
Training samples count:  550
Training on 40 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1393, Training Loss: 0.1393, Initial Validation Loss: 0.1368, Validation Loss: 0.1368,V Acc: 0.2679, Top 70th Acc: 0.3544, Bottom 30th Acc: 0.0606
Fold [1/5] Epoch [10/100] Initial Loss: 0.1393, Training Loss: 0.0284, Initial Validation Loss: 0.1368, Validation Loss: 0.0317,V Acc: 0.8661, Top 70th Acc: 0.9494, Bottom 30th Acc: 0.6667
Fold [1/5] Epoch [20/100] Initial Loss: 0.1393, Training Loss: 0.0150, Initial Validation Loss: 0.1368, Validation Loss: 0.0248,V Acc: 0.8929, Top 70th Acc: 0.9367, Bottom 30th Acc: 0.7879
Stopping early at Epoch (base 0): 28  Rolling back to Epoch (base 0): 23  Top Validation Acc: 0.9493670886075949
Fold [2/5] Epoch [0/100] Initial Loss: 0.1413, Training Loss: 0.1413, Initial Validation Loss: 0.1358, Validation Loss: 0.1358,V Acc: 0.2613, Top 70th Acc: 0.2821, Bottom 30th Acc: 0.2121
Fold [2/5] Epoch [10/100] Initial Loss: 0.1413, Training Loss: 0.0245, Initial Validation Loss: 0.1358, Validation Loss: 0.0458,V Acc: 0.8108, Top 70th Acc: 0.8718, Bottom 30th Acc: 0.6667
Fold [2/5] Epoch [20/100] Initial Loss: 0.1413, Training Loss: 0.0118, Initial Validation Loss: 0.1358, Validation Loss: 0.0406,V Acc: 0.8108, Top 70th Acc: 0.8974, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 29  Rolling back to Epoch (base 0): 24  Top Validation Acc: 0.9102564102564102
97 1 [array([0.4700671 , 0.06671136, 0.10100871, 0.19973412, 0.16247872],
      dtype=float32)]
Fold [3/5] Epoch [0/100] Initial Loss: 0.1387, Training Loss: 0.1387, Initial Validation Loss: 0.1302, Validation Loss: 0.1302,V Acc: 0.4545, Top 70th Acc: 0.5455, Bottom 30th Acc: 0.2424
Fold [3/5] Epoch [10/100] Initial Loss: 0.1387, Training Loss: 0.0256, Initial Validation Loss: 0.1302, Validation Loss: 0.0266,V Acc: 0.8909, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.7576
Fold [3/5] Epoch [20/100] Initial Loss: 0.1387, Training Loss: 0.0146, Initial Validation Loss: 0.1302, Validation Loss: 0.0241,V Acc: 0.8727, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 20  Rolling back to Epoch (base 0): 15  Top Validation Acc: 0.974025974025974
Fold [4/5] Epoch [0/100] Initial Loss: 0.1418, Training Loss: 0.1418, Initial Validation Loss: 0.1333, Validation Loss: 0.1333,V Acc: 0.2936, Top 70th Acc: 0.3117, Bottom 30th Acc: 0.2500
Fold [4/5] Epoch [10/100] Initial Loss: 0.1418, Training Loss: 0.0261, Initial Validation Loss: 0.1333, Validation Loss: 0.0336,V Acc: 0.8440, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.5625
Fold [4/5] Epoch [20/100] Initial Loss: 0.1418, Training Loss: 0.0135, Initial Validation Loss: 0.1333, Validation Loss: 0.0298,V Acc: 0.8532, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.5938
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.961038961038961
Fold [5/5] Epoch [0/100] Initial Loss: 0.1399, Training Loss: 0.1399, Initial Validation Loss: 0.1312, Validation Loss: 0.1312,V Acc: 0.3056, Top 70th Acc: 0.3421, Bottom 30th Acc: 0.2188
Fold [5/5] Epoch [10/100] Initial Loss: 0.1399, Training Loss: 0.0322, Initial Validation Loss: 0.1312, Validation Loss: 0.0371,V Acc: 0.8241, Top 70th Acc: 0.9079, Bottom 30th Acc: 0.6250
Fold [5/5] Epoch [20/100] Initial Loss: 0.1399, Training Loss: 0.0155, Initial Validation Loss: 0.1312, Validation Loss: 0.0299,V Acc: 0.8611, Top 70th Acc: 0.9079, Bottom 30th Acc: 0.7500
Fold [5/5] Epoch [30/100] Initial Loss: 0.1399, Training Loss: 0.0122, Initial Validation Loss: 0.1312, Validation Loss: 0.0284,V Acc: 0.8426, Top 70th Acc: 0.9211, Bottom 30th Acc: 0.6562
Stopping early at Epoch (base 0): 36  Rolling back to Epoch (base 0): 31  Top Validation Acc: 0.9210526315789473
Running train_nn.py with seed 98
CUDA:False
Training samples count:  550
Training on 40 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1444, Training Loss: 0.1444, Initial Validation Loss: 0.1400, Validation Loss: 0.1400,V Acc: 0.2232, Top 70th Acc: 0.2405, Bottom 30th Acc: 0.1818
Fold [1/5] Epoch [10/100] Initial Loss: 0.1444, Training Loss: 0.0356, Initial Validation Loss: 0.1400, Validation Loss: 0.0371,V Acc: 0.8661, Top 70th Acc: 0.9494, Bottom 30th Acc: 0.6667
Fold [1/5] Epoch [20/100] Initial Loss: 0.1444, Training Loss: 0.0160, Initial Validation Loss: 0.1400, Validation Loss: 0.0284,V Acc: 0.8839, Top 70th Acc: 0.9494, Bottom 30th Acc: 0.7273
Stopping early at Epoch (base 0): 21  Rolling back to Epoch (base 0): 16  Top Validation Acc: 0.9493670886075949
Fold [2/5] Epoch [0/100] Initial Loss: 0.1364, Training Loss: 0.1364, Initial Validation Loss: 0.1336, Validation Loss: 0.1336,V Acc: 0.4144, Top 70th Acc: 0.5128, Bottom 30th Acc: 0.1818
Training samples count:  550
Training on 30 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1417, Training Loss: 0.1417, Initial Validation Loss: 0.1369, Validation Loss: 0.1369,V Acc: 0.3304, Top 70th Acc: 0.3924, Bottom 30th Acc: 0.1818
Fold [1/5] Epoch [10/100] Initial Loss: 0.1417, Training Loss: 0.0306, Initial Validation Loss: 0.1369, Validation Loss: 0.0318,V Acc: 0.8929, Top 70th Acc: 0.9367, Bottom 30th Acc: 0.7879
Fold [1/5] Epoch [20/100] Initial Loss: 0.1417, Training Loss: 0.0196, Initial Validation Loss: 0.1369, Validation Loss: 0.0250,V Acc: 0.9196, Top 70th Acc: 0.9494, Bottom 30th Acc: 0.8485
Fold [1/5] Epoch [30/100] Initial Loss: 0.1417, Training Loss: 0.0164, Initial Validation Loss: 0.1369, Validation Loss: 0.0241,V Acc: 0.9107, Top 70th Acc: 0.9494, Bottom 30th Acc: 0.8182
Stopping early at Epoch (base 0): 30  Rolling back to Epoch (base 0): 25  Top Validation Acc: 0.9493670886075949
Fold [2/5] Epoch [0/100] Initial Loss: 0.1389, Training Loss: 0.1389, Initial Validation Loss: 0.1337, Validation Loss: 0.1337,V Acc: 0.2883, Top 70th Acc: 0.2692, Bottom 30th Acc: 0.3333
Fold [2/5] Epoch [10/100] Initial Loss: 0.1389, Training Loss: 0.0257, Initial Validation Loss: 0.1337, Validation Loss: 0.0388,V Acc: 0.8018, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.4848
Stopping early at Epoch (base 0): 19  Rolling back to Epoch (base 0): 14  Top Validation Acc: 0.9230769230769231
Fold [3/5] Epoch [0/100] Initial Loss: 0.1402, Training Loss: 0.1402, Initial Validation Loss: 0.1362, Validation Loss: 0.1362,V Acc: 0.2545, Top 70th Acc: 0.2597, Bottom 30th Acc: 0.2424
Fold [3/5] Epoch [10/100] Initial Loss: 0.1402, Training Loss: 0.0322, Initial Validation Loss: 0.1362, Validation Loss: 0.0347,V Acc: 0.8545, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.6970
Fold [3/5] Epoch [20/100] Initial Loss: 0.1402, Training Loss: 0.0188, Initial Validation Loss: 0.1362, Validation Loss: 0.0249,V Acc: 0.8636, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.6970
Fold [3/5] Epoch [30/100] Initial Loss: 0.1402, Training Loss: 0.0162, Initial Validation Loss: 0.1362, Validation Loss: 0.0256,V Acc: 0.8545, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 30  Rolling back to Epoch (base 0): 25  Top Validation Acc: 0.948051948051948
93 2 [array([0.75404465, 0.0321001 , 0.04131069, 0.05009052, 0.12245402],
      dtype=float32)]
Fold [4/5] Epoch [0/100] Initial Loss: 0.1416, Training Loss: 0.1416, Initial Validation Loss: 0.1299, Validation Loss: 0.1299,V Acc: 0.3211, Top 70th Acc: 0.3636, Bottom 30th Acc: 0.2188
Fold [4/5] Epoch [10/100] Initial Loss: 0.1416, Training Loss: 0.0313, Initial Validation Loss: 0.1299, Validation Loss: 0.0435,V Acc: 0.7706, Top 70th Acc: 0.8571, Bottom 30th Acc: 0.5625
Fold [4/5] Epoch [20/100] Initial Loss: 0.1416, Training Loss: 0.0184, Initial Validation Loss: 0.1299, Validation Loss: 0.0363,V Acc: 0.8165, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.5938
Fold [4/5] Epoch [30/100] Initial Loss: 0.1416, Training Loss: 0.0152, Initial Validation Loss: 0.1299, Validation Loss: 0.0345,V Acc: 0.8349, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.6250
Fold [4/5] Epoch [40/100] Initial Loss: 0.1416, Training Loss: 0.0143, Initial Validation Loss: 0.1299, Validation Loss: 0.0323,V Acc: 0.8716, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.7500
Stopping early at Epoch (base 0): 47  Rolling back to Epoch (base 0): 42  Top Validation Acc: 0.9090909090909091
Fold [5/5] Epoch [0/100] Initial Loss: 0.1402, Training Loss: 0.1402, Initial Validation Loss: 0.1317, Validation Loss: 0.1317,V Acc: 0.2593, Top 70th Acc: 0.3421, Bottom 30th Acc: 0.0625
Fold [5/5] Epoch [10/100] Initial Loss: 0.1402, Training Loss: 0.0285, Initial Validation Loss: 0.1317, Validation Loss: 0.0311,V Acc: 0.8704, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.6875
Fold [5/5] Epoch [20/100] Initial Loss: 0.1402, Training Loss: 0.0174, Initial Validation Loss: 0.1317, Validation Loss: 0.0272,V Acc: 0.8704, Top 70th Acc: 0.9868, Bottom 30th Acc: 0.5938
Stopping early at Epoch (base 0): 27  Rolling back to Epoch (base 0): 22  Top Validation Acc: 0.9868421052631579
Running train_nn.py with seed 94
CUDA:False
Training samples count:  550
Training on 30 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1392, Training Loss: 0.1392, Initial Validation Loss: 0.1383, Validation Loss: 0.1383,V Acc: 0.3036, Top 70th Acc: 0.3165, Bottom 30th Acc: 0.2727
Fold [1/5] Epoch [10/100] Initial Loss: 0.1392, Training Loss: 0.0311, Initial Validation Loss: 0.1383, Validation Loss: 0.0380,V Acc: 0.8750, Top 70th Acc: 0.9367, Bottom 30th Acc: 0.7273
Fold [1/5] Epoch [20/100] Initial Loss: 0.1392, Training Loss: 0.0181, Initial Validation Loss: 0.1383, Validation Loss: 0.0318,V Acc: 0.8482, Top 70th Acc: 0.9241, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.9493670886075949
Fold [2/5] Epoch [0/100] Initial Loss: 0.1382, Training Loss: 0.1382, Initial Validation Loss: 0.1311, Validation Loss: 0.1311,V Acc: 0.3784, Top 70th Acc: 0.4103, Bottom 30th Acc: 0.3030
Fold [2/5] Epoch [10/100] Initial Loss: 0.1382, Training Loss: 0.0301, Initial Validation Loss: 0.1311, Validation Loss: 0.0278,V Acc: 0.8829, Top 70th Acc: 0.9872, Bottom 30th Acc: 0.6364
Fold [2/5] Epoch [20/100] Initial Loss: 0.1382, Training Loss: 0.0190, Initial Validation Loss: 0.1311, Validation Loss: 0.0220,V Acc: 0.9009, Top 70th Acc: 1.0000, Bottom 30th Acc: 0.6667
Fold [2/5] Epoch [30/100] Initial Loss: 0.1382, Training Loss: 0.0167, Initial Validation Loss: 0.1311, Validation Loss: 0.0219,V Acc: 0.8829, Top 70th Acc: 1.0000, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 30  Rolling back to Epoch (base 0): 25  Top Validation Acc: 1.0
Fold [3/5] Epoch [0/100] Initial Loss: 0.1429, Training Loss: 0.1429, Initial Validation Loss: 0.1342, Validation Loss: 0.1342,V Acc: 0.3000, Top 70th Acc: 0.3896, Bottom 30th Acc: 0.0909
Fold [3/5] Epoch [10/100] Initial Loss: 0.1429, Training Loss: 0.0298, Initial Validation Loss: 0.1342, Validation Loss: 0.0319,V Acc: 0.8818, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 18  Rolling back to Epoch (base 0): 13  Top Validation Acc: 0.987012987012987
Fold [4/5] Epoch [0/100] Initial Loss: 0.1414, Training Loss: 0.1414, Initial Validation Loss: 0.1281, Validation Loss: 0.1281,V Acc: 0.2936, Top 70th Acc: 0.3766, Bottom 30th Acc: 0.0938
Fold [4/5] Epoch [10/100] Initial Loss: 0.1414, Training Loss: 0.0338, Initial Validation Loss: 0.1281, Validation Loss: 0.0400,V Acc: 0.7615, Top 70th Acc: 0.8701, Bottom 30th Acc: 0.5000
Fold [4/5] Epoch [20/100] Initial Loss: 0.1414, Training Loss: 0.0175, Initial Validation Loss: 0.1281, Validation Loss: 0.0322,V Acc: 0.7982, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.5000
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.8961038961038961
Fold [5/5] Epoch [0/100] Initial Loss: 0.1379, Training Loss: 0.1379, Initial Validation Loss: 0.1371, Validation Loss: 0.1371,V Acc: 0.2500, Top 70th Acc: 0.2632, Bottom 30th Acc: 0.2188
Fold [5/5] Epoch [10/100] Initial Loss: 0.1379, Training Loss: 0.0312, Initial Validation Loss: 0.1371, Validation Loss: 0.0410,V Acc: 0.8148, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.5312
Fold [5/5] Epoch [20/100] Initial Loss: 0.1379, Training Loss: 0.0178, Initial Validation Loss: 0.1371, Validation Loss: 0.0355,V Acc: 0.8333, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.5625
Fold [5/5] Epoch [30/100] Initial Loss: 0.1379, Training Loss: 0.0153, Initial Validation Loss: 0.1371, Validation Loss: 0.0345,V Acc: 0.8519, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.5938
Stopping early at Epoch (base 0): 34  Rolling back to Epoch (base 0): 29  Top Validation Acc: 0.9736842105263158
94 4 [array([0.7757603 , 0.04089231, 0.0250388 , 0.06378029, 0.09452822],
      dtype=float32)]
Running train_nn.py with seed 95
CUDA:False
Training samples count:  550
Training on 30 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1389, Training Loss: 0.1389, Initial Validation Loss: 0.1308, Validation Loss: 0.1308,V Acc: 0.3750, Top 70th Acc: 0.4557, Bottom 30th Acc: 0.1818
Fold [1/5] Epoch [10/100] Initial Loss: 0.1389, Training Loss: 0.0248, Initial Validation Loss: 0.1308, Validation Loss: 0.0436,V Acc: 0.8036, Top 70th Acc: 0.8608, Bottom 30th Acc: 0.6667
Fold [1/5] Epoch [30/100] Initial Loss: 0.1384, Training Loss: 0.0213, Initial Validation Loss: 0.1299, Validation Loss: 0.0420,V Acc: 0.7857, Top 70th Acc: 0.8734, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 31  Rolling back to Epoch (base 0): 26  Top Validation Acc: 0.8734177215189873
Fold [2/5] Epoch [0/100] Initial Loss: 0.1372, Training Loss: 0.1372, Initial Validation Loss: 0.1344, Validation Loss: 0.1344,V Acc: 0.3333, Top 70th Acc: 0.3718, Bottom 30th Acc: 0.2424
Fold [2/5] Epoch [10/100] Initial Loss: 0.1372, Training Loss: 0.0401, Initial Validation Loss: 0.1344, Validation Loss: 0.0348,V Acc: 0.8829, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.7576
Fold [2/5] Epoch [20/100] Initial Loss: 0.1372, Training Loss: 0.0251, Initial Validation Loss: 0.1344, Validation Loss: 0.0260,V Acc: 0.9009, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.7576
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.9358974358974359
Fold [3/5] Epoch [0/100] Initial Loss: 0.1413, Training Loss: 0.1413, Initial Validation Loss: 0.1361, Validation Loss: 0.1361,V Acc: 0.3273, Top 70th Acc: 0.2987, Bottom 30th Acc: 0.3939
Fold [3/5] Epoch [10/100] Initial Loss: 0.1413, Training Loss: 0.0400, Initial Validation Loss: 0.1361, Validation Loss: 0.0362,V Acc: 0.8545, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.6061
Fold [3/5] Epoch [20/100] Initial Loss: 0.1413, Training Loss: 0.0252, Initial Validation Loss: 0.1361, Validation Loss: 0.0296,V Acc: 0.8455, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.935064935064935
Fold [4/5] Epoch [0/100] Initial Loss: 0.1407, Training Loss: 0.1407, Initial Validation Loss: 0.1321, Validation Loss: 0.1321,V Acc: 0.2936, Top 70th Acc: 0.3247, Bottom 30th Acc: 0.2188
Fold [4/5] Epoch [10/100] Initial Loss: 0.1407, Training Loss: 0.0374, Initial Validation Loss: 0.1321, Validation Loss: 0.0383,V Acc: 0.8440, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.6250
Fold [4/5] Epoch [20/100] Initial Loss: 0.1407, Training Loss: 0.0246, Initial Validation Loss: 0.1321, Validation Loss: 0.0325,V Acc: 0.8807, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.7500
Fold [4/5] Epoch [30/100] Initial Loss: 0.1407, Training Loss: 0.0221, Initial Validation Loss: 0.1321, Validation Loss: 0.0314,V Acc: 0.8624, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.6875
Stopping early at Epoch (base 0): 36  Rolling back to Epoch (base 0): 31  Top Validation Acc: 0.948051948051948
Fold [5/5] Epoch [0/100] Initial Loss: 0.1395, Training Loss: 0.1395, Initial Validation Loss: 0.1308, Validation Loss: 0.1308,V Acc: 0.3148, Top 70th Acc: 0.4211, Bottom 30th Acc: 0.0625
Fold [5/5] Epoch [10/100] Initial Loss: 0.1395, Training Loss: 0.0432, Initial Validation Loss: 0.1308, Validation Loss: 0.0499,V Acc: 0.7407, Top 70th Acc: 0.8421, Bottom 30th Acc: 0.5000
Fold [5/5] Epoch [20/100] Initial Loss: 0.1395, Training Loss: 0.0247, Initial Validation Loss: 0.1308, Validation Loss: 0.0363,V Acc: 0.8241, Top 70th Acc: 0.9211, Bottom 30th Acc: 0.5938
Fold [5/5] Epoch [30/100] Initial Loss: 0.1395, Training Loss: 0.0211, Initial Validation Loss: 0.1308, Validation Loss: 0.0364,V Acc: 0.7963, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.4688
Stopping early at Epoch (base 0): 31  Rolling back to Epoch (base 0): 26  Top Validation Acc: 0.9078947368421053
95 4 [array([0.50903547, 0.07691155, 0.09199825, 0.23911262, 0.08294208],
      dtype=float32)]
Running train_nn.py with seed 96
CUDA:False
Training samples count:  550
Training on 20 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1378, Training Loss: 0.1378, Initial Validation Loss: 0.1371, Validation Loss: 0.1371,V Acc: 0.3929, Top 70th Acc: 0.4430, Bottom 30th Acc: 0.2727
Fold [1/5] Epoch [10/100] Initial Loss: 0.1378, Training Loss: 0.0427, Initial Validation Loss: 0.1371, Validation Loss: 0.0381,V Acc: 0.8482, Top 70th Acc: 0.9620, Bottom 30th Acc: 0.5758
Fold [1/5] Epoch [20/100] Initial Loss: 0.1378, Training Loss: 0.0262, Initial Validation Loss: 0.1371, Validation Loss: 0.0258,V Acc: 0.9107, Top 70th Acc: 0.9747, Bottom 30th Acc: 0.7576
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.9746835443037974
Fold [2/5] Epoch [0/100] Initial Loss: 0.1381, Training Loss: 0.1381, Initial Validation Loss: 0.1318, Validation Loss: 0.1318,V Acc: 0.3063, Top 70th Acc: 0.3846, Bottom 30th Acc: 0.1212
Fold [2/5] Epoch [10/100] Initial Loss: 0.1381, Training Loss: 0.0344, Initial Validation Loss: 0.1318, Validation Loss: 0.0405,V Acc: 0.8378, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.6667
Fold [2/5] Epoch [20/100] Initial Loss: 0.1381, Training Loss: 0.0235, Initial Validation Loss: 0.1318, Validation Loss: 0.0363,V Acc: 0.8198, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.9102564102564102
Fold [3/5] Epoch [0/100] Initial Loss: 0.1392, Training Loss: 0.1392, Initial Validation Loss: 0.1319, Validation Loss: 0.1319,V Acc: 0.2545, Top 70th Acc: 0.2727, Bottom 30th Acc: 0.2121
Fold [3/5] Epoch [10/100] Initial Loss: 0.1392, Training Loss: 0.0411, Initial Validation Loss: 0.1319, Validation Loss: 0.0456,V Acc: 0.8000, Top 70th Acc: 0.8961, Bottom 30th Acc: 0.5758
Fold [3/5] Epoch [20/100] Initial Loss: 0.1392, Training Loss: 0.0220, Initial Validation Loss: 0.1319, Validation Loss: 0.0389,V Acc: 0.7818, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.4545
Stopping early at Epoch (base 0): 21  Rolling back to Epoch (base 0): 16  Top Validation Acc: 0.922077922077922
Fold [4/5] Epoch [0/100] Initial Loss: 0.1364, Training Loss: 0.1364, Initial Validation Loss: 0.1287, Validation Loss: 0.1287,V Acc: 0.3486, Top 70th Acc: 0.3636, Bottom 30th Acc: 0.3125
Fold [4/5] Epoch [10/100] Initial Loss: 0.1364, Training Loss: 0.0325, Initial Validation Loss: 0.1287, Validation Loss: 0.0417,V Acc: 0.8165, Top 70th Acc: 0.8701, Bottom 30th Acc: 0.6875
Fold [4/5] Epoch [20/100] Initial Loss: 0.1364, Training Loss: 0.0231, Initial Validation Loss: 0.1287, Validation Loss: 0.0380,V Acc: 0.8073, Top 70th Acc: 0.8961, Bottom 30th Acc: 0.5938
Stopping early at Epoch (base 0): 27  Rolling back to Epoch (base 0): 22  Top Validation Acc: 0.8961038961038961
96 3 [array([0.53079665, 0.06953501, 0.14262633, 0.12162141, 0.1354207 ],
      dtype=float32)]
Fold [5/5] Epoch [0/100] Initial Loss: 0.1379, Training Loss: 0.1379, Initial Validation Loss: 0.1296, Validation Loss: 0.1296,V Acc: 0.2870, Top 70th Acc: 0.3421, Bottom 30th Acc: 0.1562
Fold [5/5] Epoch [10/100] Initial Loss: 0.1379, Training Loss: 0.0297, Initial Validation Loss: 0.1296, Validation Loss: 0.0352,V Acc: 0.8241, Top 70th Acc: 0.9211, Bottom 30th Acc: 0.5938
Fold [5/5] Epoch [20/100] Initial Loss: 0.1379, Training Loss: 0.0228, Initial Validation Loss: 0.1296, Validation Loss: 0.0311,V Acc: 0.8519, Top 70th Acc: 0.9211, Bottom 30th Acc: 0.6875
Stopping early at Epoch (base 0): 29  Rolling back to Epoch (base 0): 24  Top Validation Acc: 0.9210526315789473
Running train_nn.py with seed 97
CUDA:False
Training samples count:  550
Training on 20 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1376, Training Loss: 0.1376, Initial Validation Loss: 0.1338, Validation Loss: 0.1338,V Acc: 0.4018, Top 70th Acc: 0.4684, Bottom 30th Acc: 0.2424
Fold [1/5] Epoch [10/100] Initial Loss: 0.1376, Training Loss: 0.0301, Initial Validation Loss: 0.1338, Validation Loss: 0.0307,V Acc: 0.8839, Top 70th Acc: 0.9114, Bottom 30th Acc: 0.8182
Fold [1/5] Epoch [20/100] Initial Loss: 0.1376, Training Loss: 0.0223, Initial Validation Loss: 0.1338, Validation Loss: 0.0281,V Acc: 0.8839, Top 70th Acc: 0.9367, Bottom 30th Acc: 0.7576
Fold [1/5] Epoch [30/100] Initial Loss: 0.1376, Training Loss: 0.0207, Initial Validation Loss: 0.1338, Validation Loss: 0.0280,V Acc: 0.8750, Top 70th Acc: 0.9241, Bottom 30th Acc: 0.7576
Stopping early at Epoch (base 0): 31  Rolling back to Epoch (base 0): 26  Top Validation Acc: 0.9367088607594937
Fold [2/5] Epoch [0/100] Initial Loss: 0.1386, Training Loss: 0.1386, Initial Validation Loss: 0.1332, Validation Loss: 0.1332,V Acc: 0.3514, Top 70th Acc: 0.4103, Bottom 30th Acc: 0.2121
Stopping early at Epoch (base 0): 33  Rolling back to Epoch (base 0): 28  Top Validation Acc: 0.7142857142857143
96 3 [array([0.13489689, 0.36750132, 0.13042165, 0.23117115, 0.13600898],
      dtype=float32)]
Fold [5/5] Epoch [0/100] Initial Loss: 0.1351, Training Loss: 0.1351, Initial Validation Loss: 0.1224, Validation Loss: 0.1224,V Acc: 0.4630, Top 70th Acc: 0.5395, Bottom 30th Acc: 0.2812
Fold [5/5] Epoch [10/100] Initial Loss: 0.1351, Training Loss: 0.0809, Initial Validation Loss: 0.1224, Validation Loss: 0.0761,V Acc: 0.6759, Top 70th Acc: 0.7632, Bottom 30th Acc: 0.4688
Fold [5/5] Epoch [20/100] Initial Loss: 0.1351, Training Loss: 0.0795, Initial Validation Loss: 0.1224, Validation Loss: 0.0760,V Acc: 0.6759, Top 70th Acc: 0.7105, Bottom 30th Acc: 0.5938
Fold [5/5] Epoch [30/100] Initial Loss: 0.1351, Training Loss: 0.0791, Initial Validation Loss: 0.1224, Validation Loss: 0.0749,V Acc: 0.6574, Top 70th Acc: 0.7237, Bottom 30th Acc: 0.5000
Stopping early at Epoch (base 0): 32  Rolling back to Epoch (base 0): 27  Top Validation Acc: 0.7368421052631579
Running train_nn.py with seed 97
CUDA:False
Training samples count:  550
Training on 2 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1366, Training Loss: 0.1366, Initial Validation Loss: 0.1288, Validation Loss: 0.1288,V Acc: 0.4554, Top 70th Acc: 0.5570, Bottom 30th Acc: 0.2121
Fold [1/5] Epoch [10/100] Initial Loss: 0.1366, Training Loss: 0.0847, Initial Validation Loss: 0.1288, Validation Loss: 0.0694,V Acc: 0.6964, Top 70th Acc: 0.8101, Bottom 30th Acc: 0.4242
Fold [1/5] Epoch [20/100] Initial Loss: 0.1366, Training Loss: 0.0824, Initial Validation Loss: 0.1288, Validation Loss: 0.0669,V Acc: 0.6875, Top 70th Acc: 0.8101, Bottom 30th Acc: 0.3939
Fold [1/5] Epoch [30/100] Initial Loss: 0.1366, Training Loss: 0.0822, Initial Validation Loss: 0.1288, Validation Loss: 0.0655,V Acc: 0.7232, Top 70th Acc: 0.8354, Bottom 30th Acc: 0.4545
Fold [1/5] Epoch [40/100] Initial Loss: 0.1366, Training Loss: 0.0822, Initial Validation Loss: 0.1288, Validation Loss: 0.0649,V Acc: 0.7232, Top 70th Acc: 0.8101, Bottom 30th Acc: 0.5152
Fold [1/5] Epoch [50/100] Initial Loss: 0.1366, Training Loss: 0.0819, Initial Validation Loss: 0.1288, Validation Loss: 0.0640,V Acc: 0.7321, Top 70th Acc: 0.8228, Bottom 30th Acc: 0.5152
Stopping early at Epoch (base 0): 55  Rolling back to Epoch (base 0): 50  Top Validation Acc: 0.8354430379746836
Fold [2/5] Epoch [0/100] Initial Loss: 0.1319, Training Loss: 0.1319, Initial Validation Loss: 0.1192, Validation Loss: 0.1192,V Acc: 0.4595, Top 70th Acc: 0.5128, Bottom 30th Acc: 0.3333
Fold [2/5] Epoch [10/100] Initial Loss: 0.1319, Training Loss: 0.0759, Initial Validation Loss: 0.1192, Validation Loss: 0.0929,V Acc: 0.5676, Top 70th Acc: 0.6538, Bottom 30th Acc: 0.3636
Fold [2/5] Epoch [20/100] Initial Loss: 0.1319, Training Loss: 0.0748, Initial Validation Loss: 0.1192, Validation Loss: 0.0916,V Acc: 0.5495, Top 70th Acc: 0.6282, Bottom 30th Acc: 0.3636
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.6025641025641025
97 1 [array([0.12677732, 0.34594172, 0.11266532, 0.23478232, 0.17983338],
      dtype=float32)]
Fold [3/5] Epoch [0/100] Initial Loss: 0.1396, Training Loss: 0.1396, Initial Validation Loss: 0.1312, Validation Loss: 0.1312,V Acc: 0.4000, Top 70th Acc: 0.5325, Bottom 30th Acc: 0.0909
Fold [3/5] Epoch [10/100] Initial Loss: 0.1396, Training Loss: 0.0831, Initial Validation Loss: 0.1312, Validation Loss: 0.0721,V Acc: 0.6545, Top 70th Acc: 0.7532, Bottom 30th Acc: 0.4242
Fold [3/5] Epoch [20/100] Initial Loss: 0.1396, Training Loss: 0.0809, Initial Validation Loss: 0.1312, Validation Loss: 0.0701,V Acc: 0.6818, Top 70th Acc: 0.7532, Bottom 30th Acc: 0.5152
Fold [3/5] Epoch [30/100] Initial Loss: 0.1396, Training Loss: 0.0804, Initial Validation Loss: 0.1312, Validation Loss: 0.0695,V Acc: 0.6727, Top 70th Acc: 0.7662, Bottom 30th Acc: 0.4545
Stopping early at Epoch (base 0): 38  Rolling back to Epoch (base 0): 33  Top Validation Acc: 0.7662337662337663
Fold [4/5] Epoch [0/100] Initial Loss: 0.1332, Training Loss: 0.1332, Initial Validation Loss: 0.1197, Validation Loss: 0.1197,V Acc: 0.5321, Top 70th Acc: 0.6494, Bottom 30th Acc: 0.2500
Fold [4/5] Epoch [10/100] Initial Loss: 0.1332, Training Loss: 0.0791, Initial Validation Loss: 0.1197, Validation Loss: 0.0829,V Acc: 0.6055, Top 70th Acc: 0.7013, Bottom 30th Acc: 0.3750
Fold [4/5] Epoch [20/100] Initial Loss: 0.1332, Training Loss: 0.0774, Initial Validation Loss: 0.1197, Validation Loss: 0.0824,V Acc: 0.5872, Top 70th Acc: 0.7143, Bottom 30th Acc: 0.2812
Stopping early at Epoch (base 0): 22  Rolling back to Epoch (base 0): 17  Top Validation Acc: 0.7142857142857143
Fold [5/5] Epoch [0/100] Initial Loss: 0.1386, Training Loss: 0.1386, Initial Validation Loss: 0.1262, Validation Loss: 0.1262,V Acc: 0.3611, Top 70th Acc: 0.4211, Bottom 30th Acc: 0.2188
Fold [5/5] Epoch [10/100] Initial Loss: 0.1386, Training Loss: 0.0806, Initial Validation Loss: 0.1262, Validation Loss: 0.0818,V Acc: 0.6204, Top 70th Acc: 0.7500, Bottom 30th Acc: 0.3125
Fold [5/5] Epoch [20/100] Initial Loss: 0.1386, Training Loss: 0.0779, Initial Validation Loss: 0.1262, Validation Loss: 0.0806,V Acc: 0.6111, Top 70th Acc: 0.7763, Bottom 30th Acc: 0.2188
Stopping early at Epoch (base 0): 28  Rolling back to Epoch (base 0): 23  Top Validation Acc: 0.75
Running train_nn.py with seed 98
CUDA:False
Training samples count:  550
Training on 2 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1347, Training Loss: 0.1347, Initial Validation Loss: 0.1273, Validation Loss: 0.1273,V Acc: 0.3750, Top 70th Acc: 0.4684, Bottom 30th Acc: 0.1515
Fold [1/5] Epoch [10/100] Initial Loss: 0.1347, Training Loss: 0.0818, Initial Validation Loss: 0.1273, Validation Loss: 0.0777,V Acc: 0.6161, Top 70th Acc: 0.7848, Bottom 30th Acc: 0.2121
Fold [1/5] Epoch [20/100] Initial Loss: 0.1347, Training Loss: 0.0801, Initial Validation Loss: 0.1273, Validation Loss: 0.0759,V Acc: 0.6161, Top 70th Acc: 0.7722, Bottom 30th Acc: 0.2424
Stopping early at Epoch (base 0): 28  Rolling back to Epoch (base 0): 23  Top Validation Acc: 0.7468354430379747
Fold [2/5] Epoch [0/100] Initial Loss: 0.1365, Training Loss: 0.1365, Initial Validation Loss: 0.1297, Validation Loss: 0.1297,V Acc: 0.4054, Top 70th Acc: 0.5128, Bottom 30th Acc: 0.1515
Fold [2/5] Epoch [10/100] Initial Loss: 0.1365, Training Loss: 0.0799, Initial Validation Loss: 0.1297, Validation Loss: 0.0799,V Acc: 0.6486, Top 70th Acc: 0.7564, Bottom 30th Acc: 0.3939
Fold [2/5] Epoch [20/100] Initial Loss: 0.1365, Training Loss: 0.0779, Initial Validation Loss: 0.1297, Validation Loss: 0.0784,V Acc: 0.6486, Top 70th Acc: 0.7692, Bottom 30th Acc: 0.3636
Fold [2/5] Epoch [30/100] Initial Loss: 0.1365, Training Loss: 0.0772, Initial Validation Loss: 0.1297, Validation Loss: 0.0779,V Acc: 0.6486, Top 70th Acc: 0.7692, Bottom 30th Acc: 0.3636
Fold [2/5] Epoch [40/100] Initial Loss: 0.1365, Training Loss: 0.0769, Initial Validation Loss: 0.1297, Validation Loss: 0.0778,V Acc: 0.6486, Top 70th Acc: 0.7692, Bottom 30th Acc: 0.3636
Stopping early at Epoch (base 0): 46  Rolling back to Epoch (base 0): 41  Top Validation Acc: 0.7692307692307693
Fold [3/5] Epoch [0/100] Initial Loss: 0.1371, Training Loss: 0.1371, Initial Validation Loss: 0.1301, Validation Loss: 0.1301,V Acc: 0.3909, Top 70th Acc: 0.4805, Bottom 30th Acc: 0.1818
Fold [3/5] Epoch [10/100] Initial Loss: 0.1371, Training Loss: 0.0784, Initial Validation Loss: 0.1301, Validation Loss: 0.0868,V Acc: 0.5455, Top 70th Acc: 0.6623, Bottom 30th Acc: 0.2727
Stopping early at Epoch (base 0): 19  Rolling back to Epoch (base 0): 14  Top Validation Acc: 0.6753246753246753
Fold [4/5] Epoch [0/100] Initial Loss: 0.1390, Training Loss: 0.1390, Initial Validation Loss: 0.1280, Validation Loss: 0.1280,V Acc: 0.3945, Top 70th Acc: 0.5195, Bottom 30th Acc: 0.0938
Fold [4/5] Epoch [10/100] Initial Loss: 0.1390, Training Loss: 0.0815, Initial Validation Loss: 0.1280, Validation Loss: 0.0788,V Acc: 0.6147, Top 70th Acc: 0.7403, Bottom 30th Acc: 0.3125
Fold [4/5] Epoch [20/100] Initial Loss: 0.1390, Training Loss: 0.0790, Initial Validation Loss: 0.1280, Validation Loss: 0.0771,V Acc: 0.6422, Top 70th Acc: 0.7273, Bottom 30th Acc: 0.4375
Fold [2/5] Epoch [10/100] Initial Loss: 0.1364, Training Loss: 0.0335, Initial Validation Loss: 0.1336, Validation Loss: 0.0444,V Acc: 0.8108, Top 70th Acc: 0.8846, Bottom 30th Acc: 0.6364
Fold [2/5] Epoch [20/100] Initial Loss: 0.1364, Training Loss: 0.0151, Initial Validation Loss: 0.1336, Validation Loss: 0.0362,V Acc: 0.8468, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 28  Rolling back to Epoch (base 0): 23  Top Validation Acc: 0.9358974358974359
Fold [3/5] Epoch [0/100] Initial Loss: 0.1413, Training Loss: 0.1413, Initial Validation Loss: 0.1355, Validation Loss: 0.1355,V Acc: 0.2545, Top 70th Acc: 0.3377, Bottom 30th Acc: 0.0606
Fold [3/5] Epoch [10/100] Initial Loss: 0.1413, Training Loss: 0.0292, Initial Validation Loss: 0.1355, Validation Loss: 0.0400,V Acc: 0.8000, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.5455
Fold [3/5] Epoch [20/100] Initial Loss: 0.1413, Training Loss: 0.0135, Initial Validation Loss: 0.1355, Validation Loss: 0.0373,V Acc: 0.7818, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.4848
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.9090909090909091
Fold [4/5] Epoch [0/100] Initial Loss: 0.1394, Training Loss: 0.1394, Initial Validation Loss: 0.1303, Validation Loss: 0.1303,V Acc: 0.3303, Top 70th Acc: 0.3117, Bottom 30th Acc: 0.3750
Fold [4/5] Epoch [10/100] Initial Loss: 0.1394, Training Loss: 0.0319, Initial Validation Loss: 0.1303, Validation Loss: 0.0306,V Acc: 0.8440, Top 70th Acc: 0.9870, Bottom 30th Acc: 0.5000
Fold [4/5] Epoch [20/100] Initial Loss: 0.1394, Training Loss: 0.0147, Initial Validation Loss: 0.1303, Validation Loss: 0.0252,V Acc: 0.8349, Top 70th Acc: 0.9870, Bottom 30th Acc: 0.4688
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.987012987012987
98 3 [array([0.6185235 , 0.03996358, 0.05578664, 0.09103528, 0.19469099],
      dtype=float32)]
Fold [5/5] Epoch [0/100] Initial Loss: 0.1378, Training Loss: 0.1378, Initial Validation Loss: 0.1293, Validation Loss: 0.1293,V Acc: 0.3426, Top 70th Acc: 0.3684, Bottom 30th Acc: 0.2812
Fold [5/5] Epoch [10/100] Initial Loss: 0.1378, Training Loss: 0.0273, Initial Validation Loss: 0.1293, Validation Loss: 0.0327,V Acc: 0.8519, Top 70th Acc: 0.9737, Bottom 30th Acc: 0.5625
Fold [5/5] Epoch [20/100] Initial Loss: 0.1378, Training Loss: 0.0151, Initial Validation Loss: 0.1293, Validation Loss: 0.0322,V Acc: 0.8426, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.5938
Stopping early at Epoch (base 0): 21  Rolling back to Epoch (base 0): 16  Top Validation Acc: 0.9473684210526315
Running train_nn.py with seed 99
CUDA:False
Training samples count:  550
Training on 40 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1392, Training Loss: 0.1392, Initial Validation Loss: 0.1361, Validation Loss: 0.1361,V Acc: 0.2589, Top 70th Acc: 0.3418, Bottom 30th Acc: 0.0606
Fold [1/5] Epoch [10/100] Initial Loss: 0.1392, Training Loss: 0.0342, Initial Validation Loss: 0.1361, Validation Loss: 0.0385,V Acc: 0.8125, Top 70th Acc: 0.9620, Bottom 30th Acc: 0.4545
Fold [1/5] Epoch [20/100] Initial Loss: 0.1392, Training Loss: 0.0192, Initial Validation Loss: 0.1361, Validation Loss: 0.0327,V Acc: 0.8304, Top 70th Acc: 0.9620, Bottom 30th Acc: 0.5152
Fold [1/5] Epoch [30/100] Initial Loss: 0.1392, Training Loss: 0.0147, Initial Validation Loss: 0.1361, Validation Loss: 0.0323,V Acc: 0.8304, Top 70th Acc: 0.9747, Bottom 30th Acc: 0.4848
Stopping early at Epoch (base 0): 32  Rolling back to Epoch (base 0): 27  Top Validation Acc: 0.9620253164556962
Fold [2/5] Epoch [0/100] Initial Loss: 0.1397, Training Loss: 0.1397, Initial Validation Loss: 0.1367, Validation Loss: 0.1367,V Acc: 0.2523, Top 70th Acc: 0.3333, Bottom 30th Acc: 0.0606
Fold [2/5] Epoch [10/100] Initial Loss: 0.1397, Training Loss: 0.0321, Initial Validation Loss: 0.1367, Validation Loss: 0.0433,V Acc: 0.7928, Top 70th Acc: 0.8846, Bottom 30th Acc: 0.5758
Fold [2/5] Epoch [20/100] Initial Loss: 0.1397, Training Loss: 0.0149, Initial Validation Loss: 0.1367, Validation Loss: 0.0336,V Acc: 0.8468, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 27  Rolling back to Epoch (base 0): 22  Top Validation Acc: 0.9487179487179487
99 1 [array([0.6281447 , 0.15470722, 0.0182155 , 0.08209261, 0.11683998],
      dtype=float32)]
Fold [3/5] Epoch [0/100] Initial Loss: 0.1398, Training Loss: 0.1398, Initial Validation Loss: 0.1306, Validation Loss: 0.1306,V Acc: 0.3364, Top 70th Acc: 0.4286, Bottom 30th Acc: 0.1212
Fold [3/5] Epoch [10/100] Initial Loss: 0.1398, Training Loss: 0.0283, Initial Validation Loss: 0.1306, Validation Loss: 0.0370,V Acc: 0.8091, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.5758
Fold [3/5] Epoch [20/100] Initial Loss: 0.1398, Training Loss: 0.0156, Initial Validation Loss: 0.1306, Validation Loss: 0.0308,V Acc: 0.8182, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.4848
Fold [3/5] Epoch [30/100] Initial Loss: 0.1398, Training Loss: 0.0131, Initial Validation Loss: 0.1306, Validation Loss: 0.0294,V Acc: 0.8364, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 31  Rolling back to Epoch (base 0): 26  Top Validation Acc: 0.961038961038961
Fold [4/5] Epoch [0/100] Initial Loss: 0.1367, Training Loss: 0.1367, Initial Validation Loss: 0.1275, Validation Loss: 0.1275,V Acc: 0.4037, Top 70th Acc: 0.4935, Bottom 30th Acc: 0.1875
Fold [4/5] Epoch [10/100] Initial Loss: 0.1367, Training Loss: 0.0302, Initial Validation Loss: 0.1275, Validation Loss: 0.0354,V Acc: 0.8440, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.6562
Fold [4/5] Epoch [20/100] Initial Loss: 0.1367, Training Loss: 0.0161, Initial Validation Loss: 0.1275, Validation Loss: 0.0277,V Acc: 0.8440, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.6250
Stopping early at Epoch (base 0): 27  Rolling back to Epoch (base 0): 22  Top Validation Acc: 0.948051948051948
Fold [5/5] Epoch [0/100] Initial Loss: 0.1399, Training Loss: 0.1399, Initial Validation Loss: 0.1307, Validation Loss: 0.1307,V Acc: 0.3241, Top 70th Acc: 0.4211, Bottom 30th Acc: 0.0938
Fold [5/5] Epoch [10/100] Initial Loss: 0.1399, Training Loss: 0.0319, Initial Validation Loss: 0.1307, Validation Loss: 0.0424,V Acc: 0.7593, Top 70th Acc: 0.9211, Bottom 30th Acc: 0.3750
Fold [5/5] Epoch [20/100] Initial Loss: 0.1399, Training Loss: 0.0160, Initial Validation Loss: 0.1307, Validation Loss: 0.0340,V Acc: 0.8148, Top 70th Acc: 0.9211, Bottom 30th Acc: 0.5625
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.9078947368421053
Running train_nn.py with seed 100
CUDA:False
Training samples count:  550
Training on 40 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1388, Training Loss: 0.1388, Initial Validation Loss: 0.1375, Validation Loss: 0.1375,V Acc: 0.2857, Top 70th Acc: 0.3544, Bottom 30th Acc: 0.1212
Fold [1/5] Epoch [10/100] Initial Loss: 0.1388, Training Loss: 0.0312, Initial Validation Loss: 0.1375, Validation Loss: 0.0336,V Acc: 0.8393, Top 70th Acc: 0.9620, Bottom 30th Acc: 0.5455
Fold [1/5] Epoch [20/100] Initial Loss: 0.1388, Training Loss: 0.0152, Initial Validation Loss: 0.1375, Validation Loss: 0.0270,V Acc: 0.8571, Top 70th Acc: 0.9747, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 27  Rolling back to Epoch (base 0): 22  Top Validation Acc: 0.9746835443037974
Fold [2/5] Epoch [0/100] Initial Loss: 0.1397, Training Loss: 0.1397, Initial Validation Loss: 0.1323, Validation Loss: 0.1323,V Acc: 0.2793, Top 70th Acc: 0.3462, Bottom 30th Acc: 0.1212
Fold [2/5] Epoch [10/100] Initial Loss: 0.1397, Training Loss: 0.0312, Initial Validation Loss: 0.1323, Validation Loss: 0.0476,V Acc: 0.7658, Top 70th Acc: 0.8846, Bottom 30th Acc: 0.4848
Stopping early at Epoch (base 0): 15  Rolling back to Epoch (base 0): 10  Top Validation Acc: 0.8846153846153846
Fold [3/5] Epoch [0/100] Initial Loss: 0.1401, Training Loss: 0.1401, Initial Validation Loss: 0.1353, Validation Loss: 0.1353,V Acc: 0.2545, Top 70th Acc: 0.2987, Bottom 30th Acc: 0.1515
Fold [3/5] Epoch [10/100] Initial Loss: 0.1401, Training Loss: 0.0347, Initial Validation Loss: 0.1353, Validation Loss: 0.0415,V Acc: 0.8455, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.6364
Fold [1/5] Epoch [20/100] Initial Loss: 0.1389, Training Loss: 0.0152, Initial Validation Loss: 0.1308, Validation Loss: 0.0387,V Acc: 0.7946, Top 70th Acc: 0.8861, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.8860759493670886
Fold [2/5] Epoch [0/100] Initial Loss: 0.1353, Training Loss: 0.1353, Initial Validation Loss: 0.1323, Validation Loss: 0.1323,V Acc: 0.3694, Top 70th Acc: 0.3718, Bottom 30th Acc: 0.3636
Fold [2/5] Epoch [10/100] Initial Loss: 0.1353, Training Loss: 0.0292, Initial Validation Loss: 0.1323, Validation Loss: 0.0307,V Acc: 0.8739, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.6364
Fold [2/5] Epoch [20/100] Initial Loss: 0.1353, Training Loss: 0.0176, Initial Validation Loss: 0.1323, Validation Loss: 0.0265,V Acc: 0.8739, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.9615384615384616
Fold [3/5] Epoch [0/100] Initial Loss: 0.1385, Training Loss: 0.1385, Initial Validation Loss: 0.1367, Validation Loss: 0.1367,V Acc: 0.2545, Top 70th Acc: 0.3506, Bottom 30th Acc: 0.0303
Fold [3/5] Epoch [10/100] Initial Loss: 0.1385, Training Loss: 0.0448, Initial Validation Loss: 0.1367, Validation Loss: 0.0442,V Acc: 0.7818, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.4242
Fold [3/5] Epoch [20/100] Initial Loss: 0.1385, Training Loss: 0.0190, Initial Validation Loss: 0.1367, Validation Loss: 0.0264,V Acc: 0.8545, Top 70th Acc: 0.9870, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.987012987012987
Fold [4/5] Epoch [0/100] Initial Loss: 0.1392, Training Loss: 0.1392, Initial Validation Loss: 0.1301, Validation Loss: 0.1301,V Acc: 0.3670, Top 70th Acc: 0.4286, Bottom 30th Acc: 0.2188
Fold [4/5] Epoch [10/100] Initial Loss: 0.1392, Training Loss: 0.0271, Initial Validation Loss: 0.1301, Validation Loss: 0.0285,V Acc: 0.8624, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.6875
Fold [4/5] Epoch [20/100] Initial Loss: 0.1392, Training Loss: 0.0178, Initial Validation Loss: 0.1301, Validation Loss: 0.0253,V Acc: 0.8532, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.5938
Stopping early at Epoch (base 0): 20  Rolling back to Epoch (base 0): 15  Top Validation Acc: 0.961038961038961
Fold [5/5] Epoch [0/100] Initial Loss: 0.1386, Training Loss: 0.1386, Initial Validation Loss: 0.1296, Validation Loss: 0.1296,V Acc: 0.3704, Top 70th Acc: 0.4079, Bottom 30th Acc: 0.2812
Fold [5/5] Epoch [10/100] Initial Loss: 0.1386, Training Loss: 0.0357, Initial Validation Loss: 0.1296, Validation Loss: 0.0464,V Acc: 0.7500, Top 70th Acc: 0.8421, Bottom 30th Acc: 0.5312
Fold [5/5] Epoch [20/100] Initial Loss: 0.1386, Training Loss: 0.0184, Initial Validation Loss: 0.1296, Validation Loss: 0.0339,V Acc: 0.8148, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.5312
Fold [5/5] Epoch [30/100] Initial Loss: 0.1386, Training Loss: 0.0151, Initial Validation Loss: 0.1296, Validation Loss: 0.0331,V Acc: 0.8148, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.5000
Stopping early at Epoch (base 0): 32  Rolling back to Epoch (base 0): 27  Top Validation Acc: 0.9342105263157895
95 4 [array([0.7330167 , 0.01491331, 0.03037774, 0.17946953, 0.04222281],
      dtype=float32)]
Running train_nn.py with seed 96
CUDA:False
Training samples count:  550
Training on 30 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1407, Training Loss: 0.1407, Initial Validation Loss: 0.1416, Validation Loss: 0.1416,V Acc: 0.3393, Top 70th Acc: 0.3165, Bottom 30th Acc: 0.3939
Fold [1/5] Epoch [10/100] Initial Loss: 0.1407, Training Loss: 0.0413, Initial Validation Loss: 0.1416, Validation Loss: 0.0406,V Acc: 0.8214, Top 70th Acc: 0.9367, Bottom 30th Acc: 0.5455
Fold [1/5] Epoch [20/100] Initial Loss: 0.1407, Training Loss: 0.0208, Initial Validation Loss: 0.1416, Validation Loss: 0.0266,V Acc: 0.8661, Top 70th Acc: 0.9873, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.9746835443037974
Fold [2/5] Epoch [0/100] Initial Loss: 0.1412, Training Loss: 0.1412, Initial Validation Loss: 0.1350, Validation Loss: 0.1350,V Acc: 0.3063, Top 70th Acc: 0.3462, Bottom 30th Acc: 0.2121
Fold [2/5] Epoch [10/100] Initial Loss: 0.1412, Training Loss: 0.0441, Initial Validation Loss: 0.1350, Validation Loss: 0.0496,V Acc: 0.7207, Top 70th Acc: 0.8590, Bottom 30th Acc: 0.3939
Fold [2/5] Epoch [20/100] Initial Loss: 0.1412, Training Loss: 0.0210, Initial Validation Loss: 0.1350, Validation Loss: 0.0349,V Acc: 0.8018, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.4242
Stopping early at Epoch (base 0): 22  Rolling back to Epoch (base 0): 17  Top Validation Acc: 0.9487179487179487
Fold [3/5] Epoch [0/100] Initial Loss: 0.1416, Training Loss: 0.1416, Initial Validation Loss: 0.1307, Validation Loss: 0.1307,V Acc: 0.3182, Top 70th Acc: 0.4156, Bottom 30th Acc: 0.0909
Fold [3/5] Epoch [10/100] Initial Loss: 0.1416, Training Loss: 0.0313, Initial Validation Loss: 0.1307, Validation Loss: 0.0348,V Acc: 0.8000, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.4242
Stopping early at Epoch (base 0): 17  Rolling back to Epoch (base 0): 12  Top Validation Acc: 0.935064935064935
Fold [4/5] Epoch [0/100] Initial Loss: 0.1411, Training Loss: 0.1411, Initial Validation Loss: 0.1336, Validation Loss: 0.1336,V Acc: 0.2477, Top 70th Acc: 0.2857, Bottom 30th Acc: 0.1562
Fold [4/5] Epoch [10/100] Initial Loss: 0.1411, Training Loss: 0.0351, Initial Validation Loss: 0.1336, Validation Loss: 0.0439,V Acc: 0.8165, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.5938
Fold [4/5] Epoch [20/100] Initial Loss: 0.1411, Training Loss: 0.0207, Initial Validation Loss: 0.1336, Validation Loss: 0.0386,V Acc: 0.7798, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.4375
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.922077922077922
96 3 [array([0.58665067, 0.05831623, 0.03749809, 0.13027222, 0.1872627 ],
      dtype=float32)]
Fold [5/5] Epoch [0/100] Initial Loss: 0.1433, Training Loss: 0.1433, Initial Validation Loss: 0.1332, Validation Loss: 0.1332,V Acc: 0.2500, Top 70th Acc: 0.3553, Bottom 30th Acc: 0.0000
Fold [5/5] Epoch [10/100] Initial Loss: 0.1433, Training Loss: 0.0272, Initial Validation Loss: 0.1332, Validation Loss: 0.0381,V Acc: 0.8148, Top 70th Acc: 0.9211, Bottom 30th Acc: 0.5625
Fold [5/5] Epoch [20/100] Initial Loss: 0.1433, Training Loss: 0.0182, Initial Validation Loss: 0.1332, Validation Loss: 0.0364,V Acc: 0.8241, Top 70th Acc: 0.8947, Bottom 30th Acc: 0.6562
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.9078947368421053
Running train_nn.py with seed 97
CUDA:False
Training samples count:  550
Training on 30 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1380, Training Loss: 0.1380, Initial Validation Loss: 0.1337, Validation Loss: 0.1337,V Acc: 0.4196, Top 70th Acc: 0.5443, Bottom 30th Acc: 0.1212
Fold [1/5] Epoch [10/100] Initial Loss: 0.1380, Training Loss: 0.0321, Initial Validation Loss: 0.1337, Validation Loss: 0.0339,V Acc: 0.8750, Top 70th Acc: 0.9114, Bottom 30th Acc: 0.7879
Fold [1/5] Epoch [20/100] Initial Loss: 0.1380, Training Loss: 0.0196, Initial Validation Loss: 0.1337, Validation Loss: 0.0255,V Acc: 0.9107, Top 70th Acc: 0.9367, Bottom 30th Acc: 0.8485
Stopping early at Epoch (base 0): 29  Rolling back to Epoch (base 0): 24  Top Validation Acc: 0.9367088607594937
Fold [2/5] Epoch [0/100] Initial Loss: 0.1386, Training Loss: 0.1386, Initial Validation Loss: 0.1349, Validation Loss: 0.1349,V Acc: 0.2883, Top 70th Acc: 0.3333, Bottom 30th Acc: 0.1818
Fold [2/5] Epoch [10/100] Initial Loss: 0.1386, Training Loss: 0.0370, Initial Validation Loss: 0.1349, Validation Loss: 0.0531,V Acc: 0.7658, Top 70th Acc: 0.8333, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 19  Rolling back to Epoch (base 0): 14  Top Validation Acc: 0.8974358974358975
97 1 [array([0.5034347 , 0.09087449, 0.08917996, 0.19057238, 0.12593849],
      dtype=float32)]
Fold [3/5] Epoch [0/100] Initial Loss: 0.1381, Training Loss: 0.1381, Initial Validation Loss: 0.1328, Validation Loss: 0.1328,V Acc: 0.2545, Top 70th Acc: 0.3377, Bottom 30th Acc: 0.0606
Stopping early at Epoch (base 0): 29  Rolling back to Epoch (base 0): 24  Top Validation Acc: 0.9090909090909091
Fold [4/5] Epoch [0/100] Initial Loss: 0.1394, Training Loss: 0.1394, Initial Validation Loss: 0.1340, Validation Loss: 0.1340,V Acc: 0.2661, Top 70th Acc: 0.3117, Bottom 30th Acc: 0.1562
Fold [4/5] Epoch [10/100] Initial Loss: 0.1394, Training Loss: 0.0176, Initial Validation Loss: 0.1340, Validation Loss: 0.0392,V Acc: 0.7798, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.4375
Fold [4/5] Epoch [20/100] Initial Loss: 0.1394, Training Loss: 0.0048, Initial Validation Loss: 0.1340, Validation Loss: 0.0348,V Acc: 0.8073, Top 70th Acc: 0.8961, Bottom 30th Acc: 0.5938
Fold [4/5] Epoch [30/100] Initial Loss: 0.1394, Training Loss: 0.0038, Initial Validation Loss: 0.1340, Validation Loss: 0.0335,V Acc: 0.8165, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.5938
Fold [4/5] Epoch [40/100] Initial Loss: 0.1394, Training Loss: 0.0035, Initial Validation Loss: 0.1340, Validation Loss: 0.0333,V Acc: 0.8073, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.5625
Stopping early at Epoch (base 0): 42  Rolling back to Epoch (base 0): 37  Top Validation Acc: 0.9090909090909091
Fold [5/5] Epoch [0/100] Initial Loss: 0.1383, Training Loss: 0.1383, Initial Validation Loss: 0.1305, Validation Loss: 0.1305,V Acc: 0.2500, Top 70th Acc: 0.3289, Bottom 30th Acc: 0.0625
Fold [5/5] Epoch [10/100] Initial Loss: 0.1383, Training Loss: 0.0153, Initial Validation Loss: 0.1305, Validation Loss: 0.0272,V Acc: 0.8889, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.7188
Fold [5/5] Epoch [20/100] Initial Loss: 0.1383, Training Loss: 0.0052, Initial Validation Loss: 0.1305, Validation Loss: 0.0221,V Acc: 0.9074, Top 70th Acc: 0.9737, Bottom 30th Acc: 0.7500
Fold [5/5] Epoch [30/100] Initial Loss: 0.1383, Training Loss: 0.0043, Initial Validation Loss: 0.1305, Validation Loss: 0.0215,V Acc: 0.8981, Top 70th Acc: 0.9737, Bottom 30th Acc: 0.7188
Stopping early at Epoch (base 0): 39  Rolling back to Epoch (base 0): 34  Top Validation Acc: 0.9736842105263158
Running train_nn.py with seed 74
CUDA:False
Training samples count:  550
Training on 162 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1412, Training Loss: 0.1412, Initial Validation Loss: 0.1373, Validation Loss: 0.1373,V Acc: 0.2232, Top 70th Acc: 0.3038, Bottom 30th Acc: 0.0303
Fold [1/5] Epoch [10/100] Initial Loss: 0.1412, Training Loss: 0.0257, Initial Validation Loss: 0.1373, Validation Loss: 0.0451,V Acc: 0.7857, Top 70th Acc: 0.8734, Bottom 30th Acc: 0.5758
Fold [1/5] Epoch [20/100] Initial Loss: 0.1412, Training Loss: 0.0052, Initial Validation Loss: 0.1373, Validation Loss: 0.0388,V Acc: 0.8214, Top 70th Acc: 0.9241, Bottom 30th Acc: 0.5758
Fold [1/5] Epoch [30/100] Initial Loss: 0.1412, Training Loss: 0.0037, Initial Validation Loss: 0.1373, Validation Loss: 0.0377,V Acc: 0.8304, Top 70th Acc: 0.9241, Bottom 30th Acc: 0.6061
Fold [1/5] Epoch [40/100] Initial Loss: 0.1412, Training Loss: 0.0034, Initial Validation Loss: 0.1373, Validation Loss: 0.0366,V Acc: 0.8393, Top 70th Acc: 0.9241, Bottom 30th Acc: 0.6364
Fold [1/5] Epoch [50/100] Initial Loss: 0.1412, Training Loss: 0.0032, Initial Validation Loss: 0.1373, Validation Loss: 0.0361,V Acc: 0.8304, Top 70th Acc: 0.9367, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 53  Rolling back to Epoch (base 0): 48  Top Validation Acc: 0.9367088607594937
Fold [2/5] Epoch [0/100] Initial Loss: 0.1416, Training Loss: 0.1416, Initial Validation Loss: 0.1376, Validation Loss: 0.1376,V Acc: 0.2252, Top 70th Acc: 0.2436, Bottom 30th Acc: 0.1818
Fold [2/5] Epoch [10/100] Initial Loss: 0.1416, Training Loss: 0.0220, Initial Validation Loss: 0.1376, Validation Loss: 0.0368,V Acc: 0.8378, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.5758
Fold [2/5] Epoch [20/100] Initial Loss: 0.1416, Training Loss: 0.0055, Initial Validation Loss: 0.1376, Validation Loss: 0.0298,V Acc: 0.8468, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.5758
Fold [2/5] Epoch [30/100] Initial Loss: 0.1416, Training Loss: 0.0042, Initial Validation Loss: 0.1376, Validation Loss: 0.0290,V Acc: 0.8198, Top 70th Acc: 0.9872, Bottom 30th Acc: 0.4242
Fold [2/5] Epoch [40/100] Initial Loss: 0.1416, Training Loss: 0.0039, Initial Validation Loss: 0.1376, Validation Loss: 0.0292,V Acc: 0.8288, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.4848
Stopping early at Epoch (base 0): 40  Rolling back to Epoch (base 0): 35  Top Validation Acc: 0.9743589743589743
Fold [3/5] Epoch [0/100] Initial Loss: 0.1394, Training Loss: 0.1394, Initial Validation Loss: 0.1314, Validation Loss: 0.1314,V Acc: 0.3182, Top 70th Acc: 0.3636, Bottom 30th Acc: 0.2121
Fold [3/5] Epoch [10/100] Initial Loss: 0.1394, Training Loss: 0.0200, Initial Validation Loss: 0.1314, Validation Loss: 0.0396,V Acc: 0.8182, Top 70th Acc: 0.8961, Bottom 30th Acc: 0.6364
Fold [3/5] Epoch [20/100] Initial Loss: 0.1394, Training Loss: 0.0055, Initial Validation Loss: 0.1314, Validation Loss: 0.0342,V Acc: 0.8364, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.6364
Fold [3/5] Epoch [30/100] Initial Loss: 0.1394, Training Loss: 0.0042, Initial Validation Loss: 0.1314, Validation Loss: 0.0315,V Acc: 0.8636, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 35  Rolling back to Epoch (base 0): 30  Top Validation Acc: 0.935064935064935
Fold [4/5] Epoch [0/100] Initial Loss: 0.1386, Training Loss: 0.1386, Initial Validation Loss: 0.1339, Validation Loss: 0.1339,V Acc: 0.2936, Top 70th Acc: 0.3247, Bottom 30th Acc: 0.2188
Fold [4/5] Epoch [10/100] Initial Loss: 0.1386, Training Loss: 0.0251, Initial Validation Loss: 0.1339, Validation Loss: 0.0446,V Acc: 0.8073, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.5312
Fold [4/5] Epoch [20/100] Initial Loss: 0.1386, Training Loss: 0.0057, Initial Validation Loss: 0.1339, Validation Loss: 0.0324,V Acc: 0.8349, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.6250
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.922077922077922
74 3 [array([0.2996407 , 0.07263263, 0.05760761, 0.30114287, 0.26897624],
      dtype=float32)]
Fold [5/5] Epoch [0/100] Initial Loss: 0.1403, Training Loss: 0.1403, Initial Validation Loss: 0.1321, Validation Loss: 0.1321,V Acc: 0.3889, Top 70th Acc: 0.4211, Bottom 30th Acc: 0.3125
Fold [5/5] Epoch [10/100] Initial Loss: 0.1403, Training Loss: 0.0149, Initial Validation Loss: 0.1321, Validation Loss: 0.0335,V Acc: 0.8333, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.5938
Stopping early at Epoch (base 0): 19  Rolling back to Epoch (base 0): 14  Top Validation Acc: 0.9473684210526315
Running train_nn.py with seed 75
CUDA:False
Training samples count:  550
Training on 162 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1403, Training Loss: 0.1403, Initial Validation Loss: 0.1369, Validation Loss: 0.1369,V Acc: 0.2321, Top 70th Acc: 0.2278, Bottom 30th Acc: 0.2424
Fold [1/5] Epoch [10/100] Initial Loss: 0.1403, Training Loss: 0.0150, Initial Validation Loss: 0.1369, Validation Loss: 0.0466,V Acc: 0.7857, Top 70th Acc: 0.8608, Bottom 30th Acc: 0.6061
Fold [1/5] Epoch [20/100] Initial Loss: 0.1403, Training Loss: 0.0060, Initial Validation Loss: 0.1369, Validation Loss: 0.0469,V Acc: 0.7679, Top 70th Acc: 0.8861, Bottom 30th Acc: 0.4848
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.8860759493670886
Fold [2/5] Epoch [0/100] Initial Loss: 0.1385, Training Loss: 0.1385, Initial Validation Loss: 0.1422, Validation Loss: 0.1422,V Acc: 0.2523, Top 70th Acc: 0.2949, Bottom 30th Acc: 0.1515
Fold [2/5] Epoch [10/100] Initial Loss: 0.1385, Training Loss: 0.0254, Initial Validation Loss: 0.1422, Validation Loss: 0.0448,V Acc: 0.8198, Top 70th Acc: 0.8974, Bottom 30th Acc: 0.6364
Fold [2/5] Epoch [20/100] Initial Loss: 0.1385, Training Loss: 0.0065, Initial Validation Loss: 0.1422, Validation Loss: 0.0363,V Acc: 0.8378, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 28  Rolling back to Epoch (base 0): 23  Top Validation Acc: 0.9615384615384616
Fold [3/5] Epoch [0/100] Initial Loss: 0.1394, Training Loss: 0.1394, Initial Validation Loss: 0.1315, Validation Loss: 0.1315,V Acc: 0.3636, Top 70th Acc: 0.4416, Bottom 30th Acc: 0.1818/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)

Fold [3/5] Epoch [20/100] Initial Loss: 0.1401, Training Loss: 0.0164, Initial Validation Loss: 0.1353, Validation Loss: 0.0347,V Acc: 0.8273, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 29  Rolling back to Epoch (base 0): 24  Top Validation Acc: 0.922077922077922
100 2 [array([0.3060378 , 0.08816294, 0.05961088, 0.2113945 , 0.3347939 ],
      dtype=float32)]
Fold [4/5] Epoch [0/100] Initial Loss: 0.1426, Training Loss: 0.1426, Initial Validation Loss: 0.1342, Validation Loss: 0.1342,V Acc: 0.2752, Top 70th Acc: 0.3377, Bottom 30th Acc: 0.1250
Fold [4/5] Epoch [10/100] Initial Loss: 0.1426, Training Loss: 0.0256, Initial Validation Loss: 0.1342, Validation Loss: 0.0329,V Acc: 0.8349, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.5312
Fold [4/5] Epoch [20/100] Initial Loss: 0.1426, Training Loss: 0.0141, Initial Validation Loss: 0.1342, Validation Loss: 0.0300,V Acc: 0.8624, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.6875
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.935064935064935
Fold [5/5] Epoch [0/100] Initial Loss: 0.1397, Training Loss: 0.1397, Initial Validation Loss: 0.1336, Validation Loss: 0.1336,V Acc: 0.2685, Top 70th Acc: 0.2895, Bottom 30th Acc: 0.2188
Fold [5/5] Epoch [10/100] Initial Loss: 0.1397, Training Loss: 0.0274, Initial Validation Loss: 0.1336, Validation Loss: 0.0383,V Acc: 0.8241, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.5625
Fold [5/5] Epoch [20/100] Initial Loss: 0.1397, Training Loss: 0.0151, Initial Validation Loss: 0.1336, Validation Loss: 0.0310,V Acc: 0.8148, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.5312
Fold [5/5] Epoch [30/100] Initial Loss: 0.1397, Training Loss: 0.0125, Initial Validation Loss: 0.1336, Validation Loss: 0.0285,V Acc: 0.8056, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.4688
Stopping early at Epoch (base 0): 38  Rolling back to Epoch (base 0): 33  Top Validation Acc: 0.9473684210526315

Fold [2/5] Epoch [10/100] Initial Loss: 0.1386, Training Loss: 0.0298, Initial Validation Loss: 0.1332, Validation Loss: 0.0489,V Acc: 0.7748, Top 70th Acc: 0.8590, Bottom 30th Acc: 0.5758
Fold [2/5] Epoch [20/100] Initial Loss: 0.1386, Training Loss: 0.0209, Initial Validation Loss: 0.1332, Validation Loss: 0.0464,V Acc: 0.7838, Top 70th Acc: 0.8590, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.8589743589743589
97 1 [array([0.27113286, 0.13440347, 0.11486705, 0.2069263 , 0.27267036],
      dtype=float32)]
Fold [3/5] Epoch [0/100] Initial Loss: 0.1383, Training Loss: 0.1383, Initial Validation Loss: 0.1315, Validation Loss: 0.1315,V Acc: 0.4091, Top 70th Acc: 0.4935, Bottom 30th Acc: 0.2121
Fold [3/5] Epoch [10/100] Initial Loss: 0.1383, Training Loss: 0.0342, Initial Validation Loss: 0.1315, Validation Loss: 0.0311,V Acc: 0.8545, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.6970
Fold [3/5] Epoch [20/100] Initial Loss: 0.1383, Training Loss: 0.0239, Initial Validation Loss: 0.1315, Validation Loss: 0.0258,V Acc: 0.8545, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 27  Rolling back to Epoch (base 0): 22  Top Validation Acc: 0.961038961038961
Fold [4/5] Epoch [0/100] Initial Loss: 0.1386, Training Loss: 0.1386, Initial Validation Loss: 0.1315, Validation Loss: 0.1315,V Acc: 0.3945, Top 70th Acc: 0.4416, Bottom 30th Acc: 0.2812
Fold [4/5] Epoch [10/100] Initial Loss: 0.1386, Training Loss: 0.0332, Initial Validation Loss: 0.1315, Validation Loss: 0.0366,V Acc: 0.8532, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6250
Fold [4/5] Epoch [20/100] Initial Loss: 0.1386, Training Loss: 0.0230, Initial Validation Loss: 0.1315, Validation Loss: 0.0323,V Acc: 0.8257, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.5000
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.974025974025974
Fold [5/5] Epoch [0/100] Initial Loss: 0.1389, Training Loss: 0.1389, Initial Validation Loss: 0.1303, Validation Loss: 0.1303,V Acc: 0.3241, Top 70th Acc: 0.3684, Bottom 30th Acc: 0.2188
Fold [5/5] Epoch [10/100] Initial Loss: 0.1389, Training Loss: 0.0334, Initial Validation Loss: 0.1303, Validation Loss: 0.0337,V Acc: 0.8333, Top 70th Acc: 0.9211, Bottom 30th Acc: 0.6250
Fold [5/5] Epoch [20/100] Initial Loss: 0.1389, Training Loss: 0.0226, Initial Validation Loss: 0.1303, Validation Loss: 0.0291,V Acc: 0.8333, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.5938
Stopping early at Epoch (base 0): 21  Rolling back to Epoch (base 0): 16  Top Validation Acc: 0.9342105263157895
Running train_nn.py with seed 98
CUDA:False
Training samples count:  550
Training on 20 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1366, Training Loss: 0.1366, Initial Validation Loss: 0.1346, Validation Loss: 0.1346,V Acc: 0.2500, Top 70th Acc: 0.3038, Bottom 30th Acc: 0.1212
Fold [1/5] Epoch [10/100] Initial Loss: 0.1366, Training Loss: 0.0298, Initial Validation Loss: 0.1346, Validation Loss: 0.0342,V Acc: 0.8393, Top 70th Acc: 0.9367, Bottom 30th Acc: 0.6061
Fold [1/5] Epoch [20/100] Initial Loss: 0.1366, Training Loss: 0.0230, Initial Validation Loss: 0.1346, Validation Loss: 0.0320,V Acc: 0.8214, Top 70th Acc: 0.9494, Bottom 30th Acc: 0.5152
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.9367088607594937
Fold [2/5] Epoch [0/100] Initial Loss: 0.1354, Training Loss: 0.1354, Initial Validation Loss: 0.1310, Validation Loss: 0.1310,V Acc: 0.3874, Top 70th Acc: 0.4231, Bottom 30th Acc: 0.3030
Fold [2/5] Epoch [10/100] Initial Loss: 0.1354, Training Loss: 0.0366, Initial Validation Loss: 0.1310, Validation Loss: 0.0466,V Acc: 0.7838, Top 70th Acc: 0.8718, Bottom 30th Acc: 0.5758
Fold [2/5] Epoch [20/100] Initial Loss: 0.1354, Training Loss: 0.0247, Initial Validation Loss: 0.1310, Validation Loss: 0.0446,V Acc: 0.7658, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.4242
Fold [2/5] Epoch [30/100] Initial Loss: 0.1354, Training Loss: 0.0205, Initial Validation Loss: 0.1310, Validation Loss: 0.0426,V Acc: 0.7928, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.4848
Stopping early at Epoch (base 0): 33  Rolling back to Epoch (base 0): 28  Top Validation Acc: 0.9230769230769231
Fold [3/5] Epoch [0/100] Initial Loss: 0.1427, Training Loss: 0.1427, Initial Validation Loss: 0.1362, Validation Loss: 0.1362,V Acc: 0.2091, Top 70th Acc: 0.2208, Bottom 30th Acc: 0.1818
Fold [3/5] Epoch [10/100] Initial Loss: 0.1427, Training Loss: 0.0367, Initial Validation Loss: 0.1362, Validation Loss: 0.0441,V Acc: 0.7727, Top 70th Acc: 0.8961, Bottom 30th Acc: 0.4848
Fold [3/5] Epoch [20/100] Initial Loss: 0.1427, Training Loss: 0.0221, Initial Validation Loss: 0.1362, Validation Loss: 0.0357,V Acc: 0.8273, Top 70th Acc: 0.8961, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.8961038961038961
Fold [4/5] Epoch [0/100] Initial Loss: 0.1397, Training Loss: 0.1397, Initial Validation Loss: 0.1310, Validation Loss: 0.1310,V Acc: 0.2477, Top 70th Acc: 0.3117, Bottom 30th Acc: 0.0938
Fold [4/5] Epoch [10/100] Initial Loss: 0.1397, Training Loss: 0.0385, Initial Validation Loss: 0.1310, Validation Loss: 0.0343,V Acc: 0.8257, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.5000
Fold [4/5] Epoch [20/100] Initial Loss: 0.1397, Training Loss: 0.0250, Initial Validation Loss: 0.1310, Validation Loss: 0.0267,V Acc: 0.8807, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.7500
Stopping early at Epoch (base 0): 27  Rolling back to Epoch (base 0): 22  Top Validation Acc: 0.935064935064935
98 3 [array([0.45226482, 0.08380717, 0.09465166, 0.24273762, 0.1265387 ],
      dtype=float32)]
Fold [5/5] Epoch [0/100] Initial Loss: 0.1368, Training Loss: 0.1368, Initial Validation Loss: 0.1276, Validation Loss: 0.1276,V Acc: 0.4352, Top 70th Acc: 0.4474, Bottom 30th Acc: 0.4062
Fold [5/5] Epoch [10/100] Initial Loss: 0.1368, Training Loss: 0.0357, Initial Validation Loss: 0.1276, Validation Loss: 0.0366,V Acc: 0.8426, Top 70th Acc: 0.9211, Bottom 30th Acc: 0.6562
Fold [5/5] Epoch [20/100] Initial Loss: 0.1368, Training Loss: 0.0242, Initial Validation Loss: 0.1276, Validation Loss: 0.0319,V Acc: 0.8426, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.6250
Stopping early at Epoch (base 0): 22  Rolling back to Epoch (base 0): 17  Top Validation Acc: 0.9473684210526315
Running train_nn.py with seed 99
CUDA:False
Training samples count:  550
Training on 20 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1409, Training Loss: 0.1409, Initial Validation Loss: 0.1392, Validation Loss: 0.1392,V Acc: 0.2411, Top 70th Acc: 0.2785, Bottom 30th Acc: 0.1515
Fold [1/5] Epoch [10/100] Initial Loss: 0.1409, Training Loss: 0.0408, Initial Validation Loss: 0.1392, Validation Loss: 0.0396,V Acc: 0.8214, Top 70th Acc: 0.9367, Bottom 30th Acc: 0.5455
Fold [1/5] Epoch [20/100] Initial Loss: 0.1409, Training Loss: 0.0262, Initial Validation Loss: 0.1392, Validation Loss: 0.0303,V Acc: 0.8571, Top 70th Acc: 0.9494, Bottom 30th Acc: 0.6364
Fold [1/5] Epoch [30/100] Initial Loss: 0.1409, Training Loss: 0.0221, Initial Validation Loss: 0.1392, Validation Loss: 0.0285,V Acc: 0.8482, Top 70th Acc: 0.9494, Bottom 30th Acc: 0.6061
Fold [1/5] Epoch [40/100] Initial Loss: 0.1409, Training Loss: 0.0208, Initial Validation Loss: 0.1392, Validation Loss: 0.0281,V Acc: 0.8661, Top 70th Acc: 0.9494, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 43  Rolling back to Epoch (base 0): 38  Top Validation Acc: 0.9493670886075949
Fold [2/5] Epoch [0/100] Initial Loss: 0.1379, Training Loss: 0.1379, Initial Validation Loss: 0.1354, Validation Loss: 0.1354,V Acc: 0.2703, Top 70th Acc: 0.3333, Bottom 30th Acc: 0.1212
Fold [2/5] Epoch [10/100] Initial Loss: 0.1379, Training Loss: 0.0315, Initial Validation Loss: 0.1354, Validation Loss: 0.0394,V Acc: 0.8378, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.6061
Fold [2/5] Epoch [20/100] Initial Loss: 0.1379, Training Loss: 0.0227, Initial Validation Loss: 0.1354, Validation Loss: 0.0326,V Acc: 0.8649, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc:
Fold [4/5] Epoch [30/100] Initial Loss: 0.1390, Training Loss: 0.0780, Initial Validation Loss: 0.1280, Validation Loss: 0.0765,V Acc: 0.6514, Top 70th Acc: 0.7403, Bottom 30th Acc: 0.4375
Fold [4/5] Epoch [40/100] Initial Loss: 0.1390, Training Loss: 0.0775, Initial Validation Loss: 0.1280, Validation Loss: 0.0762,V Acc: 0.6514, Top 70th Acc: 0.7403, Bottom 30th Acc: 0.4375
Stopping early at Epoch (base 0): 42  Rolling back to Epoch (base 0): 37  Top Validation Acc: 0.7402597402597403
98 3 [array([0.117122  , 0.3455948 , 0.12585096, 0.2365336 , 0.17489861],
      dtype=float32)]
Fold [5/5] Epoch [0/100] Initial Loss: 0.1387, Training Loss: 0.1387, Initial Validation Loss: 0.1298, Validation Loss: 0.1298,V Acc: 0.2500, Top 70th Acc: 0.3553, Bottom 30th Acc: 0.0000
Fold [5/5] Epoch [10/100] Initial Loss: 0.1387, Training Loss: 0.0819, Initial Validation Loss: 0.1298, Validation Loss: 0.0747,V Acc: 0.6481, Top 70th Acc: 0.7500, Bottom 30th Acc: 0.4062
Fold [5/5] Epoch [20/100] Initial Loss: 0.1387, Training Loss: 0.0806, Initial Validation Loss: 0.1298, Validation Loss: 0.0730,V Acc: 0.6574, Top 70th Acc: 0.7368, Bottom 30th Acc: 0.4688
Fold [5/5] Epoch [30/100] Initial Loss: 0.1387, Training Loss: 0.0800, Initial Validation Loss: 0.1298, Validation Loss: 0.0726,V Acc: 0.6574, Top 70th Acc: 0.7632, Bottom 30th Acc: 0.4062
Stopping early at Epoch (base 0): 34  Rolling back to Epoch (base 0): 29  Top Validation Acc: 0.75
Running train_nn.py with seed 99
CUDA:False
Training samples count:  550
Training on 2 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1447, Training Loss: 0.1447, Initial Validation Loss: 0.1384, Validation Loss: 0.1384,V Acc: 0.2232, Top 70th Acc: 0.1899, Bottom 30th Acc: 0.3030
Fold [1/5] Epoch [10/100] Initial Loss: 0.1447, Training Loss: 0.0829, Initial Validation Loss: 0.1384, Validation Loss: 0.0751,V Acc: 0.6786, Top 70th Acc: 0.8101, Bottom 30th Acc: 0.3636
Fold [1/5] Epoch [20/100] Initial Loss: 0.1447, Training Loss: 0.0803, Initial Validation Loss: 0.1384, Validation Loss: 0.0725,V Acc: 0.7054, Top 70th Acc: 0.7975, Bottom 30th Acc: 0.4848
Fold [1/5] Epoch [30/100] Initial Loss: 0.1447, Training Loss: 0.0796, Initial Validation Loss: 0.1384, Validation Loss: 0.0712,V Acc: 0.7054, Top 70th Acc: 0.7975, Bottom 30th Acc: 0.4848
Fold [1/5] Epoch [40/100] Initial Loss: 0.1447, Training Loss: 0.0792, Initial Validation Loss: 0.1384, Validation Loss: 0.0706,V Acc: 0.7232, Top 70th Acc: 0.8228, Bottom 30th Acc: 0.4848
Fold [1/5] Epoch [50/100] Initial Loss: 0.1447, Training Loss: 0.0790, Initial Validation Loss: 0.1384, Validation Loss: 0.0707,V Acc: 0.7232, Top 70th Acc: 0.8228, Bottom 30th Acc: 0.4848
Fold [1/5] Epoch [60/100] Initial Loss: 0.1447, Training Loss: 0.0788, Initial Validation Loss: 0.1384, Validation Loss: 0.0704,V Acc: 0.7143, Top 70th Acc: 0.8101, Bottom 30th Acc: 0.4848
Stopping early at Epoch (base 0): 61  Rolling back to Epoch (base 0): 56  Top Validation Acc: 0.7974683544303798
Fold [2/5] Epoch [0/100] Initial Loss: 0.1414, Training Loss: 0.1414, Initial Validation Loss: 0.1343, Validation Loss: 0.1343,V Acc: 0.3514, Top 70th Acc: 0.4487, Bottom 30th Acc: 0.1212
Fold [2/5] Epoch [10/100] Initial Loss: 0.1414, Training Loss: 0.0802, Initial Validation Loss: 0.1343, Validation Loss: 0.0856,V Acc: 0.6216, Top 70th Acc: 0.7436, Bottom 30th Acc: 0.3333
Fold [2/5] Epoch [20/100] Initial Loss: 0.1414, Training Loss: 0.0784, Initial Validation Loss: 0.1343, Validation Loss: 0.0835,V Acc: 0.6216, Top 70th Acc: 0.7564, Bottom 30th Acc: 0.3030
Fold [2/5] Epoch [30/100] Initial Loss: 0.1414, Training Loss: 0.0779, Initial Validation Loss: 0.1343, Validation Loss: 0.0830,V Acc: 0.6216, Top 70th Acc: 0.7564, Bottom 30th Acc: 0.3030
Fold [2/5] Epoch [40/100] Initial Loss: 0.1414, Training Loss: 0.0774, Initial Validation Loss: 0.1343, Validation Loss: 0.0826,V Acc: 0.6216, Top 70th Acc: 0.7564, Bottom 30th Acc: 0.3030
Stopping early at Epoch (base 0): 49  Rolling back to Epoch (base 0): 44  Top Validation Acc: 0.7564102564102564
99 1 [array([0.12505421, 0.3529932 , 0.15180273, 0.21395744, 0.15619233],
      dtype=float32)]
Fold [3/5] Epoch [0/100] Initial Loss: 0.1329, Training Loss: 0.1329, Initial Validation Loss: 0.1165, Validation Loss: 0.1165,V Acc: 0.5364, Top 70th Acc: 0.6494, Bottom 30th Acc: 0.2727
Fold [3/5] Epoch [10/100] Initial Loss: 0.1329, Training Loss: 0.0795, Initial Validation Loss: 0.1165, Validation Loss: 0.0798,V Acc: 0.6000, Top 70th Acc: 0.7273, Bottom 30th Acc: 0.3030
Stopping early at Epoch (base 0): 15  Rolling back to Epoch (base 0): 10  Top Validation Acc: 0.7012987012987013
Fold [4/5] Epoch [0/100] Initial Loss: 0.1381, Training Loss: 0.1381, Initial Validation Loss: 0.1280, Validation Loss: 0.1280,V Acc: 0.4312, Top 70th Acc: 0.3636, Bottom 30th Acc: 0.5938
Fold [4/5] Epoch [10/100] Initial Loss: 0.1381, Training Loss: 0.0803, Initial Validation Loss: 0.1280, Validation Loss: 0.0775,V Acc: 0.5963, Top 70th Acc: 0.7143, Bottom 30th Acc: 0.3125
Stopping early at Epoch (base 0): 17  Rolling back to Epoch (base 0): 12  Top Validation Acc: 0.7272727272727273
Fold [5/5] Epoch [0/100] Initial Loss: 0.1432, Training Loss: 0.1432, Initial Validation Loss: 0.1325, Validation Loss: 0.1325,V Acc: 0.4630, Top 70th Acc: 0.5921, Bottom 30th Acc: 0.1562
Fold [5/5] Epoch [10/100] Initial Loss: 0.1432, Training Loss: 0.0801, Initial Validation Loss: 0.1325, Validation Loss: 0.0790,V Acc: 0.6204, Top 70th Acc: 0.7237, Bottom 30th Acc: 0.3750
Fold [5/5] Epoch [20/100] Initial Loss: 0.1432, Training Loss: 0.0785, Initial Validation Loss: 0.1325, Validation Loss: 0.0771,V Acc: 0.6389, Top 70th Acc: 0.7368, Bottom 30th Acc: 0.4062
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.7368421052631579
Running train_nn.py with seed 100
CUDA:False
Training samples count:  550
Training on 2 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1346, Training Loss: 0.1346, Initial Validation Loss: 0.1293, Validation Loss: 0.1293,V Acc: 0.4286, Top 70th Acc: 0.5823, Bottom 30th Acc: 0.0606
Fold [1/5] Epoch [10/100] Initial Loss: 0.1346, Training Loss: 0.0817, Initial Validation Loss: 0.1293, Validation Loss: 0.0758,V Acc: 0.6786, Top 70th Acc: 0.8101, Bottom 30th Acc: 0.3636
Fold [1/5] Epoch [20/100] Initial Loss: 0.1346, Training Loss: 0.0802, Initial Validation Loss: 0.1293, Validation Loss: 0.0745,V Acc: 0.6607, Top 70th Acc: 0.7975, Bottom 30th Acc: 0.3333
Fold [1/5] Epoch [30/100] Initial Loss: 0.1346, Training Loss: 0.0797, Initial Validation Loss: 0.1293, Validation Loss: 0.0752,V Acc: 0.6518, Top 70th Acc: 0.7975, Bottom 30th Acc: 0.3030
Stopping early at Epoch (base 0): 32  Rolling back to Epoch (base 0): 27  Top Validation Acc: 0.7974683544303798
Fold [2/5] Epoch [0/100] Initial Loss: 0.1388, Training Loss: 0.1388, Initial Validation Loss: 0.1224, Validation Loss: 0.1224,V Acc: 0.5315, Top 70th Acc: 0.5641, Bottom 30th Acc: 0.4545
Fold [2/5] Epoch [10/100] Initial Loss: 0.1388, Training Loss: 0.0823, Initial Validation Loss: 0.1224, Validation Loss: 0.0743,V Acc: 0.6396, Top 70th Acc: 0.7564, Bottom 30th Acc: 0.3636
Fold [2/5] Epoch [20/100] Initial Loss: 0.1388, Training Loss: 0.0803, Initial Validation Loss: 0.1224, Validation Loss: 0.0736,V Acc: 0.6306, Top 70th Acc: 0.7179, Bottom 30th Acc: 0.4242
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.7435897435897436
Fold [3/5] Epoch [0/100] Initial Loss: 0.1407, Training Loss: 0.1407, Initial Validation Loss: 0.1305, Validation Loss: 0.1305,V Acc: 0.5182, Top 70th Acc: 0.6234, Bottom 30th Acc: 0.2727
Fold [3/5] Epoch [10/100] Initial Loss: 0.1407, Training Loss: 0.0793, Initial Validation Loss: 0.1305, Validation Loss: 0.0825,V Acc: 0.5818, Top 70th Acc: 0.6883, Bottom 30th Acc: 0.3333
Fold [3/5] Epoch [20/100] Initial Loss: 0.1407, Training Loss: 0.0772, Initial Validation Loss: 0.1305, Validation Loss: 0.0819,V Acc: 0.5909, Top 70th Acc: 0.7013, Bottom 30th Acc: 0.3333
Stopping early at Epoch (base 0): 27  Rolling back to Epoch (base 0): 22  Top Validation Acc: 0.7142857142857143
100 2 [array([0.12276959, 0.4065232 , 0.11866745, 0.21236695, 0.1396728 ],
      dtype=float32)]/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)

Fold [4/5] Epoch [0/100] Initial Loss: 0.1341, Training Loss: 0.1341, Initial Validation Loss: 0.1226, Validation Loss: 0.1226,V Acc: 0.4220, Top 70th Acc: 0.4675, Bottom 30th Acc: 0.3125
Fold [4/5] Epoch [10/100] Initial Loss: 0.1341, Training Loss: 0.0808, Initial Validation Loss: 0.1226, Validation Loss: 0.0791,V Acc: 0.6514, Top 70th Acc: 0.7143, Bottom 30th Acc: 0.5000
Fold [4/5] Epoch [20/100] Initial Loss: 0.1341, Training Loss: 0.0785, Initial Validation Loss: 0.1226, Validation Loss: 0.0778,V Acc: 0.6422, Top 70th Acc: 0.7013, Bottom 30th Acc: 0.5000
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.7272727272727273
Fold [5/5] Epoch [0/100] Initial Loss: 0.1378, Training Loss: 0.1378, Initial Validation Loss: 0.1301, Validation Loss: 0.1301,V Acc: 0.3426, Top 70th Acc: 0.4605, Bottom 30th Acc: 0.0625
Fold [5/5] Epoch [10/100] Initial Loss: 0.1378, Training Loss: 0.0787, Initial Validation Loss: 0.1301, Validation Loss: 0.0854,V Acc: 0.5741, Top 70th Acc: 0.7500, Bottom 30th Acc: 0.1562
Fold [5/5] Epoch [20/100] Initial Loss: 0.1378, Training Loss: 0.0767, Initial Validation Loss: 0.1301, Validation Loss: 0.0827,V Acc: 0.5833, Top 70th Acc: 0.7500, Bottom 30th Acc: 0.1875
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.75
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
 0.9358974358974359
99 1 [array([0.26050535, 0.10061443, 0.08204369, 0.3759407 , 0.18089586],
      dtype=float32)]
Fold [3/5] Epoch [0/100] Initial Loss: 0.1424, Training Loss: 0.1424, Initial Validation Loss: 0.1333, Validation Loss: 0.1333,V Acc: 0.4000, Top 70th Acc: 0.4545, Bottom 30th Acc: 0.2727
Fold [3/5] Epoch [10/100] Initial Loss: 0.1424, Training Loss: 0.0365, Initial Validation Loss: 0.1333, Validation Loss: 0.0371,V Acc: 0.8273, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.5455
Fold [3/5] Epoch [20/100] Initial Loss: 0.1424, Training Loss: 0.0228, Initial Validation Loss: 0.1333, Validation Loss: 0.0323,V Acc: 0.8364, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 21  Rolling back to Epoch (base 0): 16  Top Validation Acc: 0.935064935064935
Fold [4/5] Epoch [0/100] Initial Loss: 0.1384, Training Loss: 0.1384, Initial Validation Loss: 0.1295, Validation Loss: 0.1295,V Acc: 0.3761, Top 70th Acc: 0.4416, Bottom 30th Acc: 0.2188
Fold [4/5] Epoch [10/100] Initial Loss: 0.1384, Training Loss: 0.0321, Initial Validation Loss: 0.1295, Validation Loss: 0.0345,V Acc: 0.8624, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.7188
Fold [4/5] Epoch [20/100] Initial Loss: 0.1384, Training Loss: 0.0239, Initial Validation Loss: 0.1295, Validation Loss: 0.0322,V Acc: 0.8716, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.7500
Stopping early at Epoch (base 0): 27  Rolling back to Epoch (base 0): 22  Top Validation Acc: 0.935064935064935
Fold [5/5] Epoch [0/100] Initial Loss: 0.1388, Training Loss: 0.1388, Initial Validation Loss: 0.1314, Validation Loss: 0.1314,V Acc: 0.3426, Top 70th Acc: 0.3026, Bottom 30th Acc: 0.4375
Fold [5/5] Epoch [10/100] Initial Loss: 0.1388, Training Loss: 0.0429, Initial Validation Loss: 0.1314, Validation Loss: 0.0474,V Acc: 0.7963, Top 70th Acc: 0.8684, Bottom 30th Acc: 0.6250
Fold [5/5] Epoch [20/100] Initial Loss: 0.1388, Training Loss: 0.0255, Initial Validation Loss: 0.1314, Validation Loss: 0.0337,V Acc: 0.8333, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.5938
Fold [5/5] Epoch [30/100] Initial Loss: 0.1388, Training Loss: 0.0219, Initial Validation Loss: 0.1314, Validation Loss: 0.0337,V Acc: 0.8148, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.5312
Stopping early at Epoch (base 0): 33  Rolling back to Epoch (base 0): 28  Top Validation Acc: 0.9342105263157895
Running train_nn.py with seed 100
CUDA:False
Training samples count:  550
Training on 20 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1363, Training Loss: 0.1363, Initial Validation Loss: 0.1319, Validation Loss: 0.1319,V Acc: 0.4107, Top 70th Acc: 0.5190, Bottom 30th Acc: 0.1515
Fold [1/5] Epoch [10/100] Initial Loss: 0.1363, Training Loss: 0.0358, Initial Validation Loss: 0.1319, Validation Loss: 0.0343,V Acc: 0.8571, Top 70th Acc: 0.9620, Bottom 30th Acc: 0.6061
Fold [1/5] Epoch [20/100] Initial Loss: 0.1363, Training Loss: 0.0247, Initial Validation Loss: 0.1319, Validation Loss: 0.0294,V Acc: 0.8661, Top 70th Acc: 0.9367, Bottom 30th Acc: 0.6970
Fold [1/5] Epoch [30/100] Initial Loss: 0.1363, Training Loss: 0.0225, Initial Validation Loss: 0.1319, Validation Loss: 0.0281,V Acc: 0.8661, Top 70th Acc: 0.9494, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 30  Rolling back to Epoch (base 0): 25  Top Validation Acc: 0.9493670886075949
Fold [2/5] Epoch [0/100] Initial Loss: 0.1356, Training Loss: 0.1356, Initial Validation Loss: 0.1248, Validation Loss: 0.1248,V Acc: 0.3604, Top 70th Acc: 0.3590, Bottom 30th Acc: 0.3636
Fold [2/5] Epoch [10/100] Initial Loss: 0.1356, Training Loss: 0.0319, Initial Validation Loss: 0.1248, Validation Loss: 0.0426,V Acc: 0.8018, Top 70th Acc: 0.8974, Bottom 30th Acc: 0.5758
Fold [2/5] Epoch [20/100] Initial Loss: 0.1356, Training Loss: 0.0211, Initial Validation Loss: 0.1248, Validation Loss: 0.0375,V Acc: 0.8378, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.9102564102564102
Fold [3/5] Epoch [0/100] Initial Loss: 0.1390, Training Loss: 0.1390, Initial Validation Loss: 0.1334, Validation Loss: 0.1334,V Acc: 0.2727, Top 70th Acc: 0.3117, Bottom 30th Acc: 0.1818
Fold [3/5] Epoch [10/100] Initial Loss: 0.1390, Training Loss: 0.0390, Initial Validation Loss: 0.1334, Validation Loss: 0.0433,V Acc: 0.7727, Top 70th Acc: 0.8831, Bottom 30th Acc: 0.5152
Fold [3/5] Epoch [20/100] Initial Loss: 0.1390, Training Loss: 0.0272, Initial Validation Loss: 0.1334, Validation Loss: 0.0354,V Acc: 0.8273, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.6061
Fold [3/5] Epoch [30/100] Initial Loss: 0.1390, Training Loss: 0.0214, Initial Validation Loss: 0.1334, Validation Loss: 0.0322,V Acc: 0.8364, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 37  Rolling back to Epoch (base 0): 32  Top Validation Acc: 0.935064935064935
100 2 [array([0.5101463 , 0.07997811, 0.09030115, 0.14454272, 0.17503165],
      dtype=float32)]
Fold [4/5] Epoch [0/100] Initial Loss: 0.1391, Training Loss: 0.1391, Initial Validation Loss: 0.1343, Validation Loss: 0.1343,V Acc: 0.2294, Top 70th Acc: 0.1818, Bottom 30th Acc: 0.3438
Fold [4/5] Epoch [10/100] Initial Loss: 0.1391, Training Loss: 0.0397, Initial Validation Loss: 0.1343, Validation Loss: 0.0380,V Acc: 0.8073, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.5625
Fold [4/5] Epoch [20/100] Initial Loss: 0.1391, Training Loss: 0.0265, Initial Validation Loss: 0.1343, Validation Loss: 0.0308,V Acc: 0.8349, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.5938
Fold [4/5] Epoch [30/100] Initial Loss: 0.1391, Training Loss: 0.0219, Initial Validation Loss: 0.1343, Validation Loss: 0.0284,V Acc: 0.8532, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6250
Stopping early at Epoch (base 0): 33  Rolling back to Epoch (base 0): 28  Top Validation Acc: 0.948051948051948
Fold [5/5] Epoch [0/100] Initial Loss: 0.1409, Training Loss: 0.1409, Initial Validation Loss: 0.1334, Validation Loss: 0.1334,V Acc: 0.2870, Top 70th Acc: 0.2895, Bottom 30th Acc: 0.2812
Fold [5/5] Epoch [10/100] Initial Loss: 0.1409, Training Loss: 0.0315, Initial Validation Loss: 0.1334, Validation Loss: 0.0392,V Acc: 0.8241, Top 70th Acc: 0.9211, Bottom 30th Acc: 0.5938
Fold [5/5] Epoch [20/100] Initial Loss: 0.1409, Training Loss: 0.0227, Initial Validation Loss: 0.1334, Validation Loss: 0.0368,V Acc: 0.8241, Top 70th Acc: 0.9211, Bottom 30th Acc: 0.5938
Stopping early at Epoch (base 0): 20  Rolling back to Epoch (base 0): 15  Top Validation Acc: 0.9210526315789473

Fold [3/5] Epoch [10/100] Initial Loss: 0.1381, Training Loss: 0.0286, Initial Validation Loss: 0.1328, Validation Loss: 0.0274,V Acc: 0.8909, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.7576
Stopping early at Epoch (base 0): 17  Rolling back to Epoch (base 0): 12  Top Validation Acc: 0.974025974025974
Fold [4/5] Epoch [0/100] Initial Loss: 0.1355, Training Loss: 0.1355, Initial Validation Loss: 0.1281, Validation Loss: 0.1281,V Acc: 0.4771, Top 70th Acc: 0.5584, Bottom 30th Acc: 0.2812
Fold [4/5] Epoch [10/100] Initial Loss: 0.1355, Training Loss: 0.0276, Initial Validation Loss: 0.1281, Validation Loss: 0.0333,V Acc: 0.8349, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.5312
Fold [4/5] Epoch [20/100] Initial Loss: 0.1355, Training Loss: 0.0180, Initial Validation Loss: 0.1281, Validation Loss: 0.0294,V Acc: 0.8349, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.5000
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.974025974025974
Fold [5/5] Epoch [0/100] Initial Loss: 0.1380, Training Loss: 0.1380, Initial Validation Loss: 0.1285, Validation Loss: 0.1285,V Acc: 0.3241, Top 70th Acc: 0.4079, Bottom 30th Acc: 0.1250
Fold [5/5] Epoch [10/100] Initial Loss: 0.1380, Training Loss: 0.0276, Initial Validation Loss: 0.1285, Validation Loss: 0.0329,V Acc: 0.8333, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.5938
Fold [5/5] Epoch [20/100] Initial Loss: 0.1380, Training Loss: 0.0177, Initial Validation Loss: 0.1285, Validation Loss: 0.0319,V Acc: 0.8148, Top 70th Acc: 0.9211, Bottom 30th Acc: 0.5625
Stopping early at Epoch (base 0): 21  Rolling back to Epoch (base 0): 16  Top Validation Acc: 0.9342105263157895
Running train_nn.py with seed 98
CUDA:False
Training samples count:  550
Training on 30 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1418, Training Loss: 0.1418, Initial Validation Loss: 0.1385, Validation Loss: 0.1385,V Acc: 0.2232, Top 70th Acc: 0.2278, Bottom 30th Acc: 0.2121
Fold [1/5] Epoch [10/100] Initial Loss: 0.1418, Training Loss: 0.0318, Initial Validation Loss: 0.1385, Validation Loss: 0.0385,V Acc: 0.8125, Top 70th Acc: 0.8987, Bottom 30th Acc: 0.6061
Fold [1/5] Epoch [20/100] Initial Loss: 0.1418, Training Loss: 0.0191, Initial Validation Loss: 0.1385, Validation Loss: 0.0327,V Acc: 0.8393, Top 70th Acc: 0.9494, Bottom 30th Acc: 0.5758
Fold [1/5] Epoch [30/100] Initial Loss: 0.1418, Training Loss: 0.0167, Initial Validation Loss: 0.1385, Validation Loss: 0.0308,V Acc: 0.8482, Top 70th Acc: 0.9620, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 37  Rolling back to Epoch (base 0): 32  Top Validation Acc: 0.9493670886075949
Fold [2/5] Epoch [0/100] Initial Loss: 0.1368, Training Loss: 0.1368, Initial Validation Loss: 0.1335, Validation Loss: 0.1335,V Acc: 0.3964, Top 70th Acc: 0.5128, Bottom 30th Acc: 0.1212
Fold [2/5] Epoch [10/100] Initial Loss: 0.1368, Training Loss: 0.0399, Initial Validation Loss: 0.1335, Validation Loss: 0.0492,V Acc: 0.7387, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.3333
Fold [2/5] Epoch [20/100] Initial Loss: 0.1368, Training Loss: 0.0181, Initial Validation Loss: 0.1335, Validation Loss: 0.0356,V Acc: 0.8559, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.6061
Fold [2/5] Epoch [30/100] Initial Loss: 0.1368, Training Loss: 0.0141, Initial Validation Loss: 0.1335, Validation Loss: 0.0360,V Acc: 0.8378, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 30  Rolling back to Epoch (base 0): 25  Top Validation Acc: 0.9358974358974359
Fold [3/5] Epoch [0/100] Initial Loss: 0.1402, Training Loss: 0.1402, Initial Validation Loss: 0.1325, Validation Loss: 0.1325,V Acc: 0.3455, Top 70th Acc: 0.4026, Bottom 30th Acc: 0.2121
Fold [3/5] Epoch [10/100] Initial Loss: 0.1402, Training Loss: 0.0316, Initial Validation Loss: 0.1325, Validation Loss: 0.0402,V Acc: 0.7909, Top 70th Acc: 0.8831, Bottom 30th Acc: 0.5758
Fold [3/5] Epoch [20/100] Initial Loss: 0.1402, Training Loss: 0.0168, Initial Validation Loss: 0.1325, Validation Loss: 0.0336,V Acc: 0.8182, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.5455
Fold [3/5] Epoch [30/100] Initial Loss: 0.1402, Training Loss: 0.0144, Initial Validation Loss: 0.1325, Validation Loss: 0.0333,V Acc: 0.8000, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.4545
Stopping early at Epoch (base 0): 32  Rolling back to Epoch (base 0): 27  Top Validation Acc: 0.948051948051948
Fold [4/5] Epoch [0/100] Initial Loss: 0.1410, Training Loss: 0.1410, Initial Validation Loss: 0.1298, Validation Loss: 0.1298,V Acc: 0.3670, Top 70th Acc: 0.3766, Bottom 30th Acc: 0.3438
Fold [4/5] Epoch [10/100] Initial Loss: 0.1410, Training Loss: 0.0408, Initial Validation Loss: 0.1298, Validation Loss: 0.0455,V Acc: 0.7798, Top 70th Acc: 0.8701, Bottom 30th Acc: 0.5625
Fold [4/5] Epoch [20/100] Initial Loss: 0.1410, Training Loss: 0.0202, Initial Validation Loss: 0.1298, Validation Loss: 0.0267,V Acc: 0.8532, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.6562
Fold [4/5] Epoch [30/100] Initial Loss: 0.1410, Training Loss: 0.0176, Initial Validation Loss: 0.1298, Validation Loss: 0.0260,V Acc: 0.8532, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6250
Stopping early at Epoch (base 0): 38  Rolling back to Epoch (base 0): 33  Top Validation Acc: 0.961038961038961
98 3 [array([0.8160705 , 0.02367456, 0.03014951, 0.06155021, 0.06855525],
      dtype=float32)]
Fold [5/5] Epoch [0/100] Initial Loss: 0.1404, Training Loss: 0.1404, Initial Validation Loss: 0.1298, Validation Loss: 0.1298,V Acc: 0.2500, Top 70th Acc: 0.3158, Bottom 30th Acc: 0.0938
Fold [5/5] Epoch [10/100] Initial Loss: 0.1404, Training Loss: 0.0320, Initial Validation Loss: 0.1298, Validation Loss: 0.0339,V Acc: 0.8333, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.5938
Fold [5/5] Epoch [20/100] Initial Loss: 0.1404, Training Loss: 0.0189, Initial Validation Loss: 0.1298, Validation Loss: 0.0291,V Acc: 0.8426, Top 70th Acc: 0.9737, Bottom 30th Acc: 0.5312
Fold [5/5] Epoch [30/100] Initial Loss: 0.1404, Training Loss: 0.0169, Initial Validation Loss: 0.1298, Validation Loss: 0.0288,V Acc: 0.8333, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.5312
Stopping early at Epoch (base 0): 34  Rolling back to Epoch (base 0): 29  Top Validation Acc: 0.9736842105263158
Running train_nn.py with seed 99
CUDA:False
Training samples count:  550
Training on 30 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1390, Training Loss: 0.1390, Initial Validation Loss: 0.1367, Validation Loss: 0.1367,V Acc: 0.2857, Top 70th Acc: 0.3418, Bottom 30th Acc: 0.1515
Fold [1/5] Epoch [10/100] Initial Loss: 0.1390, Training Loss: 0.0387, Initial Validation Loss: 0.1367, Validation Loss: 0.0383,V Acc: 0.8661, Top 70th Acc: 0.9241, Bottom 30th Acc: 0.7273
Fold [1/5] Epoch [20/100] Initial Loss: 0.1390, Training Loss: 0.0202, Initial Validation Loss: 0.1367, Validation Loss: 0.0273,V Acc: 0.8929, Top 70th Acc: 0.9494, Bottom 30th Acc: 0.7576
Stopping early at Epoch (base 0): 28  Rolling back to Epoch (base 0): 23  Top Validation Acc: 0.9493670886075949
Fold [2/5] Epoch [0/100] Initial Loss: 0.1388, Training Loss: 0.1388, Initial Validation Loss: 0.1320, Validation Loss: 0.1320,V Acc: 0.3694, Top 70th Acc: 0.3590, Bottom 30th Acc: 0.3939
Fold [2/5] Epoch [10/100] Initial Loss: 0.1388, Training Loss: 0.0409, Initial Validation Loss: 0.1320, Validation Loss: 0.0523,V Acc: 0.7568, Top 70th Acc: 0.8718, Bottom 30th Acc: 0.4848
Fold [2/5] Epoch [20/100] Initial Loss: 0.1388, Training Loss: 0.0190, Initial Validation Loss: 0.1320, Validation Loss: 0.0338,V Acc: 0.8198, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.4848
Fold [2/5] Epoch [30/100] Initial Loss: 0.1388, Training Loss: 0.0160, Initial Validation Loss: 0.1320, Validation Loss: 0.0312,V Acc: 0.8468, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 35  Rolling back to Epoch (base 0): 30  Top Validation Acc: 0.9615384615384616
99 1 [array([0.7734107 , 0.04703829, 0.01498155, 0.08240852, 0.08216088],
      dtype=float32)]
Fold [3/5] Epoch [0/100] Initial Loss: 0.1385, Training Loss: 0.1385, Initial Validation Loss: 0.1301, Validation Loss: 0.1301,V Acc: 0.3636, Top 70th Acc: 0.4156, Bottom 30th Acc: 0.2424
Fold [3/5] Epoch [10/100] Initial Loss: 0.1385, Training Loss: 0.0260, Initial Validation Loss: 0.1301, Validation Loss: 0.0318,V Acc: 0.8455, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.6364
Fold [3/5] Epoch [10/100] Initial Loss: 0.1394, Training Loss: 0.0124, Initial Validation Loss: 0.1315, Validation Loss: 0.0399,V Acc: 0.7636, Top 70th Acc: 0.8961, Bottom 30th Acc: 0.4545
Fold [3/5] Epoch [20/100] Initial Loss: 0.1394, Training Loss: 0.0048, Initial Validation Loss: 0.1315, Validation Loss: 0.0388,V Acc: 0.7818, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.4848
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.8961038961038961
Fold [4/5] Epoch [0/100] Initial Loss: 0.1389, Training Loss: 0.1389, Initial Validation Loss: 0.1324, Validation Loss: 0.1324,V Acc: 0.2936, Top 70th Acc: 0.3506, Bottom 30th Acc: 0.1562
Fold [4/5] Epoch [10/100] Initial Loss: 0.1389, Training Loss: 0.0183, Initial Validation Loss: 0.1324, Validation Loss: 0.0338,V Acc: 0.8440, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.5625
Fold [4/5] Epoch [20/100] Initial Loss: 0.1389, Training Loss: 0.0056, Initial Validation Loss: 0.1324, Validation Loss: 0.0279,V Acc: 0.8624, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6562
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.948051948051948
75 3 [array([0.10847224, 0.04618506, 0.03911783, 0.2543717 , 0.5518532 ],
      dtype=float32)]
Fold [5/5] Epoch [0/100] Initial Loss: 0.1429, Training Loss: 0.1429, Initial Validation Loss: 0.1281, Validation Loss: 0.1281,V Acc: 0.2407, Top 70th Acc: 0.2763, Bottom 30th Acc: 0.1562
Fold [5/5] Epoch [10/100] Initial Loss: 0.1429, Training Loss: 0.0243, Initial Validation Loss: 0.1281, Validation Loss: 0.0353,V Acc: 0.8611, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.6562
Fold [5/5] Epoch [20/100] Initial Loss: 0.1429, Training Loss: 0.0056, Initial Validation Loss: 0.1281, Validation Loss: 0.0270,V Acc: 0.8704, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.7188
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.9473684210526315
Running train_nn.py with seed 76
CUDA:False
Training samples count:  550
Training on 162 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1368, Training Loss: 0.1368, Initial Validation Loss: 0.1322, Validation Loss: 0.1322,V Acc: 0.3571, Top 70th Acc: 0.4430, Bottom 30th Acc: 0.1515
Fold [1/5] Epoch [10/100] Initial Loss: 0.1368, Training Loss: 0.0318, Initial Validation Loss: 0.1322, Validation Loss: 0.0537,V Acc: 0.7411, Top 70th Acc: 0.8861, Bottom 30th Acc: 0.3939
Fold [1/5] Epoch [20/100] Initial Loss: 0.1368, Training Loss: 0.0062, Initial Validation Loss: 0.1322, Validation Loss: 0.0387,V Acc: 0.7946, Top 70th Acc: 0.9241, Bottom 30th Acc: 0.4848
Fold [1/5] Epoch [30/100] Initial Loss: 0.1368, Training Loss: 0.0043, Initial Validation Loss: 0.1322, Validation Loss: 0.0382,V Acc: 0.8036, Top 70th Acc: 0.9241, Bottom 30th Acc: 0.5152
Stopping early at Epoch (base 0): 32  Rolling back to Epoch (base 0): 27  Top Validation Acc: 0.9240506329113924
Fold [2/5] Epoch [0/100] Initial Loss: 0.1393, Training Loss: 0.1393, Initial Validation Loss: 0.1324, Validation Loss: 0.1324,V Acc: 0.2523, Top 70th Acc: 0.3333, Bottom 30th Acc: 0.0606
Fold [2/5] Epoch [10/100] Initial Loss: 0.1393, Training Loss: 0.0303, Initial Validation Loss: 0.1324, Validation Loss: 0.0431,V Acc: 0.7568, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.3636
Fold [2/5] Epoch [20/100] Initial Loss: 0.1393, Training Loss: 0.0055, Initial Validation Loss: 0.1324, Validation Loss: 0.0250,V Acc: 0.8919, Top 70th Acc: 0.9872, Bottom 30th Acc: 0.6667
Fold [2/5] Epoch [30/100] Initial Loss: 0.1393, Training Loss: 0.0039, Initial Validation Loss: 0.1324, Validation Loss: 0.0229,V Acc: 0.8919, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.6970
Fold [2/5] Epoch [40/100] Initial Loss: 0.1393, Training Loss: 0.0035, Initial Validation Loss: 0.1324, Validation Loss: 0.0225,V Acc: 0.8919, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 40  Rolling back to Epoch (base 0): 35  Top Validation Acc: 0.9743589743589743
Fold [3/5] Epoch [0/100] Initial Loss: 0.1391, Training Loss: 0.1391, Initial Validation Loss: 0.1303, Validation Loss: 0.1303,V Acc: 0.2818, Top 70th Acc: 0.3506, Bottom 30th Acc: 0.1212
Fold [3/5] Epoch [10/100] Initial Loss: 0.1391, Training Loss: 0.0199, Initial Validation Loss: 0.1303, Validation Loss: 0.0308,V Acc: 0.8545, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.6667
Fold [3/5] Epoch [20/100] Initial Loss: 0.1391, Training Loss: 0.0047, Initial Validation Loss: 0.1303, Validation Loss: 0.0226,V Acc: 0.8545, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.948051948051948
76 2 [array([0.1544296 , 0.05437653, 0.0658628 , 0.16047256, 0.56485856],
      dtype=float32)]
Fold [4/5] Epoch [0/100] Initial Loss: 0.1402, Training Loss: 0.1402, Initial Validation Loss: 0.1336, Validation Loss: 0.1336,V Acc: 0.2477, Top 70th Acc: 0.3506, Bottom 30th Acc: 0.0000
Fold [4/5] Epoch [10/100] Initial Loss: 0.1402, Training Loss: 0.0161, Initial Validation Loss: 0.1336, Validation Loss: 0.0337,V Acc: 0.8440, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.5938
Fold [4/5] Epoch [20/100] Initial Loss: 0.1402, Training Loss: 0.0050, Initial Validation Loss: 0.1336, Validation Loss: 0.0297,V Acc: 0.8440, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.5938
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.948051948051948
Fold [5/5] Epoch [0/100] Initial Loss: 0.1376, Training Loss: 0.1376, Initial Validation Loss: 0.1329, Validation Loss: 0.1329,V Acc: 0.2870, Top 70th Acc: 0.3816, Bottom 30th Acc: 0.0625
Fold [5/5] Epoch [10/100] Initial Loss: 0.1376, Training Loss: 0.0249, Initial Validation Loss: 0.1329, Validation Loss: 0.0446,V Acc: 0.7963, Top 70th Acc: 0.8816, Bottom 30th Acc: 0.5938
Fold [5/5] Epoch [20/100] Initial Loss: 0.1376, Training Loss: 0.0052, Initial Validation Loss: 0.1329, Validation Loss: 0.0298,V Acc: 0.8704, Top 70th Acc: 0.9211, Bottom 30th Acc: 0.7500
Fold [5/5] Epoch [30/100] Initial Loss: 0.1376, Training Loss: 0.0039, Initial Validation Loss: 0.1329, Validation Loss: 0.0290,V Acc: 0.8611, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.6875
Fold [5/5] Epoch [40/100] Initial Loss: 0.1376, Training Loss: 0.0036, Initial Validation Loss: 0.1329, Validation Loss: 0.0290,V Acc: 0.8611, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.6562
Stopping early at Epoch (base 0): 40  Rolling back to Epoch (base 0): 35  Top Validation Acc: 0.9473684210526315
Running train_nn.py with seed 77
CUDA:False
Training samples count:  550
Training on 162 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1384, Training Loss: 0.1384, Initial Validation Loss: 0.1369, Validation Loss: 0.1369,V Acc: 0.3393, Top 70th Acc: 0.3671, Bottom 30th Acc: 0.2727
Fold [1/5] Epoch [10/100] Initial Loss: 0.1384, Training Loss: 0.0177, Initial Validation Loss: 0.1369, Validation Loss: 0.0283,V Acc: 0.8839, Top 70th Acc: 0.9620, Bottom 30th Acc: 0.6970
Fold [1/5] Epoch [20/100] Initial Loss: 0.1384, Training Loss: 0.0051, Initial Validation Loss: 0.1369, Validation Loss: 0.0226,V Acc: 0.8839, Top 70th Acc: 0.9620, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 28  Rolling back to Epoch (base 0): 23  Top Validation Acc: 0.9746835443037974
Fold [2/5] Epoch [0/100] Initial Loss: 0.1381, Training Loss: 0.1381, Initial Validation Loss: 0.1370, Validation Loss: 0.1370,V Acc: 0.4054, Top 70th Acc: 0.4487, Bottom 30th Acc: 0.3030
Fold [2/5] Epoch [10/100] Initial Loss: 0.1381, Training Loss: 0.0155, Initial Validation Loss: 0.1370, Validation Loss: 0.0350,V Acc: 0.8559, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.6061
Fold [2/5] Epoch [20/100] Initial Loss: 0.1381, Training Loss: 0.0046, Initial Validation Loss: 0.1370, Validation Loss: 0.0274,V Acc: 0.8649, Top 70th Acc: 0.9872, Bottom 30th Acc: 0.5758
Fold [2/5] Epoch [30/100] Initial Loss: 0.1381, Training Loss: 0.0037, Initial Validation Loss: 0.1370, Validation Loss: 0.0255,V Acc: 0.8919, Top 70th Acc: 0.9872, Bottom 30th Acc: 0.6667
Fold [2/5] Epoch [40/100] Initial Loss: 0.1381, Training Loss: 0.0034, Initial Validation Loss: 0.1370, Validation Loss: 0.0247,V Acc: 0.8919, Top 70th Acc: 0.9872, Bottom 30th Acc: 0.6667/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)

Fold [3/5] Epoch [20/100] Initial Loss: 0.1385, Training Loss: 0.0170, Initial Validation Loss: 0.1301, Validation Loss: 0.0323,V Acc: 0.8273, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 22  Rolling back to Epoch (base 0): 17  Top Validation Acc: 0.948051948051948
Fold [4/5] Epoch [0/100] Initial Loss: 0.1391, Training Loss: 0.1391, Initial Validation Loss: 0.1315, Validation Loss: 0.1315,V Acc: 0.3303, Top 70th Acc: 0.3506, Bottom 30th Acc: 0.2812
Fold [4/5] Epoch [10/100] Initial Loss: 0.1391, Training Loss: 0.0341, Initial Validation Loss: 0.1315, Validation Loss: 0.0413,V Acc: 0.7890, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.5000
Fold [4/5] Epoch [20/100] Initial Loss: 0.1391, Training Loss: 0.0197, Initial Validation Loss: 0.1315, Validation Loss: 0.0316,V Acc: 0.8440, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.5938
Fold [4/5] Epoch [30/100] Initial Loss: 0.1391, Training Loss: 0.0172, Initial Validation Loss: 0.1315, Validation Loss: 0.0303,V Acc: 0.8440, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.5938
Stopping early at Epoch (base 0): 30  Rolling back to Epoch (base 0): 25  Top Validation Acc: 0.948051948051948
Fold [5/5] Epoch [0/100] Initial Loss: 0.1414, Training Loss: 0.1414, Initial Validation Loss: 0.1333, Validation Loss: 0.1333,V Acc: 0.2593, Top 70th Acc: 0.2895, Bottom 30th Acc: 0.1875
Fold [5/5] Epoch [10/100] Initial Loss: 0.1414, Training Loss: 0.0308, Initial Validation Loss: 0.1333, Validation Loss: 0.0382,V Acc: 0.8148, Top 70th Acc: 0.9079, Bottom 30th Acc: 0.5938
Fold [5/5] Epoch [20/100] Initial Loss: 0.1414, Training Loss: 0.0175, Initial Validation Loss: 0.1333, Validation Loss: 0.0325,V Acc: 0.8241, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.5625
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.9210526315789473
Running train_nn.py with seed 100
CUDA:False
Training samples count:  550
Training on 29 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1402, Training Loss: 0.1402, Initial Validation Loss: 0.1357, Validation Loss: 0.1357,V Acc: 0.2589, Top 70th Acc: 0.3038, Bottom 30th Acc: 0.1515
Fold [1/5] Epoch [10/100] Initial Loss: 0.1402, Training Loss: 0.0306, Initial Validation Loss: 0.1357, Validation Loss: 0.0308,V Acc: 0.8571, Top 70th Acc: 0.9620, Bottom 30th Acc: 0.6061
Fold [1/5] Epoch [20/100] Initial Loss: 0.1402, Training Loss: 0.0196, Initial Validation Loss: 0.1357, Validation Loss: 0.0281,V Acc: 0.8482, Top 70th Acc: 0.9494, Bottom 30th Acc: 0.6061
Fold [1/5] Epoch [30/100] Initial Loss: 0.1402, Training Loss: 0.0172, Initial Validation Loss: 0.1357, Validation Loss: 0.0268,V Acc: 0.8482, Top 70th Acc: 0.9620, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 33  Rolling back to Epoch (base 0): 28  Top Validation Acc: 0.9493670886075949
Fold [2/5] Epoch [0/100] Initial Loss: 0.1382, Training Loss: 0.1382, Initial Validation Loss: 0.1304, Validation Loss: 0.1304,V Acc: 0.3333, Top 70th Acc: 0.3590, Bottom 30th Acc: 0.2727
Fold [2/5] Epoch [10/100] Initial Loss: 0.1382, Training Loss: 0.0379, Initial Validation Loss: 0.1304, Validation Loss: 0.0503,V Acc: 0.7387, Top 70th Acc: 0.8846, Bottom 30th Acc: 0.3939
Fold [2/5] Epoch [20/100] Initial Loss: 0.1382, Training Loss: 0.0214, Initial Validation Loss: 0.1304, Validation Loss: 0.0385,V Acc: 0.8108, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.5152
Fold [2/5] Epoch [30/100] Initial Loss: 0.1382, Training Loss: 0.0167, Initial Validation Loss: 0.1304, Validation Loss: 0.0355,V Acc: 0.8378, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 33  Rolling back to Epoch (base 0): 28  Top Validation Acc: 0.9487179487179487
Fold [3/5] Epoch [0/100] Initial Loss: 0.1415, Training Loss: 0.1415, Initial Validation Loss: 0.1334, Validation Loss: 0.1334,V Acc: 0.3818, Top 70th Acc: 0.4286, Bottom 30th Acc: 0.2727
Fold [3/5] Epoch [10/100] Initial Loss: 0.1415, Training Loss: 0.0290, Initial Validation Loss: 0.1334, Validation Loss: 0.0347,V Acc: 0.8455, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.6667
Fold [3/5] Epoch [20/100] Initial Loss: 0.1415, Training Loss: 0.0177, Initial Validation Loss: 0.1334, Validation Loss: 0.0299,V Acc: 0.8727, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 27  Rolling back to Epoch (base 0): 22  Top Validation Acc: 0.948051948051948
100 2 [array([0.54540235, 0.06245735, 0.02762262, 0.07530184, 0.2892157 ],
      dtype=float32)]
Fold [4/5] Epoch [0/100] Initial Loss: 0.1397, Training Loss: 0.1397, Initial Validation Loss: 0.1320, Validation Loss: 0.1320,V Acc: 0.3761, Top 70th Acc: 0.4416, Bottom 30th Acc: 0.2188
Fold [4/5] Epoch [10/100] Initial Loss: 0.1397, Training Loss: 0.0277, Initial Validation Loss: 0.1320, Validation Loss: 0.0310,V Acc: 0.8624, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.6250
Fold [4/5] Epoch [20/100] Initial Loss: 0.1397, Training Loss: 0.0177, Initial Validation Loss: 0.1320, Validation Loss: 0.0282,V Acc: 0.8349, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.5625
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.935064935064935
Fold [5/5] Epoch [0/100] Initial Loss: 0.1397, Training Loss: 0.1397, Initial Validation Loss: 0.1326, Validation Loss: 0.1326,V Acc: 0.3889, Top 70th Acc: 0.4605, Bottom 30th Acc: 0.2188
Fold [5/5] Epoch [10/100] Initial Loss: 0.1397, Training Loss: 0.0320, Initial Validation Loss: 0.1326, Validation Loss: 0.0383,V Acc: 0.8056, Top 70th Acc: 0.9079, Bottom 30th Acc: 0.5625
Fold [5/5] Epoch [20/100] Initial Loss: 0.1397, Training Loss: 0.0183, Initial Validation Loss: 0.1326, Validation Loss: 0.0317,V Acc: 0.8241, Top 70th Acc: 0.9211, Bottom 30th Acc: 0.5938
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.9342105263157895

Fold [2/5] Epoch [50/100] Initial Loss: 0.1381, Training Loss: 0.0033, Initial Validation Loss: 0.1370, Validation Loss: 0.0239,V Acc: 0.9009, Top 70th Acc: 0.9872, Bottom 30th Acc: 0.6970
Fold [2/5] Epoch [60/100] Initial Loss: 0.1381, Training Loss: 0.0032, Initial Validation Loss: 0.1370, Validation Loss: 0.0236,V Acc: 0.9099, Top 70th Acc: 0.9872, Bottom 30th Acc: 0.7273
Stopping early at Epoch (base 0): 66  Rolling back to Epoch (base 0): 61  Top Validation Acc: 0.9871794871794872
Fold [3/5] Epoch [0/100] Initial Loss: 0.1423, Training Loss: 0.1423, Initial Validation Loss: 0.1302, Validation Loss: 0.1302,V Acc: 0.3727, Top 70th Acc: 0.4675, Bottom 30th Acc: 0.1515
Fold [3/5] Epoch [10/100] Initial Loss: 0.1423, Training Loss: 0.0152, Initial Validation Loss: 0.1302, Validation Loss: 0.0352,V Acc: 0.8182, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.5758
Fold [3/5] Epoch [20/100] Initial Loss: 0.1423, Training Loss: 0.0048, Initial Validation Loss: 0.1302, Validation Loss: 0.0323,V Acc: 0.8091, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.9090909090909091
Fold [4/5] Epoch [0/100] Initial Loss: 0.1397, Training Loss: 0.1397, Initial Validation Loss: 0.1318, Validation Loss: 0.1318,V Acc: 0.3394, Top 70th Acc: 0.3506, Bottom 30th Acc: 0.3125
Fold [4/5] Epoch [10/100] Initial Loss: 0.1397, Training Loss: 0.0249, Initial Validation Loss: 0.1318, Validation Loss: 0.0344,V Acc: 0.8349, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.5938
Fold [4/5] Epoch [20/100] Initial Loss: 0.1397, Training Loss: 0.0069, Initial Validation Loss: 0.1318, Validation Loss: 0.0286,V Acc: 0.8440, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.5938
Stopping early at Epoch (base 0): 27  Rolling back to Epoch (base 0): 22  Top Validation Acc: 0.935064935064935
77 3 [array([0.25562903, 0.03254882, 0.03421991, 0.16217344, 0.5154287 ],
      dtype=float32)]
Fold [5/5] Epoch [0/100] Initial Loss: 0.1385, Training Loss: 0.1385, Initial Validation Loss: 0.1318, Validation Loss: 0.1318,V Acc: 0.2963, Top 70th Acc: 0.3553, Bottom 30th Acc: 0.1562
Fold [5/5] Epoch [10/100] Initial Loss: 0.1385, Training Loss: 0.0226, Initial Validation Loss: 0.1318, Validation Loss: 0.0487,V Acc: 0.8056, Top 70th Acc: 0.9211, Bottom 30th Acc: 0.5312
Fold [5/5] Epoch [20/100] Initial Loss: 0.1385, Training Loss: 0.0055, Initial Validation Loss: 0.1318, Validation Loss: 0.0400,V Acc: 0.8148, Top 70th Acc: 0.9079, Bottom 30th Acc: 0.5938
Fold [5/5] Epoch [30/100] Initial Loss: 0.1385, Training Loss: 0.0042, Initial Validation Loss: 0.1318, Validation Loss: 0.0370,V Acc: 0.8241, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.5625
Fold [5/5] Epoch [40/100] Initial Loss: 0.1385, Training Loss: 0.0038, Initial Validation Loss: 0.1318, Validation Loss: 0.0365,V Acc: 0.8426, Top 70th Acc: 0.9079, Bottom 30th Acc: 0.6875
Stopping early at Epoch (base 0): 44  Rolling back to Epoch (base 0): 39  Top Validation Acc: 0.9342105263157895
Running train_nn.py with seed 78
CUDA:False
Training samples count:  550
Training on 162 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1396, Training Loss: 0.1396, Initial Validation Loss: 0.1402, Validation Loss: 0.1402,V Acc: 0.2857, Top 70th Acc: 0.2785, Bottom 30th Acc: 0.3030
Fold [1/5] Epoch [10/100] Initial Loss: 0.1396, Training Loss: 0.0199, Initial Validation Loss: 0.1402, Validation Loss: 0.0348,V Acc: 0.8750, Top 70th Acc: 0.9494, Bottom 30th Acc: 0.6970
Fold [1/5] Epoch [20/100] Initial Loss: 0.1396, Training Loss: 0.0053, Initial Validation Loss: 0.1402, Validation Loss: 0.0243,V Acc: 0.9107, Top 70th Acc: 0.9873, Bottom 30th Acc: 0.7273
Fold [1/5] Epoch [30/100] Initial Loss: 0.1396, Training Loss: 0.0039, Initial Validation Loss: 0.1402, Validation Loss: 0.0236,V Acc: 0.9018, Top 70th Acc: 0.9873, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 32  Rolling back to Epoch (base 0): 27  Top Validation Acc: 0.9873417721518988
Fold [2/5] Epoch [0/100] Initial Loss: 0.1403, Training Loss: 0.1403, Initial Validation Loss: 0.1320, Validation Loss: 0.1320,V Acc: 0.2523, Top 70th Acc: 0.3462, Bottom 30th Acc: 0.0303
Fold [2/5] Epoch [10/100] Initial Loss: 0.1403, Training Loss: 0.0249, Initial Validation Loss: 0.1320, Validation Loss: 0.0401,V Acc: 0.8018, Top 70th Acc: 0.8974, Bottom 30th Acc: 0.5758
Fold [2/5] Epoch [20/100] Initial Loss: 0.1403, Training Loss: 0.0053, Initial Validation Loss: 0.1320, Validation Loss: 0.0301,V Acc: 0.8468, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.9230769230769231
Fold [3/5] Epoch [0/100] Initial Loss: 0.1389, Training Loss: 0.1389, Initial Validation Loss: 0.1356, Validation Loss: 0.1356,V Acc: 0.2273, Top 70th Acc: 0.2857, Bottom 30th Acc: 0.0909
Fold [3/5] Epoch [10/100] Initial Loss: 0.1389, Training Loss: 0.0262, Initial Validation Loss: 0.1356, Validation Loss: 0.0537,V Acc: 0.7727, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.4545
Fold [3/5] Epoch [20/100] Initial Loss: 0.1389, Training Loss: 0.0072, Initial Validation Loss: 0.1356, Validation Loss: 0.0424,V Acc: 0.8091, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.5455
Fold [3/5] Epoch [30/100] Initial Loss: 0.1389, Training Loss: 0.0048, Initial Validation Loss: 0.1356, Validation Loss: 0.0399,V Acc: 0.8273, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 39  Rolling back to Epoch (base 0): 34  Top Validation Acc: 0.922077922077922
Fold [4/5] Epoch [0/100] Initial Loss: 0.1374, Training Loss: 0.1374, Initial Validation Loss: 0.1342, Validation Loss: 0.1342,V Acc: 0.3486, Top 70th Acc: 0.4156, Bottom 30th Acc: 0.1875
Fold [4/5] Epoch [10/100] Initial Loss: 0.1374, Training Loss: 0.0113, Initial Validation Loss: 0.1342, Validation Loss: 0.0311,V Acc: 0.8440, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.5938
Fold [4/5] Epoch [20/100] Initial Loss: 0.1374, Training Loss: 0.0049, Initial Validation Loss: 0.1342, Validation Loss: 0.0270,V Acc: 0.8624, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.6250
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.961038961038961
Fold [5/5] Epoch [0/100] Initial Loss: 0.1432, Training Loss: 0.1432, Initial Validation Loss: 0.1276, Validation Loss: 0.1276,V Acc: 0.3611, Top 70th Acc: 0.4211, Bottom 30th Acc: 0.2188
Fold [5/5] Epoch [10/100] Initial Loss: 0.1432, Training Loss: 0.0150, Initial Validation Loss: 0.1276, Validation Loss: 0.0333,V Acc: 0.8056, Top 70th Acc: 0.8947, Bottom 30th Acc: 0.5938
Fold [5/5] Epoch [20/100] Initial Loss: 0.1432, Training Loss: 0.0048, Initial Validation Loss: 0.1276, Validation Loss: 0.0301,V Acc: 0.8056, Top 70th Acc: 0.9079, Bottom 30th Acc: 0.5625
Stopping early at Epoch (base 0): 28  Rolling back to Epoch (base 0): 23  Top Validation Acc: 0.9210526315789473
78 4 [array([0.1833091 , 0.0656013 , 0.06328429, 0.23438358, 0.4534217 ],
      dtype=float32)]
Running train_nn.py with seed 79
CUDA:False
Training samples count:  550
Training on 162 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1407, Training Loss: 0.1407, Initial Validation Loss: 0.1350, Validation Loss: 0.1350,V Acc: 0.2857, Top 70th Acc: 0.3291, Bottom 30th Acc: 0.1818
Fold [1/5] Epoch [10/100] Initial Loss: 0.1407, Training Loss: 0.0188, Initial Validation Loss: 0.1350, Validation Loss: 0.0312,V Acc: 0.8750, Top 70th Acc: 0.9494, Bottom 30th Acc: 0.6970
Fold [1/5] Epoch [20/100] Initial Loss: 0.1407, Training Loss: 0.0048, Initial Validation Loss: 0.1350, Validation Loss: 0.0252,V Acc: 0.8929, Top 70th Acc: 0.9620, Bottom 30th Acc: 0.7273
Fold [1/5] Epoch [30/100] Initial Loss: 0.1407, Training Loss: 0.0037, Initial Validation Loss: 0.1350, Validation Loss: 0.0252,V Acc: 0.9018, Top 70th Acc: 0.9620, Bottom 30th Acc: 0.7576
Stopping early at Epoch (base 0): 32  Rolling back to Epoch (base 0): 27  Top Validation Acc: 0.9620253164556962
Fold [2/5] Epoch [0/100] Initial Loss: 0.1394, Training Loss: 0.1394, Initial Validation Loss: 0.1397, Validation Loss: 0.1397,V Acc: 0.3153, Top 70th Acc: 0.3333, Bottom 30th Acc: 0.2727
Fold [2/5] Epoch [10/100] Initial Loss: 0.1394, Training Loss: 0.0144, Initial Validation Loss: 0.1397, Validation Loss: 0.0326,V Acc: 0.8829, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.7879
Fold [2/5] Epoch [20/100] Initial Loss: 0.1394, Training Loss: 0.0045, Initial Validation Loss: 0.1397, Validation Loss: 0.0308,V Acc: 0.8649, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.7273
Stopping early at Epoch (base 0): 20  Rolling back to Epoch (base 0): 15  Top Validation Acc: 0.9230769230769231
Fold [3/5] Epoch [0/100] Initial Loss: 0.1413, Training Loss: 0.1413, Initial Validation Loss: 0.1325, Validation Loss: 0.1325,V Acc: 0.3182, Top 70th Acc: 0.3766, Bottom 30th Acc: 0.1818
Fold [3/5] Epoch [10/100] Initial Loss: 0.1413, Training Loss: 0.0220, Initial Validation Loss: 0.1325, Validation Loss: 0.0399,V Acc: 0.8182, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.5152
Stopping early at Epoch (base 0): 19  Rolling back to Epoch (base 0): 14  Top Validation Acc: 0.922077922077922
79 2 [array([0.33289406, 0.14389452, 0.08285245, 0.1854731 , 0.2548859 ],
      dtype=float32)]
Fold [4/5] Epoch [0/100] Initial Loss: 0.1408, Training Loss: 0.1408, Initial Validation Loss: 0.1312, Validation Loss: 0.1312,V Acc: 0.4404, Top 70th Acc: 0.5065, Bottom 30th Acc: 0.2812
Fold [4/5] Epoch [10/100] Initial Loss: 0.1408, Training Loss: 0.0237, Initial Validation Loss: 0.1312, Validation Loss: 0.0375,V Acc: 0.7798, Top 70th Acc: 0.8961, Bottom 30th Acc: 0.5000
Fold [4/5] Epoch [20/100] Initial Loss: 0.1408, Training Loss: 0.0050, Initial Validation Loss: 0.1312, Validation Loss: 0.0318,V Acc: 0.8440, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.5938
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.948051948051948
Fold [5/5] Epoch [0/100] Initial Loss: 0.1387, Training Loss: 0.1387, Initial Validation Loss: 0.1322, Validation Loss: 0.1322,V Acc: 0.2778, Top 70th Acc: 0.3421, Bottom 30th Acc: 0.1250
Fold [5/5] Epoch [10/100] Initial Loss: 0.1387, Training Loss: 0.0153, Initial Validation Loss: 0.1322, Validation Loss: 0.0426,V Acc: 0.7685, Top 70th Acc: 0.8947, Bottom 30th Acc: 0.4688
Fold [5/5] Epoch [20/100] Initial Loss: 0.1387, Training Loss: 0.0056, Initial Validation Loss: 0.1322, Validation Loss: 0.0397,V Acc: 0.7870, Top 70th Acc: 0.9079, Bottom 30th Acc: 0.5000
Fold [5/5] Epoch [30/100] Initial Loss: 0.1387, Training Loss: 0.0044, Initial Validation Loss: 0.1322, Validation Loss: 0.0380,V Acc: 0.8148, Top 70th Acc: 0.9211, Bottom 30th Acc: 0.5625
Fold [5/5] Epoch [40/100] Initial Loss: 0.1387, Training Loss: 0.0039, Initial Validation Loss: 0.1322, Validation Loss: 0.0363,V Acc: 0.8241, Top 70th Acc: 0.9211, Bottom 30th Acc: 0.5938
Fold [5/5] Epoch [50/100] Initial Loss: 0.1387, Training Loss: 0.0037, Initial Validation Loss: 0.1322, Validation Loss: 0.0346,V Acc: 0.8241, Top 70th Acc: 0.9211, Bottom 30th Acc: 0.5938
Fold [5/5] Epoch [60/100] Initial Loss: 0.1387, Training Loss: 0.0036, Initial Validation Loss: 0.1322, Validation Loss: 0.0333,V Acc: 0.8241, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.5625
Fold [5/5] Epoch [70/100] Initial Loss: 0.1387, Training Loss: 0.0035, Initial Validation Loss: 0.1322, Validation Loss: 0.0321,V Acc: 0.8241, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.5625
Fold [5/5] Epoch [80/100] Initial Loss: 0.1387, Training Loss: 0.0034, Initial Validation Loss: 0.1322, Validation Loss: 0.0317,V Acc: 0.8333, Top 70th Acc: 0.9211, Bottom 30th Acc: 0.6250
Stopping early at Epoch (base 0): 83  Rolling back to Epoch (base 0): 78  Top Validation Acc: 0.9210526315789473
Running train_nn.py with seed 80
CUDA:False
Training samples count:  550
Training on 162 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1370, Training Loss: 0.1370, Initial Validation Loss: 0.1392, Validation Loss: 0.1392,V Acc: 0.2768, Top 70th Acc: 0.3291, Bottom 30th Acc: 0.1515
Fold [1/5] Epoch [10/100] Initial Loss: 0.1370, Training Loss: 0.0211, Initial Validation Loss: 0.1392, Validation Loss: 0.0397,V Acc: 0.8214, Top 70th Acc: 0.9241, Bottom 30th Acc: 0.5758
Fold [1/5] Epoch [20/100] Initial Loss: 0.1370, Training Loss: 0.0063, Initial Validation Loss: 0.1392, Validation Loss: 0.0348,V Acc: 0.8393, Top 70th Acc: 0.9494, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.9493670886075949
Fold [2/5] Epoch [0/100] Initial Loss: 0.1383, Training Loss: 0.1383, Initial Validation Loss: 0.1336, Validation Loss: 0.1336,V Acc: 0.2523, Top 70th Acc: 0.3462, Bottom 30th Acc: 0.0303
Fold [2/5] Epoch [10/100] Initial Loss: 0.1383, Training Loss: 0.0162, Initial Validation Loss: 0.1336, Validation Loss: 0.0394,V Acc: 0.8018, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.5152
Fold [2/5] Epoch [20/100] Initial Loss: 0.1383, Training Loss: 0.0055, Initial Validation Loss: 0.1336, Validation Loss: 0.0356,V Acc: 0.7838, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.4242
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.9487179487179487
80 1 [array([0.28942552, 0.04120464, 0.02537955, 0.17925596, 0.46473432],
      dtype=float32)]
Fold [3/5] Epoch [0/100] Initial Loss: 0.1381, Training Loss: 0.1381, Initial Validation Loss: 0.1338, Validation Loss: 0.1338,V Acc: 0.4000, Top 70th Acc: 0.4675, Bottom 30th Acc: 0.2424
Fold [3/5] Epoch [10/100] Initial Loss: 0.1381, Training Loss: 0.0228, Initial Validation Loss: 0.1338, Validation Loss: 0.0404,V Acc: 0.8273, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.6364
Fold [3/5] Epoch [20/100] Initial Loss: 0.1381, Training Loss: 0.0064, Initial Validation Loss: 0.1338, Validation Loss: 0.0360,V Acc: 0.8182, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.5455
Fold [3/5] Epoch [30/100] Initial Loss: 0.1381, Training Loss: 0.0047, Initial Validation Loss: 0.1338, Validation Loss: 0.0355,V Acc: 0.8091, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 33  Rolling back to Epoch (base 0): 28  Top Validation Acc: 0.935064935064935
Fold [4/5] Epoch [0/100] Initial Loss: 0.1411, Training Loss: 0.1411, Initial Validation Loss: 0.1289, Validation Loss: 0.1289,V Acc: 0.2294, Top 70th Acc: 0.1948, Bottom 30th Acc: 0.3125
Fold [4/5] Epoch [10/100] Initial Loss: 0.1411, Training Loss: 0.0244, Initial Validation Loss: 0.1289, Validation Loss: 0.0381,V Acc: 0.7982, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.5312
Fold [4/5] Epoch [20/100] Initial Loss: 0.1411, Training Loss: 0.0052, Initial Validation Loss: 0.1289, Validation Loss: 0.0272,V Acc: 0.8349, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.5625
Stopping early at Epoch (base 0): 22  Rolling back to Epoch (base 0): 17  Top Validation Acc: 0.961038961038961
Fold [5/5] Epoch [0/100] Initial Loss: 0.1389, Training Loss: 0.1389, Initial Validation Loss: 0.1332, Validation Loss: 0.1332,V Acc: 0.2870, Top 70th Acc: 0.3421, Bottom 30th Acc: 0.1562
Fold [5/5] Epoch [10/100] Initial Loss: 0.1389, Training Loss: 0.0173, Initial Validation Loss: 0.1332, Validation Loss: 0.0344,V Acc: 0.8426, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.6250
Fold [5/5] Epoch [20/100] Initial Loss: 0.1389, Training Loss: 0.0051, Initial Validation Loss: 0.1332, Validation Loss: 0.0276,V Acc: 0.8519, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.5938
Fold [5/5] Epoch [30/100] Initial Loss: 0.1389, Training Loss: 0.0039, Initial Validation Loss: 0.1332, Validation Loss: 0.0259,V Acc: 0.8519, Top 70th Acc: 0.9737, Bottom 30th Acc: 0.5625
Fold [5/5] Epoch [40/100] Initial Loss: 0.1389, Training Loss: 0.0036, Initial Validation Loss: 0.1332, Validation Loss: 0.0255,V Acc: 0.8519, Top 70th Acc: 0.9737, Bottom 30th Acc: 0.5625
Stopping early at Epoch (base 0): 49  Rolling back to Epoch (base 0): 44  Top Validation Acc: 0.9736842105263158
Running train_nn.py with seed 81
CUDA:False
Training samples count:  550
Training on 162 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1413, Training Loss: 0.1413, Initial Validation Loss: 0.1341, Validation Loss: 0.1341,V Acc: 0.4018, Top 70th Acc: 0.4430, Bottom 30th Acc: 0.3030
Fold [1/5] Epoch [10/100] Initial Loss: 0.1413, Training Loss: 0.0280, Initial Validation Loss: 0.1341, Validation Loss: 0.0453,V Acc: 0.7768, Top 70th Acc: 0.8987, Bottom 30th Acc: 0.4848
Fold [1/5] Epoch [20/100] Initial Loss: 0.1413, Training Loss: 0.0067, Initial Validation Loss: 0.1341, Validation Loss: 0.0349,V Acc: 0.8304, Top 70th Acc: 0.9241, Bottom 30th Acc: 0.6061
Fold [1/5] Epoch [30/100] Initial Loss: 0.1413, Training Loss: 0.0045, Initial Validation Loss: 0.1341, Validation Loss: 0.0334,V Acc: 0.8482, Top 70th Acc: 0.9494, Bottom 30th Acc: 0.6061
Fold [1/5] Epoch [40/100] Initial Loss: 0.1413, Training Loss: 0.0039, Initial Validation Loss: 0.1341, Validation Loss: 0.0319,V Acc: 0.8482, Top 70th Acc: 0.9241, Bottom 30th Acc: 0.6667
Fold [1/5] Epoch [50/100] Initial Loss: 0.1413, Training Loss: 0.0038, Initial Validation Loss: 0.1341, Validation Loss: 0.0310,V Acc: 0.8482, Top 70th Acc: 0.9367, Bottom 30th Acc: 0.6364
Fold [1/5] Epoch [60/100] Initial Loss: 0.1413, Training Loss: 0.0036, Initial Validation Loss: 0.1341, Validation Loss: 0.0306,V Acc: 0.8571, Top 70th Acc: 0.9367, Bottom 30th Acc: 0.6667
Fold [1/5] Epoch [70/100] Initial Loss: 0.1413, Training Loss: 0.0036, Initial Validation Loss: 0.1341, Validation Loss: 0.0306,V Acc: 0.8571, Top 70th Acc: 0.9367, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 72  Rolling back to Epoch (base 0): 67  Top Validation Acc: 0.9367088607594937
Fold [2/5] Epoch [0/100] Initial Loss: 0.1388, Training Loss: 0.1388, Initial Validation Loss: 0.1356, Validation Loss: 0.1356,V Acc: 0.3063, Top 70th Acc: 0.3718, Bottom 30th Acc: 0.1515
Fold [2/5] Epoch [10/100] Initial Loss: 0.1388, Training Loss: 0.0159, Initial Validation Loss: 0.1356, Validation Loss: 0.0316,V Acc: 0.8919, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.7576
Fold [2/5] Epoch [20/100] Initial Loss: 0.1388, Training Loss: 0.0051, Initial Validation Loss: 0.1356, Validation Loss: 0.0288,V Acc: 0.8559, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.9487179487179487
Fold [3/5] Epoch [0/100] Initial Loss: 0.1405, Training Loss: 0.1405, Initial Validation Loss: 0.1355, Validation Loss: 0.1355,V Acc: 0.3091, Top 70th Acc: 0.3377, Bottom 30th Acc: 0.2424
Fold [3/5] Epoch [10/100] Initial Loss: 0.1405, Training Loss: 0.0146, Initial Validation Loss: 0.1355, Validation Loss: 0.0313,V Acc: 0.8455, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.5455
Fold [3/5] Epoch [20/100] Initial Loss: 0.1405, Training Loss: 0.0046, Initial Validation Loss: 0.1355, Validation Loss: 0.0281,V Acc: 0.8727, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.948051948051948
Fold [4/5] Epoch [0/100] Initial Loss: 0.1391, Training Loss: 0.1391, Initial Validation Loss: 0.1353, Validation Loss: 0.1353,V Acc: 0.2477, Top 70th Acc: 0.3247, Bottom 30th Acc: 0.0625
Fold [4/5] Epoch [10/100] Initial Loss: 0.1391, Training Loss: 0.0146, Initial Validation Loss: 0.1353, Validation Loss: 0.0367,V Acc: 0.8532, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.5938
Fold [4/5] Epoch [20/100] Initial Loss: 0.1391, Training Loss: 0.0050, Initial Validation Loss: 0.1353, Validation Loss: 0.0321,V Acc: 0.8532, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.5625
Fold [4/5] Epoch [30/100] Initial Loss: 0.1391, Training Loss: 0.0040, Initial Validation Loss: 0.1353, Validation Loss: 0.0307,V Acc: 0.8716, Top 70th Acc: 0.9870, Bottom 30th Acc: 0.5938
Fold [4/5] Epoch [40/100] Initial Loss: 0.1391, Training Loss: 0.0037, Initial Validation Loss: 0.1353, Validation Loss: 0.0302,V Acc: 0.8716, Top 70th Acc: 0.9870, Bottom 30th Acc: 0.5938
Stopping early at Epoch (base 0): 43  Rolling back to Epoch (base 0): 38  Top Validation Acc: 0.987012987012987
Fold [5/5] Epoch [0/100] Initial Loss: 0.1396, Training Loss: 0.1396, Initial Validation Loss: 0.1317, Validation Loss: 0.1317,V Acc: 0.2500, Top 70th Acc: 0.3421, Bottom 30th Acc: 0.0312
Fold [5/5] Epoch [10/100] Initial Loss: 0.1396, Training Loss: 0.0291, Initial Validation Loss: 0.1317, Validation Loss: 0.0377,V Acc: 0.8241, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.5625
Fold [5/5] Epoch [20/100] Initial Loss: 0.1396, Training Loss: 0.0054, Initial Validation Loss: 0.1317, Validation Loss: 0.0248,V Acc: 0.8704, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.6562
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.9473684210526315
81 4 [array([0.2881959 , 0.04493174, 0.0626511 , 0.24139851, 0.3628227 ],
      dtype=float32)]
Running train_nn.py with seed 82
CUDA:False
Training samples count:  550
Training on 162 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1399, Training Loss: 0.1399, Initial Validation Loss: 0.1319, Validation Loss: 0.1319,V Acc: 0.2500, Top 70th Acc: 0.3418, Bottom 30th Acc: 0.0303
Fold [1/5] Epoch [10/100] Initial Loss: 0.1399, Training Loss: 0.0189, Initial Validation Loss: 0.1319, Validation Loss: 0.0412,V Acc: 0.7589, Top 70th Acc: 0.9114, Bottom 30th Acc: 0.3939
Fold [1/5] Epoch [20/100] Initial Loss: 0.1399, Training Loss: 0.0060, Initial Validation Loss: 0.1319, Validation Loss: 0.0363,V Acc: 0.7857, Top 70th Acc: 0.9367, Bottom 30th Acc: 0.4242
Fold [1/5] Epoch [30/100] Initial Loss: 0.1399, Training Loss: 0.0046, Initial Validation Loss: 0.1319, Validation Loss: 0.0357,V Acc: 0.7946, Top 70th Acc: 0.9241, Bottom 30th Acc: 0.4848
Stopping early at Epoch (base 0): 36  Rolling back to Epoch (base 0): 31  Top Validation Acc: 0.9240506329113924
Fold [2/5] Epoch [0/100] Initial Loss: 0.1411, Training Loss: 0.1411, Initial Validation Loss: 0.1366, Validation Loss: 0.1366,V Acc: 0.2793, Top 70th Acc: 0.3590, Bottom 30th Acc: 0.0909
Fold [2/5] Epoch [10/100] Initial Loss: 0.1411, Training Loss: 0.0228, Initial Validation Loss: 0.1366, Validation Loss: 0.0395,V Acc: 0.8559, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.7273
Fold [2/5] Epoch [20/100] Initial Loss: 0.1411, Training Loss: 0.0078, Initial Validation Loss: 0.1366, Validation Loss: 0.0397,V Acc: 0.8198, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 20  Rolling back to Epoch (base 0): 15  Top Validation Acc: 0.9230769230769231
Fold [3/5] Epoch [0/100] Initial Loss: 0.1384, Training Loss: 0.1384, Initial Validation Loss: 0.1372, Validation Loss: 0.1372,V Acc: 0.3091, Top 70th Acc: 0.4286, Bottom 30th Acc: 0.0303
Fold [3/5] Epoch [10/100] Initial Loss: 0.1384, Training Loss: 0.0231, Initial Validation Loss: 0.1372, Validation Loss: 0.0365,V Acc: 0.8545, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.6061
Fold [3/5] Epoch [20/100] Initial Loss: 0.1384, Training Loss: 0.0057, Initial Validation Loss: 0.1372, Validation Loss: 0.0276,V Acc: 0.8636, Top 70th Acc: 0.9870, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.987012987012987
Fold [4/5] Epoch [0/100] Initial Loss: 0.1396, Training Loss: 0.1396, Initial Validation Loss: 0.1306, Validation Loss: 0.1306,V Acc: 0.3394, Top 70th Acc: 0.3766, Bottom 30th Acc: 0.2500
Fold [4/5] Epoch [10/100] Initial Loss: 0.1396, Training Loss: 0.0160, Initial Validation Loss: 0.1306, Validation Loss: 0.0312,V Acc: 0.8991, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.7812
Fold [4/5] Epoch [20/100] Initial Loss: 0.1396, Training Loss: 0.0052, Initial Validation Loss: 0.1306, Validation Loss: 0.0266,V Acc: 0.8716, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.6562
Fold [4/5] Epoch [30/100] Initial Loss: 0.1396, Training Loss: 0.0042, Initial Validation Loss: 0.1306, Validation Loss: 0.0267,V Acc: 0.8807, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.7188
Stopping early at Epoch (base 0): 31  Rolling back to Epoch (base 0): 26  Top Validation Acc: 0.961038961038961
Fold [5/5] Epoch [0/100] Initial Loss: 0.1429, Training Loss: 0.1429, Initial Validation Loss: 0.1298, Validation Loss: 0.1298,V Acc: 0.2685, Top 70th Acc: 0.2368, Bottom 30th Acc: 0.3438
Fold [5/5] Epoch [10/100] Initial Loss: 0.1429, Training Loss: 0.0145, Initial Validation Loss: 0.1298, Validation Loss: 0.0396,V Acc: 0.7685, Top 70th Acc: 0.8947, Bottom 30th Acc: 0.4688
Stopping early at Epoch (base 0): 17  Rolling back to Epoch (base 0): 12  Top Validation Acc: 0.8947368421052632
82 4 [array([0.1028684 , 0.12866071, 0.09069786, 0.2083909 , 0.46938214],
      dtype=float32)]
Running train_nn.py with seed 83
CUDA:False
Training samples count:  550
Training on 162 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1387, Training Loss: 0.1387, Initial Validation Loss: 0.1361, Validation Loss: 0.1361,V Acc: 0.2589, Top 70th Acc: 0.3544, Bottom 30th Acc: 0.0303
Fold [1/5] Epoch [10/100] Initial Loss: 0.1387, Training Loss: 0.0180, Initial Validation Loss: 0.1361, Validation Loss: 0.0316,V Acc: 0.8661, Top 70th Acc: 0.9494, Bottom 30th Acc: 0.6667
Fold [1/5] Epoch [20/100] Initial Loss: 0.1387, Training Loss: 0.0063, Initial Validation Loss: 0.1361, Validation Loss: 0.0290,V Acc: 0.8839, Top 70th Acc: 0.9747, Bottom 30th Acc: 0.6667
Fold [1/5] Epoch [30/100] Initial Loss: 0.1387, Training Loss: 0.0045, Initial Validation Loss: 0.1361, Validation Loss: 0.0289,V Acc: 0.8661, Top 70th Acc: 0.9620, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 30  Rolling back to Epoch (base 0): 25  Top Validation Acc: 0.9620253164556962
Fold [2/5] Epoch [0/100] Initial Loss: 0.1387, Training Loss: 0.1387, Initial Validation Loss: 0.1346, Validation Loss: 0.1346,V Acc: 0.3153, Top 70th Acc: 0.4103, Bottom 30th Acc: 0.0909
Fold [2/5] Epoch [10/100] Initial Loss: 0.1387, Training Loss: 0.0231, Initial Validation Loss: 0.1346, Validation Loss: 0.0397,V Acc: 0.8378, Top 70th Acc: 0.8974, Bottom 30th Acc: 0.6970
Fold [2/5] Epoch [20/100] Initial Loss: 0.1387, Training Loss: 0.0066, Initial Validation Loss: 0.1346, Validation Loss: 0.0314,V Acc: 0.8468, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.6364
Fold [2/5] Epoch [30/100] Initial Loss: 0.1387, Training Loss: 0.0048, Initial Validation Loss: 0.1346, Validation Loss: 0.0293,V Acc: 0.8378, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.5758
Fold [2/5] Epoch [40/100] Initial Loss: 0.1387, Training Loss: 0.0044, Initial Validation Loss: 0.1346, Validation Loss: 0.0278,V Acc: 0.8378, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.5455
Fold [2/5] Epoch [50/100] Initial Loss: 0.1387, Training Loss: 0.0042, Initial Validation Loss: 0.1346, Validation Loss: 0.0262,V Acc: 0.8468, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 54  Rolling back to Epoch (base 0): 49  Top Validation Acc: 0.9487179487179487
Fold [3/5] Epoch [0/100] Initial Loss: 0.1408, Training Loss: 0.1408, Initial Validation Loss: 0.1319, Validation Loss: 0.1319,V Acc: 0.3818, Top 70th Acc: 0.4805, Bottom 30th Acc: 0.1515
Fold [3/5] Epoch [10/100] Initial Loss: 0.1408, Training Loss: 0.0135, Initial Validation Loss: 0.1319, Validation Loss: 0.0458,V Acc: 0.7818, Top 70th Acc: 0.8961, Bottom 30th Acc: 0.5152
Fold [3/5] Epoch [20/100] Initial Loss: 0.1408, Training Loss: 0.0046, Initial Validation Loss: 0.1319, Validation Loss: 0.0381,V Acc: 0.8182, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.935064935064935
Fold [4/5] Epoch [0/100] Initial Loss: 0.1387, Training Loss: 0.1387, Initial Validation Loss: 0.1309, Validation Loss: 0.1309,V Acc: 0.2661, Top 70th Acc: 0.3506, Bottom 30th Acc: 0.0625
Fold [4/5] Epoch [10/100] Initial Loss: 0.1387, Training Loss: 0.0187, Initial Validation Loss: 0.1309, Validation Loss: 0.0375,V Acc: 0.8165, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.5625
Fold [4/5] Epoch [20/100] Initial Loss: 0.1387, Training Loss: 0.0050, Initial Validation Loss: 0.1309, Validation Loss: 0.0308,V Acc: 0.8532, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.6562
Fold [4/5] Epoch [30/100] Initial Loss: 0.1387, Training Loss: 0.0040, Initial Validation Loss: 0.1309, Validation Loss: 0.0309,V Acc: 0.8440, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.5625
Stopping early at Epoch (base 0): 33  Rolling back to Epoch (base 0): 28  Top Validation Acc: 0.961038961038961
83 3 [array([0.25903174, 0.04568305, 0.06504161, 0.29241464, 0.33782908],
      dtype=float32)]
Fold [5/5] Epoch [0/100] Initial Loss: 0.1393, Training Loss: 0.1393, Initial Validation Loss: 0.1335, Validation Loss: 0.1335,V Acc: 0.2685, Top 70th Acc: 0.3026, Bottom 30th Acc: 0.1875
Fold [5/5] Epoch [10/100] Initial Loss: 0.1393, Training Loss: 0.0155, Initial Validation Loss: 0.1335, Validation Loss: 0.0332,V Acc: 0.7963, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.4688
Fold [5/5] Epoch [20/100] Initial Loss: 0.1393, Training Loss: 0.0050, Initial Validation Loss: 0.1335, Validation Loss: 0.0301,V Acc: 0.8333, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.5625
Stopping early at Epoch (base 0): 21  Rolling back to Epoch (base 0): 16  Top Validation Acc: 0.9342105263157895
Running train_nn.py with seed 84
CUDA:False
Training samples count:  550
Training on 162 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1393, Training Loss: 0.1393, Initial Validation Loss: 0.1351, Validation Loss: 0.1351,V Acc: 0.2500, Top 70th Acc: 0.3165, Bottom 30th Acc: 0.0909
Fold [1/5] Epoch [10/100] Initial Loss: 0.1393, Training Loss: 0.0150, Initial Validation Loss: 0.1351, Validation Loss: 0.0373,V Acc: 0.8036, Top 70th Acc: 0.9241, Bottom 30th Acc: 0.5152
Fold [1/5] Epoch [20/100] Initial Loss: 0.1393, Training Loss: 0.0048, Initial Validation Loss: 0.1351, Validation Loss: 0.0326,V Acc: 0.8304, Top 70th Acc: 0.9241, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 29  Rolling back to Epoch (base 0): 24  Top Validation Acc: 0.9113924050632911
Fold [2/5] Epoch [0/100] Initial Loss: 0.1384, Training Loss: 0.1384, Initial Validation Loss: 0.1362, Validation Loss: 0.1362,V Acc: 0.3243, Top 70th Acc: 0.3974, Bottom 30th Acc: 0.1515
Fold [2/5] Epoch [10/100] Initial Loss: 0.1384, Training Loss: 0.0226, Initial Validation Loss: 0.1362, Validation Loss: 0.0330,V Acc: 0.8198, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.5455
Fold [2/5] Epoch [20/100] Initial Loss: 0.1384, Training Loss: 0.0054, Initial Validation Loss: 0.1362, Validation Loss: 0.0270,V Acc: 0.8559, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 20  Rolling back to Epoch (base 0): 15  Top Validation Acc: 0.9615384615384616
84 1 [array([0.29093823, 0.07974149, 0.1530363 , 0.19883198, 0.27745196],
      dtype=float32)]
Fold [3/5] Epoch [0/100] Initial Loss: 0.1404, Training Loss: 0.1404, Initial Validation Loss: 0.1324, Validation Loss: 0.1324,V Acc: 0.2545, Top 70th Acc: 0.3506, Bottom 30th Acc: 0.0303
Fold [3/5] Epoch [10/100] Initial Loss: 0.1404, Training Loss: 0.0219, Initial Validation Loss: 0.1324, Validation Loss: 0.0330,V Acc: 0.8727, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6970
Fold [3/5] Epoch [20/100] Initial Loss: 0.1404, Training Loss: 0.0050, Initial Validation Loss: 0.1324, Validation Loss: 0.0268,V Acc: 0.8727, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.6667
Fold [3/5] Epoch [30/100] Initial Loss: 0.1404, Training Loss: 0.0039, Initial Validation Loss: 0.1324, Validation Loss: 0.0250,V Acc: 0.9000, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.7576
Stopping early at Epoch (base 0): 37  Rolling back to Epoch (base 0): 32  Top Validation Acc: 0.961038961038961
Fold [4/5] Epoch [0/100] Initial Loss: 0.1391, Training Loss: 0.1391, Initial Validation Loss: 0.1351, Validation Loss: 0.1351,V Acc: 0.2477, Top 70th Acc: 0.3506, Bottom 30th Acc: 0.0000
Fold [4/5] Epoch [10/100] Initial Loss: 0.1391, Training Loss: 0.0257, Initial Validation Loss: 0.1351, Validation Loss: 0.0396,V Acc: 0.8624, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.6875
Fold [4/5] Epoch [20/100] Initial Loss: 0.1391, Training Loss: 0.0050, Initial Validation Loss: 0.1351, Validation Loss: 0.0261,V Acc: 0.8716, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.6562
Fold [4/5] Epoch [30/100] Initial Loss: 0.1391, Training Loss: 0.0038, Initial Validation Loss: 0.1351, Validation Loss: 0.0257,V Acc: 0.8899, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.7188
Stopping early at Epoch (base 0): 30  Rolling back to Epoch (base 0): 25  Top Validation Acc: 0.961038961038961
Fold [5/5] Epoch [0/100] Initial Loss: 0.1382, Training Loss: 0.1382, Initial Validation Loss: 0.1313, Validation Loss: 0.1313,V Acc: 0.2685, Top 70th Acc: 0.3684, Bottom 30th Acc: 0.0312
Fold [5/5] Epoch [10/100] Initial Loss: 0.1382, Training Loss: 0.0105, Initial Validation Loss: 0.1313, Validation Loss: 0.0254,V Acc: 0.8889, Top 70th Acc: 0.9868, Bottom 30th Acc: 0.6562
Fold [5/5] Epoch [20/100] Initial Loss: 0.1382, Training Loss: 0.0046, Initial Validation Loss: 0.1313, Validation Loss: 0.0246,V Acc: 0.8889, Top 70th Acc: 0.9737, Bottom 30th Acc: 0.6875
Stopping early at Epoch (base 0): 20  Rolling back to Epoch (base 0): 15  Top Validation Acc: 0.9736842105263158
Running train_nn.py with seed 85
CUDA:False
Training samples count:  550
Training on 162 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1416, Training Loss: 0.1416, Initial Validation Loss: 0.1373, Validation Loss: 0.1373,V Acc: 0.2500, Top 70th Acc: 0.3291, Bottom 30th Acc: 0.0606
Fold [1/5] Epoch [10/100] Initial Loss: 0.1416, Training Loss: 0.0151, Initial Validation Loss: 0.1373, Validation Loss: 0.0331,V Acc: 0.8661, Top 70th Acc: 0.9620, Bottom 30th Acc: 0.6364
Fold [1/5] Epoch [20/100] Initial Loss: 0.1416, Training Loss: 0.0048, Initial Validation Loss: 0.1373, Validation Loss: 0.0280,V Acc: 0.8750, Top 70th Acc: 0.9620, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.9620253164556962
Fold [2/5] Epoch [0/100] Initial Loss: 0.1419, Training Loss: 0.1419, Initial Validation Loss: 0.1380, Validation Loss: 0.1380,V Acc: 0.3604, Top 70th Acc: 0.3974, Bottom 30th Acc: 0.2727
Fold [2/5] Epoch [10/100] Initial Loss: 0.1419, Training Loss: 0.0145, Initial Validation Loss: 0.1380, Validation Loss: 0.0310,V Acc: 0.8829, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.6667
Fold [2/5] Epoch [20/100] Initial Loss: 0.1419, Training Loss: 0.0048, Initial Validation Loss: 0.1380, Validation Loss: 0.0271,V Acc: 0.8919, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 28  Rolling back to Epoch (base 0): 23  Top Validation Acc: 0.9871794871794872
Fold [3/5] Epoch [0/100] Initial Loss: 0.1399, Training Loss: 0.1399, Initial Validation Loss: 0.1355, Validation Loss: 0.1355,V Acc: 0.2364, Top 70th Acc: 0.3247, Bottom 30th Acc: 0.0303
Fold [3/5] Epoch [10/100] Initial Loss: 0.1399, Training Loss: 0.0146, Initial Validation Loss: 0.1355, Validation Loss: 0.0350,V Acc: 0.8273, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.6061
Fold [3/5] Epoch [20/100] Initial Loss: 0.1399, Training Loss: 0.0045, Initial Validation Loss: 0.1355, Validation Loss: 0.0309,V Acc: 0.8727, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.7273
Stopping early at Epoch (base 0): 29  Rolling back to Epoch (base 0): 24  Top Validation Acc: 0.935064935064935
85 2 [array([0.35129094, 0.06115009, 0.05769983, 0.281848  , 0.2480111 ],
      dtype=float32)]
Fold [4/5] Epoch [0/100] Initial Loss: 0.1363, Training Loss: 0.1363, Initial Validation Loss: 0.1331, Validation Loss: 0.1331,V Acc: 0.4220, Top 70th Acc: 0.5195, Bottom 30th Acc: 0.1875
Fold [4/5] Epoch [10/100] Initial Loss: 0.1363, Training Loss: 0.0136, Initial Validation Loss: 0.1331, Validation Loss: 0.0317,V Acc: 0.8899, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.7500
Fold [4/5] Epoch [20/100] Initial Loss: 0.1363, Training Loss: 0.0053, Initial Validation Loss: 0.1331, Validation Loss: 0.0288,V Acc: 0.8716, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.7188
Stopping early at Epoch (base 0): 28  Rolling back to Epoch (base 0): 23  Top Validation Acc: 0.935064935064935
Fold [5/5] Epoch [0/100] Initial Loss: 0.1408, Training Loss: 0.1408, Initial Validation Loss: 0.1271, Validation Loss: 0.1271,V Acc: 0.2500, Top 70th Acc: 0.2632, Bottom 30th Acc: 0.2188
Fold [5/5] Epoch [10/100] Initial Loss: 0.1408, Training Loss: 0.0349, Initial Validation Loss: 0.1271, Validation Loss: 0.0550,V Acc: 0.6944, Top 70th Acc: 0.8289, Bottom 30th Acc: 0.3750
Fold [5/5] Epoch [20/100] Initial Loss: 0.1408, Training Loss: 0.0094, Initial Validation Loss: 0.1271, Validation Loss: 0.0427,V Acc: 0.7593, Top 70th Acc: 0.8947, Bottom 30th Acc: 0.4375
Fold [5/5] Epoch [30/100] Initial Loss: 0.1408, Training Loss: 0.0040, Initial Validation Loss: 0.1271, Validation Loss: 0.0383,V Acc: 0.7778, Top 70th Acc: 0.9079, Bottom 30th Acc: 0.4688
Fold [5/5] Epoch [40/100] Initial Loss: 0.1408, Training Loss: 0.0034, Initial Validation Loss: 0.1271, Validation Loss: 0.0376,V Acc: 0.7778, Top 70th Acc: 0.9211, Bottom 30th Acc: 0.4375
Fold [5/5] Epoch [50/100] Initial Loss: 0.1408, Training Loss: 0.0033, Initial Validation Loss: 0.1271, Validation Loss: 0.0369,V Acc: 0.7870, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.4375
Stopping early at Epoch (base 0): 56  Rolling back to Epoch (base 0): 51  Top Validation Acc: 0.9342105263157895
Running train_nn.py with seed 86
CUDA:False
Training samples count:  550
Training on 162 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1434, Training Loss: 0.1434, Initial Validation Loss: 0.1334, Validation Loss: 0.1334,V Acc: 0.2500, Top 70th Acc: 0.3544, Bottom 30th Acc: 0.0000
Fold [1/5] Epoch [10/100] Initial Loss: 0.1434, Training Loss: 0.0146, Initial Validation Loss: 0.1334, Validation Loss: 0.0356,V Acc: 0.8661, Top 70th Acc: 0.9494, Bottom 30th Acc: 0.6667
Fold [1/5] Epoch [20/100] Initial Loss: 0.1434, Training Loss: 0.0050, Initial Validation Loss: 0.1334, Validation Loss: 0.0305,V Acc: 0.8661, Top 70th Acc: 0.9620, Bottom 30th Acc: 0.6364
Fold [1/5] Epoch [30/100] Initial Loss: 0.1434, Training Loss: 0.0042, Initial Validation Loss: 0.1334, Validation Loss: 0.0291,V Acc: 0.8750, Top 70th Acc: 0.9620, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 34  Rolling back to Epoch (base 0): 29  Top Validation Acc: 0.9746835443037974
86 0 [array([0.4964507 , 0.02947965, 0.07690226, 0.2795459 , 0.11762151],
      dtype=float32)]
Fold [2/5] Epoch [0/100] Initial Loss: 0.1386, Training Loss: 0.1386, Initial Validation Loss: 0.1362, Validation Loss: 0.1362,V Acc: 0.2613, Top 70th Acc: 0.3590, Bottom 30th Acc: 0.0303
Fold [2/5] Epoch [10/100] Initial Loss: 0.1386, Training Loss: 0.0165, Initial Validation Loss: 0.1362, Validation Loss: 0.0345,V Acc: 0.8649, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.6364
Fold [2/5] Epoch [20/100] Initial Loss: 0.1386, Training Loss: 0.0065, Initial Validation Loss: 0.1362, Validation Loss: 0.0323,V Acc: 0.8739, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.9615384615384616
Fold [3/5] Epoch [0/100] Initial Loss: 0.1387, Training Loss: 0.1387, Initial Validation Loss: 0.1354, Validation Loss: 0.1354,V Acc: 0.3182, Top 70th Acc: 0.3636, Bottom 30th Acc: 0.2121
Fold [3/5] Epoch [10/100] Initial Loss: 0.1387, Training Loss: 0.0187, Initial Validation Loss: 0.1354, Validation Loss: 0.0272,V Acc: 0.8909, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.6970
Fold [3/5] Epoch [20/100] Initial Loss: 0.1387, Training Loss: 0.0058, Initial Validation Loss: 0.1354, Validation Loss: 0.0212,V Acc: 0.8909, Top 70th Acc: 0.9870, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 21  Rolling back to Epoch (base 0): 16  Top Validation Acc: 0.987012987012987
Fold [4/5] Epoch [0/100] Initial Loss: 0.1399, Training Loss: 0.1399, Initial Validation Loss: 0.1320, Validation Loss: 0.1320,V Acc: 0.2936, Top 70th Acc: 0.3896, Bottom 30th Acc: 0.0625
Fold [4/5] Epoch [10/100] Initial Loss: 0.1399, Training Loss: 0.0290, Initial Validation Loss: 0.1320, Validation Loss: 0.0476,V Acc: 0.7523, Top 70th Acc: 0.8831, Bottom 30th Acc: 0.4375
Fold [4/5] Epoch [20/100] Initial Loss: 0.1399, Training Loss: 0.0051, Initial Validation Loss: 0.1320, Validation Loss: 0.0311,V Acc: 0.8165, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.5000
Fold [4/5] Epoch [30/100] Initial Loss: 0.1399, Training Loss: 0.0037, Initial Validation Loss: 0.1320, Validation Loss: 0.0301,V Acc: 0.8349, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.5625
Fold [4/5] Epoch [40/100] Initial Loss: 0.1399, Training Loss: 0.0033, Initial Validation Loss: 0.1320, Validation Loss: 0.0299,V Acc: 0.8349, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.5625
Stopping early at Epoch (base 0): 47  Rolling back to Epoch (base 0): 42  Top Validation Acc: 0.948051948051948
Fold [5/5] Epoch [0/100] Initial Loss: 0.1404, Training Loss: 0.1404, Initial Validation Loss: 0.1303, Validation Loss: 0.1303,V Acc: 0.3611, Top 70th Acc: 0.4605, Bottom 30th Acc: 0.1250
Fold [5/5] Epoch [10/100] Initial Loss: 0.1404, Training Loss: 0.0176, Initial Validation Loss: 0.1303, Validation Loss: 0.0396,V Acc: 0.7685, Top 70th Acc: 0.9079, Bottom 30th Acc: 0.4375
Fold [5/5] Epoch [20/100] Initial Loss: 0.1404, Training Loss: 0.0052, Initial Validation Loss: 0.1303, Validation Loss: 0.0351,V Acc: 0.7778, Top 70th Acc: 0.9211, Bottom 30th Acc: 0.4375
Fold [5/5] Epoch [30/100] Initial Loss: 0.1404, Training Loss: 0.0040, Initial Validation Loss: 0.1303, Validation Loss: 0.0333,V Acc: 0.8056, Top 70th Acc: 0.9079, Bottom 30th Acc: 0.5625
Stopping early at Epoch (base 0): 35  Rolling back to Epoch (base 0): 30  Top Validation Acc: 0.9342105263157895
Running train_nn.py with seed 87
CUDA:False
Training samples count:  550
Training on 162 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1399, Training Loss: 0.1399, Initial Validation Loss: 0.1380, Validation Loss: 0.1380,V Acc: 0.2232, Top 70th Acc: 0.3038, Bottom 30th Acc: 0.0303
Fold [1/5] Epoch [10/100] Initial Loss: 0.1399, Training Loss: 0.0249, Initial Validation Loss: 0.1380, Validation Loss: 0.0480,V Acc: 0.8036, Top 70th Acc: 0.8608, Bottom 30th Acc: 0.6667
Fold [1/5] Epoch [20/100] Initial Loss: 0.1399, Training Loss: 0.0052, Initial Validation Loss: 0.1380, Validation Loss: 0.0376,V Acc: 0.8482, Top 70th Acc: 0.9114, Bottom 30th Acc: 0.6970
Fold [1/5] Epoch [30/100] Initial Loss: 0.1399, Training Loss: 0.0039, Initial Validation Loss: 0.1380, Validation Loss: 0.0363,V Acc: 0.8571, Top 70th Acc: 0.9494, Bottom 30th Acc: 0.6364
Fold [1/5] Epoch [40/100] Initial Loss: 0.1399, Training Loss: 0.0036, Initial Validation Loss: 0.1380, Validation Loss: 0.0364,V Acc: 0.8482, Top 70th Acc: 0.9367, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 44  Rolling back to Epoch (base 0): 39  Top Validation Acc: 0.9367088607594937
Fold [2/5] Epoch [0/100] Initial Loss: 0.1393, Training Loss: 0.1393, Initial Validation Loss: 0.1346, Validation Loss: 0.1346,V Acc: 0.2523, Top 70th Acc: 0.3333, Bottom 30th Acc: 0.0606
Fold [2/5] Epoch [10/100] Initial Loss: 0.1393, Training Loss: 0.0162, Initial Validation Loss: 0.1346, Validation Loss: 0.0292,V Acc: 0.8739, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 19  Rolling back to Epoch (base 0): 14  Top Validation Acc: 0.9743589743589743
87 1 [array([0.24652594, 0.04411642, 0.03093882, 0.20835687, 0.470062  ],
      dtype=float32)]
Fold [3/5] Epoch [0/100] Initial Loss: 0.1392, Training Loss: 0.1392, Initial Validation Loss: 0.1339, Validation Loss: 0.1339,V Acc: 0.2545, Top 70th Acc: 0.3506, Bottom 30th Acc: 0.0303
Fold [3/5] Epoch [10/100] Initial Loss: 0.1392, Training Loss: 0.0239, Initial Validation Loss: 0.1339, Validation Loss: 0.0403,V Acc: 0.8000, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.5455
Fold [3/5] Epoch [20/100] Initial Loss: 0.1392, Training Loss: 0.0052, Initial Validation Loss: 0.1339, Validation Loss: 0.0318,V Acc: 0.8273, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.5758
Fold [3/5] Epoch [30/100] Initial Loss: 0.1392, Training Loss: 0.0041, Initial Validation Loss: 0.1339, Validation Loss: 0.0313,V Acc: 0.8364, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 30  Rolling back to Epoch (base 0): 25  Top Validation Acc: 0.948051948051948
Fold [4/5] Epoch [0/100] Initial Loss: 0.1390, Training Loss: 0.1390, Initial Validation Loss: 0.1342, Validation Loss: 0.1342,V Acc: 0.2477, Top 70th Acc: 0.3377, Bottom 30th Acc: 0.0312
Fold [4/5] Epoch [10/100] Initial Loss: 0.1390, Training Loss: 0.0203, Initial Validation Loss: 0.1342, Validation Loss: 0.0301,V Acc: 0.8991, Top 70th Acc: 0.9870, Bottom 30th Acc: 0.6875
Fold [4/5] Epoch [20/100] Initial Loss: 0.1390, Training Loss: 0.0059, Initial Validation Loss: 0.1342, Validation Loss: 0.0233,V Acc: 0.8899, Top 70th Acc: 0.9870, Bottom 30th Acc: 0.6562
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.987012987012987
Fold [5/5] Epoch [0/100] Initial Loss: 0.1383, Training Loss: 0.1383, Initial Validation Loss: 0.1283, Validation Loss: 0.1283,V Acc: 0.2500, Top 70th Acc: 0.3289, Bottom 30th Acc: 0.0625
Fold [5/5] Epoch [10/100] Initial Loss: 0.1383, Training Loss: 0.0143, Initial Validation Loss: 0.1283, Validation Loss: 0.0317,V Acc: 0.8426, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.5625
Fold [5/5] Epoch [20/100] Initial Loss: 0.1383, Training Loss: 0.0050, Initial Validation Loss: 0.1283, Validation Loss: 0.0305,V Acc: 0.8426, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.5938
Stopping early at Epoch (base 0): 20  Rolling back to Epoch (base 0): 15  Top Validation Acc: 0.9473684210526315
Running train_nn.py with seed 88
CUDA:False
Training samples count:  550
Training on 162 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1381, Training Loss: 0.1381, Initial Validation Loss: 0.1384, Validation Loss: 0.1384,V Acc: 0.2500, Top 70th Acc: 0.3418, Bottom 30th Acc: 0.0303
Fold [1/5] Epoch [10/100] Initial Loss: 0.1381, Training Loss: 0.0170, Initial Validation Loss: 0.1384, Validation Loss: 0.0293,V Acc: 0.9018, Top 70th Acc: 0.9873, Bottom 30th Acc: 0.6970
Fold [1/5] Epoch [20/100] Initial Loss: 0.1381, Training Loss: 0.0061, Initial Validation Loss: 0.1384, Validation Loss: 0.0281,V Acc: 0.8661, Top 70th Acc: 0.9747, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 22  Rolling back to Epoch (base 0): 17  Top Validation Acc: 0.9746835443037974
Fold [2/5] Epoch [0/100] Initial Loss: 0.1396, Training Loss: 0.1396, Initial Validation Loss: 0.1328, Validation Loss: 0.1328,V Acc: 0.2703, Top 70th Acc: 0.3333, Bottom 30th Acc: 0.1212
Fold [2/5] Epoch [10/100] Initial Loss: 0.1396, Training Loss: 0.0160, Initial Validation Loss: 0.1328, Validation Loss: 0.0288,V Acc: 0.8739, Top 70th Acc: 1.0000, Bottom 30th Acc: 0.5758
Fold [2/5] Epoch [20/100] Initial Loss: 0.1396, Training Loss: 0.0076, Initial Validation Loss: 0.1328, Validation Loss: 0.0249,V Acc: 0.8829, Top 70th Acc: 0.9872, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.9871794871794872
Fold [3/5] Epoch [0/100] Initial Loss: 0.1387, Training Loss: 0.1387, Initial Validation Loss: 0.1325, Validation Loss: 0.1325,V Acc: 0.3364, Top 70th Acc: 0.3896, Bottom 30th Acc: 0.2121
Fold [3/5] Epoch [10/100] Initial Loss: 0.1387, Training Loss: 0.0240, Initial Validation Loss: 0.1325, Validation Loss: 0.0513,V Acc: 0.7636, Top 70th Acc: 0.8571, Bottom 30th Acc: 0.5455
Fold [3/5] Epoch [20/100] Initial Loss: 0.1387, Training Loss: 0.0054, Initial Validation Loss: 0.1325, Validation Loss: 0.0398,V Acc: 0.8273, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.8961038961038961
88 2 [array([0.12224536, 0.03246472, 0.03067657, 0.25346944, 0.561144  ],
      dtype=float32)]
Fold [4/5] Epoch [0/100] Initial Loss: 0.1416, Training Loss: 0.1416, Initial Validation Loss: 0.1248, Validation Loss: 0.1248,V Acc: 0.4037, Top 70th Acc: 0.5455, Bottom 30th Acc: 0.0625
Fold [4/5] Epoch [10/100] Initial Loss: 0.1416, Training Loss: 0.0151, Initial Validation Loss: 0.1248, Validation Loss: 0.0425,V Acc: 0.7798, Top 70th Acc: 0.8831, Bottom 30th Acc: 0.5312
Fold [4/5] Epoch [20/100] Initial Loss: 0.1416, Training Loss: 0.0052, Initial Validation Loss: 0.1248, Validation Loss: 0.0426,V Acc: 0.7982, Top 70th Acc: 0.8701, Bottom 30th Acc: 0.6250
Stopping early at Epoch (base 0): 20  Rolling back to Epoch (base 0): 15  Top Validation Acc: 0.8701298701298701
Fold [5/5] Epoch [0/100] Initial Loss: 0.1390, Training Loss: 0.1390, Initial Validation Loss: 0.1346, Validation Loss: 0.1346,V Acc: 0.4259, Top 70th Acc: 0.4868, Bottom 30th Acc: 0.2812
Fold [5/5] Epoch [10/100] Initial Loss: 0.1390, Training Loss: 0.0116, Initial Validation Loss: 0.1346, Validation Loss: 0.0300,V Acc: 0.8796, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.6875
Fold [5/5] Epoch [20/100] Initial Loss: 0.1390, Training Loss: 0.0047, Initial Validation Loss: 0.1346, Validation Loss: 0.0250,V Acc: 0.8704, Top 70th Acc: 0.9737, Bottom 30th Acc: 0.6250
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.9605263157894737
Running train_nn.py with seed 89
CUDA:False
Training samples count:  550
Training on 162 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1426, Training Loss: 0.1426, Initial Validation Loss: 0.1358, Validation Loss: 0.1358,V Acc: 0.3036, Top 70th Acc: 0.3544, Bottom 30th Acc: 0.1818
Fold [1/5] Epoch [10/100] Initial Loss: 0.1426, Training Loss: 0.0313, Initial Validation Loss: 0.1358, Validation Loss: 0.0508,V Acc: 0.7589, Top 70th Acc: 0.8861, Bottom 30th Acc: 0.4545
Fold [1/5] Epoch [20/100] Initial Loss: 0.1426, Training Loss: 0.0077, Initial Validation Loss: 0.1358, Validation Loss: 0.0419,V Acc: 0.7946, Top 70th Acc: 0.9241, Bottom 30th Acc: 0.4848
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.9240506329113924
Fold [2/5] Epoch [0/100] Initial Loss: 0.1405, Training Loss: 0.1405, Initial Validation Loss: 0.1300, Validation Loss: 0.1300,V Acc: 0.3243, Top 70th Acc: 0.3846, Bottom 30th Acc: 0.1818
Fold [2/5] Epoch [10/100] Initial Loss: 0.1405, Training Loss: 0.0134, Initial Validation Loss: 0.1300, Validation Loss: 0.0340,V Acc: 0.8108, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.5758
Fold [2/5] Epoch [20/100] Initial Loss: 0.1405, Training Loss: 0.0047, Initial Validation Loss: 0.1300, Validation Loss: 0.0311,V Acc: 0.8288, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.9358974358974359
Fold [3/5] Epoch [0/100] Initial Loss: 0.1391, Training Loss: 0.1391, Initial Validation Loss: 0.1385, Validation Loss: 0.1385,V Acc: 0.2818, Top 70th Acc: 0.2987, Bottom 30th Acc: 0.2424
Fold [3/5] Epoch [10/100] Initial Loss: 0.1391, Training Loss: 0.0163, Initial Validation Loss: 0.1385, Validation Loss: 0.0298,V Acc: 0.9182, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.8182
Fold [3/5] Epoch [20/100] Initial Loss: 0.1391, Training Loss: 0.0055, Initial Validation Loss: 0.1385, Validation Loss: 0.0261,V Acc: 0.9000, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.7273
Fold [3/5] Epoch [30/100] Initial Loss: 0.1391, Training Loss: 0.0039, Initial Validation Loss: 0.1385, Validation Loss: 0.0258,V Acc: 0.8909, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 38  Rolling back to Epoch (base 0): 33  Top Validation Acc: 0.974025974025974
Fold [4/5] Epoch [0/100] Initial Loss: 0.1384, Training Loss: 0.1384, Initial Validation Loss: 0.1306, Validation Loss: 0.1306,V Acc: 0.3761, Top 70th Acc: 0.4416, Bottom 30th Acc: 0.2188
Fold [4/5] Epoch [10/100] Initial Loss: 0.1384, Training Loss: 0.0189, Initial Validation Loss: 0.1306, Validation Loss: 0.0376,V Acc: 0.7890, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.5000
Fold [4/5] Epoch [20/100] Initial Loss: 0.1384, Training Loss: 0.0050, Initial Validation Loss: 0.1306, Validation Loss: 0.0317,V Acc: 0.7982, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.4688
Stopping early at Epoch (base 0): 22  Rolling back to Epoch (base 0): 17  Top Validation Acc: 0.935064935064935
89 3 [array([0.22730069, 0.07258   , 0.12693182, 0.27580455, 0.29738286],
      dtype=float32)]
Fold [5/5] Epoch [0/100] Initial Loss: 0.1391, Training Loss: 0.1391, Initial Validation Loss: 0.1341, Validation Loss: 0.1341,V Acc: 0.2778, Top 70th Acc: 0.3684, Bottom 30th Acc: 0.0625
Fold [5/5] Epoch [10/100] Initial Loss: 0.1391, Training Loss: 0.0221, Initial Validation Loss: 0.1341, Validation Loss: 0.0363,V Acc: 0.8333, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.5625
Fold [5/5] Epoch [20/100] Initial Loss: 0.1391, Training Loss: 0.0078, Initial Validation Loss: 0.1341, Validation Loss: 0.0255,V Acc: 0.8704, Top 70th Acc: 0.9868, Bottom 30th Acc: 0.5938
Fold [5/5] Epoch [30/100] Initial Loss: 0.1391, Training Loss: 0.0058, Initial Validation Loss: 0.1341, Validation Loss: 0.0234,V Acc: 0.8796, Top 70th Acc: 0.9868, Bottom 30th Acc: 0.6250
Fold [5/5] Epoch [40/100] Initial Loss: 0.1391, Training Loss: 0.0050, Initial Validation Loss: 0.1341, Validation Loss: 0.0230,V Acc: 0.8981, Top 70th Acc: 0.9868, Bottom 30th Acc: 0.6875
Stopping early at Epoch (base 0): 43  Rolling back to Epoch (base 0): 38  Top Validation Acc: 0.9868421052631579
Running train_nn.py with seed 90
CUDA:False
Training samples count:  550
Training on 162 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1402, Training Loss: 0.1402, Initial Validation Loss: 0.1350, Validation Loss: 0.1350,V Acc: 0.2857, Top 70th Acc: 0.3291, Bottom 30th Acc: 0.1818
Fold [1/5] Epoch [10/100] Initial Loss: 0.1402, Training Loss: 0.0275, Initial Validation Loss: 0.1350, Validation Loss: 0.0532,V Acc: 0.7321, Top 70th Acc: 0.8481, Bottom 30th Acc: 0.4545
Fold [1/5] Epoch [20/100] Initial Loss: 0.1402, Training Loss: 0.0057, Initial Validation Loss: 0.1350, Validation Loss: 0.0432,V Acc: 0.7946, Top 70th Acc: 0.8861, Bottom 30th Acc: 0.5758
Fold [1/5] Epoch [30/100] Initial Loss: 0.1402, Training Loss: 0.0038, Initial Validation Loss: 0.1350, Validation Loss: 0.0428,V Acc: 0.7768, Top 70th Acc: 0.8734, Bottom 30th Acc: 0.5455
Fold [1/5] Epoch [40/100] Initial Loss: 0.1402, Training Loss: 0.0035, Initial Validation Loss: 0.1350, Validation Loss: 0.0417,V Acc: 0.7857, Top 70th Acc: 0.8861, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 40  Rolling back to Epoch (base 0): 35  Top Validation Acc: 0.8860759493670886
Fold [2/5] Epoch [0/100] Initial Loss: 0.1417, Training Loss: 0.1417, Initial Validation Loss: 0.1342, Validation Loss: 0.1342,V Acc: 0.2613, Top 70th Acc: 0.3205, Bottom 30th Acc: 0.1212
Fold [2/5] Epoch [10/100] Initial Loss: 0.1417, Training Loss: 0.0152, Initial Validation Loss: 0.1342, Validation Loss: 0.0384,V Acc: 0.8198, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.5455
Fold [2/5] Epoch [20/100] Initial Loss: 0.1417, Training Loss: 0.0042, Initial Validation Loss: 0.1342, Validation Loss: 0.0330,V Acc: 0.8108, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.4848
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.9487179487179487
90 1 [array([0.14523053, 0.03003669, 0.04931754, 0.23884185, 0.53657347],
      dtype=float32)]
Fold [3/5] Epoch [0/100] Initial Loss: 0.1404, Training Loss: 0.1404, Initial Validation Loss: 0.1327, Validation Loss: 0.1327,V Acc: 0.3000, Top 70th Acc: 0.3117, Bottom 30th Acc: 0.2727
Fold [3/5] Epoch [10/100] Initial Loss: 0.1404, Training Loss: 0.0264, Initial Validation Loss: 0.1327, Validation Loss: 0.0370,V Acc: 0.8364, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.6364
Fold [3/5] Epoch [20/100] Initial Loss: 0.1404, Training Loss: 0.0057, Initial Validation Loss: 0.1327, Validation Loss: 0.0280,V Acc: 0.8545, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.5758
Fold [3/5] Epoch [30/100] Initial Loss: 0.1404, Training Loss: 0.0042, Initial Validation Loss: 0.1327, Validation Loss: 0.0249,V Acc: 0.8909, Top 70th Acc: 0.9870, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 33  Rolling back to Epoch (base 0): 28  Top Validation Acc: 0.974025974025974
Fold [4/5] Epoch [0/100] Initial Loss: 0.1389, Training Loss: 0.1389, Initial Validation Loss: 0.1374, Validation Loss: 0.1374,V Acc: 0.2477, Top 70th Acc: 0.2987, Bottom 30th Acc: 0.1250
Fold [4/5] Epoch [10/100] Initial Loss: 0.1389, Training Loss: 0.0279, Initial Validation Loss: 0.1374, Validation Loss: 0.0379,V Acc: 0.8532, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6250
Fold [4/5] Epoch [20/100] Initial Loss: 0.1389, Training Loss: 0.0066, Initial Validation Loss: 0.1374, Validation Loss: 0.0268,V Acc: 0.8807, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.6562
Fold [4/5] Epoch [30/100] Initial Loss: 0.1389, Training Loss: 0.0045, Initial Validation Loss: 0.1374, Validation Loss: 0.0257,V Acc: 0.8716, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.6250
Fold [4/5] Epoch [40/100] Initial Loss: 0.1389, Training Loss: 0.0040, Initial Validation Loss: 0.1374, Validation Loss: 0.0254,V Acc: 0.8899, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.6875
Fold [4/5] Epoch [50/100] Initial Loss: 0.1389, Training Loss: 0.0039, Initial Validation Loss: 0.1374, Validation Loss: 0.0243,V Acc: 0.8899, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.6875
Fold [4/5] Epoch [60/100] Initial Loss: 0.1389, Training Loss: 0.0037, Initial Validation Loss: 0.1374, Validation Loss: 0.0244,V Acc: 0.8899, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.7188
Stopping early at Epoch (base 0): 64  Rolling back to Epoch (base 0): 59  Top Validation Acc: 0.974025974025974
Fold [5/5] Epoch [0/100] Initial Loss: 0.1394, Training Loss: 0.1394, Initial Validation Loss: 0.1344, Validation Loss: 0.1344,V Acc: 0.2500, Top 70th Acc: 0.3158, Bottom 30th Acc: 0.0938
Fold [5/5] Epoch [10/100] Initial Loss: 0.1394, Training Loss: 0.0183, Initial Validation Loss: 0.1344, Validation Loss: 0.0375,V Acc: 0.8519, Top 70th Acc: 0.9211, Bottom 30th Acc: 0.6875
Fold [5/5] Epoch [20/100] Initial Loss: 0.1394, Training Loss: 0.0066, Initial Validation Loss: 0.1344, Validation Loss: 0.0331,V Acc: 0.8519, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.6562
Fold [5/5] Epoch [30/100] Initial Loss: 0.1394, Training Loss: 0.0048, Initial Validation Loss: 0.1344, Validation Loss: 0.0315,V Acc: 0.8611, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.6875
Fold [5/5] Epoch [40/100] Initial Loss: 0.1394, Training Loss: 0.0041, Initial Validation Loss: 0.1344, Validation Loss: 0.0303,V Acc: 0.8704, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.7188
Fold [5/5] Epoch [50/100] Initial Loss: 0.1394, Training Loss: 0.0038, Initial Validation Loss: 0.1344, Validation Loss: 0.0294,V Acc: 0.8519, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.6562
Stopping early at Epoch (base 0): 52  Rolling back to Epoch (base 0): 47  Top Validation Acc: 0.9342105263157895
Running train_nn.py with seed 91
CUDA:False
Training samples count:  550
Training on 162 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1419, Training Loss: 0.1419, Initial Validation Loss: 0.1342, Validation Loss: 0.1342,V Acc: 0.2500, Top 70th Acc: 0.3418, Bottom 30th Acc: 0.0303
Fold [1/5] Epoch [10/100] Initial Loss: 0.1419, Training Loss: 0.0128, Initial Validation Loss: 0.1342, Validation Loss: 0.0314,V Acc: 0.8214, Top 70th Acc: 0.9620, Bottom 30th Acc: 0.4848
Fold [1/5] Epoch [20/100] Initial Loss: 0.1419, Training Loss: 0.0047, Initial Validation Loss: 0.1342, Validation Loss: 0.0288,V Acc: 0.8214, Top 70th Acc: 0.9747, Bottom 30th Acc: 0.4545
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.9746835443037974
91 0 [array([0.15063836, 0.07836398, 0.08470638, 0.21596168, 0.47032955],
      dtype=float32)]
Fold [2/5] Epoch [0/100] Initial Loss: 0.1423, Training Loss: 0.1423, Initial Validation Loss: 0.1277, Validation Loss: 0.1277,V Acc: 0.3784, Top 70th Acc: 0.4359, Bottom 30th Acc: 0.2424
Fold [2/5] Epoch [10/100] Initial Loss: 0.1423, Training Loss: 0.0136, Initial Validation Loss: 0.1277, Validation Loss: 0.0374,V Acc: 0.8198, Top 70th Acc: 0.8974, Bottom 30th Acc: 0.6364
Fold [2/5] Epoch [20/100] Initial Loss: 0.1423, Training Loss: 0.0045, Initial Validation Loss: 0.1277, Validation Loss: 0.0364,V Acc: 0.8108, Top 70th Acc: 0.8846, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.8846153846153846
Fold [3/5] Epoch [0/100] Initial Loss: 0.1386, Training Loss: 0.1386, Initial Validation Loss: 0.1341, Validation Loss: 0.1341,V Acc: 0.4000, Top 70th Acc: 0.4545, Bottom 30th Acc: 0.2727
Fold [3/5] Epoch [10/100] Initial Loss: 0.1386, Training Loss: 0.0374, Initial Validation Loss: 0.1341, Validation Loss: 0.0539,V Acc: 0.7000, Top 70th Acc: 0.8831, Bottom 30th Acc: 0.2727
Fold [3/5] Epoch [20/100] Initial Loss: 0.1386, Training Loss: 0.0079, Initial Validation Loss: 0.1341, Validation Loss: 0.0381,V Acc: 0.8273, Top 70th Acc: 0.8961, Bottom 30th Acc: 0.6667
Fold [3/5] Epoch [30/100] Initial Loss: 0.1386, Training Loss: 0.0046, Initial Validation Loss: 0.1341, Validation Loss: 0.0357,V Acc: 0.8273, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.5758
Fold [3/5] Epoch [40/100] Initial Loss: 0.1386, Training Loss: 0.0039, Initial Validation Loss: 0.1341, Validation Loss: 0.0346,V Acc: 0.8182, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.5758
Fold [3/5] Epoch [50/100] Initial Loss: 0.1386, Training Loss: 0.0036, Initial Validation Loss: 0.1341, Validation Loss: 0.0334,V Acc: 0.8182, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.5455
Fold [3/5] Epoch [60/100] Initial Loss: 0.1386, Training Loss: 0.0034, Initial Validation Loss: 0.1341, Validation Loss: 0.0327,V Acc: 0.8273, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.5758
Fold [3/5] Epoch [70/100] Initial Loss: 0.1386, Training Loss: 0.0034, Initial Validation Loss: 0.1341, Validation Loss: 0.0319,V Acc: 0.8273, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 75  Rolling back to Epoch (base 0): 70  Top Validation Acc: 0.935064935064935
Fold [4/5] Epoch [0/100] Initial Loss: 0.1396, Training Loss: 0.1396, Initial Validation Loss: 0.1378, Validation Loss: 0.1378,V Acc: 0.2477, Top 70th Acc: 0.2468, Bottom 30th Acc: 0.2500
Fold [4/5] Epoch [10/100] Initial Loss: 0.1396, Training Loss: 0.0225, Initial Validation Loss: 0.1378, Validation Loss: 0.0342,V Acc: 0.8807, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.7188
Fold [4/5] Epoch [20/100] Initial Loss: 0.1396, Training Loss: 0.0054, Initial Validation Loss: 0.1378, Validation Loss: 0.0249,V Acc: 0.9083, Top 70th Acc: 0.9870, Bottom 30th Acc: 0.7188
Fold [4/5] Epoch [30/100] Initial Loss: 0.1396, Training Loss: 0.0042, Initial Validation Loss: 0.1378, Validation Loss: 0.0236,V Acc: 0.9083, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.7500
Fold [4/5] Epoch [40/100] Initial Loss: 0.1396, Training Loss: 0.0038, Initial Validation Loss: 0.1378, Validation Loss: 0.0226,V Acc: 0.8991, Top 70th Acc: 1.0000, Bottom 30th Acc: 0.6562
Stopping early at Epoch (base 0): 42  Rolling back to Epoch (base 0): 37  Top Validation Acc: 0.987012987012987
Fold [5/5] Epoch [0/100] Initial Loss: 0.1398, Training Loss: 0.1398, Initial Validation Loss: 0.1315, Validation Loss: 0.1315,V Acc: 0.3056, Top 70th Acc: 0.3421, Bottom 30th Acc: 0.2188
Fold [5/5] Epoch [10/100] Initial Loss: 0.1398, Training Loss: 0.0182, Initial Validation Loss: 0.1315, Validation Loss: 0.0384,V Acc: 0.8056, Top 70th Acc: 0.9211, Bottom 30th Acc: 0.5312
Fold [5/5] Epoch [20/100] Initial Loss: 0.1398, Training Loss: 0.0063, Initial Validation Loss: 0.1315, Validation Loss: 0.0351,V Acc: 0.8056, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.5000
Fold [5/5] Epoch [30/100] Initial Loss: 0.1398, Training Loss: 0.0047, Initial Validation Loss: 0.1315, Validation Loss: 0.0342,V Acc: 0.8241, Top 70th Acc: 0.9211, Bottom 30th Acc: 0.5938
Stopping early at Epoch (base 0): 31  Rolling back to Epoch (base 0): 26  Top Validation Acc: 0.9342105263157895
Running train_nn.py with seed 92
CUDA:False
Training samples count:  550
Training on 162 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1392, Training Loss: 0.1392, Initial Validation Loss: 0.1375, Validation Loss: 0.1375,V Acc: 0.2500, Top 70th Acc: 0.3165, Bottom 30th Acc: 0.0909
Fold [1/5] Epoch [10/100] Initial Loss: 0.1392, Training Loss: 0.0227, Initial Validation Loss: 0.1375, Validation Loss: 0.0397,V Acc: 0.8125, Top 70th Acc: 0.9494, Bottom 30th Acc: 0.4848
Fold [1/5] Epoch [20/100] Initial Loss: 0.1392, Training Loss: 0.0056, Initial Validation Loss: 0.1375, Validation Loss: 0.0307,V Acc: 0.8482, Top 70th Acc: 0.9620, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.9620253164556962
Fold [2/5] Epoch [0/100] Initial Loss: 0.1435, Training Loss: 0.1435, Initial Validation Loss: 0.1332, Validation Loss: 0.1332,V Acc: 0.2613, Top 70th Acc: 0.2821, Bottom 30th Acc: 0.2121
Fold [2/5] Epoch [10/100] Initial Loss: 0.1435, Training Loss: 0.0204, Initial Validation Loss: 0.1332, Validation Loss: 0.0382,V Acc: 0.8288, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.5758
Fold [2/5] Epoch [20/100] Initial Loss: 0.1435, Training Loss: 0.0051, Initial Validation Loss: 0.1332, Validation Loss: 0.0288,V Acc: 0.8468, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.6061
Fold [2/5] Epoch [30/100] Initial Loss: 0.1435, Training Loss: 0.0040, Initial Validation Loss: 0.1332, Validation Loss: 0.0285,V Acc: 0.8378, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 37  Rolling back to Epoch (base 0): 32  Top Validation Acc: 0.9615384615384616
Fold [3/5] Epoch [0/100] Initial Loss: 0.1393, Training Loss: 0.1393, Initial Validation Loss: 0.1331, Validation Loss: 0.1331,V Acc: 0.3636, Top 70th Acc: 0.4416, Bottom 30th Acc: 0.1818
Fold [3/5] Epoch [10/100] Initial Loss: 0.1393, Training Loss: 0.0232, Initial Validation Loss: 0.1331, Validation Loss: 0.0374,V Acc: 0.8091, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.4848
Fold [3/5] Epoch [20/100] Initial Loss: 0.1393, Training Loss: 0.0066, Initial Validation Loss: 0.1331, Validation Loss: 0.0330,V Acc: 0.8364, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.5152
Fold [3/5] Epoch [30/100] Initial Loss: 0.1393, Training Loss: 0.0046, Initial Validation Loss: 0.1331, Validation Loss: 0.0324,V Acc: 0.8273, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.4848/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)

Fold [3/5] Epoch [40/100] Initial Loss: 0.1393, Training Loss: 0.0041, Initial Validation Loss: 0.1331, Validation Loss: 0.0312,V Acc: 0.8364, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.5152
Stopping early at Epoch (base 0): 47  Rolling back to Epoch (base 0): 42  Top Validation Acc: 0.974025974025974
Fold [4/5] Epoch [0/100] Initial Loss: 0.1384, Training Loss: 0.1384, Initial Validation Loss: 0.1354, Validation Loss: 0.1354,V Acc: 0.2477, Top 70th Acc: 0.3117, Bottom 30th Acc: 0.0938
Fold [4/5] Epoch [10/100] Initial Loss: 0.1384, Training Loss: 0.0217, Initial Validation Loss: 0.1354, Validation Loss: 0.0424,V Acc: 0.8257, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.6250
Fold [4/5] Epoch [20/100] Initial Loss: 0.1384, Training Loss: 0.0059, Initial Validation Loss: 0.1354, Validation Loss: 0.0341,V Acc: 0.8807, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.7500
Fold [4/5] Epoch [30/100] Initial Loss: 0.1384, Training Loss: 0.0044, Initial Validation Loss: 0.1354, Validation Loss: 0.0331,V Acc: 0.8716, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.7188
Stopping early at Epoch (base 0): 34  Rolling back to Epoch (base 0): 29  Top Validation Acc: 0.935064935064935
Fold [5/5] Epoch [0/100] Initial Loss: 0.1387, Training Loss: 0.1387, Initial Validation Loss: 0.1302, Validation Loss: 0.1302,V Acc: 0.2593, Top 70th Acc: 0.3289, Bottom 30th Acc: 0.0938
Fold [5/5] Epoch [10/100] Initial Loss: 0.1387, Training Loss: 0.0183, Initial Validation Loss: 0.1302, Validation Loss: 0.0314,V Acc: 0.8148, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.5000
Fold [5/5] Epoch [20/100] Initial Loss: 0.1387, Training Loss: 0.0052, Initial Validation Loss: 0.1302, Validation Loss: 0.0285,V Acc: 0.8241, Top 70th Acc: 0.9737, Bottom 30th Acc: 0.4688
Fold [5/5] Epoch [30/100] Initial Loss: 0.1387, Training Loss: 0.0039, Initial Validation Loss: 0.1302, Validation Loss: 0.0287,V Acc: 0.8056, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.4688
Stopping early at Epoch (base 0): 33  Rolling back to Epoch (base 0): 28  Top Validation Acc: 0.9605263157894737
92 4 [array([0.27134457, 0.08332389, 0.04909247, 0.19338104, 0.402858  ],
      dtype=float32)]
Running train_nn.py with seed 93
CUDA:False
Training samples count:  550
Training on 162 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1400, Training Loss: 0.1400, Initial Validation Loss: 0.1392, Validation Loss: 0.1392,V Acc: 0.2411, Top 70th Acc: 0.3291, Bottom 30th Acc: 0.0303
Fold [1/5] Epoch [10/100] Initial Loss: 0.1400, Training Loss: 0.0303, Initial Validation Loss: 0.1392, Validation Loss: 0.0381,V Acc: 0.8393, Top 70th Acc: 0.9494, Bottom 30th Acc: 0.5758
Fold [1/5] Epoch [20/100] Initial Loss: 0.1400, Training Loss: 0.0059, Initial Validation Loss: 0.1392, Validation Loss: 0.0245,V Acc: 0.8839, Top 70th Acc: 0.9620, Bottom 30th Acc: 0.6970
Fold [1/5] Epoch [30/100] Initial Loss: 0.1400, Training Loss: 0.0042, Initial Validation Loss: 0.1392, Validation Loss: 0.0230,V Acc: 0.8839, Top 70th Acc: 0.9494, Bottom 30th Acc: 0.7273
Stopping early at Epoch (base 0): 37  Rolling back to Epoch (base 0): 32  Top Validation Acc: 0.9493670886075949
Fold [2/5] Epoch [0/100] Initial Loss: 0.1402, Training Loss: 0.1402, Initial Validation Loss: 0.1339, Validation Loss: 0.1339,V Acc: 0.2883, Top 70th Acc: 0.3462, Bottom 30th Acc: 0.1515
Fold [2/5] Epoch [10/100] Initial Loss: 0.1402, Training Loss: 0.0139, Initial Validation Loss: 0.1339, Validation Loss: 0.0326,V Acc: 0.8468, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.5758
Fold [2/5] Epoch [20/100] Initial Loss: 0.1402, Training Loss: 0.0044, Initial Validation Loss: 0.1339, Validation Loss: 0.0292,V Acc: 0.8559, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 28  Rolling back to Epoch (base 0): 23  Top Validation Acc: 0.9487179487179487
Fold [3/5] Epoch [0/100] Initial Loss: 0.1425, Training Loss: 0.1425, Initial Validation Loss: 0.1355, Validation Loss: 0.1355,V Acc: 0.3455, Top 70th Acc: 0.3766, Bottom 30th Acc: 0.2727
Fold [3/5] Epoch [10/100] Initial Loss: 0.1425, Training Loss: 0.0259, Initial Validation Loss: 0.1355, Validation Loss: 0.0388,V Acc: 0.8000, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.5455
Fold [3/5] Epoch [20/100] Initial Loss: 0.1425, Training Loss: 0.0054, Initial Validation Loss: 0.1355, Validation Loss: 0.0269,V Acc: 0.8545, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.6061
Fold [3/5] Epoch [30/100] Initial Loss: 0.1425, Training Loss: 0.0040, Initial Validation Loss: 0.1355, Validation Loss: 0.0262,V Acc: 0.8818, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.6970
Fold [3/5] Epoch [40/100] Initial Loss: 0.1425, Training Loss: 0.0037, Initial Validation Loss: 0.1355, Validation Loss: 0.0262,V Acc: 0.8727, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 44  Rolling back to Epoch (base 0): 39  Top Validation Acc: 0.961038961038961
93 2 [array([0.22206233, 0.03965987, 0.06565871, 0.36742595, 0.30519307],
      dtype=float32)]
Fold [4/5] Epoch [0/100] Initial Loss: 0.1395, Training Loss: 0.1395, Initial Validation Loss: 0.1313, Validation Loss: 0.1313,V Acc: 0.2477, Top 70th Acc: 0.3377, Bottom 30th Acc: 0.0312
Fold [4/5] Epoch [10/100] Initial Loss: 0.1395, Training Loss: 0.0217, Initial Validation Loss: 0.1313, Validation Loss: 0.0370,V Acc: 0.8257, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.6250
Fold [4/5] Epoch [20/100] Initial Loss: 0.1395, Training Loss: 0.0064, Initial Validation Loss: 0.1313, Validation Loss: 0.0341,V Acc: 0.8165, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.5625
Stopping early at Epoch (base 0): 29  Rolling back to Epoch (base 0): 24  Top Validation Acc: 0.935064935064935
Fold [5/5] Epoch [0/100] Initial Loss: 0.1395, Training Loss: 0.1395, Initial Validation Loss: 0.1321, Validation Loss: 0.1321,V Acc: 0.2500, Top 70th Acc: 0.3553, Bottom 30th Acc: 0.0000
Fold [5/5] Epoch [10/100] Initial Loss: 0.1395, Training Loss: 0.0149, Initial Validation Loss: 0.1321, Validation Loss: 0.0315,V Acc: 0.8611, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.6250
Fold [5/5] Epoch [20/100] Initial Loss: 0.1395, Training Loss: 0.0048, Initial Validation Loss: 0.1321, Validation Loss: 0.0274,V Acc: 0.8519, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.5938
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.9605263157894737
Running train_nn.py with seed 94
CUDA:False
Training samples count:  550
Training on 162 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1386, Training Loss: 0.1386, Initial Validation Loss: 0.1383, Validation Loss: 0.1383,V Acc: 0.2857, Top 70th Acc: 0.3291, Bottom 30th Acc: 0.1818
Fold [1/5] Epoch [10/100] Initial Loss: 0.1386, Training Loss: 0.0213, Initial Validation Loss: 0.1383, Validation Loss: 0.0365,V Acc: 0.8393, Top 70th Acc: 0.9494, Bottom 30th Acc: 0.5758
Fold [1/5] Epoch [20/100] Initial Loss: 0.1386, Training Loss: 0.0054, Initial Validation Loss: 0.1383, Validation Loss: 0.0258,V Acc: 0.8839, Top 70th Acc: 0.9747, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.9746835443037974
Fold [2/5] Epoch [0/100] Initial Loss: 0.1403, Training Loss: 0.1403, Initial Validation Loss: 0.1330, Validation Loss: 0.1330,V Acc: 0.3153, Top 70th Acc: 0.3590, Bottom 30th Acc: 0.2121
Fold [2/5] Epoch [10/100] Initial Loss: 0.1403, Training Loss: 0.0172, Initial Validation Loss: 0.1330, Validation Loss: 0.0329,V Acc: 0.8559, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.6061
Fold [2/5] Epoch [20/100] Initial Loss: 0.1403, Training Loss: 0.0050, Initial Validation Loss: 0.1330, Validation Loss: 0.0277,V Acc: 0.8559, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.5758
Fold [2/5] Epoch [30/100] Initial Loss: 0.1403, Training Loss: 0.0041, Initial Validation Loss: 0.1330, Validation Loss: 0.0272,V Acc: 0.8739, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 30  Rolling back to Epoch (base 0): 25  Top Validation Acc: 0.9743589743589743
Fold [3/5] Epoch [0/100] Initial Loss: 0.1395, Training Loss: 0.1395, Initial Validation Loss: 0.1354, Validation Loss: 0.1354,V Acc: 0.3364, Top 70th Acc: 0.4026, Bottom 30th Acc: 0.1818
Fold [3/5] Epoch [10/100] Initial Loss: 0.1395, Training Loss: 0.0129, Initial Validation Loss: 0.1354, Validation Loss: 0.0282,V Acc: 0.8909, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.6970
Fold [3/5] Epoch [20/100] Initial Loss: 0.1395, Training Loss: 0.0043, Initial Validation Loss: 0.1354, Validation Loss: 0.0239,V Acc: 0.8818, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.974025974025974
Fold [4/5] Epoch [0/100] Initial Loss: 0.1429, Training Loss: 0.1429, Initial Validation Loss: 0.1293, Validation Loss: 0.1293,V Acc: 0.3211, Top 70th Acc: 0.3896, Bottom 30th Acc: 0.1562
Fold [4/5] Epoch [10/100] Initial Loss: 0.1429, Training Loss: 0.0175, Initial Validation Loss: 0.1293, Validation Loss: 0.0358,V Acc: 0.8349, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.6562
Stopping early at Epoch (base 0): 18  Rolling back to Epoch (base 0): 13  Top Validation Acc: 0.8961038961038961
Fold [5/5] Epoch [0/100] Initial Loss: 0.1379, Training Loss: 0.1379, Initial Validation Loss: 0.1364, Validation Loss: 0.1364,V Acc: 0.2593, Top 70th Acc: 0.3421, Bottom 30th Acc: 0.0625
Fold [5/5] Epoch [10/100] Initial Loss: 0.1379, Training Loss: 0.0147, Initial Validation Loss: 0.1364, Validation Loss: 0.0315,V Acc: 0.8704, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.6562
Fold [5/5] Epoch [20/100] Initial Loss: 0.1379, Training Loss: 0.0052, Initial Validation Loss: 0.1364, Validation Loss: 0.0264,V Acc: 0.8889, Top 70th Acc: 0.9737, Bottom 30th Acc: 0.6875
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.9736842105263158
94 4 [array([0.26794884, 0.05785121, 0.09593042, 0.14959453, 0.42867494],
      dtype=float32)]
Running train_nn.py with seed 95
CUDA:False
Training samples count:  550
Training on 162 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1405, Training Loss: 0.1405, Initial Validation Loss: 0.1322, Validation Loss: 0.1322,V Acc: 0.2500, Top 70th Acc: 0.3418, Bottom 30th Acc: 0.0303
Fold [1/5] Epoch [10/100] Initial Loss: 0.1405, Training Loss: 0.0206, Initial Validation Loss: 0.1322, Validation Loss: 0.0495,V Acc: 0.7232, Top 70th Acc: 0.8354, Bottom 30th Acc: 0.4545
Fold [1/5] Epoch [20/100] Initial Loss: 0.1405, Training Loss: 0.0043, Initial Validation Loss: 0.1322, Validation Loss: 0.0386,V Acc: 0.7679, Top 70th Acc: 0.9114, Bottom 30th Acc: 0.4242
Stopping early at Epoch (base 0): 29  Rolling back to Epoch (base 0): 24  Top Validation Acc: 0.8987341772151899
Fold [2/5] Epoch [0/100] Initial Loss: 0.1381, Training Loss: 0.1381, Initial Validation Loss: 0.1372, Validation Loss: 0.1372,V Acc: 0.2523, Top 70th Acc: 0.3333, Bottom 30th Acc: 0.0606
Fold [2/5] Epoch [10/100] Initial Loss: 0.1381, Training Loss: 0.0194, Initial Validation Loss: 0.1372, Validation Loss: 0.0327,V Acc: 0.8378, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.5455
Fold [2/5] Epoch [20/100] Initial Loss: 0.1381, Training Loss: 0.0053, Initial Validation Loss: 0.1372, Validation Loss: 0.0287,V Acc: 0.8468, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.9743589743589743
Fold [3/5] Epoch [0/100] Initial Loss: 0.1392, Training Loss: 0.1392, Initial Validation Loss: 0.1389, Validation Loss: 0.1389,V Acc: 0.2727, Top 70th Acc: 0.2987, Bottom 30th Acc: 0.2121
Fold [3/5] Epoch [10/100] Initial Loss: 0.1392, Training Loss: 0.0169, Initial Validation Loss: 0.1389, Validation Loss: 0.0230,V Acc: 0.9000, Top 70th Acc: 1.0000, Bottom 30th Acc: 0.6667
Fold [3/5] Epoch [20/100] Initial Loss: 0.1392, Training Loss: 0.0056, Initial Validation Loss: 0.1389, Validation Loss: 0.0173,V Acc: 0.8909, Top 70th Acc: 1.0000, Bottom 30th Acc: 0.6364
Fold [3/5] Epoch [30/100] Initial Loss: 0.1392, Training Loss: 0.0045, Initial Validation Loss: 0.1389, Validation Loss: 0.0163,V Acc: 0.8909, Top 70th Acc: 1.0000, Bottom 30th Acc: 0.6364
Fold [3/5] Epoch [40/100] Initial Loss: 0.1392, Training Loss: 0.0041, Initial Validation Loss: 0.1389, Validation Loss: 0.0160,V Acc: 0.8909, Top 70th Acc: 1.0000, Bottom 30th Acc: 0.6364
Fold [3/5] Epoch [50/100] Initial Loss: 0.1392, Training Loss: 0.0040, Initial Validation Loss: 0.1389, Validation Loss: 0.0155,V Acc: 0.9000, Top 70th Acc: 1.0000, Bottom 30th Acc: 0.6667
Fold [3/5] Epoch [60/100] Initial Loss: 0.1392, Training Loss: 0.0039, Initial Validation Loss: 0.1389, Validation Loss: 0.0156,V Acc: 0.9000, Top 70th Acc: 1.0000, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 66  Rolling back to Epoch (base 0): 61  Top Validation Acc: 1.0
Fold [4/5] Epoch [0/100] Initial Loss: 0.1408, Training Loss: 0.1408, Initial Validation Loss: 0.1315, Validation Loss: 0.1315,V Acc: 0.2936, Top 70th Acc: 0.3506, Bottom 30th Acc: 0.1562
Fold [4/5] Epoch [10/100] Initial Loss: 0.1408, Training Loss: 0.0236, Initial Validation Loss: 0.1315, Validation Loss: 0.0339,V Acc: 0.8165, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.5625
Fold [4/5] Epoch [20/100] Initial Loss: 0.1408, Training Loss: 0.0052, Initial Validation Loss: 0.1315, Validation Loss: 0.0229,V Acc: 0.8440, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.5625
Fold [4/5] Epoch [30/100] Initial Loss: 0.1408, Training Loss: 0.0040, Initial Validation Loss: 0.1315, Validation Loss: 0.0223,V Acc: 0.8532, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.5938
Stopping early at Epoch (base 0): 39  Rolling back to Epoch (base 0): 34  Top Validation Acc: 0.961038961038961
Fold [5/5] Epoch [0/100] Initial Loss: 0.1450, Training Loss: 0.1450, Initial Validation Loss: 0.1320, Validation Loss: 0.1320,V Acc: 0.3333, Top 70th Acc: 0.3684, Bottom 30th Acc: 0.2500
Fold [5/5] Epoch [10/100] Initial Loss: 0.1450, Training Loss: 0.0185, Initial Validation Loss: 0.1320, Validation Loss: 0.0389,V Acc: 0.8426, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.6250
Fold [5/5] Epoch [20/100] Initial Loss: 0.1450, Training Loss: 0.0045, Initial Validation Loss: 0.1320, Validation Loss: 0.0324,V Acc: 0.8426, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.5625
Stopping early at Epoch (base 0): 20  Rolling back to Epoch (base 0): 15  Top Validation Acc: 0.9605263157894737
95 4 [array([0.40599695, 0.06673187, 0.0443567 , 0.18169725, 0.3012173 ],
      dtype=float32)]
Running train_nn.py with seed 96
CUDA:False
Training samples count:  550
Training on 162 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1406, Training Loss: 0.1406, Initial Validation Loss: 0.1392, Validation Loss: 0.1392,V Acc: 0.3661, Top 70th Acc: 0.4051, Bottom 30th Acc: 0.2727
Fold [1/5] Epoch [10/100] Initial Loss: 0.1406, Training Loss: 0.0192, Initial Validation Loss: 0.1392, Validation Loss: 0.0316,V Acc: 0.8839, Top 70th Acc: 0.9620, Bottom 30th Acc: 0.6970
Fold [1/5] Epoch [20/100] Initial Loss: 0.1406, Training Loss: 0.0059, Initial Validation Loss: 0.1392, Validation Loss: 0.0270,V Acc: 0.8839, Top 70th Acc: 0.9747, Bottom 30th Acc: 0.6667
Fold [1/5] Epoch [30/100] Initial Loss: 0.1406, Training Loss: 0.0042, Initial Validation Loss: 0.1392, Validation Loss: 0.0269,V Acc: 0.8839, Top 70th Acc: 0.9494, Bottom 30th Acc: 0.7273
Stopping early at Epoch (base 0): 33  Rolling back to Epoch (base 0): 28  Top Validation Acc: 0.9493670886075949
Fold [2/5] Epoch [0/100] Initial Loss: 0.1436, Training Loss: 0.1436, Initial Validation Loss: 0.1326, Validation Loss: 0.1326,V Acc: 0.2613, Top 70th Acc: 0.3462, Bottom 30th Acc: 0.0606
Fold [2/5] Epoch [10/100] Initial Loss: 0.1436, Training Loss: 0.0221, Initial Validation Loss: 0.1326, Validation Loss: 0.0430,V Acc: 0.7928, Top 70th Acc: 0.8590, Bottom 30th Acc: 0.6364
Fold [2/5] Epoch [20/100] Initial Loss: 0.1436, Training Loss: 0.0052, Initial Validation Loss: 0.1326, Validation Loss: 0.0372,V Acc: 0.8018, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.5455
Fold [2/5] Epoch [30/100] Initial Loss: 0.1436, Training Loss: 0.0041, Initial Validation Loss: 0.1326, Validation Loss: 0.0367,V Acc: 0.8018, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.4545
Stopping early at Epoch (base 0): 33  Rolling back to Epoch (base 0): 28  Top Validation Acc: 0.9358974358974359
Fold [3/5] Epoch [0/100] Initial Loss: 0.1406, Training Loss: 0.1406, Initial Validation Loss: 0.1338, Validation Loss: 0.1338,V Acc: 0.2545, Top 70th Acc: 0.3247, Bottom 30th Acc: 0.0909
Fold [3/5] Epoch [10/100] Initial Loss: 0.1406, Training Loss: 0.0181, Initial Validation Loss: 0.1338, Validation Loss: 0.0369,V Acc: 0.8182, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.5758
Fold [3/5] Epoch [20/100] Initial Loss: 0.1406, Training Loss: 0.0051, Initial Validation Loss: 0.1338, Validation Loss: 0.0281,V Acc: 0.8727, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.7273
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.948051948051948
Fold [4/5] Epoch [0/100] Initial Loss: 0.1395, Training Loss: 0.1395, Initial Validation Loss: 0.1319, Validation Loss: 0.1319,V Acc: 0.2661, Top 70th Acc: 0.3506, Bottom 30th Acc: 0.0625
Fold [4/5] Epoch [10/100] Initial Loss: 0.1395, Training Loss: 0.0216, Initial Validation Loss: 0.1319, Validation Loss: 0.0393,V Acc: 0.8073, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.4688
Fold [4/5] Epoch [20/100] Initial Loss: 0.1395, Training Loss: 0.0061, Initial Validation Loss: 0.1319, Validation Loss: 0.0349,V Acc: 0.8165, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.5000
Fold [4/5] Epoch [30/100] Initial Loss: 0.1395, Training Loss: 0.0045, Initial Validation Loss: 0.1319, Validation Loss: 0.0342,V Acc: 0.8165, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.5312
Stopping early at Epoch (base 0): 34  Rolling back to Epoch (base 0): 29  Top Validation Acc: 0.948051948051948
96 3 [array([0.38857687, 0.05790885, 0.03390751, 0.23514159, 0.28446528],
      dtype=float32)]
Fold [5/5] Epoch [0/100] Initial Loss: 0.1390, Training Loss: 0.1390, Initial Validation Loss: 0.1322, Validation Loss: 0.1322,V Acc: 0.2500, Top 70th Acc: 0.3026, Bottom 30th Acc: 0.1250
Fold [5/5] Epoch [10/100] Initial Loss: 0.1390, Training Loss: 0.0150, Initial Validation Loss: 0.1322, Validation Loss: 0.0403,V Acc: 0.7778, Top 70th Acc: 0.8947, Bottom 30th Acc: 0.5000
Fold [5/5] Epoch [20/100] Initial Loss: 0.1390, Training Loss: 0.0050, Initial Validation Loss: 0.1322, Validation Loss: 0.0357,V Acc: 0.8333, Top 70th Acc: 0.8816, Bottom 30th Acc: 0.7188
Fold [5/5] Epoch [30/100] Initial Loss: 0.1390, Training Loss: 0.0041, Initial Validation Loss: 0.1322, Validation Loss: 0.0341,V Acc: 0.8241, Top 70th Acc: 0.9079, Bottom 30th Acc: 0.6250
Fold [5/5] Epoch [40/100] Initial Loss: 0.1390, Training Loss: 0.0038, Initial Validation Loss: 0.1322, Validation Loss: 0.0332,V Acc: 0.8056, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.5000
Fold [5/5] Epoch [50/100] Initial Loss: 0.1390, Training Loss: 0.0037, Initial Validation Loss: 0.1322, Validation Loss: 0.0327,V Acc: 0.8148, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.5312
Fold [5/5] Epoch [60/100] Initial Loss: 0.1390, Training Loss: 0.0036, Initial Validation Loss: 0.1322, Validation Loss: 0.0326,V Acc: 0.8148, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.5312
Stopping early at Epoch (base 0): 62  Rolling back to Epoch (base 0): 57  Top Validation Acc: 0.9342105263157895
Running train_nn.py with seed 97
CUDA:False
Training samples count:  550
Training on 162 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1378, Training Loss: 0.1378, Initial Validation Loss: 0.1346, Validation Loss: 0.1346,V Acc: 0.3482, Top 70th Acc: 0.4051, Bottom 30th Acc: 0.2121
Fold [1/5] Epoch [10/100] Initial Loss: 0.1378, Training Loss: 0.0190, Initial Validation Loss: 0.1346, Validation Loss: 0.0317,V Acc: 0.8750, Top 70th Acc: 0.9747, Bottom 30th Acc: 0.6364
Fold [1/5] Epoch [20/100] Initial Loss: 0.1378, Training Loss: 0.0058, Initial Validation Loss: 0.1346, Validation Loss: 0.0244,V Acc: 0.9018, Top 70th Acc: 0.9747, Bottom 30th Acc: 0.7273
Fold [1/5] Epoch [30/100] Initial Loss: 0.1378, Training Loss: 0.0045, Initial Validation Loss: 0.1346, Validation Loss: 0.0229,V Acc: 0.8929, Top 70th Acc: 0.9747, Bottom 30th Acc: 0.6970
Fold [1/5] Epoch [40/100] Initial Loss: 0.1378, Training Loss: 0.0041, Initial Validation Loss: 0.1346, Validation Loss: 0.0222,V Acc: 0.8929, Top 70th Acc: 0.9747, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 42  Rolling back to Epoch (base 0): 37  Top Validation Acc: 0.9746835443037974
Fold [2/5] Epoch [0/100] Initial Loss: 0.1381, Training Loss: 0.1381, Initial Validation Loss: 0.1349, Validation Loss: 0.1349,V Acc: 0.2613, Top 70th Acc: 0.3590, Bottom 30th Acc: 0.0303
Fold [2/5] Epoch [10/100] Initial Loss: 0.1381, Training Loss: 0.0204, Initial Validation Loss: 0.1349, Validation Loss: 0.0502,V Acc: 0.7568, Top 70th Acc: 0.8718, Bottom 30th Acc: 0.4848
Fold [2/5] Epoch [20/100] Initial Loss: 0.1381, Training Loss: 0.0048, Initial Validation Loss: 0.1349, Validation Loss: 0.0406,V Acc: 0.8018, Top 70th Acc: 0.8974, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.8974358974358975
97 1 [array([0.21076998, 0.0358003 , 0.11477485, 0.3117676 , 0.3268873 ],
      dtype=float32)]
Fold [3/5] Epoch [0/100] Initial Loss: 0.1371, Training Loss: 0.1371, Initial Validation Loss: 0.1308, Validation Loss: 0.1308,V Acc: 0.4727, Top 70th Acc: 0.6104, Bottom 30th Acc: 0.1515
Fold [3/5] Epoch [10/100] Initial Loss: 0.1371, Training Loss: 0.0125, Initial Validation Loss: 0.1308, Validation Loss: 0.0256,V Acc: 0.8727, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.6364
Fold [3/5] Epoch [20/100] Initial Loss: 0.1371, Training Loss: 0.0049, Initial Validation Loss: 0.1308, Validation Loss: 0.0251,V Acc: 0.8727, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 21  Rolling back to Epoch (base 0): 16  Top Validation Acc: 0.974025974025974
Fold [4/5] Epoch [0/100] Initial Loss: 0.1388, Training Loss: 0.1388, Initial Validation Loss: 0.1304, Validation Loss: 0.1304,V Acc: 0.4679, Top 70th Acc: 0.5584, Bottom 30th Acc: 0.2500
Fold [4/5] Epoch [10/100] Initial Loss: 0.1388, Training Loss: 0.0262, Initial Validation Loss: 0.1304, Validation Loss: 0.0419,V Acc: 0.7982, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.4688
Fold [4/5] Epoch [20/100] Initial Loss: 0.1388, Training Loss: 0.0052, Initial Validation Loss: 0.1304, Validation Loss: 0.0307,V Acc: 0.8440, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.5938
Fold [4/5] Epoch [30/100] Initial Loss: 0.1388, Training Loss: 0.0035, Initial Validation Loss: 0.1304, Validation Loss: 0.0284,V Acc: 0.8624, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6562
Fold [4/5] Epoch [40/100] Initial Loss: 0.1388, Training Loss: 0.0031, Initial Validation Loss: 0.1304, Validation Loss: 0.0280,V Acc: 0.8624, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.6250
Fold [4/5] Epoch [50/100] Initial Loss: 0.1388, Training Loss: 0.0030, Initial Validation Loss: 0.1304, Validation Loss: 0.0278,V Acc: 0.8624, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.6250
Stopping early at Epoch (base 0): 50  Rolling back to Epoch (base 0): 45  Top Validation Acc: 0.961038961038961
Fold [5/5] Epoch [0/100] Initial Loss: 0.1410, Training Loss: 0.1410, Initial Validation Loss: 0.1305, Validation Loss: 0.1305,V Acc: 0.2593, Top 70th Acc: 0.3421, Bottom 30th Acc: 0.0625
Fold [5/5] Epoch [10/100] Initial Loss: 0.1410, Training Loss: 0.0276, Initial Validation Loss: 0.1305, Validation Loss: 0.0406,V Acc: 0.8148, Top 70th Acc: 0.8947, Bottom 30th Acc: 0.6250
Fold [5/5] Epoch [20/100] Initial Loss: 0.1410, Training Loss: 0.0052, Initial Validation Loss: 0.1305, Validation Loss: 0.0313,V Acc: 0.8241, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.5625
Fold [5/5] Epoch [30/100] Initial Loss: 0.1410, Training Loss: 0.0040, Initial Validation Loss: 0.1305, Validation Loss: 0.0310,V Acc: 0.8519, Top 70th Acc: 0.9211, Bottom 30th Acc: 0.6875
Stopping early at Epoch (base 0): 31  Rolling back to Epoch (base 0): 26  Top Validation Acc: 0.9210526315789473
Running train_nn.py with seed 98
CUDA:False
Training samples count:  550
Training on 162 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1401, Training Loss: 0.1401, Initial Validation Loss: 0.1378, Validation Loss: 0.1378,V Acc: 0.3929, Top 70th Acc: 0.4177, Bottom 30th Acc: 0.3333
Fold [1/5] Epoch [10/100] Initial Loss: 0.1401, Training Loss: 0.0164, Initial Validation Loss: 0.1378, Validation Loss: 0.0377,V Acc: 0.8393, Top 70th Acc: 0.9114, Bottom 30th Acc: 0.6667
Fold [1/5] Epoch [20/100] Initial Loss: 0.1401, Training Loss: 0.0052, Initial Validation Loss: 0.1378, Validation Loss: 0.0308,V Acc: 0.8393, Top 70th Acc: 0.9367, Bottom 30th Acc: 0.6061
Fold [1/5] Epoch [30/100] Initial Loss: 0.1401, Training Loss: 0.0039, Initial Validation Loss: 0.1378, Validation Loss: 0.0286,V Acc: 0.8571, Top 70th Acc: 0.9620, Bottom 30th Acc: 0.6061
Fold [1/5] Epoch [40/100] Initial Loss: 0.1401, Training Loss: 0.0036, Initial Validation Loss: 0.1378, Validation Loss: 0.0280,V Acc: 0.8661, Top 70th Acc: 0.9620, Bottom 30th Acc: 0.6364
Fold [1/5] Epoch [50/100] Initial Loss: 0.1401, Training Loss: 0.0035, Initial Validation Loss: 0.1378, Validation Loss: 0.0276,V Acc: 0.8661, Top 70th Acc: 0.9620, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 55  Rolling back to Epoch (base 0): 50  Top Validation Acc: 0.9493670886075949
Fold [2/5] Epoch [0/100] Initial Loss: 0.1369, Training Loss: 0.1369, Initial Validation Loss: 0.1340, Validation Loss: 0.1340,V Acc: 0.4505, Top 70th Acc: 0.5769, Bottom 30th Acc: 0.1515
Fold [2/5] Epoch [10/100] Initial Loss: 0.1369, Training Loss: 0.0143, Initial Validation Loss: 0.1340, Validation Loss: 0.0365,V Acc: 0.8198, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.5455
Fold [2/5] Epoch [20/100] Initial Loss: 0.1369, Training Loss: 0.0049, Initial Validation Loss: 0.1340, Validation Loss: 0.0322,V Acc: 0.8468, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.6364
Fold [2/5] Epoch [30/100] Initial Loss: 0.1369, Training Loss: 0.0038, Initial Validation Loss: 0.1340, Validation Loss: 0.0319,V Acc: 0.8378, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 38  Rolling back to Epoch (base 0): 33  Top Validation Acc: 0.9487179487179487
Fold [3/5] Epoch [0/100] Initial Loss: 0.1380, Training Loss: 0.1380, Initial Validation Loss: 0.1315, Validation Loss: 0.1315,V Acc: 0.4000, Top 70th Acc: 0.4545, Bottom 30th Acc: 0.2727
Fold [3/5] Epoch [10/100] Initial Loss: 0.1380, Training Loss: 0.0118, Initial Validation Loss: 0.1315, Validation Loss: 0.0335,V Acc: 0.7909, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.4242
Stopping early at Epoch (base 0): 19  Rolling back to Epoch (base 0): 14  Top Validation Acc: 0.948051948051948
Fold [4/5] Epoch [0/100] Initial Loss: 0.1412, Training Loss: 0.1412, Initial Validation Loss: 0.1312, Validation Loss: 0.1312,V Acc: 0.2477, Top 70th Acc: 0.2597, Bottom 30th Acc: 0.2188
Fold [4/5] Epoch [10/100] Initial Loss: 0.1412, Training Loss: 0.0293, Initial Validation Loss: 0.1312, Validation Loss: 0.0432,V Acc: 0.7890, Top 70th Acc: 0.8961, Bottom 30th Acc: 0.5312
Fold [4/5] Epoch [20/100] Initial Loss: 0.1412, Training Loss: 0.0063, Initial Validation Loss: 0.1312, Validation Loss: 0.0266,V Acc: 0.8716, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.6562
Fold [4/5] Epoch [30/100] Initial Loss: 0.1412, Training Loss: 0.0043, Initial Validation Loss: 0.1312, Validation Loss: 0.0264,V Acc: 0.8440, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.5625
Stopping early at Epoch (base 0): 34  Rolling back to Epoch (base 0): 29  Top Validation Acc: 0.961038961038961
98 3 [array([0.10215277, 0.0378943 , 0.04546915, 0.24927652, 0.56520724],
      dtype=float32)]
Fold [5/5] Epoch [0/100] Initial Loss: 0.1384, Training Loss: 0.1384, Initial Validation Loss: 0.1307, Validation Loss: 0.1307,V Acc: 0.2685, Top 70th Acc: 0.3684, Bottom 30th Acc: 0.0312
Fold [5/5] Epoch [10/100] Initial Loss: 0.1384, Training Loss: 0.0199, Initial Validation Loss: 0.1307, Validation Loss: 0.0383,V Acc: 0.8519, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.6562
Fold [5/5] Epoch [20/100] Initial Loss: 0.1384, Training Loss: 0.0052, Initial Validation Loss: 0.1307, Validation Loss: 0.0307,V Acc: 0.8704, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.6875
Stopping early at Epoch (base 0): 28  Rolling back to Epoch (base 0): 23  Top Validation Acc: 0.9473684210526315
Running train_nn.py with seed 99
CUDA:False
Training samples count:  550
Training on 162 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1400, Training Loss: 0.1400, Initial Validation Loss: 0.1376, Validation Loss: 0.1376,V Acc: 0.3036, Top 70th Acc: 0.3797, Bottom 30th Acc: 0.1212
Fold [1/5] Epoch [10/100] Initial Loss: 0.1400, Training Loss: 0.0274, Initial Validation Loss: 0.1376, Validation Loss: 0.0393,V Acc: 0.8304, Top 70th Acc: 0.9367, Bottom 30th Acc: 0.5758
Fold [1/5] Epoch [20/100] Initial Loss: 0.1400, Training Loss: 0.0069, Initial Validation Loss: 0.1376, Validation Loss: 0.0303,V Acc: 0.8482, Top 70th Acc: 0.9494, Bottom 30th Acc: 0.6061
Fold [1/5] Epoch [30/100] Initial Loss: 0.1400, Training Loss: 0.0047, Initial Validation Loss: 0.1376, Validation Loss: 0.0303,V Acc: 0.8304, Top 70th Acc: 0.9367, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 33  Rolling back to Epoch (base 0): 28  Top Validation Acc: 0.9240506329113924
Fold [2/5] Epoch [0/100] Initial Loss: 0.1372, Training Loss: 0.1372, Initial Validation Loss: 0.1321, Validation Loss: 0.1321,V Acc: 0.4144, Top 70th Acc: 0.5513, Bottom 30th Acc: 0.0909
Fold [2/5] Epoch [10/100] Initial Loss: 0.1372, Training Loss: 0.0122, Initial Validation Loss: 0.1321, Validation Loss: 0.0418,V Acc: 0.8198, Top 70th Acc: 0.8974, Bottom 30th Acc: 0.6364
Fold [2/5] Epoch [20/100] Initial Loss: 0.1372, Training Loss: 0.0044, Initial Validation Loss: 0.1321, Validation Loss: 0.0383,V Acc: 0.8198, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.9102564102564102
99 1 [array([0.14106503, 0.0515428 , 0.05182561, 0.27466264, 0.48090386],
      dtype=float32)]
Fold [3/5] Epoch [0/100] Initial Loss: 0.1388, Training Loss: 0.1388, Initial Validation Loss: 0.1317, Validation Loss: 0.1317,V Acc: 0.2545, Top 70th Acc: 0.2987, Bottom 30th Acc: 0.1515
Fold [3/5] Epoch [10/100] Initial Loss: 0.1388, Training Loss: 0.0181, Initial Validation Loss: 0.1317, Validation Loss: 0.0364,V Acc: 0.8273, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.6061
Fold [3/5] Epoch [20/100] Initial Loss: 0.1388, Training Loss: 0.0064, Initial Validation Loss: 0.1317, Validation Loss: 0.0327,V Acc: 0.8364, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 28  Rolling back to Epoch (base 0): 23  Top Validation Acc: 0.935064935064935
Fold [4/5] Epoch [0/100] Initial Loss: 0.1383, Training Loss: 0.1383, Initial Validation Loss: 0.1308, Validation Loss: 0.1308,V Acc: 0.2661, Top 70th Acc: 0.3377, Bottom 30th Acc: 0.0938
Fold [4/5] Epoch [10/100] Initial Loss: 0.1383, Training Loss: 0.0168, Initial Validation Loss: 0.1308, Validation Loss: 0.0318,V Acc: 0.8716, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6875
Fold [4/5] Epoch [20/100] Initial Loss: 0.1383, Training Loss: 0.0052, Initial Validation Loss: 0.1308, Validation Loss: 0.0270,V Acc: 0.8624, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.5938
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.961038961038961
Fold [5/5] Epoch [0/100] Initial Loss: 0.1398, Training Loss: 0.1398, Initial Validation Loss: 0.1323, Validation Loss: 0.1323,V Acc: 0.2685, Top 70th Acc: 0.3026, Bottom 30th Acc: 0.1875
Fold [5/5] Epoch [10/100] Initial Loss: 0.1398, Training Loss: 0.0174, Initial Validation Loss: 0.1323, Validation Loss: 0.0370,V Acc: 0.8519, Top 70th Acc: 0.9211, Bottom 30th Acc: 0.6875
Fold [5/5] Epoch [20/100] Initial Loss: 0.1398, Training Loss: 0.0047, Initial Validation Loss: 0.1323, Validation Loss: 0.0299,V Acc: 0.8519, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.6250
Stopping early at Epoch (base 0): 27  Rolling back to Epoch (base 0): 22  Top Validation Acc: 0.9342105263157895
Running train_nn.py with seed 100
CUDA:False
Training samples count:  550
Training on 162 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1385, Training Loss: 0.1385, Initial Validation Loss: 0.1355, Validation Loss: 0.1355,V Acc: 0.4464, Top 70th Acc: 0.4810, Bottom 30th Acc: 0.3636
Fold [1/5] Epoch [10/100] Initial Loss: 0.1385, Training Loss: 0.0258, Initial Validation Loss: 0.1355, Validation Loss: 0.0462,V Acc: 0.7857, Top 70th Acc: 0.8861, Bottom 30th Acc: 0.5455
Fold [1/5] Epoch [20/100] Initial Loss: 0.1385, Training Loss: 0.0047, Initial Validation Loss: 0.1355, Validation Loss: 0.0310,V Acc: 0.8661, Top 70th Acc: 0.9494, Bottom 30th Acc: 0.6667
Fold [1/5] Epoch [30/100] Initial Loss: 0.1385, Training Loss: 0.0037, Initial Validation Loss: 0.1355, Validation Loss: 0.0299,V Acc: 0.8750, Top 70th Acc: 0.9620, Bottom 30th Acc: 0.6667
Fold [1/5] Epoch [40/100] Initial Loss: 0.1385, Training Loss: 0.0035, Initial Validation Loss: 0.1355, Validation Loss: 0.0302,V Acc: 0.8750, Top 70th Acc: 0.9620, Bottom 30th Acc: 0.6667/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)

Stopping early at Epoch (base 0): 40  Rolling back to Epoch (base 0): 35  Top Validation Acc: 0.9620253164556962
Fold [2/5] Epoch [0/100] Initial Loss: 0.1399, Training Loss: 0.1399, Initial Validation Loss: 0.1302, Validation Loss: 0.1302,V Acc: 0.3333, Top 70th Acc: 0.4231, Bottom 30th Acc: 0.1212
Fold [2/5] Epoch [10/100] Initial Loss: 0.1399, Training Loss: 0.0182, Initial Validation Loss: 0.1302, Validation Loss: 0.0389,V Acc: 0.8559, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.6667
Fold [2/5] Epoch [20/100] Initial Loss: 0.1399, Training Loss: 0.0052, Initial Validation Loss: 0.1302, Validation Loss: 0.0310,V Acc: 0.8378, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.5758
Fold [2/5] Epoch [30/100] Initial Loss: 0.1399, Training Loss: 0.0041, Initial Validation Loss: 0.1302, Validation Loss: 0.0298,V Acc: 0.8649, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 36  Rolling back to Epoch (base 0): 31  Top Validation Acc: 0.9615384615384616
Fold [3/5] Epoch [0/100] Initial Loss: 0.1412, Training Loss: 0.1412, Initial Validation Loss: 0.1344, Validation Loss: 0.1344,V Acc: 0.2909, Top 70th Acc: 0.3636, Bottom 30th Acc: 0.1212
Fold [3/5] Epoch [10/100] Initial Loss: 0.1412, Training Loss: 0.0163, Initial Validation Loss: 0.1344, Validation Loss: 0.0337,V Acc: 0.8273, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.5455
Fold [3/5] Epoch [20/100] Initial Loss: 0.1412, Training Loss: 0.0050, Initial Validation Loss: 0.1344, Validation Loss: 0.0287,V Acc: 0.8455, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.5758
Fold [3/5] Epoch [30/100] Initial Loss: 0.1412, Training Loss: 0.0040, Initial Validation Loss: 0.1344, Validation Loss: 0.0281,V Acc: 0.8455, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 35  Rolling back to Epoch (base 0): 30  Top Validation Acc: 0.961038961038961
100 2 [array([0.24613294, 0.09081148, 0.06185481, 0.2589308 , 0.34226996],
      dtype=float32)]
Fold [4/5] Epoch [0/100] Initial Loss: 0.1395, Training Loss: 0.1395, Initial Validation Loss: 0.1329, Validation Loss: 0.1329,V Acc: 0.3211, Top 70th Acc: 0.4026, Bottom 30th Acc: 0.1250
Fold [4/5] Epoch [10/100] Initial Loss: 0.1395, Training Loss: 0.0156, Initial Validation Loss: 0.1329, Validation Loss: 0.0317,V Acc: 0.8624, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.5938
Fold [4/5] Epoch [20/100] Initial Loss: 0.1395, Training Loss: 0.0046, Initial Validation Loss: 0.1329, Validation Loss: 0.0272,V Acc: 0.8165, Top 70th Acc: 0.9870, Bottom 30th Acc: 0.4062
Stopping early at Epoch (base 0): 28  Rolling back to Epoch (base 0): 23  Top Validation Acc: 0.974025974025974
Fold [5/5] Epoch [0/100] Initial Loss: 0.1400, Training Loss: 0.1400, Initial Validation Loss: 0.1337, Validation Loss: 0.1337,V Acc: 0.2222, Top 70th Acc: 0.3026, Bottom 30th Acc: 0.0312
Fold [5/5] Epoch [10/100] Initial Loss: 0.1400, Training Loss: 0.0156, Initial Validation Loss: 0.1337, Validation Loss: 0.0394,V Acc: 0.8241, Top 70th Acc: 0.9211, Bottom 30th Acc: 0.5938
Fold [5/5] Epoch [20/100] Initial Loss: 0.1400, Training Loss: 0.0049, Initial Validation Loss: 0.1337, Validation Loss: 0.0339,V Acc: 0.8426, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.6250
Fold [5/5] Epoch [30/100] Initial Loss: 0.1400, Training Loss: 0.0039, Initial Validation Loss: 0.1337, Validation Loss: 0.0335,V Acc: 0.8426, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.6250
Stopping early at Epoch (base 0): 32  Rolling back to Epoch (base 0): 27  Top Validation Acc: 0.9605263157894737
