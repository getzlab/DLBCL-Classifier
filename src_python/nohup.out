Running MNB with seed 1
Running MNB with seed 2
Running MNB with seed 3
Running MNB with seed 4
Running MNB with seed 5
Running MNB with seed 6
Running MNB with seed 7
Running MNB with seed 8
Running MNB with seed 9
Running MNB with seed 10
Running MNB with seed 11
Running MNB with seed 12
Running MNB with seed 13
Running MNB with seed 14
Running MNB with seed 15
Running MNB with seed 16
Running MNB with seed 17
Running MNB with seed 18
Running MNB with seed 19
Running MNB with seed 20
Running MNB with seed 21
Running MNB with seed 22
Running MNB with seed 23
Running MNB with seed 24
Running MNB with seed 25
Running MNB with seed 26
Running MNB with seed 27
Running MNB with seed 28
Running MNB with seed 29
Running MNB with seed 30
Running MNB with seed 31
Running MNB with seed 32
Running MNB with seed 33
Running MNB with seed 34
Running MNB with seed 35
Running MNB with seed 36
Running MNB with seed 37
Running MNB with seed 38
Running MNB with seed 39
Running MNB with seed 40
Running MNB with seed 41
Running MNB with seed 42
Running MNB with seed 43
Running MNB with seed 44
Running MNB with seed 45
Running MNB with seed 46
Running MNB with seed 47
Running MNB with seed 48
Running MNB with seed 49
Running MNB with seed 50
Running MNB with seed 51
Running MNB with seed 52
Running MNB with seed 53
Running MNB with seed 54
Running MNB with seed 55
Running MNB with seed 56
Running MNB with seed 57
Running MNB with seed 58
Running MNB with seed 59
Running MNB with seed 60
Running MNB with seed 61
Running MNB with seed 62
Running MNB with seed 63
Running MNB with seed 64
Running MNB with seed 65
Running MNB with seed 66
Running MNB with seed 67
Running MNB with seed 68
Running MNB with seed 69
Running MNB with seed 70
Running MNB with seed 71
Running MNB with seed 72
Running MNB with seed 73
Running MNB with seed 74
Running MNB with seed 75
Running MNB with seed 76
Running MNB with seed 77
Running MNB with seed 78
Running MNB with seed 79
Running MNB with seed 80
Running MNB with seed 81
Running MNB with seed 82
Running MNB with seed 83
Running MNB with seed 84
Running MNB with seed 85
Running MNB with seed 86
Running MNB with seed 87
Running MNB with seed 88
Running MNB with seed 89
Running MNB with seed 90
Running MNB with seed 91
Running MNB with seed 92
Running MNB with seed 93
Running MNB with seed 94
Running MNB with seed 95
Running MNB with seed 96
Running MNB with seed 97
Running MNB with seed 98
Running MNB with seed 99
Running MNB with seed 100
Running MNB with seed 1
Running MNB with seed 2
Running MNB with seed 3
Running MNB with seed 4
Running MNB with seed 5
Running MNB with seed 6
Running MNB with seed 7
Running MNB with seed 8
Running MNB with seed 9
Running MNB with seed 10
Running MNB with seed 11
Running MNB with seed 12
Running MNB with seed 13
Running MNB with seed 14
Running MNB with seed 15
Running MNB with seed 16
Running MNB with seed 17
Running MNB with seed 18
Running MNB with seed 19
Running MNB with seed 20
Running MNB with seed 21
Running MNB with seed 22
Running MNB with seed 23
Running MNB with seed 24
Running MNB with seed 25
Running MNB with seed 26
Running MNB with seed 27
Running MNB with seed 28
Running MNB with seed 29
Running MNB with seed 30
Running MNB with seed 31
Running MNB with seed 32
Running MNB with seed 33
Running MNB with seed 34
Running MNB with seed 35
Running MNB with seed 36
Running MNB with seed 37
Running MNB with seed 38
Running MNB with seed 39
Running MNB with seed 40
Running MNB with seed 41
Running MNB with seed 42
Running MNB with seed 43
Running MNB with seed 44
Running MNB with seed 45
Running MNB with seed 46
Running MNB with seed 47
Running MNB with seed 48
Running MNB with seed 49
Running MNB with seed 50
Running MNB with seed 51
Running MNB with seed 52
Running MNB with seed 53
Running MNB with seed 54
Running MNB with seed 55
Running MNB with seed 56
Running MNB with seed 57
Running MNB with seed 58
Running MNB with seed 59
Running MNB with seed 60
Running MNB with seed 61
Running MNB with seed 62
Running MNB with seed 63
Running MNB with seed 64
Running MNB with seed 65
Running MNB with seed 66
Running MNB with seed 67
Running MNB with seed 68
Running MNB with seed 69
Running MNB with seed 70
Running MNB with seed 71
Running MNB with seed 72
Running MNB with seed 73
Running MNB with seed 74
Running MNB with seed 75
Running MNB with seed 76
Running MNB with seed 77
Running MNB with seed 78
Running MNB with seed 79
Running MNB with seed 80
Running MNB with seed 81
Running MNB with seed 82
Running MNB with seed 83
Running MNB with seed 84
Running MNB with seed 85
Running MNB with seed 86
Running MNB with seed 87
Running MNB with seed 88
Running MNB with seed 89
Running MNB with seed 90
Running MNB with seed 91
Running MNB with seed 92
Running MNB with seed 93
Running MNB with seed 94
Running MNB with seed 95
Running MNB with seed 96
Running MNB with seed 97
Running MNB with seed 98
Running MNB with seed 99
Running MNB with seed 100
Running MNB with seed 1
Running MNB with seed 2
Running MNB with seed 3
Running MNB with seed 4
Running MNB with seed 5
Running MNB with seed 6
Running MNB with seed 7
Running MNB with seed 8
Running MNB with seed 9
Running MNB with seed 10
Running MNB with seed 11
Running MNB with seed 12
Running MNB with seed 13
Running MNB with seed 14
Running MNB with seed 15
Running MNB with seed 16
Running MNB with seed 17
Running MNB with seed 18
Running MNB with seed 19
Running MNB with seed 20
Running MNB with seed 21
Running MNB with seed 22
Running MNB with seed 23
Running MNB with seed 24
Running MNB with seed 25
Running MNB with seed 26
Running MNB with seed 27
Running MNB with seed 28
Running MNB with seed 29
Running MNB with seed 30
Running MNB with seed 31
Running MNB with seed 32
Running MNB with seed 33
Running MNB with seed 34
Running MNB with seed 35
Running MNB with seed 36
Running MNB with seed 37
Running MNB with seed 38
Running MNB with seed 39
Running MNB with seed 40
Running MNB with seed 41
Running MNB with seed 42
Running MNB with seed 43
Running MNB with seed 44
Running MNB with seed 45
Running MNB with seed 46
Running MNB with seed 47
Running MNB with seed 48
Running MNB with seed 49
Running MNB with seed 50
Running MNB with seed 51
Running MNB with seed 52
Running MNB with seed 53
Running MNB with seed 54
Running MNB with seed 55
Running MNB with seed 56
Running MNB with seed 57
Running MNB with seed 58
Running MNB with seed 59
Running MNB with seed 60
Running MNB with seed 61
Running MNB with seed 62
Running MNB with seed 63
Running MNB with seed 64
Running MNB with seed 65
Running MNB with seed 66
Running MNB with seed 67
Running MNB with seed 68
Running MNB with seed 69
Running MNB with seed 70
Running MNB with seed 71
Running MNB with seed 72
Running MNB with seed 73
Running MNB with seed 74
Running MNB with seed 75
Running MNB with seed 76
Running MNB with seed 77
Running MNB with seed 78
Running MNB with seed 79
Running MNB with seed 80
Running MNB with seed 81
Running MNB with seed 82
Running MNB with seed 83
Running MNB with seed 84
Running MNB with seed 85
Running MNB with seed 86
Running MNB with seed 87
Running MNB with seed 88
Running MNB with seed 89
Running MNB with seed 90
Running MNB with seed 91
Running MNB with seed 92
Running MNB with seed 93
Running MNB with seed 94
Running MNB with seed 95
Running MNB with seed 96
Running MNB with seed 97
Running MNB with seed 98
Running MNB with seed 99
Running MNB with seed 100
Running MNB with seed 1
Running MNB with seed 2
Running MNB with seed 3
Running MNB with seed 4
Running MNB with seed 5
Running MNB with seed 6
Running MNB with seed 7
Running MNB with seed 8
Running MNB with seed 9
Running MNB with seed 10
Running MNB with seed 11
Running MNB with seed 12
Running MNB with seed 13
Running MNB with seed 14
Running MNB with seed 15
Running MNB with seed 16
Running MNB with seed 17
Running MNB with seed 18
Running MNB with seed 19
Running MNB with seed 20
Running MNB with seed 21
Running MNB with seed 22
Running MNB with seed 23
Running MNB with seed 24
Running MNB with seed 25
Running MNB with seed 26
Running MNB with seed 27
Running MNB with seed 28
Running MNB with seed 29
Running MNB with seed 30
Running MNB with seed 31
Running MNB with seed 32
Running MNB with seed 33
Running MNB with seed 34
Running MNB with seed 35
Running MNB with seed 36
Running MNB with seed 37
Running MNB with seed 38
Running MNB with seed 39
Running MNB with seed 40
Running MNB with seed 41
Running MNB with seed 42
Running MNB with seed 43
Running MNB with seed 44
Running MNB with seed 45
Running MNB with seed 46
Running MNB with seed 47
Running MNB with seed 48
Running MNB with seed 49
Running MNB with seed 50
Running MNB with seed 51
Running MNB with seed 52
Running MNB with seed 53
Running MNB with seed 54
Running MNB with seed 55
Running MNB with seed 56
Running MNB with seed 57
Running MNB with seed 58
Running MNB with seed 59
Running MNB with seed 60
Running MNB with seed 61
Running MNB with seed 62
Running MNB with seed 63
Running MNB with seed 64
Running MNB with seed 65
Running MNB with seed 66
Running MNB with seed 67
Running MNB with seed 68
Running MNB with seed 69
Running MNB with seed 70
Running MNB with seed 71
Running MNB with seed 72
Running MNB with seed 73
Running MNB with seed 74
Running MNB with seed 75
Running MNB with seed 76
Running MNB with seed 77
Running MNB with seed 78
Running MNB with seed 79
Running MNB with seed 80
Running MNB with seed 81
Running MNB with seed 82
Running MNB with seed 83
Running MNB with seed 84
Running MNB with seed 85
Running MNB with seed 86
Running MNB with seed 87
Running MNB with seed 88
Running MNB with seed 89
Running MNB with seed 90
Running MNB with seed 91
Running MNB with seed 92
Running MNB with seed 93
Running MNB with seed 94
Running MNB with seed 95
Running MNB with seed 96
Running MNB with seed 97
Running MNB with seed 98
Running MNB with seed 99
Running MNB with seed 100
Running MNB with seed 1
Running MNB with seed 2
Running MNB with seed 3
Running MNB with seed 4
Running MNB with seed 5
Running MNB with seed 6
Running MNB with seed 7
Running MNB with seed 8
Running MNB with seed 9
Running MNB with seed 10
Running MNB with seed 11
Running MNB with seed 12
Running MNB with seed 13
Running MNB with seed 14
Running MNB with seed 15
Running MNB with seed 16
Running MNB with seed 17
Running MNB with seed 18
Running MNB with seed 19
Running MNB with seed 20
Running MNB with seed 21
Running MNB with seed 22
Running MNB with seed 23
Running MNB with seed 24
Running MNB with seed 25
Running MNB with seed 26
Running MNB with seed 27
Running MNB with seed 28
Running MNB with seed 29
Running MNB with seed 30
Running MNB with seed 31
Running MNB with seed 32
Running MNB with seed 33
Running MNB with seed 34
Running MNB with seed 35
Running MNB with seed 36
Running MNB with seed 37
Running MNB with seed 38
Running MNB with seed 39
Running MNB with seed 40
Running MNB with seed 41
Running MNB with seed 42
Running MNB with seed 43
Running MNB with seed 44
Running MNB with seed 45
Running MNB with seed 46
Running MNB with seed 47
Running MNB with seed 48
Running MNB with seed 49
Running MNB with seed 50
Running MNB with seed 51
Running MNB with seed 52
Running MNB with seed 53
Running MNB with seed 54
Running MNB with seed 55
Running MNB with seed 56
Running MNB with seed 57
Running MNB with seed 58
Running MNB with seed 59
Running MNB with seed 60
Running MNB with seed 61
Running MNB with seed 62
Running MNB with seed 63
Running MNB with seed 64
Running MNB with seed 65
Running MNB with seed 66
Running MNB with seed 67
Running MNB with seed 68
Running MNB with seed 69
Running MNB with seed 70
Running MNB with seed 71
Running MNB with seed 72
Running MNB with seed 73
Running MNB with seed 74
Running MNB with seed 75
Running MNB with seed 76
Running MNB with seed 77
Running MNB with seed 78
Running MNB with seed 79
Running MNB with seed 80
Running MNB with seed 81
Running MNB with seed 82
Running MNB with seed 83
Running MNB with seed 84
Running MNB with seed 85
Running MNB with seed 86
Running MNB with seed 87
Running MNB with seed 88
Running MNB with seed 89
Running MNB with seed 90
Running MNB with seed 91
Running MNB with seed 92
Running MNB with seed 93
Running MNB with seed 94
Running MNB with seed 95
Running MNB with seed 96
Running MNB with seed 97
Running MNB with seed 98
Running MNB with seed 99
Running MNB with seed 100
Running MNB with seed 1
Running MNB with seed 2
Running MNB with seed 3
Running MNB with seed 4
Running MNB with seed 5
Running MNB with seed 6
Running MNB with seed 7
Running MNB with seed 8
Running MNB with seed 9
Running MNB with seed 10
Running MNB with seed 11
Running MNB with seed 12
Running MNB with seed 13
Running MNB with seed 14
Running MNB with seed 15
Running MNB with seed 16
Running MNB with seed 17
Running MNB with seed 18
Running MNB with seed 19
Running MNB with seed 20
Running MNB with seed 21
Running MNB with seed 22
Running MNB with seed 23
Running MNB with seed 24
Running MNB with seed 25
Running MNB with seed 26
Running MNB with seed 27
Running MNB with seed 28
Running MNB with seed 29
Running MNB with seed 30
Running MNB with seed 31
Running MNB with seed 32
Running MNB with seed 33
Running MNB with seed 34
Running MNB with seed 35
Running MNB with seed 36
Running MNB with seed 37
Running MNB with seed 38
Running MNB with seed 39
Running MNB with seed 40
Running MNB with seed 41
Running MNB with seed 42
Running MNB with seed 43
Running MNB with seed 44
Running MNB with seed 45
Running MNB with seed 46
Running MNB with seed 47
Running MNB with seed 48
Running MNB with seed 49
Running MNB with seed 50
Running MNB with seed 51
Running MNB with seed 52
Running MNB with seed 53
Running MNB with seed 54
Running MNB with seed 55
Running MNB with seed 56
Running MNB with seed 57
Running MNB with seed 58
Running MNB with seed 59
Running MNB with seed 60
Running MNB with seed 61
Running MNB with seed 62
Running MNB with seed 63
Running MNB with seed 64
Running MNB with seed 65
Running MNB with seed 66
Running MNB with seed 67
Running MNB with seed 68
Running MNB with seed 69
Running MNB with seed 70
Running MNB with seed 71
Running MNB with seed 72
Running MNB with seed 73
Running MNB with seed 74
Running MNB with seed 75
Running MNB with seed 76
Running MNB with seed 77
Running MNB with seed 78
Running MNB with seed 79
Running MNB with seed 80
Running MNB with seed 81
Running MNB with seed 82
Running MNB with seed 83
Running MNB with seed 84
Running MNB with seed 85
Running MNB with seed 86
Running MNB with seed 87
Running MNB with seed 88
Running MNB with seed 89
Running MNB with seed 90
Running MNB with seed 91
Running MNB with seed 92
Running MNB with seed 93
Running MNB with seed 94
Running MNB with seed 95
Running MNB with seed 96
Running MNB with seed 97
Running MNB with seed 98
Running MNB with seed 99
Running MNB with seed 100
Running train_nn.py with seed 1
CUDA:False
Training samples count:  550
Training on 21 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1331, Training Loss: 0.1331, Initial Validation Loss: 0.1178, Validation Loss: 0.1178,V Acc: 0.5045, Top 70th Acc: 0.6154, Bottom 30th Acc: 0.2424
Fold [1/5] Epoch [10/100] Initial Loss: 0.1331, Training Loss: 0.0236, Initial Validation Loss: 0.1178, Validation Loss: 0.0248,V Acc: 0.8649, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.6364
Fold [1/5] Epoch [20/100] Initial Loss: 0.1331, Training Loss: 0.0177, Initial Validation Loss: 0.1178, Validation Loss: 0.0193,V Acc: 0.8829, Top 70th Acc: 0.9872, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 21  Rolling back to Epoch (base 0): 16  Top Validation Acc: 0.9743589743589743
1 0 [array([0.77963376, 0.0204425 , 0.02204583, 0.0882671 , 0.0896108 ],
      dtype=float32)]
Fold [2/5] Epoch [0/100] Initial Loss: 0.1332, Training Loss: 0.1332, Initial Validation Loss: 0.1202, Validation Loss: 0.1202,V Acc: 0.5135, Top 70th Acc: 0.6410, Bottom 30th Acc: 0.2121
Fold [2/5] Epoch [10/100] Initial Loss: 0.1332, Training Loss: 0.0227, Initial Validation Loss: 0.1202, Validation Loss: 0.0287,V Acc: 0.8559, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 15  Rolling back to Epoch (base 0): 10  Top Validation Acc: 0.9358974358974359
Fold [3/5] Epoch [0/100] Initial Loss: 0.1264, Training Loss: 0.1264, Initial Validation Loss: 0.1134, Validation Loss: 0.1134,V Acc: 0.4182, Top 70th Acc: 0.5195, Bottom 30th Acc: 0.1818
Fold [3/5] Epoch [10/100] Initial Loss: 0.1264, Training Loss: 0.0257, Initial Validation Loss: 0.1134, Validation Loss: 0.0380,V Acc: 0.8545, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.6667
Fold [3/5] Epoch [20/100] Initial Loss: 0.1264, Training Loss: 0.0164, Initial Validation Loss: 0.1134, Validation Loss: 0.0288,V Acc: 0.8545, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.935064935064935
Fold [4/5] Epoch [0/100] Initial Loss: 0.1327, Training Loss: 0.1327, Initial Validation Loss: 0.1222, Validation Loss: 0.1222,V Acc: 0.4364, Top 70th Acc: 0.5455, Bottom 30th Acc: 0.1818
Fold [4/5] Epoch [10/100] Initial Loss: 0.1327, Training Loss: 0.0238, Initial Validation Loss: 0.1222, Validation Loss: 0.0283,V Acc: 0.8909, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.7273
Fold [4/5] Epoch [20/100] Initial Loss: 0.1327, Training Loss: 0.0195, Initial Validation Loss: 0.1222, Validation Loss: 0.0251,V Acc: 0.8909, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.7273
Stopping early at Epoch (base 0): 21  Rolling back to Epoch (base 0): 16  Top Validation Acc: 0.987012987012987
Fold [5/5] Epoch [0/100] Initial Loss: 0.1310, Training Loss: 0.1310, Initial Validation Loss: 0.1176, Validation Loss: 0.1176,V Acc: 0.5463, Top 70th Acc: 0.6316, Bottom 30th Acc: 0.3438
Fold [5/5] Epoch [10/100] Initial Loss: 0.1310, Training Loss: 0.0224, Initial Validation Loss: 0.1176, Validation Loss: 0.0410,V Acc: 0.8241, Top 70th Acc: 0.9079, Bottom 30th Acc: 0.6250
Stopping early at Epoch (base 0): 14  Rolling back to Epoch (base 0): 9  Top Validation Acc: 0.9342105263157895
Running train_nn.py with seed 2
CUDA:False
Training samples count:  550
Training on 21 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1292, Training Loss: 0.1292, Initial Validation Loss: 0.1205, Validation Loss: 0.1205,V Acc: 0.4234, Top 70th Acc: 0.5513, Bottom 30th Acc: 0.1212
Fold [1/5] Epoch [10/100] Initial Loss: 0.1292, Training Loss: 0.0308, Initial Validation Loss: 0.1205, Validation Loss: 0.0401,V Acc: 0.8468, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.6970
Fold [1/5] Epoch [20/100] Initial Loss: 0.1292, Training Loss: 0.0194, Initial Validation Loss: 0.1205, Validation Loss: 0.0359,V Acc: 0.8468, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.9615384615384616
2 0 [array([0.83491135, 0.02538267, 0.03672994, 0.06566835, 0.03730767],
      dtype=float32)]
Fold [2/5] Epoch [0/100] Initial Loss: 0.1361, Training Loss: 0.1361, Initial Validation Loss: 0.1312, Validation Loss: 0.1312,V Acc: 0.3604, Top 70th Acc: 0.3974, Bottom 30th Acc: 0.2727
Fold [2/5] Epoch [10/100] Initial Loss: 0.1361, Training Loss: 0.0267, Initial Validation Loss: 0.1312, Validation Loss: 0.0257,V Acc: 0.9009, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.7879
Fold [2/5] Epoch [20/100] Initial Loss: 0.1361, Training Loss: 0.0190, Initial Validation Loss: 0.1312, Validation Loss: 0.0208,V Acc: 0.8739, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.9358974358974359
Fold [3/5] Epoch [0/100] Initial Loss: 0.1302, Training Loss: 0.1302, Initial Validation Loss: 0.1116, Validation Loss: 0.1116,V Acc: 0.4909, Top 70th Acc: 0.6234, Bottom 30th Acc: 0.1818
Fold [3/5] Epoch [10/100] Initial Loss: 0.1302, Training Loss: 0.0238, Initial Validation Loss: 0.1116, Validation Loss: 0.0314,V Acc: 0.8273, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 18  Rolling back to Epoch (base 0): 13  Top Validation Acc: 0.948051948051948
Fold [4/5] Epoch [0/100] Initial Loss: 0.1313, Training Loss: 0.1313, Initial Validation Loss: 0.1147, Validation Loss: 0.1147,V Acc: 0.5636, Top 70th Acc: 0.6623, Bottom 30th Acc: 0.3333
Fold [4/5] Epoch [10/100] Initial Loss: 0.1313, Training Loss: 0.0254, Initial Validation Loss: 0.1147, Validation Loss: 0.0252,V Acc: 0.9000, Top 70th Acc: 1.0000, Bottom 30th Acc: 0.6667
Fold [4/5] Epoch [20/100] Initial Loss: 0.1313, Training Loss: 0.0184, Initial Validation Loss: 0.1147, Validation Loss: 0.0253,V Acc: 0.8909, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.7273
Stopping early at Epoch (base 0): 28  Rolling back to Epoch (base 0): 23  Top Validation Acc: 0.987012987012987
Fold [5/5] Epoch [0/100] Initial Loss: 0.1277, Training Loss: 0.1277, Initial Validation Loss: 0.1070, Validation Loss: 0.1070,V Acc: 0.5278, Top 70th Acc: 0.6316, Bottom 30th Acc: 0.2812
Fold [5/5] Epoch [10/100] Initial Loss: 0.1277, Training Loss: 0.0221, Initial Validation Loss: 0.1070, Validation Loss: 0.0370,V Acc: 0.8241, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.5625
Fold [5/5] Epoch [20/100] Initial Loss: 0.1277, Training Loss: 0.0161, Initial Validation Loss: 0.1070, Validation Loss: 0.0356,V Acc: 0.8241, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.5625
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.9342105263157895
Running train_nn.py with seed 3
CUDA:False
Training samples count:  550
Training on 21 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1314, Training Loss: 0.1314, Initial Validation Loss: 0.1196, Validation Loss: 0.1196,V Acc: 0.4775, Top 70th Acc: 0.6282, Bottom 30th Acc: 0.1212
Fold [1/5] Epoch [10/100] Initial Loss: 0.1314, Training Loss: 0.0251, Initial Validation Loss: 0.1196, Validation Loss: 0.0362,V Acc: 0.8559, Top 70th Acc: 0.8846, Bottom 30th Acc: 0.7879
Stopping early at Epoch (base 0): 16  Rolling back to Epoch (base 0): 11  Top Validation Acc: 0.9230769230769231
Fold [2/5] Epoch [0/100] Initial Loss: 0.1287, Training Loss: 0.1287, Initial Validation Loss: 0.1143, Validation Loss: 0.1143,V Acc: 0.5405, Top 70th Acc: 0.7308, Bottom 30th Acc: 0.0909
Fold [2/5] Epoch [10/100] Initial Loss: 0.1287, Training Loss: 0.0282, Initial Validation Loss: 0.1143, Validation Loss: 0.0184,V Acc: 0.8919, Top 70th Acc: 1.0000, Bottom 30th Acc: 0.6364
Fold [2/5] Epoch [20/100] Initial Loss: 0.1287, Training Loss: 0.0198, Initial Validation Loss: 0.1143, Validation Loss: 0.0182,V Acc: 0.8829, Top 70th Acc: 1.0000, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 1.0
Fold [3/5] Epoch [0/100] Initial Loss: 0.1316, Training Loss: 0.1316, Initial Validation Loss: 0.1259, Validation Loss: 0.1259,V Acc: 0.3636, Top 70th Acc: 0.4675, Bottom 30th Acc: 0.1212
Fold [3/5] Epoch [10/100] Initial Loss: 0.1316, Training Loss: 0.0247, Initial Validation Loss: 0.1259, Validation Loss: 0.0289,V Acc: 0.8818, Top 70th Acc: 0.9870, Bottom 30th Acc: 0.6364Running train_nn.py with seed 1
CUDA:False
Training samples count:  550
Training on 20 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1398, Training Loss: 0.1398, Initial Validation Loss: 0.1333, Validation Loss: 0.1333,V Acc: 0.2523, Top 70th Acc: 0.3590, Bottom 30th Acc: 0.0000
Fold [1/5] Epoch [10/100] Initial Loss: 0.1398, Training Loss: 0.0372, Initial Validation Loss: 0.1333, Validation Loss: 0.0280,V Acc: 0.8739, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.6364
Fold [1/5] Epoch [20/100] Initial Loss: 0.1398, Training Loss: 0.0245, Initial Validation Loss: 0.1333, Validation Loss: 0.0203,V Acc: 0.9099, Top 70th Acc: 0.9872, Bottom 30th Acc: 0.7273
Stopping early at Epoch (base 0): 22  Rolling back to Epoch (base 0): 17  Top Validation Acc: 0.9871794871794872
1 0 [array([0.41502163, 0.10439334, 0.17014919, 0.18333606, 0.12709981],
      dtype=float32)]
Fold [2/5] Epoch [0/100] Initial Loss: 0.1392, Training Loss: 0.1392, Initial Validation Loss: 0.1333, Validation Loss: 0.1333,V Acc: 0.2523, Top 70th Acc: 0.3462, Bottom 30th Acc: 0.0303
Fold [2/5] Epoch [10/100] Initial Loss: 0.1392, Training Loss: 0.0324, Initial Validation Loss: 0.1333, Validation Loss: 0.0341,V Acc: 0.8649, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.7576
Fold [2/5] Epoch [20/100] Initial Loss: 0.1392, Training Loss: 0.0227, Initial Validation Loss: 0.1333, Validation Loss: 0.0291,V Acc: 0.8649, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.7273
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.9358974358974359
Fold [3/5] Epoch [0/100] Initial Loss: 0.1369, Training Loss: 0.1369, Initial Validation Loss: 0.1289, Validation Loss: 0.1289,V Acc: 0.4091, Top 70th Acc: 0.4156, Bottom 30th Acc: 0.3939
Fold [3/5] Epoch [10/100] Initial Loss: 0.1369, Training Loss: 0.0303, Initial Validation Loss: 0.1289, Validation Loss: 0.0378,V Acc: 0.8182, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.5455
Fold [3/5] Epoch [20/100] Initial Loss: 0.1369, Training Loss: 0.0214, Initial Validation Loss: 0.1289, Validation Loss: 0.0354,V Acc: 0.8091, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.5152
Stopping early at Epoch (base 0): 20  Rolling back to Epoch (base 0): 15  Top Validation Acc: 0.935064935064935
Fold [4/5] Epoch [0/100] Initial Loss: 0.1376, Training Loss: 0.1376, Initial Validation Loss: 0.1341, Validation Loss: 0.1341,V Acc: 0.3000, Top 70th Acc: 0.3896, Bottom 30th Acc: 0.0909
Fold [4/5] Epoch [10/100] Initial Loss: 0.1376, Training Loss: 0.0372, Initial Validation Loss: 0.1341, Validation Loss: 0.0476,V Acc: 0.7818, Top 70th Acc: 0.8961, Bottom 30th Acc: 0.5152
Fold [4/5] Epoch [20/100] Initial Loss: 0.1376, Training Loss: 0.0240, Initial Validation Loss: 0.1341, Validation Loss: 0.0377,V Acc: 0.8273, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.5455
Fold [4/5] Epoch [30/100] Initial Loss: 0.1376, Training Loss: 0.0202, Initial Validation Loss: 0.1341, Validation Loss: 0.0376,V Acc: 0.8182, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 31  Rolling back to Epoch (base 0): 26  Top Validation Acc: 0.935064935064935
Fold [5/5] Epoch [0/100] Initial Loss: 0.1378, Training Loss: 0.1378, Initial Validation Loss: 0.1331, Validation Loss: 0.1331,V Acc: 0.3148, Top 70th Acc: 0.3421, Bottom 30th Acc: 0.2500
Fold [5/5] Epoch [10/100] Initial Loss: 0.1378, Training Loss: 0.0402, Initial Validation Loss: 0.1331, Validation Loss: 0.0513,V Acc: 0.7778, Top 70th Acc: 0.8421, Bottom 30th Acc: 0.6250
Fold [5/5] Epoch [20/100] Initial Loss: 0.1378, Training Loss: 0.0209, Initial Validation Loss: 0.1331, Validation Loss: 0.0418,V Acc: 0.7870, Top 70th Acc: 0.8684, Bottom 30th Acc: 0.5938
Fold [5/5] Epoch [30/100] Initial Loss: 0.1378, Training Loss: 0.0183, Initial Validation Loss: 0.1331, Validation Loss: 0.0410,V Acc: 0.8148, Top 70th Acc: 0.8816, Bottom 30th Acc: 0.6562
Stopping early at Epoch (base 0): 36  Rolling back to Epoch (base 0): 31  Top Validation Acc: 0.881578947368421
Running train_nn.py with seed 2
CUDA:False
Training samples count:  550
Training on 20 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1375, Training Loss: 0.1375, Initial Validation Loss: 0.1368, Validation Loss: 0.1368,V Acc: 0.2883, Top 70th Acc: 0.3333, Bottom 30th Acc: 0.1818
Fold [1/5] Epoch [10/100] Initial Loss: 0.1375, Training Loss: 0.0440, Initial Validation Loss: 0.1368, Validation Loss: 0.0460,V Acc: 0.7928, Top 70th Acc: 0.8974, Bottom 30th Acc: 0.5455
Fold [1/5] Epoch [20/100] Initial Loss: 0.1375, Training Loss: 0.0251, Initial Validation Loss: 0.1368, Validation Loss: 0.0311,V Acc: 0.8829, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.6970
Fold [1/5] Epoch [30/100] Initial Loss: 0.1375, Training Loss: 0.0218, Initial Validation Loss: 0.1368, Validation Loss: 0.0335,V Acc: 0.8649, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 31  Rolling back to Epoch (base 0): 26  Top Validation Acc: 0.9615384615384616
2 0 [array([0.3979143 , 0.1522999 , 0.12403055, 0.24167192, 0.08408335],
      dtype=float32)]
Fold [2/5] Epoch [0/100] Initial Loss: 0.1375, Training Loss: 0.1375, Initial Validation Loss: 0.1373, Validation Loss: 0.1373,V Acc: 0.2793, Top 70th Acc: 0.3462, Bottom 30th Acc: 0.1212
Fold [2/5] Epoch [10/100] Initial Loss: 0.1375, Training Loss: 0.0406, Initial Validation Loss: 0.1373, Validation Loss: 0.0399,V Acc: 0.8649, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.6970
Fold [2/5] Epoch [20/100] Initial Loss: 0.1375, Training Loss: 0.0240, Initial Validation Loss: 0.1373, Validation Loss: 0.0345,V Acc: 0.8649, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.7273
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.9358974358974359
Fold [3/5] Epoch [0/100] Initial Loss: 0.1400, Training Loss: 0.1400, Initial Validation Loss: 0.1334, Validation Loss: 0.1334,V Acc: 0.2545, Top 70th Acc: 0.3377, Bottom 30th Acc: 0.0606
Fold [3/5] Epoch [10/100] Initial Loss: 0.1400, Training Loss: 0.0327, Initial Validation Loss: 0.1334, Validation Loss: 0.0402,V Acc: 0.7909, Top 70th Acc: 0.8961, Bottom 30th Acc: 0.5455
Fold [3/5] Epoch [20/100] Initial Loss: 0.1400, Training Loss: 0.0235, Initial Validation Loss: 0.1334, Validation Loss: 0.0342,V Acc: 0.8182, Top 70th Acc: 0.8961, Bottom 30th Acc: 0.6364
Fold [3/5] Epoch [30/100] Initial Loss: 0.1400, Training Loss: 0.0220, Initial Validation Loss: 0.1334, Validation Loss: 0.0337,V Acc: 0.8182, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 30  Rolling back to Epoch (base 0): 25  Top Validation Acc: 0.9090909090909091
Fold [4/5] Epoch [0/100] Initial Loss: 0.1391, Training Loss: 0.1391, Initial Validation Loss: 0.1328, Validation Loss: 0.1328,V Acc: 0.3273, Top 70th Acc: 0.3377, Bottom 30th Acc: 0.3030
Fold [4/5] Epoch [10/100] Initial Loss: 0.1391, Training Loss: 0.0306, Initial Validation Loss: 0.1328, Validation Loss: 0.0398,V Acc: 0.8000, Top 70th Acc: 0.8961, Bottom 30th Acc: 0.5758
Fold [4/5] Epoch [20/100] Initial Loss: 0.1391, Training Loss: 0.0230, Initial Validation Loss: 0.1328, Validation Loss: 0.0378,V Acc: 0.8182, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 22  Rolling back to Epoch (base 0): 17  Top Validation Acc: 0.9090909090909091
Fold [5/5] Epoch [0/100] Initial Loss: 0.1447, Training Loss: 0.1447, Initial Validation Loss: 0.1292, Validation Loss: 0.1292,V Acc: 0.3426, Top 70th Acc: 0.3816, Bottom 30th Acc: 0.2500
Fold [5/5] Epoch [10/100] Initial Loss: 0.1447, Training Loss: 0.0390, Initial Validation Loss: 0.1292, Validation Loss: 0.0416,V Acc: 0.8056, Top 70th Acc: 0.9079, Bottom 30th Acc: 0.5625
Fold [5/5] Epoch [20/100] Initial Loss: 0.1447, Training Loss: 0.0298, Initial Validation Loss: 0.1292, Validation Loss: 0.0383,V Acc: 0.8148, Top 70th Acc: 0.9211, Bottom 30th Acc: 0.5625
Fold [5/5] Epoch [30/100] Initial Loss: 0.1447, Training Loss: 0.0239, Initial Validation Loss: 0.1292, Validation Loss: 0.0350,V Acc: 0.8426, Top 70th Acc: 0.9211, Bottom 30th Acc: 0.6562
Fold [5/5] Epoch [40/100] Initial Loss: 0.1447, Training Loss: 0.0214, Initial Validation Loss: 0.1292, Validation Loss: 0.0348,V Acc: 0.8426, Top 70th Acc: 0.9079, Bottom 30th Acc: 0.6875
Stopping early at Epoch (base 0):Running train_nn.py with seed 1
CUDA:False
Training samples count:  550
Training on 40 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1390, Training Loss: 0.1390, Initial Validation Loss: 0.1340, Validation Loss: 0.1340,V Acc: 0.3604, Top 70th Acc: 0.3462, Bottom 30th Acc: 0.3939
Fold [1/5] Epoch [10/100] Initial Loss: 0.1390, Training Loss: 0.0382, Initial Validation Loss: 0.1340, Validation Loss: 0.0368,V Acc: 0.8468, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.6970
Fold [1/5] Epoch [20/100] Initial Loss: 0.1390, Training Loss: 0.0205, Initial Validation Loss: 0.1340, Validation Loss: 0.0234,V Acc: 0.8829, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.6667
Fold [1/5] Epoch [30/100] Initial Loss: 0.1390, Training Loss: 0.0145, Initial Validation Loss: 0.1340, Validation Loss: 0.0168,V Acc: 0.9009, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.7273
Fold [1/5] Epoch [40/100] Initial Loss: 0.1390, Training Loss: 0.0124, Initial Validation Loss: 0.1340, Validation Loss: 0.0153,V Acc: 0.9009, Top 70th Acc: 0.9872, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 45  Rolling back to Epoch (base 0): 40  Top Validation Acc: 0.9871794871794872
1 0 [array([0.3887766 , 0.04396457, 0.22262888, 0.08029552, 0.2643344 ],
      dtype=float32)]
Fold [2/5] Epoch [0/100] Initial Loss: 0.1400, Training Loss: 0.1400, Initial Validation Loss: 0.1325, Validation Loss: 0.1325,V Acc: 0.2523, Top 70th Acc: 0.3590, Bottom 30th Acc: 0.0000
Fold [2/5] Epoch [10/100] Initial Loss: 0.1400, Training Loss: 0.0270, Initial Validation Loss: 0.1325, Validation Loss: 0.0342,V Acc: 0.8468, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.6970
Fold [2/5] Epoch [20/100] Initial Loss: 0.1400, Training Loss: 0.0134, Initial Validation Loss: 0.1325, Validation Loss: 0.0303,V Acc: 0.8288, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.9358974358974359
Fold [3/5] Epoch [0/100] Initial Loss: 0.1384, Training Loss: 0.1384, Initial Validation Loss: 0.1349, Validation Loss: 0.1349,V Acc: 0.2909, Top 70th Acc: 0.3506, Bottom 30th Acc: 0.1515
Fold [3/5] Epoch [10/100] Initial Loss: 0.1384, Training Loss: 0.0331, Initial Validation Loss: 0.1349, Validation Loss: 0.0435,V Acc: 0.7818, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.4545
Fold [3/5] Epoch [20/100] Initial Loss: 0.1384, Training Loss: 0.0164, Initial Validation Loss: 0.1349, Validation Loss: 0.0297,V Acc: 0.8455, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.5758
Fold [3/5] Epoch [30/100] Initial Loss: 0.1384, Training Loss: 0.0131, Initial Validation Loss: 0.1349, Validation Loss: 0.0278,V Acc: 0.8636, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 38  Rolling back to Epoch (base 0): 33  Top Validation Acc: 0.961038961038961
Fold [4/5] Epoch [0/100] Initial Loss: 0.1384, Training Loss: 0.1384, Initial Validation Loss: 0.1369, Validation Loss: 0.1369,V Acc: 0.2909, Top 70th Acc: 0.3117, Bottom 30th Acc: 0.2424
Fold [4/5] Epoch [10/100] Initial Loss: 0.1384, Training Loss: 0.0360, Initial Validation Loss: 0.1369, Validation Loss: 0.0456,V Acc: 0.7818, Top 70th Acc: 0.8831, Bottom 30th Acc: 0.5455
Fold [4/5] Epoch [20/100] Initial Loss: 0.1384, Training Loss: 0.0157, Initial Validation Loss: 0.1369, Validation Loss: 0.0298,V Acc: 0.8455, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.5758
Fold [4/5] Epoch [30/100] Initial Loss: 0.1384, Training Loss: 0.0120, Initial Validation Loss: 0.1369, Validation Loss: 0.0294,V Acc: 0.8182, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.4545
Stopping early at Epoch (base 0): 31  Rolling back to Epoch (base 0): 26  Top Validation Acc: 0.974025974025974
Fold [5/5] Epoch [0/100] Initial Loss: 0.1374, Training Loss: 0.1374, Initial Validation Loss: 0.1316, Validation Loss: 0.1316,V Acc: 0.3148, Top 70th Acc: 0.3816, Bottom 30th Acc: 0.1562
Fold [5/5] Epoch [10/100] Initial Loss: 0.1374, Training Loss: 0.0252, Initial Validation Loss: 0.1316, Validation Loss: 0.0413,V Acc: 0.8056, Top 70th Acc: 0.8816, Bottom 30th Acc: 0.6250
Fold [5/5] Epoch [20/100] Initial Loss: 0.1374, Training Loss: 0.0127, Initial Validation Loss: 0.1316, Validation Loss: 0.0356,V Acc: 0.8056, Top 70th Acc: 0.9211, Bottom 30th Acc: 0.5312
Fold [5/5] Epoch [30/100] Initial Loss: 0.1374, Training Loss: 0.0107, Initial Validation Loss: 0.1316, Validation Loss: 0.0345,V Acc: 0.8148, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.5312
Stopping early at Epoch (base 0): 35  Rolling back to Epoch (base 0): 30  Top Validation Acc: 0.9210526315789473
Running train_nn.py with seed 2
CUDA:False
Training samples count:  550
Training on 40 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1397, Training Loss: 0.1397, Initial Validation Loss: 0.1374, Validation Loss: 0.1374,V Acc: 0.2613, Top 70th Acc: 0.3077, Bottom 30th Acc: 0.1515
Fold [1/5] Epoch [10/100] Initial Loss: 0.1397, Training Loss: 0.0321, Initial Validation Loss: 0.1374, Validation Loss: 0.0411,V Acc: 0.8288, Top 70th Acc: 0.8846, Bottom 30th Acc: 0.6970
Fold [1/5] Epoch [20/100] Initial Loss: 0.1397, Training Loss: 0.0152, Initial Validation Loss: 0.1374, Validation Loss: 0.0319,V Acc: 0.8378, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 27  Rolling back to Epoch (base 0): 22  Top Validation Acc: 0.9358974358974359
2 0 [array([0.6155496 , 0.04371305, 0.07247044, 0.10406818, 0.1641987 ],
      dtype=float32)]
Fold [2/5] Epoch [0/100] Initial Loss: 0.1352, Training Loss: 0.1352, Initial Validation Loss: 0.1336, Validation Loss: 0.1336,V Acc: 0.3514, Top 70th Acc: 0.3974, Bottom 30th Acc: 0.2424
Fold [2/5] Epoch [10/100] Initial Loss: 0.1352, Training Loss: 0.0314, Initial Validation Loss: 0.1336, Validation Loss: 0.0367,V Acc: 0.7928, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.4242
Fold [2/5] Epoch [20/100] Initial Loss: 0.1352, Training Loss: 0.0149, Initial Validation Loss: 0.1336, Validation Loss: 0.0278,V Acc: 0.8559, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.5758
Fold [2/5] Epoch [30/100] Initial Loss: 0.1352, Training Loss: 0.0123, Initial Validation Loss: 0.1336, Validation Loss: 0.0273,V Acc: 0.8288, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.4848
Fold [2/5] Epoch [40/100] Initial Loss: 0.1352, Training Loss: 0.0113, Initial Validation Loss: 0.1336, Validation Loss: 0.0272,V Acc: 0.8468, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 46  Rolling back to Epoch (base 0): 41  Top Validation Acc: 0.9743589743589743
Fold [3/5] Epoch [0/100] Initial Loss: 0.1434, Training Loss: 0.1434, Initial Validation Loss: 0.1329, Validation Loss: 0.1329,V Acc: 0.3273, Top 70th Acc: 0.3377, Bottom 30th Acc: 0.3030
Fold [3/5] Epoch [10/100] Initial Loss: 0.1434, Training Loss: 0.0343, Initial Validation Loss: 0.1329, Validation Loss: 0.0405,V Acc: 0.8000, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.5455
Fold [3/5] Epoch [20/100] Initial Loss: 0.1434, Training Loss: 0.0144, Initial Validation Loss: 0.1329, Validation Loss: 0.0305,V Acc: 0.8273, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.5455
Fold [3/5] Epoch [30/100] Initial Loss: 0.1434, Training Loss: 0.0117, Initial Validation Loss: 0.1329, Validation Loss: 0.0290,V Acc: 0.8818, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.7273
Stopping early at Epoch (base 0): 31  Rolling back to Epoch (base 0): 26  Top Validation Acc: 0.948051948051948
Fold [4/5] Epoch [0/100] Initial Loss: 0.1356, Training Loss: 0.1356, Initial Validation Loss: 0.1305, Validation Loss: 0.1305,V Acc: 0.3545, Top 70th Acc: 0.3766, Bottom 30th Acc: 0.3030
Fold [4/5] Epoch [10/100] Initial Loss: 0.1356, Training Loss: 0.0233, Initial Validation Loss: 0.1305, Validation Loss: 0.0299,V Acc: 0.8636, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.6364
Fold [4/5] Epoch [20/100] Initial Loss: 0.1356, Training Loss: 0.0133, Initial Validation Loss: 0.1305, Validation Loss: 0.0271,V Acc: 0.8636, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.948051948051948
Fold [5/5] Epoch [0/100] Initial Loss: 0.1415, Training Loss: 0.1415, Initial Validation Loss: 0.1316, Validation Loss: 0.1316,V Acc: 0.2500, Top 70th Acc: 0.3026, Bottom 30th Acc: 0.1250
Fold [5/5] Epoch [10/100] Initial Loss: 0.1415, Training Loss: 0.0316, Initial Validation Loss: 0.1316, Validation Loss: 0.0397,V Acc: 0.8333, Top 70th Acc: 0.9079, Bottom 30th Acc: 0.6562Running train_nn.py with seed 1
CUDA:False
Training samples count:  550
Training on 30 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1383, Training Loss: 0.1383, Initial Validation Loss: 0.1353, Validation Loss: 0.1353,V Acc: 0.2523, Top 70th Acc: 0.3205, Bottom 30th Acc: 0.0909
Fold [1/5] Epoch [10/100] Initial Loss: 0.1383, Training Loss: 0.0416, Initial Validation Loss: 0.1353, Validation Loss: 0.0352,V Acc: 0.8559, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.6667
Fold [1/5] Epoch [20/100] Initial Loss: 0.1383, Training Loss: 0.0219, Initial Validation Loss: 0.1353, Validation Loss: 0.0230,V Acc: 0.9009, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.7576
Stopping early at Epoch (base 0): 22  Rolling back to Epoch (base 0): 17  Top Validation Acc: 0.9615384615384616
1 0 [array([0.5217886 , 0.06849745, 0.04966893, 0.14575815, 0.21428695],
      dtype=float32)]
Fold [2/5] Epoch [0/100] Initial Loss: 0.1381, Training Loss: 0.1381, Initial Validation Loss: 0.1317, Validation Loss: 0.1317,V Acc: 0.2613, Top 70th Acc: 0.3590, Bottom 30th Acc: 0.0303
Fold [2/5] Epoch [10/100] Initial Loss: 0.1381, Training Loss: 0.0357, Initial Validation Loss: 0.1317, Validation Loss: 0.0416,V Acc: 0.8559, Top 70th Acc: 0.8718, Bottom 30th Acc: 0.8182
Fold [2/5] Epoch [20/100] Initial Loss: 0.1381, Training Loss: 0.0235, Initial Validation Loss: 0.1317, Validation Loss: 0.0355,V Acc: 0.8378, Top 70th Acc: 0.8846, Bottom 30th Acc: 0.7273
Fold [2/5] Epoch [30/100] Initial Loss: 0.1381, Training Loss: 0.0181, Initial Validation Loss: 0.1317, Validation Loss: 0.0346,V Acc: 0.8559, Top 70th Acc: 0.8718, Bottom 30th Acc: 0.8182
Fold [2/5] Epoch [40/100] Initial Loss: 0.1381, Training Loss: 0.0154, Initial Validation Loss: 0.1317, Validation Loss: 0.0318,V Acc: 0.8468, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 47  Rolling back to Epoch (base 0): 42  Top Validation Acc: 0.9230769230769231
Fold [3/5] Epoch [0/100] Initial Loss: 0.1409, Training Loss: 0.1409, Initial Validation Loss: 0.1347, Validation Loss: 0.1347,V Acc: 0.2545, Top 70th Acc: 0.3247, Bottom 30th Acc: 0.0909
Fold [3/5] Epoch [10/100] Initial Loss: 0.1409, Training Loss: 0.0354, Initial Validation Loss: 0.1347, Validation Loss: 0.0451,V Acc: 0.7909, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.5152
Fold [3/5] Epoch [20/100] Initial Loss: 0.1409, Training Loss: 0.0195, Initial Validation Loss: 0.1347, Validation Loss: 0.0357,V Acc: 0.8273, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.6364
Fold [3/5] Epoch [30/100] Initial Loss: 0.1409, Training Loss: 0.0161, Initial Validation Loss: 0.1347, Validation Loss: 0.0348,V Acc: 0.8364, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 30  Rolling back to Epoch (base 0): 25  Top Validation Acc: 0.922077922077922
Fold [4/5] Epoch [0/100] Initial Loss: 0.1340, Training Loss: 0.1340, Initial Validation Loss: 0.1318, Validation Loss: 0.1318,V Acc: 0.4182, Top 70th Acc: 0.4935, Bottom 30th Acc: 0.2424
Fold [4/5] Epoch [10/100] Initial Loss: 0.1340, Training Loss: 0.0342, Initial Validation Loss: 0.1318, Validation Loss: 0.0434,V Acc: 0.7727, Top 70th Acc: 0.8961, Bottom 30th Acc: 0.4848
Fold [4/5] Epoch [20/100] Initial Loss: 0.1340, Training Loss: 0.0190, Initial Validation Loss: 0.1318, Validation Loss: 0.0333,V Acc: 0.8455, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.961038961038961
Fold [5/5] Epoch [0/100] Initial Loss: 0.1349, Training Loss: 0.1349, Initial Validation Loss: 0.1280, Validation Loss: 0.1280,V Acc: 0.3796, Top 70th Acc: 0.5000, Bottom 30th Acc: 0.0938
Fold [5/5] Epoch [10/100] Initial Loss: 0.1349, Training Loss: 0.0255, Initial Validation Loss: 0.1280, Validation Loss: 0.0394,V Acc: 0.8241, Top 70th Acc: 0.9211, Bottom 30th Acc: 0.5938
Fold [5/5] Epoch [20/100] Initial Loss: 0.1349, Training Loss: 0.0157, Initial Validation Loss: 0.1280, Validation Loss: 0.0367,V Acc: 0.8333, Top 70th Acc: 0.9211, Bottom 30th Acc: 0.6250
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.9210526315789473
Running train_nn.py with seed 2
CUDA:False
Training samples count:  550
Training on 30 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1381, Training Loss: 0.1381, Initial Validation Loss: 0.1382, Validation Loss: 0.1382,V Acc: 0.2703, Top 70th Acc: 0.3462, Bottom 30th Acc: 0.0909
Fold [1/5] Epoch [10/100] Initial Loss: 0.1381, Training Loss: 0.0405, Initial Validation Loss: 0.1382, Validation Loss: 0.0491,V Acc: 0.7838, Top 70th Acc: 0.8846, Bottom 30th Acc: 0.5455
Fold [1/5] Epoch [20/100] Initial Loss: 0.1381, Training Loss: 0.0243, Initial Validation Loss: 0.1382, Validation Loss: 0.0372,V Acc: 0.8198, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.5455
Fold [1/5] Epoch [30/100] Initial Loss: 0.1381, Training Loss: 0.0164, Initial Validation Loss: 0.1382, Validation Loss: 0.0323,V Acc: 0.8378, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.5152
Stopping early at Epoch (base 0): 36  Rolling back to Epoch (base 0): 31  Top Validation Acc: 0.9487179487179487
2 0 [array([0.73210907, 0.06763531, 0.04232624, 0.09465796, 0.06327145],
      dtype=float32)]
Fold [2/5] Epoch [0/100] Initial Loss: 0.1372, Training Loss: 0.1372, Initial Validation Loss: 0.1358, Validation Loss: 0.1358,V Acc: 0.2793, Top 70th Acc: 0.3333, Bottom 30th Acc: 0.1515
Fold [2/5] Epoch [10/100] Initial Loss: 0.1372, Training Loss: 0.0404, Initial Validation Loss: 0.1358, Validation Loss: 0.0435,V Acc: 0.8108, Top 70th Acc: 0.8974, Bottom 30th Acc: 0.6061
Fold [2/5] Epoch [20/100] Initial Loss: 0.1372, Training Loss: 0.0186, Initial Validation Loss: 0.1358, Validation Loss: 0.0269,V Acc: 0.8829, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.6970
Fold [2/5] Epoch [30/100] Initial Loss: 0.1372, Training Loss: 0.0153, Initial Validation Loss: 0.1358, Validation Loss: 0.0250,V Acc: 0.8829, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.6970
Fold [2/5] Epoch [40/100] Initial Loss: 0.1372, Training Loss: 0.0146, Initial Validation Loss: 0.1358, Validation Loss: 0.0244,V Acc: 0.8919, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.7576
Stopping early at Epoch (base 0): 40  Rolling back to Epoch (base 0): 35  Top Validation Acc: 0.9487179487179487
Fold [3/5] Epoch [0/100] Initial Loss: 0.1386, Training Loss: 0.1386, Initial Validation Loss: 0.1321, Validation Loss: 0.1321,V Acc: 0.2818, Top 70th Acc: 0.2857, Bottom 30th Acc: 0.2727
Fold [3/5] Epoch [10/100] Initial Loss: 0.1386, Training Loss: 0.0292, Initial Validation Loss: 0.1321, Validation Loss: 0.0339,V Acc: 0.8364, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.5758
Fold [3/5] Epoch [20/100] Initial Loss: 0.1386, Training Loss: 0.0169, Initial Validation Loss: 0.1321, Validation Loss: 0.0261,V Acc: 0.8818, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.961038961038961
Fold [4/5] Epoch [0/100] Initial Loss: 0.1443, Training Loss: 0.1443, Initial Validation Loss: 0.1356, Validation Loss: 0.1356,V Acc: 0.2545, Top 70th Acc: 0.3636, Bottom 30th Acc: 0.0000
Fold [4/5] Epoch [10/100] Initial Loss: 0.1443, Training Loss: 0.0264, Initial Validation Loss: 0.1356, Validation Loss: 0.0324,V Acc: 0.8818, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.6667
Fold [4/5] Epoch [20/100] Initial Loss: 0.1443, Training Loss: 0.0174, Initial Validation Loss: 0.1356, Validation Loss: 0.0293,V Acc: 0.8727, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 22  Rolling back to Epoch (base 0): 17  Top Validation Acc: 0.961038961038961
Fold [5/5] Epoch [0/100] Initial Loss: 0.1384, Training Loss: 0.1384, Initial Validation Loss: 0.1324, Validation Loss: 0.1324,V Acc: 0.2778, Top 70th Acc: 0.2895, Bottom 30th Acc: 0.2500
Fold [5/5] Epoch [10/100] Initial Loss: 0.1384, Training Loss: 0.0308, Initial Validation Loss: 0.1324, Validation Loss: 0.0396,V Acc: 0.7870, Top 70th Acc: 0.9079, Bottom 30th Acc: 0.5000
Fold [5/5] Epoch [20/100] Initial Loss: 0.1384, Training Loss: 0.0162, Initial Validation Loss: 0.1324, Validation Loss: 0.0350,V Acc: 0.8148, Top 70th Acc: 0.9211, Bottom 30th Acc: 0.5625
Stopping early at Epoch (base 0):Running train_nn.py with seed 1
CUDA:False
Training samples count:  550
Training on 2 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1344, Training Loss: 0.1344, Initial Validation Loss: 0.1266, Validation Loss: 0.1266,V Acc: 0.3874, Top 70th Acc: 0.3590, Bottom 30th Acc: 0.4545
Fold [1/5] Epoch [10/100] Initial Loss: 0.1344, Training Loss: 0.0830, Initial Validation Loss: 0.1266, Validation Loss: 0.0736,V Acc: 0.6486, Top 70th Acc: 0.7949, Bottom 30th Acc: 0.3030
Fold [1/5] Epoch [20/100] Initial Loss: 0.1344, Training Loss: 0.0817, Initial Validation Loss: 0.1266, Validation Loss: 0.0732,V Acc: 0.6486, Top 70th Acc: 0.8205, Bottom 30th Acc: 0.2424
Stopping early at Epoch (base 0): 28  Rolling back to Epoch (base 0): 23  Top Validation Acc: 0.7948717948717948
1 0 [array([0.1487126 , 0.3076577 , 0.17644444, 0.22778988, 0.13939537],
      dtype=float32)]
Fold [2/5] Epoch [0/100] Initial Loss: 0.1414, Training Loss: 0.1414, Initial Validation Loss: 0.1340, Validation Loss: 0.1340,V Acc: 0.3874, Top 70th Acc: 0.3205, Bottom 30th Acc: 0.5455
Fold [2/5] Epoch [10/100] Initial Loss: 0.1414, Training Loss: 0.0828, Initial Validation Loss: 0.1340, Validation Loss: 0.0786,V Acc: 0.6486, Top 70th Acc: 0.7308, Bottom 30th Acc: 0.4545
Fold [2/5] Epoch [20/100] Initial Loss: 0.1414, Training Loss: 0.0800, Initial Validation Loss: 0.1340, Validation Loss: 0.0763,V Acc: 0.6577, Top 70th Acc: 0.7179, Bottom 30th Acc: 0.5152
Fold [2/5] Epoch [30/100] Initial Loss: 0.1414, Training Loss: 0.0789, Initial Validation Loss: 0.1340, Validation Loss: 0.0758,V Acc: 0.6486, Top 70th Acc: 0.7308, Bottom 30th Acc: 0.4545
Fold [2/5] Epoch [40/100] Initial Loss: 0.1414, Training Loss: 0.0781, Initial Validation Loss: 0.1340, Validation Loss: 0.0757,V Acc: 0.6667, Top 70th Acc: 0.7051, Bottom 30th Acc: 0.5758
Fold [2/5] Epoch [50/100] Initial Loss: 0.1414, Training Loss: 0.0778, Initial Validation Loss: 0.1340, Validation Loss: 0.0755,V Acc: 0.6847, Top 70th Acc: 0.7051, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 57  Rolling back to Epoch (base 0): 52  Top Validation Acc: 0.717948717948718
Fold [3/5] Epoch [0/100] Initial Loss: 0.1364, Training Loss: 0.1364, Initial Validation Loss: 0.1288, Validation Loss: 0.1288,V Acc: 0.3364, Top 70th Acc: 0.4026, Bottom 30th Acc: 0.1818
Fold [3/5] Epoch [10/100] Initial Loss: 0.1364, Training Loss: 0.0788, Initial Validation Loss: 0.1288, Validation Loss: 0.0840,V Acc: 0.6000, Top 70th Acc: 0.7143, Bottom 30th Acc: 0.3333
Fold [3/5] Epoch [20/100] Initial Loss: 0.1364, Training Loss: 0.0773, Initial Validation Loss: 0.1288, Validation Loss: 0.0843,V Acc: 0.5818, Top 70th Acc: 0.6753, Bottom 30th Acc: 0.3636
Stopping early at Epoch (base 0): 22  Rolling back to Epoch (base 0): 17  Top Validation Acc: 0.7012987012987013
Fold [4/5] Epoch [0/100] Initial Loss: 0.1346, Training Loss: 0.1346, Initial Validation Loss: 0.1270, Validation Loss: 0.1270,V Acc: 0.4364, Top 70th Acc: 0.4545, Bottom 30th Acc: 0.3939
Fold [4/5] Epoch [10/100] Initial Loss: 0.1346, Training Loss: 0.0778, Initial Validation Loss: 0.1270, Validation Loss: 0.0912,V Acc: 0.5909, Top 70th Acc: 0.6753, Bottom 30th Acc: 0.3939
Fold [4/5] Epoch [20/100] Initial Loss: 0.1346, Training Loss: 0.0755, Initial Validation Loss: 0.1270, Validation Loss: 0.0889,V Acc: 0.5818, Top 70th Acc: 0.7013, Bottom 30th Acc: 0.3030
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.6883116883116883
Fold [5/5] Epoch [0/100] Initial Loss: 0.1374, Training Loss: 0.1374, Initial Validation Loss: 0.1276, Validation Loss: 0.1276,V Acc: 0.2500, Top 70th Acc: 0.3553, Bottom 30th Acc: 0.0000
Fold [5/5] Epoch [10/100] Initial Loss: 0.1374, Training Loss: 0.0815, Initial Validation Loss: 0.1276, Validation Loss: 0.0736,V Acc: 0.6389, Top 70th Acc: 0.7763, Bottom 30th Acc: 0.3125
Fold [5/5] Epoch [20/100] Initial Loss: 0.1374, Training Loss: 0.0794, Initial Validation Loss: 0.1276, Validation Loss: 0.0714,V Acc: 0.6389, Top 70th Acc: 0.7895, Bottom 30th Acc: 0.2812
Stopping early at Epoch (base 0): 27  Rolling back to Epoch (base 0): 22  Top Validation Acc: 0.7894736842105263
Running train_nn.py with seed 2
CUDA:False
Training samples count:  550
Training on 2 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1372, Training Loss: 0.1372, Initial Validation Loss: 0.1357, Validation Loss: 0.1357,V Acc: 0.2523, Top 70th Acc: 0.3462, Bottom 30th Acc: 0.0303
Fold [1/5] Epoch [10/100] Initial Loss: 0.1372, Training Loss: 0.0800, Initial Validation Loss: 0.1357, Validation Loss: 0.0831,V Acc: 0.6036, Top 70th Acc: 0.7308, Bottom 30th Acc: 0.3030
Fold [1/5] Epoch [20/100] Initial Loss: 0.1372, Training Loss: 0.0779, Initial Validation Loss: 0.1357, Validation Loss: 0.0813,V Acc: 0.6036, Top 70th Acc: 0.7821, Bottom 30th Acc: 0.1818
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.7307692307692307
2 0 [array([0.13224082, 0.39458925, 0.12881519, 0.21041355, 0.13394128],
      dtype=float32)]
Fold [2/5] Epoch [0/100] Initial Loss: 0.1340, Training Loss: 0.1340, Initial Validation Loss: 0.1285, Validation Loss: 0.1285,V Acc: 0.4324, Top 70th Acc: 0.5256, Bottom 30th Acc: 0.2121
Fold [2/5] Epoch [10/100] Initial Loss: 0.1340, Training Loss: 0.0809, Initial Validation Loss: 0.1285, Validation Loss: 0.0844,V Acc: 0.6216, Top 70th Acc: 0.7051, Bottom 30th Acc: 0.4242
Fold [2/5] Epoch [20/100] Initial Loss: 0.1340, Training Loss: 0.0787, Initial Validation Loss: 0.1285, Validation Loss: 0.0823,V Acc: 0.6216, Top 70th Acc: 0.7179, Bottom 30th Acc: 0.3939
Fold [2/5] Epoch [30/100] Initial Loss: 0.1340, Training Loss: 0.0774, Initial Validation Loss: 0.1285, Validation Loss: 0.0811,V Acc: 0.6486, Top 70th Acc: 0.7308, Bottom 30th Acc: 0.4545
Fold [2/5] Epoch [40/100] Initial Loss: 0.1340, Training Loss: 0.0769, Initial Validation Loss: 0.1285, Validation Loss: 0.0798,V Acc: 0.6667, Top 70th Acc: 0.7308, Bottom 30th Acc: 0.5152
Fold [2/5] Epoch [50/100] Initial Loss: 0.1340, Training Loss: 0.0766, Initial Validation Loss: 0.1285, Validation Loss: 0.0794,V Acc: 0.6396, Top 70th Acc: 0.7051, Bottom 30th Acc: 0.4848
Stopping early at Epoch (base 0): 56  Rolling back to Epoch (base 0): 51  Top Validation Acc: 0.7051282051282052
Fold [3/5] Epoch [0/100] Initial Loss: 0.1329, Training Loss: 0.1329, Initial Validation Loss: 0.1170, Validation Loss: 0.1170,V Acc: 0.5182, Top 70th Acc: 0.5844, Bottom 30th Acc: 0.3636
Fold [3/5] Epoch [10/100] Initial Loss: 0.1329, Training Loss: 0.0821, Initial Validation Loss: 0.1170, Validation Loss: 0.0744,V Acc: 0.6091, Top 70th Acc: 0.7273, Bottom 30th Acc: 0.3333
Fold [3/5] Epoch [20/100] Initial Loss: 0.1329, Training Loss: 0.0803, Initial Validation Loss: 0.1170, Validation Loss: 0.0731,V Acc: 0.6091, Top 70th Acc: 0.7273, Bottom 30th Acc: 0.3333
Stopping early at Epoch (base 0): 27  Rolling back to Epoch (base 0): 22  Top Validation Acc: 0.7272727272727273
Fold [4/5] Epoch [0/100] Initial Loss: 0.1393, Training Loss: 0.1393, Initial Validation Loss: 0.1322, Validation Loss: 0.1322,V Acc: 0.3636, Top 70th Acc: 0.5065, Bottom 30th Acc: 0.0303
Fold [4/5] Epoch [10/100] Initial Loss: 0.1393, Training Loss: 0.0805, Initial Validation Loss: 0.1322, Validation Loss: 0.0813,V Acc: 0.6182, Top 70th Acc: 0.7662, Bottom 30th Acc: 0.2727
Stopping early at Epoch (base 0): 19  Rolling back to Epoch (base 0): 14  Top Validation Acc: 0.7402597402597403
Fold [5/5] Epoch [0/100] Initial Loss: 0.1379, Training Loss: 0.1379, Initial Validation Loss: 0.1242, Validation Loss: 0.1242,V Acc: 0.4259, Top 70th Acc: 0.5000, Bottom 30th Acc: 0.2500
Fold [5/5] Epoch [10/100] Initial Loss: 0.1379, Training Loss: 0.0810, Initial Validation Loss: 0.1242, Validation Loss: 0.0797,V Acc: 0.6296, Top 70th Acc: 0.7632, Bottom 30th Acc: 0.3125
Fold [5/5] Epoch [20/100] Initial Loss: 0.1379, Training Loss: 0.0788, Initial Validation Loss: 0.1242, Validation Loss: 0.0769,V Acc: 0.6389, Top 70th Acc: 0.7763, Bottom 30th Acc: 0.3125
Stopping early at Epoch (base 0): 29  Rolling back to Epoch (base 0): 24  Top Validation Acc: 0.7763157894736842
Running train_nn.py with seed 3
CUDA:False
Training samples count:  550
Training on 2 featuresRunning train_nn.py with seed 1
CUDA:False
Training samples count:  550
Training on 163 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1394, Training Loss: 0.1394, Initial Validation Loss: 0.1347, Validation Loss: 0.1347,V Acc: 0.3423, Top 70th Acc: 0.3846, Bottom 30th Acc: 0.2424
Fold [1/5] Epoch [10/100] Initial Loss: 0.1394, Training Loss: 0.0183, Initial Validation Loss: 0.1347, Validation Loss: 0.0267,V Acc: 0.9099, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.7576
Fold [1/5] Epoch [20/100] Initial Loss: 0.1394, Training Loss: 0.0051, Initial Validation Loss: 0.1347, Validation Loss: 0.0235,V Acc: 0.9009, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.7273
Stopping early at Epoch (base 0): 20  Rolling back to Epoch (base 0): 15  Top Validation Acc: 0.9743589743589743
1 0 [array([0.18903649, 0.03528051, 0.07075659, 0.21658991, 0.48833647],
      dtype=float32)]
Fold [2/5] Epoch [0/100] Initial Loss: 0.1418, Training Loss: 0.1418, Initial Validation Loss: 0.1356, Validation Loss: 0.1356,V Acc: 0.2613, Top 70th Acc: 0.3077, Bottom 30th Acc: 0.1515
Fold [2/5] Epoch [10/100] Initial Loss: 0.1418, Training Loss: 0.0138, Initial Validation Loss: 0.1356, Validation Loss: 0.0299,V Acc: 0.8468, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.6667
Fold [2/5] Epoch [20/100] Initial Loss: 0.1418, Training Loss: 0.0050, Initial Validation Loss: 0.1356, Validation Loss: 0.0266,V Acc: 0.8739, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.9615384615384616
Fold [3/5] Epoch [0/100] Initial Loss: 0.1351, Training Loss: 0.1351, Initial Validation Loss: 0.1280, Validation Loss: 0.1280,V Acc: 0.4455, Top 70th Acc: 0.5714, Bottom 30th Acc: 0.1515
Fold [3/5] Epoch [10/100] Initial Loss: 0.1351, Training Loss: 0.0138, Initial Validation Loss: 0.1280, Validation Loss: 0.0296,V Acc: 0.8273, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.4848
Fold [3/5] Epoch [20/100] Initial Loss: 0.1351, Training Loss: 0.0049, Initial Validation Loss: 0.1280, Validation Loss: 0.0256,V Acc: 0.8455, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 20  Rolling back to Epoch (base 0): 15  Top Validation Acc: 0.974025974025974
Fold [4/5] Epoch [0/100] Initial Loss: 0.1406, Training Loss: 0.1406, Initial Validation Loss: 0.1372, Validation Loss: 0.1372,V Acc: 0.2545, Top 70th Acc: 0.2987, Bottom 30th Acc: 0.1515
Fold [4/5] Epoch [10/100] Initial Loss: 0.1406, Training Loss: 0.0196, Initial Validation Loss: 0.1372, Validation Loss: 0.0405,V Acc: 0.8091, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.5455
Fold [4/5] Epoch [20/100] Initial Loss: 0.1406, Training Loss: 0.0059, Initial Validation Loss: 0.1372, Validation Loss: 0.0399,V Acc: 0.8000, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.4848
Stopping early at Epoch (base 0): 21  Rolling back to Epoch (base 0): 16  Top Validation Acc: 0.922077922077922
Fold [5/5] Epoch [0/100] Initial Loss: 0.1385, Training Loss: 0.1385, Initial Validation Loss: 0.1338, Validation Loss: 0.1338,V Acc: 0.2500, Top 70th Acc: 0.3026, Bottom 30th Acc: 0.1250
Fold [5/5] Epoch [10/100] Initial Loss: 0.1385, Training Loss: 0.0162, Initial Validation Loss: 0.1338, Validation Loss: 0.0393,V Acc: 0.8056, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.5000
Fold [5/5] Epoch [20/100] Initial Loss: 0.1385, Training Loss: 0.0043, Initial Validation Loss: 0.1338, Validation Loss: 0.0358,V Acc: 0.8241, Top 70th Acc: 0.9211, Bottom 30th Acc: 0.5938
Stopping early at Epoch (base 0): 22  Rolling back to Epoch (base 0): 17  Top Validation Acc: 0.9210526315789473
Running train_nn.py with seed 2
CUDA:False
Training samples count:  550
Training on 163 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1391, Training Loss: 0.1391, Initial Validation Loss: 0.1371, Validation Loss: 0.1371,V Acc: 0.3694, Top 70th Acc: 0.3846, Bottom 30th Acc: 0.3333
Fold [1/5] Epoch [10/100] Initial Loss: 0.1391, Training Loss: 0.0191, Initial Validation Loss: 0.1371, Validation Loss: 0.0416,V Acc: 0.8468, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.6667
Fold [1/5] Epoch [20/100] Initial Loss: 0.1391, Training Loss: 0.0065, Initial Validation Loss: 0.1371, Validation Loss: 0.0343,V Acc: 0.8468, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.6061
Fold [1/5] Epoch [30/100] Initial Loss: 0.1391, Training Loss: 0.0047, Initial Validation Loss: 0.1371, Validation Loss: 0.0330,V Acc: 0.8288, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.5455
Fold [1/5] Epoch [40/100] Initial Loss: 0.1391, Training Loss: 0.0042, Initial Validation Loss: 0.1371, Validation Loss: 0.0310,V Acc: 0.8468, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.5455
Fold [1/5] Epoch [50/100] Initial Loss: 0.1391, Training Loss: 0.0038, Initial Validation Loss: 0.1371, Validation Loss: 0.0298,V Acc: 0.8559, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.6061
Fold [1/5] Epoch [60/100] Initial Loss: 0.1391, Training Loss: 0.0036, Initial Validation Loss: 0.1371, Validation Loss: 0.0288,V Acc: 0.8468, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.5758
Fold [1/5] Epoch [70/100] Initial Loss: 0.1391, Training Loss: 0.0035, Initial Validation Loss: 0.1371, Validation Loss: 0.0284,V Acc: 0.8559, Top 70th Acc: 0.9872, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 70  Rolling back to Epoch (base 0): 65  Top Validation Acc: 0.9871794871794872
2 0 [array([0.29332802, 0.04229876, 0.07732371, 0.21977414, 0.36727536],
      dtype=float32)]
Fold [2/5] Epoch [0/100] Initial Loss: 0.1361, Training Loss: 0.1361, Initial Validation Loss: 0.1344, Validation Loss: 0.1344,V Acc: 0.3063, Top 70th Acc: 0.3590, Bottom 30th Acc: 0.1818
Fold [2/5] Epoch [10/100] Initial Loss: 0.1361, Training Loss: 0.0125, Initial Validation Loss: 0.1344, Validation Loss: 0.0260,V Acc: 0.8559, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.5758
Fold [2/5] Epoch [20/100] Initial Loss: 0.1361, Training Loss: 0.0048, Initial Validation Loss: 0.1344, Validation Loss: 0.0224,V Acc: 0.8739, Top 70th Acc: 0.9872, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 20  Rolling back to Epoch (base 0): 15  Top Validation Acc: 0.9871794871794872
Fold [3/5] Epoch [0/100] Initial Loss: 0.1431, Training Loss: 0.1431, Initial Validation Loss: 0.1319, Validation Loss: 0.1319,V Acc: 0.2636, Top 70th Acc: 0.3247, Bottom 30th Acc: 0.1212
Fold [3/5] Epoch [10/100] Initial Loss: 0.1431, Training Loss: 0.0177, Initial Validation Loss: 0.1319, Validation Loss: 0.0340,V Acc: 0.8091, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.5455
Fold [3/5] Epoch [20/100] Initial Loss: 0.1431, Training Loss: 0.0048, Initial Validation Loss: 0.1319, Validation Loss: 0.0270,V Acc: 0.8364, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 28  Rolling back to Epoch (base 0): 23  Top Validation Acc: 0.948051948051948
Fold [4/5] Epoch [0/100] Initial Loss: 0.1389, Training Loss: 0.1389, Initial Validation Loss: 0.1339, Validation Loss: 0.1339,V Acc: 0.2636, Top 70th Acc: 0.3377, Bottom 30th Acc: 0.0909
Fold [4/5] Epoch [10/100] Initial Loss: 0.1389, Training Loss: 0.0185, Initial Validation Loss: 0.1339, Validation Loss: 0.0381,V Acc: 0.8273, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.6364
Fold [4/5] Epoch [20/100] Initial Loss: 0.1389, Training Loss: 0.0050, Initial Validation Loss: 0.1339, Validation Loss: 0.0287,V Acc: 0.8545, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6364
Fold [4/5] Epoch [30/100] Initial Loss: 0.1389, Training Loss: 0.0040, Initial Validation Loss: 0.1339, Validation Loss: 0.0279,V Acc: 0.8545, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 37  Rolling back to Epoch (base 0): 32  Top Validation Acc: 0.961038961038961
Fold [5/5] Epoch [0/100] Initial Loss: 0.1394, Training Loss: 0.1394, Initial Validation Loss: 0.1324, Validation Loss: 0.1324,V Acc: 0.4167, Top 70th Acc: 0.4342, Bottom 30th Acc: 0.3750
Fold [5/5] Epoch [10/100] Initial Loss: 0.1394, Training Loss: 0.0140, Initial Validation Loss: 0.1324, Validation Loss: 0.0322,V Acc: 0.8519, Top 70th Acc: 0.9868, Bottom 30th Acc: 0.5312
Fold [5/5] Epoch [20/100] Initial Loss: 0.1394, Training Loss: 0.0045, Initial Validation Loss: 0.1324, Validation Loss: 0.0282,V Acc: 0.8426, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.5625
Stopping early at Epoch (base 0):
Fold [3/5] Epoch [20/100] Initial Loss: 0.1316, Training Loss: 0.0165, Initial Validation Loss: 0.1259, Validation Loss: 0.0275,V Acc: 0.8818, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 27  Rolling back to Epoch (base 0): 22  Top Validation Acc: 0.961038961038961
Fold [4/5] Epoch [0/100] Initial Loss: 0.1362, Training Loss: 0.1362, Initial Validation Loss: 0.1275, Validation Loss: 0.1275,V Acc: 0.3000, Top 70th Acc: 0.3636, Bottom 30th Acc: 0.1515
Fold [4/5] Epoch [10/100] Initial Loss: 0.1362, Training Loss: 0.0214, Initial Validation Loss: 0.1275, Validation Loss: 0.0501,V Acc: 0.7364, Top 70th Acc: 0.8701, Bottom 30th Acc: 0.4242
Stopping early at Epoch (base 0): 18  Rolling back to Epoch (base 0): 13  Top Validation Acc: 0.8701298701298701
Fold [5/5] Epoch [0/100] Initial Loss: 0.1383, Training Loss: 0.1383, Initial Validation Loss: 0.1255, Validation Loss: 0.1255,V Acc: 0.3519, Top 70th Acc: 0.4474, Bottom 30th Acc: 0.1250
Fold [5/5] Epoch [10/100] Initial Loss: 0.1383, Training Loss: 0.0298, Initial Validation Loss: 0.1255, Validation Loss: 0.0357,V Acc: 0.8241, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.5625
Fold [5/5] Epoch [20/100] Initial Loss: 0.1383, Training Loss: 0.0192, Initial Validation Loss: 0.1255, Validation Loss: 0.0285,V Acc: 0.8889, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.7500
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.9473684210526315
3 4 [array([0.82581824, 0.02083904, 0.01219836, 0.06466983, 0.0764745 ],
      dtype=float32)]
Running train_nn.py with seed 4
CUDA:False
Training samples count:  550
Training on 21 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1330, Training Loss: 0.1330, Initial Validation Loss: 0.1230, Validation Loss: 0.1230,V Acc: 0.4775, Top 70th Acc: 0.6538, Bottom 30th Acc: 0.0606
Fold [1/5] Epoch [10/100] Initial Loss: 0.1330, Training Loss: 0.0239, Initial Validation Loss: 0.1230, Validation Loss: 0.0281,V Acc: 0.8739, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 19  Rolling back to Epoch (base 0): 14  Top Validation Acc: 0.9615384615384616
Fold [2/5] Epoch [0/100] Initial Loss: 0.1338, Training Loss: 0.1338, Initial Validation Loss: 0.1254, Validation Loss: 0.1254,V Acc: 0.4505, Top 70th Acc: 0.5769, Bottom 30th Acc: 0.1515
Fold [2/5] Epoch [10/100] Initial Loss: 0.1338, Training Loss: 0.0257, Initial Validation Loss: 0.1254, Validation Loss: 0.0284,V Acc: 0.9009, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.7576
Stopping early at Epoch (base 0): 14  Rolling back to Epoch (base 0): 9  Top Validation Acc: 0.9615384615384616
Fold [3/5] Epoch [0/100] Initial Loss: 0.1359, Training Loss: 0.1359, Initial Validation Loss: 0.1238, Validation Loss: 0.1238,V Acc: 0.4455, Top 70th Acc: 0.4935, Bottom 30th Acc: 0.3333
Fold [3/5] Epoch [10/100] Initial Loss: 0.1359, Training Loss: 0.0234, Initial Validation Loss: 0.1238, Validation Loss: 0.0324,V Acc: 0.8000, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.4242
Stopping early at Epoch (base 0): 19  Rolling back to Epoch (base 0): 14  Top Validation Acc: 0.935064935064935
Fold [4/5] Epoch [0/100] Initial Loss: 0.1378, Training Loss: 0.1378, Initial Validation Loss: 0.1316, Validation Loss: 0.1316,V Acc: 0.3000, Top 70th Acc: 0.3377, Bottom 30th Acc: 0.2121
Fold [4/5] Epoch [10/100] Initial Loss: 0.1378, Training Loss: 0.0261, Initial Validation Loss: 0.1316, Validation Loss: 0.0324,V Acc: 0.8545, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6364
Fold [4/5] Epoch [20/100] Initial Loss: 0.1378, Training Loss: 0.0165, Initial Validation Loss: 0.1316, Validation Loss: 0.0267,V Acc: 0.8909, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.6970
Fold [4/5] Epoch [30/100] Initial Loss: 0.1378, Training Loss: 0.0148, Initial Validation Loss: 0.1316, Validation Loss: 0.0267,V Acc: 0.8818, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.7273
Fold [4/5] Epoch [40/100] Initial Loss: 0.1378, Training Loss: 0.0135, Initial Validation Loss: 0.1316, Validation Loss: 0.0285,V Acc: 0.8636, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 43  Rolling back to Epoch (base 0): 38  Top Validation Acc: 0.974025974025974
4 3 [array([0.7842417 , 0.03917789, 0.01361614, 0.05992325, 0.10304104],
      dtype=float32)]
Fold [5/5] Epoch [0/100] Initial Loss: 0.1360, Training Loss: 0.1360, Initial Validation Loss: 0.1235, Validation Loss: 0.1235,V Acc: 0.4074, Top 70th Acc: 0.4605, Bottom 30th Acc: 0.2812
Fold [5/5] Epoch [10/100] Initial Loss: 0.1360, Training Loss: 0.0250, Initial Validation Loss: 0.1235, Validation Loss: 0.0269,V Acc: 0.8241, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.5000
Fold [5/5] Epoch [20/100] Initial Loss: 0.1360, Training Loss: 0.0204, Initial Validation Loss: 0.1235, Validation Loss: 0.0233,V Acc: 0.8796, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.7188
Stopping early at Epoch (base 0): 27  Rolling back to Epoch (base 0): 22  Top Validation Acc: 0.9605263157894737
Running train_nn.py with seed 5
CUDA:False
Training samples count:  550
Training on 21 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1353, Training Loss: 0.1353, Initial Validation Loss: 0.1201, Validation Loss: 0.1201,V Acc: 0.6396, Top 70th Acc: 0.7051, Bottom 30th Acc: 0.4848
Fold [1/5] Epoch [10/100] Initial Loss: 0.1353, Training Loss: 0.0266, Initial Validation Loss: 0.1201, Validation Loss: 0.0275,V Acc: 0.8919, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.8182
Fold [1/5] Epoch [20/100] Initial Loss: 0.1353, Training Loss: 0.0188, Initial Validation Loss: 0.1201, Validation Loss: 0.0245,V Acc: 0.8829, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.7273
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.9487179487179487
Fold [2/5] Epoch [0/100] Initial Loss: 0.1377, Training Loss: 0.1377, Initial Validation Loss: 0.1309, Validation Loss: 0.1309,V Acc: 0.2793, Top 70th Acc: 0.3462, Bottom 30th Acc: 0.1212
Fold [2/5] Epoch [10/100] Initial Loss: 0.1377, Training Loss: 0.0256, Initial Validation Loss: 0.1309, Validation Loss: 0.0299,V Acc: 0.8468, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 18  Rolling back to Epoch (base 0): 13  Top Validation Acc: 0.9871794871794872
Fold [3/5] Epoch [0/100] Initial Loss: 0.1409, Training Loss: 0.1409, Initial Validation Loss: 0.1244, Validation Loss: 0.1244,V Acc: 0.3545, Top 70th Acc: 0.4286, Bottom 30th Acc: 0.1818
Fold [3/5] Epoch [10/100] Initial Loss: 0.1409, Training Loss: 0.0241, Initial Validation Loss: 0.1244, Validation Loss: 0.0297,V Acc: 0.8455, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6061
Fold [3/5] Epoch [20/100] Initial Loss: 0.1409, Training Loss: 0.0174, Initial Validation Loss: 0.1244, Validation Loss: 0.0285,V Acc: 0.8182, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.4848
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.961038961038961
Fold [4/5] Epoch [0/100] Initial Loss: 0.1374, Training Loss: 0.1374, Initial Validation Loss: 0.1315, Validation Loss: 0.1315,V Acc: 0.4727, Top 70th Acc: 0.5584, Bottom 30th Acc: 0.2727
Fold [4/5] Epoch [10/100] Initial Loss: 0.1374, Training Loss: 0.0249, Initial Validation Loss: 0.1315, Validation Loss: 0.0350,V Acc: 0.8636, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6667
Fold [4/5] Epoch [20/100] Initial Loss: 0.1374, Training Loss: 0.0187, Initial Validation Loss: 0.1315, Validation Loss: 0.0289,V Acc: 0.8727, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 20  Rolling back to Epoch (base 0): 15  Top Validation Acc: 0.961038961038961
5 3 [array([0.7355412 , 0.02322537, 0.04756551, 0.1211113 , 0.07255659],
      dtype=float32)]
Fold [5/5] Epoch [0/100] Initial Loss: 0.1311, Training Loss: 0.1311, Initial Validation Loss: 0.1165, Validation Loss: 0.1165,V Acc: 0.4537, Top 70th Acc: 0.5132, Bottom 30th Acc: 0.3125
Fold [5/5] Epoch [10/100] Initial Loss: 0.1311, Training Loss: 0.0248, Initial Validation Loss: 0.1165, Validation Loss: 0.0278,V Acc: 0.8426, Top 70th Acc: 0.9868, Bottom 30th Acc: 0.5000
Fold [5/5] Epoch [20/100] Initial Loss: 0.1311, Training Loss: 0.0163, Initial Validation Loss: 0.1165, Validation Loss: 0.0245,V Acc: 0.8889, Top 70th Acc: 0.9868, Bottom 30th Acc: 0.6562
Fold [5/5] Epoch [20/100] Initial Loss: 0.1415, Training Loss: 0.0146, Initial Validation Loss: 0.1316, Validation Loss: 0.0312,V Acc: 0.8611, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.6562
Fold [5/5] Epoch [30/100] Initial Loss: 0.1415, Training Loss: 0.0124, Initial Validation Loss: 0.1316, Validation Loss: 0.0319,V Acc: 0.8704, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.6875
Stopping early at Epoch (base 0): 30  Rolling back to Epoch (base 0): 25  Top Validation Acc: 0.9473684210526315
Running train_nn.py with seed 3
CUDA:False
Training samples count:  550
Training on 40 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1400, Training Loss: 0.1400, Initial Validation Loss: 0.1354, Validation Loss: 0.1354,V Acc: 0.2523, Top 70th Acc: 0.3333, Bottom 30th Acc: 0.0606
Fold [1/5] Epoch [10/100] Initial Loss: 0.1400, Training Loss: 0.0296, Initial Validation Loss: 0.1354, Validation Loss: 0.0467,V Acc: 0.7928, Top 70th Acc: 0.8846, Bottom 30th Acc: 0.5758
Fold [1/5] Epoch [20/100] Initial Loss: 0.1400, Training Loss: 0.0179, Initial Validation Loss: 0.1354, Validation Loss: 0.0434,V Acc: 0.8108, Top 70th Acc: 0.8846, Bottom 30th Acc: 0.6364
Fold [1/5] Epoch [30/100] Initial Loss: 0.1400, Training Loss: 0.0134, Initial Validation Loss: 0.1354, Validation Loss: 0.0420,V Acc: 0.8108, Top 70th Acc: 0.8718, Bottom 30th Acc: 0.6667
Fold [1/5] Epoch [40/100] Initial Loss: 0.1400, Training Loss: 0.0110, Initial Validation Loss: 0.1354, Validation Loss: 0.0404,V Acc: 0.8108, Top 70th Acc: 0.8974, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 48  Rolling back to Epoch (base 0): 43  Top Validation Acc: 0.9102564102564102
Fold [2/5] Epoch [0/100] Initial Loss: 0.1382, Training Loss: 0.1382, Initial Validation Loss: 0.1362, Validation Loss: 0.1362,V Acc: 0.2793, Top 70th Acc: 0.3590, Bottom 30th Acc: 0.0909
Fold [2/5] Epoch [10/100] Initial Loss: 0.1382, Training Loss: 0.0439, Initial Validation Loss: 0.1362, Validation Loss: 0.0387,V Acc: 0.8198, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.5455
Fold [2/5] Epoch [20/100] Initial Loss: 0.1382, Training Loss: 0.0182, Initial Validation Loss: 0.1362, Validation Loss: 0.0173,V Acc: 0.9189, Top 70th Acc: 0.9872, Bottom 30th Acc: 0.7576
Stopping early at Epoch (base 0): 29  Rolling back to Epoch (base 0): 24  Top Validation Acc: 0.9743589743589743
Fold [3/5] Epoch [0/100] Initial Loss: 0.1389, Training Loss: 0.1389, Initial Validation Loss: 0.1356, Validation Loss: 0.1356,V Acc: 0.3727, Top 70th Acc: 0.4026, Bottom 30th Acc: 0.3030
Fold [3/5] Epoch [10/100] Initial Loss: 0.1389, Training Loss: 0.0420, Initial Validation Loss: 0.1356, Validation Loss: 0.0522,V Acc: 0.7364, Top 70th Acc: 0.8961, Bottom 30th Acc: 0.3636
Fold [3/5] Epoch [20/100] Initial Loss: 0.1389, Training Loss: 0.0164, Initial Validation Loss: 0.1356, Validation Loss: 0.0321,V Acc: 0.8273, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.4848
Stopping early at Epoch (base 0): 28  Rolling back to Epoch (base 0): 23  Top Validation Acc: 0.974025974025974
Fold [4/5] Epoch [0/100] Initial Loss: 0.1380, Training Loss: 0.1380, Initial Validation Loss: 0.1311, Validation Loss: 0.1311,V Acc: 0.4364, Top 70th Acc: 0.5195, Bottom 30th Acc: 0.2424
Fold [4/5] Epoch [10/100] Initial Loss: 0.1380, Training Loss: 0.0233, Initial Validation Loss: 0.1311, Validation Loss: 0.0338,V Acc: 0.8636, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.7273
Fold [4/5] Epoch [20/100] Initial Loss: 0.1380, Training Loss: 0.0128, Initial Validation Loss: 0.1311, Validation Loss: 0.0292,V Acc: 0.8455, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 22  Rolling back to Epoch (base 0): 17  Top Validation Acc: 0.948051948051948
Fold [5/5] Epoch [0/100] Initial Loss: 0.1393, Training Loss: 0.1393, Initial Validation Loss: 0.1285, Validation Loss: 0.1285,V Acc: 0.2778, Top 70th Acc: 0.3553, Bottom 30th Acc: 0.0938
Fold [5/5] Epoch [10/100] Initial Loss: 0.1393, Training Loss: 0.0386, Initial Validation Loss: 0.1285, Validation Loss: 0.0459,V Acc: 0.7593, Top 70th Acc: 0.8816, Bottom 30th Acc: 0.4688
Fold [5/5] Epoch [20/100] Initial Loss: 0.1393, Training Loss: 0.0137, Initial Validation Loss: 0.1285, Validation Loss: 0.0287,V Acc: 0.8148, Top 70th Acc: 0.9737, Bottom 30th Acc: 0.4375
Fold [5/5] Epoch [30/100] Initial Loss: 0.1393, Training Loss: 0.0109, Initial Validation Loss: 0.1285, Validation Loss: 0.0277,V Acc: 0.8241, Top 70th Acc: 0.9737, Bottom 30th Acc: 0.4688
Stopping early at Epoch (base 0): 36  Rolling back to Epoch (base 0): 31  Top Validation Acc: 0.9736842105263158
3 4 [array([0.61579293, 0.08056846, 0.04379531, 0.08332081, 0.17652255],
      dtype=float32)]
Running train_nn.py with seed 4
CUDA:False
Training samples count:  550
Training on 40 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1413, Training Loss: 0.1413, Initial Validation Loss: 0.1371, Validation Loss: 0.1371,V Acc: 0.3063, Top 70th Acc: 0.3462, Bottom 30th Acc: 0.2121
Fold [1/5] Epoch [10/100] Initial Loss: 0.1413, Training Loss: 0.0252, Initial Validation Loss: 0.1371, Validation Loss: 0.0369,V Acc: 0.8378, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.6061
Fold [1/5] Epoch [20/100] Initial Loss: 0.1413, Training Loss: 0.0130, Initial Validation Loss: 0.1371, Validation Loss: 0.0305,V Acc: 0.8739, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.7273
Fold [1/5] Epoch [30/100] Initial Loss: 0.1413, Training Loss: 0.0112, Initial Validation Loss: 0.1371, Validation Loss: 0.0283,V Acc: 0.8739, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.7273
Stopping early at Epoch (base 0): 35  Rolling back to Epoch (base 0): 30  Top Validation Acc: 0.9358974358974359
Fold [2/5] Epoch [0/100] Initial Loss: 0.1388, Training Loss: 0.1388, Initial Validation Loss: 0.1343, Validation Loss: 0.1343,V Acc: 0.3514, Top 70th Acc: 0.3974, Bottom 30th Acc: 0.2424
Fold [2/5] Epoch [10/100] Initial Loss: 0.1388, Training Loss: 0.0337, Initial Validation Loss: 0.1343, Validation Loss: 0.0409,V Acc: 0.8288, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.6061
Fold [2/5] Epoch [20/100] Initial Loss: 0.1388, Training Loss: 0.0169, Initial Validation Loss: 0.1343, Validation Loss: 0.0274,V Acc: 0.8739, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.6364
Fold [2/5] Epoch [30/100] Initial Loss: 0.1388, Training Loss: 0.0130, Initial Validation Loss: 0.1343, Validation Loss: 0.0244,V Acc: 0.8739, Top 70th Acc: 0.9872, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 35  Rolling back to Epoch (base 0): 30  Top Validation Acc: 0.9743589743589743
Fold [3/5] Epoch [0/100] Initial Loss: 0.1385, Training Loss: 0.1385, Initial Validation Loss: 0.1326, Validation Loss: 0.1326,V Acc: 0.2545, Top 70th Acc: 0.3117, Bottom 30th Acc: 0.1212
Fold [3/5] Epoch [10/100] Initial Loss: 0.1385, Training Loss: 0.0235, Initial Validation Loss: 0.1326, Validation Loss: 0.0416,V Acc: 0.7818, Top 70th Acc: 0.8831, Bottom 30th Acc: 0.5455
Fold [3/5] Epoch [20/100] Initial Loss: 0.1385, Training Loss: 0.0128, Initial Validation Loss: 0.1326, Validation Loss: 0.0353,V Acc: 0.7818, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.3636
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.922077922077922
Fold [4/5] Epoch [0/100] Initial Loss: 0.1393, Training Loss: 0.1393, Initial Validation Loss: 0.1350, Validation Loss: 0.1350,V Acc: 0.2818, Top 70th Acc: 0.3506, Bottom 30th Acc: 0.1212
Fold [4/5] Epoch [10/100] Initial Loss: 0.1393, Training Loss: 0.0438, Initial Validation Loss: 0.1350, Validation Loss: 0.0513,V Acc: 0.7818, Top 70th Acc: 0.8442, Bottom 30th Acc: 0.6364
Fold [4/5] Epoch [20/100] Initial Loss: 0.1393, Training Loss: 0.0166, Initial Validation Loss: 0.1350, Validation Loss: 0.0353,V Acc: 0.8545, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.7273
Fold [4/5] Epoch [30/100] Initial Loss: 0.1393, Training Loss: 0.0124, Initial Validation Loss: 0.1350, Validation Loss: 0.0325,V Acc: 0.8364, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 33  Rolling back to Epoch (base 0): 28  Top Validation Acc: 0.9090909090909091
4 3 [array([0.5784767 , 0.03345189, 0.0845114 , 0.08881127, 0.21474871],
      dtype=float32)]
Fold [5/5] Epoch [0/100] Initial Loss: 0.1371, Training Loss: 0.1371, Initial Validation Loss: 0.1288, Validation Loss: 0.1288,V Acc: 0.2500, Top 70th Acc: 0.3421, Bottom 30th Acc: 0.0312
Fold [1/5] Epoch [0/100] Initial Loss: 0.1244, Training Loss: 0.1244, Initial Validation Loss: 0.1131, Validation Loss: 0.1131,V Acc: 0.4955, Top 70th Acc: 0.6410, Bottom 30th Acc: 0.1515
Fold [1/5] Epoch [10/100] Initial Loss: 0.1244, Training Loss: 0.0808, Initial Validation Loss: 0.1131, Validation Loss: 0.0806,V Acc: 0.6306, Top 70th Acc: 0.7308, Bottom 30th Acc: 0.3939
Fold [1/5] Epoch [20/100] Initial Loss: 0.1244, Training Loss: 0.0794, Initial Validation Loss: 0.1131, Validation Loss: 0.0792,V Acc: 0.6126, Top 70th Acc: 0.7436, Bottom 30th Acc: 0.3030
Fold [1/5] Epoch [30/100] Initial Loss: 0.1244, Training Loss: 0.0789, Initial Validation Loss: 0.1131, Validation Loss: 0.0789,V Acc: 0.6126, Top 70th Acc: 0.7308, Bottom 30th Acc: 0.3333
Stopping early at Epoch (base 0): 32  Rolling back to Epoch (base 0): 27  Top Validation Acc: 0.7435897435897436
Fold [2/5] Epoch [0/100] Initial Loss: 0.1301, Training Loss: 0.1301, Initial Validation Loss: 0.1184, Validation Loss: 0.1184,V Acc: 0.4595, Top 70th Acc: 0.5256, Bottom 30th Acc: 0.3030
Fold [2/5] Epoch [10/100] Initial Loss: 0.1301, Training Loss: 0.0851, Initial Validation Loss: 0.1184, Validation Loss: 0.0685,V Acc: 0.7387, Top 70th Acc: 0.8205, Bottom 30th Acc: 0.5455
Fold [2/5] Epoch [20/100] Initial Loss: 0.1301, Training Loss: 0.0838, Initial Validation Loss: 0.1184, Validation Loss: 0.0658,V Acc: 0.7387, Top 70th Acc: 0.8205, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 22  Rolling back to Epoch (base 0): 17  Top Validation Acc: 0.8205128205128205
Fold [3/5] Epoch [0/100] Initial Loss: 0.1363, Training Loss: 0.1363, Initial Validation Loss: 0.1286, Validation Loss: 0.1286,V Acc: 0.3727, Top 70th Acc: 0.4545, Bottom 30th Acc: 0.1818
Fold [3/5] Epoch [10/100] Initial Loss: 0.1363, Training Loss: 0.0790, Initial Validation Loss: 0.1286, Validation Loss: 0.0847,V Acc: 0.5909, Top 70th Acc: 0.7403, Bottom 30th Acc: 0.2424
Fold [3/5] Epoch [20/100] Initial Loss: 0.1363, Training Loss: 0.0773, Initial Validation Loss: 0.1286, Validation Loss: 0.0833,V Acc: 0.6000, Top 70th Acc: 0.7403, Bottom 30th Acc: 0.2727
Fold [3/5] Epoch [30/100] Initial Loss: 0.1363, Training Loss: 0.0770, Initial Validation Loss: 0.1286, Validation Loss: 0.0821,V Acc: 0.6091, Top 70th Acc: 0.7532, Bottom 30th Acc: 0.2727
Fold [3/5] Epoch [40/100] Initial Loss: 0.1363, Training Loss: 0.0766, Initial Validation Loss: 0.1286, Validation Loss: 0.0812,V Acc: 0.6091, Top 70th Acc: 0.7532, Bottom 30th Acc: 0.2727
Fold [3/5] Epoch [50/100] Initial Loss: 0.1363, Training Loss: 0.0762, Initial Validation Loss: 0.1286, Validation Loss: 0.0811,V Acc: 0.6182, Top 70th Acc: 0.7403, Bottom 30th Acc: 0.3333
Fold [3/5] Epoch [60/100] Initial Loss: 0.1363, Training Loss: 0.0760, Initial Validation Loss: 0.1286, Validation Loss: 0.0806,V Acc: 0.6091, Top 70th Acc: 0.7532, Bottom 30th Acc: 0.2727
Stopping early at Epoch (base 0): 63  Rolling back to Epoch (base 0): 58  Top Validation Acc: 0.7532467532467533
Fold [4/5] Epoch [0/100] Initial Loss: 0.1358, Training Loss: 0.1358, Initial Validation Loss: 0.1260, Validation Loss: 0.1260,V Acc: 0.4000, Top 70th Acc: 0.4026, Bottom 30th Acc: 0.3939
Fold [4/5] Epoch [10/100] Initial Loss: 0.1358, Training Loss: 0.0765, Initial Validation Loss: 0.1260, Validation Loss: 0.0944,V Acc: 0.5364, Top 70th Acc: 0.6104, Bottom 30th Acc: 0.3636
Stopping early at Epoch (base 0): 16  Rolling back to Epoch (base 0): 11  Top Validation Acc: 0.6233766233766234
Fold [5/5] Epoch [0/100] Initial Loss: 0.1358, Training Loss: 0.1358, Initial Validation Loss: 0.1226, Validation Loss: 0.1226,V Acc: 0.5185, Top 70th Acc: 0.5789, Bottom 30th Acc: 0.3750
Fold [5/5] Epoch [10/100] Initial Loss: 0.1358, Training Loss: 0.0809, Initial Validation Loss: 0.1226, Validation Loss: 0.0784,V Acc: 0.6296, Top 70th Acc: 0.7237, Bottom 30th Acc: 0.4062
Fold [5/5] Epoch [20/100] Initial Loss: 0.1358, Training Loss: 0.0783, Initial Validation Loss: 0.1226, Validation Loss: 0.0781,V Acc: 0.6111, Top 70th Acc: 0.7368, Bottom 30th Acc: 0.3125
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.7368421052631579
3 4 [array([0.16855727, 0.3058551 , 0.15394334, 0.22801635, 0.14362803],
      dtype=float32)]
Running train_nn.py with seed 4
CUDA:False
Training samples count:  550
Training on 2 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1313, Training Loss: 0.1313, Initial Validation Loss: 0.1237, Validation Loss: 0.1237,V Acc: 0.4234, Top 70th Acc: 0.5000, Bottom 30th Acc: 0.2424
Fold [1/5] Epoch [10/100] Initial Loss: 0.1313, Training Loss: 0.0794, Initial Validation Loss: 0.1237, Validation Loss: 0.0843,V Acc: 0.5946, Top 70th Acc: 0.7051, Bottom 30th Acc: 0.3333
Fold [1/5] Epoch [20/100] Initial Loss: 0.1313, Training Loss: 0.0777, Initial Validation Loss: 0.1237, Validation Loss: 0.0829,V Acc: 0.5946, Top 70th Acc: 0.7179, Bottom 30th Acc: 0.3030
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.717948717948718
Fold [2/5] Epoch [0/100] Initial Loss: 0.1395, Training Loss: 0.1395, Initial Validation Loss: 0.1338, Validation Loss: 0.1338,V Acc: 0.3243, Top 70th Acc: 0.4487, Bottom 30th Acc: 0.0303
Fold [2/5] Epoch [10/100] Initial Loss: 0.1395, Training Loss: 0.0813, Initial Validation Loss: 0.1338, Validation Loss: 0.0821,V Acc: 0.6486, Top 70th Acc: 0.7308, Bottom 30th Acc: 0.4545
Fold [2/5] Epoch [20/100] Initial Loss: 0.1395, Training Loss: 0.0791, Initial Validation Loss: 0.1338, Validation Loss: 0.0800,V Acc: 0.6486, Top 70th Acc: 0.7308, Bottom 30th Acc: 0.4545
Fold [2/5] Epoch [30/100] Initial Loss: 0.1395, Training Loss: 0.0779, Initial Validation Loss: 0.1338, Validation Loss: 0.0832,V Acc: 0.6306, Top 70th Acc: 0.6923, Bottom 30th Acc: 0.4848
Stopping early at Epoch (base 0): 33  Rolling back to Epoch (base 0): 28  Top Validation Acc: 0.7435897435897436
Fold [3/5] Epoch [0/100] Initial Loss: 0.1369, Training Loss: 0.1369, Initial Validation Loss: 0.1265, Validation Loss: 0.1265,V Acc: 0.3727, Top 70th Acc: 0.4545, Bottom 30th Acc: 0.1818
Fold [3/5] Epoch [10/100] Initial Loss: 0.1369, Training Loss: 0.0773, Initial Validation Loss: 0.1265, Validation Loss: 0.0922,V Acc: 0.5727, Top 70th Acc: 0.6623, Bottom 30th Acc: 0.3636
Stopping early at Epoch (base 0): 17  Rolling back to Epoch (base 0): 12  Top Validation Acc: 0.6493506493506493
Fold [4/5] Epoch [0/100] Initial Loss: 0.1374, Training Loss: 0.1374, Initial Validation Loss: 0.1305, Validation Loss: 0.1305,V Acc: 0.3727, Top 70th Acc: 0.4416, Bottom 30th Acc: 0.2121
Fold [4/5] Epoch [10/100] Initial Loss: 0.1374, Training Loss: 0.0832, Initial Validation Loss: 0.1305, Validation Loss: 0.0727,V Acc: 0.6727, Top 70th Acc: 0.7922, Bottom 30th Acc: 0.3939
Fold [4/5] Epoch [20/100] Initial Loss: 0.1374, Training Loss: 0.0812, Initial Validation Loss: 0.1305, Validation Loss: 0.0699,V Acc: 0.6727, Top 70th Acc: 0.8052, Bottom 30th Acc: 0.3636
Stopping early at Epoch (base 0): 28  Rolling back to Epoch (base 0): 23  Top Validation Acc: 0.8051948051948052
4 3 [array([0.13912186, 0.33944604, 0.15659262, 0.21796648, 0.14687301],
      dtype=float32)]
Fold [5/5] Epoch [0/100] Initial Loss: 0.1363, Training Loss: 0.1363, Initial Validation Loss: 0.1234, Validation Loss: 0.1234,V Acc: 0.3704, Top 70th Acc: 0.4079, Bottom 30th Acc: 0.2812
Fold [5/5] Epoch [10/100] Initial Loss: 0.1363, Training Loss: 0.0823, Initial Validation Loss: 0.1234, Validation Loss: 0.0715,V Acc: 0.6481, Top 70th Acc: 0.7763, Bottom 30th Acc: 0.3438
Fold [5/5] Epoch [20/100] Initial Loss: 0.1363, Training Loss: 0.0812, Initial Validation Loss: 0.1234, Validation Loss: 0.0699,V Acc: 0.6667, Top 70th Acc: 0.7632, Bottom 30th Acc: 0.4375
Fold [5/5] Epoch [30/100] Initial Loss: 0.1363, Training Loss: 0.0808, Initial Validation Loss: 0.1234, Validation Loss: 0.0694,V Acc: 0.6574, Top 70th Acc: 0.7763, Bottom 30th Acc: 0.3750
Stopping early at Epoch (base 0): 32  Rolling back to Epoch (base 0): 27  Top Validation Acc: 0.7894736842105263
Running train_nn.py with seed 5
CUDA:False
Training samples count:  550
Training on 2 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1389, Training Loss: 0.1389, Initial Validation Loss: 0.1272, Validation Loss: 0.1272,V Acc: 0.6486, Top 70th Acc: 0.7308, Bottom 30th Acc: 0.4545 21  Rolling back to Epoch (base 0): 16  Top Validation Acc: 0.9210526315789473
Running train_nn.py with seed 3
CUDA:False
Training samples count:  550
Training on 30 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1389, Training Loss: 0.1389, Initial Validation Loss: 0.1372, Validation Loss: 0.1372,V Acc: 0.2523, Top 70th Acc: 0.3077, Bottom 30th Acc: 0.1212
Fold [1/5] Epoch [10/100] Initial Loss: 0.1389, Training Loss: 0.0424, Initial Validation Loss: 0.1372, Validation Loss: 0.0572,V Acc: 0.7568, Top 70th Acc: 0.8333, Bottom 30th Acc: 0.5758
Fold [1/5] Epoch [20/100] Initial Loss: 0.1389, Training Loss: 0.0189, Initial Validation Loss: 0.1372, Validation Loss: 0.0393,V Acc: 0.8198, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.5152
Fold [1/5] Epoch [30/100] Initial Loss: 0.1389, Training Loss: 0.0149, Initial Validation Loss: 0.1372, Validation Loss: 0.0380,V Acc: 0.8198, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 39  Rolling back to Epoch (base 0): 34  Top Validation Acc: 0.9358974358974359
Fold [2/5] Epoch [0/100] Initial Loss: 0.1422, Training Loss: 0.1422, Initial Validation Loss: 0.1365, Validation Loss: 0.1365,V Acc: 0.3063, Top 70th Acc: 0.3333, Bottom 30th Acc: 0.2424
Fold [2/5] Epoch [10/100] Initial Loss: 0.1422, Training Loss: 0.0346, Initial Validation Loss: 0.1365, Validation Loss: 0.0247,V Acc: 0.8829, Top 70th Acc: 1.0000, Bottom 30th Acc: 0.6061
Fold [2/5] Epoch [20/100] Initial Loss: 0.1422, Training Loss: 0.0209, Initial Validation Loss: 0.1365, Validation Loss: 0.0176,V Acc: 0.8919, Top 70th Acc: 1.0000, Bottom 30th Acc: 0.6364
Fold [2/5] Epoch [30/100] Initial Loss: 0.1422, Training Loss: 0.0178, Initial Validation Loss: 0.1365, Validation Loss: 0.0166,V Acc: 0.9009, Top 70th Acc: 1.0000, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 36  Rolling back to Epoch (base 0): 31  Top Validation Acc: 1.0
Fold [3/5] Epoch [0/100] Initial Loss: 0.1373, Training Loss: 0.1373, Initial Validation Loss: 0.1336, Validation Loss: 0.1336,V Acc: 0.3909, Top 70th Acc: 0.4545, Bottom 30th Acc: 0.2424
Fold [3/5] Epoch [10/100] Initial Loss: 0.1373, Training Loss: 0.0271, Initial Validation Loss: 0.1336, Validation Loss: 0.0349,V Acc: 0.8364, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.5152
Stopping early at Epoch (base 0): 18  Rolling back to Epoch (base 0): 13  Top Validation Acc: 0.961038961038961
Fold [4/5] Epoch [0/100] Initial Loss: 0.1386, Training Loss: 0.1386, Initial Validation Loss: 0.1329, Validation Loss: 0.1329,V Acc: 0.3000, Top 70th Acc: 0.3766, Bottom 30th Acc: 0.1212
Fold [4/5] Epoch [10/100] Initial Loss: 0.1386, Training Loss: 0.0351, Initial Validation Loss: 0.1329, Validation Loss: 0.0540,V Acc: 0.7182, Top 70th Acc: 0.8182, Bottom 30th Acc: 0.4848
Fold [4/5] Epoch [20/100] Initial Loss: 0.1386, Training Loss: 0.0253, Initial Validation Loss: 0.1329, Validation Loss: 0.0485,V Acc: 0.7818, Top 70th Acc: 0.8571, Bottom 30th Acc: 0.6061
Fold [4/5] Epoch [30/100] Initial Loss: 0.1386, Training Loss: 0.0207, Initial Validation Loss: 0.1329, Validation Loss: 0.0435,V Acc: 0.7818, Top 70th Acc: 0.8961, Bottom 30th Acc: 0.5152
Fold [4/5] Epoch [40/100] Initial Loss: 0.1386, Training Loss: 0.0169, Initial Validation Loss: 0.1329, Validation Loss: 0.0361,V Acc: 0.8091, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.5455
Fold [4/5] Epoch [50/100] Initial Loss: 0.1386, Training Loss: 0.0146, Initial Validation Loss: 0.1329, Validation Loss: 0.0335,V Acc: 0.8273, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.6061
Fold [4/5] Epoch [60/100] Initial Loss: 0.1386, Training Loss: 0.0135, Initial Validation Loss: 0.1329, Validation Loss: 0.0347,V Acc: 0.8182, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 60  Rolling back to Epoch (base 0): 55  Top Validation Acc: 0.922077922077922
Fold [5/5] Epoch [0/100] Initial Loss: 0.1406, Training Loss: 0.1406, Initial Validation Loss: 0.1331, Validation Loss: 0.1331,V Acc: 0.2963, Top 70th Acc: 0.3421, Bottom 30th Acc: 0.1875
Fold [5/5] Epoch [10/100] Initial Loss: 0.1406, Training Loss: 0.0354, Initial Validation Loss: 0.1331, Validation Loss: 0.0381,V Acc: 0.7963, Top 70th Acc: 0.9079, Bottom 30th Acc: 0.5312
Fold [5/5] Epoch [20/100] Initial Loss: 0.1406, Training Loss: 0.0171, Initial Validation Loss: 0.1331, Validation Loss: 0.0295,V Acc: 0.8333, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.5625
Fold [5/5] Epoch [30/100] Initial Loss: 0.1406, Training Loss: 0.0144, Initial Validation Loss: 0.1331, Validation Loss: 0.0289,V Acc: 0.8611, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.6562
Stopping early at Epoch (base 0): 31  Rolling back to Epoch (base 0): 26  Top Validation Acc: 0.9473684210526315
3 4 [array([0.5916771 , 0.15244883, 0.03190767, 0.07422838, 0.14973797],
      dtype=float32)]
Running train_nn.py with seed 4
CUDA:False
Training samples count:  550
Training on 30 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1389, Training Loss: 0.1389, Initial Validation Loss: 0.1372, Validation Loss: 0.1372,V Acc: 0.2883, Top 70th Acc: 0.3846, Bottom 30th Acc: 0.0606
Fold [1/5] Epoch [10/100] Initial Loss: 0.1389, Training Loss: 0.0291, Initial Validation Loss: 0.1372, Validation Loss: 0.0368,V Acc: 0.8468, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.6061
Fold [1/5] Epoch [20/100] Initial Loss: 0.1389, Training Loss: 0.0180, Initial Validation Loss: 0.1372, Validation Loss: 0.0316,V Acc: 0.8468, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 22  Rolling back to Epoch (base 0): 17  Top Validation Acc: 0.9358974358974359
Fold [2/5] Epoch [0/100] Initial Loss: 0.1381, Training Loss: 0.1381, Initial Validation Loss: 0.1315, Validation Loss: 0.1315,V Acc: 0.4144, Top 70th Acc: 0.5128, Bottom 30th Acc: 0.1818
Fold [2/5] Epoch [10/100] Initial Loss: 0.1381, Training Loss: 0.0377, Initial Validation Loss: 0.1315, Validation Loss: 0.0433,V Acc: 0.8378, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.6667
Fold [2/5] Epoch [20/100] Initial Loss: 0.1381, Training Loss: 0.0189, Initial Validation Loss: 0.1315, Validation Loss: 0.0276,V Acc: 0.8739, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 29  Rolling back to Epoch (base 0): 24  Top Validation Acc: 0.9615384615384616
Fold [3/5] Epoch [0/100] Initial Loss: 0.1398, Training Loss: 0.1398, Initial Validation Loss: 0.1337, Validation Loss: 0.1337,V Acc: 0.3364, Top 70th Acc: 0.3117, Bottom 30th Acc: 0.3939
Fold [3/5] Epoch [10/100] Initial Loss: 0.1398, Training Loss: 0.0454, Initial Validation Loss: 0.1337, Validation Loss: 0.0557,V Acc: 0.7273, Top 70th Acc: 0.8442, Bottom 30th Acc: 0.4545
Fold [3/5] Epoch [20/100] Initial Loss: 0.1398, Training Loss: 0.0171, Initial Validation Loss: 0.1337, Validation Loss: 0.0349,V Acc: 0.7909, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.4545
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.935064935064935
Fold [4/5] Epoch [0/100] Initial Loss: 0.1405, Training Loss: 0.1405, Initial Validation Loss: 0.1347, Validation Loss: 0.1347,V Acc: 0.2727, Top 70th Acc: 0.3896, Bottom 30th Acc: 0.0000
Fold [4/5] Epoch [10/100] Initial Loss: 0.1405, Training Loss: 0.0397, Initial Validation Loss: 0.1347, Validation Loss: 0.0409,V Acc: 0.8000, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.5152
Fold [4/5] Epoch [20/100] Initial Loss: 0.1405, Training Loss: 0.0199, Initial Validation Loss: 0.1347, Validation Loss: 0.0288,V Acc: 0.8636, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 28  Rolling back to Epoch (base 0): 23  Top Validation Acc: 0.948051948051948
4 3 [array([0.72115153, 0.07684407, 0.05273806, 0.08133901, 0.06792729],
      dtype=float32)]
Fold [5/5] Epoch [0/100] Initial Loss: 0.1390, Training Loss: 0.1390, Initial Validation Loss: 0.1295, Validation Loss: 0.1295,V Acc: 0.2500, Top 70th Acc: 0.3553, Bottom 30th Acc: 0.0000
Fold [5/5] Epoch [10/100] Initial Loss: 0.1390, Training Loss: 0.0308, Initial Validation Loss: 0.1295, Validation Loss: 0.0323,V Acc: 0.8611, Top 70th Acc: 0.9211, Bottom 30th Acc: 0.7188
Fold [5/5] Epoch [20/100] Initial Loss: 0.1390, Training Loss: 0.0183, Initial Validation Loss: 0.1295, Validation Loss: 0.0271,V Acc: 0.8704, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.6875 42  Rolling back to Epoch (base 0): 37  Top Validation Acc: 0.9210526315789473
Running train_nn.py with seed 3
CUDA:False
Training samples count:  550
Training on 20 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1365, Training Loss: 0.1365, Initial Validation Loss: 0.1313, Validation Loss: 0.1313,V Acc: 0.3063, Top 70th Acc: 0.3590, Bottom 30th Acc: 0.1818
Fold [1/5] Epoch [10/100] Initial Loss: 0.1365, Training Loss: 0.0295, Initial Validation Loss: 0.1313, Validation Loss: 0.0442,V Acc: 0.8288, Top 70th Acc: 0.8718, Bottom 30th Acc: 0.7273
Fold [1/5] Epoch [20/100] Initial Loss: 0.1365, Training Loss: 0.0220, Initial Validation Loss: 0.1313, Validation Loss: 0.0415,V Acc: 0.8288, Top 70th Acc: 0.8846, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 21  Rolling back to Epoch (base 0): 16  Top Validation Acc: 0.8846153846153846
Fold [2/5] Epoch [0/100] Initial Loss: 0.1384, Training Loss: 0.1384, Initial Validation Loss: 0.1333, Validation Loss: 0.1333,V Acc: 0.4505, Top 70th Acc: 0.4744, Bottom 30th Acc: 0.3939
Fold [2/5] Epoch [10/100] Initial Loss: 0.1384, Training Loss: 0.0375, Initial Validation Loss: 0.1333, Validation Loss: 0.0306,V Acc: 0.8739, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.6667
Fold [2/5] Epoch [20/100] Initial Loss: 0.1384, Training Loss: 0.0262, Initial Validation Loss: 0.1333, Validation Loss: 0.0204,V Acc: 0.8739, Top 70th Acc: 0.9872, Bottom 30th Acc: 0.6061
Fold [2/5] Epoch [30/100] Initial Loss: 0.1384, Training Loss: 0.0241, Initial Validation Loss: 0.1333, Validation Loss: 0.0209,V Acc: 0.8829, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 32  Rolling back to Epoch (base 0): 27  Top Validation Acc: 0.9743589743589743
Fold [3/5] Epoch [0/100] Initial Loss: 0.1381, Training Loss: 0.1381, Initial Validation Loss: 0.1342, Validation Loss: 0.1342,V Acc: 0.3273, Top 70th Acc: 0.3896, Bottom 30th Acc: 0.1818
Fold [3/5] Epoch [10/100] Initial Loss: 0.1381, Training Loss: 0.0330, Initial Validation Loss: 0.1342, Validation Loss: 0.0373,V Acc: 0.8455, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.6667
Fold [3/5] Epoch [20/100] Initial Loss: 0.1381, Training Loss: 0.0227, Initial Validation Loss: 0.1342, Validation Loss: 0.0326,V Acc: 0.8455, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6061
Fold [3/5] Epoch [30/100] Initial Loss: 0.1381, Training Loss: 0.0209, Initial Validation Loss: 0.1342, Validation Loss: 0.0307,V Acc: 0.8545, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 33  Rolling back to Epoch (base 0): 28  Top Validation Acc: 0.961038961038961
Fold [4/5] Epoch [0/100] Initial Loss: 0.1387, Training Loss: 0.1387, Initial Validation Loss: 0.1290, Validation Loss: 0.1290,V Acc: 0.3909, Top 70th Acc: 0.4935, Bottom 30th Acc: 0.1515
Fold [4/5] Epoch [10/100] Initial Loss: 0.1387, Training Loss: 0.0364, Initial Validation Loss: 0.1290, Validation Loss: 0.0467,V Acc: 0.7636, Top 70th Acc: 0.8831, Bottom 30th Acc: 0.4848
Fold [4/5] Epoch [20/100] Initial Loss: 0.1387, Training Loss: 0.0220, Initial Validation Loss: 0.1290, Validation Loss: 0.0367,V Acc: 0.8000, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.5152
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.9090909090909091
Fold [5/5] Epoch [0/100] Initial Loss: 0.1399, Training Loss: 0.1399, Initial Validation Loss: 0.1328, Validation Loss: 0.1328,V Acc: 0.3056, Top 70th Acc: 0.2237, Bottom 30th Acc: 0.5000
Fold [5/5] Epoch [10/100] Initial Loss: 0.1399, Training Loss: 0.0410, Initial Validation Loss: 0.1328, Validation Loss: 0.0416,V Acc: 0.8148, Top 70th Acc: 0.9211, Bottom 30th Acc: 0.5625
Fold [5/5] Epoch [20/100] Initial Loss: 0.1399, Training Loss: 0.0244, Initial Validation Loss: 0.1328, Validation Loss: 0.0315,V Acc: 0.8148, Top 70th Acc: 0.9211, Bottom 30th Acc: 0.5625
Fold [5/5] Epoch [30/100] Initial Loss: 0.1399, Training Loss: 0.0220, Initial Validation Loss: 0.1328, Validation Loss: 0.0287,V Acc: 0.8426, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.6250
Stopping early at Epoch (base 0): 30  Rolling back to Epoch (base 0): 25  Top Validation Acc: 0.9342105263157895
3 4 [array([0.26036692, 0.08122802, 0.20589809, 0.25812185, 0.19438502],
      dtype=float32)]
Running train_nn.py with seed 4
CUDA:False
Training samples count:  550
Training on 20 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1395, Training Loss: 0.1395, Initial Validation Loss: 0.1390, Validation Loss: 0.1390,V Acc: 0.2613, Top 70th Acc: 0.2821, Bottom 30th Acc: 0.2121
Fold [1/5] Epoch [10/100] Initial Loss: 0.1395, Training Loss: 0.0451, Initial Validation Loss: 0.1390, Validation Loss: 0.0520,V Acc: 0.7838, Top 70th Acc: 0.8718, Bottom 30th Acc: 0.5758
Fold [1/5] Epoch [20/100] Initial Loss: 0.1395, Training Loss: 0.0280, Initial Validation Loss: 0.1390, Validation Loss: 0.0439,V Acc: 0.8198, Top 70th Acc: 0.8846, Bottom 30th Acc: 0.6667
Fold [1/5] Epoch [30/100] Initial Loss: 0.1395, Training Loss: 0.0220, Initial Validation Loss: 0.1390, Validation Loss: 0.0367,V Acc: 0.8288, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.6061
Fold [1/5] Epoch [40/100] Initial Loss: 0.1395, Training Loss: 0.0204, Initial Validation Loss: 0.1390, Validation Loss: 0.0360,V Acc: 0.8018, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.4848
Stopping early at Epoch (base 0): 46  Rolling back to Epoch (base 0): 41  Top Validation Acc: 0.9230769230769231
Fold [2/5] Epoch [0/100] Initial Loss: 0.1394, Training Loss: 0.1394, Initial Validation Loss: 0.1376, Validation Loss: 0.1376,V Acc: 0.3063, Top 70th Acc: 0.3205, Bottom 30th Acc: 0.2727
Fold [2/5] Epoch [10/100] Initial Loss: 0.1394, Training Loss: 0.0370, Initial Validation Loss: 0.1376, Validation Loss: 0.0347,V Acc: 0.8378, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.5152
Fold [2/5] Epoch [20/100] Initial Loss: 0.1394, Training Loss: 0.0237, Initial Validation Loss: 0.1376, Validation Loss: 0.0282,V Acc: 0.8739, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.7273
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.9358974358974359
Fold [3/5] Epoch [0/100] Initial Loss: 0.1417, Training Loss: 0.1417, Initial Validation Loss: 0.1341, Validation Loss: 0.1341,V Acc: 0.3000, Top 70th Acc: 0.3636, Bottom 30th Acc: 0.1515
Fold [3/5] Epoch [10/100] Initial Loss: 0.1417, Training Loss: 0.0296, Initial Validation Loss: 0.1341, Validation Loss: 0.0445,V Acc: 0.7818, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.4848
Fold [3/5] Epoch [20/100] Initial Loss: 0.1417, Training Loss: 0.0218, Initial Validation Loss: 0.1341, Validation Loss: 0.0366,V Acc: 0.8364, Top 70th Acc: 0.8961, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.8831168831168831
Fold [4/5] Epoch [0/100] Initial Loss: 0.1396, Training Loss: 0.1396, Initial Validation Loss: 0.1348, Validation Loss: 0.1348,V Acc: 0.2545, Top 70th Acc: 0.2987, Bottom 30th Acc: 0.1515
Fold [4/5] Epoch [10/100] Initial Loss: 0.1396, Training Loss: 0.0309, Initial Validation Loss: 0.1348, Validation Loss: 0.0306,V Acc: 0.8818, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.6970
Fold [4/5] Epoch [20/100] Initial Loss: 0.1396, Training Loss: 0.0225, Initial Validation Loss: 0.1348, Validation Loss: 0.0282,V Acc: 0.8636, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 20  Rolling back to Epoch (base 0): 15  Top Validation Acc: 0.961038961038961
4 3 [array([0.22232229, 0.09195496, 0.10403055, 0.258651  , 0.32304117],
      dtype=float32)]
Fold [5/5] Epoch [0/100] Initial Loss: 0.1391, Training Loss: 0.1391, Initial Validation Loss: 0.1278, Validation Loss: 0.1278,V Acc: 0.3241, Top 70th Acc: 0.3816, Bottom 30th Acc: 0.1875
Fold [5/5] Epoch [10/100] Initial Loss: 0.1391, Training Loss: 0.0431, Initial Validation Loss: 0.1278, Validation Loss: 0.0433,V Acc: 0.7870, Top 70th Acc: 0.8684, Bottom 30th Acc: 0.5938
Fold [5/5] Epoch [20/100] Initial Loss: 0.1391, Training Loss: 0.0259, Initial Validation Loss: 0.1278, Validation Loss: 0.0325,V Acc: 0.8148, Top 70th Acc: 0.9211, Bottom 30th Acc: 0.5625
Fold [5/5] Epoch [30/100] Initial Loss: 0.1391, Training Loss: 0.0215, Initial Validation Loss: 0.1278, Validation Loss: 0.0288,V Acc: 0.8333, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.5938 29  Rolling back to Epoch (base 0): 24  Top Validation Acc: 0.9736842105263158
Running train_nn.py with seed 3
CUDA:False
Training samples count:  550
Training on 163 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1387, Training Loss: 0.1387, Initial Validation Loss: 0.1363, Validation Loss: 0.1363,V Acc: 0.2523, Top 70th Acc: 0.3077, Bottom 30th Acc: 0.1212
Fold [1/5] Epoch [10/100] Initial Loss: 0.1387, Training Loss: 0.0217, Initial Validation Loss: 0.1363, Validation Loss: 0.0476,V Acc: 0.7568, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.3939
Fold [1/5] Epoch [20/100] Initial Loss: 0.1387, Training Loss: 0.0050, Initial Validation Loss: 0.1363, Validation Loss: 0.0347,V Acc: 0.8018, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.5152
Fold [1/5] Epoch [30/100] Initial Loss: 0.1387, Training Loss: 0.0039, Initial Validation Loss: 0.1363, Validation Loss: 0.0337,V Acc: 0.8198, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 39  Rolling back to Epoch (base 0): 34  Top Validation Acc: 0.9358974358974359
Fold [2/5] Epoch [0/100] Initial Loss: 0.1411, Training Loss: 0.1411, Initial Validation Loss: 0.1374, Validation Loss: 0.1374,V Acc: 0.2432, Top 70th Acc: 0.3205, Bottom 30th Acc: 0.0606
Fold [2/5] Epoch [10/100] Initial Loss: 0.1411, Training Loss: 0.0187, Initial Validation Loss: 0.1374, Validation Loss: 0.0211,V Acc: 0.9279, Top 70th Acc: 1.0000, Bottom 30th Acc: 0.7576
Fold [2/5] Epoch [20/100] Initial Loss: 0.1411, Training Loss: 0.0044, Initial Validation Loss: 0.1374, Validation Loss: 0.0145,V Acc: 0.9189, Top 70th Acc: 1.0000, Bottom 30th Acc: 0.7273
Fold [2/5] Epoch [30/100] Initial Loss: 0.1411, Training Loss: 0.0035, Initial Validation Loss: 0.1374, Validation Loss: 0.0144,V Acc: 0.9369, Top 70th Acc: 1.0000, Bottom 30th Acc: 0.7879
Stopping early at Epoch (base 0): 34  Rolling back to Epoch (base 0): 29  Top Validation Acc: 1.0
Fold [3/5] Epoch [0/100] Initial Loss: 0.1362, Training Loss: 0.1362, Initial Validation Loss: 0.1327, Validation Loss: 0.1327,V Acc: 0.3909, Top 70th Acc: 0.4545, Bottom 30th Acc: 0.2424
Fold [3/5] Epoch [10/100] Initial Loss: 0.1362, Training Loss: 0.0149, Initial Validation Loss: 0.1327, Validation Loss: 0.0331,V Acc: 0.8636, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6667
Fold [3/5] Epoch [20/100] Initial Loss: 0.1362, Training Loss: 0.0046, Initial Validation Loss: 0.1327, Validation Loss: 0.0263,V Acc: 0.8545, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.6061
Fold [3/5] Epoch [30/100] Initial Loss: 0.1362, Training Loss: 0.0037, Initial Validation Loss: 0.1327, Validation Loss: 0.0256,V Acc: 0.8545, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 33  Rolling back to Epoch (base 0): 28  Top Validation Acc: 0.974025974025974
Fold [4/5] Epoch [0/100] Initial Loss: 0.1395, Training Loss: 0.1395, Initial Validation Loss: 0.1332, Validation Loss: 0.1332,V Acc: 0.3727, Top 70th Acc: 0.4545, Bottom 30th Acc: 0.1818
Fold [4/5] Epoch [10/100] Initial Loss: 0.1395, Training Loss: 0.0274, Initial Validation Loss: 0.1332, Validation Loss: 0.0440,V Acc: 0.7727, Top 70th Acc: 0.8831, Bottom 30th Acc: 0.5152
Fold [4/5] Epoch [20/100] Initial Loss: 0.1395, Training Loss: 0.0054, Initial Validation Loss: 0.1332, Validation Loss: 0.0315,V Acc: 0.8273, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.5758
Fold [4/5] Epoch [30/100] Initial Loss: 0.1395, Training Loss: 0.0041, Initial Validation Loss: 0.1332, Validation Loss: 0.0307,V Acc: 0.8364, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 35  Rolling back to Epoch (base 0): 30  Top Validation Acc: 0.922077922077922
Fold [5/5] Epoch [0/100] Initial Loss: 0.1405, Training Loss: 0.1405, Initial Validation Loss: 0.1297, Validation Loss: 0.1297,V Acc: 0.2685, Top 70th Acc: 0.3684, Bottom 30th Acc: 0.0312
Fold [5/5] Epoch [10/100] Initial Loss: 0.1405, Training Loss: 0.0135, Initial Validation Loss: 0.1297, Validation Loss: 0.0390,V Acc: 0.7778, Top 70th Acc: 0.9211, Bottom 30th Acc: 0.4375
Fold [5/5] Epoch [20/100] Initial Loss: 0.1405, Training Loss: 0.0051, Initial Validation Loss: 0.1297, Validation Loss: 0.0324,V Acc: 0.8056, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.4688
Fold [5/5] Epoch [30/100] Initial Loss: 0.1405, Training Loss: 0.0041, Initial Validation Loss: 0.1297, Validation Loss: 0.0311,V Acc: 0.8148, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.4688
Fold [5/5] Epoch [40/100] Initial Loss: 0.1405, Training Loss: 0.0037, Initial Validation Loss: 0.1297, Validation Loss: 0.0296,V Acc: 0.8426, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.5938
Stopping early at Epoch (base 0): 43  Rolling back to Epoch (base 0): 38  Top Validation Acc: 0.9473684210526315
3 4 [array([0.2912714 , 0.09350746, 0.10827097, 0.18028882, 0.32666144],
      dtype=float32)]
Running train_nn.py with seed 4
CUDA:False
Training samples count:  550
Training on 163 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1394, Training Loss: 0.1394, Initial Validation Loss: 0.1383, Validation Loss: 0.1383,V Acc: 0.3153, Top 70th Acc: 0.3333, Bottom 30th Acc: 0.2727
Fold [1/5] Epoch [10/100] Initial Loss: 0.1394, Training Loss: 0.0190, Initial Validation Loss: 0.1383, Validation Loss: 0.0402,V Acc: 0.8198, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.5455
Fold [1/5] Epoch [20/100] Initial Loss: 0.1394, Training Loss: 0.0067, Initial Validation Loss: 0.1383, Validation Loss: 0.0343,V Acc: 0.8468, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.6364
Fold [1/5] Epoch [30/100] Initial Loss: 0.1394, Training Loss: 0.0048, Initial Validation Loss: 0.1383, Validation Loss: 0.0319,V Acc: 0.8559, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.6364
Fold [1/5] Epoch [40/100] Initial Loss: 0.1394, Training Loss: 0.0042, Initial Validation Loss: 0.1383, Validation Loss: 0.0311,V Acc: 0.8739, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.6970
Fold [1/5] Epoch [50/100] Initial Loss: 0.1394, Training Loss: 0.0040, Initial Validation Loss: 0.1383, Validation Loss: 0.0306,V Acc: 0.8829, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.6970
Fold [1/5] Epoch [60/100] Initial Loss: 0.1394, Training Loss: 0.0038, Initial Validation Loss: 0.1383, Validation Loss: 0.0296,V Acc: 0.8829, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 65  Rolling back to Epoch (base 0): 60  Top Validation Acc: 0.9487179487179487
Fold [2/5] Epoch [0/100] Initial Loss: 0.1380, Training Loss: 0.1380, Initial Validation Loss: 0.1367, Validation Loss: 0.1367,V Acc: 0.3153, Top 70th Acc: 0.3718, Bottom 30th Acc: 0.1818
Fold [2/5] Epoch [10/100] Initial Loss: 0.1380, Training Loss: 0.0200, Initial Validation Loss: 0.1367, Validation Loss: 0.0376,V Acc: 0.8559, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.6061
Fold [2/5] Epoch [20/100] Initial Loss: 0.1380, Training Loss: 0.0049, Initial Validation Loss: 0.1367, Validation Loss: 0.0263,V Acc: 0.9189, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.8182
Stopping early at Epoch (base 0): 22  Rolling back to Epoch (base 0): 17  Top Validation Acc: 0.9615384615384616
Fold [3/5] Epoch [0/100] Initial Loss: 0.1380, Training Loss: 0.1380, Initial Validation Loss: 0.1328, Validation Loss: 0.1328,V Acc: 0.2545, Top 70th Acc: 0.3377, Bottom 30th Acc: 0.0606
Fold [3/5] Epoch [10/100] Initial Loss: 0.1380, Training Loss: 0.0161, Initial Validation Loss: 0.1328, Validation Loss: 0.0428,V Acc: 0.7545, Top 70th Acc: 0.8831, Bottom 30th Acc: 0.4545
Fold [3/5] Epoch [20/100] Initial Loss: 0.1380, Training Loss: 0.0048, Initial Validation Loss: 0.1328, Validation Loss: 0.0368,V Acc: 0.7909, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.5152
Stopping early at Epoch (base 0): 29  Rolling back to Epoch (base 0): 24  Top Validation Acc: 0.9090909090909091
Fold [4/5] Epoch [0/100] Initial Loss: 0.1381, Training Loss: 0.1381, Initial Validation Loss: 0.1351, Validation Loss: 0.1351,V Acc: 0.2636, Top 70th Acc: 0.3506, Bottom 30th Acc: 0.0606
Fold [4/5] Epoch [10/100] Initial Loss: 0.1381, Training Loss: 0.0324, Initial Validation Loss: 0.1351, Validation Loss: 0.0483,V Acc: 0.7545, Top 70th Acc: 0.8701, Bottom 30th Acc: 0.4848
Fold [4/5] Epoch [20/100] Initial Loss: 0.1381, Training Loss: 0.0054, Initial Validation Loss: 0.1351, Validation Loss: 0.0340,V Acc: 0.8091, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.5152
Stopping early at Epoch (base 0): 28  Rolling back to Epoch (base 0): 23  Top Validation Acc: 0.9736842105263158
Running train_nn.py with seed 6
CUDA:False
Training samples count:  550
Training on 21 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1282, Training Loss: 0.1282, Initial Validation Loss: 0.1195, Validation Loss: 0.1195,V Acc: 0.4595, Top 70th Acc: 0.6026, Bottom 30th Acc: 0.1212
Fold [1/5] Epoch [10/100] Initial Loss: 0.1282, Training Loss: 0.0237, Initial Validation Loss: 0.1195, Validation Loss: 0.0266,V Acc: 0.8559, Top 70th Acc: 0.9872, Bottom 30th Acc: 0.5455
Fold [1/5] Epoch [20/100] Initial Loss: 0.1282, Training Loss: 0.0182, Initial Validation Loss: 0.1195, Validation Loss: 0.0213,V Acc: 0.8919, Top 70th Acc: 0.9872, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.9615384615384616
6 0 [array([0.6919202 , 0.03278483, 0.03783292, 0.07508893, 0.16237316],
      dtype=float32)]
Fold [2/5] Epoch [0/100] Initial Loss: 0.1331, Training Loss: 0.1331, Initial Validation Loss: 0.1202, Validation Loss: 0.1202,V Acc: 0.4324, Top 70th Acc: 0.6026, Bottom 30th Acc: 0.0303
Fold [2/5] Epoch [10/100] Initial Loss: 0.1331, Training Loss: 0.0255, Initial Validation Loss: 0.1202, Validation Loss: 0.0441,V Acc: 0.8018, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.5455
Fold [2/5] Epoch [20/100] Initial Loss: 0.1331, Training Loss: 0.0181, Initial Validation Loss: 0.1202, Validation Loss: 0.0372,V Acc: 0.8198, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.9230769230769231
Fold [3/5] Epoch [0/100] Initial Loss: 0.1393, Training Loss: 0.1393, Initial Validation Loss: 0.1267, Validation Loss: 0.1267,V Acc: 0.3545, Top 70th Acc: 0.3766, Bottom 30th Acc: 0.3030
Fold [3/5] Epoch [10/100] Initial Loss: 0.1393, Training Loss: 0.0310, Initial Validation Loss: 0.1267, Validation Loss: 0.0423,V Acc: 0.7909, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.4545
Fold [3/5] Epoch [20/100] Initial Loss: 0.1393, Training Loss: 0.0171, Initial Validation Loss: 0.1267, Validation Loss: 0.0305,V Acc: 0.8364, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.5152
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.922077922077922
Fold [4/5] Epoch [0/100] Initial Loss: 0.1330, Training Loss: 0.1330, Initial Validation Loss: 0.1237, Validation Loss: 0.1237,V Acc: 0.4455, Top 70th Acc: 0.5195, Bottom 30th Acc: 0.2727
Fold [4/5] Epoch [10/100] Initial Loss: 0.1330, Training Loss: 0.0269, Initial Validation Loss: 0.1237, Validation Loss: 0.0256,V Acc: 0.9182, Top 70th Acc: 1.0000, Bottom 30th Acc: 0.7273
Fold [4/5] Epoch [20/100] Initial Loss: 0.1330, Training Loss: 0.0194, Initial Validation Loss: 0.1237, Validation Loss: 0.0176,V Acc: 0.9364, Top 70th Acc: 1.0000, Bottom 30th Acc: 0.7879
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.987012987012987
Fold [5/5] Epoch [0/100] Initial Loss: 0.1370, Training Loss: 0.1370, Initial Validation Loss: 0.1268, Validation Loss: 0.1268,V Acc: 0.2963, Top 70th Acc: 0.3289, Bottom 30th Acc: 0.2188
Fold [5/5] Epoch [10/100] Initial Loss: 0.1370, Training Loss: 0.0291, Initial Validation Loss: 0.1268, Validation Loss: 0.0296,V Acc: 0.8426, Top 70th Acc: 0.9737, Bottom 30th Acc: 0.5312
Fold [5/5] Epoch [20/100] Initial Loss: 0.1370, Training Loss: 0.0189, Initial Validation Loss: 0.1268, Validation Loss: 0.0262,V Acc: 0.8611, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.6562
Stopping early at Epoch (base 0): 21  Rolling back to Epoch (base 0): 16  Top Validation Acc: 0.9473684210526315
Running train_nn.py with seed 7
CUDA:False
Training samples count:  550
Training on 21 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1322, Training Loss: 0.1322, Initial Validation Loss: 0.1152, Validation Loss: 0.1152,V Acc: 0.5495, Top 70th Acc: 0.7179, Bottom 30th Acc: 0.1515
Fold [1/5] Epoch [10/100] Initial Loss: 0.1322, Training Loss: 0.0230, Initial Validation Loss: 0.1152, Validation Loss: 0.0263,V Acc: 0.8739, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.6667
Fold [1/5] Epoch [20/100] Initial Loss: 0.1322, Training Loss: 0.0172, Initial Validation Loss: 0.1152, Validation Loss: 0.0293,V Acc: 0.8739, Top 70th Acc: 0.8974, Bottom 30th Acc: 0.8182
Stopping early at Epoch (base 0): 20  Rolling back to Epoch (base 0): 15  Top Validation Acc: 0.8974358974358975
Fold [2/5] Epoch [0/100] Initial Loss: 0.1387, Training Loss: 0.1387, Initial Validation Loss: 0.1334, Validation Loss: 0.1334,V Acc: 0.3063, Top 70th Acc: 0.3590, Bottom 30th Acc: 0.1818
Fold [2/5] Epoch [10/100] Initial Loss: 0.1387, Training Loss: 0.0236, Initial Validation Loss: 0.1334, Validation Loss: 0.0388,V Acc: 0.8108, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.5152
Stopping early at Epoch (base 0): 19  Rolling back to Epoch (base 0): 14  Top Validation Acc: 0.9871794871794872
Fold [3/5] Epoch [0/100] Initial Loss: 0.1374, Training Loss: 0.1374, Initial Validation Loss: 0.1264, Validation Loss: 0.1264,V Acc: 0.4273, Top 70th Acc: 0.4156, Bottom 30th Acc: 0.4545
Fold [3/5] Epoch [10/100] Initial Loss: 0.1374, Training Loss: 0.0267, Initial Validation Loss: 0.1264, Validation Loss: 0.0308,V Acc: 0.8455, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 15  Rolling back to Epoch (base 0): 10  Top Validation Acc: 0.935064935064935
7 2 [array([0.72471267, 0.02366813, 0.05219032, 0.08290395, 0.11652496],
      dtype=float32)]
Fold [4/5] Epoch [0/100] Initial Loss: 0.1340, Training Loss: 0.1340, Initial Validation Loss: 0.1275, Validation Loss: 0.1275,V Acc: 0.5000, Top 70th Acc: 0.6234, Bottom 30th Acc: 0.2121
Fold [4/5] Epoch [10/100] Initial Loss: 0.1340, Training Loss: 0.0225, Initial Validation Loss: 0.1275, Validation Loss: 0.0346,V Acc: 0.8636, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 17  Rolling back to Epoch (base 0): 12  Top Validation Acc: 0.974025974025974
Fold [5/5] Epoch [0/100] Initial Loss: 0.1370, Training Loss: 0.1370, Initial Validation Loss: 0.1297, Validation Loss: 0.1297,V Acc: 0.4259, Top 70th Acc: 0.5921, Bottom 30th Acc: 0.0312
Fold [5/5] Epoch [10/100] Initial Loss: 0.1370, Training Loss: 0.0264, Initial Validation Loss: 0.1297, Validation Loss: 0.0279,V Acc: 0.8704, Top 70th Acc: 0.9737, Bottom 30th Acc: 0.6250
Fold [5/5] Epoch [20/100] Initial Loss: 0.1370, Training Loss: 0.0208, Initial Validation Loss: 0.1297, Validation Loss: 0.0241,V Acc: 0.8889, Top 70th Acc: 0.9868, Bottom 30th Acc: 0.6562
Fold [5/5] Epoch [30/100] Initial Loss: 0.1370, Training Loss: 0.0172, Initial Validation Loss: 0.1297, Validation Loss: 0.0240,V Acc: 0.9167, Top 70th Acc: 0.9737, Bottom 30th Acc: 0.7812
Stopping early at Epoch (base 0): 33  Rolling back to Epoch (base 0): 28  Top Validation Acc: 0.9605263157894737
Running train_nn.py with seed 8
CUDA:False
Training samples count:  550
Training on 21 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1349, Training Loss: 0.1349, Initial Validation Loss: 0.1173, Validation Loss: 0.1173,V Acc: 0.4955, Top 70th Acc: 0.5641, Bottom 30th Acc: 0.3333
Fold [1/5] Epoch [10/100] Initial Loss: 0.1349, Training Loss: 0.0254, Initial Validation Loss: 0.1173, Validation Loss: 0.0261,V Acc: 0.8649, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.6364
Fold [1/5] Epoch [20/100] Initial Loss: 0.1349, Training Loss: 0.0175, Initial Validation Loss: 0.1173, Validation Loss: 0.0262,V Acc: 0.8468, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 21  Rolling back to Epoch (base 0): 16  Top Validation Acc: 0.9743589743589743
Fold [2/5] Epoch [0/100] Initial Loss: 0.1363, Training Loss: 0.1363, Initial Validation Loss: 0.1321, Validation Loss: 0.1321,V Acc: 0.4595, Top 70th Acc: 0.5256, Bottom 30th Acc: 0.3030
Fold [2/5] Epoch [10/100] Initial Loss: 0.1363, Training Loss: 0.0275, Initial Validation Loss: 0.1321, Validation Loss: 0.0416,V Acc: 0.8288, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.6364
Fold [2/5] Epoch [20/100] Initial Loss: 0.1363, Training Loss: 0.0164, Initial Validation Loss: 0.1321, Validation Loss: 0.0386,V Acc: 0.8649, Top 70th Acc: 0.8974, Bottom 30th Acc: 0.7879training rf with seed 1
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 2 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 2
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 2 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 3
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 2 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 4
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 2 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 5
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 2 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 6
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 2 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 7
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 2 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 8
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 2 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 9
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 2 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 10
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 2 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 11
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 2 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 12
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 2 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 13
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 2 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 14
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 2 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 15
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 2 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 16
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 2 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 17
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 2 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 18
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 2 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 19
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 2 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 20
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 2 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 21
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 2 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 22
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 2 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 23
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 2 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 24
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 2 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 25
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 2 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 26
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 2 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 27
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 2 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 28
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 2 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 29
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 2 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 30
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 2 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 31
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 2 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 32
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 2 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 33
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 2 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 34
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 2 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 35
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 2 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 36
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 2 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 37
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 2 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 38
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 2 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 39
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 2 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 40
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 2 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 41
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 2 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 42
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 2 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 43
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 2 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 44
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 2 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 45
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 2 features
Fold: 1
Fold [5/5] Epoch [40/100] Initial Loss: 0.1391, Training Loss: 0.0194, Initial Validation Loss: 0.1278, Validation Loss: 0.0285,V Acc: 0.8333, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.5938
Stopping early at Epoch (base 0): 40  Rolling back to Epoch (base 0): 35  Top Validation Acc: 0.9342105263157895
Running train_nn.py with seed 5
CUDA:False
Training samples count:  550
Training on 20 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1393, Training Loss: 0.1393, Initial Validation Loss: 0.1335, Validation Loss: 0.1335,V Acc: 0.4144, Top 70th Acc: 0.5256, Bottom 30th Acc: 0.1515
Fold [1/5] Epoch [10/100] Initial Loss: 0.1393, Training Loss: 0.0502, Initial Validation Loss: 0.1335, Validation Loss: 0.0423,V Acc: 0.7928, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.4848
Fold [1/5] Epoch [20/100] Initial Loss: 0.1393, Training Loss: 0.0272, Initial Validation Loss: 0.1335, Validation Loss: 0.0298,V Acc: 0.8559, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.6364
Fold [1/5] Epoch [30/100] Initial Loss: 0.1393, Training Loss: 0.0226, Initial Validation Loss: 0.1335, Validation Loss: 0.0283,V Acc: 0.8649, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 33  Rolling back to Epoch (base 0): 28  Top Validation Acc: 0.9615384615384616
Fold [2/5] Epoch [0/100] Initial Loss: 0.1424, Training Loss: 0.1424, Initial Validation Loss: 0.1356, Validation Loss: 0.1356,V Acc: 0.3514, Top 70th Acc: 0.4103, Bottom 30th Acc: 0.2121
Fold [2/5] Epoch [10/100] Initial Loss: 0.1424, Training Loss: 0.0504, Initial Validation Loss: 0.1356, Validation Loss: 0.0502,V Acc: 0.7838, Top 70th Acc: 0.8590, Bottom 30th Acc: 0.6061
Fold [2/5] Epoch [20/100] Initial Loss: 0.1424, Training Loss: 0.0251, Initial Validation Loss: 0.1356, Validation Loss: 0.0310,V Acc: 0.8559, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.7273
Stopping early at Epoch (base 0): 29  Rolling back to Epoch (base 0): 24  Top Validation Acc: 0.9102564102564102
Fold [3/5] Epoch [0/100] Initial Loss: 0.1363, Training Loss: 0.1363, Initial Validation Loss: 0.1295, Validation Loss: 0.1295,V Acc: 0.3000, Top 70th Acc: 0.3506, Bottom 30th Acc: 0.1818
Fold [3/5] Epoch [10/100] Initial Loss: 0.1363, Training Loss: 0.0330, Initial Validation Loss: 0.1295, Validation Loss: 0.0381,V Acc: 0.8000, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.5455
Fold [3/5] Epoch [20/100] Initial Loss: 0.1363, Training Loss: 0.0238, Initial Validation Loss: 0.1295, Validation Loss: 0.0326,V Acc: 0.8000, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.4848
Fold [3/5] Epoch [30/100] Initial Loss: 0.1363, Training Loss: 0.0215, Initial Validation Loss: 0.1295, Validation Loss: 0.0326,V Acc: 0.8182, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 30  Rolling back to Epoch (base 0): 25  Top Validation Acc: 0.935064935064935
Fold [4/5] Epoch [0/100] Initial Loss: 0.1365, Training Loss: 0.1365, Initial Validation Loss: 0.1335, Validation Loss: 0.1335,V Acc: 0.2909, Top 70th Acc: 0.3506, Bottom 30th Acc: 0.1515
Fold [4/5] Epoch [10/100] Initial Loss: 0.1365, Training Loss: 0.0430, Initial Validation Loss: 0.1335, Validation Loss: 0.0571,V Acc: 0.7364, Top 70th Acc: 0.8701, Bottom 30th Acc: 0.4242
Fold [4/5] Epoch [20/100] Initial Loss: 0.1365, Training Loss: 0.0231, Initial Validation Loss: 0.1335, Validation Loss: 0.0418,V Acc: 0.8545, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.7273
Stopping early at Epoch (base 0): 27  Rolling back to Epoch (base 0): 22  Top Validation Acc: 0.922077922077922
5 3 [array([0.31166017, 0.10674955, 0.16874842, 0.22534329, 0.18749861],
      dtype=float32)]
Fold [5/5] Epoch [0/100] Initial Loss: 0.1369, Training Loss: 0.1369, Initial Validation Loss: 0.1295, Validation Loss: 0.1295,V Acc: 0.4352, Top 70th Acc: 0.4737, Bottom 30th Acc: 0.3438
Fold [5/5] Epoch [10/100] Initial Loss: 0.1369, Training Loss: 0.0421, Initial Validation Loss: 0.1295, Validation Loss: 0.0503,V Acc: 0.7685, Top 70th Acc: 0.8816, Bottom 30th Acc: 0.5000
Fold [5/5] Epoch [20/100] Initial Loss: 0.1369, Training Loss: 0.0256, Initial Validation Loss: 0.1295, Validation Loss: 0.0358,V Acc: 0.8519, Top 70th Acc: 0.9211, Bottom 30th Acc: 0.6875
Fold [5/5] Epoch [30/100] Initial Loss: 0.1369, Training Loss: 0.0210, Initial Validation Loss: 0.1295, Validation Loss: 0.0333,V Acc: 0.8796, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.7500
Fold [5/5] Epoch [40/100] Initial Loss: 0.1369, Training Loss: 0.0201, Initial Validation Loss: 0.1295, Validation Loss: 0.0323,V Acc: 0.8796, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.7500
Fold [5/5] Epoch [50/100] Initial Loss: 0.1369, Training Loss: 0.0194, Initial Validation Loss: 0.1295, Validation Loss: 0.0316,V Acc: 0.8796, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.7500
Stopping early at Epoch (base 0): 50  Rolling back to Epoch (base 0): 45  Top Validation Acc: 0.9342105263157895
Running train_nn.py with seed 6
CUDA:False
Training samples count:  550
Training on 20 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1377, Training Loss: 0.1377, Initial Validation Loss: 0.1376, Validation Loss: 0.1376,V Acc: 0.2613, Top 70th Acc: 0.3077, Bottom 30th Acc: 0.1515
Fold [1/5] Epoch [10/100] Initial Loss: 0.1377, Training Loss: 0.0355, Initial Validation Loss: 0.1376, Validation Loss: 0.0366,V Acc: 0.8649, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.6667
Fold [1/5] Epoch [20/100] Initial Loss: 0.1377, Training Loss: 0.0249, Initial Validation Loss: 0.1376, Validation Loss: 0.0303,V Acc: 0.8829, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.7273
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.9230769230769231
6 0 [array([0.377446  , 0.0468014 , 0.30910847, 0.14880651, 0.11783769],
      dtype=float32)]
Fold [2/5] Epoch [0/100] Initial Loss: 0.1383, Training Loss: 0.1383, Initial Validation Loss: 0.1358, Validation Loss: 0.1358,V Acc: 0.2613, Top 70th Acc: 0.3077, Bottom 30th Acc: 0.1515
Fold [2/5] Epoch [10/100] Initial Loss: 0.1383, Training Loss: 0.0316, Initial Validation Loss: 0.1358, Validation Loss: 0.0444,V Acc: 0.8018, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.5455
Fold [2/5] Epoch [20/100] Initial Loss: 0.1383, Training Loss: 0.0216, Initial Validation Loss: 0.1358, Validation Loss: 0.0388,V Acc: 0.8288, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 29  Rolling back to Epoch (base 0): 24  Top Validation Acc: 0.9102564102564102
Fold [3/5] Epoch [0/100] Initial Loss: 0.1362, Training Loss: 0.1362, Initial Validation Loss: 0.1275, Validation Loss: 0.1275,V Acc: 0.3455, Top 70th Acc: 0.3766, Bottom 30th Acc: 0.2727
Fold [3/5] Epoch [10/100] Initial Loss: 0.1362, Training Loss: 0.0313, Initial Validation Loss: 0.1275, Validation Loss: 0.0391,V Acc: 0.7727, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.4242
Fold [3/5] Epoch [20/100] Initial Loss: 0.1362, Training Loss: 0.0222, Initial Validation Loss: 0.1275, Validation Loss: 0.0361,V Acc: 0.7818, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.4545
Stopping early at Epoch (base 0): 22  Rolling back to Epoch (base 0): 17  Top Validation Acc: 0.9090909090909091
Fold [4/5] Epoch [0/100] Initial Loss: 0.1392, Training Loss: 0.1392, Initial Validation Loss: 0.1339, Validation Loss: 0.1339,V Acc: 0.2909, Top 70th Acc: 0.3636, Bottom 30th Acc: 0.1212
Fold [4/5] Epoch [10/100] Initial Loss: 0.1392, Training Loss: 0.0383, Initial Validation Loss: 0.1339, Validation Loss: 0.0471,V Acc: 0.8091, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.5455
Fold [4/5] Epoch [20/100] Initial Loss: 0.1392, Training Loss: 0.0233, Initial Validation Loss: 0.1339, Validation Loss: 0.0382,V Acc: 0.8727, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.7273
Fold [4/5] Epoch [30/100] Initial Loss: 0.1392, Training Loss: 0.0203, Initial Validation Loss: 0.1339, Validation Loss: 0.0364,V Acc: 0.8545, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 31  Rolling back to Epoch (base 0): 26  Top Validation Acc: 0.935064935064935
Fold [5/5] Epoch [0/100] Initial Loss: 0.1380, Training Loss: 0.1380, Initial Validation Loss: 0.1296, Validation Loss: 0.1296,V Acc: 0.2593, Top 70th Acc: 0.3158, Bottom 30th Acc: 0.1250
Fold [5/5] Epoch [10/100] Initial Loss: 0.1380, Training Loss: 0.0363, Initial Validation Loss: 0.1296, Validation Loss: 0.0386,V Acc: 0.7963, Top 70th Acc: 0.8947, Bottom 30th Acc: 0.5625
Fold [1/5] Epoch [10/100] Initial Loss: 0.1389, Training Loss: 0.0838, Initial Validation Loss: 0.1272, Validation Loss: 0.0681,V Acc: 0.6847, Top 70th Acc: 0.7949, Bottom 30th Acc: 0.4242
Stopping early at Epoch (base 0): 19  Rolling back to Epoch (base 0): 14  Top Validation Acc: 0.8205128205128205
Fold [2/5] Epoch [0/100] Initial Loss: 0.1395, Training Loss: 0.1395, Initial Validation Loss: 0.1286, Validation Loss: 0.1286,V Acc: 0.2793, Top 70th Acc: 0.3590, Bottom 30th Acc: 0.0909
Fold [2/5] Epoch [10/100] Initial Loss: 0.1395, Training Loss: 0.0826, Initial Validation Loss: 0.1286, Validation Loss: 0.0759,V Acc: 0.6757, Top 70th Acc: 0.7436, Bottom 30th Acc: 0.5152
Fold [2/5] Epoch [20/100] Initial Loss: 0.1395, Training Loss: 0.0813, Initial Validation Loss: 0.1286, Validation Loss: 0.0728,V Acc: 0.6757, Top 70th Acc: 0.7821, Bottom 30th Acc: 0.4242
Fold [2/5] Epoch [30/100] Initial Loss: 0.1395, Training Loss: 0.0803, Initial Validation Loss: 0.1286, Validation Loss: 0.0723,V Acc: 0.6667, Top 70th Acc: 0.8077, Bottom 30th Acc: 0.3333
Stopping early at Epoch (base 0): 39  Rolling back to Epoch (base 0): 34  Top Validation Acc: 0.7948717948717948
Fold [3/5] Epoch [0/100] Initial Loss: 0.1406, Training Loss: 0.1406, Initial Validation Loss: 0.1316, Validation Loss: 0.1316,V Acc: 0.3636, Top 70th Acc: 0.4416, Bottom 30th Acc: 0.1818
Fold [3/5] Epoch [10/100] Initial Loss: 0.1406, Training Loss: 0.0796, Initial Validation Loss: 0.1316, Validation Loss: 0.0805,V Acc: 0.6182, Top 70th Acc: 0.7532, Bottom 30th Acc: 0.3030
Fold [3/5] Epoch [20/100] Initial Loss: 0.1406, Training Loss: 0.0774, Initial Validation Loss: 0.1316, Validation Loss: 0.0796,V Acc: 0.6273, Top 70th Acc: 0.7532, Bottom 30th Acc: 0.3333
Fold [3/5] Epoch [30/100] Initial Loss: 0.1406, Training Loss: 0.0768, Initial Validation Loss: 0.1316, Validation Loss: 0.0785,V Acc: 0.6182, Top 70th Acc: 0.7403, Bottom 30th Acc: 0.3333
Stopping early at Epoch (base 0): 32  Rolling back to Epoch (base 0): 27  Top Validation Acc: 0.7402597402597403
Fold [4/5] Epoch [0/100] Initial Loss: 0.1297, Training Loss: 0.1297, Initial Validation Loss: 0.1210, Validation Loss: 0.1210,V Acc: 0.5000, Top 70th Acc: 0.6104, Bottom 30th Acc: 0.2424
Fold [4/5] Epoch [10/100] Initial Loss: 0.1297, Training Loss: 0.0780, Initial Validation Loss: 0.1210, Validation Loss: 0.0902,V Acc: 0.5545, Top 70th Acc: 0.6494, Bottom 30th Acc: 0.3333
Stopping early at Epoch (base 0): 19  Rolling back to Epoch (base 0): 14  Top Validation Acc: 0.6623376623376623
5 3 [array([0.14621282, 0.3708439 , 0.14922212, 0.2029144 , 0.13080674],
      dtype=float32)]
Fold [5/5] Epoch [0/100] Initial Loss: 0.1340, Training Loss: 0.1340, Initial Validation Loss: 0.1243, Validation Loss: 0.1243,V Acc: 0.4537, Top 70th Acc: 0.4737, Bottom 30th Acc: 0.4062
Fold [5/5] Epoch [10/100] Initial Loss: 0.1340, Training Loss: 0.0784, Initial Validation Loss: 0.1243, Validation Loss: 0.0879,V Acc: 0.5556, Top 70th Acc: 0.6711, Bottom 30th Acc: 0.2812
Fold [5/5] Epoch [20/100] Initial Loss: 0.1340, Training Loss: 0.0764, Initial Validation Loss: 0.1243, Validation Loss: 0.0869,V Acc: 0.5833, Top 70th Acc: 0.6711, Bottom 30th Acc: 0.3750
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.6842105263157895
Running train_nn.py with seed 6
CUDA:False
Training samples count:  550
Training on 2 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1380, Training Loss: 0.1380, Initial Validation Loss: 0.1338, Validation Loss: 0.1338,V Acc: 0.2703, Top 70th Acc: 0.3718, Bottom 30th Acc: 0.0303
Fold [1/5] Epoch [10/100] Initial Loss: 0.1380, Training Loss: 0.0827, Initial Validation Loss: 0.1338, Validation Loss: 0.0775,V Acc: 0.6667, Top 70th Acc: 0.7564, Bottom 30th Acc: 0.4545
Fold [1/5] Epoch [20/100] Initial Loss: 0.1380, Training Loss: 0.0804, Initial Validation Loss: 0.1338, Validation Loss: 0.0757,V Acc: 0.6667, Top 70th Acc: 0.7692, Bottom 30th Acc: 0.4242
Fold [1/5] Epoch [30/100] Initial Loss: 0.1380, Training Loss: 0.0795, Initial Validation Loss: 0.1338, Validation Loss: 0.0743,V Acc: 0.6396, Top 70th Acc: 0.7564, Bottom 30th Acc: 0.3636
Stopping early at Epoch (base 0): 31  Rolling back to Epoch (base 0): 26  Top Validation Acc: 0.7692307692307693
6 0 [array([0.12655008, 0.29418093, 0.14356783, 0.25410855, 0.18159255],
      dtype=float32)]
Fold [2/5] Epoch [0/100] Initial Loss: 0.1385, Training Loss: 0.1385, Initial Validation Loss: 0.1307, Validation Loss: 0.1307,V Acc: 0.4144, Top 70th Acc: 0.5128, Bottom 30th Acc: 0.1818
Fold [2/5] Epoch [10/100] Initial Loss: 0.1385, Training Loss: 0.0805, Initial Validation Loss: 0.1307, Validation Loss: 0.0811,V Acc: 0.6036, Top 70th Acc: 0.6923, Bottom 30th Acc: 0.3939
Fold [2/5] Epoch [20/100] Initial Loss: 0.1385, Training Loss: 0.0781, Initial Validation Loss: 0.1307, Validation Loss: 0.0798,V Acc: 0.6036, Top 70th Acc: 0.7051, Bottom 30th Acc: 0.3636
Fold [2/5] Epoch [30/100] Initial Loss: 0.1385, Training Loss: 0.0777, Initial Validation Loss: 0.1307, Validation Loss: 0.0790,V Acc: 0.6216, Top 70th Acc: 0.7179, Bottom 30th Acc: 0.3939
Stopping early at Epoch (base 0): 32  Rolling back to Epoch (base 0): 27  Top Validation Acc: 0.717948717948718
Fold [3/5] Epoch [0/100] Initial Loss: 0.1330, Training Loss: 0.1330, Initial Validation Loss: 0.1202, Validation Loss: 0.1202,V Acc: 0.5000, Top 70th Acc: 0.6234, Bottom 30th Acc: 0.2121
Fold [3/5] Epoch [10/100] Initial Loss: 0.1330, Training Loss: 0.0808, Initial Validation Loss: 0.1202, Validation Loss: 0.0809,V Acc: 0.6182, Top 70th Acc: 0.7532, Bottom 30th Acc: 0.3030
Fold [3/5] Epoch [20/100] Initial Loss: 0.1330, Training Loss: 0.0782, Initial Validation Loss: 0.1202, Validation Loss: 0.0794,V Acc: 0.6273, Top 70th Acc: 0.7403, Bottom 30th Acc: 0.3636
Fold [3/5] Epoch [30/100] Initial Loss: 0.1330, Training Loss: 0.0777, Initial Validation Loss: 0.1202, Validation Loss: 0.0790,V Acc: 0.6273, Top 70th Acc: 0.7662, Bottom 30th Acc: 0.3030
Fold [3/5] Epoch [40/100] Initial Loss: 0.1330, Training Loss: 0.0773, Initial Validation Loss: 0.1202, Validation Loss: 0.0787,V Acc: 0.6273, Top 70th Acc: 0.7532, Bottom 30th Acc: 0.3333
Fold [3/5] Epoch [50/100] Initial Loss: 0.1330, Training Loss: 0.0766, Initial Validation Loss: 0.1202, Validation Loss: 0.0790,V Acc: 0.6364, Top 70th Acc: 0.7532, Bottom 30th Acc: 0.3636
Fold [3/5] Epoch [60/100] Initial Loss: 0.1330, Training Loss: 0.0767, Initial Validation Loss: 0.1202, Validation Loss: 0.0785,V Acc: 0.6364, Top 70th Acc: 0.7532, Bottom 30th Acc: 0.3636
Stopping early at Epoch (base 0): 64  Rolling back to Epoch (base 0): 59  Top Validation Acc: 0.7532467532467533
Fold [4/5] Epoch [0/100] Initial Loss: 0.1338, Training Loss: 0.1338, Initial Validation Loss: 0.1247, Validation Loss: 0.1247,V Acc: 0.5273, Top 70th Acc: 0.6364, Bottom 30th Acc: 0.2727
Fold [4/5] Epoch [10/100] Initial Loss: 0.1338, Training Loss: 0.0806, Initial Validation Loss: 0.1247, Validation Loss: 0.0775,V Acc: 0.6455, Top 70th Acc: 0.7662, Bottom 30th Acc: 0.3636
Stopping early at Epoch (base 0): 18  Rolling back to Epoch (base 0): 13  Top Validation Acc: 0.7532467532467533
Fold [5/5] Epoch [0/100] Initial Loss: 0.1321, Training Loss: 0.1321, Initial Validation Loss: 0.1166, Validation Loss: 0.1166,V Acc: 0.4722, Top 70th Acc: 0.5395, Bottom 30th Acc: 0.3125
Fold [5/5] Epoch [10/100] Initial Loss: 0.1321, Training Loss: 0.0795, Initial Validation Loss: 0.1166, Validation Loss: 0.0832,V Acc: 0.6111, Top 70th Acc: 0.7105, Bottom 30th Acc: 0.3750
Fold [5/5] Epoch [20/100] Initial Loss: 0.1321, Training Loss: 0.0774, Initial Validation Loss: 0.1166, Validation Loss: 0.0819,V Acc: 0.6019, Top 70th Acc: 0.7237, Bottom 30th Acc: 0.3125
Fold [5/5] Epoch [30/100] Initial Loss: 0.1321, Training Loss: 0.0766, Initial Validation Loss: 0.1166, Validation Loss: 0.0816,V Acc: 0.5926, Top 70th Acc: 0.7105, Bottom 30th Acc: 0.3125
Stopping early at Epoch (base 0): 31  Rolling back to Epoch (base 0): 26  Top Validation Acc: 0.7105263157894737
Running train_nn.py with seed 7
CUDA:False
Training samples count:  550
Training on 2 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1360, Training Loss: 0.1360, Initial Validation Loss: 0.1287, Validation Loss: 0.1287,V Acc: 0.3333, Top 70th Acc: 0.3718, Bottom 30th Acc: 0.2424
Fold [5/5] Epoch [10/100] Initial Loss: 0.1371, Training Loss: 0.0379, Initial Validation Loss: 0.1288, Validation Loss: 0.0385,V Acc: 0.8056, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.5000
Fold [5/5] Epoch [20/100] Initial Loss: 0.1371, Training Loss: 0.0217, Initial Validation Loss: 0.1288, Validation Loss: 0.0347,V Acc: 0.8333, Top 70th Acc: 0.9211, Bottom 30th Acc: 0.6250
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.9605263157894737
Running train_nn.py with seed 5
CUDA:False
Training samples count:  550
Training on 40 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1368, Training Loss: 0.1368, Initial Validation Loss: 0.1328, Validation Loss: 0.1328,V Acc: 0.2973, Top 70th Acc: 0.3718, Bottom 30th Acc: 0.1212
Fold [1/5] Epoch [10/100] Initial Loss: 0.1368, Training Loss: 0.0415, Initial Validation Loss: 0.1328, Validation Loss: 0.0359,V Acc: 0.8559, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.6061
Fold [1/5] Epoch [20/100] Initial Loss: 0.1368, Training Loss: 0.0160, Initial Validation Loss: 0.1328, Validation Loss: 0.0224,V Acc: 0.8829, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.9743589743589743
Fold [2/5] Epoch [0/100] Initial Loss: 0.1394, Training Loss: 0.1394, Initial Validation Loss: 0.1339, Validation Loss: 0.1339,V Acc: 0.2973, Top 70th Acc: 0.3205, Bottom 30th Acc: 0.2424
Fold [2/5] Epoch [10/100] Initial Loss: 0.1394, Training Loss: 0.0255, Initial Validation Loss: 0.1339, Validation Loss: 0.0363,V Acc: 0.8108, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.5455
Fold [2/5] Epoch [20/100] Initial Loss: 0.1394, Training Loss: 0.0133, Initial Validation Loss: 0.1339, Validation Loss: 0.0337,V Acc: 0.8198, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.9487179487179487
Fold [3/5] Epoch [0/100] Initial Loss: 0.1375, Training Loss: 0.1375, Initial Validation Loss: 0.1318, Validation Loss: 0.1318,V Acc: 0.2545, Top 70th Acc: 0.3506, Bottom 30th Acc: 0.0303
Fold [3/5] Epoch [10/100] Initial Loss: 0.1375, Training Loss: 0.0268, Initial Validation Loss: 0.1318, Validation Loss: 0.0323,V Acc: 0.8000, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.5152
Fold [3/5] Epoch [20/100] Initial Loss: 0.1375, Training Loss: 0.0150, Initial Validation Loss: 0.1318, Validation Loss: 0.0263,V Acc: 0.8091, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.4848
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.935064935064935
Fold [4/5] Epoch [0/100] Initial Loss: 0.1388, Training Loss: 0.1388, Initial Validation Loss: 0.1364, Validation Loss: 0.1364,V Acc: 0.2727, Top 70th Acc: 0.2857, Bottom 30th Acc: 0.2424
Fold [4/5] Epoch [10/100] Initial Loss: 0.1388, Training Loss: 0.0306, Initial Validation Loss: 0.1364, Validation Loss: 0.0439,V Acc: 0.8091, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.5758
Fold [4/5] Epoch [20/100] Initial Loss: 0.1388, Training Loss: 0.0148, Initial Validation Loss: 0.1364, Validation Loss: 0.0305,V Acc: 0.8545, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.974025974025974
5 3 [array([0.56027484, 0.05001403, 0.06854354, 0.18794972, 0.13321786],
      dtype=float32)]
Fold [5/5] Epoch [0/100] Initial Loss: 0.1372, Training Loss: 0.1372, Initial Validation Loss: 0.1329, Validation Loss: 0.1329,V Acc: 0.3056, Top 70th Acc: 0.3553, Bottom 30th Acc: 0.1875
Fold [5/5] Epoch [10/100] Initial Loss: 0.1372, Training Loss: 0.0253, Initial Validation Loss: 0.1329, Validation Loss: 0.0380,V Acc: 0.8704, Top 70th Acc: 0.9211, Bottom 30th Acc: 0.7500
Fold [5/5] Epoch [20/100] Initial Loss: 0.1372, Training Loss: 0.0141, Initial Validation Loss: 0.1329, Validation Loss: 0.0299,V Acc: 0.8796, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.7188
Stopping early at Epoch (base 0): 27  Rolling back to Epoch (base 0): 22  Top Validation Acc: 0.9342105263157895
Running train_nn.py with seed 6
CUDA:False
Training samples count:  550
Training on 40 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1362, Training Loss: 0.1362, Initial Validation Loss: 0.1375, Validation Loss: 0.1375,V Acc: 0.2703, Top 70th Acc: 0.2949, Bottom 30th Acc: 0.2121
Fold [1/5] Epoch [10/100] Initial Loss: 0.1362, Training Loss: 0.0282, Initial Validation Loss: 0.1375, Validation Loss: 0.0309,V Acc: 0.8468, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.5758
Fold [1/5] Epoch [20/100] Initial Loss: 0.1362, Training Loss: 0.0151, Initial Validation Loss: 0.1375, Validation Loss: 0.0201,V Acc: 0.9009, Top 70th Acc: 0.9872, Bottom 30th Acc: 0.6970
Fold [1/5] Epoch [30/100] Initial Loss: 0.1362, Training Loss: 0.0125, Initial Validation Loss: 0.1375, Validation Loss: 0.0200,V Acc: 0.9099, Top 70th Acc: 0.9872, Bottom 30th Acc: 0.7273
Stopping early at Epoch (base 0): 34  Rolling back to Epoch (base 0): 29  Top Validation Acc: 0.9871794871794872
6 0 [array([0.45364395, 0.05792705, 0.04643932, 0.07506619, 0.36692342],
      dtype=float32)]
Fold [2/5] Epoch [0/100] Initial Loss: 0.1373, Training Loss: 0.1373, Initial Validation Loss: 0.1323, Validation Loss: 0.1323,V Acc: 0.3784, Top 70th Acc: 0.4359, Bottom 30th Acc: 0.2424
Fold [2/5] Epoch [10/100] Initial Loss: 0.1373, Training Loss: 0.0215, Initial Validation Loss: 0.1323, Validation Loss: 0.0388,V Acc: 0.8468, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 18  Rolling back to Epoch (base 0): 13  Top Validation Acc: 0.9230769230769231
Fold [3/5] Epoch [0/100] Initial Loss: 0.1406, Training Loss: 0.1406, Initial Validation Loss: 0.1307, Validation Loss: 0.1307,V Acc: 0.2818, Top 70th Acc: 0.2987, Bottom 30th Acc: 0.2424
Fold [3/5] Epoch [10/100] Initial Loss: 0.1406, Training Loss: 0.0280, Initial Validation Loss: 0.1307, Validation Loss: 0.0376,V Acc: 0.8000, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.5152
Fold [3/5] Epoch [20/100] Initial Loss: 0.1406, Training Loss: 0.0123, Initial Validation Loss: 0.1307, Validation Loss: 0.0331,V Acc: 0.8273, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 21  Rolling back to Epoch (base 0): 16  Top Validation Acc: 0.9090909090909091
Fold [4/5] Epoch [0/100] Initial Loss: 0.1363, Training Loss: 0.1363, Initial Validation Loss: 0.1345, Validation Loss: 0.1345,V Acc: 0.3000, Top 70th Acc: 0.3636, Bottom 30th Acc: 0.1515
Fold [4/5] Epoch [10/100] Initial Loss: 0.1363, Training Loss: 0.0274, Initial Validation Loss: 0.1345, Validation Loss: 0.0335,V Acc: 0.8818, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.7576
Fold [4/5] Epoch [20/100] Initial Loss: 0.1363, Training Loss: 0.0126, Initial Validation Loss: 0.1345, Validation Loss: 0.0257,V Acc: 0.9000, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.7576
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.961038961038961
Fold [5/5] Epoch [0/100] Initial Loss: 0.1402, Training Loss: 0.1402, Initial Validation Loss: 0.1299, Validation Loss: 0.1299,V Acc: 0.2593, Top 70th Acc: 0.3289, Bottom 30th Acc: 0.0938
Fold [5/5] Epoch [10/100] Initial Loss: 0.1402, Training Loss: 0.0271, Initial Validation Loss: 0.1299, Validation Loss: 0.0325,V Acc: 0.8519, Top 70th Acc: 0.9211, Bottom 30th Acc: 0.6875
Fold [5/5] Epoch [20/100] Initial Loss: 0.1402, Training Loss: 0.0153, Initial Validation Loss: 0.1299, Validation Loss: 0.0218,V Acc: 0.8333, Top 70th Acc: 0.9868, Bottom 30th Acc: 0.4688
Fold [5/5] Epoch [30/100] Initial Loss: 0.1402, Training Loss: 0.0127, Initial Validation Loss: 0.1299, Validation Loss: 0.0195,V Acc: 0.8611, Top 70th Acc: 0.9868, Bottom 30th Acc: 0.5625
Stopping early at Epoch (base 0): 38  Rolling back to Epoch (base 0): 33  Top Validation Acc: 1.0
Running train_nn.py with seed 7
CUDA:False
Training samples count:  550
Training on 40 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1382, Training Loss: 0.1382, Initial Validation Loss: 0.1323, Validation Loss: 0.1323,V Acc: 0.2793, Top 70th Acc: 0.3077, Bottom 30th Acc: 0.2121
Fold [1/5] Epoch [10/100] Initial Loss: 0.1382, Training Loss: 0.0292, Initial Validation Loss: 0.1323, Validation Loss: 0.0311,V Acc: 0.8468, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 21  Rolling back to Epoch (base 0): 16  Top Validation Acc: 0.9473684210526315
Running train_nn.py with seed 5
CUDA:False
Training samples count:  550
Training on 30 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1422, Training Loss: 0.1422, Initial Validation Loss: 0.1357, Validation Loss: 0.1357,V Acc: 0.3243, Top 70th Acc: 0.3846, Bottom 30th Acc: 0.1818
Fold [1/5] Epoch [10/100] Initial Loss: 0.1422, Training Loss: 0.0406, Initial Validation Loss: 0.1357, Validation Loss: 0.0337,V Acc: 0.8739, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.7273
Fold [1/5] Epoch [20/100] Initial Loss: 0.1422, Training Loss: 0.0207, Initial Validation Loss: 0.1357, Validation Loss: 0.0255,V Acc: 0.8739, Top 70th Acc: 0.9872, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.9615384615384616
Fold [2/5] Epoch [0/100] Initial Loss: 0.1383, Training Loss: 0.1383, Initial Validation Loss: 0.1325, Validation Loss: 0.1325,V Acc: 0.3964, Top 70th Acc: 0.5256, Bottom 30th Acc: 0.0909
Fold [2/5] Epoch [10/100] Initial Loss: 0.1383, Training Loss: 0.0321, Initial Validation Loss: 0.1325, Validation Loss: 0.0410,V Acc: 0.7838, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.4545
Fold [2/5] Epoch [20/100] Initial Loss: 0.1383, Training Loss: 0.0196, Initial Validation Loss: 0.1325, Validation Loss: 0.0320,V Acc: 0.8378, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.9487179487179487
Fold [3/5] Epoch [0/100] Initial Loss: 0.1404, Training Loss: 0.1404, Initial Validation Loss: 0.1336, Validation Loss: 0.1336,V Acc: 0.2545, Top 70th Acc: 0.3636, Bottom 30th Acc: 0.0000
Fold [3/5] Epoch [10/100] Initial Loss: 0.1404, Training Loss: 0.0431, Initial Validation Loss: 0.1336, Validation Loss: 0.0470,V Acc: 0.7636, Top 70th Acc: 0.8442, Bottom 30th Acc: 0.5758
Fold [3/5] Epoch [20/100] Initial Loss: 0.1404, Training Loss: 0.0198, Initial Validation Loss: 0.1336, Validation Loss: 0.0309,V Acc: 0.8182, Top 70th Acc: 0.8961, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.8831168831168831
Fold [4/5] Epoch [0/100] Initial Loss: 0.1395, Training Loss: 0.1395, Initial Validation Loss: 0.1350, Validation Loss: 0.1350,V Acc: 0.2727, Top 70th Acc: 0.3377, Bottom 30th Acc: 0.1212
Fold [4/5] Epoch [10/100] Initial Loss: 0.1395, Training Loss: 0.0294, Initial Validation Loss: 0.1350, Validation Loss: 0.0404,V Acc: 0.8364, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.6667
Fold [4/5] Epoch [20/100] Initial Loss: 0.1395, Training Loss: 0.0176, Initial Validation Loss: 0.1350, Validation Loss: 0.0341,V Acc: 0.8364, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.974025974025974
5 3 [array([0.7571142 , 0.04135257, 0.05565627, 0.07758024, 0.06829671],
      dtype=float32)]
Fold [5/5] Epoch [0/100] Initial Loss: 0.1370, Training Loss: 0.1370, Initial Validation Loss: 0.1306, Validation Loss: 0.1306,V Acc: 0.3611, Top 70th Acc: 0.4474, Bottom 30th Acc: 0.1562
Fold [5/5] Epoch [10/100] Initial Loss: 0.1370, Training Loss: 0.0276, Initial Validation Loss: 0.1306, Validation Loss: 0.0370,V Acc: 0.8889, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.7812
Fold [5/5] Epoch [20/100] Initial Loss: 0.1370, Training Loss: 0.0181, Initial Validation Loss: 0.1306, Validation Loss: 0.0295,V Acc: 0.8981, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.8125
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.9342105263157895
Running train_nn.py with seed 6
CUDA:False
Training samples count:  550
Training on 30 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1392, Training Loss: 0.1392, Initial Validation Loss: 0.1376, Validation Loss: 0.1376,V Acc: 0.2973, Top 70th Acc: 0.2949, Bottom 30th Acc: 0.3030
Fold [1/5] Epoch [10/100] Initial Loss: 0.1392, Training Loss: 0.0452, Initial Validation Loss: 0.1376, Validation Loss: 0.0538,V Acc: 0.7568, Top 70th Acc: 0.8590, Bottom 30th Acc: 0.5152
Fold [1/5] Epoch [20/100] Initial Loss: 0.1392, Training Loss: 0.0213, Initial Validation Loss: 0.1376, Validation Loss: 0.0295,V Acc: 0.8739, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.6667
Fold [1/5] Epoch [30/100] Initial Loss: 0.1392, Training Loss: 0.0165, Initial Validation Loss: 0.1376, Validation Loss: 0.0279,V Acc: 0.8739, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 34  Rolling back to Epoch (base 0): 29  Top Validation Acc: 0.9487179487179487
6 0 [array([0.7476485 , 0.04962084, 0.04635473, 0.10440053, 0.05197537],
      dtype=float32)]
Fold [2/5] Epoch [0/100] Initial Loss: 0.1378, Training Loss: 0.1378, Initial Validation Loss: 0.1356, Validation Loss: 0.1356,V Acc: 0.2703, Top 70th Acc: 0.3333, Bottom 30th Acc: 0.1212
Fold [2/5] Epoch [10/100] Initial Loss: 0.1378, Training Loss: 0.0355, Initial Validation Loss: 0.1356, Validation Loss: 0.0482,V Acc: 0.7297, Top 70th Acc: 0.8718, Bottom 30th Acc: 0.3939
Fold [2/5] Epoch [20/100] Initial Loss: 0.1378, Training Loss: 0.0200, Initial Validation Loss: 0.1356, Validation Loss: 0.0398,V Acc: 0.8288, Top 70th Acc: 0.8974, Bottom 30th Acc: 0.6667
Fold [2/5] Epoch [30/100] Initial Loss: 0.1378, Training Loss: 0.0157, Initial Validation Loss: 0.1356, Validation Loss: 0.0377,V Acc: 0.8288, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 38  Rolling back to Epoch (base 0): 33  Top Validation Acc: 0.9230769230769231
Fold [3/5] Epoch [0/100] Initial Loss: 0.1374, Training Loss: 0.1374, Initial Validation Loss: 0.1285, Validation Loss: 0.1285,V Acc: 0.3091, Top 70th Acc: 0.3636, Bottom 30th Acc: 0.1818
Fold [3/5] Epoch [10/100] Initial Loss: 0.1374, Training Loss: 0.0325, Initial Validation Loss: 0.1285, Validation Loss: 0.0377,V Acc: 0.7909, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.4848
Fold [3/5] Epoch [20/100] Initial Loss: 0.1374, Training Loss: 0.0186, Initial Validation Loss: 0.1285, Validation Loss: 0.0292,V Acc: 0.8364, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 27  Rolling back to Epoch (base 0): 22  Top Validation Acc: 0.922077922077922
Fold [4/5] Epoch [0/100] Initial Loss: 0.1388, Training Loss: 0.1388, Initial Validation Loss: 0.1381, Validation Loss: 0.1381,V Acc: 0.3364, Top 70th Acc: 0.4156, Bottom 30th Acc: 0.1515
Fold [4/5] Epoch [10/100] Initial Loss: 0.1388, Training Loss: 0.0399, Initial Validation Loss: 0.1381, Validation Loss: 0.0419,V Acc: 0.8545, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.6667
Fold [4/5] Epoch [20/100] Initial Loss: 0.1388, Training Loss: 0.0197, Initial Validation Loss: 0.1381, Validation Loss: 0.0309,V Acc: 0.8818, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.6667
Fold [4/5] Epoch [30/100] Initial Loss: 0.1388, Training Loss: 0.0166, Initial Validation Loss: 0.1381, Validation Loss: 0.0301,V Acc: 0.8818, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.6970
Fold [4/5] Epoch [40/100] Initial Loss: 0.1388, Training Loss: 0.0150, Initial Validation Loss: 0.1381, Validation Loss: 0.0296,V Acc: 0.8818, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 40  Rolling back to Epoch (base 0): 35  Top Validation Acc: 0.974025974025974
Fold [5/5] Epoch [0/100] Initial Loss: 0.1393, Training Loss: 0.1393, Initial Validation Loss: 0.1281, Validation Loss: 0.1281,V Acc: 0.3333, Top 70th Acc: 0.3684, Bottom 30th Acc: 0.2500
Fold [5/5] Epoch [10/100] Initial Loss: 0.1393, Training Loss: 0.0290, Initial Validation Loss: 0.1281, Validation Loss: 0.0330,V Acc: 0.8148, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.5000
Fold [5/5] Epoch [20/100] Initial Loss: 0.1393, Training Loss: 0.0185, Initial Validation Loss: 0.1281, Validation Loss: 0.0300,V Acc: 0.8426, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.6250
Fold [5/5] Epoch [30/100] Initial Loss: 0.1393, Training Loss: 0.0157, Initial Validation Loss: 0.1281, Validation Loss: 0.0282,V Acc: 0.8333, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.5625
Stopping early at Epoch (base 0): 37  Rolling back to Epoch (base 0): 32  Top Validation Acc:
Stopping early at Epoch (base 0): 20  Rolling back to Epoch (base 0): 15  Top Validation Acc: 0.8974358974358975
8 1 [array([0.79425603, 0.01350431, 0.02455644, 0.06979249, 0.09789078],
      dtype=float32)]
Fold [3/5] Epoch [0/100] Initial Loss: 0.1381, Training Loss: 0.1381, Initial Validation Loss: 0.1270, Validation Loss: 0.1270,V Acc: 0.4727, Top 70th Acc: 0.5455, Bottom 30th Acc: 0.3030
Fold [3/5] Epoch [10/100] Initial Loss: 0.1381, Training Loss: 0.0245, Initial Validation Loss: 0.1270, Validation Loss: 0.0279,V Acc: 0.8545, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.6061
Fold [3/5] Epoch [20/100] Initial Loss: 0.1381, Training Loss: 0.0163, Initial Validation Loss: 0.1270, Validation Loss: 0.0304,V Acc: 0.8455, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 20  Rolling back to Epoch (base 0): 15  Top Validation Acc: 0.948051948051948
Fold [4/5] Epoch [0/100] Initial Loss: 0.1280, Training Loss: 0.1280, Initial Validation Loss: 0.1181, Validation Loss: 0.1181,V Acc: 0.5545, Top 70th Acc: 0.6364, Bottom 30th Acc: 0.3636
Fold [4/5] Epoch [10/100] Initial Loss: 0.1280, Training Loss: 0.0251, Initial Validation Loss: 0.1181, Validation Loss: 0.0336,V Acc: 0.8455, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.6364
Fold [4/5] Epoch [20/100] Initial Loss: 0.1280, Training Loss: 0.0201, Initial Validation Loss: 0.1181, Validation Loss: 0.0255,V Acc: 0.8818, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 29  Rolling back to Epoch (base 0): 24  Top Validation Acc: 0.974025974025974
Fold [5/5] Epoch [0/100] Initial Loss: 0.1333, Training Loss: 0.1333, Initial Validation Loss: 0.1169, Validation Loss: 0.1169,V Acc: 0.5278, Top 70th Acc: 0.5921, Bottom 30th Acc: 0.3750
Fold [5/5] Epoch [10/100] Initial Loss: 0.1333, Training Loss: 0.0316, Initial Validation Loss: 0.1169, Validation Loss: 0.0262,V Acc: 0.8426, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.5625
Fold [5/5] Epoch [20/100] Initial Loss: 0.1333, Training Loss: 0.0204, Initial Validation Loss: 0.1169, Validation Loss: 0.0239,V Acc: 0.8611, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.6250
Stopping early at Epoch (base 0): 20  Rolling back to Epoch (base 0): 15  Top Validation Acc: 0.9605263157894737
Running train_nn.py with seed 9
CUDA:False
Training samples count:  550
Training on 21 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1391, Training Loss: 0.1391, Initial Validation Loss: 0.1353, Validation Loss: 0.1353,V Acc: 0.2973, Top 70th Acc: 0.3333, Bottom 30th Acc: 0.2121
Fold [1/5] Epoch [10/100] Initial Loss: 0.1391, Training Loss: 0.0258, Initial Validation Loss: 0.1353, Validation Loss: 0.0310,V Acc: 0.8649, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 18  Rolling back to Epoch (base 0): 13  Top Validation Acc: 0.9615384615384616
9 0 [array([0.67006445, 0.0324451 , 0.03214455, 0.1129901 , 0.15235579],
      dtype=float32)]
Fold [2/5] Epoch [0/100] Initial Loss: 0.1374, Training Loss: 0.1374, Initial Validation Loss: 0.1284, Validation Loss: 0.1284,V Acc: 0.3604, Top 70th Acc: 0.4744, Bottom 30th Acc: 0.0909
Fold [2/5] Epoch [10/100] Initial Loss: 0.1374, Training Loss: 0.0256, Initial Validation Loss: 0.1284, Validation Loss: 0.0312,V Acc: 0.8288, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.5152
Stopping early at Epoch (base 0): 19  Rolling back to Epoch (base 0): 14  Top Validation Acc: 0.9487179487179487
Fold [3/5] Epoch [0/100] Initial Loss: 0.1383, Training Loss: 0.1383, Initial Validation Loss: 0.1276, Validation Loss: 0.1276,V Acc: 0.4545, Top 70th Acc: 0.5065, Bottom 30th Acc: 0.3333
Fold [3/5] Epoch [10/100] Initial Loss: 0.1383, Training Loss: 0.0258, Initial Validation Loss: 0.1276, Validation Loss: 0.0358,V Acc: 0.8273, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.5758
Fold [3/5] Epoch [20/100] Initial Loss: 0.1383, Training Loss: 0.0177, Initial Validation Loss: 0.1276, Validation Loss: 0.0272,V Acc: 0.8818, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.7273
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.948051948051948
Fold [4/5] Epoch [0/100] Initial Loss: 0.1365, Training Loss: 0.1365, Initial Validation Loss: 0.1248, Validation Loss: 0.1248,V Acc: 0.4364, Top 70th Acc: 0.5974, Bottom 30th Acc: 0.0606
Fold [4/5] Epoch [10/100] Initial Loss: 0.1365, Training Loss: 0.0247, Initial Validation Loss: 0.1248, Validation Loss: 0.0375,V Acc: 0.8455, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.6364
Fold [4/5] Epoch [20/100] Initial Loss: 0.1365, Training Loss: 0.0168, Initial Validation Loss: 0.1248, Validation Loss: 0.0269,V Acc: 0.8818, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.948051948051948
Fold [5/5] Epoch [0/100] Initial Loss: 0.1310, Training Loss: 0.1310, Initial Validation Loss: 0.1137, Validation Loss: 0.1137,V Acc: 0.5463, Top 70th Acc: 0.6711, Bottom 30th Acc: 0.2500
Fold [5/5] Epoch [10/100] Initial Loss: 0.1310, Training Loss: 0.0235, Initial Validation Loss: 0.1137, Validation Loss: 0.0384,V Acc: 0.8056, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.5000
Fold [5/5] Epoch [20/100] Initial Loss: 0.1310, Training Loss: 0.0176, Initial Validation Loss: 0.1137, Validation Loss: 0.0244,V Acc: 0.8241, Top 70th Acc: 0.9868, Bottom 30th Acc: 0.4375
Stopping early at Epoch (base 0): 27  Rolling back to Epoch (base 0): 22  Top Validation Acc: 0.9868421052631579
Running train_nn.py with seed 10
CUDA:False
Training samples count:  550
Training on 21 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1294, Training Loss: 0.1294, Initial Validation Loss: 0.1165, Validation Loss: 0.1165,V Acc: 0.5766, Top 70th Acc: 0.6795, Bottom 30th Acc: 0.3333
Fold [1/5] Epoch [10/100] Initial Loss: 0.1294, Training Loss: 0.0224, Initial Validation Loss: 0.1165, Validation Loss: 0.0388,V Acc: 0.8198, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 18  Rolling back to Epoch (base 0): 13  Top Validation Acc: 0.8846153846153846
10 0 [array([0.7994948 , 0.02249447, 0.01388917, 0.0846838 , 0.07943774],
      dtype=float32)]
Fold [2/5] Epoch [0/100] Initial Loss: 0.1403, Training Loss: 0.1403, Initial Validation Loss: 0.1294, Validation Loss: 0.1294,V Acc: 0.4234, Top 70th Acc: 0.4487, Bottom 30th Acc: 0.3636
Fold [2/5] Epoch [10/100] Initial Loss: 0.1403, Training Loss: 0.0247, Initial Validation Loss: 0.1294, Validation Loss: 0.0286,V Acc: 0.8739, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.7273
Stopping early at Epoch (base 0): 19  Rolling back to Epoch (base 0): 14  Top Validation Acc: 0.9487179487179487
Fold [3/5] Epoch [0/100] Initial Loss: 0.1324, Training Loss: 0.1324, Initial Validation Loss: 0.1213, Validation Loss: 0.1213,V Acc: 0.4818, Top 70th Acc: 0.6234, Bottom 30th Acc: 0.1515
Fold [3/5] Epoch [10/100] Initial Loss: 0.1324, Training Loss: 0.0222, Initial Validation Loss: 0.1213, Validation Loss: 0.0232,V Acc: 0.9000, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.7273
Stopping early at Epoch (base 0): 14  Rolling back to Epoch (base 0): 9  Top Validation Acc: 0.987012987012987
Fold [4/5] Epoch [0/100] Initial Loss: 0.1302, Training Loss: 0.1302, Initial Validation Loss: 0.1186, Validation Loss: 0.1186,V Acc: 0.4727, Top 70th Acc: 0.5584, Bottom 30th Acc: 0.2727
Fold [4/5] Epoch [10/100] Initial Loss: 0.1302, Training Loss: 0.0310, Initial Validation Loss: 0.1186, Validation Loss: 0.0338,V Acc: 0.8273, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.5152
Stopping early at Epoch (base 0): 17  Rolling back to Epoch (base 0): 12  Top Validation Acc: 0.961038961038961
Fold [5/5] Epoch [0/100] Initial Loss: 0.1338, Training Loss: 0.1338, Initial Validation Loss: 0.1232, Validation Loss: 0.1232,V Acc: 0.4074, Top 70th Acc: 0.5395, Bottom 30th Acc: 0.0938
Fold [5/5] Epoch [10/100] Initial Loss: 0.1338, Training Loss: 0.0276, Initial Validation Loss: 0.1232, Validation Loss: 0.0289,V Acc: 0.8611, Top 70th Acc: 0.9737, Bottom 30th Acc: 0.5938
Fold [5/5] Epoch [20/100] Initial Loss: 0.1338, Training Loss: 0.0182, Initial Validation Loss: 0.1232, Validation Loss: 0.0255,V Acc: 0.8611, Top 70th Acc: 0.9737, Bottom 30th Acc: 0.5938
Fold [5/5] Epoch [30/100] Initial Loss: 0.1338, Training Loss: 0.0148, Initial Validation Loss: 0.1232, Validation Loss: 0.0278,V Acc: 0.8889, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.7188
Fold [4/5] Epoch [30/100] Initial Loss: 0.1381, Training Loss: 0.0040, Initial Validation Loss: 0.1351, Validation Loss: 0.0328,V Acc: 0.8182, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 38  Rolling back to Epoch (base 0): 33  Top Validation Acc: 0.935064935064935
4 3 [array([0.17903885, 0.02100427, 0.06067732, 0.19662447, 0.5426551 ],
      dtype=float32)]
Fold [5/5] Epoch [0/100] Initial Loss: 0.1406, Training Loss: 0.1406, Initial Validation Loss: 0.1298, Validation Loss: 0.1298,V Acc: 0.2963, Top 70th Acc: 0.3816, Bottom 30th Acc: 0.0938
Fold [5/5] Epoch [10/100] Initial Loss: 0.1406, Training Loss: 0.0121, Initial Validation Loss: 0.1298, Validation Loss: 0.0281,V Acc: 0.8426, Top 70th Acc: 0.9737, Bottom 30th Acc: 0.5312
Fold [5/5] Epoch [20/100] Initial Loss: 0.1406, Training Loss: 0.0049, Initial Validation Loss: 0.1298, Validation Loss: 0.0263,V Acc: 0.8333, Top 70th Acc: 0.9868, Bottom 30th Acc: 0.4688
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.9736842105263158
Running train_nn.py with seed 5
CUDA:False
Training samples count:  550
Training on 163 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1374, Training Loss: 0.1374, Initial Validation Loss: 0.1343, Validation Loss: 0.1343,V Acc: 0.2973, Top 70th Acc: 0.3718, Bottom 30th Acc: 0.1212
Fold [1/5] Epoch [10/100] Initial Loss: 0.1374, Training Loss: 0.0167, Initial Validation Loss: 0.1343, Validation Loss: 0.0325,V Acc: 0.8198, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.5152
Fold [1/5] Epoch [20/100] Initial Loss: 0.1374, Training Loss: 0.0054, Initial Validation Loss: 0.1343, Validation Loss: 0.0271,V Acc: 0.8649, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.6061
Fold [1/5] Epoch [30/100] Initial Loss: 0.1374, Training Loss: 0.0039, Initial Validation Loss: 0.1343, Validation Loss: 0.0251,V Acc: 0.8739, Top 70th Acc: 0.9872, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 34  Rolling back to Epoch (base 0): 29  Top Validation Acc: 0.9871794871794872
Fold [2/5] Epoch [0/100] Initial Loss: 0.1405, Training Loss: 0.1405, Initial Validation Loss: 0.1337, Validation Loss: 0.1337,V Acc: 0.2523, Top 70th Acc: 0.3590, Bottom 30th Acc: 0.0000
Fold [2/5] Epoch [10/100] Initial Loss: 0.1405, Training Loss: 0.0261, Initial Validation Loss: 0.1337, Validation Loss: 0.0413,V Acc: 0.7928, Top 70th Acc: 0.8974, Bottom 30th Acc: 0.5455
Fold [2/5] Epoch [20/100] Initial Loss: 0.1405, Training Loss: 0.0054, Initial Validation Loss: 0.1337, Validation Loss: 0.0284,V Acc: 0.8468, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.6061
Fold [2/5] Epoch [30/100] Initial Loss: 0.1405, Training Loss: 0.0041, Initial Validation Loss: 0.1337, Validation Loss: 0.0273,V Acc: 0.8559, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 33  Rolling back to Epoch (base 0): 28  Top Validation Acc: 0.9615384615384616
Fold [3/5] Epoch [0/100] Initial Loss: 0.1393, Training Loss: 0.1393, Initial Validation Loss: 0.1324, Validation Loss: 0.1324,V Acc: 0.2909, Top 70th Acc: 0.3506, Bottom 30th Acc: 0.1515
Fold [3/5] Epoch [10/100] Initial Loss: 0.1393, Training Loss: 0.0179, Initial Validation Loss: 0.1324, Validation Loss: 0.0310,V Acc: 0.8364, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.6061
Fold [3/5] Epoch [20/100] Initial Loss: 0.1393, Training Loss: 0.0052, Initial Validation Loss: 0.1324, Validation Loss: 0.0246,V Acc: 0.8364, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.6061
Fold [3/5] Epoch [30/100] Initial Loss: 0.1393, Training Loss: 0.0042, Initial Validation Loss: 0.1324, Validation Loss: 0.0240,V Acc: 0.8545, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 32  Rolling back to Epoch (base 0): 27  Top Validation Acc: 0.948051948051948
Fold [4/5] Epoch [0/100] Initial Loss: 0.1379, Training Loss: 0.1379, Initial Validation Loss: 0.1353, Validation Loss: 0.1353,V Acc: 0.2545, Top 70th Acc: 0.3377, Bottom 30th Acc: 0.0606
Fold [4/5] Epoch [10/100] Initial Loss: 0.1379, Training Loss: 0.0113, Initial Validation Loss: 0.1353, Validation Loss: 0.0317,V Acc: 0.8273, Top 70th Acc: 0.9870, Bottom 30th Acc: 0.4545
Stopping early at Epoch (base 0): 18  Rolling back to Epoch (base 0): 13  Top Validation Acc: 0.974025974025974
5 3 [array([0.22714002, 0.07955536, 0.0986332 , 0.22681488, 0.36785662],
      dtype=float32)]
Fold [5/5] Epoch [0/100] Initial Loss: 0.1368, Training Loss: 0.1368, Initial Validation Loss: 0.1329, Validation Loss: 0.1329,V Acc: 0.2963, Top 70th Acc: 0.3684, Bottom 30th Acc: 0.1250
Fold [5/5] Epoch [10/100] Initial Loss: 0.1368, Training Loss: 0.0159, Initial Validation Loss: 0.1329, Validation Loss: 0.0423,V Acc: 0.8148, Top 70th Acc: 0.8947, Bottom 30th Acc: 0.6250
Fold [5/5] Epoch [20/100] Initial Loss: 0.1368, Training Loss: 0.0062, Initial Validation Loss: 0.1329, Validation Loss: 0.0373,V Acc: 0.8241, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.5625
Stopping early at Epoch (base 0): 22  Rolling back to Epoch (base 0): 17  Top Validation Acc: 0.9342105263157895
Running train_nn.py with seed 6
CUDA:False
Training samples count:  550
Training on 163 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1404, Training Loss: 0.1404, Initial Validation Loss: 0.1396, Validation Loss: 0.1396,V Acc: 0.2523, Top 70th Acc: 0.2949, Bottom 30th Acc: 0.1515
Fold [1/5] Epoch [10/100] Initial Loss: 0.1404, Training Loss: 0.0226, Initial Validation Loss: 0.1396, Validation Loss: 0.0378,V Acc: 0.8468, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.6667
Fold [1/5] Epoch [20/100] Initial Loss: 0.1404, Training Loss: 0.0054, Initial Validation Loss: 0.1396, Validation Loss: 0.0271,V Acc: 0.8739, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.6667
Fold [1/5] Epoch [30/100] Initial Loss: 0.1404, Training Loss: 0.0040, Initial Validation Loss: 0.1396, Validation Loss: 0.0261,V Acc: 0.8649, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 38  Rolling back to Epoch (base 0): 33  Top Validation Acc: 0.9743589743589743
6 0 [array([0.1387911 , 0.03895472, 0.08667637, 0.24328038, 0.4922974 ],
      dtype=float32)]
Fold [2/5] Epoch [0/100] Initial Loss: 0.1397, Training Loss: 0.1397, Initial Validation Loss: 0.1359, Validation Loss: 0.1359,V Acc: 0.3063, Top 70th Acc: 0.3718, Bottom 30th Acc: 0.1515
Fold [2/5] Epoch [10/100] Initial Loss: 0.1397, Training Loss: 0.0174, Initial Validation Loss: 0.1359, Validation Loss: 0.0392,V Acc: 0.8649, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.6667
Fold [2/5] Epoch [20/100] Initial Loss: 0.1397, Training Loss: 0.0054, Initial Validation Loss: 0.1359, Validation Loss: 0.0310,V Acc: 0.8468, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 27  Rolling back to Epoch (base 0): 22  Top Validation Acc: 0.9615384615384616
Fold [3/5] Epoch [0/100] Initial Loss: 0.1394, Training Loss: 0.1394, Initial Validation Loss: 0.1299, Validation Loss: 0.1299,V Acc: 0.5000, Top 70th Acc: 0.5974, Bottom 30th Acc: 0.2727
Fold [3/5] Epoch [10/100] Initial Loss: 0.1394, Training Loss: 0.0200, Initial Validation Loss: 0.1299, Validation Loss: 0.0389,V Acc: 0.8273, Top 70th Acc: 0.8961, Bottom 30th Acc: 0.6667
Fold [3/5] Epoch [20/100] Initial Loss: 0.1394, Training Loss: 0.0046, Initial Validation Loss: 0.1299, Validation Loss: 0.0321,V Acc: 0.8091, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.5152
Stopping early at Epoch (base 0): 29  Rolling back to Epoch (base 0): 24  Top Validation Acc: 0.948051948051948
Fold [4/5] Epoch [0/100] Initial Loss: 0.1373, Training Loss: 0.1373, Initial Validation Loss: 0.1366, Validation Loss: 0.1366,V Acc: 0.2545, Top 70th Acc: 0.3506, Bottom 30th Acc: 0.0303
Fold [4/5] Epoch [10/100] Initial Loss: 0.1373, Training Loss: 0.0128, Initial Validation Loss: 0.1366, Validation Loss: 0.0310,V Acc: 0.8455, Top 70th Acc: 0.9870, Bottom 30th Acc: 0.5152
Fold [4/5] Epoch [20/100] Initial Loss: 0.1373, Training Loss: 0.0043, Initial Validation Loss: 0.1366, Validation Loss: 0.0289,V Acc: 0.8545, Top 70th Acc: 0.9870, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 21  Rolling back to Epoch (base 0): 16  Top Validation Acc: 0.987012987012987
Fold [5/5] Epoch [0/100] Initial Loss: 0.1398, Training Loss: 0.1398, Initial Validation Loss: 0.1290, Validation Loss: 0.1290,V Acc: 0.2870, Top 70th Acc: 0.3421, Bottom 30th Acc: 0.1562
Stopping early at Epoch (base 0): 32  Rolling back to Epoch (base 0): 27  Top Validation Acc: 0.9868421052631579
Running train_nn.py with seed 11
CUDA:False
Training samples count:  550
Training on 21 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1331, Training Loss: 0.1331, Initial Validation Loss: 0.1248, Validation Loss: 0.1248,V Acc: 0.4505, Top 70th Acc: 0.5769, Bottom 30th Acc: 0.1515
Fold [1/5] Epoch [10/100] Initial Loss: 0.1331, Training Loss: 0.0255, Initial Validation Loss: 0.1248, Validation Loss: 0.0267,V Acc: 0.9009, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.7273
Fold [1/5] Epoch [20/100] Initial Loss: 0.1331, Training Loss: 0.0197, Initial Validation Loss: 0.1248, Validation Loss: 0.0238,V Acc: 0.8739, Top 70th Acc: 0.9872, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 22  Rolling back to Epoch (base 0): 17  Top Validation Acc: 0.9487179487179487
Fold [2/5] Epoch [0/100] Initial Loss: 0.1313, Training Loss: 0.1313, Initial Validation Loss: 0.1262, Validation Loss: 0.1262,V Acc: 0.4505, Top 70th Acc: 0.5641, Bottom 30th Acc: 0.1818
Fold [2/5] Epoch [10/100] Initial Loss: 0.1313, Training Loss: 0.0232, Initial Validation Loss: 0.1262, Validation Loss: 0.0400,V Acc: 0.8559, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.6970
Fold [2/5] Epoch [20/100] Initial Loss: 0.1313, Training Loss: 0.0167, Initial Validation Loss: 0.1262, Validation Loss: 0.0351,V Acc: 0.8649, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 22  Rolling back to Epoch (base 0): 17  Top Validation Acc: 0.9487179487179487
Fold [3/5] Epoch [0/100] Initial Loss: 0.1342, Training Loss: 0.1342, Initial Validation Loss: 0.1213, Validation Loss: 0.1213,V Acc: 0.4545, Top 70th Acc: 0.5584, Bottom 30th Acc: 0.2121
Fold [3/5] Epoch [10/100] Initial Loss: 0.1342, Training Loss: 0.0258, Initial Validation Loss: 0.1213, Validation Loss: 0.0282,V Acc: 0.8727, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 15  Rolling back to Epoch (base 0): 10  Top Validation Acc: 0.935064935064935
Fold [4/5] Epoch [0/100] Initial Loss: 0.1340, Training Loss: 0.1340, Initial Validation Loss: 0.1194, Validation Loss: 0.1194,V Acc: 0.6000, Top 70th Acc: 0.6753, Bottom 30th Acc: 0.4242
Fold [4/5] Epoch [10/100] Initial Loss: 0.1340, Training Loss: 0.0225, Initial Validation Loss: 0.1194, Validation Loss: 0.0242,V Acc: 0.8636, Top 70th Acc: 0.9870, Bottom 30th Acc: 0.5758
Fold [4/5] Epoch [20/100] Initial Loss: 0.1340, Training Loss: 0.0184, Initial Validation Loss: 0.1194, Validation Loss: 0.0211,V Acc: 0.8727, Top 70th Acc: 0.9870, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 22  Rolling back to Epoch (base 0): 17  Top Validation Acc: 0.961038961038961
11 3 [array([0.6957278 , 0.0193505 , 0.02682981, 0.18197471, 0.07611717],
      dtype=float32)]
Fold [5/5] Epoch [0/100] Initial Loss: 0.1376, Training Loss: 0.1376, Initial Validation Loss: 0.1282, Validation Loss: 0.1282,V Acc: 0.4352, Top 70th Acc: 0.5263, Bottom 30th Acc: 0.2188
Fold [5/5] Epoch [10/100] Initial Loss: 0.1376, Training Loss: 0.0257, Initial Validation Loss: 0.1282, Validation Loss: 0.0372,V Acc: 0.8333, Top 70th Acc: 0.9211, Bottom 30th Acc: 0.6250
Fold [5/5] Epoch [20/100] Initial Loss: 0.1376, Training Loss: 0.0178, Initial Validation Loss: 0.1282, Validation Loss: 0.0283,V Acc: 0.8796, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.6875
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.9473684210526315
Running train_nn.py with seed 12
CUDA:False
Training samples count:  550
Training on 21 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1340, Training Loss: 0.1340, Initial Validation Loss: 0.1210, Validation Loss: 0.1210,V Acc: 0.4685, Top 70th Acc: 0.5128, Bottom 30th Acc: 0.3636
Fold [1/5] Epoch [10/100] Initial Loss: 0.1340, Training Loss: 0.0225, Initial Validation Loss: 0.1210, Validation Loss: 0.0392,V Acc: 0.7838, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.4545
Stopping early at Epoch (base 0): 16  Rolling back to Epoch (base 0): 11  Top Validation Acc: 0.9102564102564102
Fold [2/5] Epoch [0/100] Initial Loss: 0.1333, Training Loss: 0.1333, Initial Validation Loss: 0.1232, Validation Loss: 0.1232,V Acc: 0.4144, Top 70th Acc: 0.5256, Bottom 30th Acc: 0.1515
Fold [2/5] Epoch [10/100] Initial Loss: 0.1333, Training Loss: 0.0244, Initial Validation Loss: 0.1232, Validation Loss: 0.0281,V Acc: 0.8739, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 19  Rolling back to Epoch (base 0): 14  Top Validation Acc: 0.9615384615384616
Fold [3/5] Epoch [0/100] Initial Loss: 0.1307, Training Loss: 0.1307, Initial Validation Loss: 0.1164, Validation Loss: 0.1164,V Acc: 0.4182, Top 70th Acc: 0.5325, Bottom 30th Acc: 0.1515
Fold [3/5] Epoch [10/100] Initial Loss: 0.1307, Training Loss: 0.0239, Initial Validation Loss: 0.1164, Validation Loss: 0.0304,V Acc: 0.8545, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6364
Fold [3/5] Epoch [20/100] Initial Loss: 0.1307, Training Loss: 0.0165, Initial Validation Loss: 0.1164, Validation Loss: 0.0285,V Acc: 0.8818, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.7879
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.935064935064935
Fold [4/5] Epoch [0/100] Initial Loss: 0.1352, Training Loss: 0.1352, Initial Validation Loss: 0.1259, Validation Loss: 0.1259,V Acc: 0.5364, Top 70th Acc: 0.5974, Bottom 30th Acc: 0.3939
Fold [4/5] Epoch [10/100] Initial Loss: 0.1352, Training Loss: 0.0270, Initial Validation Loss: 0.1259, Validation Loss: 0.0244,V Acc: 0.9091, Top 70th Acc: 1.0000, Bottom 30th Acc: 0.6970
Fold [4/5] Epoch [20/100] Initial Loss: 0.1352, Training Loss: 0.0184, Initial Validation Loss: 0.1259, Validation Loss: 0.0241,V Acc: 0.8727, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 21  Rolling back to Epoch (base 0): 16  Top Validation Acc: 0.987012987012987
Fold [5/5] Epoch [0/100] Initial Loss: 0.1366, Training Loss: 0.1366, Initial Validation Loss: 0.1246, Validation Loss: 0.1246,V Acc: 0.4167, Top 70th Acc: 0.4868, Bottom 30th Acc: 0.2500
Fold [5/5] Epoch [10/100] Initial Loss: 0.1366, Training Loss: 0.0229, Initial Validation Loss: 0.1246, Validation Loss: 0.0305,V Acc: 0.8704, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.6562
Stopping early at Epoch (base 0): 15  Rolling back to Epoch (base 0): 10  Top Validation Acc: 0.9473684210526315
12 4 [array([0.7273203 , 0.03011094, 0.03103315, 0.10301127, 0.10852432],
      dtype=float32)]
Running train_nn.py with seed 13
CUDA:False
Training samples count:  550
Training on 21 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1296, Training Loss: 0.1296, Initial Validation Loss: 0.1177, Validation Loss: 0.1177,V Acc: 0.6306, Top 70th Acc: 0.6795, Bottom 30th Acc: 0.5152
Fold [1/5] Epoch [10/100] Initial Loss: 0.1296, Training Loss: 0.0276, Initial Validation Loss: 0.1177, Validation Loss: 0.0279,V Acc: 0.8919, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.7273
Fold [1/5] Epoch [20/100] Initial Loss: 0.1296, Training Loss: 0.0174, Initial Validation Loss: 0.1177, Validation Loss: 0.0227,V Acc: 0.9099, Top 70th Acc: 0.9872, Bottom 30th Acc: 0.7273
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.9615384615384616
Fold [2/5] Epoch [0/100] Initial Loss: 0.1392, Training Loss: 0.1392, Initial Validation Loss: 0.1335, Validation Loss: 0.1335,V Acc: 0.3153, Top 70th Acc: 0.3846, Bottom 30th Acc: 0.1515
Fold [2/5] Epoch [10/100] Initial Loss: 0.1392, Training Loss: 0.0254, Initial Validation Loss: 0.1335, Validation Loss: 0.0278,V Acc: 0.8829, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.6667
Fold [2/5] Epoch [20/100] Initial Loss: 0.1392, Training Loss: 0.0181, Initial Validation Loss: 0.1335, Validation Loss: 0.0285,V Acc: 0.8829, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.7273
Stopping early at Epoch (base 0): 20  Rolling back to Epoch (base 0): 15  Top Validation Acc: 0.9487179487179487
Fold [3/5] Epoch [0/100] Initial Loss: 0.1349, Training Loss: 0.1349, Initial Validation Loss: 0.1304, Validation Loss: 0.1304,V Acc: 0.4545, Top 70th Acc: 0.4805, Bottom 30th Acc: 0.3939
Fold [3/5] Epoch [10/100] Initial Loss: 0.1349, Training Loss: 0.0245, Initial Validation Loss: 0.1304, Validation Loss: 0.0242,V Acc: 0.9091, Top 70th Acc: 1.0000, Bottom 30th Acc: 0.6970
Fold [5/5] Epoch [20/100] Initial Loss: 0.1380, Training Loss: 0.0243, Initial Validation Loss: 0.1296, Validation Loss: 0.0278,V Acc: 0.8426, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.5938
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.9210526315789473
Running train_nn.py with seed 7
CUDA:False
Training samples count:  550
Training on 20 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1393, Training Loss: 0.1393, Initial Validation Loss: 0.1312, Validation Loss: 0.1312,V Acc: 0.3874, Top 70th Acc: 0.4359, Bottom 30th Acc: 0.2727
Fold [1/5] Epoch [10/100] Initial Loss: 0.1393, Training Loss: 0.0437, Initial Validation Loss: 0.1312, Validation Loss: 0.0392,V Acc: 0.7838, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.4848
Fold [1/5] Epoch [20/100] Initial Loss: 0.1393, Training Loss: 0.0250, Initial Validation Loss: 0.1312, Validation Loss: 0.0286,V Acc: 0.8468, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.9487179487179487
Fold [2/5] Epoch [0/100] Initial Loss: 0.1368, Training Loss: 0.1368, Initial Validation Loss: 0.1354, Validation Loss: 0.1354,V Acc: 0.2883, Top 70th Acc: 0.3590, Bottom 30th Acc: 0.1212
Fold [2/5] Epoch [10/100] Initial Loss: 0.1368, Training Loss: 0.0455, Initial Validation Loss: 0.1354, Validation Loss: 0.0550,V Acc: 0.7477, Top 70th Acc: 0.8718, Bottom 30th Acc: 0.4545
Fold [2/5] Epoch [20/100] Initial Loss: 0.1368, Training Loss: 0.0262, Initial Validation Loss: 0.1354, Validation Loss: 0.0307,V Acc: 0.8649, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.6364
Fold [2/5] Epoch [30/100] Initial Loss: 0.1368, Training Loss: 0.0229, Initial Validation Loss: 0.1354, Validation Loss: 0.0291,V Acc: 0.8559, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 38  Rolling back to Epoch (base 0): 33  Top Validation Acc: 0.9615384615384616
Fold [3/5] Epoch [0/100] Initial Loss: 0.1423, Training Loss: 0.1423, Initial Validation Loss: 0.1323, Validation Loss: 0.1323,V Acc: 0.2727, Top 70th Acc: 0.3506, Bottom 30th Acc: 0.0909
Fold [3/5] Epoch [10/100] Initial Loss: 0.1423, Training Loss: 0.0427, Initial Validation Loss: 0.1323, Validation Loss: 0.0492,V Acc: 0.7636, Top 70th Acc: 0.8312, Bottom 30th Acc: 0.6061
Fold [3/5] Epoch [20/100] Initial Loss: 0.1423, Training Loss: 0.0218, Initial Validation Loss: 0.1323, Validation Loss: 0.0366,V Acc: 0.8273, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.8961038961038961
7 2 [array([0.33477017, 0.04949905, 0.17584969, 0.30763704, 0.13224414],
      dtype=float32)]
Fold [4/5] Epoch [0/100] Initial Loss: 0.1377, Training Loss: 0.1377, Initial Validation Loss: 0.1346, Validation Loss: 0.1346,V Acc: 0.4000, Top 70th Acc: 0.4805, Bottom 30th Acc: 0.2121
Fold [4/5] Epoch [10/100] Initial Loss: 0.1377, Training Loss: 0.0435, Initial Validation Loss: 0.1346, Validation Loss: 0.0597,V Acc: 0.7455, Top 70th Acc: 0.8312, Bottom 30th Acc: 0.5455
Fold [4/5] Epoch [20/100] Initial Loss: 0.1377, Training Loss: 0.0207, Initial Validation Loss: 0.1346, Validation Loss: 0.0463,V Acc: 0.8091, Top 70th Acc: 0.8831, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.8831168831168831
Fold [5/5] Epoch [0/100] Initial Loss: 0.1379, Training Loss: 0.1379, Initial Validation Loss: 0.1349, Validation Loss: 0.1349,V Acc: 0.3333, Top 70th Acc: 0.3947, Bottom 30th Acc: 0.1875
Fold [5/5] Epoch [10/100] Initial Loss: 0.1379, Training Loss: 0.0323, Initial Validation Loss: 0.1349, Validation Loss: 0.0285,V Acc: 0.8981, Top 70th Acc: 0.9868, Bottom 30th Acc: 0.6875
Stopping early at Epoch (base 0): 18  Rolling back to Epoch (base 0): 13  Top Validation Acc: 0.9868421052631579
Running train_nn.py with seed 8
CUDA:False
Training samples count:  550
Training on 20 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1383, Training Loss: 0.1383, Initial Validation Loss: 0.1323, Validation Loss: 0.1323,V Acc: 0.3784, Top 70th Acc: 0.4359, Bottom 30th Acc: 0.2424
Fold [1/5] Epoch [10/100] Initial Loss: 0.1383, Training Loss: 0.0388, Initial Validation Loss: 0.1323, Validation Loss: 0.0374,V Acc: 0.8108, Top 70th Acc: 0.8974, Bottom 30th Acc: 0.6061
Fold [1/5] Epoch [20/100] Initial Loss: 0.1383, Training Loss: 0.0241, Initial Validation Loss: 0.1323, Validation Loss: 0.0268,V Acc: 0.8378, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.9358974358974359
Fold [2/5] Epoch [0/100] Initial Loss: 0.1394, Training Loss: 0.1394, Initial Validation Loss: 0.1353, Validation Loss: 0.1353,V Acc: 0.4144, Top 70th Acc: 0.4744, Bottom 30th Acc: 0.2727
Fold [2/5] Epoch [10/100] Initial Loss: 0.1394, Training Loss: 0.0430, Initial Validation Loss: 0.1353, Validation Loss: 0.0457,V Acc: 0.8288, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.5758
Fold [2/5] Epoch [20/100] Initial Loss: 0.1394, Training Loss: 0.0242, Initial Validation Loss: 0.1353, Validation Loss: 0.0301,V Acc: 0.8829, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.6667
Fold [2/5] Epoch [30/100] Initial Loss: 0.1394, Training Loss: 0.0209, Initial Validation Loss: 0.1353, Validation Loss: 0.0302,V Acc: 0.8829, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 30  Rolling back to Epoch (base 0): 25  Top Validation Acc: 0.9743589743589743
8 1 [array([0.3686873 , 0.06186339, 0.08744702, 0.27788493, 0.2041174 ],
      dtype=float32)]
Fold [3/5] Epoch [0/100] Initial Loss: 0.1413, Training Loss: 0.1413, Initial Validation Loss: 0.1332, Validation Loss: 0.1332,V Acc: 0.2273, Top 70th Acc: 0.2078, Bottom 30th Acc: 0.2727
Fold [3/5] Epoch [10/100] Initial Loss: 0.1413, Training Loss: 0.0353, Initial Validation Loss: 0.1332, Validation Loss: 0.0375,V Acc: 0.8364, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.6364
Fold [3/5] Epoch [20/100] Initial Loss: 0.1413, Training Loss: 0.0214, Initial Validation Loss: 0.1332, Validation Loss: 0.0337,V Acc: 0.8364, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.922077922077922
Fold [4/5] Epoch [0/100] Initial Loss: 0.1404, Training Loss: 0.1404, Initial Validation Loss: 0.1375, Validation Loss: 0.1375,V Acc: 0.2545, Top 70th Acc: 0.3377, Bottom 30th Acc: 0.0606
Fold [4/5] Epoch [10/100] Initial Loss: 0.1404, Training Loss: 0.0442, Initial Validation Loss: 0.1375, Validation Loss: 0.0582,V Acc: 0.7455, Top 70th Acc: 0.8571, Bottom 30th Acc: 0.4848
Fold [4/5] Epoch [20/100] Initial Loss: 0.1404, Training Loss: 0.0301, Initial Validation Loss: 0.1375, Validation Loss: 0.0460,V Acc: 0.7545, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.3939
Fold [4/5] Epoch [30/100] Initial Loss: 0.1404, Training Loss: 0.0222, Initial Validation Loss: 0.1375, Validation Loss: 0.0383,V Acc: 0.8273, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.6364
Fold [4/5] Epoch [40/100] Initial Loss: 0.1404, Training Loss: 0.0199, Initial Validation Loss: 0.1375, Validation Loss: 0.0358,V Acc: 0.8364, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 48  Rolling back to Epoch (base 0): 43  Top Validation Acc: 0.922077922077922
Fold [5/5] Epoch [0/100] Initial Loss: 0.1403, Training Loss: 0.1403, Initial Validation Loss: 0.1321, Validation Loss: 0.1321,V Acc: 0.3333, Top 70th Acc: 0.3289, Bottom 30th Acc: 0.3438
Fold [5/5] Epoch [10/100] Initial Loss: 0.1403, Training Loss: 0.0362, Initial Validation Loss: 0.1321, Validation Loss: 0.0471,V Acc: 0.7407, Top 70th Acc: 0.8684, Bottom 30th Acc: 0.4375
Fold [5/5] Epoch [20/100] Initial Loss: 0.1403, Training Loss: 0.0244, Initial Validation Loss: 0.1321, Validation Loss: 0.0394,V Acc: 0.8056, Top 70th Acc: 0.9079, Bottom 30th Acc: 0.5625
Fold [5/5] Epoch [30/100] Initial Loss: 0.1403, Training Loss: 0.0198, Initial Validation Loss: 0.1321, Validation Loss: 0.0375,V Acc: 0.8148, Top 70th Acc: 0.9079, Bottom 30th Acc: 0.5938
Stopping early at Epoch (base 0): 37  Rolling back to Epoch (base 0): 32  Top Validation Acc:
Fold [1/5] Epoch [20/100] Initial Loss: 0.1382, Training Loss: 0.0144, Initial Validation Loss: 0.1323, Validation Loss: 0.0241,V Acc: 0.8559, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.9358974358974359
Fold [2/5] Epoch [0/100] Initial Loss: 0.1382, Training Loss: 0.1382, Initial Validation Loss: 0.1367, Validation Loss: 0.1367,V Acc: 0.3423, Top 70th Acc: 0.3205, Bottom 30th Acc: 0.3939
Fold [2/5] Epoch [10/100] Initial Loss: 0.1382, Training Loss: 0.0254, Initial Validation Loss: 0.1367, Validation Loss: 0.0412,V Acc: 0.8018, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.5152
Fold [2/5] Epoch [20/100] Initial Loss: 0.1382, Training Loss: 0.0145, Initial Validation Loss: 0.1367, Validation Loss: 0.0332,V Acc: 0.8198, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.5152
Fold [2/5] Epoch [30/100] Initial Loss: 0.1382, Training Loss: 0.0123, Initial Validation Loss: 0.1367, Validation Loss: 0.0317,V Acc: 0.8018, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.4242
Stopping early at Epoch (base 0): 38  Rolling back to Epoch (base 0): 33  Top Validation Acc: 0.9487179487179487
Fold [3/5] Epoch [0/100] Initial Loss: 0.1410, Training Loss: 0.1410, Initial Validation Loss: 0.1304, Validation Loss: 0.1304,V Acc: 0.3636, Top 70th Acc: 0.3506, Bottom 30th Acc: 0.3939
Fold [3/5] Epoch [10/100] Initial Loss: 0.1410, Training Loss: 0.0284, Initial Validation Loss: 0.1304, Validation Loss: 0.0389,V Acc: 0.8182, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.6061
Fold [3/5] Epoch [20/100] Initial Loss: 0.1410, Training Loss: 0.0137, Initial Validation Loss: 0.1304, Validation Loss: 0.0342,V Acc: 0.8455, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 21  Rolling back to Epoch (base 0): 16  Top Validation Acc: 0.8961038961038961
7 2 [array([0.65749663, 0.03608401, 0.04406848, 0.12674364, 0.13560724],
      dtype=float32)]
Fold [4/5] Epoch [0/100] Initial Loss: 0.1382, Training Loss: 0.1382, Initial Validation Loss: 0.1349, Validation Loss: 0.1349,V Acc: 0.2818, Top 70th Acc: 0.3377, Bottom 30th Acc: 0.1515
Fold [4/5] Epoch [10/100] Initial Loss: 0.1382, Training Loss: 0.0274, Initial Validation Loss: 0.1349, Validation Loss: 0.0481,V Acc: 0.7727, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.3636
Fold [4/5] Epoch [20/100] Initial Loss: 0.1382, Training Loss: 0.0156, Initial Validation Loss: 0.1349, Validation Loss: 0.0396,V Acc: 0.8182, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.5152
Fold [4/5] Epoch [30/100] Initial Loss: 0.1382, Training Loss: 0.0115, Initial Validation Loss: 0.1349, Validation Loss: 0.0383,V Acc: 0.7909, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.3939
Stopping early at Epoch (base 0): 38  Rolling back to Epoch (base 0): 33  Top Validation Acc: 0.935064935064935
Fold [5/5] Epoch [0/100] Initial Loss: 0.1331, Training Loss: 0.1331, Initial Validation Loss: 0.1281, Validation Loss: 0.1281,V Acc: 0.3796, Top 70th Acc: 0.4737, Bottom 30th Acc: 0.1562
Fold [5/5] Epoch [10/100] Initial Loss: 0.1331, Training Loss: 0.0378, Initial Validation Loss: 0.1281, Validation Loss: 0.0326,V Acc: 0.8611, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.6250
Fold [5/5] Epoch [20/100] Initial Loss: 0.1331, Training Loss: 0.0169, Initial Validation Loss: 0.1281, Validation Loss: 0.0199,V Acc: 0.9074, Top 70th Acc: 1.0000, Bottom 30th Acc: 0.6875
Stopping early at Epoch (base 0): 28  Rolling back to Epoch (base 0): 23  Top Validation Acc: 1.0
Running train_nn.py with seed 8
CUDA:False
Training samples count:  550
Training on 40 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1400, Training Loss: 0.1400, Initial Validation Loss: 0.1328, Validation Loss: 0.1328,V Acc: 0.2703, Top 70th Acc: 0.3333, Bottom 30th Acc: 0.1212
Fold [1/5] Epoch [10/100] Initial Loss: 0.1400, Training Loss: 0.0246, Initial Validation Loss: 0.1328, Validation Loss: 0.0317,V Acc: 0.8198, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.5455
Fold [1/5] Epoch [20/100] Initial Loss: 0.1400, Training Loss: 0.0152, Initial Validation Loss: 0.1328, Validation Loss: 0.0278,V Acc: 0.8288, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.4848
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.9615384615384616
Fold [2/5] Epoch [0/100] Initial Loss: 0.1364, Training Loss: 0.1364, Initial Validation Loss: 0.1334, Validation Loss: 0.1334,V Acc: 0.4234, Top 70th Acc: 0.5513, Bottom 30th Acc: 0.1212
Fold [2/5] Epoch [10/100] Initial Loss: 0.1364, Training Loss: 0.0338, Initial Validation Loss: 0.1334, Validation Loss: 0.0438,V Acc: 0.8378, Top 70th Acc: 0.8974, Bottom 30th Acc: 0.6970
Fold [2/5] Epoch [20/100] Initial Loss: 0.1364, Training Loss: 0.0156, Initial Validation Loss: 0.1334, Validation Loss: 0.0289,V Acc: 0.8649, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.6970
Fold [2/5] Epoch [30/100] Initial Loss: 0.1364, Training Loss: 0.0128, Initial Validation Loss: 0.1334, Validation Loss: 0.0277,V Acc: 0.8829, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.7576
Stopping early at Epoch (base 0): 31  Rolling back to Epoch (base 0): 26  Top Validation Acc: 0.9358974358974359
8 1 [array([0.6281527 , 0.04542127, 0.08407298, 0.09076796, 0.15158504],
      dtype=float32)]
Fold [3/5] Epoch [0/100] Initial Loss: 0.1416, Training Loss: 0.1416, Initial Validation Loss: 0.1323, Validation Loss: 0.1323,V Acc: 0.2636, Top 70th Acc: 0.2078, Bottom 30th Acc: 0.3939
Fold [3/5] Epoch [10/100] Initial Loss: 0.1416, Training Loss: 0.0369, Initial Validation Loss: 0.1323, Validation Loss: 0.0410,V Acc: 0.8364, Top 70th Acc: 0.8961, Bottom 30th Acc: 0.6970
Fold [3/5] Epoch [20/100] Initial Loss: 0.1416, Training Loss: 0.0169, Initial Validation Loss: 0.1323, Validation Loss: 0.0279,V Acc: 0.8727, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.6667
Fold [3/5] Epoch [30/100] Initial Loss: 0.1416, Training Loss: 0.0123, Initial Validation Loss: 0.1323, Validation Loss: 0.0268,V Acc: 0.8909, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.7273
Stopping early at Epoch (base 0): 35  Rolling back to Epoch (base 0): 30  Top Validation Acc: 0.948051948051948
Fold [4/5] Epoch [0/100] Initial Loss: 0.1380, Training Loss: 0.1380, Initial Validation Loss: 0.1389, Validation Loss: 0.1389,V Acc: 0.2545, Top 70th Acc: 0.3506, Bottom 30th Acc: 0.0303
Fold [4/5] Epoch [10/100] Initial Loss: 0.1380, Training Loss: 0.0447, Initial Validation Loss: 0.1389, Validation Loss: 0.0574,V Acc: 0.7273, Top 70th Acc: 0.8571, Bottom 30th Acc: 0.4242
Fold [4/5] Epoch [20/100] Initial Loss: 0.1380, Training Loss: 0.0167, Initial Validation Loss: 0.1389, Validation Loss: 0.0354,V Acc: 0.8364, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.6364
Fold [4/5] Epoch [30/100] Initial Loss: 0.1380, Training Loss: 0.0119, Initial Validation Loss: 0.1389, Validation Loss: 0.0331,V Acc: 0.8455, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 34  Rolling back to Epoch (base 0): 29  Top Validation Acc: 0.935064935064935
Fold [5/5] Epoch [0/100] Initial Loss: 0.1377, Training Loss: 0.1377, Initial Validation Loss: 0.1288, Validation Loss: 0.1288,V Acc: 0.3241, Top 70th Acc: 0.4211, Bottom 30th Acc: 0.0938
Fold [5/5] Epoch [10/100] Initial Loss: 0.1377, Training Loss: 0.0310, Initial Validation Loss: 0.1288, Validation Loss: 0.0403,V Acc: 0.8333, Top 70th Acc: 0.9079, Bottom 30th Acc: 0.6562
Fold [5/5] Epoch [20/100] Initial Loss: 0.1377, Training Loss: 0.0136, Initial Validation Loss: 0.1288, Validation Loss: 0.0313,V Acc: 0.8148, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.5000
Stopping early at Epoch (base 0): 22  Rolling back to Epoch (base 0): 17  Top Validation Acc: 0.9473684210526315
Running train_nn.py with seed 9
CUDA:False
Training samples count:  550
Training on 40 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1383, Training Loss: 0.1383, Initial Validation Loss: 0.1348, Validation Loss: 0.1348,V Acc: 0.3694, Top 70th Acc: 0.4103, Bottom 30th Acc: 0.2727
Fold [1/5] Epoch [10/100] Initial Loss: 0.1383, Training Loss: 0.0244, Initial Validation Loss: 0.1348, Validation Loss: 0.0357,V Acc: 0.8739, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.7879
Stopping early at Epoch (base 0): 18  Rolling back to Epoch (base 0): 13  Top Validation Acc:
Fold [1/5] Epoch [10/100] Initial Loss: 0.1360, Training Loss: 0.0835, Initial Validation Loss: 0.1287, Validation Loss: 0.0775,V Acc: 0.6577, Top 70th Acc: 0.7692, Bottom 30th Acc: 0.3939
Fold [1/5] Epoch [20/100] Initial Loss: 0.1360, Training Loss: 0.0807, Initial Validation Loss: 0.1287, Validation Loss: 0.0748,V Acc: 0.6577, Top 70th Acc: 0.7692, Bottom 30th Acc: 0.3939
Fold [1/5] Epoch [30/100] Initial Loss: 0.1360, Training Loss: 0.0800, Initial Validation Loss: 0.1287, Validation Loss: 0.0734,V Acc: 0.6577, Top 70th Acc: 0.7692, Bottom 30th Acc: 0.3939
Stopping early at Epoch (base 0): 37  Rolling back to Epoch (base 0): 32  Top Validation Acc: 0.7692307692307693
Fold [2/5] Epoch [0/100] Initial Loss: 0.1304, Training Loss: 0.1304, Initial Validation Loss: 0.1221, Validation Loss: 0.1221,V Acc: 0.5045, Top 70th Acc: 0.5641, Bottom 30th Acc: 0.3636
Fold [2/5] Epoch [10/100] Initial Loss: 0.1304, Training Loss: 0.0782, Initial Validation Loss: 0.1221, Validation Loss: 0.0891,V Acc: 0.6126, Top 70th Acc: 0.6795, Bottom 30th Acc: 0.4545
Stopping early at Epoch (base 0): 12  Rolling back to Epoch (base 0): 7  Top Validation Acc: 0.6923076923076923
Fold [3/5] Epoch [0/100] Initial Loss: 0.1418, Training Loss: 0.1418, Initial Validation Loss: 0.1317, Validation Loss: 0.1317,V Acc: 0.3000, Top 70th Acc: 0.4286, Bottom 30th Acc: 0.0000
Fold [3/5] Epoch [10/100] Initial Loss: 0.1418, Training Loss: 0.0821, Initial Validation Loss: 0.1317, Validation Loss: 0.0802,V Acc: 0.6000, Top 70th Acc: 0.7922, Bottom 30th Acc: 0.1515
Fold [3/5] Epoch [20/100] Initial Loss: 0.1418, Training Loss: 0.0790, Initial Validation Loss: 0.1317, Validation Loss: 0.0766,V Acc: 0.6182, Top 70th Acc: 0.7922, Bottom 30th Acc: 0.2121
Fold [3/5] Epoch [30/100] Initial Loss: 0.1418, Training Loss: 0.0780, Initial Validation Loss: 0.1317, Validation Loss: 0.0763,V Acc: 0.6182, Top 70th Acc: 0.7922, Bottom 30th Acc: 0.2121
Fold [3/5] Epoch [40/100] Initial Loss: 0.1418, Training Loss: 0.0780, Initial Validation Loss: 0.1317, Validation Loss: 0.0753,V Acc: 0.6091, Top 70th Acc: 0.7922, Bottom 30th Acc: 0.1818
Fold [3/5] Epoch [50/100] Initial Loss: 0.1418, Training Loss: 0.0776, Initial Validation Loss: 0.1317, Validation Loss: 0.0750,V Acc: 0.6000, Top 70th Acc: 0.7662, Bottom 30th Acc: 0.2121
Stopping early at Epoch (base 0): 52  Rolling back to Epoch (base 0): 47  Top Validation Acc: 0.7792207792207793
7 2 [array([0.1437123 , 0.32679892, 0.14251442, 0.24305333, 0.14392108],
      dtype=float32)]
Fold [4/5] Epoch [0/100] Initial Loss: 0.1355, Training Loss: 0.1355, Initial Validation Loss: 0.1301, Validation Loss: 0.1301,V Acc: 0.4182, Top 70th Acc: 0.4675, Bottom 30th Acc: 0.3030
Fold [4/5] Epoch [10/100] Initial Loss: 0.1355, Training Loss: 0.0791, Initial Validation Loss: 0.1301, Validation Loss: 0.0848,V Acc: 0.6273, Top 70th Acc: 0.6883, Bottom 30th Acc: 0.4848
Fold [4/5] Epoch [20/100] Initial Loss: 0.1355, Training Loss: 0.0762, Initial Validation Loss: 0.1301, Validation Loss: 0.0840,V Acc: 0.6000, Top 70th Acc: 0.7013, Bottom 30th Acc: 0.3636
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.6883116883116883
Fold [5/5] Epoch [0/100] Initial Loss: 0.1377, Training Loss: 0.1377, Initial Validation Loss: 0.1261, Validation Loss: 0.1261,V Acc: 0.4722, Top 70th Acc: 0.5658, Bottom 30th Acc: 0.2500
Fold [5/5] Epoch [10/100] Initial Loss: 0.1377, Training Loss: 0.0817, Initial Validation Loss: 0.1261, Validation Loss: 0.0744,V Acc: 0.6204, Top 70th Acc: 0.7368, Bottom 30th Acc: 0.3438
Fold [5/5] Epoch [20/100] Initial Loss: 0.1377, Training Loss: 0.0804, Initial Validation Loss: 0.1261, Validation Loss: 0.0722,V Acc: 0.6389, Top 70th Acc: 0.7632, Bottom 30th Acc: 0.3438
Fold [5/5] Epoch [30/100] Initial Loss: 0.1377, Training Loss: 0.0796, Initial Validation Loss: 0.1261, Validation Loss: 0.0718,V Acc: 0.6389, Top 70th Acc: 0.7632, Bottom 30th Acc: 0.3438
Fold [5/5] Epoch [40/100] Initial Loss: 0.1377, Training Loss: 0.0788, Initial Validation Loss: 0.1261, Validation Loss: 0.0712,V Acc: 0.6667, Top 70th Acc: 0.7763, Bottom 30th Acc: 0.4062
Fold [5/5] Epoch [50/100] Initial Loss: 0.1377, Training Loss: 0.0785, Initial Validation Loss: 0.1261, Validation Loss: 0.0707,V Acc: 0.6667, Top 70th Acc: 0.7500, Bottom 30th Acc: 0.4688
Fold [5/5] Epoch [60/100] Initial Loss: 0.1377, Training Loss: 0.0779, Initial Validation Loss: 0.1261, Validation Loss: 0.0708,V Acc: 0.6574, Top 70th Acc: 0.7632, Bottom 30th Acc: 0.4062
Stopping early at Epoch (base 0): 64  Rolling back to Epoch (base 0): 59  Top Validation Acc: 0.7763157894736842
Running train_nn.py with seed 8
CUDA:False
Training samples count:  550
Training on 2 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1319, Training Loss: 0.1319, Initial Validation Loss: 0.1211, Validation Loss: 0.1211,V Acc: 0.3964, Top 70th Acc: 0.5256, Bottom 30th Acc: 0.0909
Fold [1/5] Epoch [10/100] Initial Loss: 0.1319, Training Loss: 0.0813, Initial Validation Loss: 0.1211, Validation Loss: 0.0760,V Acc: 0.6757, Top 70th Acc: 0.7308, Bottom 30th Acc: 0.5455
Fold [1/5] Epoch [20/100] Initial Loss: 0.1319, Training Loss: 0.0789, Initial Validation Loss: 0.1211, Validation Loss: 0.0748,V Acc: 0.6396, Top 70th Acc: 0.7179, Bottom 30th Acc: 0.4545
Fold [1/5] Epoch [30/100] Initial Loss: 0.1319, Training Loss: 0.0785, Initial Validation Loss: 0.1211, Validation Loss: 0.0735,V Acc: 0.6486, Top 70th Acc: 0.7308, Bottom 30th Acc: 0.4545
Fold [1/5] Epoch [40/100] Initial Loss: 0.1319, Training Loss: 0.0777, Initial Validation Loss: 0.1211, Validation Loss: 0.0732,V Acc: 0.6486, Top 70th Acc: 0.7436, Bottom 30th Acc: 0.4242
Stopping early at Epoch (base 0): 45  Rolling back to Epoch (base 0): 40  Top Validation Acc: 0.7564102564102564
Fold [2/5] Epoch [0/100] Initial Loss: 0.1363, Training Loss: 0.1363, Initial Validation Loss: 0.1336, Validation Loss: 0.1336,V Acc: 0.3333, Top 70th Acc: 0.4103, Bottom 30th Acc: 0.1515
Fold [2/5] Epoch [10/100] Initial Loss: 0.1363, Training Loss: 0.0807, Initial Validation Loss: 0.1336, Validation Loss: 0.0837,V Acc: 0.6036, Top 70th Acc: 0.7436, Bottom 30th Acc: 0.2727
Fold [2/5] Epoch [20/100] Initial Loss: 0.1363, Training Loss: 0.0777, Initial Validation Loss: 0.1336, Validation Loss: 0.0814,V Acc: 0.6036, Top 70th Acc: 0.7436, Bottom 30th Acc: 0.2727
Fold [2/5] Epoch [30/100] Initial Loss: 0.1363, Training Loss: 0.0768, Initial Validation Loss: 0.1336, Validation Loss: 0.0809,V Acc: 0.6126, Top 70th Acc: 0.7436, Bottom 30th Acc: 0.3030
Fold [2/5] Epoch [40/100] Initial Loss: 0.1363, Training Loss: 0.0758, Initial Validation Loss: 0.1336, Validation Loss: 0.0806,V Acc: 0.6216, Top 70th Acc: 0.7436, Bottom 30th Acc: 0.3333
Fold [2/5] Epoch [50/100] Initial Loss: 0.1363, Training Loss: 0.0753, Initial Validation Loss: 0.1336, Validation Loss: 0.0805,V Acc: 0.6396, Top 70th Acc: 0.7564, Bottom 30th Acc: 0.3636
Stopping early at Epoch (base 0): 52  Rolling back to Epoch (base 0): 47  Top Validation Acc: 0.7435897435897436
8 1 [array([0.13821176, 0.34761402, 0.11711005, 0.26450384, 0.1325604 ],
      dtype=float32)]
Fold [3/5] Epoch [0/100] Initial Loss: 0.1420, Training Loss: 0.1420, Initial Validation Loss: 0.1318, Validation Loss: 0.1318,V Acc: 0.2636, Top 70th Acc: 0.3506, Bottom 30th Acc: 0.0606
Fold [3/5] Epoch [10/100] Initial Loss: 0.1420, Training Loss: 0.0812, Initial Validation Loss: 0.1318, Validation Loss: 0.0792,V Acc: 0.6273, Top 70th Acc: 0.7143, Bottom 30th Acc: 0.4242
Fold [3/5] Epoch [20/100] Initial Loss: 0.1420, Training Loss: 0.0788, Initial Validation Loss: 0.1318, Validation Loss: 0.0782,V Acc: 0.6182, Top 70th Acc: 0.7273, Bottom 30th Acc: 0.3636
Stopping early at Epoch (base 0): 21  Rolling back to Epoch (base 0): 16  Top Validation Acc: 0.7142857142857143
Fold [4/5] Epoch [0/100] Initial Loss: 0.1344, Training Loss: 0.1344, Initial Validation Loss: 0.1305, Validation Loss: 0.1305,V Acc: 0.3909, Top 70th Acc: 0.5195, Bottom 30th Acc: 0.0909
Fold [4/5] Epoch [10/100] Initial Loss: 0.1344, Training Loss: 0.0792, Initial Validation Loss: 0.1305, Validation Loss: 0.0868,V Acc: 0.5909, Top 70th Acc: 0.7403, Bottom 30th Acc: 0.2424
Fold [4/5] Epoch [20/100] Initial Loss: 0.1344, Training Loss: 0.0773, Initial Validation Loss: 0.1305, Validation Loss: 0.0837,V Acc: 0.6273, Top 70th Acc: 0.7662, Bottom 30th Acc: 0.3030 0.9605263157894737
Running train_nn.py with seed 7
CUDA:False
Training samples count:  550
Training on 30 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1411, Training Loss: 0.1411, Initial Validation Loss: 0.1356, Validation Loss: 0.1356,V Acc: 0.2523, Top 70th Acc: 0.2564, Bottom 30th Acc: 0.2424
Fold [1/5] Epoch [10/100] Initial Loss: 0.1411, Training Loss: 0.0354, Initial Validation Loss: 0.1356, Validation Loss: 0.0346,V Acc: 0.8108, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.5152
Fold [1/5] Epoch [20/100] Initial Loss: 0.1411, Training Loss: 0.0193, Initial Validation Loss: 0.1356, Validation Loss: 0.0279,V Acc: 0.8378, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.6364
Fold [1/5] Epoch [30/100] Initial Loss: 0.1411, Training Loss: 0.0163, Initial Validation Loss: 0.1356, Validation Loss: 0.0276,V Acc: 0.8288, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 32  Rolling back to Epoch (base 0): 27  Top Validation Acc: 0.9487179487179487
Fold [2/5] Epoch [0/100] Initial Loss: 0.1401, Training Loss: 0.1401, Initial Validation Loss: 0.1375, Validation Loss: 0.1375,V Acc: 0.2252, Top 70th Acc: 0.2821, Bottom 30th Acc: 0.0909
Fold [2/5] Epoch [10/100] Initial Loss: 0.1401, Training Loss: 0.0384, Initial Validation Loss: 0.1375, Validation Loss: 0.0493,V Acc: 0.7748, Top 70th Acc: 0.8974, Bottom 30th Acc: 0.4848
Fold [2/5] Epoch [20/100] Initial Loss: 0.1401, Training Loss: 0.0194, Initial Validation Loss: 0.1375, Validation Loss: 0.0329,V Acc: 0.8559, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 27  Rolling back to Epoch (base 0): 22  Top Validation Acc: 0.9615384615384616
Fold [3/5] Epoch [0/100] Initial Loss: 0.1399, Training Loss: 0.1399, Initial Validation Loss: 0.1313, Validation Loss: 0.1313,V Acc: 0.2455, Top 70th Acc: 0.3247, Bottom 30th Acc: 0.0606
Fold [3/5] Epoch [10/100] Initial Loss: 0.1399, Training Loss: 0.0280, Initial Validation Loss: 0.1313, Validation Loss: 0.0424,V Acc: 0.7909, Top 70th Acc: 0.8701, Bottom 30th Acc: 0.6061
Fold [3/5] Epoch [20/100] Initial Loss: 0.1399, Training Loss: 0.0170, Initial Validation Loss: 0.1313, Validation Loss: 0.0376,V Acc: 0.8091, Top 70th Acc: 0.8961, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 28  Rolling back to Epoch (base 0): 23  Top Validation Acc: 0.8831168831168831
7 2 [array([0.77468026, 0.0660567 , 0.02491639, 0.07651044, 0.05783614],
      dtype=float32)]
Fold [4/5] Epoch [0/100] Initial Loss: 0.1395, Training Loss: 0.1395, Initial Validation Loss: 0.1347, Validation Loss: 0.1347,V Acc: 0.3364, Top 70th Acc: 0.3766, Bottom 30th Acc: 0.2424
Fold [4/5] Epoch [10/100] Initial Loss: 0.1395, Training Loss: 0.0284, Initial Validation Loss: 0.1347, Validation Loss: 0.0455,V Acc: 0.8000, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.5455
Fold [4/5] Epoch [20/100] Initial Loss: 0.1395, Training Loss: 0.0164, Initial Validation Loss: 0.1347, Validation Loss: 0.0392,V Acc: 0.8182, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 22  Rolling back to Epoch (base 0): 17  Top Validation Acc: 0.9090909090909091
Fold [5/5] Epoch [0/100] Initial Loss: 0.1382, Training Loss: 0.1382, Initial Validation Loss: 0.1333, Validation Loss: 0.1333,V Acc: 0.3611, Top 70th Acc: 0.3947, Bottom 30th Acc: 0.2812
Fold [5/5] Epoch [10/100] Initial Loss: 0.1382, Training Loss: 0.0294, Initial Validation Loss: 0.1333, Validation Loss: 0.0274,V Acc: 0.8704, Top 70th Acc: 0.9868, Bottom 30th Acc: 0.5938
Fold [5/5] Epoch [20/100] Initial Loss: 0.1382, Training Loss: 0.0196, Initial Validation Loss: 0.1333, Validation Loss: 0.0239,V Acc: 0.8796, Top 70th Acc: 0.9868, Bottom 30th Acc: 0.6250
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.9868421052631579
Running train_nn.py with seed 8
CUDA:False
Training samples count:  550
Training on 30 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1384, Training Loss: 0.1384, Initial Validation Loss: 0.1325, Validation Loss: 0.1325,V Acc: 0.2703, Top 70th Acc: 0.3077, Bottom 30th Acc: 0.1818
Fold [1/5] Epoch [10/100] Initial Loss: 0.1384, Training Loss: 0.0272, Initial Validation Loss: 0.1325, Validation Loss: 0.0297,V Acc: 0.8468, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.5758
Fold [1/5] Epoch [20/100] Initial Loss: 0.1384, Training Loss: 0.0184, Initial Validation Loss: 0.1325, Validation Loss: 0.0258,V Acc: 0.8378, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.5152
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.9487179487179487
Fold [2/5] Epoch [0/100] Initial Loss: 0.1405, Training Loss: 0.1405, Initial Validation Loss: 0.1396, Validation Loss: 0.1396,V Acc: 0.2523, Top 70th Acc: 0.3205, Bottom 30th Acc: 0.0909
Fold [2/5] Epoch [10/100] Initial Loss: 0.1405, Training Loss: 0.0346, Initial Validation Loss: 0.1396, Validation Loss: 0.0393,V Acc: 0.8559, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.6970
Fold [2/5] Epoch [20/100] Initial Loss: 0.1405, Training Loss: 0.0189, Initial Validation Loss: 0.1396, Validation Loss: 0.0278,V Acc: 0.8919, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.7576
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.9487179487179487
8 1 [array([0.56307626, 0.06098277, 0.03626346, 0.10282111, 0.23685642],
      dtype=float32)]
Fold [3/5] Epoch [0/100] Initial Loss: 0.1416, Training Loss: 0.1416, Initial Validation Loss: 0.1293, Validation Loss: 0.1293,V Acc: 0.2545, Top 70th Acc: 0.3636, Bottom 30th Acc: 0.0000
Fold [3/5] Epoch [10/100] Initial Loss: 0.1416, Training Loss: 0.0322, Initial Validation Loss: 0.1293, Validation Loss: 0.0342,V Acc: 0.8455, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.5455
Fold [3/5] Epoch [20/100] Initial Loss: 0.1416, Training Loss: 0.0181, Initial Validation Loss: 0.1293, Validation Loss: 0.0302,V Acc: 0.8273, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.948051948051948
Fold [4/5] Epoch [0/100] Initial Loss: 0.1342, Training Loss: 0.1342, Initial Validation Loss: 0.1340, Validation Loss: 0.1340,V Acc: 0.4364, Top 70th Acc: 0.4805, Bottom 30th Acc: 0.3333
Fold [4/5] Epoch [10/100] Initial Loss: 0.1342, Training Loss: 0.0336, Initial Validation Loss: 0.1340, Validation Loss: 0.0444,V Acc: 0.7818, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.4848
Fold [4/5] Epoch [20/100] Initial Loss: 0.1342, Training Loss: 0.0217, Initial Validation Loss: 0.1340, Validation Loss: 0.0379,V Acc: 0.8364, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.6061
Fold [4/5] Epoch [30/100] Initial Loss: 0.1342, Training Loss: 0.0161, Initial Validation Loss: 0.1340, Validation Loss: 0.0351,V Acc: 0.8273, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.5758
Fold [4/5] Epoch [40/100] Initial Loss: 0.1342, Training Loss: 0.0137, Initial Validation Loss: 0.1340, Validation Loss: 0.0351,V Acc: 0.8182, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 40  Rolling back to Epoch (base 0): 35  Top Validation Acc: 0.935064935064935
Fold [5/5] Epoch [0/100] Initial Loss: 0.1396, Training Loss: 0.1396, Initial Validation Loss: 0.1312, Validation Loss: 0.1312,V Acc: 0.3241, Top 70th Acc: 0.3421, Bottom 30th Acc: 0.2812
Fold [5/5] Epoch [10/100] Initial Loss: 0.1396, Training Loss: 0.0275, Initial Validation Loss: 0.1312, Validation Loss: 0.0409,V Acc: 0.8148, Top 70th Acc: 0.9079, Bottom 30th Acc: 0.5938
Fold [5/5] Epoch [20/100] Initial Loss: 0.1396, Training Loss: 0.0163, Initial Validation Loss: 0.1312, Validation Loss: 0.0339,V Acc: 0.8056, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.4688
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.9342105263157895
Running train_nn.py with seed 9
CUDA:False
Training samples count:  550
Training on 30 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1414, Training Loss: 0.1414, Initial Validation Loss: 0.1366, Validation Loss: 0.1366,V Acc: 0.2793, Top 70th Acc: 0.3590, Bottom 30th Acc: 0.0909
Fold [1/5] Epoch [10/100] Initial Loss: 0.1414, Training Loss: 0.0379, Initial Validation Loss: 0.1366, Validation Loss: 0.0459,V Acc: 0.8108, Top 70th Acc: 0.8974, Bottom 30th Acc: 0.6061training rf with seed 1
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 21 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 2
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 21 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 3
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 21 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 4
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 21 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 5
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 21 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 6
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 21 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 7
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 21 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 8
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 21 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 9
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 21 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 10
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 21 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 11
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 21 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 12
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 21 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 13
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 21 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 14
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 21 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 15
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 21 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 16
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 21 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 17
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 21 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 18
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 21 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 19
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 21 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 20
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 21 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 21
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 21 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 22
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 21 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 23
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 21 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 24
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 21 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 25
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 21 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 26
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 21 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 27
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 21 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 28
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 21 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 29
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 21 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 30
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 21 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 31
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 21 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 32
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 21 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 33
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 21 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 34
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 21 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 35
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 21 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 36
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 21 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 37
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 21 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 38
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 21 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 39
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 21 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 40
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 21 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 41
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 21 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 42
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 21 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 43
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 21 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 44
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 21 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 45
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 46
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 2 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 47
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 2 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 48
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 2 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 49
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 2 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 50
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 2 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 51
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 2 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 52
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 2 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 53
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 2 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 54
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 2 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 55
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 2 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 56
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 2 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 57
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 2 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 58
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 2 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 59
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 2 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 60
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 2 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 61
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 2 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 62
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 2 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 63
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 2 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 64
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 2 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 65
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 2 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 66
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 2 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 67
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 2 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 68
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 2 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 69
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 2 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 70
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 2 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 71
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 2 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 72
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 2 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 73
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 2 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 74
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 2 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 75
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 2 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 76
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 2 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 77
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 2 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 78
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 2 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 79
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 2 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 80
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 2 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 81
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 2 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 82
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 2 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 83
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 2 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 84
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 2 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 85
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 2 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 86
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 2 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 87
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 2 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 88
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 2 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 89
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 2 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 90
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Fold [5/5] Epoch [10/100] Initial Loss: 0.1398, Training Loss: 0.0284, Initial Validation Loss: 0.1290, Validation Loss: 0.0448,V Acc: 0.7593, Top 70th Acc: 0.8421, Bottom 30th Acc: 0.5625
Fold [5/5] Epoch [20/100] Initial Loss: 0.1398, Training Loss: 0.0060, Initial Validation Loss: 0.1290, Validation Loss: 0.0257,V Acc: 0.8704, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.6875
Fold [5/5] Epoch [30/100] Initial Loss: 0.1398, Training Loss: 0.0042, Initial Validation Loss: 0.1290, Validation Loss: 0.0227,V Acc: 0.8796, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.6875
Stopping early at Epoch (base 0): 35  Rolling back to Epoch (base 0): 30  Top Validation Acc: 0.9473684210526315
Running train_nn.py with seed 7
CUDA:False
Training samples count:  550
Training on 163 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1418, Training Loss: 0.1418, Initial Validation Loss: 0.1352, Validation Loss: 0.1352,V Acc: 0.2523, Top 70th Acc: 0.2949, Bottom 30th Acc: 0.1515
Fold [1/5] Epoch [10/100] Initial Loss: 0.1418, Training Loss: 0.0143, Initial Validation Loss: 0.1352, Validation Loss: 0.0269,V Acc: 0.8649, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.6364
Fold [1/5] Epoch [20/100] Initial Loss: 0.1418, Training Loss: 0.0048, Initial Validation Loss: 0.1352, Validation Loss: 0.0225,V Acc: 0.8829, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 27  Rolling back to Epoch (base 0): 22  Top Validation Acc: 0.9743589743589743
Fold [2/5] Epoch [0/100] Initial Loss: 0.1371, Training Loss: 0.1371, Initial Validation Loss: 0.1360, Validation Loss: 0.1360,V Acc: 0.3243, Top 70th Acc: 0.4103, Bottom 30th Acc: 0.1212
Fold [2/5] Epoch [10/100] Initial Loss: 0.1371, Training Loss: 0.0224, Initial Validation Loss: 0.1360, Validation Loss: 0.0389,V Acc: 0.8378, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.6667
Fold [2/5] Epoch [20/100] Initial Loss: 0.1371, Training Loss: 0.0053, Initial Validation Loss: 0.1360, Validation Loss: 0.0271,V Acc: 0.8739, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 29  Rolling back to Epoch (base 0): 24  Top Validation Acc: 0.9615384615384616
Fold [3/5] Epoch [0/100] Initial Loss: 0.1399, Training Loss: 0.1399, Initial Validation Loss: 0.1324, Validation Loss: 0.1324,V Acc: 0.2545, Top 70th Acc: 0.3117, Bottom 30th Acc: 0.1212
Fold [3/5] Epoch [10/100] Initial Loss: 0.1399, Training Loss: 0.0258, Initial Validation Loss: 0.1324, Validation Loss: 0.0439,V Acc: 0.7909, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.5152
Fold [3/5] Epoch [20/100] Initial Loss: 0.1399, Training Loss: 0.0048, Initial Validation Loss: 0.1324, Validation Loss: 0.0382,V Acc: 0.7818, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.4545
Stopping early at Epoch (base 0): 21  Rolling back to Epoch (base 0): 16  Top Validation Acc: 0.922077922077922
7 2 [array([0.24136825, 0.04098902, 0.16078588, 0.27396393, 0.28289297],
      dtype=float32)]
Fold [4/5] Epoch [0/100] Initial Loss: 0.1369, Training Loss: 0.1369, Initial Validation Loss: 0.1343, Validation Loss: 0.1343,V Acc: 0.3273, Top 70th Acc: 0.3896, Bottom 30th Acc: 0.1818
Fold [4/5] Epoch [10/100] Initial Loss: 0.1369, Training Loss: 0.0214, Initial Validation Loss: 0.1343, Validation Loss: 0.0460,V Acc: 0.7636, Top 70th Acc: 0.8961, Bottom 30th Acc: 0.4545
Fold [4/5] Epoch [20/100] Initial Loss: 0.1369, Training Loss: 0.0051, Initial Validation Loss: 0.1343, Validation Loss: 0.0367,V Acc: 0.8364, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.6061
Fold [4/5] Epoch [30/100] Initial Loss: 0.1369, Training Loss: 0.0038, Initial Validation Loss: 0.1343, Validation Loss: 0.0355,V Acc: 0.8273, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.5758
Fold [4/5] Epoch [40/100] Initial Loss: 0.1369, Training Loss: 0.0035, Initial Validation Loss: 0.1343, Validation Loss: 0.0346,V Acc: 0.8182, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.4848
Stopping early at Epoch (base 0): 41  Rolling back to Epoch (base 0): 36  Top Validation Acc: 0.948051948051948
Fold [5/5] Epoch [0/100] Initial Loss: 0.1402, Training Loss: 0.1402, Initial Validation Loss: 0.1355, Validation Loss: 0.1355,V Acc: 0.3333, Top 70th Acc: 0.4079, Bottom 30th Acc: 0.1562
Fold [5/5] Epoch [10/100] Initial Loss: 0.1402, Training Loss: 0.0150, Initial Validation Loss: 0.1355, Validation Loss: 0.0252,V Acc: 0.9167, Top 70th Acc: 1.0000, Bottom 30th Acc: 0.7188
Fold [5/5] Epoch [20/100] Initial Loss: 0.1402, Training Loss: 0.0050, Initial Validation Loss: 0.1355, Validation Loss: 0.0197,V Acc: 0.9444, Top 70th Acc: 1.0000, Bottom 30th Acc: 0.8125
Fold [5/5] Epoch [30/100] Initial Loss: 0.1402, Training Loss: 0.0039, Initial Validation Loss: 0.1355, Validation Loss: 0.0190,V Acc: 0.9167, Top 70th Acc: 1.0000, Bottom 30th Acc: 0.7188
Stopping early at Epoch (base 0): 37  Rolling back to Epoch (base 0): 32  Top Validation Acc: 1.0
Running train_nn.py with seed 8
CUDA:False
Training samples count:  550
Training on 163 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1423, Training Loss: 0.1423, Initial Validation Loss: 0.1336, Validation Loss: 0.1336,V Acc: 0.2523, Top 70th Acc: 0.3590, Bottom 30th Acc: 0.0000
Fold [1/5] Epoch [10/100] Initial Loss: 0.1423, Training Loss: 0.0181, Initial Validation Loss: 0.1336, Validation Loss: 0.0402,V Acc: 0.7748, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.4545
Fold [1/5] Epoch [20/100] Initial Loss: 0.1423, Training Loss: 0.0053, Initial Validation Loss: 0.1336, Validation Loss: 0.0316,V Acc: 0.8468, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.5758
Fold [1/5] Epoch [30/100] Initial Loss: 0.1423, Training Loss: 0.0039, Initial Validation Loss: 0.1336, Validation Loss: 0.0296,V Acc: 0.8378, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 33  Rolling back to Epoch (base 0): 28  Top Validation Acc: 0.9615384615384616
Fold [2/5] Epoch [0/100] Initial Loss: 0.1373, Training Loss: 0.1373, Initial Validation Loss: 0.1372, Validation Loss: 0.1372,V Acc: 0.2793, Top 70th Acc: 0.3205, Bottom 30th Acc: 0.1818
Fold [2/5] Epoch [10/100] Initial Loss: 0.1373, Training Loss: 0.0230, Initial Validation Loss: 0.1372, Validation Loss: 0.0411,V Acc: 0.8468, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.6364
Fold [2/5] Epoch [20/100] Initial Loss: 0.1373, Training Loss: 0.0064, Initial Validation Loss: 0.1372, Validation Loss: 0.0322,V Acc: 0.8649, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 20  Rolling back to Epoch (base 0): 15  Top Validation Acc: 0.9615384615384616
8 1 [array([0.28396773, 0.05444084, 0.08232013, 0.19617735, 0.3830939 ],
      dtype=float32)]
Fold [3/5] Epoch [0/100] Initial Loss: 0.1379, Training Loss: 0.1379, Initial Validation Loss: 0.1287, Validation Loss: 0.1287,V Acc: 0.4182, Top 70th Acc: 0.5065, Bottom 30th Acc: 0.2121
Fold [3/5] Epoch [10/100] Initial Loss: 0.1379, Training Loss: 0.0128, Initial Validation Loss: 0.1287, Validation Loss: 0.0287,V Acc: 0.8455, Top 70th Acc: 1.0000, Bottom 30th Acc: 0.4848
Fold [3/5] Epoch [20/100] Initial Loss: 0.1379, Training Loss: 0.0047, Initial Validation Loss: 0.1287, Validation Loss: 0.0266,V Acc: 0.8818, Top 70th Acc: 1.0000, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 20  Rolling back to Epoch (base 0): 15  Top Validation Acc: 1.0
Fold [4/5] Epoch [0/100] Initial Loss: 0.1368, Training Loss: 0.1368, Initial Validation Loss: 0.1355, Validation Loss: 0.1355,V Acc: 0.4182, Top 70th Acc: 0.4545, Bottom 30th Acc: 0.3333
Fold [4/5] Epoch [10/100] Initial Loss: 0.1368, Training Loss: 0.0183, Initial Validation Loss: 0.1355, Validation Loss: 0.0410,V Acc: 0.8273, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.6364
Fold [4/5] Epoch [20/100] Initial Loss: 0.1368, Training Loss: 0.0050, Initial Validation Loss: 0.1355, Validation Loss: 0.0334,V Acc: 0.8455, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 27  Rolling back to Epoch (base 0): 22  Top Validation Acc: 0.935064935064935
Fold [5/5] Epoch [0/100] Initial Loss: 0.1388, Training Loss: 0.1388, Initial Validation Loss: 0.1309, Validation Loss: 0.1309,V Acc: 0.2500, Top 70th Acc: 0.3289, Bottom 30th Acc: 0.0625
Fold [5/5] Epoch [10/100] Initial Loss: 0.1388, Training Loss: 0.0195, Initial Validation Loss: 0.1309, Validation Loss: 0.0421,V Acc: 0.7870, Top 70th Acc: 0.8947, Bottom 30th Acc: 0.5312/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)

Fold [3/5] Epoch [20/100] Initial Loss: 0.1349, Training Loss: 0.0192, Initial Validation Loss: 0.1304, Validation Loss: 0.0212,V Acc: 0.8818, Top 70th Acc: 1.0000, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 22  Rolling back to Epoch (base 0): 17  Top Validation Acc: 0.974025974025974
Fold [4/5] Epoch [0/100] Initial Loss: 0.1401, Training Loss: 0.1401, Initial Validation Loss: 0.1252, Validation Loss: 0.1252,V Acc: 0.4000, Top 70th Acc: 0.5455, Bottom 30th Acc: 0.0606
Fold [4/5] Epoch [10/100] Initial Loss: 0.1401, Training Loss: 0.0250, Initial Validation Loss: 0.1252, Validation Loss: 0.0372,V Acc: 0.8182, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.6061
Fold [4/5] Epoch [20/100] Initial Loss: 0.1401, Training Loss: 0.0168, Initial Validation Loss: 0.1252, Validation Loss: 0.0444,V Acc: 0.7818, Top 70th Acc: 0.8961, Bottom 30th Acc: 0.5152
Stopping early at Epoch (base 0): 20  Rolling back to Epoch (base 0): 15  Top Validation Acc: 0.8961038961038961
Fold [5/5] Epoch [0/100] Initial Loss: 0.1386, Training Loss: 0.1386, Initial Validation Loss: 0.1292, Validation Loss: 0.1292,V Acc: 0.3981, Top 70th Acc: 0.4211, Bottom 30th Acc: 0.3438
Fold [5/5] Epoch [10/100] Initial Loss: 0.1386, Training Loss: 0.0251, Initial Validation Loss: 0.1292, Validation Loss: 0.0261,V Acc: 0.8796, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.6875
Stopping early at Epoch (base 0): 15  Rolling back to Epoch (base 0): 10  Top Validation Acc: 0.9473684210526315
13 4 [array([0.564547  , 0.04550363, 0.04149511, 0.19100004, 0.15745424],
      dtype=float32)]
Running train_nn.py with seed 14
CUDA:False
Training samples count:  550
Training on 21 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1388, Training Loss: 0.1388, Initial Validation Loss: 0.1301, Validation Loss: 0.1301,V Acc: 0.4685, Top 70th Acc: 0.5385, Bottom 30th Acc: 0.3030
Fold [1/5] Epoch [10/100] Initial Loss: 0.1388, Training Loss: 0.0254, Initial Validation Loss: 0.1301, Validation Loss: 0.0282,V Acc: 0.8559, Top 70th Acc: 0.9872, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 18  Rolling back to Epoch (base 0): 13  Top Validation Acc: 0.9743589743589743
Fold [2/5] Epoch [0/100] Initial Loss: 0.1324, Training Loss: 0.1324, Initial Validation Loss: 0.1218, Validation Loss: 0.1218,V Acc: 0.3784, Top 70th Acc: 0.5000, Bottom 30th Acc: 0.0909
Fold [2/5] Epoch [10/100] Initial Loss: 0.1324, Training Loss: 0.0233, Initial Validation Loss: 0.1218, Validation Loss: 0.0382,V Acc: 0.8018, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.5455
Fold [2/5] Epoch [20/100] Initial Loss: 0.1324, Training Loss: 0.0161, Initial Validation Loss: 0.1218, Validation Loss: 0.0247,V Acc: 0.8829, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 21  Rolling back to Epoch (base 0): 16  Top Validation Acc: 0.9487179487179487
Fold [3/5] Epoch [0/100] Initial Loss: 0.1323, Training Loss: 0.1323, Initial Validation Loss: 0.1148, Validation Loss: 0.1148,V Acc: 0.5273, Top 70th Acc: 0.6234, Bottom 30th Acc: 0.3030
Fold [3/5] Epoch [10/100] Initial Loss: 0.1323, Training Loss: 0.0223, Initial Validation Loss: 0.1148, Validation Loss: 0.0278,V Acc: 0.8727, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.7273
Fold [3/5] Epoch [20/100] Initial Loss: 0.1323, Training Loss: 0.0160, Initial Validation Loss: 0.1148, Validation Loss: 0.0231,V Acc: 0.8909, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 20  Rolling back to Epoch (base 0): 15  Top Validation Acc: 0.974025974025974
Fold [4/5] Epoch [0/100] Initial Loss: 0.1309, Training Loss: 0.1309, Initial Validation Loss: 0.1101, Validation Loss: 0.1101,V Acc: 0.5182, Top 70th Acc: 0.5844, Bottom 30th Acc: 0.3636
Fold [4/5] Epoch [10/100] Initial Loss: 0.1309, Training Loss: 0.0219, Initial Validation Loss: 0.1101, Validation Loss: 0.0322,V Acc: 0.8545, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 19  Rolling back to Epoch (base 0): 14  Top Validation Acc: 0.948051948051948
Fold [5/5] Epoch [0/100] Initial Loss: 0.1339, Training Loss: 0.1339, Initial Validation Loss: 0.1265, Validation Loss: 0.1265,V Acc: 0.4259, Top 70th Acc: 0.5000, Bottom 30th Acc: 0.2500
Fold [5/5] Epoch [10/100] Initial Loss: 0.1339, Training Loss: 0.0220, Initial Validation Loss: 0.1265, Validation Loss: 0.0265,V Acc: 0.9074, Top 70th Acc: 0.9737, Bottom 30th Acc: 0.7500
Fold [5/5] Epoch [20/100] Initial Loss: 0.1339, Training Loss: 0.0162, Initial Validation Loss: 0.1265, Validation Loss: 0.0213,V Acc: 0.9074, Top 70th Acc: 0.9737, Bottom 30th Acc: 0.7500
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.9736842105263158
14 4 [array([0.7423753 , 0.00886461, 0.01573075, 0.077149  , 0.15588026],
      dtype=float32)]
Running train_nn.py with seed 15
CUDA:False
Training samples count:  550
Training on 21 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1359, Training Loss: 0.1359, Initial Validation Loss: 0.1292, Validation Loss: 0.1292,V Acc: 0.3964, Top 70th Acc: 0.4872, Bottom 30th Acc: 0.1818
Fold [1/5] Epoch [10/100] Initial Loss: 0.1359, Training Loss: 0.0232, Initial Validation Loss: 0.1292, Validation Loss: 0.0337,V Acc: 0.8468, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 17  Rolling back to Epoch (base 0): 12  Top Validation Acc: 0.9230769230769231
Fold [2/5] Epoch [0/100] Initial Loss: 0.1343, Training Loss: 0.1343, Initial Validation Loss: 0.1251, Validation Loss: 0.1251,V Acc: 0.4685, Top 70th Acc: 0.5385, Bottom 30th Acc: 0.3030
Fold [2/5] Epoch [10/100] Initial Loss: 0.1343, Training Loss: 0.0276, Initial Validation Loss: 0.1251, Validation Loss: 0.0250,V Acc: 0.8559, Top 70th Acc: 0.9872, Bottom 30th Acc: 0.5455
Fold [2/5] Epoch [20/100] Initial Loss: 0.1343, Training Loss: 0.0215, Initial Validation Loss: 0.1251, Validation Loss: 0.0200,V Acc: 0.8829, Top 70th Acc: 0.9872, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 21  Rolling back to Epoch (base 0): 16  Top Validation Acc: 0.9487179487179487
Fold [3/5] Epoch [0/100] Initial Loss: 0.1372, Training Loss: 0.1372, Initial Validation Loss: 0.1234, Validation Loss: 0.1234,V Acc: 0.3909, Top 70th Acc: 0.4545, Bottom 30th Acc: 0.2424
Fold [3/5] Epoch [10/100] Initial Loss: 0.1372, Training Loss: 0.0293, Initial Validation Loss: 0.1234, Validation Loss: 0.0329,V Acc: 0.8727, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.7576
Fold [3/5] Epoch [20/100] Initial Loss: 0.1372, Training Loss: 0.0181, Initial Validation Loss: 0.1234, Validation Loss: 0.0255,V Acc: 0.8727, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.961038961038961
Fold [4/5] Epoch [0/100] Initial Loss: 0.1276, Training Loss: 0.1276, Initial Validation Loss: 0.1097, Validation Loss: 0.1097,V Acc: 0.5545, Top 70th Acc: 0.6623, Bottom 30th Acc: 0.3030
Fold [4/5] Epoch [10/100] Initial Loss: 0.1276, Training Loss: 0.0252, Initial Validation Loss: 0.1097, Validation Loss: 0.0306,V Acc: 0.8818, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.6970
Fold [4/5] Epoch [20/100] Initial Loss: 0.1276, Training Loss: 0.0171, Initial Validation Loss: 0.1097, Validation Loss: 0.0291,V Acc: 0.8818, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 29  Rolling back to Epoch (base 0): 24  Top Validation Acc: 1.0
15 3 [array([0.79659075, 0.02248433, 0.04286485, 0.05720237, 0.08085778],
      dtype=float32)]
Fold [5/5] Epoch [0/100] Initial Loss: 0.1295, Training Loss: 0.1295, Initial Validation Loss: 0.1127, Validation Loss: 0.1127,V Acc: 0.5278, Top 70th Acc: 0.5921, Bottom 30th Acc: 0.3750
Fold [5/5] Epoch [10/100] Initial Loss: 0.1295, Training Loss: 0.0234, Initial Validation Loss: 0.1127, Validation Loss: 0.0370,V Acc: 0.8333, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.5938
Stopping early at Epoch (base 0): 17  Rolling back to Epoch (base 0): 12  Top Validation Acc: 0.9473684210526315
Running train_nn.py with seed 16
CUDA:False
Training samples count:  550
Training on 21 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1370, Training Loss: 0.1370, Initial Validation Loss: 0.1261, Validation Loss: 0.1261,V Acc: 0.4414, Top 70th Acc: 0.5513, Bottom 30th Acc: 0.1818 0.9210526315789473
Running train_nn.py with seed 9
CUDA:False
Training samples count:  550
Training on 20 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1385, Training Loss: 0.1385, Initial Validation Loss: 0.1343, Validation Loss: 0.1343,V Acc: 0.3423, Top 70th Acc: 0.3974, Bottom 30th Acc: 0.2121
Fold [1/5] Epoch [10/100] Initial Loss: 0.1385, Training Loss: 0.0409, Initial Validation Loss: 0.1343, Validation Loss: 0.0472,V Acc: 0.8108, Top 70th Acc: 0.8846, Bottom 30th Acc: 0.6364
Fold [1/5] Epoch [20/100] Initial Loss: 0.1385, Training Loss: 0.0242, Initial Validation Loss: 0.1343, Validation Loss: 0.0374,V Acc: 0.8378, Top 70th Acc: 0.8974, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.8846153846153846
9 0 [array([0.2394258 , 0.10909121, 0.23955515, 0.18539974, 0.22652815],
      dtype=float32)]
Fold [2/5] Epoch [0/100] Initial Loss: 0.1395, Training Loss: 0.1395, Initial Validation Loss: 0.1358, Validation Loss: 0.1358,V Acc: 0.2703, Top 70th Acc: 0.2564, Bottom 30th Acc: 0.3030
Fold [2/5] Epoch [10/100] Initial Loss: 0.1395, Training Loss: 0.0447, Initial Validation Loss: 0.1358, Validation Loss: 0.0545,V Acc: 0.7477, Top 70th Acc: 0.8462, Bottom 30th Acc: 0.5152
Fold [2/5] Epoch [20/100] Initial Loss: 0.1395, Training Loss: 0.0264, Initial Validation Loss: 0.1358, Validation Loss: 0.0411,V Acc: 0.7748, Top 70th Acc: 0.8974, Bottom 30th Acc: 0.4848
Fold [2/5] Epoch [30/100] Initial Loss: 0.1395, Training Loss: 0.0217, Initial Validation Loss: 0.1358, Validation Loss: 0.0371,V Acc: 0.7748, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.3636
Stopping early at Epoch (base 0): 32  Rolling back to Epoch (base 0): 27  Top Validation Acc: 0.9358974358974359
Fold [3/5] Epoch [0/100] Initial Loss: 0.1365, Training Loss: 0.1365, Initial Validation Loss: 0.1296, Validation Loss: 0.1296,V Acc: 0.2909, Top 70th Acc: 0.3636, Bottom 30th Acc: 0.1212
Fold [3/5] Epoch [10/100] Initial Loss: 0.1365, Training Loss: 0.0291, Initial Validation Loss: 0.1296, Validation Loss: 0.0406,V Acc: 0.7909, Top 70th Acc: 0.8961, Bottom 30th Acc: 0.5455
Fold [3/5] Epoch [20/100] Initial Loss: 0.1365, Training Loss: 0.0212, Initial Validation Loss: 0.1296, Validation Loss: 0.0428,V Acc: 0.7818, Top 70th Acc: 0.8701, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 21  Rolling back to Epoch (base 0): 16  Top Validation Acc: 0.8961038961038961
Fold [4/5] Epoch [0/100] Initial Loss: 0.1408, Training Loss: 0.1408, Initial Validation Loss: 0.1355, Validation Loss: 0.1355,V Acc: 0.3545, Top 70th Acc: 0.4156, Bottom 30th Acc: 0.2121
Fold [4/5] Epoch [10/100] Initial Loss: 0.1408, Training Loss: 0.0331, Initial Validation Loss: 0.1355, Validation Loss: 0.0369,V Acc: 0.8182, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 19  Rolling back to Epoch (base 0): 14  Top Validation Acc: 0.922077922077922
Fold [5/5] Epoch [0/100] Initial Loss: 0.1411, Training Loss: 0.1411, Initial Validation Loss: 0.1333, Validation Loss: 0.1333,V Acc: 0.2500, Top 70th Acc: 0.2895, Bottom 30th Acc: 0.1562
Fold [5/5] Epoch [10/100] Initial Loss: 0.1411, Training Loss: 0.0334, Initial Validation Loss: 0.1333, Validation Loss: 0.0347,V Acc: 0.8519, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.6250
Fold [5/5] Epoch [20/100] Initial Loss: 0.1411, Training Loss: 0.0247, Initial Validation Loss: 0.1333, Validation Loss: 0.0284,V Acc: 0.8519, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.5938
Stopping early at Epoch (base 0): 29  Rolling back to Epoch (base 0): 24  Top Validation Acc: 0.9736842105263158
Running train_nn.py with seed 10
CUDA:False
Training samples count:  550
Training on 20 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1407, Training Loss: 0.1407, Initial Validation Loss: 0.1342, Validation Loss: 0.1342,V Acc: 0.3063, Top 70th Acc: 0.3718, Bottom 30th Acc: 0.1515
Fold [1/5] Epoch [10/100] Initial Loss: 0.1407, Training Loss: 0.0362, Initial Validation Loss: 0.1342, Validation Loss: 0.0471,V Acc: 0.8559, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.6970
Fold [1/5] Epoch [20/100] Initial Loss: 0.1407, Training Loss: 0.0230, Initial Validation Loss: 0.1342, Validation Loss: 0.0369,V Acc: 0.8649, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.6970
Fold [1/5] Epoch [30/100] Initial Loss: 0.1407, Training Loss: 0.0203, Initial Validation Loss: 0.1342, Validation Loss: 0.0350,V Acc: 0.8468, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 32  Rolling back to Epoch (base 0): 27  Top Validation Acc: 0.9487179487179487
10 0 [array([0.44259185, 0.10098151, 0.15656121, 0.13926074, 0.16060467],
      dtype=float32)]
Fold [2/5] Epoch [0/100] Initial Loss: 0.1393, Training Loss: 0.1393, Initial Validation Loss: 0.1317, Validation Loss: 0.1317,V Acc: 0.2883, Top 70th Acc: 0.3077, Bottom 30th Acc: 0.2424
Fold [2/5] Epoch [10/100] Initial Loss: 0.1393, Training Loss: 0.0383, Initial Validation Loss: 0.1317, Validation Loss: 0.0480,V Acc: 0.7297, Top 70th Acc: 0.8590, Bottom 30th Acc: 0.4242
Fold [2/5] Epoch [20/100] Initial Loss: 0.1393, Training Loss: 0.0255, Initial Validation Loss: 0.1317, Validation Loss: 0.0358,V Acc: 0.7838, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.4848
Fold [2/5] Epoch [30/100] Initial Loss: 0.1393, Training Loss: 0.0220, Initial Validation Loss: 0.1317, Validation Loss: 0.0348,V Acc: 0.7838, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.4545
Stopping early at Epoch (base 0): 37  Rolling back to Epoch (base 0): 32  Top Validation Acc: 0.9102564102564102
Fold [3/5] Epoch [0/100] Initial Loss: 0.1382, Training Loss: 0.1382, Initial Validation Loss: 0.1370, Validation Loss: 0.1370,V Acc: 0.2364, Top 70th Acc: 0.2987, Bottom 30th Acc: 0.0909
Fold [3/5] Epoch [10/100] Initial Loss: 0.1382, Training Loss: 0.0351, Initial Validation Loss: 0.1370, Validation Loss: 0.0335,V Acc: 0.8636, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6667
Fold [3/5] Epoch [20/100] Initial Loss: 0.1382, Training Loss: 0.0227, Initial Validation Loss: 0.1370, Validation Loss: 0.0265,V Acc: 0.8636, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.6364
Fold [3/5] Epoch [30/100] Initial Loss: 0.1382, Training Loss: 0.0211, Initial Validation Loss: 0.1370, Validation Loss: 0.0251,V Acc: 0.8909, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 35  Rolling back to Epoch (base 0): 30  Top Validation Acc: 0.974025974025974
Fold [4/5] Epoch [0/100] Initial Loss: 0.1370, Training Loss: 0.1370, Initial Validation Loss: 0.1320, Validation Loss: 0.1320,V Acc: 0.4000, Top 70th Acc: 0.4545, Bottom 30th Acc: 0.2727
Fold [4/5] Epoch [10/100] Initial Loss: 0.1370, Training Loss: 0.0304, Initial Validation Loss: 0.1320, Validation Loss: 0.0399,V Acc: 0.8091, Top 70th Acc: 0.8831, Bottom 30th Acc: 0.6364
Fold [4/5] Epoch [20/100] Initial Loss: 0.1370, Training Loss: 0.0210, Initial Validation Loss: 0.1320, Validation Loss: 0.0363,V Acc: 0.8455, Top 70th Acc: 0.8831, Bottom 30th Acc: 0.7576
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.8961038961038961
Fold [5/5] Epoch [0/100] Initial Loss: 0.1387, Training Loss: 0.1387, Initial Validation Loss: 0.1361, Validation Loss: 0.1361,V Acc: 0.3519, Top 70th Acc: 0.3684, Bottom 30th Acc: 0.3125
Fold [5/5] Epoch [10/100] Initial Loss: 0.1387, Training Loss: 0.0333, Initial Validation Loss: 0.1361, Validation Loss: 0.0361,V Acc: 0.8704, Top 70th Acc: 0.9079, Bottom 30th Acc: 0.7812
Fold [5/5] Epoch [20/100] Initial Loss: 0.1387, Training Loss: 0.0217, Initial Validation Loss: 0.1361, Validation Loss: 0.0295,V Acc: 0.8611, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.6875
Fold [5/5] Epoch [30/100] Initial Loss: 0.1387, Training Loss: 0.0196, Initial Validation Loss: 0.1361, Validation Loss: 0.0281,V Acc: 0.8611, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.6875
Stopping early at Epoch (base 0): 31  Rolling back to Epoch (base 0): 26  Top Validation Acc: 0.9342105263157895
Running train_nn.py with seed 11
CUDA:False
Training samples count:  550
Training on 20 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1382, Training Loss: 0.1382, Initial Validation Loss: 0.1362, Validation Loss: 0.1362,V Acc: 0.3243, Top 70th Acc: 0.3462, Bottom 30th Acc: 0.2727
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.7402597402597403
Fold [5/5] Epoch [0/100] Initial Loss: 0.1373, Training Loss: 0.1373, Initial Validation Loss: 0.1226, Validation Loss: 0.1226,V Acc: 0.3981, Top 70th Acc: 0.4868, Bottom 30th Acc: 0.1875
Fold [5/5] Epoch [10/100] Initial Loss: 0.1373, Training Loss: 0.0825, Initial Validation Loss: 0.1226, Validation Loss: 0.0768,V Acc: 0.6296, Top 70th Acc: 0.7237, Bottom 30th Acc: 0.4062
Fold [5/5] Epoch [20/100] Initial Loss: 0.1373, Training Loss: 0.0800, Initial Validation Loss: 0.1226, Validation Loss: 0.0742,V Acc: 0.6296, Top 70th Acc: 0.7500, Bottom 30th Acc: 0.3438
Fold [5/5] Epoch [30/100] Initial Loss: 0.1373, Training Loss: 0.0789, Initial Validation Loss: 0.1226, Validation Loss: 0.0734,V Acc: 0.6296, Top 70th Acc: 0.7368, Bottom 30th Acc: 0.3750
Stopping early at Epoch (base 0): 34  Rolling back to Epoch (base 0): 29  Top Validation Acc: 0.7368421052631579
Running train_nn.py with seed 9
CUDA:False
Training samples count:  550
Training on 2 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1350, Training Loss: 0.1350, Initial Validation Loss: 0.1286, Validation Loss: 0.1286,V Acc: 0.4054, Top 70th Acc: 0.4487, Bottom 30th Acc: 0.3030
Fold [1/5] Epoch [10/100] Initial Loss: 0.1350, Training Loss: 0.0798, Initial Validation Loss: 0.1286, Validation Loss: 0.0847,V Acc: 0.5766, Top 70th Acc: 0.6923, Bottom 30th Acc: 0.3030
Fold [1/5] Epoch [20/100] Initial Loss: 0.1350, Training Loss: 0.0775, Initial Validation Loss: 0.1286, Validation Loss: 0.0825,V Acc: 0.6036, Top 70th Acc: 0.6923, Bottom 30th Acc: 0.3939
Stopping early at Epoch (base 0): 29  Rolling back to Epoch (base 0): 24  Top Validation Acc: 0.6923076923076923
9 0 [array([0.14646241, 0.35089546, 0.14502124, 0.23090778, 0.12671308],
      dtype=float32)]
Fold [2/5] Epoch [0/100] Initial Loss: 0.1375, Training Loss: 0.1375, Initial Validation Loss: 0.1303, Validation Loss: 0.1303,V Acc: 0.4955, Top 70th Acc: 0.4872, Bottom 30th Acc: 0.5152
Fold [2/5] Epoch [10/100] Initial Loss: 0.1375, Training Loss: 0.0803, Initial Validation Loss: 0.1303, Validation Loss: 0.0850,V Acc: 0.5946, Top 70th Acc: 0.7051, Bottom 30th Acc: 0.3333
Stopping early at Epoch (base 0): 18  Rolling back to Epoch (base 0): 13  Top Validation Acc: 0.7435897435897436
Fold [3/5] Epoch [0/100] Initial Loss: 0.1371, Training Loss: 0.1371, Initial Validation Loss: 0.1261, Validation Loss: 0.1261,V Acc: 0.2545, Top 70th Acc: 0.3636, Bottom 30th Acc: 0.0000
Fold [3/5] Epoch [10/100] Initial Loss: 0.1371, Training Loss: 0.0818, Initial Validation Loss: 0.1261, Validation Loss: 0.0795,V Acc: 0.6273, Top 70th Acc: 0.7143, Bottom 30th Acc: 0.4242
Fold [3/5] Epoch [20/100] Initial Loss: 0.1371, Training Loss: 0.0797, Initial Validation Loss: 0.1261, Validation Loss: 0.0765,V Acc: 0.6364, Top 70th Acc: 0.7403, Bottom 30th Acc: 0.3939
Fold [3/5] Epoch [30/100] Initial Loss: 0.1371, Training Loss: 0.0791, Initial Validation Loss: 0.1261, Validation Loss: 0.0750,V Acc: 0.6364, Top 70th Acc: 0.7143, Bottom 30th Acc: 0.4545
Fold [3/5] Epoch [40/100] Initial Loss: 0.1371, Training Loss: 0.0784, Initial Validation Loss: 0.1261, Validation Loss: 0.0748,V Acc: 0.6273, Top 70th Acc: 0.7273, Bottom 30th Acc: 0.3939
Fold [3/5] Epoch [50/100] Initial Loss: 0.1371, Training Loss: 0.0778, Initial Validation Loss: 0.1261, Validation Loss: 0.0753,V Acc: 0.6364, Top 70th Acc: 0.7403, Bottom 30th Acc: 0.3939
Fold [3/5] Epoch [60/100] Initial Loss: 0.1371, Training Loss: 0.0777, Initial Validation Loss: 0.1261, Validation Loss: 0.0736,V Acc: 0.6364, Top 70th Acc: 0.7273, Bottom 30th Acc: 0.4242
Stopping early at Epoch (base 0): 67  Rolling back to Epoch (base 0): 62  Top Validation Acc: 0.7272727272727273
Fold [4/5] Epoch [0/100] Initial Loss: 0.1305, Training Loss: 0.1305, Initial Validation Loss: 0.1213, Validation Loss: 0.1213,V Acc: 0.4545, Top 70th Acc: 0.5455, Bottom 30th Acc: 0.2424
Fold [4/5] Epoch [10/100] Initial Loss: 0.1305, Training Loss: 0.0808, Initial Validation Loss: 0.1213, Validation Loss: 0.0786,V Acc: 0.6273, Top 70th Acc: 0.7403, Bottom 30th Acc: 0.3636
Fold [4/5] Epoch [20/100] Initial Loss: 0.1305, Training Loss: 0.0791, Initial Validation Loss: 0.1213, Validation Loss: 0.0766,V Acc: 0.6364, Top 70th Acc: 0.7532, Bottom 30th Acc: 0.3636
Fold [4/5] Epoch [30/100] Initial Loss: 0.1305, Training Loss: 0.0779, Initial Validation Loss: 0.1213, Validation Loss: 0.0758,V Acc: 0.6727, Top 70th Acc: 0.7662, Bottom 30th Acc: 0.4545
Stopping early at Epoch (base 0): 34  Rolling back to Epoch (base 0): 29  Top Validation Acc: 0.7532467532467533
Fold [5/5] Epoch [0/100] Initial Loss: 0.1352, Training Loss: 0.1352, Initial Validation Loss: 0.1225, Validation Loss: 0.1225,V Acc: 0.3611, Top 70th Acc: 0.4211, Bottom 30th Acc: 0.2188
Fold [5/5] Epoch [10/100] Initial Loss: 0.1352, Training Loss: 0.0814, Initial Validation Loss: 0.1225, Validation Loss: 0.0772,V Acc: 0.6481, Top 70th Acc: 0.7632, Bottom 30th Acc: 0.3750
Fold [5/5] Epoch [20/100] Initial Loss: 0.1352, Training Loss: 0.0791, Initial Validation Loss: 0.1225, Validation Loss: 0.0749,V Acc: 0.6481, Top 70th Acc: 0.7895, Bottom 30th Acc: 0.3125
Fold [5/5] Epoch [30/100] Initial Loss: 0.1352, Training Loss: 0.0785, Initial Validation Loss: 0.1225, Validation Loss: 0.0748,V Acc: 0.6574, Top 70th Acc: 0.7632, Bottom 30th Acc: 0.4062
Stopping early at Epoch (base 0): 34  Rolling back to Epoch (base 0): 29  Top Validation Acc: 0.7894736842105263
Running train_nn.py with seed 10
CUDA:False
Training samples count:  550
Training on 2 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1366, Training Loss: 0.1366, Initial Validation Loss: 0.1311, Validation Loss: 0.1311,V Acc: 0.3964, Top 70th Acc: 0.4103, Bottom 30th Acc: 0.3636
Fold [1/5] Epoch [10/100] Initial Loss: 0.1366, Training Loss: 0.0791, Initial Validation Loss: 0.1311, Validation Loss: 0.0891,V Acc: 0.5856, Top 70th Acc: 0.7179, Bottom 30th Acc: 0.2727
Fold [1/5] Epoch [20/100] Initial Loss: 0.1366, Training Loss: 0.0771, Initial Validation Loss: 0.1311, Validation Loss: 0.0874,V Acc: 0.6036, Top 70th Acc: 0.7179, Bottom 30th Acc: 0.3333
Fold [1/5] Epoch [30/100] Initial Loss: 0.1366, Training Loss: 0.0764, Initial Validation Loss: 0.1311, Validation Loss: 0.0869,V Acc: 0.5856, Top 70th Acc: 0.7179, Bottom 30th Acc: 0.2727
Fold [1/5] Epoch [40/100] Initial Loss: 0.1366, Training Loss: 0.0761, Initial Validation Loss: 0.1311, Validation Loss: 0.0867,V Acc: 0.6036, Top 70th Acc: 0.7308, Bottom 30th Acc: 0.3030
Stopping early at Epoch (base 0): 41  Rolling back to Epoch (base 0): 36  Top Validation Acc: 0.717948717948718
10 0 [array([0.13294134, 0.30844828, 0.14986807, 0.24331114, 0.16543117],
      dtype=float32)]
Fold [2/5] Epoch [0/100] Initial Loss: 0.1354, Training Loss: 0.1354, Initial Validation Loss: 0.1244, Validation Loss: 0.1244,V Acc: 0.5766, Top 70th Acc: 0.6410, Bottom 30th Acc: 0.4242
Fold [2/5] Epoch [10/100] Initial Loss: 0.1354, Training Loss: 0.0824, Initial Validation Loss: 0.1244, Validation Loss: 0.0743,V Acc: 0.6757, Top 70th Acc: 0.7051, Bottom 30th Acc: 0.6061
Fold [2/5] Epoch [20/100] Initial Loss: 0.1354, Training Loss: 0.0808, Initial Validation Loss: 0.1244, Validation Loss: 0.0725,V Acc: 0.6937, Top 70th Acc: 0.7308, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 28  Rolling back to Epoch (base 0): 23  Top Validation Acc: 0.7051282051282052
Fold [3/5] Epoch [0/100] Initial Loss: 0.1343, Training Loss: 0.1343, Initial Validation Loss: 0.1246, Validation Loss: 0.1246,V Acc: 0.5364, Top 70th Acc: 0.6364, Bottom 30th Acc: 0.3030
Fold [3/5] Epoch [10/100] Initial Loss: 0.1343, Training Loss: 0.0812, Initial Validation Loss: 0.1246, Validation Loss: 0.0780,V Acc: 0.6273, Top 70th Acc: 0.7532, Bottom 30th Acc: 0.3333
Fold [3/5] Epoch [20/100] Initial Loss: 0.1343, Training Loss: 0.0789, Initial Validation Loss: 0.1246, Validation Loss: 0.0768,V Acc: 0.6182, Top 70th Acc: 0.7532, Bottom 30th Acc: 0.3030
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.7662337662337663
Fold [4/5] Epoch [0/100] Initial Loss: 0.1316, Training Loss: 0.1316, Initial Validation Loss: 0.1192, Validation Loss: 0.1192,V Acc: 0.4727, Top 70th Acc: 0.5974, Bottom 30th Acc: 0.1818
Training on 2 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 91
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 2 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 92
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 2 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 93
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 2 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 94
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 2 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 95
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 2 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 96
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 2 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 97
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 2 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 98
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 2 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 99
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 2 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 100
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 2 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5

Fold [1/5] Epoch [20/100] Initial Loss: 0.1414, Training Loss: 0.0196, Initial Validation Loss: 0.1366, Validation Loss: 0.0332,V Acc: 0.8559, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 28  Rolling back to Epoch (base 0): 23  Top Validation Acc: 0.9358974358974359
9 0 [array([0.70449185, 0.04461597, 0.04692246, 0.07890625, 0.12506343],
      dtype=float32)]
Fold [2/5] Epoch [0/100] Initial Loss: 0.1407, Training Loss: 0.1407, Initial Validation Loss: 0.1334, Validation Loss: 0.1334,V Acc: 0.3063, Top 70th Acc: 0.3590, Bottom 30th Acc: 0.1818
Fold [2/5] Epoch [10/100] Initial Loss: 0.1407, Training Loss: 0.0271, Initial Validation Loss: 0.1334, Validation Loss: 0.0366,V Acc: 0.8108, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.5455
Fold [2/5] Epoch [20/100] Initial Loss: 0.1407, Training Loss: 0.0177, Initial Validation Loss: 0.1334, Validation Loss: 0.0330,V Acc: 0.7838, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.3939
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.9615384615384616
Fold [3/5] Epoch [0/100] Initial Loss: 0.1388, Training Loss: 0.1388, Initial Validation Loss: 0.1320, Validation Loss: 0.1320,V Acc: 0.3455, Top 70th Acc: 0.3896, Bottom 30th Acc: 0.2424
Fold [3/5] Epoch [10/100] Initial Loss: 0.1388, Training Loss: 0.0322, Initial Validation Loss: 0.1320, Validation Loss: 0.0416,V Acc: 0.8000, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.5152
Fold [3/5] Epoch [20/100] Initial Loss: 0.1388, Training Loss: 0.0167, Initial Validation Loss: 0.1320, Validation Loss: 0.0318,V Acc: 0.8273, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.5152
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.935064935064935
Fold [4/5] Epoch [0/100] Initial Loss: 0.1388, Training Loss: 0.1388, Initial Validation Loss: 0.1367, Validation Loss: 0.1367,V Acc: 0.2545, Top 70th Acc: 0.3117, Bottom 30th Acc: 0.1212
Fold [4/5] Epoch [10/100] Initial Loss: 0.1388, Training Loss: 0.0470, Initial Validation Loss: 0.1367, Validation Loss: 0.0495,V Acc: 0.7727, Top 70th Acc: 0.8571, Bottom 30th Acc: 0.5758
Fold [4/5] Epoch [20/100] Initial Loss: 0.1388, Training Loss: 0.0205, Initial Validation Loss: 0.1367, Validation Loss: 0.0288,V Acc: 0.8636, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6667
Fold [4/5] Epoch [30/100] Initial Loss: 0.1388, Training Loss: 0.0159, Initial Validation Loss: 0.1367, Validation Loss: 0.0283,V Acc: 0.8545, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 37  Rolling back to Epoch (base 0): 32  Top Validation Acc: 0.948051948051948
Fold [5/5] Epoch [0/100] Initial Loss: 0.1367, Training Loss: 0.1367, Initial Validation Loss: 0.1275, Validation Loss: 0.1275,V Acc: 0.3889, Top 70th Acc: 0.4342, Bottom 30th Acc: 0.2812
Fold [5/5] Epoch [10/100] Initial Loss: 0.1367, Training Loss: 0.0362, Initial Validation Loss: 0.1275, Validation Loss: 0.0450,V Acc: 0.7778, Top 70th Acc: 0.8684, Bottom 30th Acc: 0.5625
Fold [5/5] Epoch [20/100] Initial Loss: 0.1367, Training Loss: 0.0184, Initial Validation Loss: 0.1275, Validation Loss: 0.0331,V Acc: 0.8148, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.5000
Stopping early at Epoch (base 0): 29  Rolling back to Epoch (base 0): 24  Top Validation Acc: 0.9473684210526315
Running train_nn.py with seed 10
CUDA:False
Training samples count:  550
Training on 30 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1422, Training Loss: 0.1422, Initial Validation Loss: 0.1360, Validation Loss: 0.1360,V Acc: 0.3333, Top 70th Acc: 0.3846, Bottom 30th Acc: 0.2121
Fold [1/5] Epoch [10/100] Initial Loss: 0.1422, Training Loss: 0.0357, Initial Validation Loss: 0.1360, Validation Loss: 0.0457,V Acc: 0.8288, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.5758
Fold [1/5] Epoch [20/100] Initial Loss: 0.1422, Training Loss: 0.0165, Initial Validation Loss: 0.1360, Validation Loss: 0.0343,V Acc: 0.8468, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.5758
Fold [1/5] Epoch [30/100] Initial Loss: 0.1422, Training Loss: 0.0141, Initial Validation Loss: 0.1360, Validation Loss: 0.0346,V Acc: 0.8468, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 30  Rolling back to Epoch (base 0): 25  Top Validation Acc: 0.9358974358974359
10 0 [array([0.82607514, 0.04994642, 0.03540047, 0.04562962, 0.04294822],
      dtype=float32)]
Fold [2/5] Epoch [0/100] Initial Loss: 0.1388, Training Loss: 0.1388, Initial Validation Loss: 0.1301, Validation Loss: 0.1301,V Acc: 0.2793, Top 70th Acc: 0.3205, Bottom 30th Acc: 0.1818
Fold [2/5] Epoch [10/100] Initial Loss: 0.1388, Training Loss: 0.0353, Initial Validation Loss: 0.1301, Validation Loss: 0.0466,V Acc: 0.7477, Top 70th Acc: 0.8590, Bottom 30th Acc: 0.4848
Fold [2/5] Epoch [20/100] Initial Loss: 0.1388, Training Loss: 0.0196, Initial Validation Loss: 0.1301, Validation Loss: 0.0325,V Acc: 0.7748, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.3939
Fold [2/5] Epoch [30/100] Initial Loss: 0.1388, Training Loss: 0.0154, Initial Validation Loss: 0.1301, Validation Loss: 0.0304,V Acc: 0.7838, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.3939
Stopping early at Epoch (base 0): 30  Rolling back to Epoch (base 0): 25  Top Validation Acc: 0.9487179487179487
Fold [3/5] Epoch [0/100] Initial Loss: 0.1385, Training Loss: 0.1385, Initial Validation Loss: 0.1372, Validation Loss: 0.1372,V Acc: 0.2364, Top 70th Acc: 0.2078, Bottom 30th Acc: 0.3030
Fold [3/5] Epoch [10/100] Initial Loss: 0.1385, Training Loss: 0.0291, Initial Validation Loss: 0.1372, Validation Loss: 0.0308,V Acc: 0.8636, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.6364
Fold [3/5] Epoch [20/100] Initial Loss: 0.1385, Training Loss: 0.0182, Initial Validation Loss: 0.1372, Validation Loss: 0.0242,V Acc: 0.8909, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 28  Rolling back to Epoch (base 0): 23  Top Validation Acc: 1.0
Fold [4/5] Epoch [0/100] Initial Loss: 0.1380, Training Loss: 0.1380, Initial Validation Loss: 0.1348, Validation Loss: 0.1348,V Acc: 0.3636, Top 70th Acc: 0.4156, Bottom 30th Acc: 0.2424
Fold [4/5] Epoch [10/100] Initial Loss: 0.1380, Training Loss: 0.0262, Initial Validation Loss: 0.1348, Validation Loss: 0.0356,V Acc: 0.8273, Top 70th Acc: 0.8961, Bottom 30th Acc: 0.6667
Fold [4/5] Epoch [20/100] Initial Loss: 0.1380, Training Loss: 0.0161, Initial Validation Loss: 0.1348, Validation Loss: 0.0342,V Acc: 0.8273, Top 70th Acc: 0.8961, Bottom 30th Acc: 0.6667
Fold [4/5] Epoch [30/100] Initial Loss: 0.1380, Training Loss: 0.0142, Initial Validation Loss: 0.1348, Validation Loss: 0.0335,V Acc: 0.8455, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 34  Rolling back to Epoch (base 0): 29  Top Validation Acc: 0.9090909090909091
Fold [5/5] Epoch [0/100] Initial Loss: 0.1377, Training Loss: 0.1377, Initial Validation Loss: 0.1351, Validation Loss: 0.1351,V Acc: 0.2500, Top 70th Acc: 0.3421, Bottom 30th Acc: 0.0312
Fold [5/5] Epoch [10/100] Initial Loss: 0.1377, Training Loss: 0.0370, Initial Validation Loss: 0.1351, Validation Loss: 0.0371,V Acc: 0.8333, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.5938
Fold [5/5] Epoch [20/100] Initial Loss: 0.1377, Training Loss: 0.0190, Initial Validation Loss: 0.1351, Validation Loss: 0.0229,V Acc: 0.8981, Top 70th Acc: 0.9868, Bottom 30th Acc: 0.6875
Stopping early at Epoch (base 0): 27  Rolling back to Epoch (base 0): 22  Top Validation Acc: 0.9736842105263158
Running train_nn.py with seed 11
CUDA:False
Training samples count:  550
Training on 30 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1410, Training Loss: 0.1410, Initial Validation Loss: 0.1372, Validation Loss: 0.1372,V Acc: 0.2523, Top 70th Acc: 0.3205, Bottom 30th Acc: 0.0909
Fold [1/5] Epoch [10/100] Initial Loss: 0.1410, Training Loss: 0.0291, Initial Validation Loss: 0.1372, Validation Loss: 0.0350,V Acc: 0.8649, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.7576
Fold [1/5] Epoch [20/100] Initial Loss: 0.1410, Training Loss: 0.0171, Initial Validation Loss: 0.1372, Validation Loss: 0.0316,V Acc: 0.8198, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.9102564102564102
9 0 [array([0.6402026 , 0.0641027 , 0.09194745, 0.0554297 , 0.14831762],
      dtype=float32)]
Fold [2/5] Epoch [0/100] Initial Loss: 0.1367, Training Loss: 0.1367, Initial Validation Loss: 0.1325, Validation Loss: 0.1325,V Acc: 0.3514, Top 70th Acc: 0.3974, Bottom 30th Acc: 0.2424
Fold [2/5] Epoch [10/100] Initial Loss: 0.1367, Training Loss: 0.0239, Initial Validation Loss: 0.1325, Validation Loss: 0.0345,V Acc: 0.8288, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.6061
Fold [2/5] Epoch [20/100] Initial Loss: 0.1367, Training Loss: 0.0156, Initial Validation Loss: 0.1325, Validation Loss: 0.0305,V Acc: 0.8198, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.4848
Fold [2/5] Epoch [30/100] Initial Loss: 0.1367, Training Loss: 0.0134, Initial Validation Loss: 0.1325, Validation Loss: 0.0305,V Acc: 0.8198, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.5152
Stopping early at Epoch (base 0): 31  Rolling back to Epoch (base 0): 26  Top Validation Acc: 0.9358974358974359
Fold [3/5] Epoch [0/100] Initial Loss: 0.1364, Training Loss: 0.1364, Initial Validation Loss: 0.1315, Validation Loss: 0.1315,V Acc: 0.3364, Top 70th Acc: 0.4286, Bottom 30th Acc: 0.1212
Fold [3/5] Epoch [10/100] Initial Loss: 0.1364, Training Loss: 0.0237, Initial Validation Loss: 0.1315, Validation Loss: 0.0347,V Acc: 0.8182, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.4545
Fold [3/5] Epoch [20/100] Initial Loss: 0.1364, Training Loss: 0.0138, Initial Validation Loss: 0.1315, Validation Loss: 0.0328,V Acc: 0.8091, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.4242
Stopping early at Epoch (base 0): 21  Rolling back to Epoch (base 0): 16  Top Validation Acc: 0.948051948051948
Fold [4/5] Epoch [0/100] Initial Loss: 0.1384, Training Loss: 0.1384, Initial Validation Loss: 0.1351, Validation Loss: 0.1351,V Acc: 0.2636, Top 70th Acc: 0.3377, Bottom 30th Acc: 0.0909
Fold [4/5] Epoch [10/100] Initial Loss: 0.1384, Training Loss: 0.0286, Initial Validation Loss: 0.1351, Validation Loss: 0.0362,V Acc: 0.8455, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6061
Fold [4/5] Epoch [20/100] Initial Loss: 0.1384, Training Loss: 0.0155, Initial Validation Loss: 0.1351, Validation Loss: 0.0302,V Acc: 0.8545, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.948051948051948
Fold [5/5] Epoch [0/100] Initial Loss: 0.1385, Training Loss: 0.1385, Initial Validation Loss: 0.1348, Validation Loss: 0.1348,V Acc: 0.2500, Top 70th Acc: 0.2500, Bottom 30th Acc: 0.2500
Fold [5/5] Epoch [10/100] Initial Loss: 0.1385, Training Loss: 0.0333, Initial Validation Loss: 0.1348, Validation Loss: 0.0414,V Acc: 0.7778, Top 70th Acc: 0.9079, Bottom 30th Acc: 0.4688
Fold [5/5] Epoch [20/100] Initial Loss: 0.1385, Training Loss: 0.0157, Initial Validation Loss: 0.1348, Validation Loss: 0.0268,V Acc: 0.8519, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.6250
Fold [5/5] Epoch [30/100] Initial Loss: 0.1385, Training Loss: 0.0134, Initial Validation Loss: 0.1348, Validation Loss: 0.0280,V Acc: 0.8519, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.6250
Stopping early at Epoch (base 0): 32  Rolling back to Epoch (base 0): 27  Top Validation Acc: 0.9605263157894737
Running train_nn.py with seed 10
CUDA:False
Training samples count:  550
Training on 40 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1393, Training Loss: 0.1393, Initial Validation Loss: 0.1330, Validation Loss: 0.1330,V Acc: 0.3153, Top 70th Acc: 0.3974, Bottom 30th Acc: 0.1212
Fold [1/5] Epoch [10/100] Initial Loss: 0.1393, Training Loss: 0.0390, Initial Validation Loss: 0.1330, Validation Loss: 0.0540,V Acc: 0.7658, Top 70th Acc: 0.8718, Bottom 30th Acc: 0.5152
Fold [1/5] Epoch [20/100] Initial Loss: 0.1393, Training Loss: 0.0147, Initial Validation Loss: 0.1330, Validation Loss: 0.0353,V Acc: 0.8198, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.4848
Stopping early at Epoch (base 0): 29  Rolling back to Epoch (base 0): 24  Top Validation Acc: 0.9230769230769231
10 0 [array([0.6810638 , 0.03828502, 0.06169155, 0.10278171, 0.11617793],
      dtype=float32)]
Fold [2/5] Epoch [0/100] Initial Loss: 0.1394, Training Loss: 0.1394, Initial Validation Loss: 0.1292, Validation Loss: 0.1292,V Acc: 0.3423, Top 70th Acc: 0.3462, Bottom 30th Acc: 0.3333
Fold [2/5] Epoch [10/100] Initial Loss: 0.1394, Training Loss: 0.0440, Initial Validation Loss: 0.1292, Validation Loss: 0.0564,V Acc: 0.7117, Top 70th Acc: 0.8077, Bottom 30th Acc: 0.4848
Fold [2/5] Epoch [20/100] Initial Loss: 0.1394, Training Loss: 0.0229, Initial Validation Loss: 0.1292, Validation Loss: 0.0412,V Acc: 0.7568, Top 70th Acc: 0.8846, Bottom 30th Acc: 0.4545
Fold [2/5] Epoch [30/100] Initial Loss: 0.1394, Training Loss: 0.0134, Initial Validation Loss: 0.1292, Validation Loss: 0.0341,V Acc: 0.7928, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.4848
Fold [2/5] Epoch [40/100] Initial Loss: 0.1394, Training Loss: 0.0110, Initial Validation Loss: 0.1292, Validation Loss: 0.0316,V Acc: 0.8018, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.4848
Stopping early at Epoch (base 0): 49  Rolling back to Epoch (base 0): 44  Top Validation Acc: 0.9230769230769231
Fold [3/5] Epoch [0/100] Initial Loss: 0.1386, Training Loss: 0.1386, Initial Validation Loss: 0.1359, Validation Loss: 0.1359,V Acc: 0.3273, Top 70th Acc: 0.4156, Bottom 30th Acc: 0.1212
Fold [3/5] Epoch [10/100] Initial Loss: 0.1386, Training Loss: 0.0317, Initial Validation Loss: 0.1359, Validation Loss: 0.0366,V Acc: 0.8455, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6061
Fold [3/5] Epoch [20/100] Initial Loss: 0.1386, Training Loss: 0.0144, Initial Validation Loss: 0.1359, Validation Loss: 0.0253,V Acc: 0.9000, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.7273
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.974025974025974
Fold [4/5] Epoch [0/100] Initial Loss: 0.1372, Training Loss: 0.1372, Initial Validation Loss: 0.1337, Validation Loss: 0.1337,V Acc: 0.3455, Top 70th Acc: 0.4156, Bottom 30th Acc: 0.1818
Fold [4/5] Epoch [10/100] Initial Loss: 0.1372, Training Loss: 0.0264, Initial Validation Loss: 0.1337, Validation Loss: 0.0393,V Acc: 0.7909, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.5152
Fold [4/5] Epoch [20/100] Initial Loss: 0.1372, Training Loss: 0.0130, Initial Validation Loss: 0.1337, Validation Loss: 0.0341,V Acc: 0.8091, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.922077922077922
Fold [5/5] Epoch [0/100] Initial Loss: 0.1365, Training Loss: 0.1365, Initial Validation Loss: 0.1320, Validation Loss: 0.1320,V Acc: 0.2778, Top 70th Acc: 0.3553, Bottom 30th Acc: 0.0938
Fold [5/5] Epoch [10/100] Initial Loss: 0.1365, Training Loss: 0.0278, Initial Validation Loss: 0.1320, Validation Loss: 0.0300,V Acc: 0.8519, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.5938
Fold [5/5] Epoch [20/100] Initial Loss: 0.1365, Training Loss: 0.0147, Initial Validation Loss: 0.1320, Validation Loss: 0.0230,V Acc: 0.8796, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.6875
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.9605263157894737
Running train_nn.py with seed 11
CUDA:False
Training samples count:  550
Training on 40 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1386, Training Loss: 0.1386, Initial Validation Loss: 0.1363, Validation Loss: 0.1363,V Acc: 0.3243, Top 70th Acc: 0.3846, Bottom 30th Acc: 0.1818
Fold [1/5] Epoch [10/100] Initial Loss: 0.1386, Training Loss: 0.0365, Initial Validation Loss: 0.1363, Validation Loss: 0.0425,V Acc: 0.8018, Top 70th Acc: 0.8846, Bottom 30th Acc: 0.6061
Fold [1/5] Epoch [20/100] Initial Loss: 0.1386, Training Loss: 0.0202, Initial Validation Loss: 0.1363, Validation Loss: 0.0344,V Acc: 0.8108, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.5152
Fold [1/5] Epoch [30/100] Initial Loss: 0.1386, Training Loss: 0.0135, Initial Validation Loss: 0.1363, Validation Loss: 0.0289,V Acc: 0.8559, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.6667
Fold [1/5] Epoch [40/100] Initial Loss: 0.1386, Training Loss: 0.0116, Initial Validation Loss: 0.1363, Validation Loss: 0.0275,V Acc: 0.8559, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.6364
Fold [1/5] Epoch [10/100] Initial Loss: 0.1370, Training Loss: 0.0268, Initial Validation Loss: 0.1261, Validation Loss: 0.0363,V Acc: 0.7838, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.4545
Fold [1/5] Epoch [20/100] Initial Loss: 0.1370, Training Loss: 0.0176, Initial Validation Loss: 0.1261, Validation Loss: 0.0285,V Acc: 0.8559, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.9358974358974359
Fold [2/5] Epoch [0/100] Initial Loss: 0.1351, Training Loss: 0.1351, Initial Validation Loss: 0.1283, Validation Loss: 0.1283,V Acc: 0.4324, Top 70th Acc: 0.5000, Bottom 30th Acc: 0.2727
Fold [2/5] Epoch [10/100] Initial Loss: 0.1351, Training Loss: 0.0276, Initial Validation Loss: 0.1283, Validation Loss: 0.0311,V Acc: 0.8829, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.7273
Fold [2/5] Epoch [20/100] Initial Loss: 0.1351, Training Loss: 0.0173, Initial Validation Loss: 0.1283, Validation Loss: 0.0298,V Acc: 0.8378, Top 70th Acc: 0.9872, Bottom 30th Acc: 0.4848
Stopping early at Epoch (base 0): 22  Rolling back to Epoch (base 0): 17  Top Validation Acc: 0.9743589743589743
16 1 [array([0.7595318 , 0.04466645, 0.01972872, 0.08647896, 0.08959407],
      dtype=float32)]
Fold [3/5] Epoch [0/100] Initial Loss: 0.1283, Training Loss: 0.1283, Initial Validation Loss: 0.1154, Validation Loss: 0.1154,V Acc: 0.5909, Top 70th Acc: 0.6883, Bottom 30th Acc: 0.3636
Fold [3/5] Epoch [10/100] Initial Loss: 0.1283, Training Loss: 0.0236, Initial Validation Loss: 0.1154, Validation Loss: 0.0305,V Acc: 0.8545, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.6667
Fold [3/5] Epoch [20/100] Initial Loss: 0.1283, Training Loss: 0.0171, Initial Validation Loss: 0.1154, Validation Loss: 0.0302,V Acc: 0.8636, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 21  Rolling back to Epoch (base 0): 16  Top Validation Acc: 0.9090909090909091
Fold [4/5] Epoch [0/100] Initial Loss: 0.1362, Training Loss: 0.1362, Initial Validation Loss: 0.1210, Validation Loss: 0.1210,V Acc: 0.5545, Top 70th Acc: 0.6364, Bottom 30th Acc: 0.3636
Fold [4/5] Epoch [10/100] Initial Loss: 0.1362, Training Loss: 0.0286, Initial Validation Loss: 0.1210, Validation Loss: 0.0265,V Acc: 0.8818, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 16  Rolling back to Epoch (base 0): 11  Top Validation Acc: 0.961038961038961
Fold [5/5] Epoch [0/100] Initial Loss: 0.1392, Training Loss: 0.1392, Initial Validation Loss: 0.1282, Validation Loss: 0.1282,V Acc: 0.4630, Top 70th Acc: 0.5132, Bottom 30th Acc: 0.3438
Fold [5/5] Epoch [10/100] Initial Loss: 0.1392, Training Loss: 0.0258, Initial Validation Loss: 0.1282, Validation Loss: 0.0280,V Acc: 0.8704, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.6875
Stopping early at Epoch (base 0): 17  Rolling back to Epoch (base 0): 12  Top Validation Acc: 0.9736842105263158
Running train_nn.py with seed 17
CUDA:False
Training samples count:  550
Training on 21 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1336, Training Loss: 0.1336, Initial Validation Loss: 0.1254, Validation Loss: 0.1254,V Acc: 0.4414, Top 70th Acc: 0.4615, Bottom 30th Acc: 0.3939
Fold [1/5] Epoch [10/100] Initial Loss: 0.1336, Training Loss: 0.0263, Initial Validation Loss: 0.1254, Validation Loss: 0.0280,V Acc: 0.8919, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.7273
Stopping early at Epoch (base 0): 15  Rolling back to Epoch (base 0): 10  Top Validation Acc: 0.9615384615384616
Fold [2/5] Epoch [0/100] Initial Loss: 0.1254, Training Loss: 0.1254, Initial Validation Loss: 0.1135, Validation Loss: 0.1135,V Acc: 0.4324, Top 70th Acc: 0.5897, Bottom 30th Acc: 0.0606
Fold [2/5] Epoch [10/100] Initial Loss: 0.1254, Training Loss: 0.0231, Initial Validation Loss: 0.1135, Validation Loss: 0.0278,V Acc: 0.8739, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.6970
Fold [2/5] Epoch [20/100] Initial Loss: 0.1254, Training Loss: 0.0177, Initial Validation Loss: 0.1135, Validation Loss: 0.0233,V Acc: 0.8829, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.9743589743589743
Fold [3/5] Epoch [0/100] Initial Loss: 0.1284, Training Loss: 0.1284, Initial Validation Loss: 0.1194, Validation Loss: 0.1194,V Acc: 0.4818, Top 70th Acc: 0.5844, Bottom 30th Acc: 0.2424
Fold [3/5] Epoch [10/100] Initial Loss: 0.1284, Training Loss: 0.0223, Initial Validation Loss: 0.1194, Validation Loss: 0.0308,V Acc: 0.8727, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.6667
Fold [3/5] Epoch [20/100] Initial Loss: 0.1284, Training Loss: 0.0170, Initial Validation Loss: 0.1194, Validation Loss: 0.0274,V Acc: 0.8636, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.6364
Fold [3/5] Epoch [30/100] Initial Loss: 0.1284, Training Loss: 0.0139, Initial Validation Loss: 0.1194, Validation Loss: 0.0307,V Acc: 0.8636, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 30  Rolling back to Epoch (base 0): 25  Top Validation Acc: 0.935064935064935
Fold [4/5] Epoch [0/100] Initial Loss: 0.1294, Training Loss: 0.1294, Initial Validation Loss: 0.1173, Validation Loss: 0.1173,V Acc: 0.4545, Top 70th Acc: 0.5844, Bottom 30th Acc: 0.1515
Fold [4/5] Epoch [10/100] Initial Loss: 0.1294, Training Loss: 0.0233, Initial Validation Loss: 0.1173, Validation Loss: 0.0344,V Acc: 0.8636, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 15  Rolling back to Epoch (base 0): 10  Top Validation Acc: 0.9090909090909091
Fold [5/5] Epoch [0/100] Initial Loss: 0.1345, Training Loss: 0.1345, Initial Validation Loss: 0.1159, Validation Loss: 0.1159,V Acc: 0.5556, Top 70th Acc: 0.6974, Bottom 30th Acc: 0.2188
Fold [5/5] Epoch [10/100] Initial Loss: 0.1345, Training Loss: 0.0264, Initial Validation Loss: 0.1159, Validation Loss: 0.0306,V Acc: 0.8426, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.5938
Fold [5/5] Epoch [20/100] Initial Loss: 0.1345, Training Loss: 0.0189, Initial Validation Loss: 0.1159, Validation Loss: 0.0267,V Acc: 0.8426, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.6250
Stopping early at Epoch (base 0): 28  Rolling back to Epoch (base 0): 23  Top Validation Acc: 0.9078947368421053
17 4 [array([0.76112276, 0.00907221, 0.02419258, 0.08408678, 0.12152565],
      dtype=float32)]
Running train_nn.py with seed 18
CUDA:False
Training samples count:  550
Training on 21 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1322, Training Loss: 0.1322, Initial Validation Loss: 0.1210, Validation Loss: 0.1210,V Acc: 0.6216, Top 70th Acc: 0.7436, Bottom 30th Acc: 0.3333
Fold [1/5] Epoch [10/100] Initial Loss: 0.1322, Training Loss: 0.0256, Initial Validation Loss: 0.1210, Validation Loss: 0.0298,V Acc: 0.8649, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 18  Rolling back to Epoch (base 0): 13  Top Validation Acc: 0.9487179487179487
Fold [2/5] Epoch [0/100] Initial Loss: 0.1368, Training Loss: 0.1368, Initial Validation Loss: 0.1295, Validation Loss: 0.1295,V Acc: 0.5045, Top 70th Acc: 0.6154, Bottom 30th Acc: 0.2424
Fold [2/5] Epoch [10/100] Initial Loss: 0.1368, Training Loss: 0.0325, Initial Validation Loss: 0.1295, Validation Loss: 0.0281,V Acc: 0.9099, Top 70th Acc: 0.9872, Bottom 30th Acc: 0.7273
Fold [2/5] Epoch [20/100] Initial Loss: 0.1368, Training Loss: 0.0180, Initial Validation Loss: 0.1295, Validation Loss: 0.0229,V Acc: 0.9279, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.8182
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.9743589743589743
18 1 [array([0.82465494, 0.01205079, 0.02505741, 0.07571967, 0.0625171 ],
      dtype=float32)]
Fold [3/5] Epoch [0/100] Initial Loss: 0.1311, Training Loss: 0.1311, Initial Validation Loss: 0.1178, Validation Loss: 0.1178,V Acc: 0.4909, Top 70th Acc: 0.5844, Bottom 30th Acc: 0.2727
Fold [3/5] Epoch [10/100] Initial Loss: 0.1311, Training Loss: 0.0213, Initial Validation Loss: 0.1178, Validation Loss: 0.0363,V Acc: 0.8455, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.5758
Fold [3/5] Epoch [20/100] Initial Loss: 0.1311, Training Loss: 0.0176, Initial Validation Loss: 0.1178, Validation Loss: 0.0334,V Acc: 0.8818, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.7273
Fold [5/5] Epoch [20/100] Initial Loss: 0.1388, Training Loss: 0.0069, Initial Validation Loss: 0.1309, Validation Loss: 0.0393,V Acc: 0.8056, Top 70th Acc: 0.9211, Bottom 30th Acc: 0.5312
Stopping early at Epoch (base 0): 20  Rolling back to Epoch (base 0): 15  Top Validation Acc: 0.9210526315789473
Running train_nn.py with seed 9
CUDA:False
Training samples count:  550
Training on 163 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1379, Training Loss: 0.1379, Initial Validation Loss: 0.1365, Validation Loss: 0.1365,V Acc: 0.3063, Top 70th Acc: 0.3590, Bottom 30th Acc: 0.1818
Fold [1/5] Epoch [10/100] Initial Loss: 0.1379, Training Loss: 0.0118, Initial Validation Loss: 0.1365, Validation Loss: 0.0345,V Acc: 0.8288, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.6061
Fold [1/5] Epoch [20/100] Initial Loss: 0.1379, Training Loss: 0.0043, Initial Validation Loss: 0.1365, Validation Loss: 0.0319,V Acc: 0.8468, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.9487179487179487
9 0 [array([0.12665266, 0.05594614, 0.06895578, 0.1671737 , 0.58127177],
      dtype=float32)]
Fold [2/5] Epoch [0/100] Initial Loss: 0.1419, Training Loss: 0.1419, Initial Validation Loss: 0.1354, Validation Loss: 0.1354,V Acc: 0.2523, Top 70th Acc: 0.3333, Bottom 30th Acc: 0.0606
Fold [2/5] Epoch [10/100] Initial Loss: 0.1419, Training Loss: 0.0182, Initial Validation Loss: 0.1354, Validation Loss: 0.0414,V Acc: 0.8108, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 18  Rolling back to Epoch (base 0): 13  Top Validation Acc: 0.9358974358974359
Fold [3/5] Epoch [0/100] Initial Loss: 0.1373, Training Loss: 0.1373, Initial Validation Loss: 0.1301, Validation Loss: 0.1301,V Acc: 0.3727, Top 70th Acc: 0.4416, Bottom 30th Acc: 0.2121
Fold [3/5] Epoch [10/100] Initial Loss: 0.1373, Training Loss: 0.0258, Initial Validation Loss: 0.1301, Validation Loss: 0.0409,V Acc: 0.8455, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.6970
Fold [3/5] Epoch [20/100] Initial Loss: 0.1373, Training Loss: 0.0078, Initial Validation Loss: 0.1301, Validation Loss: 0.0370,V Acc: 0.7909, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.4545
Stopping early at Epoch (base 0): 22  Rolling back to Epoch (base 0): 17  Top Validation Acc: 0.922077922077922
Fold [4/5] Epoch [0/100] Initial Loss: 0.1385, Training Loss: 0.1385, Initial Validation Loss: 0.1344, Validation Loss: 0.1344,V Acc: 0.2545, Top 70th Acc: 0.3506, Bottom 30th Acc: 0.0303
Fold [4/5] Epoch [10/100] Initial Loss: 0.1385, Training Loss: 0.0113, Initial Validation Loss: 0.1344, Validation Loss: 0.0283,V Acc: 0.8545, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.6061
Fold [4/5] Epoch [20/100] Initial Loss: 0.1385, Training Loss: 0.0049, Initial Validation Loss: 0.1344, Validation Loss: 0.0249,V Acc: 0.8636, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6667
Fold [4/5] Epoch [30/100] Initial Loss: 0.1385, Training Loss: 0.0041, Initial Validation Loss: 0.1344, Validation Loss: 0.0240,V Acc: 0.8727, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 35  Rolling back to Epoch (base 0): 30  Top Validation Acc: 0.974025974025974
Fold [5/5] Epoch [0/100] Initial Loss: 0.1389, Training Loss: 0.1389, Initial Validation Loss: 0.1320, Validation Loss: 0.1320,V Acc: 0.2500, Top 70th Acc: 0.3421, Bottom 30th Acc: 0.0312
Fold [5/5] Epoch [10/100] Initial Loss: 0.1389, Training Loss: 0.0211, Initial Validation Loss: 0.1320, Validation Loss: 0.0364,V Acc: 0.8241, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.5625
Fold [5/5] Epoch [20/100] Initial Loss: 0.1389, Training Loss: 0.0055, Initial Validation Loss: 0.1320, Validation Loss: 0.0260,V Acc: 0.8519, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.5938
Stopping early at Epoch (base 0): 28  Rolling back to Epoch (base 0): 23  Top Validation Acc: 0.9605263157894737
Running train_nn.py with seed 10
CUDA:False
Training samples count:  550
Training on 163 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1385, Training Loss: 0.1385, Initial Validation Loss: 0.1322, Validation Loss: 0.1322,V Acc: 0.3423, Top 70th Acc: 0.3846, Bottom 30th Acc: 0.2424
Fold [1/5] Epoch [10/100] Initial Loss: 0.1385, Training Loss: 0.0155, Initial Validation Loss: 0.1322, Validation Loss: 0.0491,V Acc: 0.7568, Top 70th Acc: 0.8718, Bottom 30th Acc: 0.4848
Fold [1/5] Epoch [20/100] Initial Loss: 0.1385, Training Loss: 0.0053, Initial Validation Loss: 0.1322, Validation Loss: 0.0450,V Acc: 0.7838, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.4545
Fold [1/5] Epoch [30/100] Initial Loss: 0.1385, Training Loss: 0.0043, Initial Validation Loss: 0.1322, Validation Loss: 0.0448,V Acc: 0.7748, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.4242
Stopping early at Epoch (base 0): 33  Rolling back to Epoch (base 0): 28  Top Validation Acc: 0.9230769230769231
10 0 [array([0.1603586 , 0.0694116 , 0.03577447, 0.14041434, 0.59404105],
      dtype=float32)]
Fold [2/5] Epoch [0/100] Initial Loss: 0.1407, Training Loss: 0.1407, Initial Validation Loss: 0.1332, Validation Loss: 0.1332,V Acc: 0.2613, Top 70th Acc: 0.3205, Bottom 30th Acc: 0.1212
Fold [2/5] Epoch [10/100] Initial Loss: 0.1407, Training Loss: 0.0298, Initial Validation Loss: 0.1332, Validation Loss: 0.0473,V Acc: 0.7748, Top 70th Acc: 0.8590, Bottom 30th Acc: 0.5758
Fold [2/5] Epoch [20/100] Initial Loss: 0.1407, Training Loss: 0.0056, Initial Validation Loss: 0.1332, Validation Loss: 0.0320,V Acc: 0.8468, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.6061
Fold [2/5] Epoch [30/100] Initial Loss: 0.1407, Training Loss: 0.0041, Initial Validation Loss: 0.1332, Validation Loss: 0.0308,V Acc: 0.8468, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.5758
Fold [2/5] Epoch [40/100] Initial Loss: 0.1407, Training Loss: 0.0039, Initial Validation Loss: 0.1332, Validation Loss: 0.0295,V Acc: 0.8468, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 46  Rolling back to Epoch (base 0): 41  Top Validation Acc: 0.9487179487179487
Fold [3/5] Epoch [0/100] Initial Loss: 0.1395, Training Loss: 0.1395, Initial Validation Loss: 0.1370, Validation Loss: 0.1370,V Acc: 0.2545, Top 70th Acc: 0.3377, Bottom 30th Acc: 0.0606
Fold [3/5] Epoch [10/100] Initial Loss: 0.1395, Training Loss: 0.0193, Initial Validation Loss: 0.1370, Validation Loss: 0.0345,V Acc: 0.8545, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6364
Fold [3/5] Epoch [20/100] Initial Loss: 0.1395, Training Loss: 0.0052, Initial Validation Loss: 0.1370, Validation Loss: 0.0247,V Acc: 0.8909, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.7273
Fold [3/5] Epoch [30/100] Initial Loss: 0.1395, Training Loss: 0.0041, Initial Validation Loss: 0.1370, Validation Loss: 0.0238,V Acc: 0.8727, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.6667
Fold [3/5] Epoch [40/100] Initial Loss: 0.1395, Training Loss: 0.0038, Initial Validation Loss: 0.1370, Validation Loss: 0.0234,V Acc: 0.9000, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.7879
Stopping early at Epoch (base 0): 49  Rolling back to Epoch (base 0): 44  Top Validation Acc: 0.948051948051948
Fold [4/5] Epoch [0/100] Initial Loss: 0.1382, Training Loss: 0.1382, Initial Validation Loss: 0.1353, Validation Loss: 0.1353,V Acc: 0.2545, Top 70th Acc: 0.3377, Bottom 30th Acc: 0.0606
Fold [4/5] Epoch [10/100] Initial Loss: 0.1382, Training Loss: 0.0213, Initial Validation Loss: 0.1353, Validation Loss: 0.0385,V Acc: 0.8273, Top 70th Acc: 0.8961, Bottom 30th Acc: 0.6667
Fold [4/5] Epoch [20/100] Initial Loss: 0.1382, Training Loss: 0.0071, Initial Validation Loss: 0.1353, Validation Loss: 0.0351,V Acc: 0.8091, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 22  Rolling back to Epoch (base 0): 17  Top Validation Acc: 0.922077922077922
Fold [5/5] Epoch [0/100] Initial Loss: 0.1372, Training Loss: 0.1372, Initial Validation Loss: 0.1357, Validation Loss: 0.1357,V Acc: 0.2500, Top 70th Acc: 0.2895, Bottom 30th Acc: 0.1562
Fold [5/5] Epoch [10/100] Initial Loss: 0.1372, Training Loss: 0.0150, Initial Validation Loss: 0.1357, Validation Loss: 0.0292,V Acc: 0.8889, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.7812
Fold [5/5] Epoch [20/100] Initial Loss: 0.1372, Training Loss: 0.0049, Initial Validation Loss: 0.1357, Validation Loss: 0.0251,V Acc: 0.8889, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.7188
Fold [1/5] Epoch [10/100] Initial Loss: 0.1382, Training Loss: 0.0355, Initial Validation Loss: 0.1362, Validation Loss: 0.0380,V Acc: 0.8378, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.6667
Fold [1/5] Epoch [20/100] Initial Loss: 0.1382, Training Loss: 0.0233, Initial Validation Loss: 0.1362, Validation Loss: 0.0332,V Acc: 0.8559, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.7273
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.8974358974358975
Fold [2/5] Epoch [0/100] Initial Loss: 0.1378, Training Loss: 0.1378, Initial Validation Loss: 0.1394, Validation Loss: 0.1394,V Acc: 0.2523, Top 70th Acc: 0.3590, Bottom 30th Acc: 0.0000
Fold [2/5] Epoch [10/100] Initial Loss: 0.1378, Training Loss: 0.0423, Initial Validation Loss: 0.1394, Validation Loss: 0.0564,V Acc: 0.7477, Top 70th Acc: 0.8846, Bottom 30th Acc: 0.4242
Fold [2/5] Epoch [20/100] Initial Loss: 0.1378, Training Loss: 0.0245, Initial Validation Loss: 0.1394, Validation Loss: 0.0390,V Acc: 0.8108, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.5152
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.9358974358974359
Fold [3/5] Epoch [0/100] Initial Loss: 0.1392, Training Loss: 0.1392, Initial Validation Loss: 0.1325, Validation Loss: 0.1325,V Acc: 0.3091, Top 70th Acc: 0.3247, Bottom 30th Acc: 0.2727
Fold [3/5] Epoch [10/100] Initial Loss: 0.1392, Training Loss: 0.0380, Initial Validation Loss: 0.1325, Validation Loss: 0.0391,V Acc: 0.8636, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.6970
Fold [3/5] Epoch [20/100] Initial Loss: 0.1392, Training Loss: 0.0248, Initial Validation Loss: 0.1325, Validation Loss: 0.0333,V Acc: 0.8818, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.7576
Stopping early at Epoch (base 0): 22  Rolling back to Epoch (base 0): 17  Top Validation Acc: 0.922077922077922
Fold [4/5] Epoch [0/100] Initial Loss: 0.1390, Training Loss: 0.1390, Initial Validation Loss: 0.1301, Validation Loss: 0.1301,V Acc: 0.3636, Top 70th Acc: 0.3506, Bottom 30th Acc: 0.3939
Fold [4/5] Epoch [10/100] Initial Loss: 0.1390, Training Loss: 0.0345, Initial Validation Loss: 0.1301, Validation Loss: 0.0341,V Acc: 0.8364, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 18  Rolling back to Epoch (base 0): 13  Top Validation Acc: 0.922077922077922
11 3 [array([0.35698274, 0.0738861 , 0.18723474, 0.18495096, 0.19694546],
      dtype=float32)]
Fold [5/5] Epoch [0/100] Initial Loss: 0.1408, Training Loss: 0.1408, Initial Validation Loss: 0.1314, Validation Loss: 0.1314,V Acc: 0.2500, Top 70th Acc: 0.3026, Bottom 30th Acc: 0.1250
Fold [5/5] Epoch [10/100] Initial Loss: 0.1408, Training Loss: 0.0457, Initial Validation Loss: 0.1314, Validation Loss: 0.0453,V Acc: 0.7685, Top 70th Acc: 0.8816, Bottom 30th Acc: 0.5000
Fold [5/5] Epoch [20/100] Initial Loss: 0.1408, Training Loss: 0.0250, Initial Validation Loss: 0.1314, Validation Loss: 0.0320,V Acc: 0.8333, Top 70th Acc: 0.9079, Bottom 30th Acc: 0.6562
Stopping early at Epoch (base 0): 27  Rolling back to Epoch (base 0): 22  Top Validation Acc: 0.9078947368421053
Running train_nn.py with seed 12
CUDA:False
Training samples count:  550
Training on 20 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1456, Training Loss: 0.1456, Initial Validation Loss: 0.1326, Validation Loss: 0.1326,V Acc: 0.3964, Top 70th Acc: 0.4359, Bottom 30th Acc: 0.3030
Fold [1/5] Epoch [10/100] Initial Loss: 0.1456, Training Loss: 0.0335, Initial Validation Loss: 0.1326, Validation Loss: 0.0382,V Acc: 0.8018, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 17  Rolling back to Epoch (base 0): 12  Top Validation Acc: 0.8974358974358975
Fold [2/5] Epoch [0/100] Initial Loss: 0.1382, Training Loss: 0.1382, Initial Validation Loss: 0.1338, Validation Loss: 0.1338,V Acc: 0.3694, Top 70th Acc: 0.4103, Bottom 30th Acc: 0.2727
Fold [2/5] Epoch [10/100] Initial Loss: 0.1382, Training Loss: 0.0425, Initial Validation Loss: 0.1338, Validation Loss: 0.0455,V Acc: 0.8288, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.5758
Fold [2/5] Epoch [20/100] Initial Loss: 0.1382, Training Loss: 0.0265, Initial Validation Loss: 0.1338, Validation Loss: 0.0325,V Acc: 0.8739, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.6667
Fold [2/5] Epoch [30/100] Initial Loss: 0.1382, Training Loss: 0.0227, Initial Validation Loss: 0.1338, Validation Loss: 0.0300,V Acc: 0.8919, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.7576
Fold [2/5] Epoch [40/100] Initial Loss: 0.1382, Training Loss: 0.0213, Initial Validation Loss: 0.1338, Validation Loss: 0.0313,V Acc: 0.8739, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.7273
Stopping early at Epoch (base 0): 40  Rolling back to Epoch (base 0): 35  Top Validation Acc: 0.9358974358974359
Fold [3/5] Epoch [0/100] Initial Loss: 0.1427, Training Loss: 0.1427, Initial Validation Loss: 0.1372, Validation Loss: 0.1372,V Acc: 0.2545, Top 70th Acc: 0.2597, Bottom 30th Acc: 0.2424
Fold [3/5] Epoch [10/100] Initial Loss: 0.1427, Training Loss: 0.0445, Initial Validation Loss: 0.1372, Validation Loss: 0.0415,V Acc: 0.8091, Top 70th Acc: 0.8831, Bottom 30th Acc: 0.6364
Fold [3/5] Epoch [20/100] Initial Loss: 0.1427, Training Loss: 0.0300, Initial Validation Loss: 0.1372, Validation Loss: 0.0308,V Acc: 0.8455, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.6364
Fold [3/5] Epoch [30/100] Initial Loss: 0.1427, Training Loss: 0.0248, Initial Validation Loss: 0.1372, Validation Loss: 0.0288,V Acc: 0.8636, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 32  Rolling back to Epoch (base 0): 27  Top Validation Acc: 0.935064935064935
Fold [4/5] Epoch [0/100] Initial Loss: 0.1374, Training Loss: 0.1374, Initial Validation Loss: 0.1315, Validation Loss: 0.1315,V Acc: 0.2909, Top 70th Acc: 0.3377, Bottom 30th Acc: 0.1818
Fold [4/5] Epoch [10/100] Initial Loss: 0.1374, Training Loss: 0.0464, Initial Validation Loss: 0.1315, Validation Loss: 0.0516,V Acc: 0.7636, Top 70th Acc: 0.8701, Bottom 30th Acc: 0.5152
Fold [4/5] Epoch [20/100] Initial Loss: 0.1374, Training Loss: 0.0244, Initial Validation Loss: 0.1315, Validation Loss: 0.0359,V Acc: 0.8091, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.5152
Stopping early at Epoch (base 0): 28  Rolling back to Epoch (base 0): 23  Top Validation Acc: 0.922077922077922
Fold [5/5] Epoch [0/100] Initial Loss: 0.1397, Training Loss: 0.1397, Initial Validation Loss: 0.1342, Validation Loss: 0.1342,V Acc: 0.3241, Top 70th Acc: 0.3947, Bottom 30th Acc: 0.1562
Fold [5/5] Epoch [10/100] Initial Loss: 0.1397, Training Loss: 0.0291, Initial Validation Loss: 0.1342, Validation Loss: 0.0420,V Acc: 0.8148, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.5312
Fold [5/5] Epoch [20/100] Initial Loss: 0.1397, Training Loss: 0.0218, Initial Validation Loss: 0.1342, Validation Loss: 0.0407,V Acc: 0.7870, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.4375
Stopping early at Epoch (base 0): 22  Rolling back to Epoch (base 0): 17  Top Validation Acc: 0.9210526315789473
12 4 [array([0.30090475, 0.12294509, 0.17995782, 0.19877365, 0.19741865],
      dtype=float32)]
Running train_nn.py with seed 13
CUDA:False
Training samples count:  550
Training on 20 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1396, Training Loss: 0.1396, Initial Validation Loss: 0.1388, Validation Loss: 0.1388,V Acc: 0.3153, Top 70th Acc: 0.3718, Bottom 30th Acc: 0.1818
Fold [1/5] Epoch [10/100] Initial Loss: 0.1396, Training Loss: 0.0488, Initial Validation Loss: 0.1388, Validation Loss: 0.0471,V Acc: 0.7838, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.4545
Fold [1/5] Epoch [20/100] Initial Loss: 0.1396, Training Loss: 0.0272, Initial Validation Loss: 0.1388, Validation Loss: 0.0302,V Acc: 0.8559, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.6061
Fold [1/5] Epoch [30/100] Initial Loss: 0.1396, Training Loss: 0.0221, Initial Validation Loss: 0.1388, Validation Loss: 0.0263,V Acc: 0.8739, Top 70th Acc: 0.9872, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 37  Rolling back to Epoch (base 0): 32  Top Validation Acc: 0.9871794871794872
Fold [2/5] Epoch [0/100] Initial Loss: 0.1428, Training Loss: 0.1428, Initial Validation Loss: 0.1352, Validation Loss: 0.1352,V Acc: 0.2523, Top 70th Acc: 0.1667, Bottom 30th Acc: 0.4545
Fold [4/5] Epoch [10/100] Initial Loss: 0.1316, Training Loss: 0.0798, Initial Validation Loss: 0.1192, Validation Loss: 0.0799,V Acc: 0.6091, Top 70th Acc: 0.7403, Bottom 30th Acc: 0.3030
Stopping early at Epoch (base 0): 18  Rolling back to Epoch (base 0): 13  Top Validation Acc: 0.7142857142857143
Fold [5/5] Epoch [0/100] Initial Loss: 0.1373, Training Loss: 0.1373, Initial Validation Loss: 0.1303, Validation Loss: 0.1303,V Acc: 0.3981, Top 70th Acc: 0.4079, Bottom 30th Acc: 0.3750
Fold [5/5] Epoch [10/100] Initial Loss: 0.1373, Training Loss: 0.0806, Initial Validation Loss: 0.1303, Validation Loss: 0.0794,V Acc: 0.6296, Top 70th Acc: 0.7368, Bottom 30th Acc: 0.3750
Fold [5/5] Epoch [20/100] Initial Loss: 0.1373, Training Loss: 0.0790, Initial Validation Loss: 0.1303, Validation Loss: 0.0784,V Acc: 0.6296, Top 70th Acc: 0.7632, Bottom 30th Acc: 0.3125
Fold [5/5] Epoch [30/100] Initial Loss: 0.1373, Training Loss: 0.0787, Initial Validation Loss: 0.1303, Validation Loss: 0.0765,V Acc: 0.6389, Top 70th Acc: 0.7632, Bottom 30th Acc: 0.3438
Fold [5/5] Epoch [40/100] Initial Loss: 0.1373, Training Loss: 0.0783, Initial Validation Loss: 0.1303, Validation Loss: 0.0760,V Acc: 0.6389, Top 70th Acc: 0.7895, Bottom 30th Acc: 0.2812
Fold [5/5] Epoch [50/100] Initial Loss: 0.1373, Training Loss: 0.0779, Initial Validation Loss: 0.1303, Validation Loss: 0.0754,V Acc: 0.6574, Top 70th Acc: 0.7632, Bottom 30th Acc: 0.4062
Stopping early at Epoch (base 0): 56  Rolling back to Epoch (base 0): 51  Top Validation Acc: 0.75
Running train_nn.py with seed 11
CUDA:False
Training samples count:  550
Training on 2 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1374, Training Loss: 0.1374, Initial Validation Loss: 0.1330, Validation Loss: 0.1330,V Acc: 0.5225, Top 70th Acc: 0.6538, Bottom 30th Acc: 0.2121
Fold [1/5] Epoch [10/100] Initial Loss: 0.1374, Training Loss: 0.0810, Initial Validation Loss: 0.1330, Validation Loss: 0.0828,V Acc: 0.6216, Top 70th Acc: 0.7436, Bottom 30th Acc: 0.3333
Fold [1/5] Epoch [20/100] Initial Loss: 0.1374, Training Loss: 0.0789, Initial Validation Loss: 0.1330, Validation Loss: 0.0811,V Acc: 0.6306, Top 70th Acc: 0.7564, Bottom 30th Acc: 0.3333
Fold [1/5] Epoch [30/100] Initial Loss: 0.1374, Training Loss: 0.0782, Initial Validation Loss: 0.1330, Validation Loss: 0.0805,V Acc: 0.6306, Top 70th Acc: 0.7692, Bottom 30th Acc: 0.3030
Fold [1/5] Epoch [40/100] Initial Loss: 0.1374, Training Loss: 0.0779, Initial Validation Loss: 0.1330, Validation Loss: 0.0799,V Acc: 0.6306, Top 70th Acc: 0.7692, Bottom 30th Acc: 0.3030
Fold [1/5] Epoch [50/100] Initial Loss: 0.1374, Training Loss: 0.0775, Initial Validation Loss: 0.1330, Validation Loss: 0.0795,V Acc: 0.6306, Top 70th Acc: 0.7564, Bottom 30th Acc: 0.3333
Stopping early at Epoch (base 0): 50  Rolling back to Epoch (base 0): 45  Top Validation Acc: 0.7564102564102564
Fold [2/5] Epoch [0/100] Initial Loss: 0.1363, Training Loss: 0.1363, Initial Validation Loss: 0.1382, Validation Loss: 0.1382,V Acc: 0.2703, Top 70th Acc: 0.3590, Bottom 30th Acc: 0.0606
Fold [2/5] Epoch [10/100] Initial Loss: 0.1363, Training Loss: 0.0785, Initial Validation Loss: 0.1382, Validation Loss: 0.0941,V Acc: 0.5766, Top 70th Acc: 0.6795, Bottom 30th Acc: 0.3333
Fold [2/5] Epoch [20/100] Initial Loss: 0.1363, Training Loss: 0.0760, Initial Validation Loss: 0.1382, Validation Loss: 0.0918,V Acc: 0.6126, Top 70th Acc: 0.6795, Bottom 30th Acc: 0.4545
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.6923076923076923
Fold [3/5] Epoch [0/100] Initial Loss: 0.1344, Training Loss: 0.1344, Initial Validation Loss: 0.1232, Validation Loss: 0.1232,V Acc: 0.5364, Top 70th Acc: 0.6364, Bottom 30th Acc: 0.3030
Fold [3/5] Epoch [10/100] Initial Loss: 0.1344, Training Loss: 0.0822, Initial Validation Loss: 0.1232, Validation Loss: 0.0789,V Acc: 0.6273, Top 70th Acc: 0.7273, Bottom 30th Acc: 0.3939
Fold [3/5] Epoch [20/100] Initial Loss: 0.1344, Training Loss: 0.0795, Initial Validation Loss: 0.1232, Validation Loss: 0.0773,V Acc: 0.6364, Top 70th Acc: 0.7403, Bottom 30th Acc: 0.3939
Fold [3/5] Epoch [30/100] Initial Loss: 0.1344, Training Loss: 0.0787, Initial Validation Loss: 0.1232, Validation Loss: 0.0761,V Acc: 0.6455, Top 70th Acc: 0.7143, Bottom 30th Acc: 0.4848
Stopping early at Epoch (base 0): 36  Rolling back to Epoch (base 0): 31  Top Validation Acc: 0.7142857142857143
Fold [4/5] Epoch [0/100] Initial Loss: 0.1348, Training Loss: 0.1348, Initial Validation Loss: 0.1231, Validation Loss: 0.1231,V Acc: 0.4727, Top 70th Acc: 0.5195, Bottom 30th Acc: 0.3636
Fold [4/5] Epoch [10/100] Initial Loss: 0.1348, Training Loss: 0.0826, Initial Validation Loss: 0.1231, Validation Loss: 0.0725,V Acc: 0.6727, Top 70th Acc: 0.7532, Bottom 30th Acc: 0.4848
Fold [4/5] Epoch [20/100] Initial Loss: 0.1348, Training Loss: 0.0810, Initial Validation Loss: 0.1231, Validation Loss: 0.0712,V Acc: 0.6636, Top 70th Acc: 0.7532, Bottom 30th Acc: 0.4545
Fold [4/5] Epoch [30/100] Initial Loss: 0.1348, Training Loss: 0.0803, Initial Validation Loss: 0.1231, Validation Loss: 0.0710,V Acc: 0.6545, Top 70th Acc: 0.7403, Bottom 30th Acc: 0.4545
Stopping early at Epoch (base 0): 36  Rolling back to Epoch (base 0): 31  Top Validation Acc: 0.7402597402597403
11 3 [array([0.14702247, 0.30208036, 0.15986332, 0.24086282, 0.150171  ],
      dtype=float32)]
Fold [5/5] Epoch [0/100] Initial Loss: 0.1315, Training Loss: 0.1315, Initial Validation Loss: 0.1231, Validation Loss: 0.1231,V Acc: 0.3611, Top 70th Acc: 0.4868, Bottom 30th Acc: 0.0625
Fold [5/5] Epoch [10/100] Initial Loss: 0.1315, Training Loss: 0.0815, Initial Validation Loss: 0.1231, Validation Loss: 0.0752,V Acc: 0.6204, Top 70th Acc: 0.7632, Bottom 30th Acc: 0.2812
Fold [5/5] Epoch [20/100] Initial Loss: 0.1315, Training Loss: 0.0796, Initial Validation Loss: 0.1231, Validation Loss: 0.0728,V Acc: 0.6389, Top 70th Acc: 0.7500, Bottom 30th Acc: 0.3750
Fold [5/5] Epoch [30/100] Initial Loss: 0.1315, Training Loss: 0.0788, Initial Validation Loss: 0.1231, Validation Loss: 0.0724,V Acc: 0.6204, Top 70th Acc: 0.7500, Bottom 30th Acc: 0.3125
Stopping early at Epoch (base 0): 32  Rolling back to Epoch (base 0): 27  Top Validation Acc: 0.7631578947368421
Running train_nn.py with seed 12
CUDA:False
Training samples count:  550
Training on 2 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1356, Training Loss: 0.1356, Initial Validation Loss: 0.1230, Validation Loss: 0.1230,V Acc: 0.4595, Top 70th Acc: 0.5769, Bottom 30th Acc: 0.1818
Fold [1/5] Epoch [10/100] Initial Loss: 0.1356, Training Loss: 0.0801, Initial Validation Loss: 0.1230, Validation Loss: 0.0788,V Acc: 0.6306, Top 70th Acc: 0.7179, Bottom 30th Acc: 0.4242
Fold [1/5] Epoch [20/100] Initial Loss: 0.1356, Training Loss: 0.0787, Initial Validation Loss: 0.1230, Validation Loss: 0.0784,V Acc: 0.6126, Top 70th Acc: 0.7179, Bottom 30th Acc: 0.3636
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.7307692307692307
Fold [2/5] Epoch [0/100] Initial Loss: 0.1288, Training Loss: 0.1288, Initial Validation Loss: 0.1190, Validation Loss: 0.1190,V Acc: 0.5225, Top 70th Acc: 0.6410, Bottom 30th Acc: 0.2424
Fold [2/5] Epoch [10/100] Initial Loss: 0.1288, Training Loss: 0.0787, Initial Validation Loss: 0.1190, Validation Loss: 0.0872,V Acc: 0.6036, Top 70th Acc: 0.6795, Bottom 30th Acc: 0.4242
Stopping early at Epoch (base 0): 13  Rolling back to Epoch (base 0): 8  Top Validation Acc: 0.6923076923076923
Fold [3/5] Epoch [0/100] Initial Loss: 0.1411, Training Loss: 0.1411, Initial Validation Loss: 0.1335, Validation Loss: 0.1335,V Acc: 0.2545, Top 70th Acc: 0.3636, Bottom 30th Acc: 0.0000
Fold [3/5] Epoch [10/100] Initial Loss: 0.1411, Training Loss: 0.0851, Initial Validation Loss: 0.1335, Validation Loss: 0.0674,V Acc: 0.6909, Top 70th Acc: 0.8312, Bottom 30th Acc: 0.3636
Fold [3/5] Epoch [20/100] Initial Loss: 0.1411, Training Loss: 0.0831, Initial Validation Loss: 0.1335, Validation Loss: 0.0653,V Acc: 0.6909, Top 70th Acc: 0.8442, Bottom 30th Acc: 0.3333
Fold [3/5] Epoch [30/100] Initial Loss: 0.1411, Training Loss: 0.0825, Initial Validation Loss: 0.1335, Validation Loss: 0.0646,V Acc: 0.6818, Top 70th Acc: 0.8312, Bottom 30th Acc: 0.3333 0.9102564102564102
Fold [2/5] Epoch [0/100] Initial Loss: 0.1368, Training Loss: 0.1368, Initial Validation Loss: 0.1382, Validation Loss: 0.1382,V Acc: 0.3243, Top 70th Acc: 0.3590, Bottom 30th Acc: 0.2424
Fold [2/5] Epoch [10/100] Initial Loss: 0.1368, Training Loss: 0.0257, Initial Validation Loss: 0.1382, Validation Loss: 0.0372,V Acc: 0.8288, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.5455
Fold [2/5] Epoch [20/100] Initial Loss: 0.1368, Training Loss: 0.0172, Initial Validation Loss: 0.1382, Validation Loss: 0.0304,V Acc: 0.8559, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.9615384615384616
Fold [3/5] Epoch [0/100] Initial Loss: 0.1394, Training Loss: 0.1394, Initial Validation Loss: 0.1341, Validation Loss: 0.1341,V Acc: 0.2455, Top 70th Acc: 0.2597, Bottom 30th Acc: 0.2121
Fold [3/5] Epoch [10/100] Initial Loss: 0.1394, Training Loss: 0.0358, Initial Validation Loss: 0.1341, Validation Loss: 0.0443,V Acc: 0.7727, Top 70th Acc: 0.8961, Bottom 30th Acc: 0.4848
Fold [3/5] Epoch [20/100] Initial Loss: 0.1394, Training Loss: 0.0222, Initial Validation Loss: 0.1341, Validation Loss: 0.0374,V Acc: 0.8091, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.5758
Fold [3/5] Epoch [30/100] Initial Loss: 0.1394, Training Loss: 0.0181, Initial Validation Loss: 0.1341, Validation Loss: 0.0319,V Acc: 0.8455, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.6667
Fold [3/5] Epoch [40/100] Initial Loss: 0.1394, Training Loss: 0.0165, Initial Validation Loss: 0.1341, Validation Loss: 0.0284,V Acc: 0.8818, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.7576
Fold [3/5] Epoch [50/100] Initial Loss: 0.1394, Training Loss: 0.0155, Initial Validation Loss: 0.1341, Validation Loss: 0.0270,V Acc: 0.8818, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.7273
Stopping early at Epoch (base 0): 58  Rolling back to Epoch (base 0): 53  Top Validation Acc: 0.935064935064935
Fold [4/5] Epoch [0/100] Initial Loss: 0.1436, Training Loss: 0.1436, Initial Validation Loss: 0.1346, Validation Loss: 0.1346,V Acc: 0.2545, Top 70th Acc: 0.1818, Bottom 30th Acc: 0.4242
Fold [4/5] Epoch [10/100] Initial Loss: 0.1436, Training Loss: 0.0335, Initial Validation Loss: 0.1346, Validation Loss: 0.0350,V Acc: 0.8364, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.6061
Fold [4/5] Epoch [20/100] Initial Loss: 0.1436, Training Loss: 0.0185, Initial Validation Loss: 0.1346, Validation Loss: 0.0307,V Acc: 0.8455, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.948051948051948
11 3 [array([0.6860561 , 0.04708561, 0.05122355, 0.08925323, 0.12638167],
      dtype=float32)]
Fold [5/5] Epoch [0/100] Initial Loss: 0.1391, Training Loss: 0.1391, Initial Validation Loss: 0.1321, Validation Loss: 0.1321,V Acc: 0.2593, Top 70th Acc: 0.3289, Bottom 30th Acc: 0.0938
Fold [5/5] Epoch [10/100] Initial Loss: 0.1391, Training Loss: 0.0376, Initial Validation Loss: 0.1321, Validation Loss: 0.0456,V Acc: 0.7778, Top 70th Acc: 0.8553, Bottom 30th Acc: 0.5938
Fold [5/5] Epoch [20/100] Initial Loss: 0.1391, Training Loss: 0.0186, Initial Validation Loss: 0.1321, Validation Loss: 0.0372,V Acc: 0.7870, Top 70th Acc: 0.9211, Bottom 30th Acc: 0.4688
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.9078947368421053
Running train_nn.py with seed 12
CUDA:False
Training samples count:  550
Training on 30 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1389, Training Loss: 0.1389, Initial Validation Loss: 0.1312, Validation Loss: 0.1312,V Acc: 0.2973, Top 70th Acc: 0.3333, Bottom 30th Acc: 0.2121
Fold [1/5] Epoch [10/100] Initial Loss: 0.1389, Training Loss: 0.0291, Initial Validation Loss: 0.1312, Validation Loss: 0.0347,V Acc: 0.7928, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.5152
Fold [1/5] Epoch [20/100] Initial Loss: 0.1389, Training Loss: 0.0174, Initial Validation Loss: 0.1312, Validation Loss: 0.0308,V Acc: 0.8468, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.9102564102564102
Fold [2/5] Epoch [0/100] Initial Loss: 0.1410, Training Loss: 0.1410, Initial Validation Loss: 0.1384, Validation Loss: 0.1384,V Acc: 0.3243, Top 70th Acc: 0.3974, Bottom 30th Acc: 0.1515
Fold [2/5] Epoch [10/100] Initial Loss: 0.1410, Training Loss: 0.0390, Initial Validation Loss: 0.1384, Validation Loss: 0.0416,V Acc: 0.8378, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.6364
Fold [2/5] Epoch [20/100] Initial Loss: 0.1410, Training Loss: 0.0194, Initial Validation Loss: 0.1384, Validation Loss: 0.0318,V Acc: 0.8739, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.7273
Fold [2/5] Epoch [30/100] Initial Loss: 0.1410, Training Loss: 0.0149, Initial Validation Loss: 0.1384, Validation Loss: 0.0314,V Acc: 0.8829, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.7576
Stopping early at Epoch (base 0): 33  Rolling back to Epoch (base 0): 28  Top Validation Acc: 0.9487179487179487
Fold [3/5] Epoch [0/100] Initial Loss: 0.1409, Training Loss: 0.1409, Initial Validation Loss: 0.1364, Validation Loss: 0.1364,V Acc: 0.3091, Top 70th Acc: 0.3636, Bottom 30th Acc: 0.1818
Fold [3/5] Epoch [10/100] Initial Loss: 0.1409, Training Loss: 0.0352, Initial Validation Loss: 0.1364, Validation Loss: 0.0369,V Acc: 0.7909, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.5152
Fold [3/5] Epoch [20/100] Initial Loss: 0.1409, Training Loss: 0.0188, Initial Validation Loss: 0.1364, Validation Loss: 0.0257,V Acc: 0.8545, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6364
Fold [3/5] Epoch [30/100] Initial Loss: 0.1409, Training Loss: 0.0163, Initial Validation Loss: 0.1364, Validation Loss: 0.0270,V Acc: 0.8455, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 30  Rolling back to Epoch (base 0): 25  Top Validation Acc: 0.948051948051948
Fold [4/5] Epoch [0/100] Initial Loss: 0.1389, Training Loss: 0.1389, Initial Validation Loss: 0.1325, Validation Loss: 0.1325,V Acc: 0.3091, Top 70th Acc: 0.3636, Bottom 30th Acc: 0.1818
Fold [4/5] Epoch [10/100] Initial Loss: 0.1389, Training Loss: 0.0304, Initial Validation Loss: 0.1325, Validation Loss: 0.0368,V Acc: 0.8273, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.5455
Fold [4/5] Epoch [20/100] Initial Loss: 0.1389, Training Loss: 0.0170, Initial Validation Loss: 0.1325, Validation Loss: 0.0312,V Acc: 0.8273, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 21  Rolling back to Epoch (base 0): 16  Top Validation Acc: 0.948051948051948
Fold [5/5] Epoch [0/100] Initial Loss: 0.1394, Training Loss: 0.1394, Initial Validation Loss: 0.1352, Validation Loss: 0.1352,V Acc: 0.3148, Top 70th Acc: 0.3816, Bottom 30th Acc: 0.1562
Fold [5/5] Epoch [10/100] Initial Loss: 0.1394, Training Loss: 0.0262, Initial Validation Loss: 0.1352, Validation Loss: 0.0375,V Acc: 0.8426, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.5625
Fold [5/5] Epoch [20/100] Initial Loss: 0.1394, Training Loss: 0.0165, Initial Validation Loss: 0.1352, Validation Loss: 0.0337,V Acc: 0.8333, Top 70th Acc: 0.9737, Bottom 30th Acc: 0.5000
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.9605263157894737
12 4 [array([0.5521905 , 0.08566827, 0.05409946, 0.07823779, 0.22980405],
      dtype=float32)]
Running train_nn.py with seed 13
CUDA:False
Training samples count:  550
Training on 30 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1394, Training Loss: 0.1394, Initial Validation Loss: 0.1399, Validation Loss: 0.1399,V Acc: 0.2883, Top 70th Acc: 0.2821, Bottom 30th Acc: 0.3030
Fold [1/5] Epoch [10/100] Initial Loss: 0.1394, Training Loss: 0.0333, Initial Validation Loss: 0.1399, Validation Loss: 0.0347,V Acc: 0.8649, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.6364
Fold [1/5] Epoch [20/100] Initial Loss: 0.1394, Training Loss: 0.0188, Initial Validation Loss: 0.1399, Validation Loss: 0.0278,V Acc: 0.8919, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.7273
Stopping early at Epoch (base 0): 20  Rolling back to Epoch (base 0): 15  Top Validation Acc: 0.9615384615384616
Fold [2/5] Epoch [0/100] Initial Loss: 0.1381, Training Loss: 0.1381, Initial Validation Loss: 0.1329, Validation Loss: 0.1329,V Acc: 0.3333, Top 70th Acc: 0.3590, Bottom 30th Acc: 0.2727
Fold [1/5] Epoch [50/100] Initial Loss: 0.1386, Training Loss: 0.0106, Initial Validation Loss: 0.1363, Validation Loss: 0.0263,V Acc: 0.8739, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.7273
Stopping early at Epoch (base 0): 59  Rolling back to Epoch (base 0): 54  Top Validation Acc: 0.9487179487179487
Fold [2/5] Epoch [0/100] Initial Loss: 0.1379, Training Loss: 0.1379, Initial Validation Loss: 0.1388, Validation Loss: 0.1388,V Acc: 0.2883, Top 70th Acc: 0.3205, Bottom 30th Acc: 0.2121
Fold [2/5] Epoch [10/100] Initial Loss: 0.1379, Training Loss: 0.0288, Initial Validation Loss: 0.1388, Validation Loss: 0.0420,V Acc: 0.7928, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.4242
Fold [2/5] Epoch [20/100] Initial Loss: 0.1379, Training Loss: 0.0133, Initial Validation Loss: 0.1388, Validation Loss: 0.0302,V Acc: 0.8288, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.4848
Fold [2/5] Epoch [30/100] Initial Loss: 0.1379, Training Loss: 0.0109, Initial Validation Loss: 0.1388, Validation Loss: 0.0305,V Acc: 0.8378, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.5152
Stopping early at Epoch (base 0): 33  Rolling back to Epoch (base 0): 28  Top Validation Acc: 0.9743589743589743
Fold [3/5] Epoch [0/100] Initial Loss: 0.1376, Training Loss: 0.1376, Initial Validation Loss: 0.1299, Validation Loss: 0.1299,V Acc: 0.4364, Top 70th Acc: 0.5195, Bottom 30th Acc: 0.2424
Fold [3/5] Epoch [10/100] Initial Loss: 0.1376, Training Loss: 0.0261, Initial Validation Loss: 0.1299, Validation Loss: 0.0314,V Acc: 0.8909, Top 70th Acc: 0.9870, Bottom 30th Acc: 0.6667
Fold [3/5] Epoch [20/100] Initial Loss: 0.1376, Training Loss: 0.0146, Initial Validation Loss: 0.1299, Validation Loss: 0.0256,V Acc: 0.8818, Top 70th Acc: 0.9870, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 27  Rolling back to Epoch (base 0): 22  Top Validation Acc: 0.974025974025974
Fold [4/5] Epoch [0/100] Initial Loss: 0.1405, Training Loss: 0.1405, Initial Validation Loss: 0.1333, Validation Loss: 0.1333,V Acc: 0.2545, Top 70th Acc: 0.2987, Bottom 30th Acc: 0.1515
Fold [4/5] Epoch [10/100] Initial Loss: 0.1405, Training Loss: 0.0380, Initial Validation Loss: 0.1333, Validation Loss: 0.0349,V Acc: 0.8000, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.4242
Fold [4/5] Epoch [20/100] Initial Loss: 0.1405, Training Loss: 0.0148, Initial Validation Loss: 0.1333, Validation Loss: 0.0239,V Acc: 0.8636, Top 70th Acc: 0.9870, Bottom 30th Acc: 0.5758
Fold [4/5] Epoch [30/100] Initial Loss: 0.1405, Training Loss: 0.0114, Initial Validation Loss: 0.1333, Validation Loss: 0.0256,V Acc: 0.8455, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 30  Rolling back to Epoch (base 0): 25  Top Validation Acc: 0.961038961038961
11 3 [array([0.52919847, 0.04890575, 0.06656811, 0.09937427, 0.25595337],
      dtype=float32)]
Fold [5/5] Epoch [0/100] Initial Loss: 0.1381, Training Loss: 0.1381, Initial Validation Loss: 0.1320, Validation Loss: 0.1320,V Acc: 0.2500, Top 70th Acc: 0.3158, Bottom 30th Acc: 0.0938
Fold [5/5] Epoch [10/100] Initial Loss: 0.1381, Training Loss: 0.0318, Initial Validation Loss: 0.1320, Validation Loss: 0.0424,V Acc: 0.7778, Top 70th Acc: 0.9211, Bottom 30th Acc: 0.4375
Fold [5/5] Epoch [20/100] Initial Loss: 0.1381, Training Loss: 0.0151, Initial Validation Loss: 0.1320, Validation Loss: 0.0339,V Acc: 0.8426, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.5938
Stopping early at Epoch (base 0): 29  Rolling back to Epoch (base 0): 24  Top Validation Acc: 0.9342105263157895
Running train_nn.py with seed 12
CUDA:False
Training samples count:  550
Training on 40 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1405, Training Loss: 0.1405, Initial Validation Loss: 0.1315, Validation Loss: 0.1315,V Acc: 0.3423, Top 70th Acc: 0.4103, Bottom 30th Acc: 0.1818
Fold [1/5] Epoch [10/100] Initial Loss: 0.1405, Training Loss: 0.0269, Initial Validation Loss: 0.1315, Validation Loss: 0.0316,V Acc: 0.8198, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.5758
Fold [1/5] Epoch [20/100] Initial Loss: 0.1405, Training Loss: 0.0147, Initial Validation Loss: 0.1315, Validation Loss: 0.0279,V Acc: 0.8649, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.9358974358974359
Fold [2/5] Epoch [0/100] Initial Loss: 0.1354, Training Loss: 0.1354, Initial Validation Loss: 0.1332, Validation Loss: 0.1332,V Acc: 0.4775, Top 70th Acc: 0.5385, Bottom 30th Acc: 0.3333
Fold [2/5] Epoch [10/100] Initial Loss: 0.1354, Training Loss: 0.0293, Initial Validation Loss: 0.1332, Validation Loss: 0.0443,V Acc: 0.8198, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.5455
Fold [2/5] Epoch [20/100] Initial Loss: 0.1354, Training Loss: 0.0165, Initial Validation Loss: 0.1332, Validation Loss: 0.0366,V Acc: 0.8649, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.6667
Fold [2/5] Epoch [30/100] Initial Loss: 0.1354, Training Loss: 0.0124, Initial Validation Loss: 0.1332, Validation Loss: 0.0351,V Acc: 0.8649, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 30  Rolling back to Epoch (base 0): 25  Top Validation Acc: 0.9615384615384616
Fold [3/5] Epoch [0/100] Initial Loss: 0.1394, Training Loss: 0.1394, Initial Validation Loss: 0.1373, Validation Loss: 0.1373,V Acc: 0.2545, Top 70th Acc: 0.3247, Bottom 30th Acc: 0.0909
Fold [3/5] Epoch [10/100] Initial Loss: 0.1394, Training Loss: 0.0388, Initial Validation Loss: 0.1373, Validation Loss: 0.0388,V Acc: 0.8182, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.6061
Fold [3/5] Epoch [20/100] Initial Loss: 0.1394, Training Loss: 0.0172, Initial Validation Loss: 0.1373, Validation Loss: 0.0264,V Acc: 0.8727, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.7273
Fold [3/5] Epoch [30/100] Initial Loss: 0.1394, Training Loss: 0.0141, Initial Validation Loss: 0.1373, Validation Loss: 0.0254,V Acc: 0.8727, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 33  Rolling back to Epoch (base 0): 28  Top Validation Acc: 0.948051948051948
Fold [4/5] Epoch [0/100] Initial Loss: 0.1389, Training Loss: 0.1389, Initial Validation Loss: 0.1337, Validation Loss: 0.1337,V Acc: 0.3091, Top 70th Acc: 0.3117, Bottom 30th Acc: 0.3030
Fold [4/5] Epoch [10/100] Initial Loss: 0.1389, Training Loss: 0.0306, Initial Validation Loss: 0.1337, Validation Loss: 0.0429,V Acc: 0.7545, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.3939
Fold [4/5] Epoch [20/100] Initial Loss: 0.1389, Training Loss: 0.0130, Initial Validation Loss: 0.1337, Validation Loss: 0.0370,V Acc: 0.8091, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.922077922077922
Fold [5/5] Epoch [0/100] Initial Loss: 0.1377, Training Loss: 0.1377, Initial Validation Loss: 0.1346, Validation Loss: 0.1346,V Acc: 0.2500, Top 70th Acc: 0.3289, Bottom 30th Acc: 0.0625
Fold [5/5] Epoch [10/100] Initial Loss: 0.1377, Training Loss: 0.0323, Initial Validation Loss: 0.1346, Validation Loss: 0.0456,V Acc: 0.7593, Top 70th Acc: 0.9211, Bottom 30th Acc: 0.3750
Fold [5/5] Epoch [20/100] Initial Loss: 0.1377, Training Loss: 0.0154, Initial Validation Loss: 0.1346, Validation Loss: 0.0315,V Acc: 0.8148, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.4688
Stopping early at Epoch (base 0): 27  Rolling back to Epoch (base 0): 22  Top Validation Acc: 0.9605263157894737
12 4 [array([0.6714825 , 0.07459369, 0.05536278, 0.05865574, 0.13990529],
      dtype=float32)]
Running train_nn.py with seed 13
CUDA:False
Training samples count:  550
Training on 40 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1378, Training Loss: 0.1378, Initial Validation Loss: 0.1384, Validation Loss: 0.1384,V Acc: 0.3423, Top 70th Acc: 0.3718, Bottom 30th Acc: 0.2727
Fold [1/5] Epoch [10/100] Initial Loss: 0.1378, Training Loss: 0.0388, Initial Validation Loss: 0.1384, Validation Loss: 0.0421,V Acc: 0.8288, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.6061
Fold [1/5] Epoch [20/100] Initial Loss: 0.1378, Training Loss: 0.0179, Initial Validation Loss: 0.1384, Validation Loss: 0.0262,V Acc: 0.8919, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.7273
Stopping early at Epoch (base 0): 28  Rolling back to Epoch (base 0): 23  Top Validation Acc:
Stopping early at Epoch (base 0): 20  Rolling back to Epoch (base 0): 15  Top Validation Acc: 0.948051948051948
Fold [4/5] Epoch [0/100] Initial Loss: 0.1375, Training Loss: 0.1375, Initial Validation Loss: 0.1226, Validation Loss: 0.1226,V Acc: 0.4636, Top 70th Acc: 0.5844, Bottom 30th Acc: 0.1818
Fold [4/5] Epoch [10/100] Initial Loss: 0.1375, Training Loss: 0.0288, Initial Validation Loss: 0.1226, Validation Loss: 0.0327,V Acc: 0.8273, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.6364
Fold [4/5] Epoch [20/100] Initial Loss: 0.1375, Training Loss: 0.0180, Initial Validation Loss: 0.1226, Validation Loss: 0.0222,V Acc: 0.8455, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.935064935064935
Fold [5/5] Epoch [0/100] Initial Loss: 0.1236, Training Loss: 0.1236, Initial Validation Loss: 0.1058, Validation Loss: 0.1058,V Acc: 0.4722, Top 70th Acc: 0.6053, Bottom 30th Acc: 0.1562
Fold [5/5] Epoch [10/100] Initial Loss: 0.1236, Training Loss: 0.0223, Initial Validation Loss: 0.1058, Validation Loss: 0.0303,V Acc: 0.8611, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.6875
Stopping early at Epoch (base 0): 18  Rolling back to Epoch (base 0): 13  Top Validation Acc: 0.9473684210526315
Running train_nn.py with seed 19
CUDA:False
Training samples count:  550
Training on 21 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1333, Training Loss: 0.1333, Initial Validation Loss: 0.1200, Validation Loss: 0.1200,V Acc: 0.4234, Top 70th Acc: 0.4359, Bottom 30th Acc: 0.3939
Fold [1/5] Epoch [10/100] Initial Loss: 0.1333, Training Loss: 0.0270, Initial Validation Loss: 0.1200, Validation Loss: 0.0251,V Acc: 0.8919, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.6970
Fold [1/5] Epoch [20/100] Initial Loss: 0.1333, Training Loss: 0.0181, Initial Validation Loss: 0.1200, Validation Loss: 0.0232,V Acc: 0.8829, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.9487179487179487
Fold [2/5] Epoch [0/100] Initial Loss: 0.1365, Training Loss: 0.1365, Initial Validation Loss: 0.1231, Validation Loss: 0.1231,V Acc: 0.5135, Top 70th Acc: 0.5897, Bottom 30th Acc: 0.3333
Fold [2/5] Epoch [10/100] Initial Loss: 0.1365, Training Loss: 0.0249, Initial Validation Loss: 0.1231, Validation Loss: 0.0319,V Acc: 0.8468, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.6667
Fold [2/5] Epoch [20/100] Initial Loss: 0.1365, Training Loss: 0.0204, Initial Validation Loss: 0.1231, Validation Loss: 0.0260,V Acc: 0.8559, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.9102564102564102
Fold [3/5] Epoch [0/100] Initial Loss: 0.1299, Training Loss: 0.1299, Initial Validation Loss: 0.1207, Validation Loss: 0.1207,V Acc: 0.4818, Top 70th Acc: 0.5844, Bottom 30th Acc: 0.2424
Fold [3/5] Epoch [10/100] Initial Loss: 0.1299, Training Loss: 0.0240, Initial Validation Loss: 0.1207, Validation Loss: 0.0332,V Acc: 0.8818, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.7576
Stopping early at Epoch (base 0): 14  Rolling back to Epoch (base 0): 9  Top Validation Acc: 0.961038961038961
Fold [4/5] Epoch [0/100] Initial Loss: 0.1284, Training Loss: 0.1284, Initial Validation Loss: 0.1211, Validation Loss: 0.1211,V Acc: 0.4818, Top 70th Acc: 0.5455, Bottom 30th Acc: 0.3333
Fold [4/5] Epoch [10/100] Initial Loss: 0.1284, Training Loss: 0.0212, Initial Validation Loss: 0.1211, Validation Loss: 0.0328,V Acc: 0.8364, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 15  Rolling back to Epoch (base 0): 10  Top Validation Acc: 0.922077922077922
19 3 [array([0.7737777 , 0.01863172, 0.04162995, 0.07186799, 0.09409254],
      dtype=float32)]
Fold [5/5] Epoch [0/100] Initial Loss: 0.1353, Training Loss: 0.1353, Initial Validation Loss: 0.1248, Validation Loss: 0.1248,V Acc: 0.5000, Top 70th Acc: 0.5658, Bottom 30th Acc: 0.3438
Fold [5/5] Epoch [10/100] Initial Loss: 0.1353, Training Loss: 0.0255, Initial Validation Loss: 0.1248, Validation Loss: 0.0331,V Acc: 0.8519, Top 70th Acc: 0.9868, Bottom 30th Acc: 0.5312
Fold [5/5] Epoch [20/100] Initial Loss: 0.1353, Training Loss: 0.0174, Initial Validation Loss: 0.1248, Validation Loss: 0.0303,V Acc: 0.8611, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.6250
Stopping early at Epoch (base 0): 20  Rolling back to Epoch (base 0): 15  Top Validation Acc: 0.9605263157894737
Running train_nn.py with seed 20
CUDA:False
Training samples count:  550
Training on 21 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1413, Training Loss: 0.1413, Initial Validation Loss: 0.1328, Validation Loss: 0.1328,V Acc: 0.3153, Top 70th Acc: 0.3846, Bottom 30th Acc: 0.1515
Fold [1/5] Epoch [10/100] Initial Loss: 0.1413, Training Loss: 0.0235, Initial Validation Loss: 0.1328, Validation Loss: 0.0273,V Acc: 0.9009, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.7273
Stopping early at Epoch (base 0): 17  Rolling back to Epoch (base 0): 12  Top Validation Acc: 0.9615384615384616
Fold [2/5] Epoch [0/100] Initial Loss: 0.1395, Training Loss: 0.1395, Initial Validation Loss: 0.1364, Validation Loss: 0.1364,V Acc: 0.2523, Top 70th Acc: 0.3077, Bottom 30th Acc: 0.1212
Fold [2/5] Epoch [10/100] Initial Loss: 0.1395, Training Loss: 0.0234, Initial Validation Loss: 0.1364, Validation Loss: 0.0294,V Acc: 0.8829, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.6970
Fold [2/5] Epoch [20/100] Initial Loss: 0.1395, Training Loss: 0.0175, Initial Validation Loss: 0.1364, Validation Loss: 0.0285,V Acc: 0.8468, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 20  Rolling back to Epoch (base 0): 15  Top Validation Acc: 0.9743589743589743
Fold [3/5] Epoch [0/100] Initial Loss: 0.1398, Training Loss: 0.1398, Initial Validation Loss: 0.1223, Validation Loss: 0.1223,V Acc: 0.3727, Top 70th Acc: 0.4286, Bottom 30th Acc: 0.2424
Fold [3/5] Epoch [10/100] Initial Loss: 0.1398, Training Loss: 0.0246, Initial Validation Loss: 0.1223, Validation Loss: 0.0308,V Acc: 0.8545, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 16  Rolling back to Epoch (base 0): 11  Top Validation Acc: 0.922077922077922
Fold [4/5] Epoch [0/100] Initial Loss: 0.1373, Training Loss: 0.1373, Initial Validation Loss: 0.1296, Validation Loss: 0.1296,V Acc: 0.4091, Top 70th Acc: 0.4545, Bottom 30th Acc: 0.3030
Fold [4/5] Epoch [10/100] Initial Loss: 0.1373, Training Loss: 0.0249, Initial Validation Loss: 0.1296, Validation Loss: 0.0366,V Acc: 0.8364, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.6364
Fold [4/5] Epoch [20/100] Initial Loss: 0.1373, Training Loss: 0.0176, Initial Validation Loss: 0.1296, Validation Loss: 0.0273,V Acc: 0.8818, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.935064935064935
Fold [5/5] Epoch [0/100] Initial Loss: 0.1370, Training Loss: 0.1370, Initial Validation Loss: 0.1288, Validation Loss: 0.1288,V Acc: 0.4722, Top 70th Acc: 0.4474, Bottom 30th Acc: 0.5312
Fold [5/5] Epoch [10/100] Initial Loss: 0.1370, Training Loss: 0.0306, Initial Validation Loss: 0.1288, Validation Loss: 0.0359,V Acc: 0.8333, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.5938
Fold [5/5] Epoch [20/100] Initial Loss: 0.1370, Training Loss: 0.0217, Initial Validation Loss: 0.1288, Validation Loss: 0.0223,V Acc: 0.8611, Top 70th Acc: 0.9737, Bottom 30th Acc: 0.5938
Fold [5/5] Epoch [30/100] Initial Loss: 0.1370, Training Loss: 0.0180, Initial Validation Loss: 0.1288, Validation Loss: 0.0196,V Acc: 0.9259, Top 70th Acc: 0.9868, Bottom 30th Acc: 0.7812
Fold [5/5] Epoch [40/100] Initial Loss: 0.1370, Training Loss: 0.0167, Initial Validation Loss: 0.1288, Validation Loss: 0.0198,V Acc: 0.9167, Top 70th Acc: 0.9868, Bottom 30th Acc: 0.7500
Stopping early at Epoch (base 0): 44  Rolling back to Epoch (base 0): 39  Top Validation Acc: 0.9868421052631579
20 4 [array([0.8047191 , 0.0135052 , 0.01680497, 0.05348597, 0.11148477],
      dtype=float32)]
Running train_nn.py with seed 21
CUDA:False
Training samples count:  550
Training on 21 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1383, Training Loss: 0.1383, Initial Validation Loss: 0.1325, Validation Loss: 0.1325,V Acc: 0.3784, Top 70th Acc: 0.4487, Bottom 30th Acc: 0.2121
Stopping early at Epoch (base 0): 33  Rolling back to Epoch (base 0): 28  Top Validation Acc: 0.8311688311688312
Fold [4/5] Epoch [0/100] Initial Loss: 0.1310, Training Loss: 0.1310, Initial Validation Loss: 0.1199, Validation Loss: 0.1199,V Acc: 0.4000, Top 70th Acc: 0.4935, Bottom 30th Acc: 0.1818
Fold [4/5] Epoch [10/100] Initial Loss: 0.1310, Training Loss: 0.0814, Initial Validation Loss: 0.1199, Validation Loss: 0.0792,V Acc: 0.6455, Top 70th Acc: 0.7403, Bottom 30th Acc: 0.4242
Fold [4/5] Epoch [20/100] Initial Loss: 0.1310, Training Loss: 0.0795, Initial Validation Loss: 0.1199, Validation Loss: 0.0776,V Acc: 0.6636, Top 70th Acc: 0.7532, Bottom 30th Acc: 0.4545
Fold [4/5] Epoch [30/100] Initial Loss: 0.1310, Training Loss: 0.0790, Initial Validation Loss: 0.1199, Validation Loss: 0.0769,V Acc: 0.6636, Top 70th Acc: 0.7273, Bottom 30th Acc: 0.5152
Stopping early at Epoch (base 0): 35  Rolling back to Epoch (base 0): 30  Top Validation Acc: 0.7532467532467533
Fold [5/5] Epoch [0/100] Initial Loss: 0.1347, Training Loss: 0.1347, Initial Validation Loss: 0.1304, Validation Loss: 0.1304,V Acc: 0.3148, Top 70th Acc: 0.3553, Bottom 30th Acc: 0.2188
Fold [5/5] Epoch [10/100] Initial Loss: 0.1347, Training Loss: 0.0786, Initial Validation Loss: 0.1304, Validation Loss: 0.0904,V Acc: 0.5463, Top 70th Acc: 0.6842, Bottom 30th Acc: 0.2188
Fold [5/5] Epoch [20/100] Initial Loss: 0.1347, Training Loss: 0.0761, Initial Validation Loss: 0.1304, Validation Loss: 0.0893,V Acc: 0.5648, Top 70th Acc: 0.6974, Bottom 30th Acc: 0.2500
Fold [5/5] Epoch [30/100] Initial Loss: 0.1347, Training Loss: 0.0751, Initial Validation Loss: 0.1304, Validation Loss: 0.0881,V Acc: 0.5648, Top 70th Acc: 0.6974, Bottom 30th Acc: 0.2500
Stopping early at Epoch (base 0): 33  Rolling back to Epoch (base 0): 28  Top Validation Acc: 0.6973684210526315
12 4 [array([0.13141102, 0.35253298, 0.15349743, 0.22832705, 0.13423154],
      dtype=float32)]
Running train_nn.py with seed 13
CUDA:False
Training samples count:  550
Training on 2 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1331, Training Loss: 0.1331, Initial Validation Loss: 0.1303, Validation Loss: 0.1303,V Acc: 0.4505, Top 70th Acc: 0.5385, Bottom 30th Acc: 0.2424
Fold [1/5] Epoch [10/100] Initial Loss: 0.1331, Training Loss: 0.0795, Initial Validation Loss: 0.1303, Validation Loss: 0.0850,V Acc: 0.5946, Top 70th Acc: 0.7051, Bottom 30th Acc: 0.3333
Fold [1/5] Epoch [20/100] Initial Loss: 0.1331, Training Loss: 0.0770, Initial Validation Loss: 0.1303, Validation Loss: 0.0832,V Acc: 0.5856, Top 70th Acc: 0.7051, Bottom 30th Acc: 0.3030
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.7307692307692307
Fold [2/5] Epoch [0/100] Initial Loss: 0.1383, Training Loss: 0.1383, Initial Validation Loss: 0.1248, Validation Loss: 0.1248,V Acc: 0.3694, Top 70th Acc: 0.4487, Bottom 30th Acc: 0.1818
Fold [2/5] Epoch [10/100] Initial Loss: 0.1383, Training Loss: 0.0818, Initial Validation Loss: 0.1248, Validation Loss: 0.0808,V Acc: 0.6306, Top 70th Acc: 0.7308, Bottom 30th Acc: 0.3939
Fold [2/5] Epoch [20/100] Initial Loss: 0.1383, Training Loss: 0.0793, Initial Validation Loss: 0.1248, Validation Loss: 0.0784,V Acc: 0.6486, Top 70th Acc: 0.7564, Bottom 30th Acc: 0.3939
Fold [2/5] Epoch [30/100] Initial Loss: 0.1383, Training Loss: 0.0785, Initial Validation Loss: 0.1248, Validation Loss: 0.0785,V Acc: 0.6486, Top 70th Acc: 0.7564, Bottom 30th Acc: 0.3939
Stopping early at Epoch (base 0): 30  Rolling back to Epoch (base 0): 25  Top Validation Acc: 0.7564102564102564
Fold [3/5] Epoch [0/100] Initial Loss: 0.1362, Training Loss: 0.1362, Initial Validation Loss: 0.1314, Validation Loss: 0.1314,V Acc: 0.4091, Top 70th Acc: 0.5325, Bottom 30th Acc: 0.1212
Fold [3/5] Epoch [10/100] Initial Loss: 0.1362, Training Loss: 0.0789, Initial Validation Loss: 0.1314, Validation Loss: 0.0818,V Acc: 0.6273, Top 70th Acc: 0.7143, Bottom 30th Acc: 0.4242
Stopping early at Epoch (base 0): 19  Rolling back to Epoch (base 0): 14  Top Validation Acc: 0.7012987012987013
Fold [4/5] Epoch [0/100] Initial Loss: 0.1375, Training Loss: 0.1375, Initial Validation Loss: 0.1227, Validation Loss: 0.1227,V Acc: 0.3455, Top 70th Acc: 0.4416, Bottom 30th Acc: 0.1212
Fold [4/5] Epoch [10/100] Initial Loss: 0.1375, Training Loss: 0.0804, Initial Validation Loss: 0.1227, Validation Loss: 0.0828,V Acc: 0.6000, Top 70th Acc: 0.7143, Bottom 30th Acc: 0.3333
Fold [4/5] Epoch [20/100] Initial Loss: 0.1375, Training Loss: 0.0784, Initial Validation Loss: 0.1227, Validation Loss: 0.0820,V Acc: 0.5818, Top 70th Acc: 0.7273, Bottom 30th Acc: 0.2424
Stopping early at Epoch (base 0): 29  Rolling back to Epoch (base 0): 24  Top Validation Acc: 0.7012987012987013
Fold [5/5] Epoch [0/100] Initial Loss: 0.1320, Training Loss: 0.1320, Initial Validation Loss: 0.1186, Validation Loss: 0.1186,V Acc: 0.5463, Top 70th Acc: 0.7368, Bottom 30th Acc: 0.0938
Fold [5/5] Epoch [10/100] Initial Loss: 0.1320, Training Loss: 0.0827, Initial Validation Loss: 0.1186, Validation Loss: 0.0728,V Acc: 0.6481, Top 70th Acc: 0.8026, Bottom 30th Acc: 0.2812
Fold [5/5] Epoch [20/100] Initial Loss: 0.1320, Training Loss: 0.0814, Initial Validation Loss: 0.1186, Validation Loss: 0.0702,V Acc: 0.6759, Top 70th Acc: 0.8289, Bottom 30th Acc: 0.3125
Fold [5/5] Epoch [30/100] Initial Loss: 0.1320, Training Loss: 0.0810, Initial Validation Loss: 0.1186, Validation Loss: 0.0702,V Acc: 0.6944, Top 70th Acc: 0.8158, Bottom 30th Acc: 0.4062
Fold [5/5] Epoch [40/100] Initial Loss: 0.1320, Training Loss: 0.0806, Initial Validation Loss: 0.1186, Validation Loss: 0.0696,V Acc: 0.7037, Top 70th Acc: 0.8421, Bottom 30th Acc: 0.3750
Fold [5/5] Epoch [50/100] Initial Loss: 0.1320, Training Loss: 0.0808, Initial Validation Loss: 0.1186, Validation Loss: 0.0688,V Acc: 0.6944, Top 70th Acc: 0.8289, Bottom 30th Acc: 0.3750
Stopping early at Epoch (base 0): 56  Rolling back to Epoch (base 0): 51  Top Validation Acc: 0.8157894736842105
13 4 [array([0.15648448, 0.33673567, 0.15275699, 0.21920836, 0.13481447],
      dtype=float32)]
Running train_nn.py with seed 14
CUDA:False
Training samples count:  550
Training on 2 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1374, Training Loss: 0.1374, Initial Validation Loss: 0.1285, Validation Loss: 0.1285,V Acc: 0.4054, Top 70th Acc: 0.4744, Bottom 30th Acc: 0.2424
Fold [1/5] Epoch [10/100] Initial Loss: 0.1374, Training Loss: 0.0827, Initial Validation Loss: 0.1285, Validation Loss: 0.0746,V Acc: 0.6847, Top 70th Acc: 0.8077, Bottom 30th Acc: 0.3939
Fold [1/5] Epoch [20/100] Initial Loss: 0.1374, Training Loss: 0.0795, Initial Validation Loss: 0.1285, Validation Loss: 0.0715,V Acc: 0.6847, Top 70th Acc: 0.7821, Bottom 30th Acc: 0.4545
Fold [1/5] Epoch [30/100] Initial Loss: 0.1374, Training Loss: 0.0787, Initial Validation Loss: 0.1285, Validation Loss: 0.0709,V Acc: 0.7117, Top 70th Acc: 0.8077, Bottom 30th Acc: 0.4848
Fold [1/5] Epoch [40/100] Initial Loss: 0.1374, Training Loss: 0.0784, Initial Validation Loss: 0.1285, Validation Loss: 0.0704,V Acc: 0.7207, Top 70th Acc: 0.7949, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 40  Rolling back to Epoch (base 0): 35  Top Validation Acc: 0.7948717948717948
Fold [2/5] Epoch [0/100] Initial Loss: 0.1443, Training Loss: 0.1443, Initial Validation Loss: 0.1302, Validation Loss: 0.1302,V Acc: 0.3243, Top 70th Acc: 0.4487, Bottom 30th Acc: 0.0303
Fold [2/5] Epoch [10/100] Initial Loss: 0.1443, Training Loss: 0.0788, Initial Validation Loss: 0.1302, Validation Loss: 0.0897,V Acc: 0.5495, Top 70th Acc: 0.6538, Bottom 30th Acc: 0.3030
Fold [2/5] Epoch [20/100] Initial Loss: 0.1443, Training Loss: 0.0758, Initial Validation Loss: 0.1302, Validation Loss: 0.0895,V Acc: 0.5586, Top 70th Acc: 0.6795, Bottom 30th Acc: 0.2727
Fold [2/5] Epoch [30/100] Initial Loss: 0.1443, Training Loss: 0.0748, Initial Validation Loss: 0.1302, Validation Loss: 0.0890,V Acc: 0.5766, Top 70th Acc: 0.6923, Bottom 30th Acc: 0.3030
Stopping early at Epoch (base 0): 32  Rolling back to Epoch (base 0): 27  Top Validation Acc: 0.6666666666666666
Fold [3/5] Epoch [0/100] Initial Loss: 0.1284, Training Loss: 0.1284, Initial Validation Loss: 0.1194, Validation Loss: 0.1194,V Acc: 0.4364, Top 70th Acc: 0.5195, Bottom 30th Acc: 0.2424
Fold [2/5] Epoch [10/100] Initial Loss: 0.1428, Training Loss: 0.0413, Initial Validation Loss: 0.1352, Validation Loss: 0.0509,V Acc: 0.7568, Top 70th Acc: 0.8333, Bottom 30th Acc: 0.5758
Fold [2/5] Epoch [20/100] Initial Loss: 0.1428, Training Loss: 0.0225, Initial Validation Loss: 0.1352, Validation Loss: 0.0403,V Acc: 0.7748, Top 70th Acc: 0.8846, Bottom 30th Acc: 0.5152
Fold [2/5] Epoch [30/100] Initial Loss: 0.1428, Training Loss: 0.0196, Initial Validation Loss: 0.1352, Validation Loss: 0.0383,V Acc: 0.8108, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 37  Rolling back to Epoch (base 0): 32  Top Validation Acc: 0.8974358974358975
Fold [3/5] Epoch [0/100] Initial Loss: 0.1402, Training Loss: 0.1402, Initial Validation Loss: 0.1385, Validation Loss: 0.1385,V Acc: 0.2727, Top 70th Acc: 0.2987, Bottom 30th Acc: 0.2121
Fold [3/5] Epoch [10/100] Initial Loss: 0.1402, Training Loss: 0.0287, Initial Validation Loss: 0.1385, Validation Loss: 0.0332,V Acc: 0.8727, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 19  Rolling back to Epoch (base 0): 14  Top Validation Acc: 0.935064935064935
Fold [4/5] Epoch [0/100] Initial Loss: 0.1413, Training Loss: 0.1413, Initial Validation Loss: 0.1280, Validation Loss: 0.1280,V Acc: 0.2636, Top 70th Acc: 0.2597, Bottom 30th Acc: 0.2727
Fold [4/5] Epoch [10/100] Initial Loss: 0.1413, Training Loss: 0.0465, Initial Validation Loss: 0.1280, Validation Loss: 0.0564,V Acc: 0.7364, Top 70th Acc: 0.8182, Bottom 30th Acc: 0.5455
Fold [4/5] Epoch [20/100] Initial Loss: 0.1413, Training Loss: 0.0238, Initial Validation Loss: 0.1280, Validation Loss: 0.0407,V Acc: 0.8000, Top 70th Acc: 0.8701, Bottom 30th Acc: 0.6364
Fold [4/5] Epoch [30/100] Initial Loss: 0.1413, Training Loss: 0.0198, Initial Validation Loss: 0.1280, Validation Loss: 0.0364,V Acc: 0.8182, Top 70th Acc: 0.8961, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 35  Rolling back to Epoch (base 0): 30  Top Validation Acc: 0.8961038961038961
Fold [5/5] Epoch [0/100] Initial Loss: 0.1387, Training Loss: 0.1387, Initial Validation Loss: 0.1325, Validation Loss: 0.1325,V Acc: 0.3056, Top 70th Acc: 0.3026, Bottom 30th Acc: 0.3125
Fold [5/5] Epoch [10/100] Initial Loss: 0.1387, Training Loss: 0.0326, Initial Validation Loss: 0.1325, Validation Loss: 0.0418,V Acc: 0.8056, Top 70th Acc: 0.8947, Bottom 30th Acc: 0.5938
Fold [5/5] Epoch [20/100] Initial Loss: 0.1387, Training Loss: 0.0219, Initial Validation Loss: 0.1325, Validation Loss: 0.0342,V Acc: 0.8333, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.5938
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.9210526315789473
13 4 [array([0.2902985 , 0.10351678, 0.06858209, 0.3027351 , 0.23486756],
      dtype=float32)]
Running train_nn.py with seed 14
CUDA:False
Training samples count:  550
Training on 20 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1416, Training Loss: 0.1416, Initial Validation Loss: 0.1363, Validation Loss: 0.1363,V Acc: 0.2793, Top 70th Acc: 0.3077, Bottom 30th Acc: 0.2121
Fold [1/5] Epoch [10/100] Initial Loss: 0.1416, Training Loss: 0.0478, Initial Validation Loss: 0.1363, Validation Loss: 0.0451,V Acc: 0.8018, Top 70th Acc: 0.8846, Bottom 30th Acc: 0.6061
Fold [1/5] Epoch [20/100] Initial Loss: 0.1416, Training Loss: 0.0259, Initial Validation Loss: 0.1363, Validation Loss: 0.0247,V Acc: 0.8829, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 28  Rolling back to Epoch (base 0): 23  Top Validation Acc: 0.9615384615384616
Fold [2/5] Epoch [0/100] Initial Loss: 0.1395, Training Loss: 0.1395, Initial Validation Loss: 0.1336, Validation Loss: 0.1336,V Acc: 0.3333, Top 70th Acc: 0.3462, Bottom 30th Acc: 0.3030
Fold [2/5] Epoch [10/100] Initial Loss: 0.1395, Training Loss: 0.0281, Initial Validation Loss: 0.1336, Validation Loss: 0.0448,V Acc: 0.7748, Top 70th Acc: 0.8590, Bottom 30th Acc: 0.5758
Fold [2/5] Epoch [20/100] Initial Loss: 0.1395, Training Loss: 0.0212, Initial Validation Loss: 0.1336, Validation Loss: 0.0404,V Acc: 0.7748, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.4242
Stopping early at Epoch (base 0): 27  Rolling back to Epoch (base 0): 22  Top Validation Acc: 0.9102564102564102
Fold [3/5] Epoch [0/100] Initial Loss: 0.1371, Training Loss: 0.1371, Initial Validation Loss: 0.1339, Validation Loss: 0.1339,V Acc: 0.3455, Top 70th Acc: 0.4156, Bottom 30th Acc: 0.1818
Fold [3/5] Epoch [10/100] Initial Loss: 0.1371, Training Loss: 0.0314, Initial Validation Loss: 0.1339, Validation Loss: 0.0391,V Acc: 0.8273, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.5758
Fold [3/5] Epoch [20/100] Initial Loss: 0.1371, Training Loss: 0.0218, Initial Validation Loss: 0.1339, Validation Loss: 0.0389,V Acc: 0.8182, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.5152
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.961038961038961
Fold [4/5] Epoch [0/100] Initial Loss: 0.1366, Training Loss: 0.1366, Initial Validation Loss: 0.1262, Validation Loss: 0.1262,V Acc: 0.3727, Top 70th Acc: 0.4545, Bottom 30th Acc: 0.1818
Fold [4/5] Epoch [10/100] Initial Loss: 0.1366, Training Loss: 0.0343, Initial Validation Loss: 0.1262, Validation Loss: 0.0386,V Acc: 0.8273, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.6364
Fold [4/5] Epoch [20/100] Initial Loss: 0.1366, Training Loss: 0.0228, Initial Validation Loss: 0.1262, Validation Loss: 0.0297,V Acc: 0.8636, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.961038961038961
Fold [5/5] Epoch [0/100] Initial Loss: 0.1372, Training Loss: 0.1372, Initial Validation Loss: 0.1335, Validation Loss: 0.1335,V Acc: 0.2963, Top 70th Acc: 0.3816, Bottom 30th Acc: 0.0938
Fold [5/5] Epoch [10/100] Initial Loss: 0.1372, Training Loss: 0.0355, Initial Validation Loss: 0.1335, Validation Loss: 0.0312,V Acc: 0.8611, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.6875
Fold [5/5] Epoch [20/100] Initial Loss: 0.1372, Training Loss: 0.0237, Initial Validation Loss: 0.1335, Validation Loss: 0.0253,V Acc: 0.9074, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.8125
Stopping early at Epoch (base 0): 20  Rolling back to Epoch (base 0): 15  Top Validation Acc: 0.9473684210526315
14 4 [array([0.30711794, 0.11762211, 0.21272266, 0.14284486, 0.2196924 ],
      dtype=float32)]
Running train_nn.py with seed 15
CUDA:False
Training samples count:  550
Training on 20 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1386, Training Loss: 0.1386, Initial Validation Loss: 0.1354, Validation Loss: 0.1354,V Acc: 0.2523, Top 70th Acc: 0.3333, Bottom 30th Acc: 0.0606
Fold [1/5] Epoch [10/100] Initial Loss: 0.1386, Training Loss: 0.0374, Initial Validation Loss: 0.1354, Validation Loss: 0.0475,V Acc: 0.7748, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.4545
Fold [1/5] Epoch [20/100] Initial Loss: 0.1386, Training Loss: 0.0208, Initial Validation Loss: 0.1354, Validation Loss: 0.0425,V Acc: 0.7568, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.3636
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.8974358974358975
Fold [2/5] Epoch [0/100] Initial Loss: 0.1367, Training Loss: 0.1367, Initial Validation Loss: 0.1349, Validation Loss: 0.1349,V Acc: 0.3514, Top 70th Acc: 0.3846, Bottom 30th Acc: 0.2727
Fold [2/5] Epoch [10/100] Initial Loss: 0.1367, Training Loss: 0.0415, Initial Validation Loss: 0.1349, Validation Loss: 0.0402,V Acc: 0.8559, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.6970
Fold [2/5] Epoch [20/100] Initial Loss: 0.1367, Training Loss: 0.0252, Initial Validation Loss: 0.1349, Validation Loss: 0.0256,V Acc: 0.8829, Top 70th Acc: 0.9872, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 29  Rolling back to Epoch (base 0): 24  Top Validation Acc: 0.9743589743589743
Fold [3/5] Epoch [0/100] Initial Loss: 0.1389, Training Loss: 0.1389, Initial Validation Loss: 0.1332, Validation Loss: 0.1332,V Acc: 0.3273, Top 70th Acc: 0.4026, Bottom 30th Acc: 0.1515
Fold [3/5] Epoch [10/100] Initial Loss: 0.1389, Training Loss: 0.0397, Initial Validation Loss: 0.1332, Validation Loss: 0.0466,V Acc: 0.7636, Top 70th Acc: 0.8701, Bottom 30th Acc: 0.5152
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.9605263157894737
Running train_nn.py with seed 11
CUDA:False
Training samples count:  550
Training on 163 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1387, Training Loss: 0.1387, Initial Validation Loss: 0.1372, Validation Loss: 0.1372,V Acc: 0.2613, Top 70th Acc: 0.3333, Bottom 30th Acc: 0.0909
Fold [1/5] Epoch [10/100] Initial Loss: 0.1387, Training Loss: 0.0135, Initial Validation Loss: 0.1372, Validation Loss: 0.0320,V Acc: 0.8378, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.5758
Fold [1/5] Epoch [20/100] Initial Loss: 0.1387, Training Loss: 0.0051, Initial Validation Loss: 0.1372, Validation Loss: 0.0264,V Acc: 0.8739, Top 70th Acc: 0.9872, Bottom 30th Acc: 0.6061
Fold [1/5] Epoch [30/100] Initial Loss: 0.1387, Training Loss: 0.0041, Initial Validation Loss: 0.1372, Validation Loss: 0.0254,V Acc: 0.8739, Top 70th Acc: 0.9872, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 33  Rolling back to Epoch (base 0): 28  Top Validation Acc: 0.9871794871794872
Fold [2/5] Epoch [0/100] Initial Loss: 0.1383, Training Loss: 0.1383, Initial Validation Loss: 0.1397, Validation Loss: 0.1397,V Acc: 0.2613, Top 70th Acc: 0.3590, Bottom 30th Acc: 0.0303
Fold [2/5] Epoch [10/100] Initial Loss: 0.1383, Training Loss: 0.0142, Initial Validation Loss: 0.1397, Validation Loss: 0.0346,V Acc: 0.8468, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.5758
Fold [2/5] Epoch [20/100] Initial Loss: 0.1383, Training Loss: 0.0045, Initial Validation Loss: 0.1397, Validation Loss: 0.0296,V Acc: 0.8649, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 27  Rolling back to Epoch (base 0): 22  Top Validation Acc: 0.9743589743589743
Fold [3/5] Epoch [0/100] Initial Loss: 0.1411, Training Loss: 0.1411, Initial Validation Loss: 0.1329, Validation Loss: 0.1329,V Acc: 0.3182, Top 70th Acc: 0.3896, Bottom 30th Acc: 0.1515
Fold [3/5] Epoch [10/100] Initial Loss: 0.1411, Training Loss: 0.0187, Initial Validation Loss: 0.1329, Validation Loss: 0.0345,V Acc: 0.8455, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.6667
Fold [3/5] Epoch [20/100] Initial Loss: 0.1411, Training Loss: 0.0049, Initial Validation Loss: 0.1329, Validation Loss: 0.0283,V Acc: 0.8364, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.5758
Fold [3/5] Epoch [30/100] Initial Loss: 0.1411, Training Loss: 0.0040, Initial Validation Loss: 0.1329, Validation Loss: 0.0283,V Acc: 0.8364, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 30  Rolling back to Epoch (base 0): 25  Top Validation Acc: 0.935064935064935
Fold [4/5] Epoch [0/100] Initial Loss: 0.1401, Training Loss: 0.1401, Initial Validation Loss: 0.1330, Validation Loss: 0.1330,V Acc: 0.2545, Top 70th Acc: 0.3377, Bottom 30th Acc: 0.0606
Fold [4/5] Epoch [10/100] Initial Loss: 0.1401, Training Loss: 0.0233, Initial Validation Loss: 0.1330, Validation Loss: 0.0396,V Acc: 0.8000, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.5152
Fold [4/5] Epoch [20/100] Initial Loss: 0.1401, Training Loss: 0.0068, Initial Validation Loss: 0.1330, Validation Loss: 0.0385,V Acc: 0.8000, Top 70th Acc: 0.8961, Bottom 30th Acc: 0.5758
Fold [4/5] Epoch [30/100] Initial Loss: 0.1401, Training Loss: 0.0049, Initial Validation Loss: 0.1330, Validation Loss: 0.0346,V Acc: 0.8273, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.6364
Fold [4/5] Epoch [40/100] Initial Loss: 0.1401, Training Loss: 0.0042, Initial Validation Loss: 0.1330, Validation Loss: 0.0336,V Acc: 0.8091, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.5455
Fold [4/5] Epoch [50/100] Initial Loss: 0.1401, Training Loss: 0.0038, Initial Validation Loss: 0.1330, Validation Loss: 0.0319,V Acc: 0.8182, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.5758
Fold [4/5] Epoch [60/100] Initial Loss: 0.1401, Training Loss: 0.0036, Initial Validation Loss: 0.1330, Validation Loss: 0.0314,V Acc: 0.8091, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.5455
Fold [4/5] Epoch [70/100] Initial Loss: 0.1401, Training Loss: 0.0035, Initial Validation Loss: 0.1330, Validation Loss: 0.0296,V Acc: 0.8273, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.5455
Fold [4/5] Epoch [80/100] Initial Loss: 0.1401, Training Loss: 0.0035, Initial Validation Loss: 0.1330, Validation Loss: 0.0295,V Acc: 0.8182, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.5152
Stopping early at Epoch (base 0): 83  Rolling back to Epoch (base 0): 78  Top Validation Acc: 0.935064935064935
11 3 [array([0.29441836, 0.05399966, 0.0528456 , 0.30005082, 0.29868552],
      dtype=float32)]
Fold [5/5] Epoch [0/100] Initial Loss: 0.1376, Training Loss: 0.1376, Initial Validation Loss: 0.1298, Validation Loss: 0.1298,V Acc: 0.2500, Top 70th Acc: 0.3421, Bottom 30th Acc: 0.0312
Fold [5/5] Epoch [10/100] Initial Loss: 0.1376, Training Loss: 0.0130, Initial Validation Loss: 0.1298, Validation Loss: 0.0308,V Acc: 0.8889, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.7812
Fold [5/5] Epoch [20/100] Initial Loss: 0.1376, Training Loss: 0.0044, Initial Validation Loss: 0.1298, Validation Loss: 0.0273,V Acc: 0.8981, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.8125
Stopping early at Epoch (base 0): 29  Rolling back to Epoch (base 0): 24  Top Validation Acc: 0.9473684210526315
Running train_nn.py with seed 12
CUDA:False
Training samples count:  550
Training on 163 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1403, Training Loss: 0.1403, Initial Validation Loss: 0.1317, Validation Loss: 0.1317,V Acc: 0.2793, Top 70th Acc: 0.2821, Bottom 30th Acc: 0.2727
Fold [1/5] Epoch [10/100] Initial Loss: 0.1403, Training Loss: 0.0273, Initial Validation Loss: 0.1317, Validation Loss: 0.0405,V Acc: 0.7838, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.4848
Fold [1/5] Epoch [20/100] Initial Loss: 0.1403, Training Loss: 0.0056, Initial Validation Loss: 0.1317, Validation Loss: 0.0272,V Acc: 0.8559, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 29  Rolling back to Epoch (base 0): 24  Top Validation Acc: 0.9615384615384616
Fold [2/5] Epoch [0/100] Initial Loss: 0.1389, Training Loss: 0.1389, Initial Validation Loss: 0.1350, Validation Loss: 0.1350,V Acc: 0.2703, Top 70th Acc: 0.3333, Bottom 30th Acc: 0.1212
Fold [2/5] Epoch [10/100] Initial Loss: 0.1389, Training Loss: 0.0166, Initial Validation Loss: 0.1350, Validation Loss: 0.0312,V Acc: 0.8829, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.6667
Fold [2/5] Epoch [20/100] Initial Loss: 0.1389, Training Loss: 0.0047, Initial Validation Loss: 0.1350, Validation Loss: 0.0261,V Acc: 0.8919, Top 70th Acc: 0.9872, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 29  Rolling back to Epoch (base 0): 24  Top Validation Acc: 0.9743589743589743
Fold [3/5] Epoch [0/100] Initial Loss: 0.1378, Training Loss: 0.1378, Initial Validation Loss: 0.1352, Validation Loss: 0.1352,V Acc: 0.2909, Top 70th Acc: 0.3636, Bottom 30th Acc: 0.1212
Fold [3/5] Epoch [10/100] Initial Loss: 0.1378, Training Loss: 0.0181, Initial Validation Loss: 0.1352, Validation Loss: 0.0376,V Acc: 0.7909, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.5152
Fold [3/5] Epoch [20/100] Initial Loss: 0.1378, Training Loss: 0.0060, Initial Validation Loss: 0.1352, Validation Loss: 0.0325,V Acc: 0.8364, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.6061
Fold [3/5] Epoch [30/100] Initial Loss: 0.1378, Training Loss: 0.0046, Initial Validation Loss: 0.1352, Validation Loss: 0.0316,V Acc: 0.8545, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.6667
Fold [3/5] Epoch [40/100] Initial Loss: 0.1378, Training Loss: 0.0041, Initial Validation Loss: 0.1352, Validation Loss: 0.0306,V Acc: 0.8455, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6061
Fold [3/5] Epoch [50/100] Initial Loss: 0.1378, Training Loss: 0.0039, Initial Validation Loss: 0.1352, Validation Loss: 0.0301,V Acc: 0.8364, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 59  Rolling back to Epoch (base 0): 54  Top Validation Acc: 0.948051948051948
Fold [4/5] Epoch [0/100] Initial Loss: 0.1413, Training Loss: 0.1413, Initial Validation Loss: 0.1330, Validation Loss: 0.1330,V Acc: 0.3545, Top 70th Acc: 0.4935, Bottom 30th Acc: 0.0303
Fold [4/5] Epoch [10/100] Initial Loss: 0.1413, Training Loss: 0.0199, Initial Validation Loss: 0.1330, Validation Loss: 0.0368,V Acc: 0.8455, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.6667
Fold [2/5] Epoch [10/100] Initial Loss: 0.1381, Training Loss: 0.0326, Initial Validation Loss: 0.1329, Validation Loss: 0.0371,V Acc: 0.8288, Top 70th Acc: 0.8974, Bottom 30th Acc: 0.6667
Fold [2/5] Epoch [20/100] Initial Loss: 0.1381, Training Loss: 0.0177, Initial Validation Loss: 0.1329, Validation Loss: 0.0296,V Acc: 0.8288, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.6061
Fold [2/5] Epoch [30/100] Initial Loss: 0.1381, Training Loss: 0.0148, Initial Validation Loss: 0.1329, Validation Loss: 0.0284,V Acc: 0.8468, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 38  Rolling back to Epoch (base 0): 33  Top Validation Acc: 0.9358974358974359
Fold [3/5] Epoch [0/100] Initial Loss: 0.1398, Training Loss: 0.1398, Initial Validation Loss: 0.1351, Validation Loss: 0.1351,V Acc: 0.4364, Top 70th Acc: 0.5195, Bottom 30th Acc: 0.2424
Fold [3/5] Epoch [10/100] Initial Loss: 0.1398, Training Loss: 0.0340, Initial Validation Loss: 0.1351, Validation Loss: 0.0366,V Acc: 0.8545, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.6061
Fold [3/5] Epoch [20/100] Initial Loss: 0.1398, Training Loss: 0.0212, Initial Validation Loss: 0.1351, Validation Loss: 0.0290,V Acc: 0.8636, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.6061
Fold [3/5] Epoch [30/100] Initial Loss: 0.1398, Training Loss: 0.0162, Initial Validation Loss: 0.1351, Validation Loss: 0.0288,V Acc: 0.8636, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 33  Rolling back to Epoch (base 0): 28  Top Validation Acc: 0.961038961038961
Fold [4/5] Epoch [0/100] Initial Loss: 0.1439, Training Loss: 0.1439, Initial Validation Loss: 0.1300, Validation Loss: 0.1300,V Acc: 0.3636, Top 70th Acc: 0.3896, Bottom 30th Acc: 0.3030
Fold [4/5] Epoch [10/100] Initial Loss: 0.1439, Training Loss: 0.0432, Initial Validation Loss: 0.1300, Validation Loss: 0.0551,V Acc: 0.7636, Top 70th Acc: 0.8312, Bottom 30th Acc: 0.6061
Fold [4/5] Epoch [20/100] Initial Loss: 0.1439, Training Loss: 0.0182, Initial Validation Loss: 0.1300, Validation Loss: 0.0388,V Acc: 0.8091, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.5455
Fold [4/5] Epoch [30/100] Initial Loss: 0.1439, Training Loss: 0.0153, Initial Validation Loss: 0.1300, Validation Loss: 0.0375,V Acc: 0.8364, Top 70th Acc: 0.8961, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 30  Rolling back to Epoch (base 0): 25  Top Validation Acc: 0.8961038961038961
Fold [5/5] Epoch [0/100] Initial Loss: 0.1361, Training Loss: 0.1361, Initial Validation Loss: 0.1322, Validation Loss: 0.1322,V Acc: 0.3611, Top 70th Acc: 0.4474, Bottom 30th Acc: 0.1562
Fold [5/5] Epoch [10/100] Initial Loss: 0.1361, Training Loss: 0.0282, Initial Validation Loss: 0.1322, Validation Loss: 0.0356,V Acc: 0.8333, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.5938
Fold [5/5] Epoch [20/100] Initial Loss: 0.1361, Training Loss: 0.0176, Initial Validation Loss: 0.1322, Validation Loss: 0.0307,V Acc: 0.8333, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.5312
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.9605263157894737
13 4 [array([0.47966248, 0.08625913, 0.05802479, 0.13400593, 0.24204774],
      dtype=float32)]
Running train_nn.py with seed 14
CUDA:False
Training samples count:  550
Training on 30 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1382, Training Loss: 0.1382, Initial Validation Loss: 0.1358, Validation Loss: 0.1358,V Acc: 0.2523, Top 70th Acc: 0.2949, Bottom 30th Acc: 0.1515
Fold [1/5] Epoch [10/100] Initial Loss: 0.1382, Training Loss: 0.0445, Initial Validation Loss: 0.1358, Validation Loss: 0.0491,V Acc: 0.7838, Top 70th Acc: 0.8718, Bottom 30th Acc: 0.5758
Fold [1/5] Epoch [20/100] Initial Loss: 0.1382, Training Loss: 0.0204, Initial Validation Loss: 0.1358, Validation Loss: 0.0310,V Acc: 0.8468, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.6667
Fold [1/5] Epoch [30/100] Initial Loss: 0.1382, Training Loss: 0.0178, Initial Validation Loss: 0.1358, Validation Loss: 0.0288,V Acc: 0.8559, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 33  Rolling back to Epoch (base 0): 28  Top Validation Acc: 0.9487179487179487
Fold [2/5] Epoch [0/100] Initial Loss: 0.1388, Training Loss: 0.1388, Initial Validation Loss: 0.1363, Validation Loss: 0.1363,V Acc: 0.2883, Top 70th Acc: 0.3590, Bottom 30th Acc: 0.1212
Fold [2/5] Epoch [10/100] Initial Loss: 0.1388, Training Loss: 0.0311, Initial Validation Loss: 0.1363, Validation Loss: 0.0446,V Acc: 0.7838, Top 70th Acc: 0.8718, Bottom 30th Acc: 0.5758
Fold [2/5] Epoch [20/100] Initial Loss: 0.1388, Training Loss: 0.0182, Initial Validation Loss: 0.1363, Validation Loss: 0.0402,V Acc: 0.7748, Top 70th Acc: 0.8846, Bottom 30th Acc: 0.5152
Fold [2/5] Epoch [30/100] Initial Loss: 0.1388, Training Loss: 0.0158, Initial Validation Loss: 0.1363, Validation Loss: 0.0395,V Acc: 0.7568, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.3939
Stopping early at Epoch (base 0): 32  Rolling back to Epoch (base 0): 27  Top Validation Acc: 0.8846153846153846
Fold [3/5] Epoch [0/100] Initial Loss: 0.1367, Training Loss: 0.1367, Initial Validation Loss: 0.1343, Validation Loss: 0.1343,V Acc: 0.3091, Top 70th Acc: 0.3636, Bottom 30th Acc: 0.1818
Fold [3/5] Epoch [10/100] Initial Loss: 0.1367, Training Loss: 0.0383, Initial Validation Loss: 0.1343, Validation Loss: 0.0406,V Acc: 0.8455, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6061
Fold [3/5] Epoch [20/100] Initial Loss: 0.1367, Training Loss: 0.0189, Initial Validation Loss: 0.1343, Validation Loss: 0.0358,V Acc: 0.8364, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 20  Rolling back to Epoch (base 0): 15  Top Validation Acc: 0.948051948051948
Fold [4/5] Epoch [0/100] Initial Loss: 0.1453, Training Loss: 0.1453, Initial Validation Loss: 0.1332, Validation Loss: 0.1332,V Acc: 0.2273, Top 70th Acc: 0.1688, Bottom 30th Acc: 0.3636
Fold [4/5] Epoch [10/100] Initial Loss: 0.1453, Training Loss: 0.0364, Initial Validation Loss: 0.1332, Validation Loss: 0.0411,V Acc: 0.8091, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.5758
Fold [4/5] Epoch [20/100] Initial Loss: 0.1453, Training Loss: 0.0180, Initial Validation Loss: 0.1332, Validation Loss: 0.0331,V Acc: 0.8091, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.4848
Stopping early at Epoch (base 0): 20  Rolling back to Epoch (base 0): 15  Top Validation Acc: 0.948051948051948
Fold [5/5] Epoch [0/100] Initial Loss: 0.1373, Training Loss: 0.1373, Initial Validation Loss: 0.1343, Validation Loss: 0.1343,V Acc: 0.2870, Top 70th Acc: 0.3553, Bottom 30th Acc: 0.1250
Fold [5/5] Epoch [10/100] Initial Loss: 0.1373, Training Loss: 0.0349, Initial Validation Loss: 0.1343, Validation Loss: 0.0334,V Acc: 0.8519, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.5938
Fold [5/5] Epoch [20/100] Initial Loss: 0.1373, Training Loss: 0.0197, Initial Validation Loss: 0.1343, Validation Loss: 0.0250,V Acc: 0.8704, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.6562
Fold [5/5] Epoch [30/100] Initial Loss: 0.1373, Training Loss: 0.0174, Initial Validation Loss: 0.1343, Validation Loss: 0.0232,V Acc: 0.8796, Top 70th Acc: 0.9737, Bottom 30th Acc: 0.6562
Stopping early at Epoch (base 0): 34  Rolling back to Epoch (base 0): 29  Top Validation Acc: 0.9605263157894737
14 4 [array([0.78456527, 0.05633949, 0.01698143, 0.05002818, 0.09208568],
      dtype=float32)]
Running train_nn.py with seed 15
CUDA:False
Training samples count:  550
Training on 30 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1399, Training Loss: 0.1399, Initial Validation Loss: 0.1344, Validation Loss: 0.1344,V Acc: 0.3874, Top 70th Acc: 0.4872, Bottom 30th Acc: 0.1515
Fold [1/5] Epoch [10/100] Initial Loss: 0.1399, Training Loss: 0.0269, Initial Validation Loss: 0.1344, Validation Loss: 0.0453,V Acc: 0.7568, Top 70th Acc: 0.8718, Bottom 30th Acc: 0.4848
Stopping early at Epoch (base 0): 19  Rolling back to Epoch (base 0): 14  Top Validation Acc: 0.9102564102564102
Fold [2/5] Epoch [0/100] Initial Loss: 0.1377, Training Loss: 0.1377, Initial Validation Loss: 0.1355, Validation Loss: 0.1355,V Acc: 0.2793, Top 70th Acc: 0.3205, Bottom 30th Acc: 0.1818
Fold [2/5] Epoch [10/100] Initial Loss: 0.1377, Training Loss: 0.0373, Initial Validation Loss: 0.1355, Validation Loss: 0.0391,V Acc: 0.8378, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.5455/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
 0.9743589743589743
Fold [2/5] Epoch [0/100] Initial Loss: 0.1409, Training Loss: 0.1409, Initial Validation Loss: 0.1314, Validation Loss: 0.1314,V Acc: 0.3514, Top 70th Acc: 0.3846, Bottom 30th Acc: 0.2727
Fold [2/5] Epoch [10/100] Initial Loss: 0.1409, Training Loss: 0.0291, Initial Validation Loss: 0.1314, Validation Loss: 0.0374,V Acc: 0.8018, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 18  Rolling back to Epoch (base 0): 13  Top Validation Acc: 0.9102564102564102
Fold [3/5] Epoch [0/100] Initial Loss: 0.1355, Training Loss: 0.1355, Initial Validation Loss: 0.1330, Validation Loss: 0.1330,V Acc: 0.4000, Top 70th Acc: 0.4805, Bottom 30th Acc: 0.2121
Fold [3/5] Epoch [10/100] Initial Loss: 0.1355, Training Loss: 0.0262, Initial Validation Loss: 0.1330, Validation Loss: 0.0375,V Acc: 0.8182, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.5455
Fold [3/5] Epoch [20/100] Initial Loss: 0.1355, Training Loss: 0.0131, Initial Validation Loss: 0.1330, Validation Loss: 0.0340,V Acc: 0.8273, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.5152
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.974025974025974
Fold [4/5] Epoch [0/100] Initial Loss: 0.1405, Training Loss: 0.1405, Initial Validation Loss: 0.1296, Validation Loss: 0.1296,V Acc: 0.3273, Top 70th Acc: 0.3636, Bottom 30th Acc: 0.2424
Fold [4/5] Epoch [10/100] Initial Loss: 0.1405, Training Loss: 0.0304, Initial Validation Loss: 0.1296, Validation Loss: 0.0428,V Acc: 0.7909, Top 70th Acc: 0.8961, Bottom 30th Acc: 0.5455
Fold [4/5] Epoch [20/100] Initial Loss: 0.1405, Training Loss: 0.0139, Initial Validation Loss: 0.1296, Validation Loss: 0.0358,V Acc: 0.8091, Top 70th Acc: 0.8961, Bottom 30th Acc: 0.6061
Fold [4/5] Epoch [30/100] Initial Loss: 0.1405, Training Loss: 0.0113, Initial Validation Loss: 0.1296, Validation Loss: 0.0348,V Acc: 0.8091, Top 70th Acc: 0.8961, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 33  Rolling back to Epoch (base 0): 28  Top Validation Acc: 0.9090909090909091
Fold [5/5] Epoch [0/100] Initial Loss: 0.1407, Training Loss: 0.1407, Initial Validation Loss: 0.1360, Validation Loss: 0.1360,V Acc: 0.2500, Top 70th Acc: 0.3158, Bottom 30th Acc: 0.0938
Fold [5/5] Epoch [10/100] Initial Loss: 0.1407, Training Loss: 0.0448, Initial Validation Loss: 0.1360, Validation Loss: 0.0512,V Acc: 0.7593, Top 70th Acc: 0.8553, Bottom 30th Acc: 0.5312
Fold [5/5] Epoch [20/100] Initial Loss: 0.1407, Training Loss: 0.0174, Initial Validation Loss: 0.1360, Validation Loss: 0.0327,V Acc: 0.8333, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.5625
Fold [5/5] Epoch [30/100] Initial Loss: 0.1407, Training Loss: 0.0130, Initial Validation Loss: 0.1360, Validation Loss: 0.0311,V Acc: 0.8519, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.6250
Stopping early at Epoch (base 0): 33  Rolling back to Epoch (base 0): 28  Top Validation Acc: 0.9473684210526315
13 4 [array([0.47904527, 0.07448846, 0.11056716, 0.11523049, 0.22066864],
      dtype=float32)]
Running train_nn.py with seed 14
CUDA:False
Training samples count:  550
Training on 40 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1388, Training Loss: 0.1388, Initial Validation Loss: 0.1351, Validation Loss: 0.1351,V Acc: 0.2523, Top 70th Acc: 0.3205, Bottom 30th Acc: 0.0909
Fold [1/5] Epoch [10/100] Initial Loss: 0.1388, Training Loss: 0.0364, Initial Validation Loss: 0.1351, Validation Loss: 0.0381,V Acc: 0.8468, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.6667
Fold [1/5] Epoch [20/100] Initial Loss: 0.1388, Training Loss: 0.0155, Initial Validation Loss: 0.1351, Validation Loss: 0.0265,V Acc: 0.8739, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.6667
Fold [1/5] Epoch [30/100] Initial Loss: 0.1388, Training Loss: 0.0128, Initial Validation Loss: 0.1351, Validation Loss: 0.0250,V Acc: 0.8739, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 32  Rolling back to Epoch (base 0): 27  Top Validation Acc: 0.9615384615384616
Fold [2/5] Epoch [0/100] Initial Loss: 0.1383, Training Loss: 0.1383, Initial Validation Loss: 0.1346, Validation Loss: 0.1346,V Acc: 0.2703, Top 70th Acc: 0.3205, Bottom 30th Acc: 0.1515
Fold [2/5] Epoch [10/100] Initial Loss: 0.1383, Training Loss: 0.0354, Initial Validation Loss: 0.1346, Validation Loss: 0.0535,V Acc: 0.7117, Top 70th Acc: 0.7949, Bottom 30th Acc: 0.5152
Fold [2/5] Epoch [20/100] Initial Loss: 0.1383, Training Loss: 0.0171, Initial Validation Loss: 0.1346, Validation Loss: 0.0441,V Acc: 0.7568, Top 70th Acc: 0.8718, Bottom 30th Acc: 0.4848
Fold [2/5] Epoch [30/100] Initial Loss: 0.1383, Training Loss: 0.0120, Initial Validation Loss: 0.1346, Validation Loss: 0.0381,V Acc: 0.7658, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.3939
Stopping early at Epoch (base 0): 39  Rolling back to Epoch (base 0): 34  Top Validation Acc: 0.9230769230769231
Fold [3/5] Epoch [0/100] Initial Loss: 0.1416, Training Loss: 0.1416, Initial Validation Loss: 0.1357, Validation Loss: 0.1357,V Acc: 0.2636, Top 70th Acc: 0.3377, Bottom 30th Acc: 0.0909
Fold [3/5] Epoch [10/100] Initial Loss: 0.1416, Training Loss: 0.0345, Initial Validation Loss: 0.1357, Validation Loss: 0.0438,V Acc: 0.8364, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.6667
Fold [3/5] Epoch [20/100] Initial Loss: 0.1416, Training Loss: 0.0143, Initial Validation Loss: 0.1357, Validation Loss: 0.0309,V Acc: 0.8455, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 22  Rolling back to Epoch (base 0): 17  Top Validation Acc: 0.961038961038961
Fold [4/5] Epoch [0/100] Initial Loss: 0.1388, Training Loss: 0.1388, Initial Validation Loss: 0.1272, Validation Loss: 0.1272,V Acc: 0.4091, Top 70th Acc: 0.4545, Bottom 30th Acc: 0.3030
Fold [4/5] Epoch [10/100] Initial Loss: 0.1388, Training Loss: 0.0371, Initial Validation Loss: 0.1272, Validation Loss: 0.0441,V Acc: 0.8000, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.5455
Fold [4/5] Epoch [20/100] Initial Loss: 0.1388, Training Loss: 0.0132, Initial Validation Loss: 0.1272, Validation Loss: 0.0295,V Acc: 0.8273, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.5152
Stopping early at Epoch (base 0): 29  Rolling back to Epoch (base 0): 24  Top Validation Acc: 0.922077922077922
Fold [5/5] Epoch [0/100] Initial Loss: 0.1409, Training Loss: 0.1409, Initial Validation Loss: 0.1368, Validation Loss: 0.1368,V Acc: 0.3056, Top 70th Acc: 0.2895, Bottom 30th Acc: 0.3438
Fold [5/5] Epoch [10/100] Initial Loss: 0.1409, Training Loss: 0.0366, Initial Validation Loss: 0.1368, Validation Loss: 0.0351,V Acc: 0.8796, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.7500
Fold [5/5] Epoch [20/100] Initial Loss: 0.1409, Training Loss: 0.0145, Initial Validation Loss: 0.1368, Validation Loss: 0.0226,V Acc: 0.8889, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.7188
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.9605263157894737
14 4 [array([0.5687211 , 0.0674179 , 0.07415838, 0.11085909, 0.17884354],
      dtype=float32)]
Running train_nn.py with seed 15
CUDA:False
Training samples count:  550
Training on 40 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1379, Training Loss: 0.1379, Initial Validation Loss: 0.1354, Validation Loss: 0.1354,V Acc: 0.2523, Top 70th Acc: 0.3333, Bottom 30th Acc: 0.0606
Fold [1/5] Epoch [10/100] Initial Loss: 0.1379, Training Loss: 0.0352, Initial Validation Loss: 0.1354, Validation Loss: 0.0498,V Acc: 0.7297, Top 70th Acc: 0.8205, Bottom 30th Acc: 0.5152
Fold [1/5] Epoch [20/100] Initial Loss: 0.1379, Training Loss: 0.0137, Initial Validation Loss: 0.1354, Validation Loss: 0.0396,V Acc: 0.7658, Top 70th Acc: 0.8974, Bottom 30th Acc: 0.4545
Fold [1/5] Epoch [30/100] Initial Loss: 0.1379, Training Loss: 0.0106, Initial Validation Loss: 0.1354, Validation Loss: 0.0394,V Acc: 0.7658, Top 70th Acc: 0.8846, Bottom 30th Acc: 0.4848
Stopping early at Epoch (base 0): 32  Rolling back to Epoch (base 0): 27  Top Validation Acc: 0.8846153846153846
Fold [2/5] Epoch [0/100] Initial Loss: 0.1409, Training Loss: 0.1409, Initial Validation Loss: 0.1372, Validation Loss: 0.1372,V Acc: 0.3153, Top 70th Acc: 0.3205, Bottom 30th Acc: 0.3030
Fold [2/5] Epoch [10/100] Initial Loss: 0.1409, Training Loss: 0.0322, Initial Validation Loss: 0.1372, Validation Loss: 0.0333,V Acc: 0.8649, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.6061/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)

Fold [1/5] Epoch [10/100] Initial Loss: 0.1383, Training Loss: 0.0311, Initial Validation Loss: 0.1325, Validation Loss: 0.0298,V Acc: 0.8559, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.6364
Fold [1/5] Epoch [20/100] Initial Loss: 0.1383, Training Loss: 0.0185, Initial Validation Loss: 0.1325, Validation Loss: 0.0249,V Acc: 0.8829, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.6970
Fold [1/5] Epoch [30/100] Initial Loss: 0.1383, Training Loss: 0.0181, Initial Validation Loss: 0.1325, Validation Loss: 0.0240,V Acc: 0.8919, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.7273
Stopping early at Epoch (base 0): 39  Rolling back to Epoch (base 0): 34  Top Validation Acc: 0.9615384615384616
Fold [2/5] Epoch [0/100] Initial Loss: 0.1364, Training Loss: 0.1364, Initial Validation Loss: 0.1232, Validation Loss: 0.1232,V Acc: 0.4144, Top 70th Acc: 0.5513, Bottom 30th Acc: 0.0909
Fold [2/5] Epoch [10/100] Initial Loss: 0.1364, Training Loss: 0.0255, Initial Validation Loss: 0.1232, Validation Loss: 0.0359,V Acc: 0.8108, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.4545
Fold [2/5] Epoch [20/100] Initial Loss: 0.1364, Training Loss: 0.0172, Initial Validation Loss: 0.1232, Validation Loss: 0.0371,V Acc: 0.8378, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.9487179487179487
Fold [3/5] Epoch [0/100] Initial Loss: 0.1318, Training Loss: 0.1318, Initial Validation Loss: 0.1224, Validation Loss: 0.1224,V Acc: 0.4364, Top 70th Acc: 0.5195, Bottom 30th Acc: 0.2424
Fold [3/5] Epoch [10/100] Initial Loss: 0.1318, Training Loss: 0.0246, Initial Validation Loss: 0.1224, Validation Loss: 0.0322,V Acc: 0.8455, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.6667
Fold [3/5] Epoch [20/100] Initial Loss: 0.1318, Training Loss: 0.0184, Initial Validation Loss: 0.1224, Validation Loss: 0.0363,V Acc: 0.8182, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 20  Rolling back to Epoch (base 0): 15  Top Validation Acc: 0.935064935064935
21 2 [array([0.7495374 , 0.04367904, 0.02615636, 0.06156556, 0.11906164],
      dtype=float32)]
Fold [4/5] Epoch [0/100] Initial Loss: 0.1307, Training Loss: 0.1307, Initial Validation Loss: 0.1181, Validation Loss: 0.1181,V Acc: 0.4545, Top 70th Acc: 0.5584, Bottom 30th Acc: 0.2121
Fold [4/5] Epoch [10/100] Initial Loss: 0.1307, Training Loss: 0.0247, Initial Validation Loss: 0.1181, Validation Loss: 0.0280,V Acc: 0.8636, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 19  Rolling back to Epoch (base 0): 14  Top Validation Acc: 0.9090909090909091
Fold [5/5] Epoch [0/100] Initial Loss: 0.1376, Training Loss: 0.1376, Initial Validation Loss: 0.1202, Validation Loss: 0.1202,V Acc: 0.5093, Top 70th Acc: 0.5789, Bottom 30th Acc: 0.3438
Fold [5/5] Epoch [10/100] Initial Loss: 0.1376, Training Loss: 0.0281, Initial Validation Loss: 0.1202, Validation Loss: 0.0271,V Acc: 0.8704, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.6562
Fold [5/5] Epoch [20/100] Initial Loss: 0.1376, Training Loss: 0.0196, Initial Validation Loss: 0.1202, Validation Loss: 0.0245,V Acc: 0.8704, Top 70th Acc: 0.9868, Bottom 30th Acc: 0.5938
Fold [5/5] Epoch [30/100] Initial Loss: 0.1376, Training Loss: 0.0188, Initial Validation Loss: 0.1202, Validation Loss: 0.0248,V Acc: 0.8611, Top 70th Acc: 0.9737, Bottom 30th Acc: 0.5938
Stopping early at Epoch (base 0): 30  Rolling back to Epoch (base 0): 25  Top Validation Acc: 0.9736842105263158
Running train_nn.py with seed 22
CUDA:False
Training samples count:  550
Training on 21 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1369, Training Loss: 0.1369, Initial Validation Loss: 0.1184, Validation Loss: 0.1184,V Acc: 0.5405, Top 70th Acc: 0.5769, Bottom 30th Acc: 0.4545
Fold [1/5] Epoch [10/100] Initial Loss: 0.1369, Training Loss: 0.0253, Initial Validation Loss: 0.1184, Validation Loss: 0.0320,V Acc: 0.8468, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.6970
Fold [1/5] Epoch [20/100] Initial Loss: 0.1369, Training Loss: 0.0165, Initial Validation Loss: 0.1184, Validation Loss: 0.0309,V Acc: 0.8468, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 22  Rolling back to Epoch (base 0): 17  Top Validation Acc: 0.9358974358974359
Fold [2/5] Epoch [0/100] Initial Loss: 0.1326, Training Loss: 0.1326, Initial Validation Loss: 0.1176, Validation Loss: 0.1176,V Acc: 0.4775, Top 70th Acc: 0.5897, Bottom 30th Acc: 0.2121
Fold [2/5] Epoch [10/100] Initial Loss: 0.1326, Training Loss: 0.0256, Initial Validation Loss: 0.1176, Validation Loss: 0.0200,V Acc: 0.9099, Top 70th Acc: 1.0000, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 16  Rolling back to Epoch (base 0): 11  Top Validation Acc: 0.9871794871794872
Fold [3/5] Epoch [0/100] Initial Loss: 0.1351, Training Loss: 0.1351, Initial Validation Loss: 0.1285, Validation Loss: 0.1285,V Acc: 0.3818, Top 70th Acc: 0.3766, Bottom 30th Acc: 0.3939
Fold [3/5] Epoch [10/100] Initial Loss: 0.1351, Training Loss: 0.0235, Initial Validation Loss: 0.1285, Validation Loss: 0.0306,V Acc: 0.8545, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.5758
Fold [3/5] Epoch [20/100] Initial Loss: 0.1351, Training Loss: 0.0171, Initial Validation Loss: 0.1285, Validation Loss: 0.0255,V Acc: 0.9000, Top 70th Acc: 0.9870, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.974025974025974
Fold [4/5] Epoch [0/100] Initial Loss: 0.1281, Training Loss: 0.1281, Initial Validation Loss: 0.1147, Validation Loss: 0.1147,V Acc: 0.4727, Top 70th Acc: 0.6104, Bottom 30th Acc: 0.1515
Fold [4/5] Epoch [10/100] Initial Loss: 0.1281, Training Loss: 0.0215, Initial Validation Loss: 0.1147, Validation Loss: 0.0360,V Acc: 0.8636, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.7273
Stopping early at Epoch (base 0): 14  Rolling back to Epoch (base 0): 9  Top Validation Acc: 0.9090909090909091
Fold [5/5] Epoch [0/100] Initial Loss: 0.1289, Training Loss: 0.1289, Initial Validation Loss: 0.1199, Validation Loss: 0.1199,V Acc: 0.4444, Top 70th Acc: 0.5789, Bottom 30th Acc: 0.1250
Fold [5/5] Epoch [10/100] Initial Loss: 0.1289, Training Loss: 0.0289, Initial Validation Loss: 0.1199, Validation Loss: 0.0355,V Acc: 0.8148, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.4688
Fold [5/5] Epoch [20/100] Initial Loss: 0.1289, Training Loss: 0.0181, Initial Validation Loss: 0.1199, Validation Loss: 0.0285,V Acc: 0.8981, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.7500
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.9736842105263158
22 4 [array([0.81003225, 0.020323  , 0.02003915, 0.07198668, 0.07761896],
      dtype=float32)]
Running train_nn.py with seed 23
CUDA:False
Training samples count:  550
Training on 21 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1251, Training Loss: 0.1251, Initial Validation Loss: 0.1065, Validation Loss: 0.1065,V Acc: 0.5946, Top 70th Acc: 0.6923, Bottom 30th Acc: 0.3636
Fold [1/5] Epoch [10/100] Initial Loss: 0.1251, Training Loss: 0.0245, Initial Validation Loss: 0.1065, Validation Loss: 0.0376,V Acc: 0.8378, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.6667
Fold [1/5] Epoch [20/100] Initial Loss: 0.1251, Training Loss: 0.0157, Initial Validation Loss: 0.1065, Validation Loss: 0.0282,V Acc: 0.8468, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 22  Rolling back to Epoch (base 0): 17  Top Validation Acc: 0.9358974358974359
Fold [2/5] Epoch [0/100] Initial Loss: 0.1370, Training Loss: 0.1370, Initial Validation Loss: 0.1317, Validation Loss: 0.1317,V Acc: 0.3694, Top 70th Acc: 0.4487, Bottom 30th Acc: 0.1818
Fold [2/5] Epoch [10/100] Initial Loss: 0.1370, Training Loss: 0.0201, Initial Validation Loss: 0.1317, Validation Loss: 0.0324,V Acc: 0.8649, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.7273
Stopping early at Epoch (base 0): 17  Rolling back to Epoch (base 0): 12  Top Validation Acc: 0.9358974358974359
Fold [3/5] Epoch [0/100] Initial Loss: 0.1324, Training Loss: 0.1324, Initial Validation Loss: 0.1163, Validation Loss: 0.1163,V Acc: 0.4818, Top 70th Acc: 0.5584, Bottom 30th Acc: 0.3030
Fold [3/5] Epoch [10/100] Initial Loss: 0.1324, Training Loss: 0.0260, Initial Validation Loss: 0.1163, Validation Loss: 0.0315,V Acc: 0.8636, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.6061/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)

Fold [3/5] Epoch [10/100] Initial Loss: 0.1284, Training Loss: 0.0805, Initial Validation Loss: 0.1194, Validation Loss: 0.0787,V Acc: 0.6545, Top 70th Acc: 0.7662, Bottom 30th Acc: 0.3939
Fold [3/5] Epoch [20/100] Initial Loss: 0.1284, Training Loss: 0.0790, Initial Validation Loss: 0.1194, Validation Loss: 0.0771,V Acc: 0.6727, Top 70th Acc: 0.7662, Bottom 30th Acc: 0.4545
Fold [3/5] Epoch [30/100] Initial Loss: 0.1284, Training Loss: 0.0786, Initial Validation Loss: 0.1194, Validation Loss: 0.0767,V Acc: 0.6636, Top 70th Acc: 0.7662, Bottom 30th Acc: 0.4242
Stopping early at Epoch (base 0): 32  Rolling back to Epoch (base 0): 27  Top Validation Acc: 0.7532467532467533
Fold [4/5] Epoch [0/100] Initial Loss: 0.1412, Training Loss: 0.1412, Initial Validation Loss: 0.1290, Validation Loss: 0.1290,V Acc: 0.3909, Top 70th Acc: 0.4416, Bottom 30th Acc: 0.2727
Fold [4/5] Epoch [10/100] Initial Loss: 0.1412, Training Loss: 0.0818, Initial Validation Loss: 0.1290, Validation Loss: 0.0800,V Acc: 0.5909, Top 70th Acc: 0.7403, Bottom 30th Acc: 0.2424
Fold [4/5] Epoch [20/100] Initial Loss: 0.1412, Training Loss: 0.0794, Initial Validation Loss: 0.1290, Validation Loss: 0.0789,V Acc: 0.6182, Top 70th Acc: 0.7532, Bottom 30th Acc: 0.3030
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.7532467532467533
Fold [5/5] Epoch [0/100] Initial Loss: 0.1373, Training Loss: 0.1373, Initial Validation Loss: 0.1330, Validation Loss: 0.1330,V Acc: 0.3704, Top 70th Acc: 0.3947, Bottom 30th Acc: 0.3125
Fold [5/5] Epoch [10/100] Initial Loss: 0.1373, Training Loss: 0.0812, Initial Validation Loss: 0.1330, Validation Loss: 0.0806,V Acc: 0.6019, Top 70th Acc: 0.7105, Bottom 30th Acc: 0.3438
Fold [5/5] Epoch [20/100] Initial Loss: 0.1373, Training Loss: 0.0788, Initial Validation Loss: 0.1330, Validation Loss: 0.0783,V Acc: 0.6204, Top 70th Acc: 0.7105, Bottom 30th Acc: 0.4062
Fold [5/5] Epoch [30/100] Initial Loss: 0.1373, Training Loss: 0.0781, Initial Validation Loss: 0.1330, Validation Loss: 0.0778,V Acc: 0.6111, Top 70th Acc: 0.6974, Bottom 30th Acc: 0.4062
Fold [5/5] Epoch [40/100] Initial Loss: 0.1373, Training Loss: 0.0779, Initial Validation Loss: 0.1330, Validation Loss: 0.0772,V Acc: 0.6111, Top 70th Acc: 0.6974, Bottom 30th Acc: 0.4062
Stopping early at Epoch (base 0): 43  Rolling back to Epoch (base 0): 38  Top Validation Acc: 0.7105263157894737
14 4 [array([0.1806941 , 0.36257634, 0.12258929, 0.22076389, 0.11337631],
      dtype=float32)]
Running train_nn.py with seed 15
CUDA:False
Training samples count:  550
Training on 2 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1356, Training Loss: 0.1356, Initial Validation Loss: 0.1270, Validation Loss: 0.1270,V Acc: 0.4054, Top 70th Acc: 0.5256, Bottom 30th Acc: 0.1212
Fold [1/5] Epoch [10/100] Initial Loss: 0.1356, Training Loss: 0.0801, Initial Validation Loss: 0.1270, Validation Loss: 0.0837,V Acc: 0.6036, Top 70th Acc: 0.7051, Bottom 30th Acc: 0.3636
Stopping early at Epoch (base 0): 19  Rolling back to Epoch (base 0): 14  Top Validation Acc: 0.6666666666666666
Fold [2/5] Epoch [0/100] Initial Loss: 0.1397, Training Loss: 0.1397, Initial Validation Loss: 0.1351, Validation Loss: 0.1351,V Acc: 0.2613, Top 70th Acc: 0.3333, Bottom 30th Acc: 0.0909
Fold [2/5] Epoch [10/100] Initial Loss: 0.1397, Training Loss: 0.0826, Initial Validation Loss: 0.1351, Validation Loss: 0.0741,V Acc: 0.6757, Top 70th Acc: 0.7949, Bottom 30th Acc: 0.3939
Fold [2/5] Epoch [20/100] Initial Loss: 0.1397, Training Loss: 0.0805, Initial Validation Loss: 0.1351, Validation Loss: 0.0712,V Acc: 0.6757, Top 70th Acc: 0.7949, Bottom 30th Acc: 0.3939
Fold [2/5] Epoch [30/100] Initial Loss: 0.1397, Training Loss: 0.0796, Initial Validation Loss: 0.1351, Validation Loss: 0.0703,V Acc: 0.6847, Top 70th Acc: 0.7821, Bottom 30th Acc: 0.4545
Stopping early at Epoch (base 0): 38  Rolling back to Epoch (base 0): 33  Top Validation Acc: 0.8333333333333334
Fold [3/5] Epoch [0/100] Initial Loss: 0.1361, Training Loss: 0.1361, Initial Validation Loss: 0.1300, Validation Loss: 0.1300,V Acc: 0.4182, Top 70th Acc: 0.4416, Bottom 30th Acc: 0.3636
Fold [3/5] Epoch [10/100] Initial Loss: 0.1361, Training Loss: 0.0804, Initial Validation Loss: 0.1300, Validation Loss: 0.0822,V Acc: 0.6364, Top 70th Acc: 0.7532, Bottom 30th Acc: 0.3636
Fold [3/5] Epoch [20/100] Initial Loss: 0.1361, Training Loss: 0.0784, Initial Validation Loss: 0.1300, Validation Loss: 0.0805,V Acc: 0.6364, Top 70th Acc: 0.7403, Bottom 30th Acc: 0.3939
Fold [3/5] Epoch [30/100] Initial Loss: 0.1361, Training Loss: 0.0779, Initial Validation Loss: 0.1300, Validation Loss: 0.0800,V Acc: 0.6364, Top 70th Acc: 0.7403, Bottom 30th Acc: 0.3939
Stopping early at Epoch (base 0): 36  Rolling back to Epoch (base 0): 31  Top Validation Acc: 0.7402597402597403
Fold [4/5] Epoch [0/100] Initial Loss: 0.1379, Training Loss: 0.1379, Initial Validation Loss: 0.1308, Validation Loss: 0.1308,V Acc: 0.3818, Top 70th Acc: 0.3636, Bottom 30th Acc: 0.4242
Fold [4/5] Epoch [10/100] Initial Loss: 0.1379, Training Loss: 0.0808, Initial Validation Loss: 0.1308, Validation Loss: 0.0803,V Acc: 0.6182, Top 70th Acc: 0.7403, Bottom 30th Acc: 0.3333
Fold [4/5] Epoch [20/100] Initial Loss: 0.1379, Training Loss: 0.0784, Initial Validation Loss: 0.1308, Validation Loss: 0.0785,V Acc: 0.6455, Top 70th Acc: 0.7273, Bottom 30th Acc: 0.4545
Fold [4/5] Epoch [30/100] Initial Loss: 0.1379, Training Loss: 0.0780, Initial Validation Loss: 0.1308, Validation Loss: 0.0774,V Acc: 0.6455, Top 70th Acc: 0.7403, Bottom 30th Acc: 0.4242
Fold [4/5] Epoch [40/100] Initial Loss: 0.1379, Training Loss: 0.0775, Initial Validation Loss: 0.1308, Validation Loss: 0.0774,V Acc: 0.6364, Top 70th Acc: 0.7532, Bottom 30th Acc: 0.3636
Stopping early at Epoch (base 0): 41  Rolling back to Epoch (base 0): 36  Top Validation Acc: 0.7532467532467533
15 3 [array([0.1256561 , 0.32801136, 0.14719558, 0.2509393 , 0.14819765],
      dtype=float32)]
Fold [5/5] Epoch [0/100] Initial Loss: 0.1355, Training Loss: 0.1355, Initial Validation Loss: 0.1283, Validation Loss: 0.1283,V Acc: 0.3704, Top 70th Acc: 0.3684, Bottom 30th Acc: 0.3750
Fold [5/5] Epoch [10/100] Initial Loss: 0.1355, Training Loss: 0.0798, Initial Validation Loss: 0.1283, Validation Loss: 0.0823,V Acc: 0.6204, Top 70th Acc: 0.7105, Bottom 30th Acc: 0.4062
Fold [5/5] Epoch [20/100] Initial Loss: 0.1355, Training Loss: 0.0775, Initial Validation Loss: 0.1283, Validation Loss: 0.0812,V Acc: 0.6204, Top 70th Acc: 0.7237, Bottom 30th Acc: 0.3750
Fold [5/5] Epoch [30/100] Initial Loss: 0.1355, Training Loss: 0.0767, Initial Validation Loss: 0.1283, Validation Loss: 0.0810,V Acc: 0.6204, Top 70th Acc: 0.7237, Bottom 30th Acc: 0.3750
Stopping early at Epoch (base 0): 30  Rolling back to Epoch (base 0): 25  Top Validation Acc: 0.7236842105263158
Running train_nn.py with seed 16
CUDA:False
Training samples count:  550
Training on 2 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1389, Training Loss: 0.1389, Initial Validation Loss: 0.1298, Validation Loss: 0.1298,V Acc: 0.3333, Top 70th Acc: 0.3462, Bottom 30th Acc: 0.3030
Fold [1/5] Epoch [10/100] Initial Loss: 0.1389, Training Loss: 0.0791, Initial Validation Loss: 0.1298, Validation Loss: 0.0869,V Acc: 0.5856, Top 70th Acc: 0.6795, Bottom 30th Acc: 0.3636
Fold [1/5] Epoch [20/100] Initial Loss: 0.1389, Training Loss: 0.0762, Initial Validation Loss: 0.1298, Validation Loss: 0.0869,V Acc: 0.5766, Top 70th Acc: 0.6667, Bottom 30th Acc: 0.3636
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.6666666666666666
Fold [2/5] Epoch [0/100] Initial Loss: 0.1312, Training Loss: 0.1312, Initial Validation Loss: 0.1259, Validation Loss: 0.1259,V Acc: 0.3694, Top 70th Acc: 0.3718, Bottom 30th Acc: 0.3636
Fold [2/5] Epoch [10/100] Initial Loss: 0.1312, Training Loss: 0.0790, Initial Validation Loss: 0.1259, Validation Loss: 0.0886,V Acc: 0.5676, Top 70th Acc: 0.7051, Bottom 30th Acc: 0.2424
Fold [2/5] Epoch [20/100] Initial Loss: 0.1312, Training Loss: 0.0773, Initial Validation Loss: 0.1259, Validation Loss: 0.0877,V Acc: 0.5586, Top 70th Acc: 0.7051, Bottom 30th Acc: 0.2121
Fold [3/5] Epoch [20/100] Initial Loss: 0.1389, Training Loss: 0.0282, Initial Validation Loss: 0.1332, Validation Loss: 0.0387,V Acc: 0.7727, Top 70th Acc: 0.8701, Bottom 30th Acc: 0.5455
Fold [3/5] Epoch [30/100] Initial Loss: 0.1389, Training Loss: 0.0228, Initial Validation Loss: 0.1332, Validation Loss: 0.0338,V Acc: 0.8273, Top 70th Acc: 0.8961, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 38  Rolling back to Epoch (base 0): 33  Top Validation Acc: 0.8961038961038961
Fold [4/5] Epoch [0/100] Initial Loss: 0.1383, Training Loss: 0.1383, Initial Validation Loss: 0.1330, Validation Loss: 0.1330,V Acc: 0.3273, Top 70th Acc: 0.4026, Bottom 30th Acc: 0.1515
Fold [4/5] Epoch [10/100] Initial Loss: 0.1383, Training Loss: 0.0333, Initial Validation Loss: 0.1330, Validation Loss: 0.0358,V Acc: 0.8545, Top 70th Acc: 0.8831, Bottom 30th Acc: 0.7879
Fold [4/5] Epoch [20/100] Initial Loss: 0.1383, Training Loss: 0.0250, Initial Validation Loss: 0.1330, Validation Loss: 0.0303,V Acc: 0.8545, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.6970
Fold [4/5] Epoch [30/100] Initial Loss: 0.1383, Training Loss: 0.0232, Initial Validation Loss: 0.1330, Validation Loss: 0.0282,V Acc: 0.8818, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.7879
Stopping early at Epoch (base 0): 34  Rolling back to Epoch (base 0): 29  Top Validation Acc: 0.935064935064935
15 3 [array([0.42228922, 0.05182711, 0.12032863, 0.22772808, 0.177827  ],
      dtype=float32)]
Fold [5/5] Epoch [0/100] Initial Loss: 0.1390, Training Loss: 0.1390, Initial Validation Loss: 0.1327, Validation Loss: 0.1327,V Acc: 0.3426, Top 70th Acc: 0.4079, Bottom 30th Acc: 0.1875
Fold [5/5] Epoch [10/100] Initial Loss: 0.1390, Training Loss: 0.0314, Initial Validation Loss: 0.1327, Validation Loss: 0.0426,V Acc: 0.8241, Top 70th Acc: 0.9211, Bottom 30th Acc: 0.5938
Fold [5/5] Epoch [20/100] Initial Loss: 0.1390, Training Loss: 0.0205, Initial Validation Loss: 0.1327, Validation Loss: 0.0368,V Acc: 0.8426, Top 70th Acc: 0.9211, Bottom 30th Acc: 0.6562
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.9210526315789473
Running train_nn.py with seed 16
CUDA:False
Training samples count:  550
Training on 20 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1394, Training Loss: 0.1394, Initial Validation Loss: 0.1333, Validation Loss: 0.1333,V Acc: 0.2703, Top 70th Acc: 0.3077, Bottom 30th Acc: 0.1818
Fold [1/5] Epoch [10/100] Initial Loss: 0.1394, Training Loss: 0.0396, Initial Validation Loss: 0.1333, Validation Loss: 0.0542,V Acc: 0.7297, Top 70th Acc: 0.8205, Bottom 30th Acc: 0.5152
Fold [1/5] Epoch [20/100] Initial Loss: 0.1394, Training Loss: 0.0246, Initial Validation Loss: 0.1333, Validation Loss: 0.0454,V Acc: 0.7387, Top 70th Acc: 0.8974, Bottom 30th Acc: 0.3636
Fold [1/5] Epoch [30/100] Initial Loss: 0.1394, Training Loss: 0.0208, Initial Validation Loss: 0.1333, Validation Loss: 0.0431,V Acc: 0.7568, Top 70th Acc: 0.8846, Bottom 30th Acc: 0.4545
Fold [1/5] Epoch [40/100] Initial Loss: 0.1394, Training Loss: 0.0197, Initial Validation Loss: 0.1333, Validation Loss: 0.0410,V Acc: 0.7568, Top 70th Acc: 0.8974, Bottom 30th Acc: 0.4242
Stopping early at Epoch (base 0): 42  Rolling back to Epoch (base 0): 37  Top Validation Acc: 0.8974358974358975
Fold [2/5] Epoch [0/100] Initial Loss: 0.1382, Training Loss: 0.1382, Initial Validation Loss: 0.1353, Validation Loss: 0.1353,V Acc: 0.3333, Top 70th Acc: 0.3974, Bottom 30th Acc: 0.1818
Fold [2/5] Epoch [10/100] Initial Loss: 0.1382, Training Loss: 0.0431, Initial Validation Loss: 0.1353, Validation Loss: 0.0510,V Acc: 0.7928, Top 70th Acc: 0.8846, Bottom 30th Acc: 0.5758
Fold [2/5] Epoch [20/100] Initial Loss: 0.1382, Training Loss: 0.0239, Initial Validation Loss: 0.1353, Validation Loss: 0.0369,V Acc: 0.8468, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 29  Rolling back to Epoch (base 0): 24  Top Validation Acc: 0.9358974358974359
16 1 [array([0.41364035, 0.0844221 , 0.14809304, 0.22430809, 0.12953648],
      dtype=float32)]
Fold [3/5] Epoch [0/100] Initial Loss: 0.1410, Training Loss: 0.1410, Initial Validation Loss: 0.1371, Validation Loss: 0.1371,V Acc: 0.2545, Top 70th Acc: 0.3117, Bottom 30th Acc: 0.1212
Fold [3/5] Epoch [10/100] Initial Loss: 0.1410, Training Loss: 0.0448, Initial Validation Loss: 0.1371, Validation Loss: 0.0428,V Acc: 0.8000, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.4848
Fold [3/5] Epoch [20/100] Initial Loss: 0.1410, Training Loss: 0.0257, Initial Validation Loss: 0.1371, Validation Loss: 0.0305,V Acc: 0.8818, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.7576
Fold [3/5] Epoch [30/100] Initial Loss: 0.1410, Training Loss: 0.0230, Initial Validation Loss: 0.1371, Validation Loss: 0.0309,V Acc: 0.8818, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.7273
Stopping early at Epoch (base 0): 31  Rolling back to Epoch (base 0): 26  Top Validation Acc: 0.948051948051948
Fold [4/5] Epoch [0/100] Initial Loss: 0.1414, Training Loss: 0.1414, Initial Validation Loss: 0.1355, Validation Loss: 0.1355,V Acc: 0.3273, Top 70th Acc: 0.2727, Bottom 30th Acc: 0.4545
Fold [4/5] Epoch [10/100] Initial Loss: 0.1414, Training Loss: 0.0436, Initial Validation Loss: 0.1355, Validation Loss: 0.0417,V Acc: 0.8091, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.5152
Fold [4/5] Epoch [20/100] Initial Loss: 0.1414, Training Loss: 0.0262, Initial Validation Loss: 0.1355, Validation Loss: 0.0270,V Acc: 0.8727, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.961038961038961
Fold [5/5] Epoch [0/100] Initial Loss: 0.1396, Training Loss: 0.1396, Initial Validation Loss: 0.1334, Validation Loss: 0.1334,V Acc: 0.2500, Top 70th Acc: 0.3026, Bottom 30th Acc: 0.1250
Fold [5/5] Epoch [10/100] Initial Loss: 0.1396, Training Loss: 0.0422, Initial Validation Loss: 0.1334, Validation Loss: 0.0475,V Acc: 0.7870, Top 70th Acc: 0.8553, Bottom 30th Acc: 0.6250
Fold [5/5] Epoch [20/100] Initial Loss: 0.1396, Training Loss: 0.0243, Initial Validation Loss: 0.1334, Validation Loss: 0.0364,V Acc: 0.8426, Top 70th Acc: 0.8684, Bottom 30th Acc: 0.7812
Stopping early at Epoch (base 0): 29  Rolling back to Epoch (base 0): 24  Top Validation Acc: 0.881578947368421
Running train_nn.py with seed 17
CUDA:False
Training samples count:  550
Training on 20 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1380, Training Loss: 0.1380, Initial Validation Loss: 0.1305, Validation Loss: 0.1305,V Acc: 0.3784, Top 70th Acc: 0.4231, Bottom 30th Acc: 0.2727
Fold [1/5] Epoch [10/100] Initial Loss: 0.1380, Training Loss: 0.0349, Initial Validation Loss: 0.1305, Validation Loss: 0.0381,V Acc: 0.8649, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.6970
Fold [1/5] Epoch [20/100] Initial Loss: 0.1380, Training Loss: 0.0221, Initial Validation Loss: 0.1305, Validation Loss: 0.0350,V Acc: 0.8378, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 20  Rolling back to Epoch (base 0): 15  Top Validation Acc: 0.9358974358974359
Fold [2/5] Epoch [0/100] Initial Loss: 0.1435, Training Loss: 0.1435, Initial Validation Loss: 0.1390, Validation Loss: 0.1390,V Acc: 0.2703, Top 70th Acc: 0.3462, Bottom 30th Acc: 0.0909
Fold [2/5] Epoch [10/100] Initial Loss: 0.1435, Training Loss: 0.0458, Initial Validation Loss: 0.1390, Validation Loss: 0.0505,V Acc: 0.7658, Top 70th Acc: 0.8590, Bottom 30th Acc: 0.5455
Fold [2/5] Epoch [20/100] Initial Loss: 0.1435, Training Loss: 0.0279, Initial Validation Loss: 0.1390, Validation Loss: 0.0318,V Acc: 0.8468, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.6364
Fold [2/5] Epoch [30/100] Initial Loss: 0.1435, Training Loss: 0.0225, Initial Validation Loss: 0.1390, Validation Loss: 0.0282,V Acc: 0.8468, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 39  Rolling back to Epoch (base 0): 34  Top Validation Acc: 0.9487179487179487
Fold [3/5] Epoch [0/100] Initial Loss: 0.1372, Training Loss: 0.1372, Initial Validation Loss: 0.1346, Validation Loss: 0.1346,V Acc: 0.2909, Top 70th Acc: 0.3506, Bottom 30th Acc: 0.1515
Fold [3/5] Epoch [10/100] Initial Loss: 0.1372, Training Loss: 0.0318, Initial Validation Loss: 0.1346, Validation Loss: 0.0423,V Acc: 0.8000, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.5152
Fold [4/5] Epoch [20/100] Initial Loss: 0.1413, Training Loss: 0.0051, Initial Validation Loss: 0.1330, Validation Loss: 0.0282,V Acc: 0.8636, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.6364
Fold [4/5] Epoch [30/100] Initial Loss: 0.1413, Training Loss: 0.0041, Initial Validation Loss: 0.1330, Validation Loss: 0.0279,V Acc: 0.8455, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6061
Fold [4/5] Epoch [40/100] Initial Loss: 0.1413, Training Loss: 0.0039, Initial Validation Loss: 0.1330, Validation Loss: 0.0273,V Acc: 0.8545, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 40  Rolling back to Epoch (base 0): 35  Top Validation Acc: 0.948051948051948
Fold [5/5] Epoch [0/100] Initial Loss: 0.1384, Training Loss: 0.1384, Initial Validation Loss: 0.1341, Validation Loss: 0.1341,V Acc: 0.4074, Top 70th Acc: 0.4737, Bottom 30th Acc: 0.2500
Fold [5/5] Epoch [10/100] Initial Loss: 0.1384, Training Loss: 0.0206, Initial Validation Loss: 0.1341, Validation Loss: 0.0451,V Acc: 0.7685, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.3438
Fold [5/5] Epoch [20/100] Initial Loss: 0.1384, Training Loss: 0.0057, Initial Validation Loss: 0.1341, Validation Loss: 0.0368,V Acc: 0.8333, Top 70th Acc: 0.9211, Bottom 30th Acc: 0.6250
Fold [5/5] Epoch [30/100] Initial Loss: 0.1384, Training Loss: 0.0039, Initial Validation Loss: 0.1341, Validation Loss: 0.0355,V Acc: 0.8333, Top 70th Acc: 0.9211, Bottom 30th Acc: 0.6250
Stopping early at Epoch (base 0): 32  Rolling back to Epoch (base 0): 27  Top Validation Acc: 0.9210526315789473
12 4 [array([0.31723246, 0.03589294, 0.03647345, 0.22639477, 0.38400638],
      dtype=float32)]
Running train_nn.py with seed 13
CUDA:False
Training samples count:  550
Training on 163 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1371, Training Loss: 0.1371, Initial Validation Loss: 0.1377, Validation Loss: 0.1377,V Acc: 0.4234, Top 70th Acc: 0.4744, Bottom 30th Acc: 0.3030
Fold [1/5] Epoch [10/100] Initial Loss: 0.1371, Training Loss: 0.0159, Initial Validation Loss: 0.1377, Validation Loss: 0.0332,V Acc: 0.8829, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.6970
Fold [1/5] Epoch [20/100] Initial Loss: 0.1371, Training Loss: 0.0051, Initial Validation Loss: 0.1377, Validation Loss: 0.0293,V Acc: 0.8559, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.5758
Fold [1/5] Epoch [30/100] Initial Loss: 0.1371, Training Loss: 0.0041, Initial Validation Loss: 0.1377, Validation Loss: 0.0277,V Acc: 0.8829, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 31  Rolling back to Epoch (base 0): 26  Top Validation Acc: 0.9743589743589743
Fold [2/5] Epoch [0/100] Initial Loss: 0.1400, Training Loss: 0.1400, Initial Validation Loss: 0.1325, Validation Loss: 0.1325,V Acc: 0.3964, Top 70th Acc: 0.5000, Bottom 30th Acc: 0.1515
Fold [2/5] Epoch [10/100] Initial Loss: 0.1400, Training Loss: 0.0190, Initial Validation Loss: 0.1325, Validation Loss: 0.0434,V Acc: 0.8108, Top 70th Acc: 0.8718, Bottom 30th Acc: 0.6667
Fold [2/5] Epoch [20/100] Initial Loss: 0.1400, Training Loss: 0.0053, Initial Validation Loss: 0.1325, Validation Loss: 0.0343,V Acc: 0.8378, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.6667
Fold [2/5] Epoch [30/100] Initial Loss: 0.1400, Training Loss: 0.0040, Initial Validation Loss: 0.1325, Validation Loss: 0.0332,V Acc: 0.8468, Top 70th Acc: 0.8974, Bottom 30th Acc: 0.7273
Stopping early at Epoch (base 0): 32  Rolling back to Epoch (base 0): 27  Top Validation Acc: 0.8974358974358975
Fold [3/5] Epoch [0/100] Initial Loss: 0.1391, Training Loss: 0.1391, Initial Validation Loss: 0.1341, Validation Loss: 0.1341,V Acc: 0.4182, Top 70th Acc: 0.4675, Bottom 30th Acc: 0.3030
Fold [3/5] Epoch [10/100] Initial Loss: 0.1391, Training Loss: 0.0253, Initial Validation Loss: 0.1341, Validation Loss: 0.0451,V Acc: 0.8273, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.6061
Fold [3/5] Epoch [20/100] Initial Loss: 0.1391, Training Loss: 0.0061, Initial Validation Loss: 0.1341, Validation Loss: 0.0344,V Acc: 0.8455, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.6667
Fold [3/5] Epoch [30/100] Initial Loss: 0.1391, Training Loss: 0.0045, Initial Validation Loss: 0.1341, Validation Loss: 0.0324,V Acc: 0.8455, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.5758
Fold [3/5] Epoch [40/100] Initial Loss: 0.1391, Training Loss: 0.0041, Initial Validation Loss: 0.1341, Validation Loss: 0.0313,V Acc: 0.8636, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.6061
Fold [3/5] Epoch [50/100] Initial Loss: 0.1391, Training Loss: 0.0039, Initial Validation Loss: 0.1341, Validation Loss: 0.0302,V Acc: 0.8545, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 54  Rolling back to Epoch (base 0): 49  Top Validation Acc: 0.974025974025974
Fold [4/5] Epoch [0/100] Initial Loss: 0.1396, Training Loss: 0.1396, Initial Validation Loss: 0.1263, Validation Loss: 0.1263,V Acc: 0.3273, Top 70th Acc: 0.3896, Bottom 30th Acc: 0.1818
Fold [4/5] Epoch [10/100] Initial Loss: 0.1396, Training Loss: 0.0138, Initial Validation Loss: 0.1263, Validation Loss: 0.0403,V Acc: 0.7909, Top 70th Acc: 0.8831, Bottom 30th Acc: 0.5758
Fold [4/5] Epoch [20/100] Initial Loss: 0.1396, Training Loss: 0.0044, Initial Validation Loss: 0.1263, Validation Loss: 0.0346,V Acc: 0.8182, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.5455
Fold [4/5] Epoch [30/100] Initial Loss: 0.1396, Training Loss: 0.0037, Initial Validation Loss: 0.1263, Validation Loss: 0.0337,V Acc: 0.8091, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.5152
Stopping early at Epoch (base 0): 38  Rolling back to Epoch (base 0): 33  Top Validation Acc: 0.948051948051948
Fold [5/5] Epoch [0/100] Initial Loss: 0.1380, Training Loss: 0.1380, Initial Validation Loss: 0.1333, Validation Loss: 0.1333,V Acc: 0.2593, Top 70th Acc: 0.3289, Bottom 30th Acc: 0.0938
Fold [5/5] Epoch [10/100] Initial Loss: 0.1380, Training Loss: 0.0110, Initial Validation Loss: 0.1333, Validation Loss: 0.0288,V Acc: 0.8611, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.6250
Fold [5/5] Epoch [20/100] Initial Loss: 0.1380, Training Loss: 0.0046, Initial Validation Loss: 0.1333, Validation Loss: 0.0265,V Acc: 0.8611, Top 70th Acc: 0.9868, Bottom 30th Acc: 0.5625
Stopping early at Epoch (base 0): 20  Rolling back to Epoch (base 0): 15  Top Validation Acc: 0.9868421052631579
13 4 [array([0.22967382, 0.10104553, 0.09747948, 0.22336806, 0.34843308],
      dtype=float32)]
Running train_nn.py with seed 14
CUDA:False
Training samples count:  550
Training on 163 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1386, Training Loss: 0.1386, Initial Validation Loss: 0.1342, Validation Loss: 0.1342,V Acc: 0.2973, Top 70th Acc: 0.3974, Bottom 30th Acc: 0.0606
Fold [1/5] Epoch [10/100] Initial Loss: 0.1386, Training Loss: 0.0183, Initial Validation Loss: 0.1342, Validation Loss: 0.0314,V Acc: 0.8829, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.7879
Fold [1/5] Epoch [20/100] Initial Loss: 0.1386, Training Loss: 0.0048, Initial Validation Loss: 0.1342, Validation Loss: 0.0233,V Acc: 0.8559, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.5758
Fold [1/5] Epoch [30/100] Initial Loss: 0.1386, Training Loss: 0.0039, Initial Validation Loss: 0.1342, Validation Loss: 0.0223,V Acc: 0.8739, Top 70th Acc: 1.0000, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 33  Rolling back to Epoch (base 0): 28  Top Validation Acc: 1.0
Fold [2/5] Epoch [0/100] Initial Loss: 0.1363, Training Loss: 0.1363, Initial Validation Loss: 0.1308, Validation Loss: 0.1308,V Acc: 0.3874, Top 70th Acc: 0.4231, Bottom 30th Acc: 0.3030
Fold [2/5] Epoch [10/100] Initial Loss: 0.1363, Training Loss: 0.0109, Initial Validation Loss: 0.1308, Validation Loss: 0.0381,V Acc: 0.7928, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.4848
Fold [2/5] Epoch [20/100] Initial Loss: 0.1363, Training Loss: 0.0045, Initial Validation Loss: 0.1308, Validation Loss: 0.0347,V Acc: 0.8468, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 21  Rolling back to Epoch (base 0): 16  Top Validation Acc: 0.9230769230769231
Fold [3/5] Epoch [0/100] Initial Loss: 0.1372, Training Loss: 0.1372, Initial Validation Loss: 0.1341, Validation Loss: 0.1341,V Acc: 0.2818, Top 70th Acc: 0.3377, Bottom 30th Acc: 0.1515
Fold [3/5] Epoch [10/100] Initial Loss: 0.1372, Training Loss: 0.0211, Initial Validation Loss: 0.1341, Validation Loss: 0.0312,V Acc: 0.9000, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.7576training rf with seed 1
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 20 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 2
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 20 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 3
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 20 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 4
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 20 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 5
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 20 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 6
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 20 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 7
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 20 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 8
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 20 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 9
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 20 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 10
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 20 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 11
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 20 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 12
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 20 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 13
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 20 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 14
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 20 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 15
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 20 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 16
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 20 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 17
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 20 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 18
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 20 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 19
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 20 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 20
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 20 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 21
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 20 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 22
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 20 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 23
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 20 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 24
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 20 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 25
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 20 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 26
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 20 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 27
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 20 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 28
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 20 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 29
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 20 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 30
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 20 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 31
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 20 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 32
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 20 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 33
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 20 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 34
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 20 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 35
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 20 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 36
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 20 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 37
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 20 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 38
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 20 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 39
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 20 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 40
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 20 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 41
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 20 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 42
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 20 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 43
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 20 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 44
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 20 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 45
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Fold [2/5] Epoch [20/100] Initial Loss: 0.1409, Training Loss: 0.0161, Initial Validation Loss: 0.1372, Validation Loss: 0.0239,V Acc: 0.8739, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.6364
Fold [2/5] Epoch [30/100] Initial Loss: 0.1409, Training Loss: 0.0134, Initial Validation Loss: 0.1372, Validation Loss: 0.0226,V Acc: 0.8919, Top 70th Acc: 0.9872, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 31  Rolling back to Epoch (base 0): 26  Top Validation Acc: 0.9871794871794872
Fold [3/5] Epoch [0/100] Initial Loss: 0.1412, Training Loss: 0.1412, Initial Validation Loss: 0.1348, Validation Loss: 0.1348,V Acc: 0.2545, Top 70th Acc: 0.2987, Bottom 30th Acc: 0.1515
Fold [3/5] Epoch [10/100] Initial Loss: 0.1412, Training Loss: 0.0315, Initial Validation Loss: 0.1348, Validation Loss: 0.0390,V Acc: 0.7818, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.4242
Fold [3/5] Epoch [20/100] Initial Loss: 0.1412, Training Loss: 0.0159, Initial Validation Loss: 0.1348, Validation Loss: 0.0292,V Acc: 0.8455, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 27  Rolling back to Epoch (base 0): 22  Top Validation Acc: 0.948051948051948
Fold [4/5] Epoch [0/100] Initial Loss: 0.1389, Training Loss: 0.1389, Initial Validation Loss: 0.1349, Validation Loss: 0.1349,V Acc: 0.2545, Top 70th Acc: 0.3636, Bottom 30th Acc: 0.0000
Fold [4/5] Epoch [10/100] Initial Loss: 0.1389, Training Loss: 0.0382, Initial Validation Loss: 0.1349, Validation Loss: 0.0391,V Acc: 0.8273, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.5758
Fold [4/5] Epoch [20/100] Initial Loss: 0.1389, Training Loss: 0.0160, Initial Validation Loss: 0.1349, Validation Loss: 0.0289,V Acc: 0.8455, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 22  Rolling back to Epoch (base 0): 17  Top Validation Acc: 0.948051948051948
15 3 [array([0.6053942 , 0.05845483, 0.03425834, 0.1546022 , 0.14729036],
      dtype=float32)]
Fold [5/5] Epoch [0/100] Initial Loss: 0.1359, Training Loss: 0.1359, Initial Validation Loss: 0.1280, Validation Loss: 0.1280,V Acc: 0.2593, Top 70th Acc: 0.3553, Bottom 30th Acc: 0.0312
Fold [5/5] Epoch [10/100] Initial Loss: 0.1359, Training Loss: 0.0236, Initial Validation Loss: 0.1280, Validation Loss: 0.0394,V Acc: 0.8241, Top 70th Acc: 0.9211, Bottom 30th Acc: 0.5938
Fold [5/5] Epoch [20/100] Initial Loss: 0.1359, Training Loss: 0.0133, Initial Validation Loss: 0.1280, Validation Loss: 0.0363,V Acc: 0.8333, Top 70th Acc: 0.9079, Bottom 30th Acc: 0.6562
Stopping early at Epoch (base 0): 29  Rolling back to Epoch (base 0): 24  Top Validation Acc: 0.9210526315789473
Running train_nn.py with seed 16
CUDA:False
Training samples count:  550
Training on 40 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1407, Training Loss: 0.1407, Initial Validation Loss: 0.1346, Validation Loss: 0.1346,V Acc: 0.2342, Top 70th Acc: 0.2821, Bottom 30th Acc: 0.1212
Fold [1/5] Epoch [10/100] Initial Loss: 0.1407, Training Loss: 0.0296, Initial Validation Loss: 0.1346, Validation Loss: 0.0432,V Acc: 0.7658, Top 70th Acc: 0.8718, Bottom 30th Acc: 0.5152
Fold [1/5] Epoch [20/100] Initial Loss: 0.1407, Training Loss: 0.0142, Initial Validation Loss: 0.1346, Validation Loss: 0.0307,V Acc: 0.7928, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.4545
Fold [1/5] Epoch [30/100] Initial Loss: 0.1407, Training Loss: 0.0114, Initial Validation Loss: 0.1346, Validation Loss: 0.0306,V Acc: 0.8018, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.4848
Stopping early at Epoch (base 0): 33  Rolling back to Epoch (base 0): 28  Top Validation Acc: 0.9487179487179487
Fold [2/5] Epoch [0/100] Initial Loss: 0.1380, Training Loss: 0.1380, Initial Validation Loss: 0.1346, Validation Loss: 0.1346,V Acc: 0.3874, Top 70th Acc: 0.4744, Bottom 30th Acc: 0.1818
Fold [2/5] Epoch [10/100] Initial Loss: 0.1380, Training Loss: 0.0272, Initial Validation Loss: 0.1346, Validation Loss: 0.0362,V Acc: 0.8829, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.6970
Fold [2/5] Epoch [20/100] Initial Loss: 0.1380, Training Loss: 0.0133, Initial Validation Loss: 0.1346, Validation Loss: 0.0301,V Acc: 0.8559, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.5758
Fold [2/5] Epoch [30/100] Initial Loss: 0.1380, Training Loss: 0.0108, Initial Validation Loss: 0.1346, Validation Loss: 0.0295,V Acc: 0.8649, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 34  Rolling back to Epoch (base 0): 29  Top Validation Acc: 0.9743589743589743
16 1 [array([0.8063106 , 0.04892246, 0.05750641, 0.03812177, 0.04913881],
      dtype=float32)]
Fold [3/5] Epoch [0/100] Initial Loss: 0.1371, Training Loss: 0.1371, Initial Validation Loss: 0.1353, Validation Loss: 0.1353,V Acc: 0.3636, Top 70th Acc: 0.4156, Bottom 30th Acc: 0.2424
Fold [3/5] Epoch [10/100] Initial Loss: 0.1371, Training Loss: 0.0369, Initial Validation Loss: 0.1353, Validation Loss: 0.0411,V Acc: 0.8182, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.6061
Fold [3/5] Epoch [20/100] Initial Loss: 0.1371, Training Loss: 0.0142, Initial Validation Loss: 0.1353, Validation Loss: 0.0289,V Acc: 0.8636, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.948051948051948
Fold [4/5] Epoch [0/100] Initial Loss: 0.1388, Training Loss: 0.1388, Initial Validation Loss: 0.1336, Validation Loss: 0.1336,V Acc: 0.3000, Top 70th Acc: 0.3377, Bottom 30th Acc: 0.2121
Fold [4/5] Epoch [10/100] Initial Loss: 0.1388, Training Loss: 0.0404, Initial Validation Loss: 0.1336, Validation Loss: 0.0387,V Acc: 0.7818, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.4242
Fold [4/5] Epoch [20/100] Initial Loss: 0.1388, Training Loss: 0.0224, Initial Validation Loss: 0.1336, Validation Loss: 0.0336,V Acc: 0.8273, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.5152
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.935064935064935
Fold [5/5] Epoch [0/100] Initial Loss: 0.1400, Training Loss: 0.1400, Initial Validation Loss: 0.1309, Validation Loss: 0.1309,V Acc: 0.4259, Top 70th Acc: 0.4868, Bottom 30th Acc: 0.2812
Fold [5/5] Epoch [10/100] Initial Loss: 0.1400, Training Loss: 0.0235, Initial Validation Loss: 0.1309, Validation Loss: 0.0327,V Acc: 0.8519, Top 70th Acc: 0.8947, Bottom 30th Acc: 0.7500
Stopping early at Epoch (base 0): 19  Rolling back to Epoch (base 0): 14  Top Validation Acc: 0.9342105263157895
Running train_nn.py with seed 17
CUDA:False
Training samples count:  550
Training on 40 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1425, Training Loss: 0.1425, Initial Validation Loss: 0.1384, Validation Loss: 0.1384,V Acc: 0.2523, Top 70th Acc: 0.2692, Bottom 30th Acc: 0.2121
Fold [1/5] Epoch [10/100] Initial Loss: 0.1425, Training Loss: 0.0379, Initial Validation Loss: 0.1384, Validation Loss: 0.0466,V Acc: 0.7748, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.4545
Fold [1/5] Epoch [20/100] Initial Loss: 0.1425, Training Loss: 0.0239, Initial Validation Loss: 0.1384, Validation Loss: 0.0457,V Acc: 0.8018, Top 70th Acc: 0.8974, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 20  Rolling back to Epoch (base 0): 15  Top Validation Acc: 0.8974358974358975
Fold [2/5] Epoch [0/100] Initial Loss: 0.1382, Training Loss: 0.1382, Initial Validation Loss: 0.1355, Validation Loss: 0.1355,V Acc: 0.2613, Top 70th Acc: 0.3462, Bottom 30th Acc: 0.0606
Fold [2/5] Epoch [10/100] Initial Loss: 0.1382, Training Loss: 0.0256, Initial Validation Loss: 0.1355, Validation Loss: 0.0295,V Acc: 0.8649, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.6061
Fold [2/5] Epoch [20/100] Initial Loss: 0.1382, Training Loss: 0.0153, Initial Validation Loss: 0.1355, Validation Loss: 0.0218,V Acc: 0.9009, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.7273
Stopping early at Epoch (base 0): 29  Rolling back to Epoch (base 0): 24  Top Validation Acc: 0.9743589743589743
Fold [3/5] Epoch [0/100] Initial Loss: 0.1429, Training Loss: 0.1429, Initial Validation Loss: 0.1368, Validation Loss: 0.1368,V Acc: 0.2364, Top 70th Acc: 0.2727, Bottom 30th Acc: 0.1515
Fold [3/5] Epoch [10/100] Initial Loss: 0.1429, Training Loss: 0.0335, Initial Validation Loss: 0.1368, Validation Loss: 0.0445,V Acc: 0.8091, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.5758
Fold [2/5] Epoch [20/100] Initial Loss: 0.1377, Training Loss: 0.0201, Initial Validation Loss: 0.1355, Validation Loss: 0.0233,V Acc: 0.8739, Top 70th Acc: 1.0000, Bottom 30th Acc: 0.5758
Fold [2/5] Epoch [30/100] Initial Loss: 0.1377, Training Loss: 0.0175, Initial Validation Loss: 0.1355, Validation Loss: 0.0219,V Acc: 0.9009, Top 70th Acc: 1.0000, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 39  Rolling back to Epoch (base 0): 34  Top Validation Acc: 1.0
Fold [3/5] Epoch [0/100] Initial Loss: 0.1419, Training Loss: 0.1419, Initial Validation Loss: 0.1350, Validation Loss: 0.1350,V Acc: 0.2545, Top 70th Acc: 0.2987, Bottom 30th Acc: 0.1515
Fold [3/5] Epoch [10/100] Initial Loss: 0.1419, Training Loss: 0.0366, Initial Validation Loss: 0.1350, Validation Loss: 0.0420,V Acc: 0.7636, Top 70th Acc: 0.8961, Bottom 30th Acc: 0.4545
Fold [3/5] Epoch [20/100] Initial Loss: 0.1419, Training Loss: 0.0196, Initial Validation Loss: 0.1350, Validation Loss: 0.0296,V Acc: 0.8455, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.6364
Fold [3/5] Epoch [30/100] Initial Loss: 0.1419, Training Loss: 0.0174, Initial Validation Loss: 0.1350, Validation Loss: 0.0277,V Acc: 0.8636, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.6970
Fold [3/5] Epoch [40/100] Initial Loss: 0.1419, Training Loss: 0.0165, Initial Validation Loss: 0.1350, Validation Loss: 0.0279,V Acc: 0.8545, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 49  Rolling back to Epoch (base 0): 44  Top Validation Acc: 0.961038961038961
Fold [4/5] Epoch [0/100] Initial Loss: 0.1380, Training Loss: 0.1380, Initial Validation Loss: 0.1329, Validation Loss: 0.1329,V Acc: 0.2909, Top 70th Acc: 0.3506, Bottom 30th Acc: 0.1515
Fold [4/5] Epoch [10/100] Initial Loss: 0.1380, Training Loss: 0.0272, Initial Validation Loss: 0.1329, Validation Loss: 0.0324,V Acc: 0.8727, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.6667
Fold [4/5] Epoch [20/100] Initial Loss: 0.1380, Training Loss: 0.0176, Initial Validation Loss: 0.1329, Validation Loss: 0.0290,V Acc: 0.8727, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 28  Rolling back to Epoch (base 0): 23  Top Validation Acc: 0.961038961038961
15 3 [array([0.72864586, 0.04162112, 0.04608999, 0.05989908, 0.12374401],
      dtype=float32)]
Fold [5/5] Epoch [0/100] Initial Loss: 0.1380, Training Loss: 0.1380, Initial Validation Loss: 0.1329, Validation Loss: 0.1329,V Acc: 0.2963, Top 70th Acc: 0.3289, Bottom 30th Acc: 0.2188
Fold [5/5] Epoch [10/100] Initial Loss: 0.1380, Training Loss: 0.0365, Initial Validation Loss: 0.1329, Validation Loss: 0.0423,V Acc: 0.8519, Top 70th Acc: 0.9079, Bottom 30th Acc: 0.7188
Fold [5/5] Epoch [20/100] Initial Loss: 0.1380, Training Loss: 0.0200, Initial Validation Loss: 0.1329, Validation Loss: 0.0348,V Acc: 0.8426, Top 70th Acc: 0.9079, Bottom 30th Acc: 0.6875
Stopping early at Epoch (base 0): 27  Rolling back to Epoch (base 0): 22  Top Validation Acc: 0.8947368421052632
Running train_nn.py with seed 16
CUDA:False
Training samples count:  550
Training on 30 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1357, Training Loss: 0.1357, Initial Validation Loss: 0.1304, Validation Loss: 0.1304,V Acc: 0.3784, Top 70th Acc: 0.4231, Bottom 30th Acc: 0.2727
Fold [1/5] Epoch [10/100] Initial Loss: 0.1357, Training Loss: 0.0420, Initial Validation Loss: 0.1304, Validation Loss: 0.0555,V Acc: 0.7477, Top 70th Acc: 0.8205, Bottom 30th Acc: 0.5758
Fold [1/5] Epoch [20/100] Initial Loss: 0.1357, Training Loss: 0.0205, Initial Validation Loss: 0.1304, Validation Loss: 0.0380,V Acc: 0.7838, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.4545
Fold [1/5] Epoch [30/100] Initial Loss: 0.1357, Training Loss: 0.0161, Initial Validation Loss: 0.1304, Validation Loss: 0.0372,V Acc: 0.7928, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.5152
Fold [1/5] Epoch [40/100] Initial Loss: 0.1357, Training Loss: 0.0148, Initial Validation Loss: 0.1304, Validation Loss: 0.0352,V Acc: 0.7928, Top 70th Acc: 0.8974, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 44  Rolling back to Epoch (base 0): 39  Top Validation Acc: 0.9102564102564102
Fold [2/5] Epoch [0/100] Initial Loss: 0.1359, Training Loss: 0.1359, Initial Validation Loss: 0.1326, Validation Loss: 0.1326,V Acc: 0.3694, Top 70th Acc: 0.4744, Bottom 30th Acc: 0.1212
Fold [2/5] Epoch [10/100] Initial Loss: 0.1359, Training Loss: 0.0303, Initial Validation Loss: 0.1326, Validation Loss: 0.0394,V Acc: 0.8468, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.5455
Fold [2/5] Epoch [20/100] Initial Loss: 0.1359, Training Loss: 0.0158, Initial Validation Loss: 0.1326, Validation Loss: 0.0344,V Acc: 0.8559, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.5758
Fold [2/5] Epoch [30/100] Initial Loss: 0.1359, Training Loss: 0.0135, Initial Validation Loss: 0.1326, Validation Loss: 0.0335,V Acc: 0.8559, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 33  Rolling back to Epoch (base 0): 28  Top Validation Acc: 0.9743589743589743
16 1 [array([0.8542047 , 0.0408547 , 0.03197465, 0.05121998, 0.02174601],
      dtype=float32)]
Fold [3/5] Epoch [0/100] Initial Loss: 0.1373, Training Loss: 0.1373, Initial Validation Loss: 0.1331, Validation Loss: 0.1331,V Acc: 0.4000, Top 70th Acc: 0.4675, Bottom 30th Acc: 0.2424
Fold [3/5] Epoch [10/100] Initial Loss: 0.1373, Training Loss: 0.0324, Initial Validation Loss: 0.1331, Validation Loss: 0.0327,V Acc: 0.8364, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.5455
Fold [3/5] Epoch [20/100] Initial Loss: 0.1373, Training Loss: 0.0180, Initial Validation Loss: 0.1331, Validation Loss: 0.0265,V Acc: 0.8818, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.961038961038961
Fold [4/5] Epoch [0/100] Initial Loss: 0.1386, Training Loss: 0.1386, Initial Validation Loss: 0.1340, Validation Loss: 0.1340,V Acc: 0.2273, Top 70th Acc: 0.2857, Bottom 30th Acc: 0.0909
Fold [4/5] Epoch [10/100] Initial Loss: 0.1386, Training Loss: 0.0353, Initial Validation Loss: 0.1340, Validation Loss: 0.0329,V Acc: 0.8273, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.4848
Fold [4/5] Epoch [20/100] Initial Loss: 0.1386, Training Loss: 0.0203, Initial Validation Loss: 0.1340, Validation Loss: 0.0231,V Acc: 0.8636, Top 70th Acc: 1.0000, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 29  Rolling back to Epoch (base 0): 24  Top Validation Acc: 0.987012987012987
Fold [5/5] Epoch [0/100] Initial Loss: 0.1382, Training Loss: 0.1382, Initial Validation Loss: 0.1314, Validation Loss: 0.1314,V Acc: 0.3241, Top 70th Acc: 0.3684, Bottom 30th Acc: 0.2188
Fold [5/5] Epoch [10/100] Initial Loss: 0.1382, Training Loss: 0.0318, Initial Validation Loss: 0.1314, Validation Loss: 0.0367,V Acc: 0.8241, Top 70th Acc: 0.8947, Bottom 30th Acc: 0.6562
Fold [5/5] Epoch [20/100] Initial Loss: 0.1382, Training Loss: 0.0183, Initial Validation Loss: 0.1314, Validation Loss: 0.0301,V Acc: 0.8704, Top 70th Acc: 0.9211, Bottom 30th Acc: 0.7500
Fold [5/5] Epoch [30/100] Initial Loss: 0.1382, Training Loss: 0.0156, Initial Validation Loss: 0.1314, Validation Loss: 0.0282,V Acc: 0.8519, Top 70th Acc: 0.9211, Bottom 30th Acc: 0.6875
Stopping early at Epoch (base 0): 30  Rolling back to Epoch (base 0): 25  Top Validation Acc: 0.9210526315789473
Running train_nn.py with seed 17
CUDA:False
Training samples count:  550
Training on 30 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1426, Training Loss: 0.1426, Initial Validation Loss: 0.1353, Validation Loss: 0.1353,V Acc: 0.3243, Top 70th Acc: 0.3590, Bottom 30th Acc: 0.2424
Fold [1/5] Epoch [10/100] Initial Loss: 0.1426, Training Loss: 0.0306, Initial Validation Loss: 0.1353, Validation Loss: 0.0410,V Acc: 0.8198, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.5152
Fold [1/5] Epoch [20/100] Initial Loss: 0.1426, Training Loss: 0.0175, Initial Validation Loss: 0.1353, Validation Loss: 0.0320,V Acc: 0.8378, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 22  Rolling back to Epoch (base 0): 17  Top Validation Acc: 0.9487179487179487
Fold [2/5] Epoch [0/100] Initial Loss: 0.1380, Training Loss: 0.1380, Initial Validation Loss: 0.1374, Validation Loss: 0.1374,V Acc: 0.3333, Top 70th Acc: 0.3974, Bottom 30th Acc: 0.1818
Training on 21 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 46
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 21 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 47
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 21 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 48
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 21 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 49
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 21 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 50
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 21 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 51
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 21 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 52
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 21 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 53
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 21 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 54
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 21 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 55
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 21 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 56
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 21 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 57
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 21 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 58
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 21 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 59
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 21 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 60
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 21 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 61
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 21 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 62
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 21 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 63
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 21 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 64
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 21 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 65
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 21 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 66
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 21 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 67
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 21 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 68
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 21 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 69
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 21 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 70
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 21 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 71
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 21 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 72
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 21 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 73
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 21 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 74
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 21 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 75
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 21 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 76
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 21 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 77
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 21 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 78
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 21 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 79
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 21 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 80
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 21 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 81
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 21 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 82
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 21 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 83
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 21 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 84
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 21 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 85
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 21 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 86
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 21 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 87
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 21 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 88
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 21 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 89
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 21 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 90
Training size: 439
Stopping early at Epoch (base 0): 19  Rolling back to Epoch (base 0): 14  Top Validation Acc: 0.935064935064935
23 2 [array([0.7729103 , 0.0168143 , 0.02229258, 0.11508087, 0.07290198],
      dtype=float32)]
Fold [4/5] Epoch [0/100] Initial Loss: 0.1316, Training Loss: 0.1316, Initial Validation Loss: 0.1181, Validation Loss: 0.1181,V Acc: 0.5636, Top 70th Acc: 0.6883, Bottom 30th Acc: 0.2727
Fold [4/5] Epoch [10/100] Initial Loss: 0.1316, Training Loss: 0.0248, Initial Validation Loss: 0.1181, Validation Loss: 0.0234,V Acc: 0.9000, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.7576
Fold [4/5] Epoch [20/100] Initial Loss: 0.1316, Training Loss: 0.0189, Initial Validation Loss: 0.1181, Validation Loss: 0.0224,V Acc: 0.9000, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.7576
Stopping early at Epoch (base 0): 20  Rolling back to Epoch (base 0): 15  Top Validation Acc: 0.961038961038961
Fold [5/5] Epoch [0/100] Initial Loss: 0.1384, Training Loss: 0.1384, Initial Validation Loss: 0.1274, Validation Loss: 0.1274,V Acc: 0.3704, Top 70th Acc: 0.4605, Bottom 30th Acc: 0.1562
Fold [5/5] Epoch [10/100] Initial Loss: 0.1384, Training Loss: 0.0241, Initial Validation Loss: 0.1274, Validation Loss: 0.0192,V Acc: 0.9167, Top 70th Acc: 1.0000, Bottom 30th Acc: 0.7188
Stopping early at Epoch (base 0): 15  Rolling back to Epoch (base 0): 10  Top Validation Acc: 0.9868421052631579
Running train_nn.py with seed 24
CUDA:False
Training samples count:  550
Training on 21 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1317, Training Loss: 0.1317, Initial Validation Loss: 0.1284, Validation Loss: 0.1284,V Acc: 0.4324, Top 70th Acc: 0.5769, Bottom 30th Acc: 0.0909
Fold [1/5] Epoch [10/100] Initial Loss: 0.1317, Training Loss: 0.0284, Initial Validation Loss: 0.1284, Validation Loss: 0.0310,V Acc: 0.8829, Top 70th Acc: 0.9872, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 19  Rolling back to Epoch (base 0): 14  Top Validation Acc: 0.9743589743589743
Fold [2/5] Epoch [0/100] Initial Loss: 0.1369, Training Loss: 0.1369, Initial Validation Loss: 0.1226, Validation Loss: 0.1226,V Acc: 0.4324, Top 70th Acc: 0.5641, Bottom 30th Acc: 0.1212
Fold [2/5] Epoch [10/100] Initial Loss: 0.1369, Training Loss: 0.0198, Initial Validation Loss: 0.1226, Validation Loss: 0.0449,V Acc: 0.7748, Top 70th Acc: 0.8974, Bottom 30th Acc: 0.4848
Fold [2/5] Epoch [20/100] Initial Loss: 0.1369, Training Loss: 0.0147, Initial Validation Loss: 0.1226, Validation Loss: 0.0414,V Acc: 0.8018, Top 70th Acc: 0.8974, Bottom 30th Acc: 0.5758
Fold [2/5] Epoch [30/100] Initial Loss: 0.1369, Training Loss: 0.0113, Initial Validation Loss: 0.1226, Validation Loss: 0.0375,V Acc: 0.8108, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.5455
Fold [2/5] Epoch [40/100] Initial Loss: 0.1369, Training Loss: 0.0116, Initial Validation Loss: 0.1226, Validation Loss: 0.0365,V Acc: 0.8198, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 48  Rolling back to Epoch (base 0): 43  Top Validation Acc: 0.9358974358974359
Fold [3/5] Epoch [0/100] Initial Loss: 0.1301, Training Loss: 0.1301, Initial Validation Loss: 0.1115, Validation Loss: 0.1115,V Acc: 0.4909, Top 70th Acc: 0.6364, Bottom 30th Acc: 0.1515
Fold [3/5] Epoch [10/100] Initial Loss: 0.1301, Training Loss: 0.0223, Initial Validation Loss: 0.1115, Validation Loss: 0.0362,V Acc: 0.8364, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.6061
Fold [3/5] Epoch [20/100] Initial Loss: 0.1301, Training Loss: 0.0189, Initial Validation Loss: 0.1115, Validation Loss: 0.0224,V Acc: 0.8636, Top 70th Acc: 1.0000, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 22  Rolling back to Epoch (base 0): 17  Top Validation Acc: 0.961038961038961
24 2 [array([0.68048453, 0.03416286, 0.04509811, 0.08742258, 0.15283188],
      dtype=float32)]
Fold [4/5] Epoch [0/100] Initial Loss: 0.1338, Training Loss: 0.1338, Initial Validation Loss: 0.1275, Validation Loss: 0.1275,V Acc: 0.4364, Top 70th Acc: 0.4805, Bottom 30th Acc: 0.3333
Fold [4/5] Epoch [10/100] Initial Loss: 0.1338, Training Loss: 0.0285, Initial Validation Loss: 0.1275, Validation Loss: 0.0258,V Acc: 0.9000, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.7273
Fold [4/5] Epoch [20/100] Initial Loss: 0.1338, Training Loss: 0.0184, Initial Validation Loss: 0.1275, Validation Loss: 0.0212,V Acc: 0.9091, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.8182
Stopping early at Epoch (base 0): 20  Rolling back to Epoch (base 0): 15  Top Validation Acc: 0.948051948051948
Fold [5/5] Epoch [0/100] Initial Loss: 0.1351, Training Loss: 0.1351, Initial Validation Loss: 0.1195, Validation Loss: 0.1195,V Acc: 0.4630, Top 70th Acc: 0.5921, Bottom 30th Acc: 0.1562
Fold [5/5] Epoch [10/100] Initial Loss: 0.1351, Training Loss: 0.0249, Initial Validation Loss: 0.1195, Validation Loss: 0.0305,V Acc: 0.8426, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.5938
Stopping early at Epoch (base 0): 18  Rolling back to Epoch (base 0): 13  Top Validation Acc: 0.9473684210526315
Running train_nn.py with seed 25
CUDA:False
Training samples count:  550
Training on 21 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1327, Training Loss: 0.1327, Initial Validation Loss: 0.1208, Validation Loss: 0.1208,V Acc: 0.5315, Top 70th Acc: 0.6154, Bottom 30th Acc: 0.3333
Fold [1/5] Epoch [10/100] Initial Loss: 0.1327, Training Loss: 0.0238, Initial Validation Loss: 0.1208, Validation Loss: 0.0375,V Acc: 0.8018, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.5152
Fold [1/5] Epoch [20/100] Initial Loss: 0.1327, Training Loss: 0.0151, Initial Validation Loss: 0.1208, Validation Loss: 0.0343,V Acc: 0.8468, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 22  Rolling back to Epoch (base 0): 17  Top Validation Acc: 0.9102564102564102
Fold [2/5] Epoch [0/100] Initial Loss: 0.1370, Training Loss: 0.1370, Initial Validation Loss: 0.1295, Validation Loss: 0.1295,V Acc: 0.4234, Top 70th Acc: 0.5641, Bottom 30th Acc: 0.0909
Fold [2/5] Epoch [10/100] Initial Loss: 0.1370, Training Loss: 0.0274, Initial Validation Loss: 0.1295, Validation Loss: 0.0324,V Acc: 0.8468, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.5758
Fold [2/5] Epoch [20/100] Initial Loss: 0.1370, Training Loss: 0.0176, Initial Validation Loss: 0.1295, Validation Loss: 0.0329,V Acc: 0.8649, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 22  Rolling back to Epoch (base 0): 17  Top Validation Acc: 0.9615384615384616
Fold [3/5] Epoch [0/100] Initial Loss: 0.1386, Training Loss: 0.1386, Initial Validation Loss: 0.1284, Validation Loss: 0.1284,V Acc: 0.2545, Top 70th Acc: 0.3506, Bottom 30th Acc: 0.0303
Fold [3/5] Epoch [10/100] Initial Loss: 0.1386, Training Loss: 0.0298, Initial Validation Loss: 0.1284, Validation Loss: 0.0309,V Acc: 0.8091, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.4242
Fold [3/5] Epoch [20/100] Initial Loss: 0.1386, Training Loss: 0.0186, Initial Validation Loss: 0.1284, Validation Loss: 0.0254,V Acc: 0.8455, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.974025974025974
Fold [4/5] Epoch [0/100] Initial Loss: 0.1292, Training Loss: 0.1292, Initial Validation Loss: 0.1207, Validation Loss: 0.1207,V Acc: 0.4636, Top 70th Acc: 0.5714, Bottom 30th Acc: 0.2121
Fold [4/5] Epoch [10/100] Initial Loss: 0.1292, Training Loss: 0.0243, Initial Validation Loss: 0.1207, Validation Loss: 0.0261,V Acc: 0.9091, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.7576
Stopping early at Epoch (base 0): 16  Rolling back to Epoch (base 0): 11  Top Validation Acc: 0.987012987012987
25 3 [array([0.7152256 , 0.03019363, 0.02941593, 0.14423294, 0.08093194],
      dtype=float32)]
Fold [5/5] Epoch [0/100] Initial Loss: 0.1315, Training Loss: 0.1315, Initial Validation Loss: 0.1146, Validation Loss: 0.1146,V Acc: 0.4722, Top 70th Acc: 0.6053, Bottom 30th Acc: 0.1562
Fold [5/5] Epoch [10/100] Initial Loss: 0.1315, Training Loss: 0.0268, Initial Validation Loss: 0.1146, Validation Loss: 0.0280,V Acc: 0.8611, Top 70th Acc: 0.9868, Bottom 30th Acc: 0.5625
Fold [5/5] Epoch [20/100] Initial Loss: 0.1315, Training Loss: 0.0202, Initial Validation Loss: 0.1146, Validation Loss: 0.0209,V Acc: 0.8796, Top 70th Acc: 1.0000, Bottom 30th Acc: 0.5938
Fold [2/5] Epoch [30/100] Initial Loss: 0.1312, Training Loss: 0.0766, Initial Validation Loss: 0.1259, Validation Loss: 0.0857,V Acc: 0.5856, Top 70th Acc: 0.7051, Bottom 30th Acc: 0.3030
Fold [2/5] Epoch [40/100] Initial Loss: 0.1312, Training Loss: 0.0760, Initial Validation Loss: 0.1259, Validation Loss: 0.0849,V Acc: 0.5856, Top 70th Acc: 0.7179, Bottom 30th Acc: 0.2727
Stopping early at Epoch (base 0): 41  Rolling back to Epoch (base 0): 36  Top Validation Acc: 0.717948717948718
16 1 [array([0.13722436, 0.38330987, 0.12109147, 0.24261117, 0.11576308],
      dtype=float32)]
Fold [3/5] Epoch [0/100] Initial Loss: 0.1287, Training Loss: 0.1287, Initial Validation Loss: 0.1199, Validation Loss: 0.1199,V Acc: 0.4818, Top 70th Acc: 0.5974, Bottom 30th Acc: 0.2121
Fold [3/5] Epoch [10/100] Initial Loss: 0.1287, Training Loss: 0.0810, Initial Validation Loss: 0.1199, Validation Loss: 0.0782,V Acc: 0.6636, Top 70th Acc: 0.7273, Bottom 30th Acc: 0.5152
Fold [3/5] Epoch [20/100] Initial Loss: 0.1287, Training Loss: 0.0789, Initial Validation Loss: 0.1199, Validation Loss: 0.0773,V Acc: 0.6455, Top 70th Acc: 0.7403, Bottom 30th Acc: 0.4242
Stopping early at Epoch (base 0): 28  Rolling back to Epoch (base 0): 23  Top Validation Acc: 0.7532467532467533
Fold [4/5] Epoch [0/100] Initial Loss: 0.1363, Training Loss: 0.1363, Initial Validation Loss: 0.1263, Validation Loss: 0.1263,V Acc: 0.5091, Top 70th Acc: 0.5584, Bottom 30th Acc: 0.3939
Fold [4/5] Epoch [10/100] Initial Loss: 0.1363, Training Loss: 0.0819, Initial Validation Loss: 0.1263, Validation Loss: 0.0745,V Acc: 0.6636, Top 70th Acc: 0.7403, Bottom 30th Acc: 0.4848
Fold [4/5] Epoch [20/100] Initial Loss: 0.1363, Training Loss: 0.0796, Initial Validation Loss: 0.1263, Validation Loss: 0.0730,V Acc: 0.6909, Top 70th Acc: 0.7922, Bottom 30th Acc: 0.4545
Stopping early at Epoch (base 0): 22  Rolling back to Epoch (base 0): 17  Top Validation Acc: 0.7532467532467533
Fold [5/5] Epoch [0/100] Initial Loss: 0.1349, Training Loss: 0.1349, Initial Validation Loss: 0.1199, Validation Loss: 0.1199,V Acc: 0.5556, Top 70th Acc: 0.6974, Bottom 30th Acc: 0.2188
Fold [5/5] Epoch [10/100] Initial Loss: 0.1349, Training Loss: 0.0820, Initial Validation Loss: 0.1199, Validation Loss: 0.0773,V Acc: 0.6296, Top 70th Acc: 0.7763, Bottom 30th Acc: 0.2812
Fold [5/5] Epoch [20/100] Initial Loss: 0.1349, Training Loss: 0.0800, Initial Validation Loss: 0.1199, Validation Loss: 0.0754,V Acc: 0.6296, Top 70th Acc: 0.7895, Bottom 30th Acc: 0.2500
Fold [5/5] Epoch [30/100] Initial Loss: 0.1349, Training Loss: 0.0796, Initial Validation Loss: 0.1199, Validation Loss: 0.0766,V Acc: 0.6389, Top 70th Acc: 0.7500, Bottom 30th Acc: 0.3750
Stopping early at Epoch (base 0): 33  Rolling back to Epoch (base 0): 28  Top Validation Acc: 0.7631578947368421
Running train_nn.py with seed 17
CUDA:False
Training samples count:  550
Training on 2 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1307, Training Loss: 0.1307, Initial Validation Loss: 0.1177, Validation Loss: 0.1177,V Acc: 0.5405, Top 70th Acc: 0.6026, Bottom 30th Acc: 0.3939
Fold [1/5] Epoch [10/100] Initial Loss: 0.1307, Training Loss: 0.0821, Initial Validation Loss: 0.1177, Validation Loss: 0.0785,V Acc: 0.6396, Top 70th Acc: 0.6795, Bottom 30th Acc: 0.5455
Fold [1/5] Epoch [20/100] Initial Loss: 0.1307, Training Loss: 0.0801, Initial Validation Loss: 0.1177, Validation Loss: 0.0759,V Acc: 0.6667, Top 70th Acc: 0.7436, Bottom 30th Acc: 0.4848
Fold [1/5] Epoch [30/100] Initial Loss: 0.1307, Training Loss: 0.0795, Initial Validation Loss: 0.1177, Validation Loss: 0.0752,V Acc: 0.6667, Top 70th Acc: 0.7436, Bottom 30th Acc: 0.4848
Stopping early at Epoch (base 0): 31  Rolling back to Epoch (base 0): 26  Top Validation Acc: 0.7564102564102564
Fold [2/5] Epoch [0/100] Initial Loss: 0.1348, Training Loss: 0.1348, Initial Validation Loss: 0.1293, Validation Loss: 0.1293,V Acc: 0.3063, Top 70th Acc: 0.3590, Bottom 30th Acc: 0.1818
Fold [2/5] Epoch [10/100] Initial Loss: 0.1348, Training Loss: 0.0809, Initial Validation Loss: 0.1293, Validation Loss: 0.0841,V Acc: 0.5946, Top 70th Acc: 0.7179, Bottom 30th Acc: 0.3030
Fold [2/5] Epoch [20/100] Initial Loss: 0.1348, Training Loss: 0.0778, Initial Validation Loss: 0.1293, Validation Loss: 0.0821,V Acc: 0.6216, Top 70th Acc: 0.6923, Bottom 30th Acc: 0.4545
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.7051282051282052
Fold [3/5] Epoch [0/100] Initial Loss: 0.1347, Training Loss: 0.1347, Initial Validation Loss: 0.1228, Validation Loss: 0.1228,V Acc: 0.4455, Top 70th Acc: 0.5325, Bottom 30th Acc: 0.2424
Fold [3/5] Epoch [10/100] Initial Loss: 0.1347, Training Loss: 0.0789, Initial Validation Loss: 0.1228, Validation Loss: 0.0874,V Acc: 0.5818, Top 70th Acc: 0.6753, Bottom 30th Acc: 0.3636
Fold [3/5] Epoch [20/100] Initial Loss: 0.1347, Training Loss: 0.0771, Initial Validation Loss: 0.1228, Validation Loss: 0.0856,V Acc: 0.5818, Top 70th Acc: 0.7013, Bottom 30th Acc: 0.3030
Fold [3/5] Epoch [30/100] Initial Loss: 0.1347, Training Loss: 0.0763, Initial Validation Loss: 0.1228, Validation Loss: 0.0854,V Acc: 0.5818, Top 70th Acc: 0.7013, Bottom 30th Acc: 0.3030
Fold [3/5] Epoch [40/100] Initial Loss: 0.1347, Training Loss: 0.0756, Initial Validation Loss: 0.1228, Validation Loss: 0.0844,V Acc: 0.6091, Top 70th Acc: 0.7273, Bottom 30th Acc: 0.3333
Stopping early at Epoch (base 0): 45  Rolling back to Epoch (base 0): 40  Top Validation Acc: 0.7142857142857143
Fold [4/5] Epoch [0/100] Initial Loss: 0.1360, Training Loss: 0.1360, Initial Validation Loss: 0.1252, Validation Loss: 0.1252,V Acc: 0.3727, Top 70th Acc: 0.4545, Bottom 30th Acc: 0.1818
Fold [4/5] Epoch [10/100] Initial Loss: 0.1360, Training Loss: 0.0815, Initial Validation Loss: 0.1252, Validation Loss: 0.0767,V Acc: 0.6273, Top 70th Acc: 0.7792, Bottom 30th Acc: 0.2727
Fold [4/5] Epoch [20/100] Initial Loss: 0.1360, Training Loss: 0.0795, Initial Validation Loss: 0.1252, Validation Loss: 0.0752,V Acc: 0.6364, Top 70th Acc: 0.7792, Bottom 30th Acc: 0.3030
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.7922077922077922
Fold [5/5] Epoch [0/100] Initial Loss: 0.1432, Training Loss: 0.1432, Initial Validation Loss: 0.1321, Validation Loss: 0.1321,V Acc: 0.3796, Top 70th Acc: 0.4737, Bottom 30th Acc: 0.1562
Fold [5/5] Epoch [10/100] Initial Loss: 0.1432, Training Loss: 0.0818, Initial Validation Loss: 0.1321, Validation Loss: 0.0784,V Acc: 0.6389, Top 70th Acc: 0.7368, Bottom 30th Acc: 0.4062
Fold [5/5] Epoch [20/100] Initial Loss: 0.1432, Training Loss: 0.0796, Initial Validation Loss: 0.1321, Validation Loss: 0.0753,V Acc: 0.6574, Top 70th Acc: 0.7500, Bottom 30th Acc: 0.4375
Fold [5/5] Epoch [30/100] Initial Loss: 0.1432, Training Loss: 0.0789, Initial Validation Loss: 0.1321, Validation Loss: 0.0747,V Acc: 0.6481, Top 70th Acc: 0.7237, Bottom 30th Acc: 0.4688
Fold [5/5] Epoch [40/100] Initial Loss: 0.1432, Training Loss: 0.0782, Initial Validation Loss: 0.1321, Validation Loss: 0.0746,V Acc: 0.6389, Top 70th Acc: 0.7368, Bottom 30th Acc: 0.4062
Stopping early at Epoch (base 0): 44  Rolling back to Epoch (base 0): 39  Top Validation Acc: 0.7236842105263158
17 4 [array([0.12010225, 0.3651595 , 0.13749494, 0.2268773 , 0.15036605],
      dtype=float32)]
Running train_nn.py with seed 18
CUDA:False
Training samples count:  550
Training on 2 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1420, Training Loss: 0.1420, Initial Validation Loss: 0.1345, Validation Loss: 0.1345,V Acc: 0.2793, Top 70th Acc: 0.3718, Bottom 30th Acc: 0.0606
Fold [1/5] Epoch [10/100] Initial Loss: 0.1420, Training Loss: 0.0830, Initial Validation Loss: 0.1345, Validation Loss: 0.0782,V Acc: 0.6306, Top 70th Acc: 0.7308, Bottom 30th Acc: 0.3939
Fold [1/5] Epoch [20/100] Initial Loss: 0.1420, Training Loss: 0.0803, Initial Validation Loss: 0.1345, Validation Loss: 0.0761,V Acc: 0.6306, Top 70th Acc: 0.7179, Bottom 30th Acc: 0.4242
Stopping early at Epoch (base 0): 22  Rolling back to Epoch (base 0): 17  Top Validation Acc: 0.7307692307692307
Fold [2/5] Epoch [0/100] Initial Loss: 0.1368, Training Loss: 0.1368, Initial Validation Loss: 0.1336, Validation Loss: 0.1336,V Acc: 0.4324, Top 70th Acc: 0.5128, Bottom 30th Acc: 0.2424
Fold [3/5] Epoch [20/100] Initial Loss: 0.1372, Training Loss: 0.0205, Initial Validation Loss: 0.1346, Validation Loss: 0.0392,V Acc: 0.8091, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.935064935064935
Fold [4/5] Epoch [0/100] Initial Loss: 0.1404, Training Loss: 0.1404, Initial Validation Loss: 0.1356, Validation Loss: 0.1356,V Acc: 0.2727, Top 70th Acc: 0.2078, Bottom 30th Acc: 0.4242
Fold [4/5] Epoch [10/100] Initial Loss: 0.1404, Training Loss: 0.0396, Initial Validation Loss: 0.1356, Validation Loss: 0.0505,V Acc: 0.7727, Top 70th Acc: 0.8442, Bottom 30th Acc: 0.6061
Fold [4/5] Epoch [20/100] Initial Loss: 0.1404, Training Loss: 0.0220, Initial Validation Loss: 0.1356, Validation Loss: 0.0396,V Acc: 0.8091, Top 70th Acc: 0.8831, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 29  Rolling back to Epoch (base 0): 24  Top Validation Acc: 0.9090909090909091
Fold [5/5] Epoch [0/100] Initial Loss: 0.1387, Training Loss: 0.1387, Initial Validation Loss: 0.1275, Validation Loss: 0.1275,V Acc: 0.3519, Top 70th Acc: 0.3684, Bottom 30th Acc: 0.3125
Fold [5/5] Epoch [10/100] Initial Loss: 0.1387, Training Loss: 0.0422, Initial Validation Loss: 0.1275, Validation Loss: 0.0403,V Acc: 0.7778, Top 70th Acc: 0.8684, Bottom 30th Acc: 0.5625
Fold [5/5] Epoch [20/100] Initial Loss: 0.1387, Training Loss: 0.0246, Initial Validation Loss: 0.1275, Validation Loss: 0.0302,V Acc: 0.8241, Top 70th Acc: 0.9211, Bottom 30th Acc: 0.5938
Stopping early at Epoch (base 0): 22  Rolling back to Epoch (base 0): 17  Top Validation Acc: 0.9210526315789473
17 4 [array([0.5544066 , 0.0528451 , 0.05367856, 0.22850133, 0.11056838],
      dtype=float32)]
Running train_nn.py with seed 18
CUDA:False
Training samples count:  550
Training on 20 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1368, Training Loss: 0.1368, Initial Validation Loss: 0.1327, Validation Loss: 0.1327,V Acc: 0.2523, Top 70th Acc: 0.3077, Bottom 30th Acc: 0.1212
Fold [1/5] Epoch [10/100] Initial Loss: 0.1368, Training Loss: 0.0293, Initial Validation Loss: 0.1327, Validation Loss: 0.0375,V Acc: 0.8288, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.6061
Fold [1/5] Epoch [20/100] Initial Loss: 0.1368, Training Loss: 0.0231, Initial Validation Loss: 0.1327, Validation Loss: 0.0352,V Acc: 0.8378, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.9230769230769231
Fold [2/5] Epoch [0/100] Initial Loss: 0.1390, Training Loss: 0.1390, Initial Validation Loss: 0.1378, Validation Loss: 0.1378,V Acc: 0.3874, Top 70th Acc: 0.3846, Bottom 30th Acc: 0.3939
Fold [2/5] Epoch [10/100] Initial Loss: 0.1390, Training Loss: 0.0430, Initial Validation Loss: 0.1378, Validation Loss: 0.0470,V Acc: 0.8288, Top 70th Acc: 0.8974, Bottom 30th Acc: 0.6667
Fold [2/5] Epoch [20/100] Initial Loss: 0.1390, Training Loss: 0.0257, Initial Validation Loss: 0.1378, Validation Loss: 0.0304,V Acc: 0.8649, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.9230769230769231
18 1 [array([0.2932745 , 0.1250047 , 0.11638346, 0.29567856, 0.16965878],
      dtype=float32)]
Fold [3/5] Epoch [0/100] Initial Loss: 0.1349, Training Loss: 0.1349, Initial Validation Loss: 0.1313, Validation Loss: 0.1313,V Acc: 0.4727, Top 70th Acc: 0.5065, Bottom 30th Acc: 0.3939
Fold [3/5] Epoch [10/100] Initial Loss: 0.1349, Training Loss: 0.0491, Initial Validation Loss: 0.1313, Validation Loss: 0.0517,V Acc: 0.7727, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.4545
Fold [3/5] Epoch [20/100] Initial Loss: 0.1349, Training Loss: 0.0257, Initial Validation Loss: 0.1313, Validation Loss: 0.0375,V Acc: 0.8364, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 22  Rolling back to Epoch (base 0): 17  Top Validation Acc: 0.948051948051948
Fold [4/5] Epoch [0/100] Initial Loss: 0.1398, Training Loss: 0.1398, Initial Validation Loss: 0.1287, Validation Loss: 0.1287,V Acc: 0.3364, Top 70th Acc: 0.4026, Bottom 30th Acc: 0.1818
Fold [4/5] Epoch [10/100] Initial Loss: 0.1398, Training Loss: 0.0330, Initial Validation Loss: 0.1287, Validation Loss: 0.0384,V Acc: 0.8091, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.5455
Fold [4/5] Epoch [20/100] Initial Loss: 0.1398, Training Loss: 0.0229, Initial Validation Loss: 0.1287, Validation Loss: 0.0352,V Acc: 0.8182, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.9090909090909091
Fold [5/5] Epoch [0/100] Initial Loss: 0.1386, Training Loss: 0.1386, Initial Validation Loss: 0.1327, Validation Loss: 0.1327,V Acc: 0.2870, Top 70th Acc: 0.3421, Bottom 30th Acc: 0.1562
Fold [5/5] Epoch [10/100] Initial Loss: 0.1386, Training Loss: 0.0390, Initial Validation Loss: 0.1327, Validation Loss: 0.0376,V Acc: 0.8148, Top 70th Acc: 0.9211, Bottom 30th Acc: 0.5625
Fold [5/5] Epoch [20/100] Initial Loss: 0.1386, Training Loss: 0.0249, Initial Validation Loss: 0.1327, Validation Loss: 0.0289,V Acc: 0.8148, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.4688
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.9078947368421053
Running train_nn.py with seed 19
CUDA:False
Training samples count:  550
Training on 20 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1400, Training Loss: 0.1400, Initial Validation Loss: 0.1340, Validation Loss: 0.1340,V Acc: 0.2613, Top 70th Acc: 0.2436, Bottom 30th Acc: 0.3030
Fold [1/5] Epoch [10/100] Initial Loss: 0.1400, Training Loss: 0.0326, Initial Validation Loss: 0.1340, Validation Loss: 0.0402,V Acc: 0.8288, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.6061
Fold [1/5] Epoch [20/100] Initial Loss: 0.1400, Training Loss: 0.0218, Initial Validation Loss: 0.1340, Validation Loss: 0.0322,V Acc: 0.8739, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.7273
Fold [1/5] Epoch [30/100] Initial Loss: 0.1400, Training Loss: 0.0203, Initial Validation Loss: 0.1340, Validation Loss: 0.0315,V Acc: 0.8468, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.6061
Fold [1/5] Epoch [40/100] Initial Loss: 0.1400, Training Loss: 0.0195, Initial Validation Loss: 0.1340, Validation Loss: 0.0300,V Acc: 0.8559, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 46  Rolling back to Epoch (base 0): 41  Top Validation Acc: 0.9871794871794872
Fold [2/5] Epoch [0/100] Initial Loss: 0.1407, Training Loss: 0.1407, Initial Validation Loss: 0.1298, Validation Loss: 0.1298,V Acc: 0.2793, Top 70th Acc: 0.3590, Bottom 30th Acc: 0.0909
Fold [2/5] Epoch [10/100] Initial Loss: 0.1407, Training Loss: 0.0364, Initial Validation Loss: 0.1298, Validation Loss: 0.0361,V Acc: 0.8288, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.6364
Fold [2/5] Epoch [20/100] Initial Loss: 0.1407, Training Loss: 0.0229, Initial Validation Loss: 0.1298, Validation Loss: 0.0296,V Acc: 0.8559, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.7273
Fold [2/5] Epoch [30/100] Initial Loss: 0.1407, Training Loss: 0.0200, Initial Validation Loss: 0.1298, Validation Loss: 0.0287,V Acc: 0.8378, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 37  Rolling back to Epoch (base 0): 32  Top Validation Acc: 0.9102564102564102
Fold [3/5] Epoch [0/100] Initial Loss: 0.1365, Training Loss: 0.1365, Initial Validation Loss: 0.1320, Validation Loss: 0.1320,V Acc: 0.3545, Top 70th Acc: 0.4156, Bottom 30th Acc: 0.2121
Fold [3/5] Epoch [10/100] Initial Loss: 0.1365, Training Loss: 0.0369, Initial Validation Loss: 0.1320, Validation Loss: 0.0373,V Acc: 0.8273, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.5758
Fold [3/5] Epoch [20/100] Initial Loss: 0.1365, Training Loss: 0.0253, Initial Validation Loss: 0.1320, Validation Loss: 0.0280,V Acc: 0.8636, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6667
Fold [3/5] Epoch [30/100] Initial Loss: 0.1365, Training Loss: 0.0224, Initial Validation Loss: 0.1320, Validation Loss: 0.0256,V Acc: 0.8909, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.7273
Fold [3/5] Epoch [40/100] Initial Loss: 0.1365, Training Loss: 0.0214, Initial Validation Loss: 0.1320, Validation Loss: 0.0245,V Acc: 0.9000, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.7879/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)

Fold [3/5] Epoch [20/100] Initial Loss: 0.1372, Training Loss: 0.0051, Initial Validation Loss: 0.1341, Validation Loss: 0.0253,V Acc: 0.8909, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 28  Rolling back to Epoch (base 0): 23  Top Validation Acc: 0.974025974025974
Fold [4/5] Epoch [0/100] Initial Loss: 0.1386, Training Loss: 0.1386, Initial Validation Loss: 0.1297, Validation Loss: 0.1297,V Acc: 0.2545, Top 70th Acc: 0.3377, Bottom 30th Acc: 0.0606
Fold [4/5] Epoch [10/100] Initial Loss: 0.1386, Training Loss: 0.0163, Initial Validation Loss: 0.1297, Validation Loss: 0.0312,V Acc: 0.8273, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.5455
Fold [4/5] Epoch [20/100] Initial Loss: 0.1386, Training Loss: 0.0046, Initial Validation Loss: 0.1297, Validation Loss: 0.0270,V Acc: 0.8727, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.7273
Stopping early at Epoch (base 0): 20  Rolling back to Epoch (base 0): 15  Top Validation Acc: 0.935064935064935
Fold [5/5] Epoch [0/100] Initial Loss: 0.1384, Training Loss: 0.1384, Initial Validation Loss: 0.1350, Validation Loss: 0.1350,V Acc: 0.3056, Top 70th Acc: 0.2895, Bottom 30th Acc: 0.3438
Fold [5/5] Epoch [10/100] Initial Loss: 0.1384, Training Loss: 0.0165, Initial Validation Loss: 0.1350, Validation Loss: 0.0295,V Acc: 0.8796, Top 70th Acc: 0.9868, Bottom 30th Acc: 0.6250
Fold [5/5] Epoch [20/100] Initial Loss: 0.1384, Training Loss: 0.0051, Initial Validation Loss: 0.1350, Validation Loss: 0.0240,V Acc: 0.8611, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.6250
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.9736842105263158
14 4 [array([0.21951278, 0.02824294, 0.04234198, 0.1927559 , 0.5171464 ],
      dtype=float32)]
Running train_nn.py with seed 15
CUDA:False
Training samples count:  550
Training on 163 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1371, Training Loss: 0.1371, Initial Validation Loss: 0.1342, Validation Loss: 0.1342,V Acc: 0.2613, Top 70th Acc: 0.3590, Bottom 30th Acc: 0.0303
Fold [1/5] Epoch [10/100] Initial Loss: 0.1371, Training Loss: 0.0146, Initial Validation Loss: 0.1342, Validation Loss: 0.0450,V Acc: 0.7658, Top 70th Acc: 0.8462, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 15  Rolling back to Epoch (base 0): 10  Top Validation Acc: 0.8461538461538461
Fold [2/5] Epoch [0/100] Initial Loss: 0.1380, Training Loss: 0.1380, Initial Validation Loss: 0.1371, Validation Loss: 0.1371,V Acc: 0.2523, Top 70th Acc: 0.3205, Bottom 30th Acc: 0.0909
Fold [2/5] Epoch [10/100] Initial Loss: 0.1380, Training Loss: 0.0257, Initial Validation Loss: 0.1371, Validation Loss: 0.0355,V Acc: 0.8378, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.5758
Fold [2/5] Epoch [20/100] Initial Loss: 0.1380, Training Loss: 0.0056, Initial Validation Loss: 0.1371, Validation Loss: 0.0280,V Acc: 0.8739, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.6364
Fold [2/5] Epoch [30/100] Initial Loss: 0.1380, Training Loss: 0.0041, Initial Validation Loss: 0.1371, Validation Loss: 0.0264,V Acc: 0.8919, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.6970
Fold [2/5] Epoch [40/100] Initial Loss: 0.1380, Training Loss: 0.0038, Initial Validation Loss: 0.1371, Validation Loss: 0.0256,V Acc: 0.8739, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.6364
Fold [2/5] Epoch [50/100] Initial Loss: 0.1380, Training Loss: 0.0036, Initial Validation Loss: 0.1371, Validation Loss: 0.0252,V Acc: 0.8739, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.6364
Fold [2/5] Epoch [60/100] Initial Loss: 0.1380, Training Loss: 0.0036, Initial Validation Loss: 0.1371, Validation Loss: 0.0251,V Acc: 0.8739, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 60  Rolling back to Epoch (base 0): 55  Top Validation Acc: 0.9743589743589743
Fold [3/5] Epoch [0/100] Initial Loss: 0.1397, Training Loss: 0.1397, Initial Validation Loss: 0.1321, Validation Loss: 0.1321,V Acc: 0.3091, Top 70th Acc: 0.3506, Bottom 30th Acc: 0.2121
Fold [3/5] Epoch [10/100] Initial Loss: 0.1397, Training Loss: 0.0194, Initial Validation Loss: 0.1321, Validation Loss: 0.0355,V Acc: 0.8545, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.6970
Fold [3/5] Epoch [20/100] Initial Loss: 0.1397, Training Loss: 0.0063, Initial Validation Loss: 0.1321, Validation Loss: 0.0303,V Acc: 0.8636, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.6970
Fold [3/5] Epoch [30/100] Initial Loss: 0.1397, Training Loss: 0.0046, Initial Validation Loss: 0.1321, Validation Loss: 0.0274,V Acc: 0.8545, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6364
Fold [3/5] Epoch [40/100] Initial Loss: 0.1397, Training Loss: 0.0039, Initial Validation Loss: 0.1321, Validation Loss: 0.0256,V Acc: 0.8636, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 49  Rolling back to Epoch (base 0): 44  Top Validation Acc: 0.948051948051948
Fold [4/5] Epoch [0/100] Initial Loss: 0.1388, Training Loss: 0.1388, Initial Validation Loss: 0.1339, Validation Loss: 0.1339,V Acc: 0.2545, Top 70th Acc: 0.3506, Bottom 30th Acc: 0.0303
Fold [4/5] Epoch [10/100] Initial Loss: 0.1388, Training Loss: 0.0159, Initial Validation Loss: 0.1339, Validation Loss: 0.0330,V Acc: 0.8364, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 19  Rolling back to Epoch (base 0): 14  Top Validation Acc: 0.935064935064935
15 3 [array([0.23919113, 0.05142677, 0.07543401, 0.13976789, 0.49418032],
      dtype=float32)]
Fold [5/5] Epoch [0/100] Initial Loss: 0.1370, Training Loss: 0.1370, Initial Validation Loss: 0.1312, Validation Loss: 0.1312,V Acc: 0.2778, Top 70th Acc: 0.3553, Bottom 30th Acc: 0.0938
Fold [5/5] Epoch [10/100] Initial Loss: 0.1370, Training Loss: 0.0181, Initial Validation Loss: 0.1312, Validation Loss: 0.0391,V Acc: 0.8519, Top 70th Acc: 0.9211, Bottom 30th Acc: 0.6875
Fold [5/5] Epoch [20/100] Initial Loss: 0.1370, Training Loss: 0.0048, Initial Validation Loss: 0.1312, Validation Loss: 0.0297,V Acc: 0.8611, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.6250
Stopping early at Epoch (base 0): 29  Rolling back to Epoch (base 0): 24  Top Validation Acc: 0.9342105263157895
Running train_nn.py with seed 16
CUDA:False
Training samples count:  550
Training on 163 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1381, Training Loss: 0.1381, Initial Validation Loss: 0.1306, Validation Loss: 0.1306,V Acc: 0.2973, Top 70th Acc: 0.3590, Bottom 30th Acc: 0.1515
Fold [1/5] Epoch [10/100] Initial Loss: 0.1381, Training Loss: 0.0182, Initial Validation Loss: 0.1306, Validation Loss: 0.0481,V Acc: 0.7568, Top 70th Acc: 0.8590, Bottom 30th Acc: 0.5152
Fold [1/5] Epoch [20/100] Initial Loss: 0.1381, Training Loss: 0.0055, Initial Validation Loss: 0.1306, Validation Loss: 0.0403,V Acc: 0.7477, Top 70th Acc: 0.8846, Bottom 30th Acc: 0.4242
Fold [1/5] Epoch [30/100] Initial Loss: 0.1381, Training Loss: 0.0043, Initial Validation Loss: 0.1306, Validation Loss: 0.0392,V Acc: 0.7658, Top 70th Acc: 0.8846, Bottom 30th Acc: 0.4848
Fold [1/5] Epoch [40/100] Initial Loss: 0.1381, Training Loss: 0.0039, Initial Validation Loss: 0.1306, Validation Loss: 0.0383,V Acc: 0.7658, Top 70th Acc: 0.8974, Bottom 30th Acc: 0.4545
Stopping early at Epoch (base 0): 48  Rolling back to Epoch (base 0): 43  Top Validation Acc: 0.9102564102564102
Fold [2/5] Epoch [0/100] Initial Loss: 0.1392, Training Loss: 0.1392, Initial Validation Loss: 0.1346, Validation Loss: 0.1346,V Acc: 0.4685, Top 70th Acc: 0.5385, Bottom 30th Acc: 0.3030
Fold [2/5] Epoch [10/100] Initial Loss: 0.1392, Training Loss: 0.0138, Initial Validation Loss: 0.1346, Validation Loss: 0.0332,V Acc: 0.8468, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.5455
Fold [2/5] Epoch [20/100] Initial Loss: 0.1392, Training Loss: 0.0045, Initial Validation Loss: 0.1346, Validation Loss: 0.0278,V Acc: 0.8649, Top 70th Acc: 0.9872, Bottom 30th Acc: 0.5758
Fold [2/5] Epoch [30/100] Initial Loss: 0.1392, Training Loss: 0.0037, Initial Validation Loss: 0.1346, Validation Loss: 0.0275,V Acc: 0.8559, Top 70th Acc: 0.9872, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 31  Rolling back to Epoch (base 0): 26  Top Validation Acc: 0.9743589743589743
16 1 [array([0.47801176, 0.11403482, 0.05338721, 0.10196366, 0.25260258],
      dtype=float32)]
Fold [2/5] Epoch [10/100] Initial Loss: 0.1380, Training Loss: 0.0304, Initial Validation Loss: 0.1374, Validation Loss: 0.0398,V Acc: 0.8018, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.5152
Fold [2/5] Epoch [20/100] Initial Loss: 0.1380, Training Loss: 0.0184, Initial Validation Loss: 0.1374, Validation Loss: 0.0304,V Acc: 0.8288, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.5455
Fold [2/5] Epoch [30/100] Initial Loss: 0.1380, Training Loss: 0.0162, Initial Validation Loss: 0.1374, Validation Loss: 0.0283,V Acc: 0.8378, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 32  Rolling back to Epoch (base 0): 27  Top Validation Acc: 0.9615384615384616
Fold [3/5] Epoch [0/100] Initial Loss: 0.1388, Training Loss: 0.1388, Initial Validation Loss: 0.1332, Validation Loss: 0.1332,V Acc: 0.2727, Top 70th Acc: 0.3506, Bottom 30th Acc: 0.0909
Fold [3/5] Epoch [10/100] Initial Loss: 0.1388, Training Loss: 0.0303, Initial Validation Loss: 0.1332, Validation Loss: 0.0427,V Acc: 0.8091, Top 70th Acc: 0.8961, Bottom 30th Acc: 0.6061
Fold [3/5] Epoch [20/100] Initial Loss: 0.1388, Training Loss: 0.0170, Initial Validation Loss: 0.1332, Validation Loss: 0.0361,V Acc: 0.8273, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.948051948051948
Fold [4/5] Epoch [0/100] Initial Loss: 0.1380, Training Loss: 0.1380, Initial Validation Loss: 0.1334, Validation Loss: 0.1334,V Acc: 0.2545, Top 70th Acc: 0.3636, Bottom 30th Acc: 0.0000
Fold [4/5] Epoch [10/100] Initial Loss: 0.1380, Training Loss: 0.0275, Initial Validation Loss: 0.1334, Validation Loss: 0.0386,V Acc: 0.8273, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.5152
Fold [4/5] Epoch [20/100] Initial Loss: 0.1380, Training Loss: 0.0169, Initial Validation Loss: 0.1334, Validation Loss: 0.0354,V Acc: 0.8182, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 27  Rolling back to Epoch (base 0): 22  Top Validation Acc: 0.8961038961038961
Fold [5/5] Epoch [0/100] Initial Loss: 0.1383, Training Loss: 0.1383, Initial Validation Loss: 0.1302, Validation Loss: 0.1302,V Acc: 0.3611, Top 70th Acc: 0.4474, Bottom 30th Acc: 0.1562
Fold [5/5] Epoch [10/100] Initial Loss: 0.1383, Training Loss: 0.0367, Initial Validation Loss: 0.1302, Validation Loss: 0.0360,V Acc: 0.7963, Top 70th Acc: 0.8947, Bottom 30th Acc: 0.5625
Fold [5/5] Epoch [20/100] Initial Loss: 0.1383, Training Loss: 0.0198, Initial Validation Loss: 0.1302, Validation Loss: 0.0267,V Acc: 0.8426, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.5938
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.9342105263157895
17 4 [array([0.71893036, 0.07493888, 0.03389262, 0.07190635, 0.10033182],
      dtype=float32)]
Running train_nn.py with seed 18
CUDA:False
Training samples count:  550
Training on 30 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1404, Training Loss: 0.1404, Initial Validation Loss: 0.1358, Validation Loss: 0.1358,V Acc: 0.2523, Top 70th Acc: 0.3205, Bottom 30th Acc: 0.0909
Fold [1/5] Epoch [10/100] Initial Loss: 0.1404, Training Loss: 0.0386, Initial Validation Loss: 0.1358, Validation Loss: 0.0436,V Acc: 0.7928, Top 70th Acc: 0.8974, Bottom 30th Acc: 0.5455
Fold [1/5] Epoch [20/100] Initial Loss: 0.1404, Training Loss: 0.0183, Initial Validation Loss: 0.1358, Validation Loss: 0.0293,V Acc: 0.8378, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.5455
Fold [1/5] Epoch [30/100] Initial Loss: 0.1404, Training Loss: 0.0153, Initial Validation Loss: 0.1358, Validation Loss: 0.0279,V Acc: 0.8649, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.6364
Fold [1/5] Epoch [40/100] Initial Loss: 0.1404, Training Loss: 0.0143, Initial Validation Loss: 0.1358, Validation Loss: 0.0284,V Acc: 0.8468, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 40  Rolling back to Epoch (base 0): 35  Top Validation Acc: 0.9487179487179487
Fold [2/5] Epoch [0/100] Initial Loss: 0.1376, Training Loss: 0.1376, Initial Validation Loss: 0.1359, Validation Loss: 0.1359,V Acc: 0.3153, Top 70th Acc: 0.3590, Bottom 30th Acc: 0.2121
Fold [2/5] Epoch [10/100] Initial Loss: 0.1376, Training Loss: 0.0393, Initial Validation Loss: 0.1359, Validation Loss: 0.0421,V Acc: 0.8198, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.6061
Fold [2/5] Epoch [20/100] Initial Loss: 0.1376, Training Loss: 0.0183, Initial Validation Loss: 0.1359, Validation Loss: 0.0254,V Acc: 0.8919, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.7273
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.9615384615384616
18 1 [array([0.5524524 , 0.11495237, 0.03553542, 0.06373091, 0.23332886],
      dtype=float32)]
Fold [3/5] Epoch [0/100] Initial Loss: 0.1399, Training Loss: 0.1399, Initial Validation Loss: 0.1373, Validation Loss: 0.1373,V Acc: 0.2545, Top 70th Acc: 0.2597, Bottom 30th Acc: 0.2424
Fold [3/5] Epoch [10/100] Initial Loss: 0.1399, Training Loss: 0.0383, Initial Validation Loss: 0.1373, Validation Loss: 0.0460,V Acc: 0.8000, Top 70th Acc: 0.8831, Bottom 30th Acc: 0.6061
Fold [3/5] Epoch [20/100] Initial Loss: 0.1399, Training Loss: 0.0185, Initial Validation Loss: 0.1373, Validation Loss: 0.0345,V Acc: 0.8545, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 27  Rolling back to Epoch (base 0): 22  Top Validation Acc: 0.961038961038961
Fold [4/5] Epoch [0/100] Initial Loss: 0.1425, Training Loss: 0.1425, Initial Validation Loss: 0.1321, Validation Loss: 0.1321,V Acc: 0.3091, Top 70th Acc: 0.3247, Bottom 30th Acc: 0.2727
Fold [4/5] Epoch [10/100] Initial Loss: 0.1425, Training Loss: 0.0305, Initial Validation Loss: 0.1321, Validation Loss: 0.0363,V Acc: 0.8455, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.6667
Fold [4/5] Epoch [20/100] Initial Loss: 0.1425, Training Loss: 0.0166, Initial Validation Loss: 0.1321, Validation Loss: 0.0286,V Acc: 0.8273, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.948051948051948
Fold [5/5] Epoch [0/100] Initial Loss: 0.1420, Training Loss: 0.1420, Initial Validation Loss: 0.1341, Validation Loss: 0.1341,V Acc: 0.2593, Top 70th Acc: 0.2895, Bottom 30th Acc: 0.1875
Fold [5/5] Epoch [10/100] Initial Loss: 0.1420, Training Loss: 0.0388, Initial Validation Loss: 0.1341, Validation Loss: 0.0433,V Acc: 0.8056, Top 70th Acc: 0.9211, Bottom 30th Acc: 0.5312
Fold [5/5] Epoch [20/100] Initial Loss: 0.1420, Training Loss: 0.0257, Initial Validation Loss: 0.1341, Validation Loss: 0.0363,V Acc: 0.7778, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.3750
Fold [5/5] Epoch [30/100] Initial Loss: 0.1420, Training Loss: 0.0185, Initial Validation Loss: 0.1341, Validation Loss: 0.0298,V Acc: 0.8611, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.6250
Fold [5/5] Epoch [40/100] Initial Loss: 0.1420, Training Loss: 0.0156, Initial Validation Loss: 0.1341, Validation Loss: 0.0266,V Acc: 0.8519, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.6250
Fold [5/5] Epoch [50/100] Initial Loss: 0.1420, Training Loss: 0.0142, Initial Validation Loss: 0.1341, Validation Loss: 0.0267,V Acc: 0.8426, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.5625
Stopping early at Epoch (base 0): 52  Rolling back to Epoch (base 0): 47  Top Validation Acc: 0.9736842105263158
Running train_nn.py with seed 19
CUDA:False
Training samples count:  550
Training on 30 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1394, Training Loss: 0.1394, Initial Validation Loss: 0.1343, Validation Loss: 0.1343,V Acc: 0.2523, Top 70th Acc: 0.3205, Bottom 30th Acc: 0.0909
Fold [1/5] Epoch [10/100] Initial Loss: 0.1394, Training Loss: 0.0384, Initial Validation Loss: 0.1343, Validation Loss: 0.0424,V Acc: 0.8288, Top 70th Acc: 0.8974, Bottom 30th Acc: 0.6667
Fold [1/5] Epoch [20/100] Initial Loss: 0.1394, Training Loss: 0.0184, Initial Validation Loss: 0.1343, Validation Loss: 0.0331,V Acc: 0.8649, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 29  Rolling back to Epoch (base 0): 24  Top Validation Acc: 0.9487179487179487
Fold [2/5] Epoch [0/100] Initial Loss: 0.1378, Training Loss: 0.1378, Initial Validation Loss: 0.1288, Validation Loss: 0.1288,V Acc: 0.3153, Top 70th Acc: 0.4103, Bottom 30th Acc: 0.0909
Fold [5/5] Epoch [30/100] Initial Loss: 0.1315, Training Loss: 0.0184, Initial Validation Loss: 0.1146, Validation Loss: 0.0189,V Acc: 0.8796, Top 70th Acc: 1.0000, Bottom 30th Acc: 0.5938
Stopping early at Epoch (base 0): 39  Rolling back to Epoch (base 0): 34  Top Validation Acc: 0.9868421052631579
Running train_nn.py with seed 26
CUDA:False
Training samples count:  550
Training on 21 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1327, Training Loss: 0.1327, Initial Validation Loss: 0.1210, Validation Loss: 0.1210,V Acc: 0.5315, Top 70th Acc: 0.5897, Bottom 30th Acc: 0.3939
Fold [1/5] Epoch [10/100] Initial Loss: 0.1327, Training Loss: 0.0203, Initial Validation Loss: 0.1210, Validation Loss: 0.0309,V Acc: 0.8378, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 12  Rolling back to Epoch (base 0): 7  Top Validation Acc: 0.9743589743589743
Fold [2/5] Epoch [0/100] Initial Loss: 0.1380, Training Loss: 0.1380, Initial Validation Loss: 0.1323, Validation Loss: 0.1323,V Acc: 0.3423, Top 70th Acc: 0.4615, Bottom 30th Acc: 0.0606
Fold [2/5] Epoch [10/100] Initial Loss: 0.1380, Training Loss: 0.0265, Initial Validation Loss: 0.1323, Validation Loss: 0.0252,V Acc: 0.9009, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.7273
Fold [2/5] Epoch [20/100] Initial Loss: 0.1380, Training Loss: 0.0196, Initial Validation Loss: 0.1323, Validation Loss: 0.0234,V Acc: 0.8739, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 22  Rolling back to Epoch (base 0): 17  Top Validation Acc: 0.9743589743589743
Fold [3/5] Epoch [0/100] Initial Loss: 0.1366, Training Loss: 0.1366, Initial Validation Loss: 0.1263, Validation Loss: 0.1263,V Acc: 0.3727, Top 70th Acc: 0.4026, Bottom 30th Acc: 0.3030
Fold [3/5] Epoch [10/100] Initial Loss: 0.1366, Training Loss: 0.0228, Initial Validation Loss: 0.1263, Validation Loss: 0.0250,V Acc: 0.8909, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 19  Rolling back to Epoch (base 0): 14  Top Validation Acc: 0.948051948051948
26 2 [array([0.7096597 , 0.01443345, 0.03566473, 0.09297898, 0.14726312],
      dtype=float32)]
Fold [4/5] Epoch [0/100] Initial Loss: 0.1377, Training Loss: 0.1377, Initial Validation Loss: 0.1237, Validation Loss: 0.1237,V Acc: 0.3727, Top 70th Acc: 0.4935, Bottom 30th Acc: 0.0909
Fold [4/5] Epoch [10/100] Initial Loss: 0.1377, Training Loss: 0.0238, Initial Validation Loss: 0.1237, Validation Loss: 0.0326,V Acc: 0.8091, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.4545
Fold [4/5] Epoch [20/100] Initial Loss: 0.1377, Training Loss: 0.0165, Initial Validation Loss: 0.1237, Validation Loss: 0.0280,V Acc: 0.8273, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.922077922077922
Fold [5/5] Epoch [0/100] Initial Loss: 0.1198, Training Loss: 0.1198, Initial Validation Loss: 0.1019, Validation Loss: 0.1019,V Acc: 0.5741, Top 70th Acc: 0.6974, Bottom 30th Acc: 0.2812
Fold [5/5] Epoch [10/100] Initial Loss: 0.1198, Training Loss: 0.0209, Initial Validation Loss: 0.1019, Validation Loss: 0.0228,V Acc: 0.9074, Top 70th Acc: 0.9868, Bottom 30th Acc: 0.7188
Stopping early at Epoch (base 0): 15  Rolling back to Epoch (base 0): 10  Top Validation Acc: 0.9605263157894737
Running train_nn.py with seed 27
CUDA:False
Training samples count:  550
Training on 21 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1365, Training Loss: 0.1365, Initial Validation Loss: 0.1254, Validation Loss: 0.1254,V Acc: 0.5135, Top 70th Acc: 0.6026, Bottom 30th Acc: 0.3030
Fold [1/5] Epoch [10/100] Initial Loss: 0.1365, Training Loss: 0.0274, Initial Validation Loss: 0.1254, Validation Loss: 0.0385,V Acc: 0.8378, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.5758
Fold [1/5] Epoch [20/100] Initial Loss: 0.1365, Training Loss: 0.0169, Initial Validation Loss: 0.1254, Validation Loss: 0.0323,V Acc: 0.8468, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.9358974358974359
Fold [2/5] Epoch [0/100] Initial Loss: 0.1339, Training Loss: 0.1339, Initial Validation Loss: 0.1218, Validation Loss: 0.1218,V Acc: 0.4324, Top 70th Acc: 0.5897, Bottom 30th Acc: 0.0606
Fold [2/5] Epoch [10/100] Initial Loss: 0.1339, Training Loss: 0.0246, Initial Validation Loss: 0.1218, Validation Loss: 0.0281,V Acc: 0.8739, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 17  Rolling back to Epoch (base 0): 12  Top Validation Acc: 0.9871794871794872
Fold [3/5] Epoch [0/100] Initial Loss: 0.1384, Training Loss: 0.1384, Initial Validation Loss: 0.1276, Validation Loss: 0.1276,V Acc: 0.3455, Top 70th Acc: 0.3766, Bottom 30th Acc: 0.2727
Fold [3/5] Epoch [10/100] Initial Loss: 0.1384, Training Loss: 0.0277, Initial Validation Loss: 0.1276, Validation Loss: 0.0364,V Acc: 0.8000, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.5152
Fold [3/5] Epoch [20/100] Initial Loss: 0.1384, Training Loss: 0.0177, Initial Validation Loss: 0.1276, Validation Loss: 0.0313,V Acc: 0.8091, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.5455
Fold [3/5] Epoch [30/100] Initial Loss: 0.1384, Training Loss: 0.0161, Initial Validation Loss: 0.1276, Validation Loss: 0.0266,V Acc: 0.8364, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 31  Rolling back to Epoch (base 0): 26  Top Validation Acc: 0.948051948051948
Fold [4/5] Epoch [0/100] Initial Loss: 0.1299, Training Loss: 0.1299, Initial Validation Loss: 0.1186, Validation Loss: 0.1186,V Acc: 0.4455, Top 70th Acc: 0.5714, Bottom 30th Acc: 0.1515
Fold [4/5] Epoch [10/100] Initial Loss: 0.1299, Training Loss: 0.0252, Initial Validation Loss: 0.1186, Validation Loss: 0.0294,V Acc: 0.8909, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 18  Rolling back to Epoch (base 0): 13  Top Validation Acc: 0.948051948051948
Fold [5/5] Epoch [0/100] Initial Loss: 0.1273, Training Loss: 0.1273, Initial Validation Loss: 0.1143, Validation Loss: 0.1143,V Acc: 0.4630, Top 70th Acc: 0.5263, Bottom 30th Acc: 0.3125
Fold [5/5] Epoch [10/100] Initial Loss: 0.1273, Training Loss: 0.0245, Initial Validation Loss: 0.1143, Validation Loss: 0.0285,V Acc: 0.8796, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.6875
Fold [5/5] Epoch [20/100] Initial Loss: 0.1273, Training Loss: 0.0172, Initial Validation Loss: 0.1143, Validation Loss: 0.0259,V Acc: 0.8796, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.7500
Fold [5/5] Epoch [30/100] Initial Loss: 0.1273, Training Loss: 0.0143, Initial Validation Loss: 0.1143, Validation Loss: 0.0290,V Acc: 0.8333, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.5312
Stopping early at Epoch (base 0): 31  Rolling back to Epoch (base 0): 26  Top Validation Acc: 0.9473684210526315
27 4 [array([0.7807744 , 0.01860569, 0.02477937, 0.08783983, 0.08800071],
      dtype=float32)]
Running train_nn.py with seed 28
CUDA:False
Training samples count:  550
Training on 21 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1335, Training Loss: 0.1335, Initial Validation Loss: 0.1286, Validation Loss: 0.1286,V Acc: 0.4595, Top 70th Acc: 0.5513, Bottom 30th Acc: 0.2424
Fold [1/5] Epoch [10/100] Initial Loss: 0.1335, Training Loss: 0.0236, Initial Validation Loss: 0.1286, Validation Loss: 0.0293,V Acc: 0.8559, Top 70th Acc: 1.0000, Bottom 30th Acc: 0.5152
Stopping early at Epoch (base 0): 18  Rolling back to Epoch (base 0): 13  Top Validation Acc: 0.9743589743589743
Fold [2/5] Epoch [0/100] Initial Loss: 0.1348, Training Loss: 0.1348, Initial Validation Loss: 0.1210, Validation Loss: 0.1210,V Acc: 0.4505, Top 70th Acc: 0.5641, Bottom 30th Acc: 0.1818
Fold [2/5] Epoch [10/100] Initial Loss: 0.1348, Training Loss: 0.0235, Initial Validation Loss: 0.1210, Validation Loss: 0.0274,V Acc: 0.8649, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.6667
Fold [2/5] Epoch [20/100] Initial Loss: 0.1348, Training Loss: 0.0160, Initial Validation Loss: 0.1210, Validation Loss: 0.0241,V Acc: 0.8829, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.7576
Stopping early at Epoch (base 0): 22  Rolling back to Epoch (base 0): 17  Top Validation Acc: 0.9615384615384616
28 1 [array([0.7775649 , 0.01519181, 0.02844332, 0.08640388, 0.09239616],
      dtype=float32)]
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 21 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 91
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 21 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 92
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 21 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 93
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 21 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 94
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 21 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 95
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 21 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 96
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 21 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 97
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 21 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 98
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 21 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 99
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 21 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 100
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 21 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5

Fold [3/5] Epoch [20/100] Initial Loss: 0.1429, Training Loss: 0.0134, Initial Validation Loss: 0.1368, Validation Loss: 0.0336,V Acc: 0.8091, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.4545
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.974025974025974
Fold [4/5] Epoch [0/100] Initial Loss: 0.1397, Training Loss: 0.1397, Initial Validation Loss: 0.1330, Validation Loss: 0.1330,V Acc: 0.2545, Top 70th Acc: 0.3247, Bottom 30th Acc: 0.0909
Fold [4/5] Epoch [10/100] Initial Loss: 0.1397, Training Loss: 0.0409, Initial Validation Loss: 0.1330, Validation Loss: 0.0505,V Acc: 0.7364, Top 70th Acc: 0.8701, Bottom 30th Acc: 0.4242
Fold [4/5] Epoch [20/100] Initial Loss: 0.1397, Training Loss: 0.0152, Initial Validation Loss: 0.1330, Validation Loss: 0.0317,V Acc: 0.8545, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.6667
Fold [4/5] Epoch [30/100] Initial Loss: 0.1397, Training Loss: 0.0120, Initial Validation Loss: 0.1330, Validation Loss: 0.0295,V Acc: 0.8818, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.7273
Stopping early at Epoch (base 0): 39  Rolling back to Epoch (base 0): 34  Top Validation Acc: 0.935064935064935
Fold [5/5] Epoch [0/100] Initial Loss: 0.1396, Training Loss: 0.1396, Initial Validation Loss: 0.1318, Validation Loss: 0.1318,V Acc: 0.2407, Top 70th Acc: 0.3289, Bottom 30th Acc: 0.0312
Fold [5/5] Epoch [10/100] Initial Loss: 0.1396, Training Loss: 0.0358, Initial Validation Loss: 0.1318, Validation Loss: 0.0365,V Acc: 0.8148, Top 70th Acc: 0.9079, Bottom 30th Acc: 0.5938
Fold [5/5] Epoch [20/100] Initial Loss: 0.1396, Training Loss: 0.0150, Initial Validation Loss: 0.1318, Validation Loss: 0.0259,V Acc: 0.8611, Top 70th Acc: 0.9211, Bottom 30th Acc: 0.7188
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.9473684210526315
17 4 [array([0.75653666, 0.02977339, 0.05209915, 0.1023737 , 0.0592172 ],
      dtype=float32)]
Running train_nn.py with seed 18
CUDA:False
Training samples count:  550
Training on 40 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1371, Training Loss: 0.1371, Initial Validation Loss: 0.1358, Validation Loss: 0.1358,V Acc: 0.2523, Top 70th Acc: 0.2949, Bottom 30th Acc: 0.1515
Fold [1/5] Epoch [10/100] Initial Loss: 0.1371, Training Loss: 0.0216, Initial Validation Loss: 0.1358, Validation Loss: 0.0362,V Acc: 0.8378, Top 70th Acc: 0.8846, Bottom 30th Acc: 0.7273
Fold [1/5] Epoch [20/100] Initial Loss: 0.1371, Training Loss: 0.0141, Initial Validation Loss: 0.1358, Validation Loss: 0.0326,V Acc: 0.8378, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.9230769230769231
Fold [2/5] Epoch [0/100] Initial Loss: 0.1389, Training Loss: 0.1389, Initial Validation Loss: 0.1361, Validation Loss: 0.1361,V Acc: 0.3604, Top 70th Acc: 0.3718, Bottom 30th Acc: 0.3333
Fold [2/5] Epoch [10/100] Initial Loss: 0.1389, Training Loss: 0.0383, Initial Validation Loss: 0.1361, Validation Loss: 0.0426,V Acc: 0.8288, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.5758
Fold [2/5] Epoch [20/100] Initial Loss: 0.1389, Training Loss: 0.0169, Initial Validation Loss: 0.1361, Validation Loss: 0.0254,V Acc: 0.9009, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.7273
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.9615384615384616
18 1 [array([0.6304236 , 0.0576923 , 0.0564965 , 0.10615041, 0.14923714],
      dtype=float32)]
Fold [3/5] Epoch [0/100] Initial Loss: 0.1390, Training Loss: 0.1390, Initial Validation Loss: 0.1339, Validation Loss: 0.1339,V Acc: 0.3273, Top 70th Acc: 0.3766, Bottom 30th Acc: 0.2121
Fold [3/5] Epoch [10/100] Initial Loss: 0.1390, Training Loss: 0.0274, Initial Validation Loss: 0.1339, Validation Loss: 0.0404,V Acc: 0.8273, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.6061
Fold [3/5] Epoch [20/100] Initial Loss: 0.1390, Training Loss: 0.0139, Initial Validation Loss: 0.1339, Validation Loss: 0.0378,V Acc: 0.8091, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 20  Rolling back to Epoch (base 0): 15  Top Validation Acc: 0.922077922077922
Fold [4/5] Epoch [0/100] Initial Loss: 0.1357, Training Loss: 0.1357, Initial Validation Loss: 0.1250, Validation Loss: 0.1250,V Acc: 0.4091, Top 70th Acc: 0.4286, Bottom 30th Acc: 0.3636
Fold [4/5] Epoch [10/100] Initial Loss: 0.1357, Training Loss: 0.0256, Initial Validation Loss: 0.1250, Validation Loss: 0.0392,V Acc: 0.8182, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.6061
Fold [4/5] Epoch [20/100] Initial Loss: 0.1357, Training Loss: 0.0126, Initial Validation Loss: 0.1250, Validation Loss: 0.0333,V Acc: 0.8273, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.948051948051948
Fold [5/5] Epoch [0/100] Initial Loss: 0.1367, Training Loss: 0.1367, Initial Validation Loss: 0.1305, Validation Loss: 0.1305,V Acc: 0.2963, Top 70th Acc: 0.3421, Bottom 30th Acc: 0.1875
Fold [5/5] Epoch [10/100] Initial Loss: 0.1367, Training Loss: 0.0310, Initial Validation Loss: 0.1305, Validation Loss: 0.0345,V Acc: 0.8333, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.5938
Fold [5/5] Epoch [20/100] Initial Loss: 0.1367, Training Loss: 0.0149, Initial Validation Loss: 0.1305, Validation Loss: 0.0274,V Acc: 0.8611, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.6562
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.9473684210526315
Running train_nn.py with seed 19
CUDA:False
Training samples count:  550
Training on 40 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1374, Training Loss: 0.1374, Initial Validation Loss: 0.1342, Validation Loss: 0.1342,V Acc: 0.2523, Top 70th Acc: 0.2949, Bottom 30th Acc: 0.1515
Fold [1/5] Epoch [10/100] Initial Loss: 0.1374, Training Loss: 0.0254, Initial Validation Loss: 0.1342, Validation Loss: 0.0335,V Acc: 0.8378, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.5455
Fold [1/5] Epoch [20/100] Initial Loss: 0.1374, Training Loss: 0.0143, Initial Validation Loss: 0.1342, Validation Loss: 0.0302,V Acc: 0.8288, Top 70th Acc: 0.9872, Bottom 30th Acc: 0.4545
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.9871794871794872
Fold [2/5] Epoch [0/100] Initial Loss: 0.1435, Training Loss: 0.1435, Initial Validation Loss: 0.1331, Validation Loss: 0.1331,V Acc: 0.2613, Top 70th Acc: 0.3077, Bottom 30th Acc: 0.1515
Fold [2/5] Epoch [10/100] Initial Loss: 0.1435, Training Loss: 0.0400, Initial Validation Loss: 0.1331, Validation Loss: 0.0429,V Acc: 0.7658, Top 70th Acc: 0.8846, Bottom 30th Acc: 0.4848
Fold [2/5] Epoch [20/100] Initial Loss: 0.1435, Training Loss: 0.0160, Initial Validation Loss: 0.1331, Validation Loss: 0.0289,V Acc: 0.8198, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.5455
Fold [2/5] Epoch [30/100] Initial Loss: 0.1435, Training Loss: 0.0116, Initial Validation Loss: 0.1331, Validation Loss: 0.0267,V Acc: 0.8288, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 31  Rolling back to Epoch (base 0): 26  Top Validation Acc: 0.9358974358974359
Fold [3/5] Epoch [0/100] Initial Loss: 0.1398, Training Loss: 0.1398, Initial Validation Loss: 0.1351, Validation Loss: 0.1351,V Acc: 0.3273, Top 70th Acc: 0.3766, Bottom 30th Acc: 0.2121
Fold [3/5] Epoch [10/100] Initial Loss: 0.1398, Training Loss: 0.0460, Initial Validation Loss: 0.1351, Validation Loss: 0.0439,V Acc: 0.7909, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.4242
Fold [3/5] Epoch [20/100] Initial Loss: 0.1398, Training Loss: 0.0238, Initial Validation Loss: 0.1351, Validation Loss: 0.0322,V Acc: 0.8727, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.6667
Fold [3/5] Epoch [30/100] Initial Loss: 0.1398, Training Loss: 0.0159, Initial Validation Loss: 0.1351, Validation Loss: 0.0269,V Acc: 0.8727, Top 70th Acc: 0.9870, Bottom 30th Acc: 0.6061
Fold [3/5] Epoch [40/100] Initial Loss: 0.1398, Training Loss: 0.0127, Initial Validation Loss: 0.1351, Validation Loss: 0.0225,V Acc: 0.9000, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.7273
Fold [3/5] Epoch [50/100] Initial Loss: 0.1398, Training Loss: 0.0115, Initial Validation Loss: 0.1351, Validation Loss: 0.0221,V Acc: 0.9091, Top 70th Acc: 0.9870, Bottom 30th Acc: 0.7273training rf with seed 1
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 163 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 2
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 163 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 3
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 163 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 4
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 163 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 5
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 163 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 6
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 163 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 7
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 163 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 8
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 163 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 9
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 163 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 10
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 163 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 11
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 163 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 12
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 163 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 13
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 163 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 14
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 163 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 15
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 163 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 16
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 163 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 17
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 163 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 18
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 163 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 19
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 163 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 20
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 163 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 21
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 163 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 22
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 163 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 23
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 163 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 24
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 163 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 25
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 163 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 26
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 163 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 27
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 163 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 28
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 163 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 29
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 163 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 30
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 163 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 31
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 163 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 32
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 163 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 33
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 163 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 34
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 163 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 35
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 163 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 36
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 163 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 37
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 163 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 38
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 163 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 39
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 163 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 40
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 163 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 41
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 163 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 42
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 163 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 43
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 163 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 44
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 163 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 45
Training size: 439
Training size: 439
Stopping early at Epoch (base 0): 41  Rolling back to Epoch (base 0): 36  Top Validation Acc: 0.961038961038961
Fold [4/5] Epoch [0/100] Initial Loss: 0.1385, Training Loss: 0.1385, Initial Validation Loss: 0.1377, Validation Loss: 0.1377,V Acc: 0.2545, Top 70th Acc: 0.3117, Bottom 30th Acc: 0.1212
Fold [4/5] Epoch [10/100] Initial Loss: 0.1385, Training Loss: 0.0364, Initial Validation Loss: 0.1377, Validation Loss: 0.0419,V Acc: 0.8273, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.6364
Fold [4/5] Epoch [20/100] Initial Loss: 0.1385, Training Loss: 0.0232, Initial Validation Loss: 0.1377, Validation Loss: 0.0314,V Acc: 0.8455, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.935064935064935
19 3 [array([0.22996488, 0.08900928, 0.13716583, 0.3784457 , 0.1654143 ],
      dtype=float32)]
Fold [5/5] Epoch [0/100] Initial Loss: 0.1371, Training Loss: 0.1371, Initial Validation Loss: 0.1328, Validation Loss: 0.1328,V Acc: 0.3519, Top 70th Acc: 0.3947, Bottom 30th Acc: 0.2500
Fold [5/5] Epoch [10/100] Initial Loss: 0.1371, Training Loss: 0.0331, Initial Validation Loss: 0.1328, Validation Loss: 0.0450,V Acc: 0.7870, Top 70th Acc: 0.8947, Bottom 30th Acc: 0.5312
Fold [5/5] Epoch [20/100] Initial Loss: 0.1371, Training Loss: 0.0214, Initial Validation Loss: 0.1328, Validation Loss: 0.0396,V Acc: 0.7963, Top 70th Acc: 0.9079, Bottom 30th Acc: 0.5312
Stopping early at Epoch (base 0): 22  Rolling back to Epoch (base 0): 17  Top Validation Acc: 0.9210526315789473
Running train_nn.py with seed 20
CUDA:False
Training samples count:  550
Training on 20 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1360, Training Loss: 0.1360, Initial Validation Loss: 0.1297, Validation Loss: 0.1297,V Acc: 0.4505, Top 70th Acc: 0.5385, Bottom 30th Acc: 0.2424
Fold [1/5] Epoch [10/100] Initial Loss: 0.1360, Training Loss: 0.0346, Initial Validation Loss: 0.1297, Validation Loss: 0.0434,V Acc: 0.7838, Top 70th Acc: 0.8974, Bottom 30th Acc: 0.5152
Fold [1/5] Epoch [20/100] Initial Loss: 0.1360, Training Loss: 0.0228, Initial Validation Loss: 0.1297, Validation Loss: 0.0410,V Acc: 0.7838, Top 70th Acc: 0.8846, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 21  Rolling back to Epoch (base 0): 16  Top Validation Acc: 0.8846153846153846
Fold [2/5] Epoch [0/100] Initial Loss: 0.1359, Training Loss: 0.1359, Initial Validation Loss: 0.1369, Validation Loss: 0.1369,V Acc: 0.2703, Top 70th Acc: 0.3590, Bottom 30th Acc: 0.0606
Fold [2/5] Epoch [10/100] Initial Loss: 0.1359, Training Loss: 0.0543, Initial Validation Loss: 0.1369, Validation Loss: 0.0574,V Acc: 0.7477, Top 70th Acc: 0.8590, Bottom 30th Acc: 0.4848
Fold [2/5] Epoch [20/100] Initial Loss: 0.1359, Training Loss: 0.0275, Initial Validation Loss: 0.1369, Validation Loss: 0.0347,V Acc: 0.8559, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.6667
Fold [2/5] Epoch [30/100] Initial Loss: 0.1359, Training Loss: 0.0226, Initial Validation Loss: 0.1369, Validation Loss: 0.0327,V Acc: 0.8739, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.7879
Stopping early at Epoch (base 0): 34  Rolling back to Epoch (base 0): 29  Top Validation Acc: 0.9102564102564102
Fold [3/5] Epoch [0/100] Initial Loss: 0.1402, Training Loss: 0.1402, Initial Validation Loss: 0.1315, Validation Loss: 0.1315,V Acc: 0.2727, Top 70th Acc: 0.2727, Bottom 30th Acc: 0.2727
Fold [3/5] Epoch [10/100] Initial Loss: 0.1402, Training Loss: 0.0420, Initial Validation Loss: 0.1315, Validation Loss: 0.0397,V Acc: 0.8000, Top 70th Acc: 0.8442, Bottom 30th Acc: 0.6970
Fold [3/5] Epoch [20/100] Initial Loss: 0.1402, Training Loss: 0.0242, Initial Validation Loss: 0.1315, Validation Loss: 0.0292,V Acc: 0.8091, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.5152
Stopping early at Epoch (base 0): 27  Rolling back to Epoch (base 0): 22  Top Validation Acc: 0.9090909090909091
Fold [4/5] Epoch [0/100] Initial Loss: 0.1392, Training Loss: 0.1392, Initial Validation Loss: 0.1349, Validation Loss: 0.1349,V Acc: 0.3273, Top 70th Acc: 0.3377, Bottom 30th Acc: 0.3030
Fold [4/5] Epoch [10/100] Initial Loss: 0.1392, Training Loss: 0.0345, Initial Validation Loss: 0.1349, Validation Loss: 0.0384,V Acc: 0.8000, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.4848
Fold [4/5] Epoch [20/100] Initial Loss: 0.1392, Training Loss: 0.0234, Initial Validation Loss: 0.1349, Validation Loss: 0.0337,V Acc: 0.8000, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.5152
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.9090909090909091
Fold [5/5] Epoch [0/100] Initial Loss: 0.1374, Training Loss: 0.1374, Initial Validation Loss: 0.1323, Validation Loss: 0.1323,V Acc: 0.3704, Top 70th Acc: 0.3816, Bottom 30th Acc: 0.3438
Fold [5/5] Epoch [10/100] Initial Loss: 0.1374, Training Loss: 0.0339, Initial Validation Loss: 0.1323, Validation Loss: 0.0463,V Acc: 0.7685, Top 70th Acc: 0.8421, Bottom 30th Acc: 0.5938
Fold [5/5] Epoch [20/100] Initial Loss: 0.1374, Training Loss: 0.0222, Initial Validation Loss: 0.1323, Validation Loss: 0.0411,V Acc: 0.8241, Top 70th Acc: 0.9079, Bottom 30th Acc: 0.6250
Stopping early at Epoch (base 0): 29  Rolling back to Epoch (base 0): 24  Top Validation Acc: 0.8947368421052632
20 4 [array([0.22165865, 0.12934186, 0.10707389, 0.25413716, 0.28778848],
      dtype=float32)]
Running train_nn.py with seed 21
CUDA:False
Training samples count:  550
Training on 20 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1381, Training Loss: 0.1381, Initial Validation Loss: 0.1348, Validation Loss: 0.1348,V Acc: 0.3604, Top 70th Acc: 0.4231, Bottom 30th Acc: 0.2121
Fold [1/5] Epoch [10/100] Initial Loss: 0.1381, Training Loss: 0.0531, Initial Validation Loss: 0.1348, Validation Loss: 0.0543,V Acc: 0.7297, Top 70th Acc: 0.8590, Bottom 30th Acc: 0.4242
Fold [1/5] Epoch [20/100] Initial Loss: 0.1381, Training Loss: 0.0270, Initial Validation Loss: 0.1348, Validation Loss: 0.0290,V Acc: 0.8829, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.7273
Fold [1/5] Epoch [30/100] Initial Loss: 0.1381, Training Loss: 0.0229, Initial Validation Loss: 0.1348, Validation Loss: 0.0253,V Acc: 0.9009, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.7576
Stopping early at Epoch (base 0): 35  Rolling back to Epoch (base 0): 30  Top Validation Acc: 0.9743589743589743
Fold [2/5] Epoch [0/100] Initial Loss: 0.1365, Training Loss: 0.1365, Initial Validation Loss: 0.1300, Validation Loss: 0.1300,V Acc: 0.4505, Top 70th Acc: 0.5385, Bottom 30th Acc: 0.2424
Fold [2/5] Epoch [10/100] Initial Loss: 0.1365, Training Loss: 0.0318, Initial Validation Loss: 0.1300, Validation Loss: 0.0368,V Acc: 0.8288, Top 70th Acc: 0.8846, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 18  Rolling back to Epoch (base 0): 13  Top Validation Acc: 0.9102564102564102
Fold [3/5] Epoch [0/100] Initial Loss: 0.1378, Training Loss: 0.1378, Initial Validation Loss: 0.1332, Validation Loss: 0.1332,V Acc: 0.2727, Top 70th Acc: 0.2987, Bottom 30th Acc: 0.2121
Fold [3/5] Epoch [10/100] Initial Loss: 0.1378, Training Loss: 0.0414, Initial Validation Loss: 0.1332, Validation Loss: 0.0468,V Acc: 0.7727, Top 70th Acc: 0.8961, Bottom 30th Acc: 0.4848
Fold [3/5] Epoch [20/100] Initial Loss: 0.1378, Training Loss: 0.0230, Initial Validation Loss: 0.1332, Validation Loss: 0.0392,V Acc: 0.8273, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.6061
Fold [3/5] Epoch [30/100] Initial Loss: 0.1378, Training Loss: 0.0190, Initial Validation Loss: 0.1332, Validation Loss: 0.0373,V Acc: 0.8455, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 39  Rolling back to Epoch (base 0): 34  Top Validation Acc: 0.922077922077922
21 2 [array([0.3599352 , 0.07824744, 0.14828388, 0.23326375, 0.18026967],
      dtype=float32)]
Fold [4/5] Epoch [0/100] Initial Loss: 0.1398, Training Loss: 0.1398, Initial Validation Loss: 0.1348, Validation Loss: 0.1348,V Acc: 0.2000, Top 70th Acc: 0.1948, Bottom 30th Acc: 0.2121
Fold [4/5] Epoch [10/100] Initial Loss: 0.1398, Training Loss: 0.0367, Initial Validation Loss: 0.1348, Validation Loss: 0.0432,V Acc: 0.8091, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.5455
Fold [4/5] Epoch [20/100] Initial Loss: 0.1398, Training Loss: 0.0236, Initial Validation Loss: 0.1348, Validation Loss: 0.0333,V Acc: 0.8636, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6667
Fold [2/5] Epoch [10/100] Initial Loss: 0.1368, Training Loss: 0.0820, Initial Validation Loss: 0.1336, Validation Loss: 0.0779,V Acc: 0.6667, Top 70th Acc: 0.7821, Bottom 30th Acc: 0.3939
Fold [2/5] Epoch [20/100] Initial Loss: 0.1368, Training Loss: 0.0803, Initial Validation Loss: 0.1336, Validation Loss: 0.0759,V Acc: 0.6486, Top 70th Acc: 0.7821, Bottom 30th Acc: 0.3333
Fold [2/5] Epoch [30/100] Initial Loss: 0.1368, Training Loss: 0.0797, Initial Validation Loss: 0.1336, Validation Loss: 0.0764,V Acc: 0.6667, Top 70th Acc: 0.7564, Bottom 30th Acc: 0.4545
Stopping early at Epoch (base 0): 33  Rolling back to Epoch (base 0): 28  Top Validation Acc: 0.782051282051282
18 1 [array([0.14560711, 0.3895315 , 0.12861602, 0.2001624 , 0.13608302],
      dtype=float32)]
Fold [3/5] Epoch [0/100] Initial Loss: 0.1365, Training Loss: 0.1365, Initial Validation Loss: 0.1305, Validation Loss: 0.1305,V Acc: 0.3727, Top 70th Acc: 0.5065, Bottom 30th Acc: 0.0606
Fold [3/5] Epoch [10/100] Initial Loss: 0.1365, Training Loss: 0.0788, Initial Validation Loss: 0.1305, Validation Loss: 0.0875,V Acc: 0.5727, Top 70th Acc: 0.7013, Bottom 30th Acc: 0.2727
Stopping early at Epoch (base 0): 17  Rolling back to Epoch (base 0): 12  Top Validation Acc: 0.7012987012987013
Fold [4/5] Epoch [0/100] Initial Loss: 0.1305, Training Loss: 0.1305, Initial Validation Loss: 0.1142, Validation Loss: 0.1142,V Acc: 0.5091, Top 70th Acc: 0.6364, Bottom 30th Acc: 0.2121
Fold [4/5] Epoch [10/100] Initial Loss: 0.1305, Training Loss: 0.0794, Initial Validation Loss: 0.1142, Validation Loss: 0.0841,V Acc: 0.6000, Top 70th Acc: 0.6753, Bottom 30th Acc: 0.4242
Stopping early at Epoch (base 0): 18  Rolling back to Epoch (base 0): 13  Top Validation Acc: 0.6753246753246753
Fold [5/5] Epoch [0/100] Initial Loss: 0.1379, Training Loss: 0.1379, Initial Validation Loss: 0.1305, Validation Loss: 0.1305,V Acc: 0.3148, Top 70th Acc: 0.3684, Bottom 30th Acc: 0.1875
Fold [5/5] Epoch [10/100] Initial Loss: 0.1379, Training Loss: 0.0813, Initial Validation Loss: 0.1305, Validation Loss: 0.0767,V Acc: 0.6204, Top 70th Acc: 0.7632, Bottom 30th Acc: 0.2812
Fold [5/5] Epoch [20/100] Initial Loss: 0.1379, Training Loss: 0.0783, Initial Validation Loss: 0.1305, Validation Loss: 0.0780,V Acc: 0.6296, Top 70th Acc: 0.7632, Bottom 30th Acc: 0.3125
Fold [5/5] Epoch [30/100] Initial Loss: 0.1379, Training Loss: 0.0774, Initial Validation Loss: 0.1305, Validation Loss: 0.0740,V Acc: 0.6389, Top 70th Acc: 0.7763, Bottom 30th Acc: 0.3125
Stopping early at Epoch (base 0): 35  Rolling back to Epoch (base 0): 30  Top Validation Acc: 0.7631578947368421
Running train_nn.py with seed 19
CUDA:False
Training samples count:  550
Training on 2 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1380, Training Loss: 0.1380, Initial Validation Loss: 0.1312, Validation Loss: 0.1312,V Acc: 0.2793, Top 70th Acc: 0.3590, Bottom 30th Acc: 0.0909
Fold [1/5] Epoch [10/100] Initial Loss: 0.1380, Training Loss: 0.0813, Initial Validation Loss: 0.1312, Validation Loss: 0.0785,V Acc: 0.6577, Top 70th Acc: 0.7179, Bottom 30th Acc: 0.5152
Fold [1/5] Epoch [20/100] Initial Loss: 0.1380, Training Loss: 0.0788, Initial Validation Loss: 0.1312, Validation Loss: 0.0782,V Acc: 0.6486, Top 70th Acc: 0.7051, Bottom 30th Acc: 0.5152
Stopping early at Epoch (base 0): 22  Rolling back to Epoch (base 0): 17  Top Validation Acc: 0.6923076923076923
Fold [2/5] Epoch [0/100] Initial Loss: 0.1401, Training Loss: 0.1401, Initial Validation Loss: 0.1278, Validation Loss: 0.1278,V Acc: 0.3604, Top 70th Acc: 0.4359, Bottom 30th Acc: 0.1818
Fold [2/5] Epoch [10/100] Initial Loss: 0.1401, Training Loss: 0.0828, Initial Validation Loss: 0.1278, Validation Loss: 0.0746,V Acc: 0.6577, Top 70th Acc: 0.7692, Bottom 30th Acc: 0.3939
Fold [2/5] Epoch [20/100] Initial Loss: 0.1401, Training Loss: 0.0799, Initial Validation Loss: 0.1278, Validation Loss: 0.0778,V Acc: 0.6216, Top 70th Acc: 0.7564, Bottom 30th Acc: 0.3030
Stopping early at Epoch (base 0): 22  Rolling back to Epoch (base 0): 17  Top Validation Acc: 0.7435897435897436
Fold [3/5] Epoch [0/100] Initial Loss: 0.1334, Training Loss: 0.1334, Initial Validation Loss: 0.1237, Validation Loss: 0.1237,V Acc: 0.3455, Top 70th Acc: 0.4026, Bottom 30th Acc: 0.2121
Fold [3/5] Epoch [10/100] Initial Loss: 0.1334, Training Loss: 0.0810, Initial Validation Loss: 0.1237, Validation Loss: 0.0811,V Acc: 0.6000, Top 70th Acc: 0.7143, Bottom 30th Acc: 0.3333
Fold [3/5] Epoch [20/100] Initial Loss: 0.1334, Training Loss: 0.0782, Initial Validation Loss: 0.1237, Validation Loss: 0.0807,V Acc: 0.6182, Top 70th Acc: 0.7273, Bottom 30th Acc: 0.3636
Fold [3/5] Epoch [30/100] Initial Loss: 0.1334, Training Loss: 0.0774, Initial Validation Loss: 0.1237, Validation Loss: 0.0803,V Acc: 0.6182, Top 70th Acc: 0.7273, Bottom 30th Acc: 0.3636
Fold [3/5] Epoch [40/100] Initial Loss: 0.1334, Training Loss: 0.0765, Initial Validation Loss: 0.1237, Validation Loss: 0.0795,V Acc: 0.6000, Top 70th Acc: 0.7143, Bottom 30th Acc: 0.3333
Stopping early at Epoch (base 0): 41  Rolling back to Epoch (base 0): 36  Top Validation Acc: 0.7142857142857143
Fold [4/5] Epoch [0/100] Initial Loss: 0.1326, Training Loss: 0.1326, Initial Validation Loss: 0.1258, Validation Loss: 0.1258,V Acc: 0.4636, Top 70th Acc: 0.5974, Bottom 30th Acc: 0.1515
Fold [4/5] Epoch [10/100] Initial Loss: 0.1326, Training Loss: 0.0793, Initial Validation Loss: 0.1258, Validation Loss: 0.0874,V Acc: 0.5818, Top 70th Acc: 0.6753, Bottom 30th Acc: 0.3636
Fold [4/5] Epoch [20/100] Initial Loss: 0.1326, Training Loss: 0.0774, Initial Validation Loss: 0.1258, Validation Loss: 0.0877,V Acc: 0.5818, Top 70th Acc: 0.7143, Bottom 30th Acc: 0.2727
Stopping early at Epoch (base 0): 29  Rolling back to Epoch (base 0): 24  Top Validation Acc: 0.7272727272727273
19 3 [array([0.12555459, 0.3963852 , 0.13523535, 0.2109364 , 0.13188837],
      dtype=float32)]
Fold [5/5] Epoch [0/100] Initial Loss: 0.1378, Training Loss: 0.1378, Initial Validation Loss: 0.1336, Validation Loss: 0.1336,V Acc: 0.2500, Top 70th Acc: 0.3553, Bottom 30th Acc: 0.0000
Fold [5/5] Epoch [10/100] Initial Loss: 0.1378, Training Loss: 0.0810, Initial Validation Loss: 0.1336, Validation Loss: 0.0803,V Acc: 0.6204, Top 70th Acc: 0.7500, Bottom 30th Acc: 0.3125
Fold [5/5] Epoch [20/100] Initial Loss: 0.1378, Training Loss: 0.0791, Initial Validation Loss: 0.1336, Validation Loss: 0.0800,V Acc: 0.6389, Top 70th Acc: 0.7632, Bottom 30th Acc: 0.3438
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.7368421052631579
Running train_nn.py with seed 20
CUDA:False
Training samples count:  550
Training on 2 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1360, Training Loss: 0.1360, Initial Validation Loss: 0.1288, Validation Loss: 0.1288,V Acc: 0.4685, Top 70th Acc: 0.5000, Bottom 30th Acc: 0.3939
Fold [1/5] Epoch [10/100] Initial Loss: 0.1360, Training Loss: 0.0807, Initial Validation Loss: 0.1288, Validation Loss: 0.0813,V Acc: 0.6306, Top 70th Acc: 0.7308, Bottom 30th Acc: 0.3939
Fold [1/5] Epoch [20/100] Initial Loss: 0.1360, Training Loss: 0.0782, Initial Validation Loss: 0.1288, Validation Loss: 0.0799,V Acc: 0.6306, Top 70th Acc: 0.7564, Bottom 30th Acc: 0.3333
Stopping early at Epoch (base 0): 20  Rolling back to Epoch (base 0): 15  Top Validation Acc: 0.7564102564102564
Fold [2/5] Epoch [0/100] Initial Loss: 0.1363, Training Loss: 0.1363, Initial Validation Loss: 0.1258, Validation Loss: 0.1258,V Acc: 0.4234, Top 70th Acc: 0.5769, Bottom 30th Acc: 0.0606
Fold [2/5] Epoch [10/100] Initial Loss: 0.1363, Training Loss: 0.0789, Initial Validation Loss: 0.1258, Validation Loss: 0.0893,V Acc: 0.6036, Top 70th Acc: 0.7179, Bottom 30th Acc: 0.3333
Fold [2/5] Epoch [20/100] Initial Loss: 0.1363, Training Loss: 0.0768, Initial Validation Loss: 0.1258, Validation Loss: 0.0875,V Acc: 0.6126, Top 70th Acc: 0.7308, Bottom 30th Acc: 0.3333
Fold [2/5] Epoch [30/100] Initial Loss: 0.1363, Training Loss: 0.0764, Initial Validation Loss: 0.1258, Validation Loss: 0.0876,V Acc: 0.6036, Top 70th Acc: 0.7179, Bottom 30th Acc: 0.3333
Stopping early at Epoch (base 0): 32  Rolling back to Epoch (base 0): 27  Top Validation Acc:
Fold [3/5] Epoch [0/100] Initial Loss: 0.1363, Training Loss: 0.1363, Initial Validation Loss: 0.1252, Validation Loss: 0.1252,V Acc: 0.4364, Top 70th Acc: 0.5584, Bottom 30th Acc: 0.1515
Fold [3/5] Epoch [10/100] Initial Loss: 0.1363, Training Loss: 0.0231, Initial Validation Loss: 0.1252, Validation Loss: 0.0273,V Acc: 0.8818, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.7273
Fold [3/5] Epoch [20/100] Initial Loss: 0.1363, Training Loss: 0.0173, Initial Validation Loss: 0.1252, Validation Loss: 0.0287,V Acc: 0.8727, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.7273
Stopping early at Epoch (base 0): 27  Rolling back to Epoch (base 0): 22  Top Validation Acc: 0.922077922077922
Fold [4/5] Epoch [0/100] Initial Loss: 0.1358, Training Loss: 0.1358, Initial Validation Loss: 0.1302, Validation Loss: 0.1302,V Acc: 0.4636, Top 70th Acc: 0.5584, Bottom 30th Acc: 0.2424
Fold [4/5] Epoch [10/100] Initial Loss: 0.1358, Training Loss: 0.0282, Initial Validation Loss: 0.1302, Validation Loss: 0.0406,V Acc: 0.8000, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.4848
Fold [4/5] Epoch [20/100] Initial Loss: 0.1358, Training Loss: 0.0174, Initial Validation Loss: 0.1302, Validation Loss: 0.0298,V Acc: 0.8545, Top 70th Acc: 0.9870, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.974025974025974
Fold [5/5] Epoch [0/100] Initial Loss: 0.1307, Training Loss: 0.1307, Initial Validation Loss: 0.1090, Validation Loss: 0.1090,V Acc: 0.5833, Top 70th Acc: 0.7368, Bottom 30th Acc: 0.2188
Fold [5/5] Epoch [10/100] Initial Loss: 0.1307, Training Loss: 0.0249, Initial Validation Loss: 0.1090, Validation Loss: 0.0227,V Acc: 0.8704, Top 70th Acc: 0.9868, Bottom 30th Acc: 0.5938
Fold [5/5] Epoch [20/100] Initial Loss: 0.1307, Training Loss: 0.0196, Initial Validation Loss: 0.1090, Validation Loss: 0.0204,V Acc: 0.8796, Top 70th Acc: 0.9868, Bottom 30th Acc: 0.6250
Stopping early at Epoch (base 0): 27  Rolling back to Epoch (base 0): 22  Top Validation Acc: 0.9736842105263158
Running train_nn.py with seed 29
CUDA:False
Training samples count:  550
Training on 21 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1314, Training Loss: 0.1314, Initial Validation Loss: 0.1235, Validation Loss: 0.1235,V Acc: 0.5946, Top 70th Acc: 0.6282, Bottom 30th Acc: 0.5152
Fold [1/5] Epoch [10/100] Initial Loss: 0.1314, Training Loss: 0.0239, Initial Validation Loss: 0.1235, Validation Loss: 0.0312,V Acc: 0.8649, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.6061
Fold [1/5] Epoch [20/100] Initial Loss: 0.1314, Training Loss: 0.0170, Initial Validation Loss: 0.1235, Validation Loss: 0.0296,V Acc: 0.8919, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.7273
Stopping early at Epoch (base 0): 21  Rolling back to Epoch (base 0): 16  Top Validation Acc: 0.9743589743589743
29 0 [array([0.76865524, 0.0220102 , 0.02052212, 0.12358836, 0.06522408],
      dtype=float32)]
Fold [2/5] Epoch [0/100] Initial Loss: 0.1308, Training Loss: 0.1308, Initial Validation Loss: 0.1205, Validation Loss: 0.1205,V Acc: 0.4865, Top 70th Acc: 0.5128, Bottom 30th Acc: 0.4242
Fold [2/5] Epoch [10/100] Initial Loss: 0.1308, Training Loss: 0.0372, Initial Validation Loss: 0.1205, Validation Loss: 0.0338,V Acc: 0.8649, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.6667
Fold [2/5] Epoch [20/100] Initial Loss: 0.1308, Training Loss: 0.0191, Initial Validation Loss: 0.1205, Validation Loss: 0.0236,V Acc: 0.8829, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 22  Rolling back to Epoch (base 0): 17  Top Validation Acc: 0.9743589743589743
Fold [3/5] Epoch [0/100] Initial Loss: 0.1399, Training Loss: 0.1399, Initial Validation Loss: 0.1290, Validation Loss: 0.1290,V Acc: 0.3455, Top 70th Acc: 0.4026, Bottom 30th Acc: 0.2121
Fold [3/5] Epoch [10/100] Initial Loss: 0.1399, Training Loss: 0.0249, Initial Validation Loss: 0.1290, Validation Loss: 0.0261,V Acc: 0.8727, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6970
Fold [3/5] Epoch [20/100] Initial Loss: 0.1399, Training Loss: 0.0185, Initial Validation Loss: 0.1290, Validation Loss: 0.0222,V Acc: 0.9091, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.7879
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.948051948051948
Fold [4/5] Epoch [0/100] Initial Loss: 0.1358, Training Loss: 0.1358, Initial Validation Loss: 0.1244, Validation Loss: 0.1244,V Acc: 0.4273, Top 70th Acc: 0.5714, Bottom 30th Acc: 0.0909
Fold [4/5] Epoch [10/100] Initial Loss: 0.1358, Training Loss: 0.0229, Initial Validation Loss: 0.1244, Validation Loss: 0.0284,V Acc: 0.8636, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.6970
Fold [4/5] Epoch [20/100] Initial Loss: 0.1358, Training Loss: 0.0159, Initial Validation Loss: 0.1244, Validation Loss: 0.0254,V Acc: 0.8818, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.935064935064935
Fold [5/5] Epoch [0/100] Initial Loss: 0.1341, Training Loss: 0.1341, Initial Validation Loss: 0.1219, Validation Loss: 0.1219,V Acc: 0.4722, Top 70th Acc: 0.5000, Bottom 30th Acc: 0.4062
Fold [5/5] Epoch [10/100] Initial Loss: 0.1341, Training Loss: 0.0251, Initial Validation Loss: 0.1219, Validation Loss: 0.0290,V Acc: 0.8704, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.6562
Stopping early at Epoch (base 0): 16  Rolling back to Epoch (base 0): 11  Top Validation Acc: 0.9605263157894737
Running train_nn.py with seed 30
CUDA:False
Training samples count:  550
Training on 21 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1357, Training Loss: 0.1357, Initial Validation Loss: 0.1275, Validation Loss: 0.1275,V Acc: 0.3784, Top 70th Acc: 0.4872, Bottom 30th Acc: 0.1212
Fold [1/5] Epoch [10/100] Initial Loss: 0.1357, Training Loss: 0.0225, Initial Validation Loss: 0.1275, Validation Loss: 0.0300,V Acc: 0.8739, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.7273
Stopping early at Epoch (base 0): 19  Rolling back to Epoch (base 0): 14  Top Validation Acc: 0.9487179487179487
Fold [2/5] Epoch [0/100] Initial Loss: 0.1315, Training Loss: 0.1315, Initial Validation Loss: 0.1182, Validation Loss: 0.1182,V Acc: 0.4505, Top 70th Acc: 0.5513, Bottom 30th Acc: 0.2121
Fold [2/5] Epoch [10/100] Initial Loss: 0.1315, Training Loss: 0.0242, Initial Validation Loss: 0.1182, Validation Loss: 0.0306,V Acc: 0.8288, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 16  Rolling back to Epoch (base 0): 11  Top Validation Acc: 0.9615384615384616
Fold [3/5] Epoch [0/100] Initial Loss: 0.1373, Training Loss: 0.1373, Initial Validation Loss: 0.1242, Validation Loss: 0.1242,V Acc: 0.4545, Top 70th Acc: 0.4805, Bottom 30th Acc: 0.3939
Fold [3/5] Epoch [10/100] Initial Loss: 0.1373, Training Loss: 0.0224, Initial Validation Loss: 0.1242, Validation Loss: 0.0311,V Acc: 0.8364, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 17  Rolling back to Epoch (base 0): 12  Top Validation Acc: 0.948051948051948
Fold [4/5] Epoch [0/100] Initial Loss: 0.1387, Training Loss: 0.1387, Initial Validation Loss: 0.1302, Validation Loss: 0.1302,V Acc: 0.3636, Top 70th Acc: 0.4935, Bottom 30th Acc: 0.0606
Fold [4/5] Epoch [10/100] Initial Loss: 0.1387, Training Loss: 0.0259, Initial Validation Loss: 0.1302, Validation Loss: 0.0299,V Acc: 0.8636, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.6061
Fold [4/5] Epoch [20/100] Initial Loss: 0.1387, Training Loss: 0.0182, Initial Validation Loss: 0.1302, Validation Loss: 0.0309,V Acc: 0.8727, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.7273
Stopping early at Epoch (base 0): 21  Rolling back to Epoch (base 0): 16  Top Validation Acc: 0.974025974025974
Fold [5/5] Epoch [0/100] Initial Loss: 0.1306, Training Loss: 0.1306, Initial Validation Loss: 0.1151, Validation Loss: 0.1151,V Acc: 0.6111, Top 70th Acc: 0.7237, Bottom 30th Acc: 0.3438
Fold [5/5] Epoch [10/100] Initial Loss: 0.1306, Training Loss: 0.0253, Initial Validation Loss: 0.1151, Validation Loss: 0.0271,V Acc: 0.8981, Top 70th Acc: 0.9737, Bottom 30th Acc: 0.7188
Fold [5/5] Epoch [20/100] Initial Loss: 0.1306, Training Loss: 0.0173, Initial Validation Loss: 0.1151, Validation Loss: 0.0223,V Acc: 0.9167, Top 70th Acc: 0.9868, Bottom 30th Acc: 0.7500/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)

Stopping early at Epoch (base 0): 52  Rolling back to Epoch (base 0): 47  Top Validation Acc: 0.987012987012987
Fold [4/5] Epoch [0/100] Initial Loss: 0.1396, Training Loss: 0.1396, Initial Validation Loss: 0.1387, Validation Loss: 0.1387,V Acc: 0.3000, Top 70th Acc: 0.3506, Bottom 30th Acc: 0.1818
Fold [4/5] Epoch [10/100] Initial Loss: 0.1396, Training Loss: 0.0359, Initial Validation Loss: 0.1387, Validation Loss: 0.0455,V Acc: 0.7636, Top 70th Acc: 0.8831, Bottom 30th Acc: 0.4848
Fold [4/5] Epoch [20/100] Initial Loss: 0.1396, Training Loss: 0.0172, Initial Validation Loss: 0.1387, Validation Loss: 0.0357,V Acc: 0.8182, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.5455
Fold [4/5] Epoch [30/100] Initial Loss: 0.1396, Training Loss: 0.0122, Initial Validation Loss: 0.1387, Validation Loss: 0.0336,V Acc: 0.8455, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.6667
Fold [4/5] Epoch [40/100] Initial Loss: 0.1396, Training Loss: 0.0109, Initial Validation Loss: 0.1387, Validation Loss: 0.0332,V Acc: 0.8364, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 41  Rolling back to Epoch (base 0): 36  Top Validation Acc: 0.922077922077922
19 3 [array([0.570691  , 0.06395692, 0.08556446, 0.10869828, 0.17108938],
      dtype=float32)]
Fold [5/5] Epoch [0/100] Initial Loss: 0.1388, Training Loss: 0.1388, Initial Validation Loss: 0.1349, Validation Loss: 0.1349,V Acc: 0.2685, Top 70th Acc: 0.2895, Bottom 30th Acc: 0.2188
Fold [5/5] Epoch [10/100] Initial Loss: 0.1388, Training Loss: 0.0331, Initial Validation Loss: 0.1349, Validation Loss: 0.0524,V Acc: 0.7407, Top 70th Acc: 0.8816, Bottom 30th Acc: 0.4062
Fold [5/5] Epoch [20/100] Initial Loss: 0.1388, Training Loss: 0.0135, Initial Validation Loss: 0.1349, Validation Loss: 0.0355,V Acc: 0.8241, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.5312
Fold [5/5] Epoch [30/100] Initial Loss: 0.1388, Training Loss: 0.0105, Initial Validation Loss: 0.1349, Validation Loss: 0.0345,V Acc: 0.8241, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.5625
Stopping early at Epoch (base 0): 37  Rolling back to Epoch (base 0): 32  Top Validation Acc: 0.9342105263157895
Running train_nn.py with seed 20
CUDA:False
Training samples count:  550
Training on 40 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1409, Training Loss: 0.1409, Initial Validation Loss: 0.1346, Validation Loss: 0.1346,V Acc: 0.3694, Top 70th Acc: 0.3974, Bottom 30th Acc: 0.3030
Fold [1/5] Epoch [10/100] Initial Loss: 0.1409, Training Loss: 0.0247, Initial Validation Loss: 0.1346, Validation Loss: 0.0414,V Acc: 0.7748, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.4545
Fold [1/5] Epoch [20/100] Initial Loss: 0.1409, Training Loss: 0.0125, Initial Validation Loss: 0.1346, Validation Loss: 0.0336,V Acc: 0.8288, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.9230769230769231
Fold [2/5] Epoch [0/100] Initial Loss: 0.1368, Training Loss: 0.1368, Initial Validation Loss: 0.1357, Validation Loss: 0.1357,V Acc: 0.3063, Top 70th Acc: 0.3462, Bottom 30th Acc: 0.2121
Fold [2/5] Epoch [10/100] Initial Loss: 0.1368, Training Loss: 0.0308, Initial Validation Loss: 0.1357, Validation Loss: 0.0408,V Acc: 0.8108, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.5455
Fold [2/5] Epoch [20/100] Initial Loss: 0.1368, Training Loss: 0.0154, Initial Validation Loss: 0.1357, Validation Loss: 0.0309,V Acc: 0.8378, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.5152
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.9743589743589743
Fold [3/5] Epoch [0/100] Initial Loss: 0.1387, Training Loss: 0.1387, Initial Validation Loss: 0.1285, Validation Loss: 0.1285,V Acc: 0.3182, Top 70th Acc: 0.4026, Bottom 30th Acc: 0.1212
Fold [3/5] Epoch [10/100] Initial Loss: 0.1387, Training Loss: 0.0376, Initial Validation Loss: 0.1285, Validation Loss: 0.0392,V Acc: 0.7818, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.4545
Fold [3/5] Epoch [20/100] Initial Loss: 0.1387, Training Loss: 0.0191, Initial Validation Loss: 0.1285, Validation Loss: 0.0315,V Acc: 0.8364, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.6364
Fold [3/5] Epoch [30/100] Initial Loss: 0.1387, Training Loss: 0.0142, Initial Validation Loss: 0.1285, Validation Loss: 0.0275,V Acc: 0.8364, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.5455
Fold [3/5] Epoch [40/100] Initial Loss: 0.1387, Training Loss: 0.0123, Initial Validation Loss: 0.1285, Validation Loss: 0.0263,V Acc: 0.8364, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 46  Rolling back to Epoch (base 0): 41  Top Validation Acc: 0.961038961038961
Fold [4/5] Epoch [0/100] Initial Loss: 0.1366, Training Loss: 0.1366, Initial Validation Loss: 0.1322, Validation Loss: 0.1322,V Acc: 0.4182, Top 70th Acc: 0.5584, Bottom 30th Acc: 0.0909
Fold [4/5] Epoch [10/100] Initial Loss: 0.1366, Training Loss: 0.0317, Initial Validation Loss: 0.1322, Validation Loss: 0.0388,V Acc: 0.8000, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.5152
Fold [4/5] Epoch [20/100] Initial Loss: 0.1366, Training Loss: 0.0149, Initial Validation Loss: 0.1322, Validation Loss: 0.0329,V Acc: 0.8364, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.935064935064935
Fold [5/5] Epoch [0/100] Initial Loss: 0.1382, Training Loss: 0.1382, Initial Validation Loss: 0.1352, Validation Loss: 0.1352,V Acc: 0.2407, Top 70th Acc: 0.2500, Bottom 30th Acc: 0.2188
Fold [5/5] Epoch [10/100] Initial Loss: 0.1382, Training Loss: 0.0379, Initial Validation Loss: 0.1352, Validation Loss: 0.0516,V Acc: 0.7500, Top 70th Acc: 0.8684, Bottom 30th Acc: 0.4688
Fold [5/5] Epoch [20/100] Initial Loss: 0.1382, Training Loss: 0.0206, Initial Validation Loss: 0.1352, Validation Loss: 0.0444,V Acc: 0.7593, Top 70th Acc: 0.8816, Bottom 30th Acc: 0.4688
Fold [5/5] Epoch [30/100] Initial Loss: 0.1382, Training Loss: 0.0159, Initial Validation Loss: 0.1352, Validation Loss: 0.0429,V Acc: 0.7593, Top 70th Acc: 0.8947, Bottom 30th Acc: 0.4375
Fold [5/5] Epoch [40/100] Initial Loss: 0.1382, Training Loss: 0.0124, Initial Validation Loss: 0.1352, Validation Loss: 0.0411,V Acc: 0.7778, Top 70th Acc: 0.8947, Bottom 30th Acc: 0.5000
Fold [5/5] Epoch [50/100] Initial Loss: 0.1382, Training Loss: 0.0110, Initial Validation Loss: 0.1352, Validation Loss: 0.0414,V Acc: 0.7778, Top 70th Acc: 0.9079, Bottom 30th Acc: 0.4688
Fold [5/5] Epoch [60/100] Initial Loss: 0.1382, Training Loss: 0.0103, Initial Validation Loss: 0.1352, Validation Loss: 0.0391,V Acc: 0.7778, Top 70th Acc: 0.9211, Bottom 30th Acc: 0.4375
Stopping early at Epoch (base 0): 65  Rolling back to Epoch (base 0): 60  Top Validation Acc: 0.9210526315789473
20 4 [array([0.5765488 , 0.16203672, 0.03132276, 0.06060946, 0.16948225],
      dtype=float32)]
Running train_nn.py with seed 21
CUDA:False
Training samples count:  550
Training on 40 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1380, Training Loss: 0.1380, Initial Validation Loss: 0.1366, Validation Loss: 0.1366,V Acc: 0.4144, Top 70th Acc: 0.4487, Bottom 30th Acc: 0.3333
Fold [1/5] Epoch [10/100] Initial Loss: 0.1380, Training Loss: 0.0380, Initial Validation Loss: 0.1366, Validation Loss: 0.0425,V Acc: 0.8018, Top 70th Acc: 0.8846, Bottom 30th Acc: 0.6061
Fold [1/5] Epoch [20/100] Initial Loss: 0.1380, Training Loss: 0.0151, Initial Validation Loss: 0.1366, Validation Loss: 0.0293,V Acc: 0.8739, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.7273
Fold [1/5] Epoch [30/100] Initial Loss: 0.1380, Training Loss: 0.0123, Initial Validation Loss: 0.1366, Validation Loss: 0.0275,V Acc: 0.8919, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.7273
Stopping early at Epoch (base 0): 35  Rolling back to Epoch (base 0): 30  Top Validation Acc: 0.9615384615384616
Fold [2/5] Epoch [0/100] Initial Loss: 0.1414, Training Loss: 0.1414, Initial Validation Loss: 0.1347, Validation Loss: 0.1347,V Acc: 0.2523, Top 70th Acc: 0.3205, Bottom 30th Acc: 0.0909
Fold [2/5] Epoch [10/100] Initial Loss: 0.1414, Training Loss: 0.0348, Initial Validation Loss: 0.1347, Validation Loss: 0.0436,V Acc: 0.7838, Top 70th Acc: 0.8718, Bottom 30th Acc: 0.5758
Fold [2/5] Epoch [10/100] Initial Loss: 0.1378, Training Loss: 0.0269, Initial Validation Loss: 0.1288, Validation Loss: 0.0341,V Acc: 0.8108, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.5758
Fold [2/5] Epoch [20/100] Initial Loss: 0.1378, Training Loss: 0.0181, Initial Validation Loss: 0.1288, Validation Loss: 0.0322,V Acc: 0.8108, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 21  Rolling back to Epoch (base 0): 16  Top Validation Acc: 0.9230769230769231
Fold [3/5] Epoch [0/100] Initial Loss: 0.1393, Training Loss: 0.1393, Initial Validation Loss: 0.1364, Validation Loss: 0.1364,V Acc: 0.3000, Top 70th Acc: 0.2338, Bottom 30th Acc: 0.4545
Fold [3/5] Epoch [10/100] Initial Loss: 0.1393, Training Loss: 0.0302, Initial Validation Loss: 0.1364, Validation Loss: 0.0293,V Acc: 0.8727, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.6667
Fold [3/5] Epoch [20/100] Initial Loss: 0.1393, Training Loss: 0.0197, Initial Validation Loss: 0.1364, Validation Loss: 0.0239,V Acc: 0.8636, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.974025974025974
Fold [4/5] Epoch [0/100] Initial Loss: 0.1361, Training Loss: 0.1361, Initial Validation Loss: 0.1343, Validation Loss: 0.1343,V Acc: 0.4364, Top 70th Acc: 0.4805, Bottom 30th Acc: 0.3333
Fold [4/5] Epoch [10/100] Initial Loss: 0.1361, Training Loss: 0.0337, Initial Validation Loss: 0.1343, Validation Loss: 0.0419,V Acc: 0.8091, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.5152
Fold [4/5] Epoch [20/100] Initial Loss: 0.1361, Training Loss: 0.0202, Initial Validation Loss: 0.1343, Validation Loss: 0.0359,V Acc: 0.8636, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 22  Rolling back to Epoch (base 0): 17  Top Validation Acc: 0.922077922077922
19 3 [array([0.4933545 , 0.07336059, 0.09970824, 0.14184763, 0.19172908],
      dtype=float32)]
Fold [5/5] Epoch [0/100] Initial Loss: 0.1380, Training Loss: 0.1380, Initial Validation Loss: 0.1318, Validation Loss: 0.1318,V Acc: 0.3056, Top 70th Acc: 0.3421, Bottom 30th Acc: 0.2188
Fold [5/5] Epoch [10/100] Initial Loss: 0.1380, Training Loss: 0.0239, Initial Validation Loss: 0.1318, Validation Loss: 0.0400,V Acc: 0.8056, Top 70th Acc: 0.9211, Bottom 30th Acc: 0.5312
Stopping early at Epoch (base 0): 19  Rolling back to Epoch (base 0): 14  Top Validation Acc: 0.9078947368421053
Running train_nn.py with seed 20
CUDA:False
Training samples count:  550
Training on 30 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1409, Training Loss: 0.1409, Initial Validation Loss: 0.1347, Validation Loss: 0.1347,V Acc: 0.3604, Top 70th Acc: 0.3718, Bottom 30th Acc: 0.3333
Fold [1/5] Epoch [10/100] Initial Loss: 0.1409, Training Loss: 0.0437, Initial Validation Loss: 0.1347, Validation Loss: 0.0510,V Acc: 0.7748, Top 70th Acc: 0.8462, Bottom 30th Acc: 0.6061
Fold [1/5] Epoch [20/100] Initial Loss: 0.1409, Training Loss: 0.0212, Initial Validation Loss: 0.1347, Validation Loss: 0.0379,V Acc: 0.8108, Top 70th Acc: 0.8974, Bottom 30th Acc: 0.6061
Fold [1/5] Epoch [30/100] Initial Loss: 0.1409, Training Loss: 0.0166, Initial Validation Loss: 0.1347, Validation Loss: 0.0352,V Acc: 0.8378, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.6667
Fold [1/5] Epoch [40/100] Initial Loss: 0.1409, Training Loss: 0.0149, Initial Validation Loss: 0.1347, Validation Loss: 0.0346,V Acc: 0.8378, Top 70th Acc: 0.8974, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 41  Rolling back to Epoch (base 0): 36  Top Validation Acc: 0.8846153846153846
Fold [2/5] Epoch [0/100] Initial Loss: 0.1372, Training Loss: 0.1372, Initial Validation Loss: 0.1375, Validation Loss: 0.1375,V Acc: 0.3333, Top 70th Acc: 0.3846, Bottom 30th Acc: 0.2121
Fold [2/5] Epoch [10/100] Initial Loss: 0.1372, Training Loss: 0.0365, Initial Validation Loss: 0.1375, Validation Loss: 0.0464,V Acc: 0.8288, Top 70th Acc: 0.8974, Bottom 30th Acc: 0.6667
Fold [2/5] Epoch [20/100] Initial Loss: 0.1372, Training Loss: 0.0176, Initial Validation Loss: 0.1375, Validation Loss: 0.0318,V Acc: 0.8649, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.6970
Fold [2/5] Epoch [30/100] Initial Loss: 0.1372, Training Loss: 0.0152, Initial Validation Loss: 0.1375, Validation Loss: 0.0322,V Acc: 0.8559, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 34  Rolling back to Epoch (base 0): 29  Top Validation Acc: 0.9487179487179487
Fold [3/5] Epoch [0/100] Initial Loss: 0.1397, Training Loss: 0.1397, Initial Validation Loss: 0.1290, Validation Loss: 0.1290,V Acc: 0.3364, Top 70th Acc: 0.3896, Bottom 30th Acc: 0.2121
Fold [3/5] Epoch [10/100] Initial Loss: 0.1397, Training Loss: 0.0285, Initial Validation Loss: 0.1290, Validation Loss: 0.0326,V Acc: 0.8182, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.5758
Fold [3/5] Epoch [20/100] Initial Loss: 0.1397, Training Loss: 0.0185, Initial Validation Loss: 0.1290, Validation Loss: 0.0258,V Acc: 0.8636, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.7273
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.922077922077922
Fold [4/5] Epoch [0/100] Initial Loss: 0.1380, Training Loss: 0.1380, Initial Validation Loss: 0.1355, Validation Loss: 0.1355,V Acc: 0.3182, Top 70th Acc: 0.3896, Bottom 30th Acc: 0.1515
Fold [4/5] Epoch [10/100] Initial Loss: 0.1380, Training Loss: 0.0325, Initial Validation Loss: 0.1355, Validation Loss: 0.0391,V Acc: 0.8364, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.6364
Fold [4/5] Epoch [20/100] Initial Loss: 0.1380, Training Loss: 0.0182, Initial Validation Loss: 0.1355, Validation Loss: 0.0337,V Acc: 0.8182, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.922077922077922
Fold [5/5] Epoch [0/100] Initial Loss: 0.1392, Training Loss: 0.1392, Initial Validation Loss: 0.1345, Validation Loss: 0.1345,V Acc: 0.3148, Top 70th Acc: 0.3026, Bottom 30th Acc: 0.3438
Fold [5/5] Epoch [10/100] Initial Loss: 0.1392, Training Loss: 0.0425, Initial Validation Loss: 0.1345, Validation Loss: 0.0527,V Acc: 0.7315, Top 70th Acc: 0.8553, Bottom 30th Acc: 0.4375
Fold [5/5] Epoch [20/100] Initial Loss: 0.1392, Training Loss: 0.0189, Initial Validation Loss: 0.1345, Validation Loss: 0.0359,V Acc: 0.8056, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.4375
Stopping early at Epoch (base 0): 28  Rolling back to Epoch (base 0): 23  Top Validation Acc: 0.9473684210526315
20 4 [array([0.74264723, 0.08444919, 0.03334618, 0.09243399, 0.04712346],
      dtype=float32)]
Running train_nn.py with seed 21
CUDA:False
Training samples count:  550
Training on 30 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1400, Training Loss: 0.1400, Initial Validation Loss: 0.1365, Validation Loss: 0.1365,V Acc: 0.2613, Top 70th Acc: 0.3077, Bottom 30th Acc: 0.1515
Fold [1/5] Epoch [10/100] Initial Loss: 0.1400, Training Loss: 0.0408, Initial Validation Loss: 0.1365, Validation Loss: 0.0377,V Acc: 0.8378, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.6364
Fold [1/5] Epoch [20/100] Initial Loss: 0.1400, Training Loss: 0.0198, Initial Validation Loss: 0.1365, Validation Loss: 0.0273,V Acc: 0.8649, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.6364
Fold [1/5] Epoch [30/100] Initial Loss: 0.1400, Training Loss: 0.0175, Initial Validation Loss: 0.1365, Validation Loss: 0.0259,V Acc: 0.8829, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 31  Rolling back to Epoch (base 0): 26  Top Validation Acc: 0.9615384615384616
Fold [2/5] Epoch [0/100] Initial Loss: 0.1416, Training Loss: 0.1416, Initial Validation Loss: 0.1364, Validation Loss: 0.1364,V Acc: 0.2523, Top 70th Acc: 0.3077, Bottom 30th Acc: 0.1212
Fold [2/5] Epoch [10/100] Initial Loss: 0.1416, Training Loss: 0.0379, Initial Validation Loss: 0.1364, Validation Loss: 0.0411,V Acc: 0.8108, Top 70th Acc: 0.8974, Bottom 30th Acc: 0.6061
Fold [2/5] Epoch [20/100] Initial Loss: 0.1416, Training Loss: 0.0198, Initial Validation Loss: 0.1364, Validation Loss: 0.0325,V Acc: 0.7928, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.4545
Stopping early at Epoch (base 0): 20  Rolling back to Epoch (base 0): 15  Top Validation Acc:
Fold [3/5] Epoch [0/100] Initial Loss: 0.1383, Training Loss: 0.1383, Initial Validation Loss: 0.1370, Validation Loss: 0.1370,V Acc: 0.2727, Top 70th Acc: 0.3636, Bottom 30th Acc: 0.0606
Fold [3/5] Epoch [10/100] Initial Loss: 0.1383, Training Loss: 0.0206, Initial Validation Loss: 0.1370, Validation Loss: 0.0336,V Acc: 0.8636, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6667
Fold [3/5] Epoch [20/100] Initial Loss: 0.1383, Training Loss: 0.0049, Initial Validation Loss: 0.1370, Validation Loss: 0.0238,V Acc: 0.8727, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.974025974025974
Fold [4/5] Epoch [0/100] Initial Loss: 0.1391, Training Loss: 0.1391, Initial Validation Loss: 0.1343, Validation Loss: 0.1343,V Acc: 0.2727, Top 70th Acc: 0.3377, Bottom 30th Acc: 0.1212
Fold [4/5] Epoch [10/100] Initial Loss: 0.1391, Training Loss: 0.0264, Initial Validation Loss: 0.1343, Validation Loss: 0.0359,V Acc: 0.8364, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.6061
Fold [4/5] Epoch [20/100] Initial Loss: 0.1391, Training Loss: 0.0049, Initial Validation Loss: 0.1343, Validation Loss: 0.0260,V Acc: 0.8545, Top 70th Acc: 1.0000, Bottom 30th Acc: 0.5152
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.987012987012987
Fold [5/5] Epoch [0/100] Initial Loss: 0.1373, Training Loss: 0.1373, Initial Validation Loss: 0.1292, Validation Loss: 0.1292,V Acc: 0.3056, Top 70th Acc: 0.3553, Bottom 30th Acc: 0.1875
Fold [5/5] Epoch [10/100] Initial Loss: 0.1373, Training Loss: 0.0281, Initial Validation Loss: 0.1292, Validation Loss: 0.0468,V Acc: 0.7778, Top 70th Acc: 0.8684, Bottom 30th Acc: 0.5625
Stopping early at Epoch (base 0): 19  Rolling back to Epoch (base 0): 14  Top Validation Acc: 0.8947368421052632
Running train_nn.py with seed 17
CUDA:False
Training samples count:  550
Training on 163 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1385, Training Loss: 0.1385, Initial Validation Loss: 0.1355, Validation Loss: 0.1355,V Acc: 0.3063, Top 70th Acc: 0.3846, Bottom 30th Acc: 0.1212
Fold [1/5] Epoch [10/100] Initial Loss: 0.1385, Training Loss: 0.0307, Initial Validation Loss: 0.1355, Validation Loss: 0.0453,V Acc: 0.7928, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.4848
Fold [1/5] Epoch [20/100] Initial Loss: 0.1385, Training Loss: 0.0052, Initial Validation Loss: 0.1355, Validation Loss: 0.0317,V Acc: 0.8559, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.6364
Fold [1/5] Epoch [30/100] Initial Loss: 0.1385, Training Loss: 0.0037, Initial Validation Loss: 0.1355, Validation Loss: 0.0308,V Acc: 0.8829, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.7273
Stopping early at Epoch (base 0): 37  Rolling back to Epoch (base 0): 32  Top Validation Acc: 0.9487179487179487
Fold [2/5] Epoch [0/100] Initial Loss: 0.1379, Training Loss: 0.1379, Initial Validation Loss: 0.1338, Validation Loss: 0.1338,V Acc: 0.3874, Top 70th Acc: 0.4487, Bottom 30th Acc: 0.2424
Fold [2/5] Epoch [10/100] Initial Loss: 0.1379, Training Loss: 0.0144, Initial Validation Loss: 0.1338, Validation Loss: 0.0319,V Acc: 0.8378, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.5758
Fold [2/5] Epoch [20/100] Initial Loss: 0.1379, Training Loss: 0.0050, Initial Validation Loss: 0.1338, Validation Loss: 0.0270,V Acc: 0.8649, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.6364
Fold [2/5] Epoch [30/100] Initial Loss: 0.1379, Training Loss: 0.0040, Initial Validation Loss: 0.1338, Validation Loss: 0.0269,V Acc: 0.8829, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.7273
Fold [2/5] Epoch [40/100] Initial Loss: 0.1379, Training Loss: 0.0038, Initial Validation Loss: 0.1338, Validation Loss: 0.0261,V Acc: 0.8829, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.6970
Fold [2/5] Epoch [50/100] Initial Loss: 0.1379, Training Loss: 0.0036, Initial Validation Loss: 0.1338, Validation Loss: 0.0257,V Acc: 0.9009, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.7576
Stopping early at Epoch (base 0): 51  Rolling back to Epoch (base 0): 46  Top Validation Acc: 0.9615384615384616
Fold [3/5] Epoch [0/100] Initial Loss: 0.1366, Training Loss: 0.1366, Initial Validation Loss: 0.1347, Validation Loss: 0.1347,V Acc: 0.2818, Top 70th Acc: 0.3247, Bottom 30th Acc: 0.1818
Fold [3/5] Epoch [10/100] Initial Loss: 0.1366, Training Loss: 0.0198, Initial Validation Loss: 0.1347, Validation Loss: 0.0448,V Acc: 0.7727, Top 70th Acc: 0.8831, Bottom 30th Acc: 0.5152
Fold [3/5] Epoch [20/100] Initial Loss: 0.1366, Training Loss: 0.0053, Initial Validation Loss: 0.1347, Validation Loss: 0.0378,V Acc: 0.8182, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 29  Rolling back to Epoch (base 0): 24  Top Validation Acc: 0.922077922077922
Fold [4/5] Epoch [0/100] Initial Loss: 0.1397, Training Loss: 0.1397, Initial Validation Loss: 0.1330, Validation Loss: 0.1330,V Acc: 0.3000, Top 70th Acc: 0.3636, Bottom 30th Acc: 0.1515
Fold [4/5] Epoch [10/100] Initial Loss: 0.1397, Training Loss: 0.0158, Initial Validation Loss: 0.1330, Validation Loss: 0.0370,V Acc: 0.8273, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.5152
Fold [4/5] Epoch [20/100] Initial Loss: 0.1397, Training Loss: 0.0051, Initial Validation Loss: 0.1330, Validation Loss: 0.0285,V Acc: 0.8636, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.6061
Fold [4/5] Epoch [30/100] Initial Loss: 0.1397, Training Loss: 0.0041, Initial Validation Loss: 0.1330, Validation Loss: 0.0260,V Acc: 0.8727, Top 70th Acc: 0.9870, Bottom 30th Acc: 0.6061
Fold [4/5] Epoch [40/100] Initial Loss: 0.1397, Training Loss: 0.0038, Initial Validation Loss: 0.1330, Validation Loss: 0.0254,V Acc: 0.8727, Top 70th Acc: 0.9870, Bottom 30th Acc: 0.6061
Fold [4/5] Epoch [50/100] Initial Loss: 0.1397, Training Loss: 0.0037, Initial Validation Loss: 0.1330, Validation Loss: 0.0249,V Acc: 0.8727, Top 70th Acc: 0.9870, Bottom 30th Acc: 0.6061
Fold [4/5] Epoch [60/100] Initial Loss: 0.1397, Training Loss: 0.0036, Initial Validation Loss: 0.1330, Validation Loss: 0.0247,V Acc: 0.8818, Top 70th Acc: 0.9870, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 65  Rolling back to Epoch (base 0): 60  Top Validation Acc: 0.987012987012987
Fold [5/5] Epoch [0/100] Initial Loss: 0.1396, Training Loss: 0.1396, Initial Validation Loss: 0.1276, Validation Loss: 0.1276,V Acc: 0.3333, Top 70th Acc: 0.3553, Bottom 30th Acc: 0.2812
Fold [5/5] Epoch [10/100] Initial Loss: 0.1396, Training Loss: 0.0129, Initial Validation Loss: 0.1276, Validation Loss: 0.0346,V Acc: 0.8148, Top 70th Acc: 0.9211, Bottom 30th Acc: 0.5625
Fold [5/5] Epoch [20/100] Initial Loss: 0.1396, Training Loss: 0.0049, Initial Validation Loss: 0.1276, Validation Loss: 0.0318,V Acc: 0.8333, Top 70th Acc: 0.9079, Bottom 30th Acc: 0.6562
Stopping early at Epoch (base 0): 21  Rolling back to Epoch (base 0): 16  Top Validation Acc: 0.9210526315789473
17 4 [array([0.40349627, 0.09539825, 0.08733077, 0.13330352, 0.2804712 ],
      dtype=float32)]
Running train_nn.py with seed 18
CUDA:False
Training samples count:  550
Training on 163 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1380, Training Loss: 0.1380, Initial Validation Loss: 0.1350, Validation Loss: 0.1350,V Acc: 0.2793, Top 70th Acc: 0.3462, Bottom 30th Acc: 0.1212
Fold [1/5] Epoch [10/100] Initial Loss: 0.1380, Training Loss: 0.0134, Initial Validation Loss: 0.1350, Validation Loss: 0.0298,V Acc: 0.8559, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 18  Rolling back to Epoch (base 0): 13  Top Validation Acc: 0.9358974358974359
Fold [2/5] Epoch [0/100] Initial Loss: 0.1374, Training Loss: 0.1374, Initial Validation Loss: 0.1362, Validation Loss: 0.1362,V Acc: 0.4054, Top 70th Acc: 0.5128, Bottom 30th Acc: 0.1515
Fold [2/5] Epoch [10/100] Initial Loss: 0.1374, Training Loss: 0.0152, Initial Validation Loss: 0.1362, Validation Loss: 0.0316,V Acc: 0.8559, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.6061
Fold [2/5] Epoch [20/100] Initial Loss: 0.1374, Training Loss: 0.0048, Initial Validation Loss: 0.1362, Validation Loss: 0.0260,V Acc: 0.8739, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.6364
Fold [2/5] Epoch [30/100] Initial Loss: 0.1374, Training Loss: 0.0040, Initial Validation Loss: 0.1362, Validation Loss: 0.0252,V Acc: 0.8649, Top 70th Acc: 1.0000, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.961038961038961
Fold [5/5] Epoch [0/100] Initial Loss: 0.1390, Training Loss: 0.1390, Initial Validation Loss: 0.1323, Validation Loss: 0.1323,V Acc: 0.3056, Top 70th Acc: 0.3684, Bottom 30th Acc: 0.1562
Fold [5/5] Epoch [10/100] Initial Loss: 0.1390, Training Loss: 0.0333, Initial Validation Loss: 0.1323, Validation Loss: 0.0381,V Acc: 0.8241, Top 70th Acc: 0.9211, Bottom 30th Acc: 0.5938
Fold [5/5] Epoch [20/100] Initial Loss: 0.1390, Training Loss: 0.0228, Initial Validation Loss: 0.1323, Validation Loss: 0.0310,V Acc: 0.8426, Top 70th Acc: 0.9079, Bottom 30th Acc: 0.6875
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.9210526315789473
Running train_nn.py with seed 22
CUDA:False
Training samples count:  550
Training on 20 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1456, Training Loss: 0.1456, Initial Validation Loss: 0.1354, Validation Loss: 0.1354,V Acc: 0.2523, Top 70th Acc: 0.2564, Bottom 30th Acc: 0.2424
Fold [1/5] Epoch [10/100] Initial Loss: 0.1456, Training Loss: 0.0369, Initial Validation Loss: 0.1354, Validation Loss: 0.0459,V Acc: 0.7568, Top 70th Acc: 0.8590, Bottom 30th Acc: 0.5152
Fold [1/5] Epoch [20/100] Initial Loss: 0.1456, Training Loss: 0.0220, Initial Validation Loss: 0.1354, Validation Loss: 0.0370,V Acc: 0.8018, Top 70th Acc: 0.8974, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.8974358974358975
Fold [2/5] Epoch [0/100] Initial Loss: 0.1411, Training Loss: 0.1411, Initial Validation Loss: 0.1332, Validation Loss: 0.1332,V Acc: 0.3153, Top 70th Acc: 0.3590, Bottom 30th Acc: 0.2121
Fold [2/5] Epoch [10/100] Initial Loss: 0.1411, Training Loss: 0.0406, Initial Validation Loss: 0.1332, Validation Loss: 0.0354,V Acc: 0.8559, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.6667
Fold [2/5] Epoch [20/100] Initial Loss: 0.1411, Training Loss: 0.0265, Initial Validation Loss: 0.1332, Validation Loss: 0.0240,V Acc: 0.8739, Top 70th Acc: 1.0000, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 28  Rolling back to Epoch (base 0): 23  Top Validation Acc: 1.0
Fold [3/5] Epoch [0/100] Initial Loss: 0.1410, Training Loss: 0.1410, Initial Validation Loss: 0.1374, Validation Loss: 0.1374,V Acc: 0.3636, Top 70th Acc: 0.3117, Bottom 30th Acc: 0.4848
Fold [3/5] Epoch [10/100] Initial Loss: 0.1410, Training Loss: 0.0444, Initial Validation Loss: 0.1374, Validation Loss: 0.0465,V Acc: 0.8091, Top 70th Acc: 0.8831, Bottom 30th Acc: 0.6364
Fold [3/5] Epoch [20/100] Initial Loss: 0.1410, Training Loss: 0.0254, Initial Validation Loss: 0.1374, Validation Loss: 0.0382,V Acc: 0.8455, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.6667
Fold [3/5] Epoch [30/100] Initial Loss: 0.1410, Training Loss: 0.0216, Initial Validation Loss: 0.1374, Validation Loss: 0.0363,V Acc: 0.8727, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.7576
Stopping early at Epoch (base 0): 33  Rolling back to Epoch (base 0): 28  Top Validation Acc: 0.935064935064935
Fold [4/5] Epoch [0/100] Initial Loss: 0.1383, Training Loss: 0.1383, Initial Validation Loss: 0.1331, Validation Loss: 0.1331,V Acc: 0.3091, Top 70th Acc: 0.3766, Bottom 30th Acc: 0.1515
Fold [4/5] Epoch [10/100] Initial Loss: 0.1383, Training Loss: 0.0323, Initial Validation Loss: 0.1331, Validation Loss: 0.0465,V Acc: 0.8091, Top 70th Acc: 0.8442, Bottom 30th Acc: 0.7273
Fold [4/5] Epoch [20/100] Initial Loss: 0.1383, Training Loss: 0.0213, Initial Validation Loss: 0.1331, Validation Loss: 0.0401,V Acc: 0.8364, Top 70th Acc: 0.8701, Bottom 30th Acc: 0.7576
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.9090909090909091
Fold [5/5] Epoch [0/100] Initial Loss: 0.1359, Training Loss: 0.1359, Initial Validation Loss: 0.1333, Validation Loss: 0.1333,V Acc: 0.4074, Top 70th Acc: 0.4211, Bottom 30th Acc: 0.3750
Fold [5/5] Epoch [10/100] Initial Loss: 0.1359, Training Loss: 0.0374, Initial Validation Loss: 0.1333, Validation Loss: 0.0425,V Acc: 0.8241, Top 70th Acc: 0.9079, Bottom 30th Acc: 0.6250
Fold [5/5] Epoch [20/100] Initial Loss: 0.1359, Training Loss: 0.0242, Initial Validation Loss: 0.1333, Validation Loss: 0.0294,V Acc: 0.8704, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.7188
Fold [5/5] Epoch [30/100] Initial Loss: 0.1359, Training Loss: 0.0220, Initial Validation Loss: 0.1333, Validation Loss: 0.0292,V Acc: 0.8704, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.7188
Stopping early at Epoch (base 0): 31  Rolling back to Epoch (base 0): 26  Top Validation Acc: 0.9473684210526315
22 4 [array([0.33780393, 0.17429692, 0.14870164, 0.18426104, 0.15493643],
      dtype=float32)]
Running train_nn.py with seed 23
CUDA:False
Training samples count:  550
Training on 20 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1381, Training Loss: 0.1381, Initial Validation Loss: 0.1335, Validation Loss: 0.1335,V Acc: 0.4234, Top 70th Acc: 0.4744, Bottom 30th Acc: 0.3030
Fold [1/5] Epoch [10/100] Initial Loss: 0.1381, Training Loss: 0.0301, Initial Validation Loss: 0.1335, Validation Loss: 0.0399,V Acc: 0.7748, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.4242
Fold [1/5] Epoch [20/100] Initial Loss: 0.1381, Training Loss: 0.0218, Initial Validation Loss: 0.1335, Validation Loss: 0.0349,V Acc: 0.8108, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.5152
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.9358974358974359
Fold [2/5] Epoch [0/100] Initial Loss: 0.1391, Training Loss: 0.1391, Initial Validation Loss: 0.1360, Validation Loss: 0.1360,V Acc: 0.2613, Top 70th Acc: 0.2821, Bottom 30th Acc: 0.2121
Fold [2/5] Epoch [10/100] Initial Loss: 0.1391, Training Loss: 0.0465, Initial Validation Loss: 0.1360, Validation Loss: 0.0503,V Acc: 0.7568, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.3333
Fold [2/5] Epoch [20/100] Initial Loss: 0.1391, Training Loss: 0.0230, Initial Validation Loss: 0.1360, Validation Loss: 0.0401,V Acc: 0.8288, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 20  Rolling back to Epoch (base 0): 15  Top Validation Acc: 0.9102564102564102
Fold [3/5] Epoch [0/100] Initial Loss: 0.1397, Training Loss: 0.1397, Initial Validation Loss: 0.1334, Validation Loss: 0.1334,V Acc: 0.3455, Top 70th Acc: 0.3636, Bottom 30th Acc: 0.3030
Fold [3/5] Epoch [10/100] Initial Loss: 0.1397, Training Loss: 0.0364, Initial Validation Loss: 0.1334, Validation Loss: 0.0500,V Acc: 0.7455, Top 70th Acc: 0.8571, Bottom 30th Acc: 0.4848
Fold [3/5] Epoch [20/100] Initial Loss: 0.1397, Training Loss: 0.0279, Initial Validation Loss: 0.1334, Validation Loss: 0.0429,V Acc: 0.7818, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.4848
Fold [3/5] Epoch [30/100] Initial Loss: 0.1397, Training Loss: 0.0229, Initial Validation Loss: 0.1334, Validation Loss: 0.0357,V Acc: 0.8455, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.6970
Fold [3/5] Epoch [40/100] Initial Loss: 0.1397, Training Loss: 0.0211, Initial Validation Loss: 0.1334, Validation Loss: 0.0339,V Acc: 0.8455, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 48  Rolling back to Epoch (base 0): 43  Top Validation Acc: 0.922077922077922
23 2 [array([0.32040104, 0.04499605, 0.24712753, 0.2562506 , 0.13122483],
      dtype=float32)]
Fold [4/5] Epoch [0/100] Initial Loss: 0.1375, Training Loss: 0.1375, Initial Validation Loss: 0.1323, Validation Loss: 0.1323,V Acc: 0.3909, Top 70th Acc: 0.4026, Bottom 30th Acc: 0.3636
Fold [4/5] Epoch [10/100] Initial Loss: 0.1375, Training Loss: 0.0351, Initial Validation Loss: 0.1323, Validation Loss: 0.0348,V Acc: 0.8182, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.5455
Fold [4/5] Epoch [20/100] Initial Loss: 0.1375, Training Loss: 0.0223, Initial Validation Loss: 0.1323, Validation Loss: 0.0291,V Acc: 0.8636, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.7273
Stopping early at Epoch (base 0): 21  Rolling back to Epoch (base 0): 16  Top Validation Acc: 0.922077922077922
Fold [5/5] Epoch [0/100] Initial Loss: 0.1372, Training Loss: 0.1372, Initial Validation Loss: 0.1340, Validation Loss: 0.1340,V Acc: 0.2685, Top 70th Acc: 0.3553, Bottom 30th Acc: 0.0625 0.717948717948718
Fold [3/5] Epoch [0/100] Initial Loss: 0.1347, Training Loss: 0.1347, Initial Validation Loss: 0.1202, Validation Loss: 0.1202,V Acc: 0.3455, Top 70th Acc: 0.4286, Bottom 30th Acc: 0.1515
Fold [3/5] Epoch [10/100] Initial Loss: 0.1347, Training Loss: 0.0838, Initial Validation Loss: 0.1202, Validation Loss: 0.0715,V Acc: 0.6182, Top 70th Acc: 0.7403, Bottom 30th Acc: 0.3333
Fold [3/5] Epoch [20/100] Initial Loss: 0.1347, Training Loss: 0.0820, Initial Validation Loss: 0.1202, Validation Loss: 0.0691,V Acc: 0.6182, Top 70th Acc: 0.7273, Bottom 30th Acc: 0.3636
Fold [3/5] Epoch [30/100] Initial Loss: 0.1347, Training Loss: 0.0813, Initial Validation Loss: 0.1202, Validation Loss: 0.0670,V Acc: 0.6364, Top 70th Acc: 0.7662, Bottom 30th Acc: 0.3333
Stopping early at Epoch (base 0): 38  Rolling back to Epoch (base 0): 33  Top Validation Acc: 0.7402597402597403
Fold [4/5] Epoch [0/100] Initial Loss: 0.1352, Training Loss: 0.1352, Initial Validation Loss: 0.1282, Validation Loss: 0.1282,V Acc: 0.3818, Top 70th Acc: 0.4416, Bottom 30th Acc: 0.2424
Fold [4/5] Epoch [10/100] Initial Loss: 0.1352, Training Loss: 0.0802, Initial Validation Loss: 0.1282, Validation Loss: 0.0838,V Acc: 0.6364, Top 70th Acc: 0.7143, Bottom 30th Acc: 0.4545
Fold [4/5] Epoch [20/100] Initial Loss: 0.1352, Training Loss: 0.0782, Initial Validation Loss: 0.1282, Validation Loss: 0.0828,V Acc: 0.6273, Top 70th Acc: 0.7013, Bottom 30th Acc: 0.4545
Stopping early at Epoch (base 0): 29  Rolling back to Epoch (base 0): 24  Top Validation Acc: 0.7012987012987013
Fold [5/5] Epoch [0/100] Initial Loss: 0.1368, Training Loss: 0.1368, Initial Validation Loss: 0.1305, Validation Loss: 0.1305,V Acc: 0.5093, Top 70th Acc: 0.5658, Bottom 30th Acc: 0.3750
Fold [5/5] Epoch [10/100] Initial Loss: 0.1368, Training Loss: 0.0810, Initial Validation Loss: 0.1305, Validation Loss: 0.0795,V Acc: 0.6574, Top 70th Acc: 0.7632, Bottom 30th Acc: 0.4062
Fold [5/5] Epoch [20/100] Initial Loss: 0.1368, Training Loss: 0.0790, Initial Validation Loss: 0.1305, Validation Loss: 0.0778,V Acc: 0.6389, Top 70th Acc: 0.7500, Bottom 30th Acc: 0.3750
Fold [5/5] Epoch [30/100] Initial Loss: 0.1368, Training Loss: 0.0783, Initial Validation Loss: 0.1305, Validation Loss: 0.0773,V Acc: 0.6204, Top 70th Acc: 0.7632, Bottom 30th Acc: 0.2812
Stopping early at Epoch (base 0): 37  Rolling back to Epoch (base 0): 32  Top Validation Acc: 0.7763157894736842
20 4 [array([0.14054991, 0.33857426, 0.15823002, 0.22883011, 0.13381569],
      dtype=float32)]
Running train_nn.py with seed 21
CUDA:False
Training samples count:  550
Training on 2 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1334, Training Loss: 0.1334, Initial Validation Loss: 0.1304, Validation Loss: 0.1304,V Acc: 0.4685, Top 70th Acc: 0.5128, Bottom 30th Acc: 0.3636
Fold [1/5] Epoch [10/100] Initial Loss: 0.1334, Training Loss: 0.0806, Initial Validation Loss: 0.1304, Validation Loss: 0.0817,V Acc: 0.6396, Top 70th Acc: 0.7051, Bottom 30th Acc: 0.4848
Stopping early at Epoch (base 0): 18  Rolling back to Epoch (base 0): 13  Top Validation Acc: 0.717948717948718
Fold [2/5] Epoch [0/100] Initial Loss: 0.1343, Training Loss: 0.1343, Initial Validation Loss: 0.1228, Validation Loss: 0.1228,V Acc: 0.4505, Top 70th Acc: 0.5256, Bottom 30th Acc: 0.2727
Fold [2/5] Epoch [10/100] Initial Loss: 0.1343, Training Loss: 0.0824, Initial Validation Loss: 0.1228, Validation Loss: 0.0750,V Acc: 0.6486, Top 70th Acc: 0.7436, Bottom 30th Acc: 0.4242
Fold [2/5] Epoch [20/100] Initial Loss: 0.1343, Training Loss: 0.0806, Initial Validation Loss: 0.1228, Validation Loss: 0.0734,V Acc: 0.6577, Top 70th Acc: 0.7308, Bottom 30th Acc: 0.4848
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.7435897435897436
Fold [3/5] Epoch [0/100] Initial Loss: 0.1417, Training Loss: 0.1417, Initial Validation Loss: 0.1345, Validation Loss: 0.1345,V Acc: 0.2273, Top 70th Acc: 0.2208, Bottom 30th Acc: 0.2424
Fold [3/5] Epoch [10/100] Initial Loss: 0.1417, Training Loss: 0.0796, Initial Validation Loss: 0.1345, Validation Loss: 0.0860,V Acc: 0.5909, Top 70th Acc: 0.7532, Bottom 30th Acc: 0.2121
Fold [3/5] Epoch [20/100] Initial Loss: 0.1417, Training Loss: 0.0773, Initial Validation Loss: 0.1345, Validation Loss: 0.0830,V Acc: 0.6091, Top 70th Acc: 0.7532, Bottom 30th Acc: 0.2727
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.7532467532467533
21 2 [array([0.1256221 , 0.33998048, 0.15936433, 0.22868899, 0.14634407],
      dtype=float32)]
Fold [4/5] Epoch [0/100] Initial Loss: 0.1362, Training Loss: 0.1362, Initial Validation Loss: 0.1236, Validation Loss: 0.1236,V Acc: 0.4091, Top 70th Acc: 0.5065, Bottom 30th Acc: 0.1818
Fold [4/5] Epoch [10/100] Initial Loss: 0.1362, Training Loss: 0.0803, Initial Validation Loss: 0.1236, Validation Loss: 0.0805,V Acc: 0.6455, Top 70th Acc: 0.7013, Bottom 30th Acc: 0.5152
Fold [4/5] Epoch [20/100] Initial Loss: 0.1362, Training Loss: 0.0790, Initial Validation Loss: 0.1236, Validation Loss: 0.0789,V Acc: 0.6545, Top 70th Acc: 0.7273, Bottom 30th Acc: 0.4848
Stopping early at Epoch (base 0): 27  Rolling back to Epoch (base 0): 22  Top Validation Acc: 0.7402597402597403
Fold [5/5] Epoch [0/100] Initial Loss: 0.1355, Training Loss: 0.1355, Initial Validation Loss: 0.1283, Validation Loss: 0.1283,V Acc: 0.3611, Top 70th Acc: 0.4342, Bottom 30th Acc: 0.1875
Fold [5/5] Epoch [10/100] Initial Loss: 0.1355, Training Loss: 0.0806, Initial Validation Loss: 0.1283, Validation Loss: 0.0794,V Acc: 0.6111, Top 70th Acc: 0.7237, Bottom 30th Acc: 0.3438
Fold [5/5] Epoch [20/100] Initial Loss: 0.1355, Training Loss: 0.0786, Initial Validation Loss: 0.1283, Validation Loss: 0.0770,V Acc: 0.6019, Top 70th Acc: 0.7105, Bottom 30th Acc: 0.3438
Fold [5/5] Epoch [30/100] Initial Loss: 0.1355, Training Loss: 0.0779, Initial Validation Loss: 0.1283, Validation Loss: 0.0765,V Acc: 0.6019, Top 70th Acc: 0.7105, Bottom 30th Acc: 0.3438
Fold [5/5] Epoch [40/100] Initial Loss: 0.1355, Training Loss: 0.0777, Initial Validation Loss: 0.1283, Validation Loss: 0.0754,V Acc: 0.6204, Top 70th Acc: 0.7237, Bottom 30th Acc: 0.3750
Fold [5/5] Epoch [50/100] Initial Loss: 0.1355, Training Loss: 0.0774, Initial Validation Loss: 0.1283, Validation Loss: 0.0750,V Acc: 0.6204, Top 70th Acc: 0.7237, Bottom 30th Acc: 0.3750
Stopping early at Epoch (base 0): 57  Rolling back to Epoch (base 0): 52  Top Validation Acc: 0.7105263157894737
Running train_nn.py with seed 22
CUDA:False
Training samples count:  550
Training on 2 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1390, Training Loss: 0.1390, Initial Validation Loss: 0.1307, Validation Loss: 0.1307,V Acc: 0.2523, Top 70th Acc: 0.3590, Bottom 30th Acc: 0.0000
Fold [1/5] Epoch [10/100] Initial Loss: 0.1390, Training Loss: 0.0799, Initial Validation Loss: 0.1307, Validation Loss: 0.0829,V Acc: 0.6396, Top 70th Acc: 0.6923, Bottom 30th Acc: 0.5152
Fold [1/5] Epoch [20/100] Initial Loss: 0.1390, Training Loss: 0.0780, Initial Validation Loss: 0.1307, Validation Loss: 0.0819,V Acc: 0.6306, Top 70th Acc: 0.7308, Bottom 30th Acc: 0.3939
Fold [1/5] Epoch [30/100] Initial Loss: 0.1390, Training Loss: 0.0773, Initial Validation Loss: 0.1307, Validation Loss: 0.0806,V Acc: 0.6306, Top 70th Acc: 0.7179, Bottom 30th Acc: 0.4242
Stopping early at Epoch (base 0): 32  Rolling back to Epoch (base 0): 27  Top Validation Acc: 0.7435897435897436
Fold [2/5] Epoch [0/100] Initial Loss: 0.1290, Training Loss: 0.1290, Initial Validation Loss: 0.1142, Validation Loss: 0.1142,V Acc: 0.4865, Top 70th Acc: 0.6026, Bottom 30th Acc: 0.2121
Fold [2/5] Epoch [10/100] Initial Loss: 0.1290, Training Loss: 0.0836, Initial Validation Loss: 0.1142, Validation Loss: 0.0721,V Acc: 0.6667, Top 70th Acc: 0.7692, Bottom 30th Acc: 0.4242
Fold [2/5] Epoch [20/100] Initial Loss: 0.1290, Training Loss: 0.0813, Initial Validation Loss: 0.1142, Validation Loss: 0.0691,V Acc: 0.6577, Top 70th Acc: 0.8077, Bottom 30th Acc: 0.3030
Fold [2/5] Epoch [30/100] Initial Loss: 0.1290, Training Loss: 0.0808, Initial Validation Loss: 0.1142, Validation Loss: 0.0686,V Acc: 0.6757, Top 70th Acc: 0.7949, Bottom 30th Acc: 0.3939
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.9605263157894737
30 4 [array([0.8312941 , 0.01150783, 0.02465015, 0.08297607, 0.04957192],
      dtype=float32)]
Running train_nn.py with seed 31
CUDA:False
Training samples count:  550
Training on 21 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1320, Training Loss: 0.1320, Initial Validation Loss: 0.1157, Validation Loss: 0.1157,V Acc: 0.4234, Top 70th Acc: 0.5513, Bottom 30th Acc: 0.1212
Fold [1/5] Epoch [10/100] Initial Loss: 0.1320, Training Loss: 0.0275, Initial Validation Loss: 0.1157, Validation Loss: 0.0336,V Acc: 0.8559, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 14  Rolling back to Epoch (base 0): 9  Top Validation Acc: 0.9358974358974359
31 0 [array([0.6738115 , 0.02226164, 0.06887049, 0.12266134, 0.11239509],
      dtype=float32)]
Fold [2/5] Epoch [0/100] Initial Loss: 0.1322, Training Loss: 0.1322, Initial Validation Loss: 0.1156, Validation Loss: 0.1156,V Acc: 0.5315, Top 70th Acc: 0.6026, Bottom 30th Acc: 0.3636
Fold [2/5] Epoch [10/100] Initial Loss: 0.1322, Training Loss: 0.0251, Initial Validation Loss: 0.1156, Validation Loss: 0.0262,V Acc: 0.8829, Top 70th Acc: 0.9872, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 16  Rolling back to Epoch (base 0): 11  Top Validation Acc: 0.9743589743589743
Fold [3/5] Epoch [0/100] Initial Loss: 0.1262, Training Loss: 0.1262, Initial Validation Loss: 0.1112, Validation Loss: 0.1112,V Acc: 0.5636, Top 70th Acc: 0.6104, Bottom 30th Acc: 0.4545
Fold [3/5] Epoch [10/100] Initial Loss: 0.1262, Training Loss: 0.0262, Initial Validation Loss: 0.1112, Validation Loss: 0.0276,V Acc: 0.8364, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 18  Rolling back to Epoch (base 0): 13  Top Validation Acc: 0.974025974025974
Fold [4/5] Epoch [0/100] Initial Loss: 0.1347, Training Loss: 0.1347, Initial Validation Loss: 0.1299, Validation Loss: 0.1299,V Acc: 0.3727, Top 70th Acc: 0.4416, Bottom 30th Acc: 0.2121
Fold [4/5] Epoch [10/100] Initial Loss: 0.1347, Training Loss: 0.0222, Initial Validation Loss: 0.1299, Validation Loss: 0.0383,V Acc: 0.8182, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.5758
Fold [4/5] Epoch [20/100] Initial Loss: 0.1347, Training Loss: 0.0146, Initial Validation Loss: 0.1299, Validation Loss: 0.0355,V Acc: 0.8182, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 21  Rolling back to Epoch (base 0): 16  Top Validation Acc: 0.8961038961038961
Fold [5/5] Epoch [0/100] Initial Loss: 0.1269, Training Loss: 0.1269, Initial Validation Loss: 0.1127, Validation Loss: 0.1127,V Acc: 0.6481, Top 70th Acc: 0.7237, Bottom 30th Acc: 0.4688
Fold [5/5] Epoch [10/100] Initial Loss: 0.1269, Training Loss: 0.0283, Initial Validation Loss: 0.1127, Validation Loss: 0.0368,V Acc: 0.8241, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.5625
Fold [5/5] Epoch [20/100] Initial Loss: 0.1269, Training Loss: 0.0177, Initial Validation Loss: 0.1127, Validation Loss: 0.0358,V Acc: 0.8333, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.5938
Stopping early at Epoch (base 0): 22  Rolling back to Epoch (base 0): 17  Top Validation Acc: 0.9473684210526315
Running train_nn.py with seed 32
CUDA:False
Training samples count:  550
Training on 21 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1305, Training Loss: 0.1305, Initial Validation Loss: 0.1192, Validation Loss: 0.1192,V Acc: 0.4865, Top 70th Acc: 0.6154, Bottom 30th Acc: 0.1818
Fold [1/5] Epoch [10/100] Initial Loss: 0.1305, Training Loss: 0.0229, Initial Validation Loss: 0.1192, Validation Loss: 0.0332,V Acc: 0.8468, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 16  Rolling back to Epoch (base 0): 11  Top Validation Acc: 0.9230769230769231
Fold [2/5] Epoch [0/100] Initial Loss: 0.1303, Training Loss: 0.1303, Initial Validation Loss: 0.1167, Validation Loss: 0.1167,V Acc: 0.5856, Top 70th Acc: 0.6795, Bottom 30th Acc: 0.3636
Fold [2/5] Epoch [10/100] Initial Loss: 0.1303, Training Loss: 0.0292, Initial Validation Loss: 0.1167, Validation Loss: 0.0332,V Acc: 0.8559, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.6667
Fold [2/5] Epoch [20/100] Initial Loss: 0.1303, Training Loss: 0.0192, Initial Validation Loss: 0.1167, Validation Loss: 0.0252,V Acc: 0.9099, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.7576
Stopping early at Epoch (base 0): 29  Rolling back to Epoch (base 0): 24  Top Validation Acc: 0.9230769230769231
Fold [3/5] Epoch [0/100] Initial Loss: 0.1365, Training Loss: 0.1365, Initial Validation Loss: 0.1237, Validation Loss: 0.1237,V Acc: 0.4909, Top 70th Acc: 0.5455, Bottom 30th Acc: 0.3636
Fold [3/5] Epoch [10/100] Initial Loss: 0.1365, Training Loss: 0.0264, Initial Validation Loss: 0.1237, Validation Loss: 0.0342,V Acc: 0.8273, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.5152
Fold [3/5] Epoch [20/100] Initial Loss: 0.1365, Training Loss: 0.0176, Initial Validation Loss: 0.1237, Validation Loss: 0.0303,V Acc: 0.8273, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.5455
Fold [3/5] Epoch [30/100] Initial Loss: 0.1365, Training Loss: 0.0175, Initial Validation Loss: 0.1237, Validation Loss: 0.0329,V Acc: 0.8273, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.5152
Stopping early at Epoch (base 0): 30  Rolling back to Epoch (base 0): 25  Top Validation Acc: 0.961038961038961
32 2 [array([0.78996885, 0.04221072, 0.03208086, 0.0512561 , 0.08448345],
      dtype=float32)]
Fold [4/5] Epoch [0/100] Initial Loss: 0.1366, Training Loss: 0.1366, Initial Validation Loss: 0.1265, Validation Loss: 0.1265,V Acc: 0.4182, Top 70th Acc: 0.5065, Bottom 30th Acc: 0.2121
Fold [4/5] Epoch [10/100] Initial Loss: 0.1366, Training Loss: 0.0255, Initial Validation Loss: 0.1265, Validation Loss: 0.0326,V Acc: 0.8727, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 19  Rolling back to Epoch (base 0): 14  Top Validation Acc: 0.922077922077922
Fold [5/5] Epoch [0/100] Initial Loss: 0.1391, Training Loss: 0.1391, Initial Validation Loss: 0.1286, Validation Loss: 0.1286,V Acc: 0.3056, Top 70th Acc: 0.3289, Bottom 30th Acc: 0.2500
Fold [5/5] Epoch [10/100] Initial Loss: 0.1391, Training Loss: 0.0261, Initial Validation Loss: 0.1286, Validation Loss: 0.0283,V Acc: 0.8889, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.7188
Stopping early at Epoch (base 0): 15  Rolling back to Epoch (base 0): 10  Top Validation Acc: 0.9342105263157895
Running train_nn.py with seed 33
CUDA:False
Training samples count:  550
Training on 21 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1362, Training Loss: 0.1362, Initial Validation Loss: 0.1320, Validation Loss: 0.1320,V Acc: 0.4054, Top 70th Acc: 0.4359, Bottom 30th Acc: 0.3333
Fold [1/5] Epoch [10/100] Initial Loss: 0.1362, Training Loss: 0.0303, Initial Validation Loss: 0.1320, Validation Loss: 0.0344,V Acc: 0.8288, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.5455
Fold [1/5] Epoch [20/100] Initial Loss: 0.1362, Training Loss: 0.0185, Initial Validation Loss: 0.1320, Validation Loss: 0.0278,V Acc: 0.8378, Top 70th Acc: 0.9872, Bottom 30th Acc: 0.4848
Stopping early at Epoch (base 0): 27  Rolling back to Epoch (base 0): 22  Top Validation Acc: 0.9743589743589743
Fold [2/5] Epoch [0/100] Initial Loss: 0.1358, Training Loss: 0.1358, Initial Validation Loss: 0.1378, Validation Loss: 0.1378,V Acc: 0.4144, Top 70th Acc: 0.5256, Bottom 30th Acc: 0.1515
Fold [2/5] Epoch [10/100] Initial Loss: 0.1358, Training Loss: 0.0317, Initial Validation Loss: 0.1378, Validation Loss: 0.0320,V Acc: 0.8739, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.6970
Fold [2/5] Epoch [20/100] Initial Loss: 0.1358, Training Loss: 0.0176, Initial Validation Loss: 0.1378, Validation Loss: 0.0361,V Acc: 0.8288, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.9615384615384616
33 1 [array([0.5902004 , 0.01683859, 0.03608828, 0.16858137, 0.18829134],
      dtype=float32)]
Fold [3/5] Epoch [0/100] Initial Loss: 0.1280, Training Loss: 0.1280, Initial Validation Loss: 0.1097, Validation Loss: 0.1097,V Acc: 0.5727, Top 70th Acc: 0.6104, Bottom 30th Acc: 0.4848
Fold [3/5] Epoch [10/100] Initial Loss: 0.1280, Training Loss: 0.0299, Initial Validation Loss: 0.1097, Validation Loss: 0.0332,V Acc: 0.8364, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.5758
Fold [2/5] Epoch [20/100] Initial Loss: 0.1414, Training Loss: 0.0182, Initial Validation Loss: 0.1347, Validation Loss: 0.0334,V Acc: 0.7928, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.4545
Fold [2/5] Epoch [30/100] Initial Loss: 0.1414, Training Loss: 0.0135, Initial Validation Loss: 0.1347, Validation Loss: 0.0307,V Acc: 0.8108, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 30  Rolling back to Epoch (base 0): 25  Top Validation Acc: 0.9230769230769231
Fold [3/5] Epoch [0/100] Initial Loss: 0.1413, Training Loss: 0.1413, Initial Validation Loss: 0.1363, Validation Loss: 0.1363,V Acc: 0.2364, Top 70th Acc: 0.2078, Bottom 30th Acc: 0.3030
Fold [3/5] Epoch [10/100] Initial Loss: 0.1413, Training Loss: 0.0370, Initial Validation Loss: 0.1363, Validation Loss: 0.0446,V Acc: 0.8091, Top 70th Acc: 0.8961, Bottom 30th Acc: 0.6061
Fold [3/5] Epoch [20/100] Initial Loss: 0.1413, Training Loss: 0.0183, Initial Validation Loss: 0.1363, Validation Loss: 0.0365,V Acc: 0.8000, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.5152
Fold [3/5] Epoch [30/100] Initial Loss: 0.1413, Training Loss: 0.0122, Initial Validation Loss: 0.1363, Validation Loss: 0.0342,V Acc: 0.8273, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 38  Rolling back to Epoch (base 0): 33  Top Validation Acc: 0.935064935064935
21 2 [array([0.41209927, 0.11385044, 0.0351081 , 0.07304759, 0.3658946 ],
      dtype=float32)]
Fold [4/5] Epoch [0/100] Initial Loss: 0.1387, Training Loss: 0.1387, Initial Validation Loss: 0.1356, Validation Loss: 0.1356,V Acc: 0.2364, Top 70th Acc: 0.2857, Bottom 30th Acc: 0.1212
Fold [4/5] Epoch [10/100] Initial Loss: 0.1387, Training Loss: 0.0333, Initial Validation Loss: 0.1356, Validation Loss: 0.0398,V Acc: 0.8364, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.6667
Fold [4/5] Epoch [20/100] Initial Loss: 0.1387, Training Loss: 0.0144, Initial Validation Loss: 0.1356, Validation Loss: 0.0345,V Acc: 0.8091, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.4848
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.935064935064935
Fold [5/5] Epoch [0/100] Initial Loss: 0.1423, Training Loss: 0.1423, Initial Validation Loss: 0.1338, Validation Loss: 0.1338,V Acc: 0.2500, Top 70th Acc: 0.3158, Bottom 30th Acc: 0.0938
Fold [5/5] Epoch [10/100] Initial Loss: 0.1423, Training Loss: 0.0312, Initial Validation Loss: 0.1338, Validation Loss: 0.0400,V Acc: 0.7778, Top 70th Acc: 0.8947, Bottom 30th Acc: 0.5000
Fold [5/5] Epoch [20/100] Initial Loss: 0.1423, Training Loss: 0.0172, Initial Validation Loss: 0.1338, Validation Loss: 0.0289,V Acc: 0.8241, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.5625
Fold [5/5] Epoch [30/100] Initial Loss: 0.1423, Training Loss: 0.0131, Initial Validation Loss: 0.1338, Validation Loss: 0.0244,V Acc: 0.8519, Top 70th Acc: 0.9737, Bottom 30th Acc: 0.5625
Stopping early at Epoch (base 0): 34  Rolling back to Epoch (base 0): 29  Top Validation Acc: 0.9736842105263158
Running train_nn.py with seed 22
CUDA:False
Training samples count:  550
Training on 40 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1399, Training Loss: 0.1399, Initial Validation Loss: 0.1326, Validation Loss: 0.1326,V Acc: 0.3333, Top 70th Acc: 0.3333, Bottom 30th Acc: 0.3333
Fold [1/5] Epoch [10/100] Initial Loss: 0.1399, Training Loss: 0.0338, Initial Validation Loss: 0.1326, Validation Loss: 0.0467,V Acc: 0.7568, Top 70th Acc: 0.8590, Bottom 30th Acc: 0.5152
Fold [1/5] Epoch [20/100] Initial Loss: 0.1399, Training Loss: 0.0139, Initial Validation Loss: 0.1326, Validation Loss: 0.0330,V Acc: 0.8468, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.9102564102564102
Fold [2/5] Epoch [0/100] Initial Loss: 0.1386, Training Loss: 0.1386, Initial Validation Loss: 0.1355, Validation Loss: 0.1355,V Acc: 0.2523, Top 70th Acc: 0.3077, Bottom 30th Acc: 0.1212
Fold [2/5] Epoch [10/100] Initial Loss: 0.1386, Training Loss: 0.0291, Initial Validation Loss: 0.1355, Validation Loss: 0.0279,V Acc: 0.8919, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.7273
Fold [2/5] Epoch [20/100] Initial Loss: 0.1386, Training Loss: 0.0141, Initial Validation Loss: 0.1355, Validation Loss: 0.0234,V Acc: 0.8739, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.9487179487179487
Fold [3/5] Epoch [0/100] Initial Loss: 0.1381, Training Loss: 0.1381, Initial Validation Loss: 0.1370, Validation Loss: 0.1370,V Acc: 0.3909, Top 70th Acc: 0.4545, Bottom 30th Acc: 0.2424
Fold [3/5] Epoch [10/100] Initial Loss: 0.1381, Training Loss: 0.0348, Initial Validation Loss: 0.1370, Validation Loss: 0.0400,V Acc: 0.8364, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.5152
Fold [3/5] Epoch [20/100] Initial Loss: 0.1381, Training Loss: 0.0151, Initial Validation Loss: 0.1370, Validation Loss: 0.0294,V Acc: 0.8545, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.987012987012987
Fold [4/5] Epoch [0/100] Initial Loss: 0.1404, Training Loss: 0.1404, Initial Validation Loss: 0.1340, Validation Loss: 0.1340,V Acc: 0.2727, Top 70th Acc: 0.2987, Bottom 30th Acc: 0.2121
Fold [4/5] Epoch [10/100] Initial Loss: 0.1404, Training Loss: 0.0303, Initial Validation Loss: 0.1340, Validation Loss: 0.0422,V Acc: 0.8182, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.5758
Fold [4/5] Epoch [20/100] Initial Loss: 0.1404, Training Loss: 0.0154, Initial Validation Loss: 0.1340, Validation Loss: 0.0330,V Acc: 0.8091, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.5455
Fold [4/5] Epoch [30/100] Initial Loss: 0.1404, Training Loss: 0.0124, Initial Validation Loss: 0.1340, Validation Loss: 0.0338,V Acc: 0.8091, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 30  Rolling back to Epoch (base 0): 25  Top Validation Acc: 0.922077922077922
Fold [5/5] Epoch [0/100] Initial Loss: 0.1381, Training Loss: 0.1381, Initial Validation Loss: 0.1344, Validation Loss: 0.1344,V Acc: 0.3426, Top 70th Acc: 0.3684, Bottom 30th Acc: 0.2812
Fold [5/5] Epoch [10/100] Initial Loss: 0.1381, Training Loss: 0.0299, Initial Validation Loss: 0.1344, Validation Loss: 0.0366,V Acc: 0.8333, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.5625
Fold [5/5] Epoch [20/100] Initial Loss: 0.1381, Training Loss: 0.0152, Initial Validation Loss: 0.1344, Validation Loss: 0.0288,V Acc: 0.8704, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.6875
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.9605263157894737
22 4 [array([0.6143932 , 0.02974515, 0.07042191, 0.10259061, 0.18284915],
      dtype=float32)]
Running train_nn.py with seed 23
CUDA:False
Training samples count:  550
Training on 40 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1390, Training Loss: 0.1390, Initial Validation Loss: 0.1334, Validation Loss: 0.1334,V Acc: 0.3243, Top 70th Acc: 0.3846, Bottom 30th Acc: 0.1818
Fold [1/5] Epoch [10/100] Initial Loss: 0.1390, Training Loss: 0.0338, Initial Validation Loss: 0.1334, Validation Loss: 0.0426,V Acc: 0.8018, Top 70th Acc: 0.8974, Bottom 30th Acc: 0.5758
Fold [1/5] Epoch [20/100] Initial Loss: 0.1390, Training Loss: 0.0142, Initial Validation Loss: 0.1334, Validation Loss: 0.0299,V Acc: 0.8559, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.9230769230769231
Fold [2/5] Epoch [0/100] Initial Loss: 0.1383, Training Loss: 0.1383, Initial Validation Loss: 0.1348, Validation Loss: 0.1348,V Acc: 0.2523, Top 70th Acc: 0.3205, Bottom 30th Acc: 0.0909
Fold [2/5] Epoch [10/100] Initial Loss: 0.1383, Training Loss: 0.0306, Initial Validation Loss: 0.1348, Validation Loss: 0.0435,V Acc: 0.7928, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.4848
Fold [2/5] Epoch [20/100] Initial Loss: 0.1383, Training Loss: 0.0134, Initial Validation Loss: 0.1348, Validation Loss: 0.0366,V Acc: 0.8108, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.4545
Stopping early at Epoch (base 0): 29  Rolling back to Epoch (base 0): 24  Top Validation Acc:training rf with seed 1
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 30 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 2
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 30 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 3
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 30 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 4
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 30 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 5
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 30 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 6
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 30 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 7
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 30 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 8
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 30 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 9
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 30 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 10
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 30 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 11
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 30 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 12
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 30 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 13
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 30 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 14
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 30 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 15
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 30 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 16
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 30 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 17
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 30 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 18
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 30 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 19
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 30 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 20
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 30 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 21
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 30 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 22
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 30 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 23
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 30 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 24
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 30 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 25
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 30 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 26
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 30 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 27
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 30 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 28
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 30 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 29
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 30 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 30
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 30 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 31
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 30 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 32
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 30 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 33
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 30 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 34
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 30 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 35
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 30 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 36
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 30 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 37
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 30 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 38
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 30 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 39
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 30 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 40
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 30 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 41
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 30 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 42
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 30 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 43
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 30 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 44
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 30 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 45
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442 0.9358974358974359
Fold [3/5] Epoch [0/100] Initial Loss: 0.1357, Training Loss: 0.1357, Initial Validation Loss: 0.1294, Validation Loss: 0.1294,V Acc: 0.3818, Top 70th Acc: 0.4286, Bottom 30th Acc: 0.2727
Fold [3/5] Epoch [10/100] Initial Loss: 0.1357, Training Loss: 0.0387, Initial Validation Loss: 0.1294, Validation Loss: 0.0462,V Acc: 0.8000, Top 70th Acc: 0.8961, Bottom 30th Acc: 0.5758
Fold [3/5] Epoch [20/100] Initial Loss: 0.1357, Training Loss: 0.0186, Initial Validation Loss: 0.1294, Validation Loss: 0.0342,V Acc: 0.8545, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6364
Fold [3/5] Epoch [30/100] Initial Loss: 0.1357, Training Loss: 0.0157, Initial Validation Loss: 0.1294, Validation Loss: 0.0339,V Acc: 0.8545, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 31  Rolling back to Epoch (base 0): 26  Top Validation Acc: 0.961038961038961
21 2 [array([0.7127475 , 0.10926195, 0.02499204, 0.06940597, 0.08359258],
      dtype=float32)]
Fold [4/5] Epoch [0/100] Initial Loss: 0.1380, Training Loss: 0.1380, Initial Validation Loss: 0.1313, Validation Loss: 0.1313,V Acc: 0.3091, Top 70th Acc: 0.3636, Bottom 30th Acc: 0.1818
Fold [4/5] Epoch [10/100] Initial Loss: 0.1380, Training Loss: 0.0249, Initial Validation Loss: 0.1313, Validation Loss: 0.0360,V Acc: 0.8455, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.6667
Fold [4/5] Epoch [20/100] Initial Loss: 0.1380, Training Loss: 0.0174, Initial Validation Loss: 0.1313, Validation Loss: 0.0337,V Acc: 0.8455, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.935064935064935
Fold [5/5] Epoch [0/100] Initial Loss: 0.1382, Training Loss: 0.1382, Initial Validation Loss: 0.1319, Validation Loss: 0.1319,V Acc: 0.2685, Top 70th Acc: 0.2763, Bottom 30th Acc: 0.2500
Fold [5/5] Epoch [10/100] Initial Loss: 0.1382, Training Loss: 0.0329, Initial Validation Loss: 0.1319, Validation Loss: 0.0392,V Acc: 0.8241, Top 70th Acc: 0.9211, Bottom 30th Acc: 0.5938
Fold [5/5] Epoch [20/100] Initial Loss: 0.1382, Training Loss: 0.0207, Initial Validation Loss: 0.1319, Validation Loss: 0.0313,V Acc: 0.8519, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.6250
Fold [5/5] Epoch [30/100] Initial Loss: 0.1382, Training Loss: 0.0178, Initial Validation Loss: 0.1319, Validation Loss: 0.0309,V Acc: 0.8426, Top 70th Acc: 0.9211, Bottom 30th Acc: 0.6562
Stopping early at Epoch (base 0): 36  Rolling back to Epoch (base 0): 31  Top Validation Acc: 0.9342105263157895
Running train_nn.py with seed 22
CUDA:False
Training samples count:  550
Training on 30 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1395, Training Loss: 0.1395, Initial Validation Loss: 0.1322, Validation Loss: 0.1322,V Acc: 0.2523, Top 70th Acc: 0.3462, Bottom 30th Acc: 0.0303
Fold [1/5] Epoch [10/100] Initial Loss: 0.1395, Training Loss: 0.0240, Initial Validation Loss: 0.1322, Validation Loss: 0.0370,V Acc: 0.8108, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 19  Rolling back to Epoch (base 0): 14  Top Validation Acc: 0.9230769230769231
Fold [2/5] Epoch [0/100] Initial Loss: 0.1413, Training Loss: 0.1413, Initial Validation Loss: 0.1349, Validation Loss: 0.1349,V Acc: 0.3153, Top 70th Acc: 0.3718, Bottom 30th Acc: 0.1818
Fold [2/5] Epoch [10/100] Initial Loss: 0.1413, Training Loss: 0.0398, Initial Validation Loss: 0.1349, Validation Loss: 0.0304,V Acc: 0.8739, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.6364
Fold [2/5] Epoch [20/100] Initial Loss: 0.1413, Training Loss: 0.0200, Initial Validation Loss: 0.1349, Validation Loss: 0.0219,V Acc: 0.9009, Top 70th Acc: 0.9872, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.9871794871794872
Fold [3/5] Epoch [0/100] Initial Loss: 0.1383, Training Loss: 0.1383, Initial Validation Loss: 0.1364, Validation Loss: 0.1364,V Acc: 0.2455, Top 70th Acc: 0.2727, Bottom 30th Acc: 0.1818
Fold [3/5] Epoch [10/100] Initial Loss: 0.1383, Training Loss: 0.0406, Initial Validation Loss: 0.1364, Validation Loss: 0.0496,V Acc: 0.7636, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.4242
Fold [3/5] Epoch [20/100] Initial Loss: 0.1383, Training Loss: 0.0185, Initial Validation Loss: 0.1364, Validation Loss: 0.0340,V Acc: 0.8455, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 28  Rolling back to Epoch (base 0): 23  Top Validation Acc: 0.948051948051948
Fold [4/5] Epoch [0/100] Initial Loss: 0.1411, Training Loss: 0.1411, Initial Validation Loss: 0.1349, Validation Loss: 0.1349,V Acc: 0.2636, Top 70th Acc: 0.2597, Bottom 30th Acc: 0.2727
Fold [4/5] Epoch [10/100] Initial Loss: 0.1411, Training Loss: 0.0330, Initial Validation Loss: 0.1349, Validation Loss: 0.0498,V Acc: 0.7364, Top 70th Acc: 0.8571, Bottom 30th Acc: 0.4545
Fold [4/5] Epoch [20/100] Initial Loss: 0.1411, Training Loss: 0.0184, Initial Validation Loss: 0.1349, Validation Loss: 0.0400,V Acc: 0.8091, Top 70th Acc: 0.8961, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 28  Rolling back to Epoch (base 0): 23  Top Validation Acc: 0.8961038961038961
Fold [5/5] Epoch [0/100] Initial Loss: 0.1377, Training Loss: 0.1377, Initial Validation Loss: 0.1376, Validation Loss: 0.1376,V Acc: 0.2685, Top 70th Acc: 0.2368, Bottom 30th Acc: 0.3438
Fold [5/5] Epoch [10/100] Initial Loss: 0.1377, Training Loss: 0.0438, Initial Validation Loss: 0.1376, Validation Loss: 0.0452,V Acc: 0.8148, Top 70th Acc: 0.9211, Bottom 30th Acc: 0.5625
Fold [5/5] Epoch [20/100] Initial Loss: 0.1377, Training Loss: 0.0252, Initial Validation Loss: 0.1376, Validation Loss: 0.0343,V Acc: 0.8333, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.5625
Fold [5/5] Epoch [30/100] Initial Loss: 0.1377, Training Loss: 0.0173, Initial Validation Loss: 0.1376, Validation Loss: 0.0289,V Acc: 0.8519, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.5938
Stopping early at Epoch (base 0): 39  Rolling back to Epoch (base 0): 34  Top Validation Acc: 0.9473684210526315
22 4 [array([0.84538394, 0.03187845, 0.02042383, 0.04576967, 0.05654409],
      dtype=float32)]
Running train_nn.py with seed 23
CUDA:False
Training samples count:  550
Training on 30 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1383, Training Loss: 0.1383, Initial Validation Loss: 0.1342, Validation Loss: 0.1342,V Acc: 0.2793, Top 70th Acc: 0.3718, Bottom 30th Acc: 0.0606
Fold [1/5] Epoch [10/100] Initial Loss: 0.1383, Training Loss: 0.0272, Initial Validation Loss: 0.1342, Validation Loss: 0.0349,V Acc: 0.8108, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 17  Rolling back to Epoch (base 0): 12  Top Validation Acc: 0.9102564102564102
Fold [2/5] Epoch [0/100] Initial Loss: 0.1393, Training Loss: 0.1393, Initial Validation Loss: 0.1352, Validation Loss: 0.1352,V Acc: 0.4054, Top 70th Acc: 0.5000, Bottom 30th Acc: 0.1818
Fold [2/5] Epoch [10/100] Initial Loss: 0.1393, Training Loss: 0.0336, Initial Validation Loss: 0.1352, Validation Loss: 0.0433,V Acc: 0.7658, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.3030
Fold [2/5] Epoch [20/100] Initial Loss: 0.1393, Training Loss: 0.0183, Initial Validation Loss: 0.1352, Validation Loss: 0.0351,V Acc: 0.8468, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 28  Rolling back to Epoch (base 0): 23  Top Validation Acc: 0.9615384615384616
Fold [3/5] Epoch [0/100] Initial Loss: 0.1378, Training Loss: 0.1378, Initial Validation Loss: 0.1311, Validation Loss: 0.1311,V Acc: 0.2909, Top 70th Acc: 0.3377, Bottom 30th Acc: 0.1818
Fold [3/5] Epoch [10/100] Initial Loss: 0.1378, Training Loss: 0.0335, Initial Validation Loss: 0.1311, Validation Loss: 0.0385,V Acc: 0.8545, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.6970
Fold [3/5] Epoch [20/100] Initial Loss: 0.1378, Training Loss: 0.0189, Initial Validation Loss: 0.1311, Validation Loss: 0.0316,V Acc: 0.8545, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.948051948051948
23 2 [array([0.48071557, 0.06963196, 0.13593136, 0.13768034, 0.17604081],
      dtype=float32)]
Fold [4/5] Epoch [0/100] Initial Loss: 0.1347, Training Loss: 0.1347, Initial Validation Loss: 0.1273, Validation Loss: 0.1273,V Acc: 0.4273, Top 70th Acc: 0.5325, Bottom 30th Acc: 0.1818
Stopping early at Epoch (base 0): 33  Rolling back to Epoch (base 0): 28  Top Validation Acc: 0.9871794871794872
18 1 [array([0.27089494, 0.11709853, 0.12710112, 0.23604554, 0.24885982],
      dtype=float32)]
Fold [3/5] Epoch [0/100] Initial Loss: 0.1397, Training Loss: 0.1397, Initial Validation Loss: 0.1361, Validation Loss: 0.1361,V Acc: 0.2545, Top 70th Acc: 0.3636, Bottom 30th Acc: 0.0000
Fold [3/5] Epoch [10/100] Initial Loss: 0.1397, Training Loss: 0.0218, Initial Validation Loss: 0.1361, Validation Loss: 0.0394,V Acc: 0.8364, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.6061
Fold [3/5] Epoch [20/100] Initial Loss: 0.1397, Training Loss: 0.0063, Initial Validation Loss: 0.1361, Validation Loss: 0.0374,V Acc: 0.8273, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 22  Rolling back to Epoch (base 0): 17  Top Validation Acc: 0.935064935064935
Fold [4/5] Epoch [0/100] Initial Loss: 0.1377, Training Loss: 0.1377, Initial Validation Loss: 0.1276, Validation Loss: 0.1276,V Acc: 0.4636, Top 70th Acc: 0.4935, Bottom 30th Acc: 0.3939
Fold [4/5] Epoch [10/100] Initial Loss: 0.1377, Training Loss: 0.0090, Initial Validation Loss: 0.1276, Validation Loss: 0.0316,V Acc: 0.8182, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.5455
Fold [4/5] Epoch [20/100] Initial Loss: 0.1377, Training Loss: 0.0041, Initial Validation Loss: 0.1276, Validation Loss: 0.0316,V Acc: 0.8364, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 21  Rolling back to Epoch (base 0): 16  Top Validation Acc: 0.922077922077922
Fold [5/5] Epoch [0/100] Initial Loss: 0.1387, Training Loss: 0.1387, Initial Validation Loss: 0.1321, Validation Loss: 0.1321,V Acc: 0.2593, Top 70th Acc: 0.3421, Bottom 30th Acc: 0.0625
Fold [5/5] Epoch [10/100] Initial Loss: 0.1387, Training Loss: 0.0160, Initial Validation Loss: 0.1321, Validation Loss: 0.0345,V Acc: 0.8148, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.5000
Fold [5/5] Epoch [20/100] Initial Loss: 0.1387, Training Loss: 0.0051, Initial Validation Loss: 0.1321, Validation Loss: 0.0282,V Acc: 0.8333, Top 70th Acc: 0.9737, Bottom 30th Acc: 0.5000
Stopping early at Epoch (base 0): 22  Rolling back to Epoch (base 0): 17  Top Validation Acc: 0.9736842105263158
Running train_nn.py with seed 19
CUDA:False
Training samples count:  550
Training on 163 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1383, Training Loss: 0.1383, Initial Validation Loss: 0.1340, Validation Loss: 0.1340,V Acc: 0.2523, Top 70th Acc: 0.3590, Bottom 30th Acc: 0.0000
Fold [1/5] Epoch [10/100] Initial Loss: 0.1383, Training Loss: 0.0192, Initial Validation Loss: 0.1340, Validation Loss: 0.0314,V Acc: 0.8378, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.5455
Fold [1/5] Epoch [20/100] Initial Loss: 0.1383, Training Loss: 0.0052, Initial Validation Loss: 0.1340, Validation Loss: 0.0246,V Acc: 0.9009, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.7273
Stopping early at Epoch (base 0): 27  Rolling back to Epoch (base 0): 22  Top Validation Acc: 0.9743589743589743
Fold [2/5] Epoch [0/100] Initial Loss: 0.1400, Training Loss: 0.1400, Initial Validation Loss: 0.1315, Validation Loss: 0.1315,V Acc: 0.3964, Top 70th Acc: 0.4103, Bottom 30th Acc: 0.3636
Fold [2/5] Epoch [10/100] Initial Loss: 0.1400, Training Loss: 0.0150, Initial Validation Loss: 0.1315, Validation Loss: 0.0362,V Acc: 0.7928, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.5152
Fold [2/5] Epoch [20/100] Initial Loss: 0.1400, Training Loss: 0.0047, Initial Validation Loss: 0.1315, Validation Loss: 0.0344,V Acc: 0.8018, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.5152
Fold [2/5] Epoch [30/100] Initial Loss: 0.1400, Training Loss: 0.0037, Initial Validation Loss: 0.1315, Validation Loss: 0.0330,V Acc: 0.8108, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.5152
Fold [2/5] Epoch [40/100] Initial Loss: 0.1400, Training Loss: 0.0034, Initial Validation Loss: 0.1315, Validation Loss: 0.0327,V Acc: 0.8198, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.5152
Stopping early at Epoch (base 0): 47  Rolling back to Epoch (base 0): 42  Top Validation Acc: 0.9615384615384616
Fold [3/5] Epoch [0/100] Initial Loss: 0.1404, Training Loss: 0.1404, Initial Validation Loss: 0.1356, Validation Loss: 0.1356,V Acc: 0.2545, Top 70th Acc: 0.3247, Bottom 30th Acc: 0.0909
Fold [3/5] Epoch [10/100] Initial Loss: 0.1404, Training Loss: 0.0349, Initial Validation Loss: 0.1356, Validation Loss: 0.0462,V Acc: 0.7818, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.4545
Fold [3/5] Epoch [20/100] Initial Loss: 0.1404, Training Loss: 0.0060, Initial Validation Loss: 0.1356, Validation Loss: 0.0262,V Acc: 0.8545, Top 70th Acc: 0.9870, Bottom 30th Acc: 0.5455
Fold [3/5] Epoch [30/100] Initial Loss: 0.1404, Training Loss: 0.0041, Initial Validation Loss: 0.1356, Validation Loss: 0.0243,V Acc: 0.8636, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 34  Rolling back to Epoch (base 0): 29  Top Validation Acc: 0.974025974025974
Fold [4/5] Epoch [0/100] Initial Loss: 0.1365, Training Loss: 0.1365, Initial Validation Loss: 0.1362, Validation Loss: 0.1362,V Acc: 0.3364, Top 70th Acc: 0.4156, Bottom 30th Acc: 0.1515
Fold [4/5] Epoch [10/100] Initial Loss: 0.1365, Training Loss: 0.0176, Initial Validation Loss: 0.1362, Validation Loss: 0.0412,V Acc: 0.8182, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.6061
Fold [4/5] Epoch [20/100] Initial Loss: 0.1365, Training Loss: 0.0062, Initial Validation Loss: 0.1362, Validation Loss: 0.0367,V Acc: 0.8364, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.9090909090909091
19 3 [array([0.17647992, 0.08256944, 0.05037548, 0.18102226, 0.5095529 ],
      dtype=float32)]
Fold [5/5] Epoch [0/100] Initial Loss: 0.1387, Training Loss: 0.1387, Initial Validation Loss: 0.1356, Validation Loss: 0.1356,V Acc: 0.2500, Top 70th Acc: 0.3289, Bottom 30th Acc: 0.0625
Fold [5/5] Epoch [10/100] Initial Loss: 0.1387, Training Loss: 0.0183, Initial Validation Loss: 0.1356, Validation Loss: 0.0380,V Acc: 0.8519, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.6562
Fold [5/5] Epoch [20/100] Initial Loss: 0.1387, Training Loss: 0.0051, Initial Validation Loss: 0.1356, Validation Loss: 0.0298,V Acc: 0.8611, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.6562
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.9605263157894737
Running train_nn.py with seed 20
CUDA:False
Training samples count:  550
Training on 163 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1407, Training Loss: 0.1407, Initial Validation Loss: 0.1357, Validation Loss: 0.1357,V Acc: 0.2703, Top 70th Acc: 0.3205, Bottom 30th Acc: 0.1515
Fold [1/5] Epoch [10/100] Initial Loss: 0.1407, Training Loss: 0.0252, Initial Validation Loss: 0.1357, Validation Loss: 0.0419,V Acc: 0.8468, Top 70th Acc: 0.8974, Bottom 30th Acc: 0.7273
Fold [1/5] Epoch [20/100] Initial Loss: 0.1407, Training Loss: 0.0048, Initial Validation Loss: 0.1357, Validation Loss: 0.0318,V Acc: 0.8468, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.9487179487179487
Fold [2/5] Epoch [0/100] Initial Loss: 0.1375, Training Loss: 0.1375, Initial Validation Loss: 0.1367, Validation Loss: 0.1367,V Acc: 0.3243, Top 70th Acc: 0.3718, Bottom 30th Acc: 0.2121
Fold [2/5] Epoch [10/100] Initial Loss: 0.1375, Training Loss: 0.0177, Initial Validation Loss: 0.1367, Validation Loss: 0.0242,V Acc: 0.9099, Top 70th Acc: 0.9872, Bottom 30th Acc: 0.7273
Fold [2/5] Epoch [20/100] Initial Loss: 0.1375, Training Loss: 0.0054, Initial Validation Loss: 0.1367, Validation Loss: 0.0185,V Acc: 0.9189, Top 70th Acc: 0.9872, Bottom 30th Acc: 0.7576
Stopping early at Epoch (base 0): 21  Rolling back to Epoch (base 0): 16  Top Validation Acc: 0.9871794871794872
Fold [3/5] Epoch [0/100] Initial Loss: 0.1401, Training Loss: 0.1401, Initial Validation Loss: 0.1287, Validation Loss: 0.1287,V Acc: 0.3909, Top 70th Acc: 0.4675, Bottom 30th Acc: 0.2121
Fold [3/5] Epoch [10/100] Initial Loss: 0.1401, Training Loss: 0.0126, Initial Validation Loss: 0.1287, Validation Loss: 0.0287,V Acc: 0.8455, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.6364
Fold [3/5] Epoch [20/100] Initial Loss: 0.1280, Training Loss: 0.0180, Initial Validation Loss: 0.1097, Validation Loss: 0.0240,V Acc: 0.8727, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.948051948051948
Fold [4/5] Epoch [0/100] Initial Loss: 0.1308, Training Loss: 0.1308, Initial Validation Loss: 0.1077, Validation Loss: 0.1077,V Acc: 0.5273, Top 70th Acc: 0.6494, Bottom 30th Acc: 0.2424
Fold [4/5] Epoch [10/100] Initial Loss: 0.1308, Training Loss: 0.0219, Initial Validation Loss: 0.1077, Validation Loss: 0.0404,V Acc: 0.8273, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.6364
Fold [4/5] Epoch [20/100] Initial Loss: 0.1308, Training Loss: 0.0171, Initial Validation Loss: 0.1077, Validation Loss: 0.0401,V Acc: 0.8182, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 20  Rolling back to Epoch (base 0): 15  Top Validation Acc: 0.922077922077922
Fold [5/5] Epoch [0/100] Initial Loss: 0.1359, Training Loss: 0.1359, Initial Validation Loss: 0.1287, Validation Loss: 0.1287,V Acc: 0.3796, Top 70th Acc: 0.4737, Bottom 30th Acc: 0.1562
Fold [5/5] Epoch [10/100] Initial Loss: 0.1359, Training Loss: 0.0225, Initial Validation Loss: 0.1287, Validation Loss: 0.0340,V Acc: 0.8611, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.6875
Stopping early at Epoch (base 0): 13  Rolling back to Epoch (base 0): 8  Top Validation Acc: 0.9078947368421053
Running train_nn.py with seed 34
CUDA:False
Training samples count:  550
Training on 21 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1342, Training Loss: 0.1342, Initial Validation Loss: 0.1185, Validation Loss: 0.1185,V Acc: 0.4234, Top 70th Acc: 0.5897, Bottom 30th Acc: 0.0303
Fold [1/5] Epoch [10/100] Initial Loss: 0.1342, Training Loss: 0.0277, Initial Validation Loss: 0.1185, Validation Loss: 0.0224,V Acc: 0.8919, Top 70th Acc: 1.0000, Bottom 30th Acc: 0.6364
Fold [1/5] Epoch [20/100] Initial Loss: 0.1342, Training Loss: 0.0184, Initial Validation Loss: 0.1185, Validation Loss: 0.0208,V Acc: 0.8649, Top 70th Acc: 0.9872, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 21  Rolling back to Epoch (base 0): 16  Top Validation Acc: 0.9871794871794872
Fold [2/5] Epoch [0/100] Initial Loss: 0.1308, Training Loss: 0.1308, Initial Validation Loss: 0.1170, Validation Loss: 0.1170,V Acc: 0.5045, Top 70th Acc: 0.6026, Bottom 30th Acc: 0.2727
Fold [2/5] Epoch [10/100] Initial Loss: 0.1308, Training Loss: 0.0282, Initial Validation Loss: 0.1170, Validation Loss: 0.0410,V Acc: 0.8018, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.5152
Stopping early at Epoch (base 0): 18  Rolling back to Epoch (base 0): 13  Top Validation Acc: 0.9102564102564102
34 1 [array([0.7980623 , 0.02703354, 0.012898  , 0.10951522, 0.05249086],
      dtype=float32)]
Fold [3/5] Epoch [0/100] Initial Loss: 0.1381, Training Loss: 0.1381, Initial Validation Loss: 0.1321, Validation Loss: 0.1321,V Acc: 0.4909, Top 70th Acc: 0.5714, Bottom 30th Acc: 0.3030
Fold [3/5] Epoch [10/100] Initial Loss: 0.1381, Training Loss: 0.0237, Initial Validation Loss: 0.1321, Validation Loss: 0.0323,V Acc: 0.8364, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.6061
Fold [3/5] Epoch [20/100] Initial Loss: 0.1381, Training Loss: 0.0175, Initial Validation Loss: 0.1321, Validation Loss: 0.0241,V Acc: 0.8818, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 29  Rolling back to Epoch (base 0): 24  Top Validation Acc: 0.974025974025974
Fold [4/5] Epoch [0/100] Initial Loss: 0.1329, Training Loss: 0.1329, Initial Validation Loss: 0.1198, Validation Loss: 0.1198,V Acc: 0.5000, Top 70th Acc: 0.6234, Bottom 30th Acc: 0.2121
Fold [4/5] Epoch [10/100] Initial Loss: 0.1329, Training Loss: 0.0227, Initial Validation Loss: 0.1198, Validation Loss: 0.0278,V Acc: 0.8818, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.6970
Fold [4/5] Epoch [20/100] Initial Loss: 0.1329, Training Loss: 0.0181, Initial Validation Loss: 0.1198, Validation Loss: 0.0241,V Acc: 0.9091, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.7879
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.974025974025974
Fold [5/5] Epoch [0/100] Initial Loss: 0.1348, Training Loss: 0.1348, Initial Validation Loss: 0.1207, Validation Loss: 0.1207,V Acc: 0.4722, Top 70th Acc: 0.5658, Bottom 30th Acc: 0.2500
Fold [5/5] Epoch [10/100] Initial Loss: 0.1348, Training Loss: 0.0265, Initial Validation Loss: 0.1207, Validation Loss: 0.0326,V Acc: 0.8333, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.5625
Stopping early at Epoch (base 0): 18  Rolling back to Epoch (base 0): 13  Top Validation Acc: 0.9605263157894737
Running train_nn.py with seed 35
CUDA:False
Training samples count:  550
Training on 21 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1260, Training Loss: 0.1260, Initial Validation Loss: 0.1122, Validation Loss: 0.1122,V Acc: 0.6126, Top 70th Acc: 0.7949, Bottom 30th Acc: 0.1818
Fold [1/5] Epoch [10/100] Initial Loss: 0.1260, Training Loss: 0.0240, Initial Validation Loss: 0.1122, Validation Loss: 0.0285,V Acc: 0.8649, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 13  Rolling back to Epoch (base 0): 8  Top Validation Acc: 0.9743589743589743
Fold [2/5] Epoch [0/100] Initial Loss: 0.1365, Training Loss: 0.1365, Initial Validation Loss: 0.1336, Validation Loss: 0.1336,V Acc: 0.4955, Top 70th Acc: 0.6282, Bottom 30th Acc: 0.1818
Fold [2/5] Epoch [10/100] Initial Loss: 0.1365, Training Loss: 0.0303, Initial Validation Loss: 0.1336, Validation Loss: 0.0386,V Acc: 0.8468, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 18  Rolling back to Epoch (base 0): 13  Top Validation Acc: 0.9487179487179487
Fold [3/5] Epoch [0/100] Initial Loss: 0.1394, Training Loss: 0.1394, Initial Validation Loss: 0.1309, Validation Loss: 0.1309,V Acc: 0.4000, Top 70th Acc: 0.3896, Bottom 30th Acc: 0.4242
Fold [3/5] Epoch [10/100] Initial Loss: 0.1394, Training Loss: 0.0277, Initial Validation Loss: 0.1309, Validation Loss: 0.0392,V Acc: 0.8545, Top 70th Acc: 0.8961, Bottom 30th Acc: 0.7576
Stopping early at Epoch (base 0): 17  Rolling back to Epoch (base 0): 12  Top Validation Acc: 0.974025974025974
Fold [4/5] Epoch [0/100] Initial Loss: 0.1314, Training Loss: 0.1314, Initial Validation Loss: 0.1117, Validation Loss: 0.1117,V Acc: 0.5182, Top 70th Acc: 0.5584, Bottom 30th Acc: 0.4242
Fold [4/5] Epoch [10/100] Initial Loss: 0.1314, Training Loss: 0.0324, Initial Validation Loss: 0.1117, Validation Loss: 0.0430,V Acc: 0.8182, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 17  Rolling back to Epoch (base 0): 12  Top Validation Acc: 0.8961038961038961
Fold [5/5] Epoch [0/100] Initial Loss: 0.1282, Training Loss: 0.1282, Initial Validation Loss: 0.1135, Validation Loss: 0.1135,V Acc: 0.4259, Top 70th Acc: 0.5000, Bottom 30th Acc: 0.2500
Fold [5/5] Epoch [10/100] Initial Loss: 0.1282, Training Loss: 0.0315, Initial Validation Loss: 0.1135, Validation Loss: 0.0402,V Acc: 0.8148, Top 70th Acc: 0.8816, Bottom 30th Acc: 0.6562
Fold [5/5] Epoch [20/100] Initial Loss: 0.1282, Training Loss: 0.0162, Initial Validation Loss: 0.1135, Validation Loss: 0.0350,V Acc: 0.8241, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.5625
Stopping early at Epoch (base 0): 20  Rolling back to Epoch (base 0): 15  Top Validation Acc: 0.9342105263157895
35 4 [array([0.7836006 , 0.01050558, 0.01880503, 0.14238493, 0.04470385],
      dtype=float32)]
Running train_nn.py with seed 36
CUDA:False
Training samples count:  550
Training on 21 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1362, Training Loss: 0.1362, Initial Validation Loss: 0.1221, Validation Loss: 0.1221,V Acc: 0.4595, Top 70th Acc: 0.5513, Bottom 30th Acc: 0.2424
Fold [1/5] Epoch [10/100] Initial Loss: 0.1362, Training Loss: 0.0225, Initial Validation Loss: 0.1221, Validation Loss: 0.0381,V Acc: 0.7748, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.4242
Fold [1/5] Epoch [20/100] Initial Loss: 0.1362, Training Loss: 0.0177, Initial Validation Loss: 0.1221, Validation Loss: 0.0293,V Acc: 0.8559, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0):
Fold [5/5] Epoch [10/100] Initial Loss: 0.1372, Training Loss: 0.0396, Initial Validation Loss: 0.1340, Validation Loss: 0.0409,V Acc: 0.7963, Top 70th Acc: 0.9079, Bottom 30th Acc: 0.5312
Fold [5/5] Epoch [20/100] Initial Loss: 0.1372, Training Loss: 0.0243, Initial Validation Loss: 0.1340, Validation Loss: 0.0323,V Acc: 0.8148, Top 70th Acc: 0.9211, Bottom 30th Acc: 0.5625
Stopping early at Epoch (base 0): 29  Rolling back to Epoch (base 0): 24  Top Validation Acc: 0.9342105263157895
Running train_nn.py with seed 24
CUDA:False
Training samples count:  550
Training on 20 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1350, Training Loss: 0.1350, Initial Validation Loss: 0.1375, Validation Loss: 0.1375,V Acc: 0.4324, Top 70th Acc: 0.4744, Bottom 30th Acc: 0.3333
Fold [1/5] Epoch [10/100] Initial Loss: 0.1350, Training Loss: 0.0418, Initial Validation Loss: 0.1375, Validation Loss: 0.0439,V Acc: 0.8288, Top 70th Acc: 0.8846, Bottom 30th Acc: 0.6970
Fold [1/5] Epoch [20/100] Initial Loss: 0.1350, Training Loss: 0.0238, Initial Validation Loss: 0.1375, Validation Loss: 0.0273,V Acc: 0.9009, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.7879
Fold [1/5] Epoch [30/100] Initial Loss: 0.1350, Training Loss: 0.0210, Initial Validation Loss: 0.1375, Validation Loss: 0.0259,V Acc: 0.8919, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 35  Rolling back to Epoch (base 0): 30  Top Validation Acc: 0.9615384615384616
Fold [2/5] Epoch [0/100] Initial Loss: 0.1430, Training Loss: 0.1430, Initial Validation Loss: 0.1343, Validation Loss: 0.1343,V Acc: 0.2523, Top 70th Acc: 0.2821, Bottom 30th Acc: 0.1818
Fold [2/5] Epoch [10/100] Initial Loss: 0.1430, Training Loss: 0.0407, Initial Validation Loss: 0.1343, Validation Loss: 0.0459,V Acc: 0.7928, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.5152
Fold [2/5] Epoch [20/100] Initial Loss: 0.1430, Training Loss: 0.0225, Initial Validation Loss: 0.1343, Validation Loss: 0.0376,V Acc: 0.8198, Top 70th Acc: 0.8974, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.9230769230769231
Fold [3/5] Epoch [0/100] Initial Loss: 0.1410, Training Loss: 0.1410, Initial Validation Loss: 0.1338, Validation Loss: 0.1338,V Acc: 0.3364, Top 70th Acc: 0.3506, Bottom 30th Acc: 0.3030
Fold [3/5] Epoch [10/100] Initial Loss: 0.1410, Training Loss: 0.0312, Initial Validation Loss: 0.1338, Validation Loss: 0.0388,V Acc: 0.8273, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.6364
Fold [3/5] Epoch [20/100] Initial Loss: 0.1410, Training Loss: 0.0217, Initial Validation Loss: 0.1338, Validation Loss: 0.0340,V Acc: 0.8364, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.9090909090909091
24 2 [array([0.25559786, 0.16990067, 0.14674793, 0.17691825, 0.2508353 ],
      dtype=float32)]
Fold [4/5] Epoch [0/100] Initial Loss: 0.1377, Training Loss: 0.1377, Initial Validation Loss: 0.1378, Validation Loss: 0.1378,V Acc: 0.2545, Top 70th Acc: 0.3117, Bottom 30th Acc: 0.1212
Fold [4/5] Epoch [10/100] Initial Loss: 0.1377, Training Loss: 0.0326, Initial Validation Loss: 0.1378, Validation Loss: 0.0339,V Acc: 0.8818, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.6667
Fold [4/5] Epoch [20/100] Initial Loss: 0.1377, Training Loss: 0.0236, Initial Validation Loss: 0.1378, Validation Loss: 0.0247,V Acc: 0.9273, Top 70th Acc: 0.9870, Bottom 30th Acc: 0.7879
Stopping early at Epoch (base 0): 28  Rolling back to Epoch (base 0): 23  Top Validation Acc: 0.987012987012987
Fold [5/5] Epoch [0/100] Initial Loss: 0.1374, Training Loss: 0.1374, Initial Validation Loss: 0.1285, Validation Loss: 0.1285,V Acc: 0.3889, Top 70th Acc: 0.5132, Bottom 30th Acc: 0.0938
Fold [5/5] Epoch [10/100] Initial Loss: 0.1374, Training Loss: 0.0500, Initial Validation Loss: 0.1285, Validation Loss: 0.0479,V Acc: 0.7315, Top 70th Acc: 0.8947, Bottom 30th Acc: 0.3438
Fold [5/5] Epoch [20/100] Initial Loss: 0.1374, Training Loss: 0.0239, Initial Validation Loss: 0.1285, Validation Loss: 0.0329,V Acc: 0.7870, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.4375
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.9605263157894737
Running train_nn.py with seed 25
CUDA:False
Training samples count:  550
Training on 20 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1387, Training Loss: 0.1387, Initial Validation Loss: 0.1310, Validation Loss: 0.1310,V Acc: 0.3604, Top 70th Acc: 0.4487, Bottom 30th Acc: 0.1515
Fold [1/5] Epoch [10/100] Initial Loss: 0.1387, Training Loss: 0.0311, Initial Validation Loss: 0.1310, Validation Loss: 0.0382,V Acc: 0.8198, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.6061
Fold [1/5] Epoch [20/100] Initial Loss: 0.1387, Training Loss: 0.0222, Initial Validation Loss: 0.1310, Validation Loss: 0.0326,V Acc: 0.8198, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.9358974358974359
Fold [2/5] Epoch [0/100] Initial Loss: 0.1341, Training Loss: 0.1341, Initial Validation Loss: 0.1330, Validation Loss: 0.1330,V Acc: 0.3153, Top 70th Acc: 0.3846, Bottom 30th Acc: 0.1515
Fold [2/5] Epoch [10/100] Initial Loss: 0.1341, Training Loss: 0.0286, Initial Validation Loss: 0.1330, Validation Loss: 0.0366,V Acc: 0.8198, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 19  Rolling back to Epoch (base 0): 14  Top Validation Acc: 0.9230769230769231
Fold [3/5] Epoch [0/100] Initial Loss: 0.1382, Training Loss: 0.1382, Initial Validation Loss: 0.1313, Validation Loss: 0.1313,V Acc: 0.3455, Top 70th Acc: 0.4026, Bottom 30th Acc: 0.2121
Fold [3/5] Epoch [10/100] Initial Loss: 0.1382, Training Loss: 0.0367, Initial Validation Loss: 0.1313, Validation Loss: 0.0359,V Acc: 0.8273, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.5758
Fold [3/5] Epoch [20/100] Initial Loss: 0.1382, Training Loss: 0.0235, Initial Validation Loss: 0.1313, Validation Loss: 0.0278,V Acc: 0.8455, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.935064935064935
Fold [4/5] Epoch [0/100] Initial Loss: 0.1398, Training Loss: 0.1398, Initial Validation Loss: 0.1371, Validation Loss: 0.1371,V Acc: 0.2545, Top 70th Acc: 0.2987, Bottom 30th Acc: 0.1515
Fold [4/5] Epoch [10/100] Initial Loss: 0.1398, Training Loss: 0.0338, Initial Validation Loss: 0.1371, Validation Loss: 0.0340,V Acc: 0.8818, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.7273
Fold [4/5] Epoch [20/100] Initial Loss: 0.1398, Training Loss: 0.0234, Initial Validation Loss: 0.1371, Validation Loss: 0.0264,V Acc: 0.9000, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.7273
Fold [4/5] Epoch [30/100] Initial Loss: 0.1398, Training Loss: 0.0214, Initial Validation Loss: 0.1371, Validation Loss: 0.0270,V Acc: 0.8909, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 34  Rolling back to Epoch (base 0): 29  Top Validation Acc: 0.974025974025974
25 3 [array([0.30519643, 0.11541658, 0.22141083, 0.21929382, 0.13868234],
      dtype=float32)]
Fold [5/5] Epoch [0/100] Initial Loss: 0.1400, Training Loss: 0.1400, Initial Validation Loss: 0.1303, Validation Loss: 0.1303,V Acc: 0.3704, Top 70th Acc: 0.4605, Bottom 30th Acc: 0.1562
Fold [5/5] Epoch [10/100] Initial Loss: 0.1400, Training Loss: 0.0463, Initial Validation Loss: 0.1303, Validation Loss: 0.0490,V Acc: 0.7222, Top 70th Acc: 0.9079, Bottom 30th Acc: 0.2812
Fold [5/5] Epoch [20/100] Initial Loss: 0.1400, Training Loss: 0.0267, Initial Validation Loss: 0.1303, Validation Loss: 0.0321,V Acc: 0.8519, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.5938
Fold [5/5] Epoch [30/100] Initial Loss: 0.1400, Training Loss: 0.0221, Initial Validation Loss: 0.1303, Validation Loss: 0.0296,V Acc: 0.8519, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.5938
Stopping early at Epoch (base 0): 33  Rolling back to Epoch (base 0): 28  Top Validation Acc: 0.9736842105263158
Running train_nn.py with seed 26
CUDA:False
Training samples count:  550
Training on 20 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1390, Training Loss: 0.1390, Initial Validation Loss: 0.1354, Validation Loss: 0.1354,V Acc: 0.3604, Top 70th Acc: 0.3974, Bottom 30th Acc: 0.2727 0.9487179487179487
Fold [3/5] Epoch [0/100] Initial Loss: 0.1373, Training Loss: 0.1373, Initial Validation Loss: 0.1323, Validation Loss: 0.1323,V Acc: 0.3364, Top 70th Acc: 0.4286, Bottom 30th Acc: 0.1212
Fold [3/5] Epoch [10/100] Initial Loss: 0.1373, Training Loss: 0.0273, Initial Validation Loss: 0.1323, Validation Loss: 0.0390,V Acc: 0.8091, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.5152
Fold [3/5] Epoch [20/100] Initial Loss: 0.1373, Training Loss: 0.0130, Initial Validation Loss: 0.1323, Validation Loss: 0.0303,V Acc: 0.8636, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 21  Rolling back to Epoch (base 0): 16  Top Validation Acc: 0.961038961038961
23 2 [array([0.4043622 , 0.18736023, 0.07736862, 0.09679402, 0.23411492],
      dtype=float32)]
Fold [4/5] Epoch [0/100] Initial Loss: 0.1388, Training Loss: 0.1388, Initial Validation Loss: 0.1335, Validation Loss: 0.1335,V Acc: 0.3727, Top 70th Acc: 0.4156, Bottom 30th Acc: 0.2727
Fold [4/5] Epoch [10/100] Initial Loss: 0.1388, Training Loss: 0.0283, Initial Validation Loss: 0.1335, Validation Loss: 0.0344,V Acc: 0.7909, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.4242
Fold [4/5] Epoch [20/100] Initial Loss: 0.1388, Training Loss: 0.0133, Initial Validation Loss: 0.1335, Validation Loss: 0.0275,V Acc: 0.8455, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6061
Fold [4/5] Epoch [30/100] Initial Loss: 0.1388, Training Loss: 0.0110, Initial Validation Loss: 0.1335, Validation Loss: 0.0258,V Acc: 0.8636, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 32  Rolling back to Epoch (base 0): 27  Top Validation Acc: 0.961038961038961
Fold [5/5] Epoch [0/100] Initial Loss: 0.1398, Training Loss: 0.1398, Initial Validation Loss: 0.1350, Validation Loss: 0.1350,V Acc: 0.2500, Top 70th Acc: 0.3289, Bottom 30th Acc: 0.0625
Fold [5/5] Epoch [10/100] Initial Loss: 0.1398, Training Loss: 0.0304, Initial Validation Loss: 0.1350, Validation Loss: 0.0347,V Acc: 0.8426, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.5625
Fold [5/5] Epoch [20/100] Initial Loss: 0.1398, Training Loss: 0.0151, Initial Validation Loss: 0.1350, Validation Loss: 0.0259,V Acc: 0.8611, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.6562
Stopping early at Epoch (base 0): 29  Rolling back to Epoch (base 0): 24  Top Validation Acc: 0.9605263157894737
Running train_nn.py with seed 24
CUDA:False
Training samples count:  550
Training on 40 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1384, Training Loss: 0.1384, Initial Validation Loss: 0.1400, Validation Loss: 0.1400,V Acc: 0.3964, Top 70th Acc: 0.3846, Bottom 30th Acc: 0.4242
Fold [1/5] Epoch [10/100] Initial Loss: 0.1384, Training Loss: 0.0308, Initial Validation Loss: 0.1400, Validation Loss: 0.0320,V Acc: 0.8919, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.6970
Fold [1/5] Epoch [20/100] Initial Loss: 0.1384, Training Loss: 0.0166, Initial Validation Loss: 0.1400, Validation Loss: 0.0221,V Acc: 0.9099, Top 70th Acc: 0.9872, Bottom 30th Acc: 0.7273
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.9871794871794872
Fold [2/5] Epoch [0/100] Initial Loss: 0.1396, Training Loss: 0.1396, Initial Validation Loss: 0.1339, Validation Loss: 0.1339,V Acc: 0.2523, Top 70th Acc: 0.2949, Bottom 30th Acc: 0.1515
Fold [2/5] Epoch [10/100] Initial Loss: 0.1396, Training Loss: 0.0298, Initial Validation Loss: 0.1339, Validation Loss: 0.0413,V Acc: 0.8468, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.6364
Fold [2/5] Epoch [20/100] Initial Loss: 0.1396, Training Loss: 0.0127, Initial Validation Loss: 0.1339, Validation Loss: 0.0380,V Acc: 0.8018, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.4242
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.9487179487179487
Fold [3/5] Epoch [0/100] Initial Loss: 0.1395, Training Loss: 0.1395, Initial Validation Loss: 0.1316, Validation Loss: 0.1316,V Acc: 0.3273, Top 70th Acc: 0.4286, Bottom 30th Acc: 0.0909
Fold [3/5] Epoch [10/100] Initial Loss: 0.1395, Training Loss: 0.0247, Initial Validation Loss: 0.1316, Validation Loss: 0.0359,V Acc: 0.7818, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.4242
Stopping early at Epoch (base 0): 17  Rolling back to Epoch (base 0): 12  Top Validation Acc: 0.922077922077922
24 2 [array([0.31076553, 0.1058607 , 0.07860311, 0.14384623, 0.36092445],
      dtype=float32)]
Fold [4/5] Epoch [0/100] Initial Loss: 0.1364, Training Loss: 0.1364, Initial Validation Loss: 0.1383, Validation Loss: 0.1383,V Acc: 0.3545, Top 70th Acc: 0.4026, Bottom 30th Acc: 0.2424
Fold [4/5] Epoch [10/100] Initial Loss: 0.1364, Training Loss: 0.0352, Initial Validation Loss: 0.1383, Validation Loss: 0.0376,V Acc: 0.9091, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.8182
Fold [4/5] Epoch [20/100] Initial Loss: 0.1364, Training Loss: 0.0161, Initial Validation Loss: 0.1383, Validation Loss: 0.0255,V Acc: 0.8727, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.6364
Fold [4/5] Epoch [30/100] Initial Loss: 0.1364, Training Loss: 0.0130, Initial Validation Loss: 0.1383, Validation Loss: 0.0265,V Acc: 0.8909, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 30  Rolling back to Epoch (base 0): 25  Top Validation Acc: 0.974025974025974
Fold [5/5] Epoch [0/100] Initial Loss: 0.1416, Training Loss: 0.1416, Initial Validation Loss: 0.1283, Validation Loss: 0.1283,V Acc: 0.2685, Top 70th Acc: 0.3816, Bottom 30th Acc: 0.0000
Fold [5/5] Epoch [10/100] Initial Loss: 0.1416, Training Loss: 0.0272, Initial Validation Loss: 0.1283, Validation Loss: 0.0333,V Acc: 0.8519, Top 70th Acc: 0.9211, Bottom 30th Acc: 0.6875
Fold [5/5] Epoch [20/100] Initial Loss: 0.1416, Training Loss: 0.0152, Initial Validation Loss: 0.1283, Validation Loss: 0.0292,V Acc: 0.8611, Top 70th Acc: 0.9211, Bottom 30th Acc: 0.7188
Stopping early at Epoch (base 0): 27  Rolling back to Epoch (base 0): 22  Top Validation Acc: 0.9078947368421053
Running train_nn.py with seed 25
CUDA:False
Training samples count:  550
Training on 40 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1369, Training Loss: 0.1369, Initial Validation Loss: 0.1319, Validation Loss: 0.1319,V Acc: 0.2793, Top 70th Acc: 0.3205, Bottom 30th Acc: 0.1818
Fold [1/5] Epoch [10/100] Initial Loss: 0.1369, Training Loss: 0.0257, Initial Validation Loss: 0.1319, Validation Loss: 0.0329,V Acc: 0.8559, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.6667
Fold [1/5] Epoch [20/100] Initial Loss: 0.1369, Training Loss: 0.0143, Initial Validation Loss: 0.1319, Validation Loss: 0.0273,V Acc: 0.8468, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.9230769230769231
Fold [2/5] Epoch [0/100] Initial Loss: 0.1375, Training Loss: 0.1375, Initial Validation Loss: 0.1378, Validation Loss: 0.1378,V Acc: 0.2342, Top 70th Acc: 0.3077, Bottom 30th Acc: 0.0606
Fold [2/5] Epoch [10/100] Initial Loss: 0.1375, Training Loss: 0.0355, Initial Validation Loss: 0.1378, Validation Loss: 0.0394,V Acc: 0.8108, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.5758
Fold [2/5] Epoch [20/100] Initial Loss: 0.1375, Training Loss: 0.0139, Initial Validation Loss: 0.1378, Validation Loss: 0.0318,V Acc: 0.8559, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 28  Rolling back to Epoch (base 0): 23  Top Validation Acc: 0.9615384615384616
Fold [3/5] Epoch [0/100] Initial Loss: 0.1371, Training Loss: 0.1371, Initial Validation Loss: 0.1301, Validation Loss: 0.1301,V Acc: 0.3818, Top 70th Acc: 0.4286, Bottom 30th Acc: 0.2727
Fold [3/5] Epoch [10/100] Initial Loss: 0.1371, Training Loss: 0.0320, Initial Validation Loss: 0.1301, Validation Loss: 0.0421,V Acc: 0.8000, Top 70th Acc: 0.8961, Bottom 30th Acc: 0.5758
Fold [3/5] Epoch [20/100] Initial Loss: 0.1371, Training Loss: 0.0163, Initial Validation Loss: 0.1301, Validation Loss: 0.0316,V Acc: 0.8182, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.5758
Fold [3/5] Epoch [30/100] Initial Loss: 0.1371, Training Loss: 0.0129, Initial Validation Loss: 0.1301, Validation Loss: 0.0302,V Acc: 0.8273, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 31  Rolling back to Epoch (base 0):
Stopping early at Epoch (base 0): 35  Rolling back to Epoch (base 0): 30  Top Validation Acc: 0.7692307692307693
Fold [3/5] Epoch [0/100] Initial Loss: 0.1419, Training Loss: 0.1419, Initial Validation Loss: 0.1358, Validation Loss: 0.1358,V Acc: 0.2545, Top 70th Acc: 0.2727, Bottom 30th Acc: 0.2121
Fold [3/5] Epoch [10/100] Initial Loss: 0.1419, Training Loss: 0.0819, Initial Validation Loss: 0.1358, Validation Loss: 0.0759,V Acc: 0.6545, Top 70th Acc: 0.7143, Bottom 30th Acc: 0.5152
Fold [3/5] Epoch [20/100] Initial Loss: 0.1419, Training Loss: 0.0797, Initial Validation Loss: 0.1358, Validation Loss: 0.0740,V Acc: 0.6455, Top 70th Acc: 0.7403, Bottom 30th Acc: 0.4242
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.7402597402597403
Fold [4/5] Epoch [0/100] Initial Loss: 0.1358, Training Loss: 0.1358, Initial Validation Loss: 0.1265, Validation Loss: 0.1265,V Acc: 0.3455, Top 70th Acc: 0.3896, Bottom 30th Acc: 0.2424
Fold [4/5] Epoch [10/100] Initial Loss: 0.1358, Training Loss: 0.0774, Initial Validation Loss: 0.1265, Validation Loss: 0.0934,V Acc: 0.5545, Top 70th Acc: 0.6623, Bottom 30th Acc: 0.3030
Stopping early at Epoch (base 0): 15  Rolling back to Epoch (base 0): 10  Top Validation Acc: 0.6753246753246753
Fold [5/5] Epoch [0/100] Initial Loss: 0.1339, Training Loss: 0.1339, Initial Validation Loss: 0.1313, Validation Loss: 0.1313,V Acc: 0.3426, Top 70th Acc: 0.3684, Bottom 30th Acc: 0.2812
Fold [5/5] Epoch [10/100] Initial Loss: 0.1339, Training Loss: 0.0815, Initial Validation Loss: 0.1313, Validation Loss: 0.0783,V Acc: 0.6389, Top 70th Acc: 0.7368, Bottom 30th Acc: 0.4062
Fold [5/5] Epoch [20/100] Initial Loss: 0.1339, Training Loss: 0.0792, Initial Validation Loss: 0.1313, Validation Loss: 0.0758,V Acc: 0.6389, Top 70th Acc: 0.7632, Bottom 30th Acc: 0.3438
Fold [5/5] Epoch [30/100] Initial Loss: 0.1339, Training Loss: 0.0785, Initial Validation Loss: 0.1313, Validation Loss: 0.0754,V Acc: 0.6296, Top 70th Acc: 0.7632, Bottom 30th Acc: 0.3125
Fold [5/5] Epoch [40/100] Initial Loss: 0.1339, Training Loss: 0.0777, Initial Validation Loss: 0.1313, Validation Loss: 0.0753,V Acc: 0.6389, Top 70th Acc: 0.7368, Bottom 30th Acc: 0.4062
Stopping early at Epoch (base 0): 42  Rolling back to Epoch (base 0): 37  Top Validation Acc: 0.7631578947368421
22 4 [array([0.16884948, 0.36468306, 0.11893874, 0.23094264, 0.11658607],
      dtype=float32)]
Running train_nn.py with seed 23
CUDA:False
Training samples count:  550
Training on 2 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1418, Training Loss: 0.1418, Initial Validation Loss: 0.1349, Validation Loss: 0.1349,V Acc: 0.3874, Top 70th Acc: 0.3205, Bottom 30th Acc: 0.5455
Fold [1/5] Epoch [10/100] Initial Loss: 0.1418, Training Loss: 0.0803, Initial Validation Loss: 0.1349, Validation Loss: 0.0843,V Acc: 0.6036, Top 70th Acc: 0.7051, Bottom 30th Acc: 0.3636
Fold [1/5] Epoch [20/100] Initial Loss: 0.1418, Training Loss: 0.0779, Initial Validation Loss: 0.1349, Validation Loss: 0.0831,V Acc: 0.6036, Top 70th Acc: 0.7051, Bottom 30th Acc: 0.3636
Stopping early at Epoch (base 0): 21  Rolling back to Epoch (base 0): 16  Top Validation Acc: 0.717948717948718
Fold [2/5] Epoch [0/100] Initial Loss: 0.1332, Training Loss: 0.1332, Initial Validation Loss: 0.1291, Validation Loss: 0.1291,V Acc: 0.3604, Top 70th Acc: 0.4744, Bottom 30th Acc: 0.0909
Fold [2/5] Epoch [10/100] Initial Loss: 0.1332, Training Loss: 0.0804, Initial Validation Loss: 0.1291, Validation Loss: 0.0807,V Acc: 0.6396, Top 70th Acc: 0.7692, Bottom 30th Acc: 0.3333
Fold [2/5] Epoch [20/100] Initial Loss: 0.1332, Training Loss: 0.0785, Initial Validation Loss: 0.1291, Validation Loss: 0.0790,V Acc: 0.6396, Top 70th Acc: 0.7564, Bottom 30th Acc: 0.3636
Stopping early at Epoch (base 0): 28  Rolling back to Epoch (base 0): 23  Top Validation Acc: 0.7307692307692307
Fold [3/5] Epoch [0/100] Initial Loss: 0.1342, Training Loss: 0.1342, Initial Validation Loss: 0.1255, Validation Loss: 0.1255,V Acc: 0.4091, Top 70th Acc: 0.4675, Bottom 30th Acc: 0.2727
Fold [3/5] Epoch [10/100] Initial Loss: 0.1342, Training Loss: 0.0801, Initial Validation Loss: 0.1255, Validation Loss: 0.0818,V Acc: 0.6091, Top 70th Acc: 0.6883, Bottom 30th Acc: 0.4242
Fold [3/5] Epoch [20/100] Initial Loss: 0.1342, Training Loss: 0.0783, Initial Validation Loss: 0.1255, Validation Loss: 0.0801,V Acc: 0.6182, Top 70th Acc: 0.7013, Bottom 30th Acc: 0.4242
Fold [3/5] Epoch [30/100] Initial Loss: 0.1342, Training Loss: 0.0768, Initial Validation Loss: 0.1255, Validation Loss: 0.0811,V Acc: 0.6273, Top 70th Acc: 0.7013, Bottom 30th Acc: 0.4545
Fold [3/5] Epoch [40/100] Initial Loss: 0.1342, Training Loss: 0.0768, Initial Validation Loss: 0.1255, Validation Loss: 0.0796,V Acc: 0.6182, Top 70th Acc: 0.7013, Bottom 30th Acc: 0.4242
Stopping early at Epoch (base 0): 48  Rolling back to Epoch (base 0): 43  Top Validation Acc: 0.7012987012987013
23 2 [array([0.12766802, 0.3308762 , 0.11397382, 0.27653894, 0.15094301],
      dtype=float32)]
Fold [4/5] Epoch [0/100] Initial Loss: 0.1298, Training Loss: 0.1298, Initial Validation Loss: 0.1178, Validation Loss: 0.1178,V Acc: 0.4545, Top 70th Acc: 0.4675, Bottom 30th Acc: 0.4242
Fold [4/5] Epoch [10/100] Initial Loss: 0.1298, Training Loss: 0.0816, Initial Validation Loss: 0.1178, Validation Loss: 0.0764,V Acc: 0.6455, Top 70th Acc: 0.7273, Bottom 30th Acc: 0.4545
Fold [4/5] Epoch [20/100] Initial Loss: 0.1298, Training Loss: 0.0795, Initial Validation Loss: 0.1178, Validation Loss: 0.0756,V Acc: 0.6273, Top 70th Acc: 0.7143, Bottom 30th Acc: 0.4242
Stopping early at Epoch (base 0): 21  Rolling back to Epoch (base 0): 16  Top Validation Acc: 0.7142857142857143
Fold [5/5] Epoch [0/100] Initial Loss: 0.1380, Training Loss: 0.1380, Initial Validation Loss: 0.1331, Validation Loss: 0.1331,V Acc: 0.2870, Top 70th Acc: 0.3816, Bottom 30th Acc: 0.0625
Fold [5/5] Epoch [10/100] Initial Loss: 0.1380, Training Loss: 0.0816, Initial Validation Loss: 0.1331, Validation Loss: 0.0809,V Acc: 0.6389, Top 70th Acc: 0.7500, Bottom 30th Acc: 0.3750
Fold [5/5] Epoch [20/100] Initial Loss: 0.1380, Training Loss: 0.0789, Initial Validation Loss: 0.1331, Validation Loss: 0.0770,V Acc: 0.6574, Top 70th Acc: 0.7500, Bottom 30th Acc: 0.4375
Fold [5/5] Epoch [30/100] Initial Loss: 0.1380, Training Loss: 0.0779, Initial Validation Loss: 0.1331, Validation Loss: 0.0762,V Acc: 0.6574, Top 70th Acc: 0.7632, Bottom 30th Acc: 0.4062
Stopping early at Epoch (base 0): 31  Rolling back to Epoch (base 0): 26  Top Validation Acc: 0.7368421052631579
Running train_nn.py with seed 24
CUDA:False
Training samples count:  550
Training on 2 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1366, Training Loss: 0.1366, Initial Validation Loss: 0.1341, Validation Loss: 0.1341,V Acc: 0.5405, Top 70th Acc: 0.6538, Bottom 30th Acc: 0.2727
Fold [1/5] Epoch [10/100] Initial Loss: 0.1366, Training Loss: 0.0798, Initial Validation Loss: 0.1341, Validation Loss: 0.0835,V Acc: 0.6667, Top 70th Acc: 0.7179, Bottom 30th Acc: 0.5455
Fold [1/5] Epoch [20/100] Initial Loss: 0.1366, Training Loss: 0.0777, Initial Validation Loss: 0.1341, Validation Loss: 0.0819,V Acc: 0.6577, Top 70th Acc: 0.7308, Bottom 30th Acc: 0.4848
Fold [1/5] Epoch [30/100] Initial Loss: 0.1366, Training Loss: 0.0766, Initial Validation Loss: 0.1341, Validation Loss: 0.0822,V Acc: 0.6757, Top 70th Acc: 0.7564, Bottom 30th Acc: 0.4848
Stopping early at Epoch (base 0): 31  Rolling back to Epoch (base 0): 26  Top Validation Acc: 0.7564102564102564
Fold [2/5] Epoch [0/100] Initial Loss: 0.1383, Training Loss: 0.1383, Initial Validation Loss: 0.1237, Validation Loss: 0.1237,V Acc: 0.3694, Top 70th Acc: 0.4231, Bottom 30th Acc: 0.2424
Fold [2/5] Epoch [10/100] Initial Loss: 0.1383, Training Loss: 0.0820, Initial Validation Loss: 0.1237, Validation Loss: 0.0758,V Acc: 0.6396, Top 70th Acc: 0.7692, Bottom 30th Acc: 0.3333
Fold [2/5] Epoch [20/100] Initial Loss: 0.1383, Training Loss: 0.0803, Initial Validation Loss: 0.1237, Validation Loss: 0.0744,V Acc: 0.6396, Top 70th Acc: 0.7564, Bottom 30th Acc: 0.3636
Fold [2/5] Epoch [30/100] Initial Loss: 0.1383, Training Loss: 0.0794, Initial Validation Loss: 0.1237, Validation Loss: 0.0746,V Acc: 0.6306, Top 70th Acc: 0.7692, Bottom 30th Acc: 0.3030
Fold [4/5] Epoch [10/100] Initial Loss: 0.1347, Training Loss: 0.0338, Initial Validation Loss: 0.1273, Validation Loss: 0.0409,V Acc: 0.7727, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.3939
Fold [4/5] Epoch [20/100] Initial Loss: 0.1347, Training Loss: 0.0187, Initial Validation Loss: 0.1273, Validation Loss: 0.0383,V Acc: 0.7818, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.4545
Fold [4/5] Epoch [30/100] Initial Loss: 0.1347, Training Loss: 0.0149, Initial Validation Loss: 0.1273, Validation Loss: 0.0373,V Acc: 0.7727, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.3939
Fold [4/5] Epoch [40/100] Initial Loss: 0.1347, Training Loss: 0.0139, Initial Validation Loss: 0.1273, Validation Loss: 0.0362,V Acc: 0.7818, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.4242
Fold [4/5] Epoch [50/100] Initial Loss: 0.1347, Training Loss: 0.0129, Initial Validation Loss: 0.1273, Validation Loss: 0.0363,V Acc: 0.7818, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.4242
Stopping early at Epoch (base 0): 52  Rolling back to Epoch (base 0): 47  Top Validation Acc: 0.935064935064935
Fold [5/5] Epoch [0/100] Initial Loss: 0.1363, Training Loss: 0.1363, Initial Validation Loss: 0.1306, Validation Loss: 0.1306,V Acc: 0.4352, Top 70th Acc: 0.5395, Bottom 30th Acc: 0.1875
Fold [5/5] Epoch [10/100] Initial Loss: 0.1363, Training Loss: 0.0319, Initial Validation Loss: 0.1306, Validation Loss: 0.0363,V Acc: 0.8241, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.5625
Fold [5/5] Epoch [20/100] Initial Loss: 0.1363, Training Loss: 0.0200, Initial Validation Loss: 0.1306, Validation Loss: 0.0277,V Acc: 0.8611, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.6562
Fold [5/5] Epoch [30/100] Initial Loss: 0.1363, Training Loss: 0.0175, Initial Validation Loss: 0.1306, Validation Loss: 0.0266,V Acc: 0.8611, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.6562
Stopping early at Epoch (base 0): 34  Rolling back to Epoch (base 0): 29  Top Validation Acc: 0.9605263157894737
Running train_nn.py with seed 24
CUDA:False
Training samples count:  550
Training on 30 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1395, Training Loss: 0.1395, Initial Validation Loss: 0.1416, Validation Loss: 0.1416,V Acc: 0.2883, Top 70th Acc: 0.3205, Bottom 30th Acc: 0.2121
Fold [1/5] Epoch [10/100] Initial Loss: 0.1395, Training Loss: 0.0356, Initial Validation Loss: 0.1416, Validation Loss: 0.0401,V Acc: 0.8378, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.5758
Fold [1/5] Epoch [20/100] Initial Loss: 0.1395, Training Loss: 0.0206, Initial Validation Loss: 0.1416, Validation Loss: 0.0289,V Acc: 0.8739, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.6970
Fold [1/5] Epoch [30/100] Initial Loss: 0.1395, Training Loss: 0.0176, Initial Validation Loss: 0.1416, Validation Loss: 0.0274,V Acc: 0.8649, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 39  Rolling back to Epoch (base 0): 34  Top Validation Acc: 0.9487179487179487
Fold [2/5] Epoch [0/100] Initial Loss: 0.1401, Training Loss: 0.1401, Initial Validation Loss: 0.1309, Validation Loss: 0.1309,V Acc: 0.2523, Top 70th Acc: 0.3333, Bottom 30th Acc: 0.0606
Fold [2/5] Epoch [10/100] Initial Loss: 0.1401, Training Loss: 0.0306, Initial Validation Loss: 0.1309, Validation Loss: 0.0405,V Acc: 0.8288, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.6364
Fold [2/5] Epoch [20/100] Initial Loss: 0.1401, Training Loss: 0.0162, Initial Validation Loss: 0.1309, Validation Loss: 0.0350,V Acc: 0.8018, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.4545
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.9487179487179487
Fold [3/5] Epoch [0/100] Initial Loss: 0.1384, Training Loss: 0.1384, Initial Validation Loss: 0.1323, Validation Loss: 0.1323,V Acc: 0.2909, Top 70th Acc: 0.3896, Bottom 30th Acc: 0.0606
Fold [3/5] Epoch [10/100] Initial Loss: 0.1384, Training Loss: 0.0440, Initial Validation Loss: 0.1323, Validation Loss: 0.0567,V Acc: 0.7091, Top 70th Acc: 0.8442, Bottom 30th Acc: 0.3939
Fold [3/5] Epoch [20/100] Initial Loss: 0.1384, Training Loss: 0.0213, Initial Validation Loss: 0.1323, Validation Loss: 0.0365,V Acc: 0.8000, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.5455
Fold [3/5] Epoch [30/100] Initial Loss: 0.1384, Training Loss: 0.0168, Initial Validation Loss: 0.1323, Validation Loss: 0.0335,V Acc: 0.8091, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.5152
Stopping early at Epoch (base 0): 33  Rolling back to Epoch (base 0): 28  Top Validation Acc: 0.922077922077922
24 2 [array([0.4827068 , 0.07189219, 0.06893254, 0.17562097, 0.20084746],
      dtype=float32)]
Fold [4/5] Epoch [0/100] Initial Loss: 0.1360, Training Loss: 0.1360, Initial Validation Loss: 0.1350, Validation Loss: 0.1350,V Acc: 0.4000, Top 70th Acc: 0.4156, Bottom 30th Acc: 0.3636
Fold [4/5] Epoch [10/100] Initial Loss: 0.1360, Training Loss: 0.0278, Initial Validation Loss: 0.1350, Validation Loss: 0.0298,V Acc: 0.9091, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.7576
Fold [4/5] Epoch [20/100] Initial Loss: 0.1360, Training Loss: 0.0182, Initial Validation Loss: 0.1350, Validation Loss: 0.0244,V Acc: 0.8909, Top 70th Acc: 1.0000, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 22  Rolling back to Epoch (base 0): 17  Top Validation Acc: 1.0
Fold [5/5] Epoch [0/100] Initial Loss: 0.1403, Training Loss: 0.1403, Initial Validation Loss: 0.1289, Validation Loss: 0.1289,V Acc: 0.3333, Top 70th Acc: 0.3289, Bottom 30th Acc: 0.3438
Fold [5/5] Epoch [10/100] Initial Loss: 0.1403, Training Loss: 0.0421, Initial Validation Loss: 0.1289, Validation Loss: 0.0448,V Acc: 0.7593, Top 70th Acc: 0.8684, Bottom 30th Acc: 0.5000
Fold [5/5] Epoch [20/100] Initial Loss: 0.1403, Training Loss: 0.0181, Initial Validation Loss: 0.1289, Validation Loss: 0.0309,V Acc: 0.8056, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.4688
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.9342105263157895
Running train_nn.py with seed 25
CUDA:False
Training samples count:  550
Training on 30 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1425, Training Loss: 0.1425, Initial Validation Loss: 0.1365, Validation Loss: 0.1365,V Acc: 0.2342, Top 70th Acc: 0.2308, Bottom 30th Acc: 0.2424
Fold [1/5] Epoch [10/100] Initial Loss: 0.1425, Training Loss: 0.0333, Initial Validation Loss: 0.1365, Validation Loss: 0.0402,V Acc: 0.8288, Top 70th Acc: 0.8974, Bottom 30th Acc: 0.6667
Fold [1/5] Epoch [20/100] Initial Loss: 0.1425, Training Loss: 0.0195, Initial Validation Loss: 0.1365, Validation Loss: 0.0311,V Acc: 0.8378, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.6061
Fold [1/5] Epoch [30/100] Initial Loss: 0.1425, Training Loss: 0.0170, Initial Validation Loss: 0.1365, Validation Loss: 0.0314,V Acc: 0.8288, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 30  Rolling back to Epoch (base 0): 25  Top Validation Acc: 0.9487179487179487
Fold [2/5] Epoch [0/100] Initial Loss: 0.1397, Training Loss: 0.1397, Initial Validation Loss: 0.1374, Validation Loss: 0.1374,V Acc: 0.2523, Top 70th Acc: 0.3590, Bottom 30th Acc: 0.0000
Fold [2/5] Epoch [10/100] Initial Loss: 0.1397, Training Loss: 0.0306, Initial Validation Loss: 0.1374, Validation Loss: 0.0364,V Acc: 0.8468, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.5758
Fold [2/5] Epoch [20/100] Initial Loss: 0.1397, Training Loss: 0.0176, Initial Validation Loss: 0.1374, Validation Loss: 0.0341,V Acc: 0.8198, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.4848
Stopping early at Epoch (base 0): 20  Rolling back to Epoch (base 0): 15  Top Validation Acc: 0.9615384615384616
Fold [3/5] Epoch [0/100] Initial Loss: 0.1387, Training Loss: 0.1387, Initial Validation Loss: 0.1300, Validation Loss: 0.1300,V Acc: 0.3091, Top 70th Acc: 0.3766, Bottom 30th Acc: 0.1515
Fold [3/5] Epoch [10/100] Initial Loss: 0.1387, Training Loss: 0.0379, Initial Validation Loss: 0.1300, Validation Loss: 0.0443,V Acc: 0.7636, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.3939
Fold [3/5] Epoch [20/100] Initial Loss: 0.1387, Training Loss: 0.0213, Initial Validation Loss: 0.1300, Validation Loss: 0.0299,V Acc: 0.8000, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.4545
Stopping early at Epoch (base 0): 28  Rolling back to Epoch (base 0): 23  Top Validation Acc: 0.948051948051948
Fold [3/5] Epoch [20/100] Initial Loss: 0.1401, Training Loss: 0.0044, Initial Validation Loss: 0.1287, Validation Loss: 0.0257,V Acc: 0.8364, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 27  Rolling back to Epoch (base 0): 22  Top Validation Acc: 0.948051948051948
Fold [4/5] Epoch [0/100] Initial Loss: 0.1382, Training Loss: 0.1382, Initial Validation Loss: 0.1354, Validation Loss: 0.1354,V Acc: 0.3000, Top 70th Acc: 0.3506, Bottom 30th Acc: 0.1818
Fold [4/5] Epoch [10/100] Initial Loss: 0.1382, Training Loss: 0.0202, Initial Validation Loss: 0.1354, Validation Loss: 0.0477,V Acc: 0.7909, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.5152
Fold [4/5] Epoch [20/100] Initial Loss: 0.1382, Training Loss: 0.0052, Initial Validation Loss: 0.1354, Validation Loss: 0.0415,V Acc: 0.7818, Top 70th Acc: 0.8961, Bottom 30th Acc: 0.5152
Stopping early at Epoch (base 0): 29  Rolling back to Epoch (base 0): 24  Top Validation Acc: 0.8961038961038961
Fold [5/5] Epoch [0/100] Initial Loss: 0.1364, Training Loss: 0.1364, Initial Validation Loss: 0.1338, Validation Loss: 0.1338,V Acc: 0.3333, Top 70th Acc: 0.4079, Bottom 30th Acc: 0.1562
Fold [5/5] Epoch [10/100] Initial Loss: 0.1364, Training Loss: 0.0145, Initial Validation Loss: 0.1338, Validation Loss: 0.0335,V Acc: 0.8148, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.5000
Fold [5/5] Epoch [20/100] Initial Loss: 0.1364, Training Loss: 0.0047, Initial Validation Loss: 0.1338, Validation Loss: 0.0310,V Acc: 0.8148, Top 70th Acc: 0.9737, Bottom 30th Acc: 0.4375
Stopping early at Epoch (base 0): 21  Rolling back to Epoch (base 0): 16  Top Validation Acc: 0.9736842105263158
20 4 [array([0.16335112, 0.09129529, 0.16453573, 0.16847183, 0.412346  ],
      dtype=float32)]
Running train_nn.py with seed 21
CUDA:False
Training samples count:  550
Training on 163 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1379, Training Loss: 0.1379, Initial Validation Loss: 0.1362, Validation Loss: 0.1362,V Acc: 0.3604, Top 70th Acc: 0.4744, Bottom 30th Acc: 0.0909
Fold [1/5] Epoch [10/100] Initial Loss: 0.1379, Training Loss: 0.0156, Initial Validation Loss: 0.1362, Validation Loss: 0.0297,V Acc: 0.8919, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.7273
Fold [1/5] Epoch [20/100] Initial Loss: 0.1379, Training Loss: 0.0048, Initial Validation Loss: 0.1362, Validation Loss: 0.0264,V Acc: 0.8739, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.9615384615384616
Fold [2/5] Epoch [0/100] Initial Loss: 0.1402, Training Loss: 0.1402, Initial Validation Loss: 0.1334, Validation Loss: 0.1334,V Acc: 0.3604, Top 70th Acc: 0.4103, Bottom 30th Acc: 0.2424
Fold [2/5] Epoch [10/100] Initial Loss: 0.1402, Training Loss: 0.0163, Initial Validation Loss: 0.1334, Validation Loss: 0.0309,V Acc: 0.8288, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.5758
Fold [2/5] Epoch [20/100] Initial Loss: 0.1402, Training Loss: 0.0044, Initial Validation Loss: 0.1334, Validation Loss: 0.0255,V Acc: 0.8198, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.4545
Fold [2/5] Epoch [30/100] Initial Loss: 0.1402, Training Loss: 0.0035, Initial Validation Loss: 0.1334, Validation Loss: 0.0249,V Acc: 0.8559, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 38  Rolling back to Epoch (base 0): 33  Top Validation Acc: 0.9743589743589743
Fold [3/5] Epoch [0/100] Initial Loss: 0.1395, Training Loss: 0.1395, Initial Validation Loss: 0.1343, Validation Loss: 0.1343,V Acc: 0.3455, Top 70th Acc: 0.3636, Bottom 30th Acc: 0.3030
Fold [3/5] Epoch [10/100] Initial Loss: 0.1395, Training Loss: 0.0171, Initial Validation Loss: 0.1343, Validation Loss: 0.0387,V Acc: 0.7909, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.3636
Fold [3/5] Epoch [20/100] Initial Loss: 0.1395, Training Loss: 0.0050, Initial Validation Loss: 0.1343, Validation Loss: 0.0365,V Acc: 0.8000, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.4242
Fold [3/5] Epoch [30/100] Initial Loss: 0.1395, Training Loss: 0.0038, Initial Validation Loss: 0.1343, Validation Loss: 0.0361,V Acc: 0.8091, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.4545
Fold [3/5] Epoch [40/100] Initial Loss: 0.1395, Training Loss: 0.0035, Initial Validation Loss: 0.1343, Validation Loss: 0.0354,V Acc: 0.8000, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.4242
Fold [3/5] Epoch [50/100] Initial Loss: 0.1395, Training Loss: 0.0034, Initial Validation Loss: 0.1343, Validation Loss: 0.0346,V Acc: 0.7909, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.3939
Fold [3/5] Epoch [60/100] Initial Loss: 0.1395, Training Loss: 0.0033, Initial Validation Loss: 0.1343, Validation Loss: 0.0343,V Acc: 0.8000, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.4242
Stopping early at Epoch (base 0): 68  Rolling back to Epoch (base 0): 63  Top Validation Acc: 0.961038961038961
21 2 [array([0.17746803, 0.06294736, 0.05751079, 0.18302962, 0.51904416],
      dtype=float32)]
Fold [4/5] Epoch [0/100] Initial Loss: 0.1395, Training Loss: 0.1395, Initial Validation Loss: 0.1345, Validation Loss: 0.1345,V Acc: 0.2545, Top 70th Acc: 0.3117, Bottom 30th Acc: 0.1212
Fold [4/5] Epoch [10/100] Initial Loss: 0.1395, Training Loss: 0.0172, Initial Validation Loss: 0.1345, Validation Loss: 0.0330,V Acc: 0.8455, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6061
Fold [4/5] Epoch [20/100] Initial Loss: 0.1395, Training Loss: 0.0050, Initial Validation Loss: 0.1345, Validation Loss: 0.0290,V Acc: 0.8364, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.5758
Fold [4/5] Epoch [30/100] Initial Loss: 0.1395, Training Loss: 0.0041, Initial Validation Loss: 0.1345, Validation Loss: 0.0287,V Acc: 0.8455, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 31  Rolling back to Epoch (base 0): 26  Top Validation Acc: 0.948051948051948
Fold [5/5] Epoch [0/100] Initial Loss: 0.1412, Training Loss: 0.1412, Initial Validation Loss: 0.1334, Validation Loss: 0.1334,V Acc: 0.2778, Top 70th Acc: 0.2895, Bottom 30th Acc: 0.2500
Fold [5/5] Epoch [10/100] Initial Loss: 0.1412, Training Loss: 0.0157, Initial Validation Loss: 0.1334, Validation Loss: 0.0349,V Acc: 0.7963, Top 70th Acc: 0.9737, Bottom 30th Acc: 0.3750
Fold [5/5] Epoch [20/100] Initial Loss: 0.1412, Training Loss: 0.0055, Initial Validation Loss: 0.1334, Validation Loss: 0.0301,V Acc: 0.8241, Top 70th Acc: 0.9737, Bottom 30th Acc: 0.4688
Fold [5/5] Epoch [30/100] Initial Loss: 0.1412, Training Loss: 0.0043, Initial Validation Loss: 0.1334, Validation Loss: 0.0291,V Acc: 0.8241, Top 70th Acc: 0.9737, Bottom 30th Acc: 0.4688
Stopping early at Epoch (base 0): 33  Rolling back to Epoch (base 0): 28  Top Validation Acc: 0.9736842105263158
Running train_nn.py with seed 22
CUDA:False
Training samples count:  550
Training on 163 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1387, Training Loss: 0.1387, Initial Validation Loss: 0.1340, Validation Loss: 0.1340,V Acc: 0.2523, Top 70th Acc: 0.3333, Bottom 30th Acc: 0.0606
Fold [1/5] Epoch [10/100] Initial Loss: 0.1387, Training Loss: 0.0294, Initial Validation Loss: 0.1340, Validation Loss: 0.0474,V Acc: 0.7748, Top 70th Acc: 0.8846, Bottom 30th Acc: 0.5152
Fold [1/5] Epoch [20/100] Initial Loss: 0.1387, Training Loss: 0.0051, Initial Validation Loss: 0.1340, Validation Loss: 0.0365,V Acc: 0.8018, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.4545
Fold [1/5] Epoch [30/100] Initial Loss: 0.1387, Training Loss: 0.0036, Initial Validation Loss: 0.1340, Validation Loss: 0.0357,V Acc: 0.8018, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.5152
Stopping early at Epoch (base 0): 32  Rolling back to Epoch (base 0): 27  Top Validation Acc: 0.9358974358974359
Fold [2/5] Epoch [0/100] Initial Loss: 0.1372, Training Loss: 0.1372, Initial Validation Loss: 0.1302, Validation Loss: 0.1302,V Acc: 0.3243, Top 70th Acc: 0.3846, Bottom 30th Acc: 0.1818
Fold [2/5] Epoch [10/100] Initial Loss: 0.1372, Training Loss: 0.0138, Initial Validation Loss: 0.1302, Validation Loss: 0.0272,V Acc: 0.8468, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.5758
Fold [2/5] Epoch [20/100] Initial Loss: 0.1372, Training Loss: 0.0047, Initial Validation Loss: 0.1302, Validation Loss: 0.0231,V Acc: 0.8559, Top 70th Acc: 0.9872, Bottom 30th Acc: 0.5455 21  Rolling back to Epoch (base 0): 16  Top Validation Acc: 0.9487179487179487
Fold [2/5] Epoch [0/100] Initial Loss: 0.1382, Training Loss: 0.1382, Initial Validation Loss: 0.1355, Validation Loss: 0.1355,V Acc: 0.3063, Top 70th Acc: 0.3718, Bottom 30th Acc: 0.1515
Fold [2/5] Epoch [10/100] Initial Loss: 0.1382, Training Loss: 0.0226, Initial Validation Loss: 0.1355, Validation Loss: 0.0333,V Acc: 0.8829, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.7576
Fold [2/5] Epoch [20/100] Initial Loss: 0.1382, Training Loss: 0.0162, Initial Validation Loss: 0.1355, Validation Loss: 0.0342,V Acc: 0.8559, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.9487179487179487
Fold [3/5] Epoch [0/100] Initial Loss: 0.1373, Training Loss: 0.1373, Initial Validation Loss: 0.1290, Validation Loss: 0.1290,V Acc: 0.3909, Top 70th Acc: 0.4416, Bottom 30th Acc: 0.2727
Fold [3/5] Epoch [10/100] Initial Loss: 0.1373, Training Loss: 0.0276, Initial Validation Loss: 0.1290, Validation Loss: 0.0343,V Acc: 0.8727, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 17  Rolling back to Epoch (base 0): 12  Top Validation Acc: 1.0
Fold [4/5] Epoch [0/100] Initial Loss: 0.1303, Training Loss: 0.1303, Initial Validation Loss: 0.1093, Validation Loss: 0.1093,V Acc: 0.4727, Top 70th Acc: 0.6104, Bottom 30th Acc: 0.1515
Fold [4/5] Epoch [10/100] Initial Loss: 0.1303, Training Loss: 0.0246, Initial Validation Loss: 0.1093, Validation Loss: 0.0259,V Acc: 0.8545, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6364
Fold [4/5] Epoch [20/100] Initial Loss: 0.1303, Training Loss: 0.0158, Initial Validation Loss: 0.1093, Validation Loss: 0.0256,V Acc: 0.8636, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 22  Rolling back to Epoch (base 0): 17  Top Validation Acc: 0.935064935064935
Fold [5/5] Epoch [0/100] Initial Loss: 0.1324, Training Loss: 0.1324, Initial Validation Loss: 0.1149, Validation Loss: 0.1149,V Acc: 0.5648, Top 70th Acc: 0.6316, Bottom 30th Acc: 0.4062
Fold [5/5] Epoch [10/100] Initial Loss: 0.1324, Training Loss: 0.0250, Initial Validation Loss: 0.1149, Validation Loss: 0.0290,V Acc: 0.8796, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.7188
Stopping early at Epoch (base 0): 16  Rolling back to Epoch (base 0): 11  Top Validation Acc: 0.9736842105263158
36 4 [array([0.579299  , 0.0409328 , 0.04614677, 0.14785111, 0.1857703 ],
      dtype=float32)]
Running train_nn.py with seed 37
CUDA:False
Training samples count:  550
Training on 21 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1302, Training Loss: 0.1302, Initial Validation Loss: 0.1210, Validation Loss: 0.1210,V Acc: 0.5405, Top 70th Acc: 0.6282, Bottom 30th Acc: 0.3333
Fold [1/5] Epoch [10/100] Initial Loss: 0.1302, Training Loss: 0.0246, Initial Validation Loss: 0.1210, Validation Loss: 0.0279,V Acc: 0.8378, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.5152
Stopping early at Epoch (base 0): 17  Rolling back to Epoch (base 0): 12  Top Validation Acc: 0.9487179487179487
Fold [2/5] Epoch [0/100] Initial Loss: 0.1313, Training Loss: 0.1313, Initial Validation Loss: 0.1253, Validation Loss: 0.1253,V Acc: 0.4505, Top 70th Acc: 0.5769, Bottom 30th Acc: 0.1515
Fold [2/5] Epoch [10/100] Initial Loss: 0.1313, Training Loss: 0.0321, Initial Validation Loss: 0.1253, Validation Loss: 0.0354,V Acc: 0.8739, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.6970
Fold [2/5] Epoch [20/100] Initial Loss: 0.1313, Training Loss: 0.0182, Initial Validation Loss: 0.1253, Validation Loss: 0.0198,V Acc: 0.9009, Top 70th Acc: 1.0000, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.9743589743589743
Fold [3/5] Epoch [0/100] Initial Loss: 0.1400, Training Loss: 0.1400, Initial Validation Loss: 0.1238, Validation Loss: 0.1238,V Acc: 0.4091, Top 70th Acc: 0.5065, Bottom 30th Acc: 0.1818
Fold [3/5] Epoch [10/100] Initial Loss: 0.1400, Training Loss: 0.0258, Initial Validation Loss: 0.1238, Validation Loss: 0.0383,V Acc: 0.7818, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.3939
Fold [3/5] Epoch [20/100] Initial Loss: 0.1400, Training Loss: 0.0177, Initial Validation Loss: 0.1238, Validation Loss: 0.0336,V Acc: 0.8182, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.5152
Stopping early at Epoch (base 0): 28  Rolling back to Epoch (base 0): 23  Top Validation Acc: 0.948051948051948
Fold [4/5] Epoch [0/100] Initial Loss: 0.1208, Training Loss: 0.1208, Initial Validation Loss: 0.1073, Validation Loss: 0.1073,V Acc: 0.4455, Top 70th Acc: 0.5455, Bottom 30th Acc: 0.2121
Fold [4/5] Epoch [10/100] Initial Loss: 0.1208, Training Loss: 0.0217, Initial Validation Loss: 0.1073, Validation Loss: 0.0284,V Acc: 0.8545, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 19  Rolling back to Epoch (base 0): 14  Top Validation Acc: 0.961038961038961
Fold [5/5] Epoch [0/100] Initial Loss: 0.1373, Training Loss: 0.1373, Initial Validation Loss: 0.1181, Validation Loss: 0.1181,V Acc: 0.3981, Top 70th Acc: 0.4211, Bottom 30th Acc: 0.3438
Fold [5/5] Epoch [10/100] Initial Loss: 0.1373, Training Loss: 0.0225, Initial Validation Loss: 0.1181, Validation Loss: 0.0263,V Acc: 0.8796, Top 70th Acc: 0.9737, Bottom 30th Acc: 0.6562
Fold [5/5] Epoch [20/100] Initial Loss: 0.1373, Training Loss: 0.0169, Initial Validation Loss: 0.1181, Validation Loss: 0.0250,V Acc: 0.8704, Top 70th Acc: 0.9737, Bottom 30th Acc: 0.6250
Stopping early at Epoch (base 0): 21  Rolling back to Epoch (base 0): 16  Top Validation Acc: 0.9605263157894737
37 4 [array([0.73704356, 0.02290342, 0.02090059, 0.09258054, 0.12657186],
      dtype=float32)]
Running train_nn.py with seed 38
CUDA:False
Training samples count:  550
Training on 21 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1212, Training Loss: 0.1212, Initial Validation Loss: 0.1105, Validation Loss: 0.1105,V Acc: 0.4685, Top 70th Acc: 0.5897, Bottom 30th Acc: 0.1818
Fold [1/5] Epoch [10/100] Initial Loss: 0.1212, Training Loss: 0.0228, Initial Validation Loss: 0.1105, Validation Loss: 0.0286,V Acc: 0.8739, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 18  Rolling back to Epoch (base 0): 13  Top Validation Acc: 0.9743589743589743
Fold [2/5] Epoch [0/100] Initial Loss: 0.1359, Training Loss: 0.1359, Initial Validation Loss: 0.1223, Validation Loss: 0.1223,V Acc: 0.4595, Top 70th Acc: 0.5000, Bottom 30th Acc: 0.3636
Fold [2/5] Epoch [10/100] Initial Loss: 0.1359, Training Loss: 0.0292, Initial Validation Loss: 0.1223, Validation Loss: 0.0435,V Acc: 0.7838, Top 70th Acc: 0.8846, Bottom 30th Acc: 0.5455
Fold [2/5] Epoch [20/100] Initial Loss: 0.1359, Training Loss: 0.0170, Initial Validation Loss: 0.1223, Validation Loss: 0.0355,V Acc: 0.8288, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.8846153846153846
Fold [3/5] Epoch [0/100] Initial Loss: 0.1376, Training Loss: 0.1376, Initial Validation Loss: 0.1321, Validation Loss: 0.1321,V Acc: 0.3909, Top 70th Acc: 0.4805, Bottom 30th Acc: 0.1818
Fold [3/5] Epoch [10/100] Initial Loss: 0.1376, Training Loss: 0.0315, Initial Validation Loss: 0.1321, Validation Loss: 0.0377,V Acc: 0.8364, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.5758
Fold [3/5] Epoch [20/100] Initial Loss: 0.1376, Training Loss: 0.0176, Initial Validation Loss: 0.1321, Validation Loss: 0.0321,V Acc: 0.8545, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.935064935064935
Fold [4/5] Epoch [0/100] Initial Loss: 0.1346, Training Loss: 0.1346, Initial Validation Loss: 0.1238, Validation Loss: 0.1238,V Acc: 0.4273, Top 70th Acc: 0.4545, Bottom 30th Acc: 0.3636
Fold [4/5] Epoch [10/100] Initial Loss: 0.1346, Training Loss: 0.0329, Initial Validation Loss: 0.1238, Validation Loss: 0.0244,V Acc: 0.9000, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.7879
Fold [4/5] Epoch [20/100] Initial Loss: 0.1346, Training Loss: 0.0188, Initial Validation Loss: 0.1238, Validation Loss: 0.0242,V Acc: 0.8727, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.6667 26  Top Validation Acc: 0.948051948051948
Fold [4/5] Epoch [0/100] Initial Loss: 0.1358, Training Loss: 0.1358, Initial Validation Loss: 0.1346, Validation Loss: 0.1346,V Acc: 0.3636, Top 70th Acc: 0.4286, Bottom 30th Acc: 0.2121
Fold [4/5] Epoch [10/100] Initial Loss: 0.1358, Training Loss: 0.0308, Initial Validation Loss: 0.1346, Validation Loss: 0.0388,V Acc: 0.8455, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.6970
Fold [4/5] Epoch [20/100] Initial Loss: 0.1358, Training Loss: 0.0164, Initial Validation Loss: 0.1346, Validation Loss: 0.0285,V Acc: 0.8636, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.974025974025974
25 3 [array([0.68795055, 0.09341641, 0.07046494, 0.07164793, 0.07652016],
      dtype=float32)]
Fold [5/5] Epoch [0/100] Initial Loss: 0.1375, Training Loss: 0.1375, Initial Validation Loss: 0.1302, Validation Loss: 0.1302,V Acc: 0.3889, Top 70th Acc: 0.4474, Bottom 30th Acc: 0.2500
Fold [5/5] Epoch [10/100] Initial Loss: 0.1375, Training Loss: 0.0322, Initial Validation Loss: 0.1302, Validation Loss: 0.0424,V Acc: 0.8056, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.5000
Fold [5/5] Epoch [20/100] Initial Loss: 0.1375, Training Loss: 0.0152, Initial Validation Loss: 0.1302, Validation Loss: 0.0327,V Acc: 0.8056, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.4375
Stopping early at Epoch (base 0): 27  Rolling back to Epoch (base 0): 22  Top Validation Acc: 0.9605263157894737
Running train_nn.py with seed 26
CUDA:False
Training samples count:  550
Training on 40 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1384, Training Loss: 0.1384, Initial Validation Loss: 0.1359, Validation Loss: 0.1359,V Acc: 0.2973, Top 70th Acc: 0.3077, Bottom 30th Acc: 0.2727
Fold [1/5] Epoch [10/100] Initial Loss: 0.1384, Training Loss: 0.0393, Initial Validation Loss: 0.1359, Validation Loss: 0.0482,V Acc: 0.7387, Top 70th Acc: 0.8974, Bottom 30th Acc: 0.3636
Fold [1/5] Epoch [20/100] Initial Loss: 0.1384, Training Loss: 0.0162, Initial Validation Loss: 0.1359, Validation Loss: 0.0297,V Acc: 0.8559, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.5758
Fold [1/5] Epoch [30/100] Initial Loss: 0.1384, Training Loss: 0.0118, Initial Validation Loss: 0.1359, Validation Loss: 0.0284,V Acc: 0.8739, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.6667
Fold [1/5] Epoch [40/100] Initial Loss: 0.1384, Training Loss: 0.0105, Initial Validation Loss: 0.1359, Validation Loss: 0.0278,V Acc: 0.8739, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 44  Rolling back to Epoch (base 0): 39  Top Validation Acc: 0.9615384615384616
Fold [2/5] Epoch [0/100] Initial Loss: 0.1379, Training Loss: 0.1379, Initial Validation Loss: 0.1317, Validation Loss: 0.1317,V Acc: 0.3874, Top 70th Acc: 0.4487, Bottom 30th Acc: 0.2424
Fold [2/5] Epoch [10/100] Initial Loss: 0.1379, Training Loss: 0.0313, Initial Validation Loss: 0.1317, Validation Loss: 0.0331,V Acc: 0.8739, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.7576
Fold [2/5] Epoch [20/100] Initial Loss: 0.1379, Training Loss: 0.0151, Initial Validation Loss: 0.1317, Validation Loss: 0.0282,V Acc: 0.8829, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.7273
Stopping early at Epoch (base 0): 22  Rolling back to Epoch (base 0): 17  Top Validation Acc: 0.9615384615384616
Fold [3/5] Epoch [0/100] Initial Loss: 0.1406, Training Loss: 0.1406, Initial Validation Loss: 0.1358, Validation Loss: 0.1358,V Acc: 0.2818, Top 70th Acc: 0.2727, Bottom 30th Acc: 0.3030
Fold [3/5] Epoch [10/100] Initial Loss: 0.1406, Training Loss: 0.0304, Initial Validation Loss: 0.1358, Validation Loss: 0.0393,V Acc: 0.8545, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.6970
Fold [3/5] Epoch [20/100] Initial Loss: 0.1406, Training Loss: 0.0155, Initial Validation Loss: 0.1358, Validation Loss: 0.0310,V Acc: 0.8364, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.5455
Fold [3/5] Epoch [30/100] Initial Loss: 0.1406, Training Loss: 0.0130, Initial Validation Loss: 0.1358, Validation Loss: 0.0300,V Acc: 0.8364, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.5152
Stopping early at Epoch (base 0): 31  Rolling back to Epoch (base 0): 26  Top Validation Acc: 0.974025974025974
26 2 [array([0.7230959 , 0.06355381, 0.05911496, 0.05876298, 0.09547246],
      dtype=float32)]
Fold [4/5] Epoch [0/100] Initial Loss: 0.1429, Training Loss: 0.1429, Initial Validation Loss: 0.1332, Validation Loss: 0.1332,V Acc: 0.2727, Top 70th Acc: 0.3117, Bottom 30th Acc: 0.1818
Fold [4/5] Epoch [10/100] Initial Loss: 0.1429, Training Loss: 0.0325, Initial Validation Loss: 0.1332, Validation Loss: 0.0417,V Acc: 0.7636, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.3939
Fold [4/5] Epoch [20/100] Initial Loss: 0.1429, Training Loss: 0.0174, Initial Validation Loss: 0.1332, Validation Loss: 0.0352,V Acc: 0.7909, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.4545
Fold [4/5] Epoch [30/100] Initial Loss: 0.1429, Training Loss: 0.0125, Initial Validation Loss: 0.1332, Validation Loss: 0.0329,V Acc: 0.8000, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.4848
Stopping early at Epoch (base 0): 38  Rolling back to Epoch (base 0): 33  Top Validation Acc: 0.948051948051948
Fold [5/5] Epoch [0/100] Initial Loss: 0.1369, Training Loss: 0.1369, Initial Validation Loss: 0.1326, Validation Loss: 0.1326,V Acc: 0.2778, Top 70th Acc: 0.3026, Bottom 30th Acc: 0.2188
Fold [5/5] Epoch [10/100] Initial Loss: 0.1369, Training Loss: 0.0292, Initial Validation Loss: 0.1326, Validation Loss: 0.0371,V Acc: 0.8519, Top 70th Acc: 0.9079, Bottom 30th Acc: 0.7188
Fold [5/5] Epoch [20/100] Initial Loss: 0.1369, Training Loss: 0.0151, Initial Validation Loss: 0.1326, Validation Loss: 0.0307,V Acc: 0.8426, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.5938
Stopping early at Epoch (base 0): 21  Rolling back to Epoch (base 0): 16  Top Validation Acc: 0.9473684210526315
Running train_nn.py with seed 27
CUDA:False
Training samples count:  550
Training on 40 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1386, Training Loss: 0.1386, Initial Validation Loss: 0.1347, Validation Loss: 0.1347,V Acc: 0.3333, Top 70th Acc: 0.3077, Bottom 30th Acc: 0.3939
Fold [1/5] Epoch [10/100] Initial Loss: 0.1386, Training Loss: 0.0357, Initial Validation Loss: 0.1347, Validation Loss: 0.0459,V Acc: 0.7658, Top 70th Acc: 0.8462, Bottom 30th Acc: 0.5758
Fold [1/5] Epoch [20/100] Initial Loss: 0.1386, Training Loss: 0.0185, Initial Validation Loss: 0.1347, Validation Loss: 0.0379,V Acc: 0.8108, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.5758
Fold [1/5] Epoch [30/100] Initial Loss: 0.1386, Training Loss: 0.0126, Initial Validation Loss: 0.1347, Validation Loss: 0.0331,V Acc: 0.8468, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.6970
Fold [1/5] Epoch [40/100] Initial Loss: 0.1386, Training Loss: 0.0112, Initial Validation Loss: 0.1347, Validation Loss: 0.0317,V Acc: 0.8288, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 44  Rolling back to Epoch (base 0): 39  Top Validation Acc: 0.9230769230769231
Fold [2/5] Epoch [0/100] Initial Loss: 0.1409, Training Loss: 0.1409, Initial Validation Loss: 0.1373, Validation Loss: 0.1373,V Acc: 0.2973, Top 70th Acc: 0.3077, Bottom 30th Acc: 0.2727
Fold [2/5] Epoch [10/100] Initial Loss: 0.1409, Training Loss: 0.0338, Initial Validation Loss: 0.1373, Validation Loss: 0.0397,V Acc: 0.8108, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.4848
Fold [2/5] Epoch [20/100] Initial Loss: 0.1409, Training Loss: 0.0155, Initial Validation Loss: 0.1373, Validation Loss: 0.0258,V Acc: 0.8829, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.6667
Fold [2/5] Epoch [30/100] Initial Loss: 0.1409, Training Loss: 0.0125, Initial Validation Loss: 0.1373, Validation Loss: 0.0249,V Acc: 0.8919, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.7273
Fold [2/5] Epoch [40/100] Initial Loss: 0.1409, Training Loss: 0.0112, Initial Validation Loss: 0.1373, Validation Loss: 0.0242,V Acc: 0.9009, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.7273
Stopping early at Epoch (base 0): 43  Rolling back to Epoch (base 0): 38  Top Validation Acc: 0.9743589743589743
Fold [3/5] Epoch [0/100] Initial Loss: 0.1417, Training Loss: 0.1417, Initial Validation Loss: 0.1336, Validation Loss: 0.1336,V Acc: 0.4000, Top 70th Acc: 0.4156, Bottom 30th Acc: 0.3636
Stopping early at Epoch (base 0): 34  Rolling back to Epoch (base 0): 29  Top Validation Acc: 0.7692307692307693
Fold [3/5] Epoch [0/100] Initial Loss: 0.1376, Training Loss: 0.1376, Initial Validation Loss: 0.1283, Validation Loss: 0.1283,V Acc: 0.4000, Top 70th Acc: 0.4416, Bottom 30th Acc: 0.3030
Fold [3/5] Epoch [10/100] Initial Loss: 0.1376, Training Loss: 0.0780, Initial Validation Loss: 0.1283, Validation Loss: 0.0888,V Acc: 0.5727, Top 70th Acc: 0.6494, Bottom 30th Acc: 0.3939
Fold [3/5] Epoch [20/100] Initial Loss: 0.1376, Training Loss: 0.0763, Initial Validation Loss: 0.1283, Validation Loss: 0.0867,V Acc: 0.5727, Top 70th Acc: 0.6364, Bottom 30th Acc: 0.4242
Fold [3/5] Epoch [30/100] Initial Loss: 0.1376, Training Loss: 0.0754, Initial Validation Loss: 0.1283, Validation Loss: 0.0868,V Acc: 0.5727, Top 70th Acc: 0.6364, Bottom 30th Acc: 0.4242
Stopping early at Epoch (base 0): 36  Rolling back to Epoch (base 0): 31  Top Validation Acc: 0.6493506493506493
24 2 [array([0.12442613, 0.3403066 , 0.14674678, 0.26099002, 0.12753047],
      dtype=float32)]
Fold [4/5] Epoch [0/100] Initial Loss: 0.1355, Training Loss: 0.1355, Initial Validation Loss: 0.1299, Validation Loss: 0.1299,V Acc: 0.3636, Top 70th Acc: 0.3766, Bottom 30th Acc: 0.3333
Fold [4/5] Epoch [10/100] Initial Loss: 0.1355, Training Loss: 0.0821, Initial Validation Loss: 0.1299, Validation Loss: 0.0815,V Acc: 0.6182, Top 70th Acc: 0.7532, Bottom 30th Acc: 0.3030
Fold [4/5] Epoch [20/100] Initial Loss: 0.1355, Training Loss: 0.0790, Initial Validation Loss: 0.1299, Validation Loss: 0.0802,V Acc: 0.6182, Top 70th Acc: 0.8052, Bottom 30th Acc: 0.1818
Fold [4/5] Epoch [30/100] Initial Loss: 0.1355, Training Loss: 0.0781, Initial Validation Loss: 0.1299, Validation Loss: 0.0800,V Acc: 0.6000, Top 70th Acc: 0.8182, Bottom 30th Acc: 0.0909
Stopping early at Epoch (base 0): 30  Rolling back to Epoch (base 0): 25  Top Validation Acc: 0.8181818181818182
Fold [5/5] Epoch [0/100] Initial Loss: 0.1411, Training Loss: 0.1411, Initial Validation Loss: 0.1305, Validation Loss: 0.1305,V Acc: 0.2500, Top 70th Acc: 0.3553, Bottom 30th Acc: 0.0000
Fold [5/5] Epoch [10/100] Initial Loss: 0.1411, Training Loss: 0.0832, Initial Validation Loss: 0.1305, Validation Loss: 0.0734,V Acc: 0.6759, Top 70th Acc: 0.7632, Bottom 30th Acc: 0.4688
Fold [5/5] Epoch [20/100] Initial Loss: 0.1411, Training Loss: 0.0809, Initial Validation Loss: 0.1305, Validation Loss: 0.0696,V Acc: 0.6667, Top 70th Acc: 0.7895, Bottom 30th Acc: 0.3750
Stopping early at Epoch (base 0): 27  Rolling back to Epoch (base 0): 22  Top Validation Acc: 0.7631578947368421
Running train_nn.py with seed 25
CUDA:False
Training samples count:  550
Training on 2 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1333, Training Loss: 0.1333, Initial Validation Loss: 0.1230, Validation Loss: 0.1230,V Acc: 0.4324, Top 70th Acc: 0.5000, Bottom 30th Acc: 0.2727
Fold [1/5] Epoch [10/100] Initial Loss: 0.1333, Training Loss: 0.0780, Initial Validation Loss: 0.1230, Validation Loss: 0.0867,V Acc: 0.5856, Top 70th Acc: 0.6923, Bottom 30th Acc: 0.3333
Fold [1/5] Epoch [20/100] Initial Loss: 0.1333, Training Loss: 0.0762, Initial Validation Loss: 0.1230, Validation Loss: 0.0857,V Acc: 0.5946, Top 70th Acc: 0.6923, Bottom 30th Acc: 0.3636
Fold [1/5] Epoch [30/100] Initial Loss: 0.1333, Training Loss: 0.0752, Initial Validation Loss: 0.1230, Validation Loss: 0.0862,V Acc: 0.5946, Top 70th Acc: 0.6923, Bottom 30th Acc: 0.3636
Fold [1/5] Epoch [40/100] Initial Loss: 0.1333, Training Loss: 0.0748, Initial Validation Loss: 0.1230, Validation Loss: 0.0864,V Acc: 0.6036, Top 70th Acc: 0.6923, Bottom 30th Acc: 0.3939
Stopping early at Epoch (base 0): 44  Rolling back to Epoch (base 0): 39  Top Validation Acc: 0.7051282051282052
Fold [2/5] Epoch [0/100] Initial Loss: 0.1356, Training Loss: 0.1356, Initial Validation Loss: 0.1305, Validation Loss: 0.1305,V Acc: 0.3514, Top 70th Acc: 0.3974, Bottom 30th Acc: 0.2424
Fold [2/5] Epoch [10/100] Initial Loss: 0.1356, Training Loss: 0.0813, Initial Validation Loss: 0.1305, Validation Loss: 0.0794,V Acc: 0.6486, Top 70th Acc: 0.7308, Bottom 30th Acc: 0.4545
Fold [2/5] Epoch [20/100] Initial Loss: 0.1356, Training Loss: 0.0790, Initial Validation Loss: 0.1305, Validation Loss: 0.0793,V Acc: 0.6486, Top 70th Acc: 0.7308, Bottom 30th Acc: 0.4545
Fold [2/5] Epoch [30/100] Initial Loss: 0.1356, Training Loss: 0.0783, Initial Validation Loss: 0.1305, Validation Loss: 0.0772,V Acc: 0.6396, Top 70th Acc: 0.7308, Bottom 30th Acc: 0.4242
Stopping early at Epoch (base 0): 35  Rolling back to Epoch (base 0): 30  Top Validation Acc: 0.717948717948718
Fold [3/5] Epoch [0/100] Initial Loss: 0.1379, Training Loss: 0.1379, Initial Validation Loss: 0.1245, Validation Loss: 0.1245,V Acc: 0.3636, Top 70th Acc: 0.4286, Bottom 30th Acc: 0.2121
Fold [3/5] Epoch [10/100] Initial Loss: 0.1379, Training Loss: 0.0812, Initial Validation Loss: 0.1245, Validation Loss: 0.0813,V Acc: 0.6000, Top 70th Acc: 0.7013, Bottom 30th Acc: 0.3636
Stopping early at Epoch (base 0): 19  Rolling back to Epoch (base 0): 14  Top Validation Acc: 0.7272727272727273
Fold [4/5] Epoch [0/100] Initial Loss: 0.1372, Training Loss: 0.1372, Initial Validation Loss: 0.1292, Validation Loss: 0.1292,V Acc: 0.4455, Top 70th Acc: 0.5974, Bottom 30th Acc: 0.0909
Fold [4/5] Epoch [10/100] Initial Loss: 0.1372, Training Loss: 0.0816, Initial Validation Loss: 0.1292, Validation Loss: 0.0801,V Acc: 0.6364, Top 70th Acc: 0.7403, Bottom 30th Acc: 0.3939
Fold [4/5] Epoch [20/100] Initial Loss: 0.1372, Training Loss: 0.0794, Initial Validation Loss: 0.1292, Validation Loss: 0.0773,V Acc: 0.6545, Top 70th Acc: 0.7403, Bottom 30th Acc: 0.4545
Fold [4/5] Epoch [30/100] Initial Loss: 0.1372, Training Loss: 0.0789, Initial Validation Loss: 0.1292, Validation Loss: 0.0770,V Acc: 0.6727, Top 70th Acc: 0.7403, Bottom 30th Acc: 0.5152
Stopping early at Epoch (base 0): 30  Rolling back to Epoch (base 0): 25  Top Validation Acc: 0.7402597402597403
25 3 [array([0.15944488, 0.31273496, 0.13966638, 0.22923814, 0.15891565],
      dtype=float32)]
Fold [5/5] Epoch [0/100] Initial Loss: 0.1393, Training Loss: 0.1393, Initial Validation Loss: 0.1307, Validation Loss: 0.1307,V Acc: 0.3889, Top 70th Acc: 0.5000, Bottom 30th Acc: 0.1250
Fold [5/5] Epoch [10/100] Initial Loss: 0.1393, Training Loss: 0.0821, Initial Validation Loss: 0.1307, Validation Loss: 0.0787,V Acc: 0.6204, Top 70th Acc: 0.7500, Bottom 30th Acc: 0.3125
Fold [5/5] Epoch [20/100] Initial Loss: 0.1393, Training Loss: 0.0794, Initial Validation Loss: 0.1307, Validation Loss: 0.0759,V Acc: 0.6296, Top 70th Acc: 0.7500, Bottom 30th Acc: 0.3438
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.7236842105263158
Running train_nn.py with seed 26
CUDA:False
Training samples count:  550
Training on 2 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1381, Training Loss: 0.1381, Initial Validation Loss: 0.1330, Validation Loss: 0.1330,V Acc: 0.2973, Top 70th Acc: 0.3590, Bottom 30th Acc: 0.1515
Fold [1/5] Epoch [10/100] Initial Loss: 0.1381, Training Loss: 0.0801, Initial Validation Loss: 0.1330, Validation Loss: 0.0812,V Acc: 0.6216, Top 70th Acc: 0.7564, Bottom 30th Acc: 0.3030
Fold [1/5] Epoch [20/100] Initial Loss: 0.1381, Training Loss: 0.0782, Initial Validation Loss: 0.1330, Validation Loss: 0.0798,V Acc: 0.6306, Top 70th Acc: 0.7436, Bottom 30th Acc: 0.3636
Fold [1/5] Epoch [30/100] Initial Loss: 0.1381, Training Loss: 0.0776, Initial Validation Loss: 0.1330, Validation Loss: 0.0799,V Acc: 0.6216, Top 70th Acc: 0.7436, Bottom 30th Acc: 0.3333
Fold [1/5] Epoch [40/100] Initial Loss: 0.1381, Training Loss: 0.0771, Initial Validation Loss: 0.1330, Validation Loss: 0.0785,V Acc: 0.6486, Top 70th Acc: 0.7436, Bottom 30th Acc: 0.4242
Stopping early at Epoch (base 0): 42  Rolling back to Epoch (base 0): 37  Top Validation Acc: 0.7435897435897436
Fold [2/5] Epoch [0/100] Initial Loss: 0.1335, Training Loss: 0.1335, Initial Validation Loss: 0.1248, Validation Loss: 0.1248,V Acc: 0.5495, Top 70th Acc: 0.5897, Bottom 30th Acc: 0.4545
Fold [2/5] Epoch [10/100] Initial Loss: 0.1335, Training Loss: 0.0811, Initial Validation Loss: 0.1248, Validation Loss: 0.0784,V Acc: 0.6306, Top 70th Acc: 0.7179, Bottom 30th Acc: 0.4242
Fold [1/5] Epoch [10/100] Initial Loss: 0.1390, Training Loss: 0.0357, Initial Validation Loss: 0.1354, Validation Loss: 0.0370,V Acc: 0.8108, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.4242
Fold [1/5] Epoch [20/100] Initial Loss: 0.1390, Training Loss: 0.0235, Initial Validation Loss: 0.1354, Validation Loss: 0.0319,V Acc: 0.8378, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.5152
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.9358974358974359
Fold [2/5] Epoch [0/100] Initial Loss: 0.1372, Training Loss: 0.1372, Initial Validation Loss: 0.1349, Validation Loss: 0.1349,V Acc: 0.2613, Top 70th Acc: 0.3590, Bottom 30th Acc: 0.0303
Fold [2/5] Epoch [10/100] Initial Loss: 0.1372, Training Loss: 0.0407, Initial Validation Loss: 0.1349, Validation Loss: 0.0480,V Acc: 0.7658, Top 70th Acc: 0.8590, Bottom 30th Acc: 0.5455
Fold [2/5] Epoch [20/100] Initial Loss: 0.1372, Training Loss: 0.0242, Initial Validation Loss: 0.1349, Validation Loss: 0.0348,V Acc: 0.8198, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 29  Rolling back to Epoch (base 0): 24  Top Validation Acc: 0.9230769230769231
Fold [3/5] Epoch [0/100] Initial Loss: 0.1372, Training Loss: 0.1372, Initial Validation Loss: 0.1351, Validation Loss: 0.1351,V Acc: 0.3000, Top 70th Acc: 0.3766, Bottom 30th Acc: 0.1212
Fold [3/5] Epoch [10/100] Initial Loss: 0.1372, Training Loss: 0.0390, Initial Validation Loss: 0.1351, Validation Loss: 0.0416,V Acc: 0.8545, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.6970
Fold [3/5] Epoch [20/100] Initial Loss: 0.1372, Training Loss: 0.0243, Initial Validation Loss: 0.1351, Validation Loss: 0.0329,V Acc: 0.8455, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.5758
Fold [3/5] Epoch [30/100] Initial Loss: 0.1372, Training Loss: 0.0215, Initial Validation Loss: 0.1351, Validation Loss: 0.0335,V Acc: 0.8636, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.7273
Stopping early at Epoch (base 0): 30  Rolling back to Epoch (base 0): 25  Top Validation Acc: 0.922077922077922
26 2 [array([0.38057363, 0.14558145, 0.10674016, 0.1917706 , 0.17533407],
      dtype=float32)]
Fold [4/5] Epoch [0/100] Initial Loss: 0.1394, Training Loss: 0.1394, Initial Validation Loss: 0.1301, Validation Loss: 0.1301,V Acc: 0.3273, Top 70th Acc: 0.3766, Bottom 30th Acc: 0.2121
Fold [4/5] Epoch [10/100] Initial Loss: 0.1394, Training Loss: 0.0334, Initial Validation Loss: 0.1301, Validation Loss: 0.0333,V Acc: 0.8182, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.5455
Fold [4/5] Epoch [20/100] Initial Loss: 0.1394, Training Loss: 0.0227, Initial Validation Loss: 0.1301, Validation Loss: 0.0311,V Acc: 0.8273, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 22  Rolling back to Epoch (base 0): 17  Top Validation Acc: 0.948051948051948
Fold [5/5] Epoch [0/100] Initial Loss: 0.1390, Training Loss: 0.1390, Initial Validation Loss: 0.1305, Validation Loss: 0.1305,V Acc: 0.3241, Top 70th Acc: 0.4342, Bottom 30th Acc: 0.0625
Fold [5/5] Epoch [10/100] Initial Loss: 0.1390, Training Loss: 0.0356, Initial Validation Loss: 0.1305, Validation Loss: 0.0378,V Acc: 0.8796, Top 70th Acc: 0.9211, Bottom 30th Acc: 0.7812
Fold [5/5] Epoch [20/100] Initial Loss: 0.1390, Training Loss: 0.0247, Initial Validation Loss: 0.1305, Validation Loss: 0.0281,V Acc: 0.8981, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.7500
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.9473684210526315
Running train_nn.py with seed 27
CUDA:False
Training samples count:  550
Training on 20 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1371, Training Loss: 0.1371, Initial Validation Loss: 0.1328, Validation Loss: 0.1328,V Acc: 0.4595, Top 70th Acc: 0.5385, Bottom 30th Acc: 0.2727
Fold [1/5] Epoch [10/100] Initial Loss: 0.1371, Training Loss: 0.0327, Initial Validation Loss: 0.1328, Validation Loss: 0.0329,V Acc: 0.8378, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.5455
Fold [1/5] Epoch [20/100] Initial Loss: 0.1371, Training Loss: 0.0225, Initial Validation Loss: 0.1328, Validation Loss: 0.0303,V Acc: 0.8378, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 22  Rolling back to Epoch (base 0): 17  Top Validation Acc: 0.9358974358974359
Fold [2/5] Epoch [0/100] Initial Loss: 0.1392, Training Loss: 0.1392, Initial Validation Loss: 0.1369, Validation Loss: 0.1369,V Acc: 0.2523, Top 70th Acc: 0.3462, Bottom 30th Acc: 0.0303
Fold [2/5] Epoch [10/100] Initial Loss: 0.1392, Training Loss: 0.0320, Initial Validation Loss: 0.1369, Validation Loss: 0.0353,V Acc: 0.8649, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.6061
Fold [2/5] Epoch [20/100] Initial Loss: 0.1392, Training Loss: 0.0228, Initial Validation Loss: 0.1369, Validation Loss: 0.0294,V Acc: 0.8559, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.9743589743589743
Fold [3/5] Epoch [0/100] Initial Loss: 0.1390, Training Loss: 0.1390, Initial Validation Loss: 0.1322, Validation Loss: 0.1322,V Acc: 0.2909, Top 70th Acc: 0.2727, Bottom 30th Acc: 0.3333
Fold [3/5] Epoch [10/100] Initial Loss: 0.1390, Training Loss: 0.0289, Initial Validation Loss: 0.1322, Validation Loss: 0.0411,V Acc: 0.8091, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.5758
Fold [3/5] Epoch [20/100] Initial Loss: 0.1390, Training Loss: 0.0213, Initial Validation Loss: 0.1322, Validation Loss: 0.0377,V Acc: 0.8000, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.935064935064935
Fold [4/5] Epoch [0/100] Initial Loss: 0.1384, Training Loss: 0.1384, Initial Validation Loss: 0.1359, Validation Loss: 0.1359,V Acc: 0.3182, Top 70th Acc: 0.4156, Bottom 30th Acc: 0.0909
Fold [4/5] Epoch [10/100] Initial Loss: 0.1384, Training Loss: 0.0461, Initial Validation Loss: 0.1359, Validation Loss: 0.0456,V Acc: 0.8000, Top 70th Acc: 0.8961, Bottom 30th Acc: 0.5758
Fold [4/5] Epoch [20/100] Initial Loss: 0.1384, Training Loss: 0.0257, Initial Validation Loss: 0.1359, Validation Loss: 0.0289,V Acc: 0.8818, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 29  Rolling back to Epoch (base 0): 24  Top Validation Acc: 0.961038961038961
Fold [5/5] Epoch [0/100] Initial Loss: 0.1377, Training Loss: 0.1377, Initial Validation Loss: 0.1329, Validation Loss: 0.1329,V Acc: 0.3981, Top 70th Acc: 0.5000, Bottom 30th Acc: 0.1562
Fold [5/5] Epoch [10/100] Initial Loss: 0.1377, Training Loss: 0.0320, Initial Validation Loss: 0.1329, Validation Loss: 0.0368,V Acc: 0.8241, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.5625
Fold [5/5] Epoch [20/100] Initial Loss: 0.1377, Training Loss: 0.0225, Initial Validation Loss: 0.1329, Validation Loss: 0.0341,V Acc: 0.8333, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.5938
Fold [5/5] Epoch [30/100] Initial Loss: 0.1377, Training Loss: 0.0202, Initial Validation Loss: 0.1329, Validation Loss: 0.0331,V Acc: 0.8333, Top 70th Acc: 0.9211, Bottom 30th Acc: 0.6250
Stopping early at Epoch (base 0): 36  Rolling back to Epoch (base 0): 31  Top Validation Acc: 0.9342105263157895
27 4 [array([0.3479772 , 0.1447286 , 0.13852091, 0.19382897, 0.17494434],
      dtype=float32)]
Running train_nn.py with seed 28
CUDA:False
Training samples count:  550
Training on 20 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1395, Training Loss: 0.1395, Initial Validation Loss: 0.1397, Validation Loss: 0.1397,V Acc: 0.2703, Top 70th Acc: 0.3205, Bottom 30th Acc: 0.1515
Fold [1/5] Epoch [10/100] Initial Loss: 0.1395, Training Loss: 0.0378, Initial Validation Loss: 0.1397, Validation Loss: 0.0475,V Acc: 0.8198, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.5758
Fold [1/5] Epoch [20/100] Initial Loss: 0.1395, Training Loss: 0.0234, Initial Validation Loss: 0.1397, Validation Loss: 0.0375,V Acc: 0.8378, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.5758
Fold [1/5] Epoch [30/100] Initial Loss: 0.1395, Training Loss: 0.0204, Initial Validation Loss: 0.1397, Validation Loss: 0.0367,V Acc: 0.8288, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.5455
Fold [1/5] Epoch [40/100] Initial Loss: 0.1395, Training Loss: 0.0190, Initial Validation Loss: 0.1397, Validation Loss: 0.0363,V Acc: 0.8288, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.5455
Fold [4/5] Epoch [0/100] Initial Loss: 0.1373, Training Loss: 0.1373, Initial Validation Loss: 0.1367, Validation Loss: 0.1367,V Acc: 0.3182, Top 70th Acc: 0.3636, Bottom 30th Acc: 0.2121
Fold [4/5] Epoch [10/100] Initial Loss: 0.1373, Training Loss: 0.0354, Initial Validation Loss: 0.1367, Validation Loss: 0.0376,V Acc: 0.8545, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.7273
Fold [4/5] Epoch [20/100] Initial Loss: 0.1373, Training Loss: 0.0196, Initial Validation Loss: 0.1367, Validation Loss: 0.0268,V Acc: 0.8636, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 29  Rolling back to Epoch (base 0): 24  Top Validation Acc: 0.961038961038961
25 3 [array([0.747857  , 0.04372613, 0.04905437, 0.10052329, 0.05883916],
      dtype=float32)]
Fold [5/5] Epoch [0/100] Initial Loss: 0.1395, Training Loss: 0.1395, Initial Validation Loss: 0.1302, Validation Loss: 0.1302,V Acc: 0.3519, Top 70th Acc: 0.4079, Bottom 30th Acc: 0.2188
Fold [5/5] Epoch [10/100] Initial Loss: 0.1395, Training Loss: 0.0240, Initial Validation Loss: 0.1302, Validation Loss: 0.0339,V Acc: 0.8056, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.4375
Fold [5/5] Epoch [20/100] Initial Loss: 0.1395, Training Loss: 0.0160, Initial Validation Loss: 0.1302, Validation Loss: 0.0332,V Acc: 0.8241, Top 70th Acc: 0.9211, Bottom 30th Acc: 0.5938
Stopping early at Epoch (base 0): 22  Rolling back to Epoch (base 0): 17  Top Validation Acc: 0.9605263157894737
Running train_nn.py with seed 26
CUDA:False
Training samples count:  550
Training on 30 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1418, Training Loss: 0.1418, Initial Validation Loss: 0.1375, Validation Loss: 0.1375,V Acc: 0.2793, Top 70th Acc: 0.2949, Bottom 30th Acc: 0.2424
Fold [1/5] Epoch [10/100] Initial Loss: 0.1418, Training Loss: 0.0366, Initial Validation Loss: 0.1375, Validation Loss: 0.0433,V Acc: 0.8198, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.6061
Fold [1/5] Epoch [20/100] Initial Loss: 0.1418, Training Loss: 0.0163, Initial Validation Loss: 0.1375, Validation Loss: 0.0327,V Acc: 0.8468, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.9487179487179487
Fold [2/5] Epoch [0/100] Initial Loss: 0.1388, Training Loss: 0.1388, Initial Validation Loss: 0.1366, Validation Loss: 0.1366,V Acc: 0.2523, Top 70th Acc: 0.2949, Bottom 30th Acc: 0.1515
Fold [2/5] Epoch [10/100] Initial Loss: 0.1388, Training Loss: 0.0288, Initial Validation Loss: 0.1366, Validation Loss: 0.0324,V Acc: 0.8649, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.6970
Fold [2/5] Epoch [20/100] Initial Loss: 0.1388, Training Loss: 0.0178, Initial Validation Loss: 0.1366, Validation Loss: 0.0275,V Acc: 0.8739, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 22  Rolling back to Epoch (base 0): 17  Top Validation Acc: 0.9487179487179487
Fold [3/5] Epoch [0/100] Initial Loss: 0.1374, Training Loss: 0.1374, Initial Validation Loss: 0.1349, Validation Loss: 0.1349,V Acc: 0.3364, Top 70th Acc: 0.3506, Bottom 30th Acc: 0.3030
Fold [3/5] Epoch [10/100] Initial Loss: 0.1374, Training Loss: 0.0412, Initial Validation Loss: 0.1349, Validation Loss: 0.0433,V Acc: 0.7818, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.4848
Fold [3/5] Epoch [20/100] Initial Loss: 0.1374, Training Loss: 0.0191, Initial Validation Loss: 0.1349, Validation Loss: 0.0275,V Acc: 0.8909, Top 70th Acc: 0.9870, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.987012987012987
26 2 [array([0.63946205, 0.12441368, 0.06381109, 0.06396109, 0.10835204],
      dtype=float32)]
Fold [4/5] Epoch [0/100] Initial Loss: 0.1388, Training Loss: 0.1388, Initial Validation Loss: 0.1297, Validation Loss: 0.1297,V Acc: 0.3727, Top 70th Acc: 0.4156, Bottom 30th Acc: 0.2727
Fold [4/5] Epoch [10/100] Initial Loss: 0.1388, Training Loss: 0.0265, Initial Validation Loss: 0.1297, Validation Loss: 0.0312,V Acc: 0.8364, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.6061
Fold [4/5] Epoch [20/100] Initial Loss: 0.1388, Training Loss: 0.0174, Initial Validation Loss: 0.1297, Validation Loss: 0.0297,V Acc: 0.8182, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.935064935064935
Fold [5/5] Epoch [0/100] Initial Loss: 0.1387, Training Loss: 0.1387, Initial Validation Loss: 0.1322, Validation Loss: 0.1322,V Acc: 0.2870, Top 70th Acc: 0.3553, Bottom 30th Acc: 0.1250
Fold [5/5] Epoch [10/100] Initial Loss: 0.1387, Training Loss: 0.0308, Initial Validation Loss: 0.1322, Validation Loss: 0.0368,V Acc: 0.8426, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.5938
Fold [5/5] Epoch [20/100] Initial Loss: 0.1387, Training Loss: 0.0183, Initial Validation Loss: 0.1322, Validation Loss: 0.0292,V Acc: 0.8519, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.5938
Stopping early at Epoch (base 0): 22  Rolling back to Epoch (base 0): 17  Top Validation Acc: 0.9605263157894737
Running train_nn.py with seed 27
CUDA:False
Training samples count:  550
Training on 30 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1367, Training Loss: 0.1367, Initial Validation Loss: 0.1309, Validation Loss: 0.1309,V Acc: 0.4595, Top 70th Acc: 0.5641, Bottom 30th Acc: 0.2121
Fold [1/5] Epoch [10/100] Initial Loss: 0.1367, Training Loss: 0.0300, Initial Validation Loss: 0.1309, Validation Loss: 0.0384,V Acc: 0.8288, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 19  Rolling back to Epoch (base 0): 14  Top Validation Acc: 0.9230769230769231
Fold [2/5] Epoch [0/100] Initial Loss: 0.1325, Training Loss: 0.1325, Initial Validation Loss: 0.1286, Validation Loss: 0.1286,V Acc: 0.4324, Top 70th Acc: 0.4744, Bottom 30th Acc: 0.3333
Fold [2/5] Epoch [10/100] Initial Loss: 0.1325, Training Loss: 0.0278, Initial Validation Loss: 0.1286, Validation Loss: 0.0340,V Acc: 0.8649, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.6364
Fold [2/5] Epoch [20/100] Initial Loss: 0.1325, Training Loss: 0.0183, Initial Validation Loss: 0.1286, Validation Loss: 0.0280,V Acc: 0.8829, Top 70th Acc: 0.9872, Bottom 30th Acc: 0.6364
Fold [2/5] Epoch [30/100] Initial Loss: 0.1325, Training Loss: 0.0153, Initial Validation Loss: 0.1286, Validation Loss: 0.0279,V Acc: 0.8559, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 30  Rolling back to Epoch (base 0): 25  Top Validation Acc: 0.9743589743589743
Fold [3/5] Epoch [0/100] Initial Loss: 0.1401, Training Loss: 0.1401, Initial Validation Loss: 0.1337, Validation Loss: 0.1337,V Acc: 0.2364, Top 70th Acc: 0.2208, Bottom 30th Acc: 0.2727
Fold [3/5] Epoch [10/100] Initial Loss: 0.1401, Training Loss: 0.0372, Initial Validation Loss: 0.1337, Validation Loss: 0.0526,V Acc: 0.7455, Top 70th Acc: 0.8442, Bottom 30th Acc: 0.5152
Stopping early at Epoch (base 0): 17  Rolling back to Epoch (base 0): 12  Top Validation Acc: 0.8311688311688312
Fold [4/5] Epoch [0/100] Initial Loss: 0.1390, Training Loss: 0.1390, Initial Validation Loss: 0.1332, Validation Loss: 0.1332,V Acc: 0.3000, Top 70th Acc: 0.3117, Bottom 30th Acc: 0.2727
Fold [4/5] Epoch [10/100] Initial Loss: 0.1390, Training Loss: 0.0356, Initial Validation Loss: 0.1332, Validation Loss: 0.0376,V Acc: 0.8455, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.5455
Fold [4/5] Epoch [20/100] Initial Loss: 0.1390, Training Loss: 0.0181, Initial Validation Loss: 0.1332, Validation Loss: 0.0264,V Acc: 0.8545, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.974025974025974
Fold [5/5] Epoch [0/100] Initial Loss: 0.1398, Training Loss: 0.1398, Initial Validation Loss: 0.1353, Validation Loss: 0.1353,V Acc: 0.2500, Top 70th Acc: 0.2632, Bottom 30th Acc: 0.2188
Fold [5/5] Epoch [10/100] Initial Loss: 0.1398, Training Loss: 0.0392, Initial Validation Loss: 0.1353, Validation Loss: 0.0444,V Acc: 0.7500, Top 70th Acc: 0.8947, Bottom 30th Acc: 0.4062
Fold [5/5] Epoch [20/100] Initial Loss: 0.1398, Training Loss: 0.0174, Initial Validation Loss: 0.1353, Validation Loss: 0.0359,V Acc: 0.7870, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.4375
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.974025974025974
Fold [5/5] Epoch [0/100] Initial Loss: 0.1338, Training Loss: 0.1338, Initial Validation Loss: 0.1162, Validation Loss: 0.1162,V Acc: 0.4722, Top 70th Acc: 0.4737, Bottom 30th Acc: 0.4688
Fold [5/5] Epoch [10/100] Initial Loss: 0.1338, Training Loss: 0.0225, Initial Validation Loss: 0.1162, Validation Loss: 0.0242,V Acc: 0.8889, Top 70th Acc: 0.9737, Bottom 30th Acc: 0.6875
Stopping early at Epoch (base 0): 15  Rolling back to Epoch (base 0): 10  Top Validation Acc: 0.9605263157894737
38 4 [array([0.61376566, 0.03662661, 0.05754473, 0.10753389, 0.18452923],
      dtype=float32)]
Running train_nn.py with seed 39
CUDA:False
Training samples count:  550
Training on 21 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1272, Training Loss: 0.1272, Initial Validation Loss: 0.1109, Validation Loss: 0.1109,V Acc: 0.4955, Top 70th Acc: 0.6026, Bottom 30th Acc: 0.2424
Fold [1/5] Epoch [10/100] Initial Loss: 0.1272, Training Loss: 0.0229, Initial Validation Loss: 0.1109, Validation Loss: 0.0311,V Acc: 0.8468, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.6061
Fold [1/5] Epoch [20/100] Initial Loss: 0.1272, Training Loss: 0.0165, Initial Validation Loss: 0.1109, Validation Loss: 0.0262,V Acc: 0.8649, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 22  Rolling back to Epoch (base 0): 17  Top Validation Acc: 0.9615384615384616
Fold [2/5] Epoch [0/100] Initial Loss: 0.1377, Training Loss: 0.1377, Initial Validation Loss: 0.1297, Validation Loss: 0.1297,V Acc: 0.4505, Top 70th Acc: 0.4487, Bottom 30th Acc: 0.4545
Fold [2/5] Epoch [10/100] Initial Loss: 0.1377, Training Loss: 0.0271, Initial Validation Loss: 0.1297, Validation Loss: 0.0382,V Acc: 0.8198, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.6061
Fold [2/5] Epoch [20/100] Initial Loss: 0.1377, Training Loss: 0.0171, Initial Validation Loss: 0.1297, Validation Loss: 0.0320,V Acc: 0.8559, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.9358974358974359
39 1 [array([0.8189603 , 0.02378943, 0.03011107, 0.05953988, 0.06759929],
      dtype=float32)]
Fold [3/5] Epoch [0/100] Initial Loss: 0.1333, Training Loss: 0.1333, Initial Validation Loss: 0.1152, Validation Loss: 0.1152,V Acc: 0.4273, Top 70th Acc: 0.5584, Bottom 30th Acc: 0.1212
Fold [3/5] Epoch [10/100] Initial Loss: 0.1333, Training Loss: 0.0228, Initial Validation Loss: 0.1152, Validation Loss: 0.0294,V Acc: 0.8818, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.7576
Fold [3/5] Epoch [20/100] Initial Loss: 0.1333, Training Loss: 0.0178, Initial Validation Loss: 0.1152, Validation Loss: 0.0289,V Acc: 0.8273, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.935064935064935
Fold [4/5] Epoch [0/100] Initial Loss: 0.1303, Training Loss: 0.1303, Initial Validation Loss: 0.1212, Validation Loss: 0.1212,V Acc: 0.4182, Top 70th Acc: 0.4935, Bottom 30th Acc: 0.2424
Fold [4/5] Epoch [10/100] Initial Loss: 0.1303, Training Loss: 0.0244, Initial Validation Loss: 0.1212, Validation Loss: 0.0225,V Acc: 0.9182, Top 70th Acc: 1.0000, Bottom 30th Acc: 0.7273
Stopping early at Epoch (base 0): 19  Rolling back to Epoch (base 0): 14  Top Validation Acc: 1.0
Fold [5/5] Epoch [0/100] Initial Loss: 0.1344, Training Loss: 0.1344, Initial Validation Loss: 0.1141, Validation Loss: 0.1141,V Acc: 0.5556, Top 70th Acc: 0.6184, Bottom 30th Acc: 0.4062
Fold [5/5] Epoch [10/100] Initial Loss: 0.1344, Training Loss: 0.0248, Initial Validation Loss: 0.1141, Validation Loss: 0.0267,V Acc: 0.8426, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.5625
Fold [5/5] Epoch [20/100] Initial Loss: 0.1344, Training Loss: 0.0184, Initial Validation Loss: 0.1141, Validation Loss: 0.0331,V Acc: 0.8333, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.5312
Stopping early at Epoch (base 0): 20  Rolling back to Epoch (base 0): 15  Top Validation Acc: 0.9605263157894737
Running train_nn.py with seed 40
CUDA:False
Training samples count:  550
Training on 21 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1337, Training Loss: 0.1337, Initial Validation Loss: 0.1314, Validation Loss: 0.1314,V Acc: 0.3874, Top 70th Acc: 0.4744, Bottom 30th Acc: 0.1818
Fold [1/5] Epoch [10/100] Initial Loss: 0.1337, Training Loss: 0.0275, Initial Validation Loss: 0.1314, Validation Loss: 0.0306,V Acc: 0.8739, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.6364
Fold [1/5] Epoch [20/100] Initial Loss: 0.1337, Training Loss: 0.0191, Initial Validation Loss: 0.1314, Validation Loss: 0.0250,V Acc: 0.8739, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.6364
Fold [1/5] Epoch [30/100] Initial Loss: 0.1337, Training Loss: 0.0155, Initial Validation Loss: 0.1314, Validation Loss: 0.0279,V Acc: 0.9099, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.7879
Stopping early at Epoch (base 0): 30  Rolling back to Epoch (base 0): 25  Top Validation Acc: 0.9615384615384616
Fold [2/5] Epoch [0/100] Initial Loss: 0.1390, Training Loss: 0.1390, Initial Validation Loss: 0.1242, Validation Loss: 0.1242,V Acc: 0.4865, Top 70th Acc: 0.6026, Bottom 30th Acc: 0.2121
Fold [2/5] Epoch [10/100] Initial Loss: 0.1390, Training Loss: 0.0271, Initial Validation Loss: 0.1242, Validation Loss: 0.0252,V Acc: 0.8919, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.7273
Fold [2/5] Epoch [20/100] Initial Loss: 0.1390, Training Loss: 0.0197, Initial Validation Loss: 0.1242, Validation Loss: 0.0208,V Acc: 0.9189, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.8182
Stopping early at Epoch (base 0): 21  Rolling back to Epoch (base 0): 16  Top Validation Acc: 0.9615384615384616
40 1 [array([0.76237404, 0.03880029, 0.03674697, 0.0933196 , 0.06875908],
      dtype=float32)]
Fold [3/5] Epoch [0/100] Initial Loss: 0.1322, Training Loss: 0.1322, Initial Validation Loss: 0.1245, Validation Loss: 0.1245,V Acc: 0.4636, Top 70th Acc: 0.5065, Bottom 30th Acc: 0.3636
Fold [3/5] Epoch [10/100] Initial Loss: 0.1322, Training Loss: 0.0250, Initial Validation Loss: 0.1245, Validation Loss: 0.0360,V Acc: 0.8727, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.7273
Fold [3/5] Epoch [20/100] Initial Loss: 0.1322, Training Loss: 0.0165, Initial Validation Loss: 0.1245, Validation Loss: 0.0300,V Acc: 0.8545, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 22  Rolling back to Epoch (base 0): 17  Top Validation Acc: 0.974025974025974
Fold [4/5] Epoch [0/100] Initial Loss: 0.1320, Training Loss: 0.1320, Initial Validation Loss: 0.1203, Validation Loss: 0.1203,V Acc: 0.4818, Top 70th Acc: 0.5195, Bottom 30th Acc: 0.3939
Fold [4/5] Epoch [10/100] Initial Loss: 0.1320, Training Loss: 0.0284, Initial Validation Loss: 0.1203, Validation Loss: 0.0366,V Acc: 0.8182, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.5152
Fold [4/5] Epoch [20/100] Initial Loss: 0.1320, Training Loss: 0.0186, Initial Validation Loss: 0.1203, Validation Loss: 0.0285,V Acc: 0.8727, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 21  Rolling back to Epoch (base 0): 16  Top Validation Acc: 0.948051948051948
Fold [5/5] Epoch [0/100] Initial Loss: 0.1352, Training Loss: 0.1352, Initial Validation Loss: 0.1206, Validation Loss: 0.1206,V Acc: 0.5370, Top 70th Acc: 0.6053, Bottom 30th Acc: 0.3750
Fold [5/5] Epoch [10/100] Initial Loss: 0.1352, Training Loss: 0.0210, Initial Validation Loss: 0.1206, Validation Loss: 0.0279,V Acc: 0.8426, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.5938
Stopping early at Epoch (base 0): 19  Rolling back to Epoch (base 0): 14  Top Validation Acc: 0.9342105263157895
Running train_nn.py with seed 41
CUDA:False
Training samples count:  550
Training on 21 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1333, Training Loss: 0.1333, Initial Validation Loss: 0.1235, Validation Loss: 0.1235,V Acc: 0.4414, Top 70th Acc: 0.5641, Bottom 30th Acc: 0.1515
Fold [1/5] Epoch [10/100] Initial Loss: 0.1333, Training Loss: 0.0205, Initial Validation Loss: 0.1235, Validation Loss: 0.0269,V Acc: 0.8829, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 14  Rolling back to Epoch (base 0):
Fold [2/5] Epoch [30/100] Initial Loss: 0.1372, Training Loss: 0.0039, Initial Validation Loss: 0.1302, Validation Loss: 0.0218,V Acc: 0.8559, Top 70th Acc: 0.9872, Bottom 30th Acc: 0.5455
Fold [2/5] Epoch [40/100] Initial Loss: 0.1372, Training Loss: 0.0037, Initial Validation Loss: 0.1302, Validation Loss: 0.0213,V Acc: 0.8649, Top 70th Acc: 1.0000, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 44  Rolling back to Epoch (base 0): 39  Top Validation Acc: 1.0
Fold [3/5] Epoch [0/100] Initial Loss: 0.1366, Training Loss: 0.1366, Initial Validation Loss: 0.1331, Validation Loss: 0.1331,V Acc: 0.2727, Top 70th Acc: 0.3636, Bottom 30th Acc: 0.0606
Fold [3/5] Epoch [10/100] Initial Loss: 0.1366, Training Loss: 0.0152, Initial Validation Loss: 0.1331, Validation Loss: 0.0342,V Acc: 0.8727, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6970
Fold [3/5] Epoch [20/100] Initial Loss: 0.1366, Training Loss: 0.0047, Initial Validation Loss: 0.1331, Validation Loss: 0.0295,V Acc: 0.9000, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.7879
Stopping early at Epoch (base 0): 22  Rolling back to Epoch (base 0): 17  Top Validation Acc: 0.948051948051948
Fold [4/5] Epoch [0/100] Initial Loss: 0.1373, Training Loss: 0.1373, Initial Validation Loss: 0.1330, Validation Loss: 0.1330,V Acc: 0.4364, Top 70th Acc: 0.4675, Bottom 30th Acc: 0.3636
Fold [4/5] Epoch [10/100] Initial Loss: 0.1373, Training Loss: 0.0152, Initial Validation Loss: 0.1330, Validation Loss: 0.0427,V Acc: 0.8091, Top 70th Acc: 0.8961, Bottom 30th Acc: 0.6061
Fold [4/5] Epoch [20/100] Initial Loss: 0.1373, Training Loss: 0.0056, Initial Validation Loss: 0.1330, Validation Loss: 0.0352,V Acc: 0.8273, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.5758
Fold [4/5] Epoch [30/100] Initial Loss: 0.1373, Training Loss: 0.0041, Initial Validation Loss: 0.1330, Validation Loss: 0.0336,V Acc: 0.8545, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.6667
Fold [4/5] Epoch [40/100] Initial Loss: 0.1373, Training Loss: 0.0038, Initial Validation Loss: 0.1330, Validation Loss: 0.0327,V Acc: 0.8636, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.7273
Stopping early at Epoch (base 0): 44  Rolling back to Epoch (base 0): 39  Top Validation Acc: 0.935064935064935
Fold [5/5] Epoch [0/100] Initial Loss: 0.1377, Training Loss: 0.1377, Initial Validation Loss: 0.1348, Validation Loss: 0.1348,V Acc: 0.3519, Top 70th Acc: 0.4474, Bottom 30th Acc: 0.1250
Fold [5/5] Epoch [10/100] Initial Loss: 0.1377, Training Loss: 0.0236, Initial Validation Loss: 0.1348, Validation Loss: 0.0418,V Acc: 0.8056, Top 70th Acc: 0.9211, Bottom 30th Acc: 0.5312
Fold [5/5] Epoch [20/100] Initial Loss: 0.1377, Training Loss: 0.0061, Initial Validation Loss: 0.1348, Validation Loss: 0.0302,V Acc: 0.8796, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.7188
Fold [5/5] Epoch [30/100] Initial Loss: 0.1377, Training Loss: 0.0042, Initial Validation Loss: 0.1348, Validation Loss: 0.0278,V Acc: 0.8796, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.7188
Fold [5/5] Epoch [40/100] Initial Loss: 0.1377, Training Loss: 0.0038, Initial Validation Loss: 0.1348, Validation Loss: 0.0276,V Acc: 0.8796, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.7188
Stopping early at Epoch (base 0): 43  Rolling back to Epoch (base 0): 38  Top Validation Acc: 0.9473684210526315
22 4 [array([0.21967761, 0.03679736, 0.03071963, 0.29143763, 0.42136776],
      dtype=float32)]
Running train_nn.py with seed 23
CUDA:False
Training samples count:  550
Training on 163 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1390, Training Loss: 0.1390, Initial Validation Loss: 0.1349, Validation Loss: 0.1349,V Acc: 0.3784, Top 70th Acc: 0.4103, Bottom 30th Acc: 0.3030
Fold [1/5] Epoch [10/100] Initial Loss: 0.1390, Training Loss: 0.0114, Initial Validation Loss: 0.1349, Validation Loss: 0.0336,V Acc: 0.8378, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.6061
Fold [1/5] Epoch [20/100] Initial Loss: 0.1390, Training Loss: 0.0045, Initial Validation Loss: 0.1349, Validation Loss: 0.0306,V Acc: 0.8288, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.5758
Fold [1/5] Epoch [30/100] Initial Loss: 0.1390, Training Loss: 0.0039, Initial Validation Loss: 0.1349, Validation Loss: 0.0300,V Acc: 0.8378, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 34  Rolling back to Epoch (base 0): 29  Top Validation Acc: 0.9487179487179487
Fold [2/5] Epoch [0/100] Initial Loss: 0.1400, Training Loss: 0.1400, Initial Validation Loss: 0.1350, Validation Loss: 0.1350,V Acc: 0.3604, Top 70th Acc: 0.4359, Bottom 30th Acc: 0.1818
Fold [2/5] Epoch [10/100] Initial Loss: 0.1400, Training Loss: 0.0226, Initial Validation Loss: 0.1350, Validation Loss: 0.0395,V Acc: 0.8468, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.6061
Fold [2/5] Epoch [20/100] Initial Loss: 0.1400, Training Loss: 0.0047, Initial Validation Loss: 0.1350, Validation Loss: 0.0274,V Acc: 0.8739, Top 70th Acc: 0.9872, Bottom 30th Acc: 0.6061
Fold [2/5] Epoch [30/100] Initial Loss: 0.1400, Training Loss: 0.0035, Initial Validation Loss: 0.1350, Validation Loss: 0.0269,V Acc: 0.8739, Top 70th Acc: 0.9872, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 35  Rolling back to Epoch (base 0): 30  Top Validation Acc: 0.9871794871794872
Fold [3/5] Epoch [0/100] Initial Loss: 0.1357, Training Loss: 0.1357, Initial Validation Loss: 0.1279, Validation Loss: 0.1279,V Acc: 0.4545, Top 70th Acc: 0.5455, Bottom 30th Acc: 0.2424
Fold [3/5] Epoch [10/100] Initial Loss: 0.1357, Training Loss: 0.0144, Initial Validation Loss: 0.1279, Validation Loss: 0.0371,V Acc: 0.7909, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.4242
Fold [3/5] Epoch [20/100] Initial Loss: 0.1357, Training Loss: 0.0046, Initial Validation Loss: 0.1279, Validation Loss: 0.0358,V Acc: 0.8182, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.935064935064935
23 2 [array([0.1722842 , 0.07721722, 0.03470843, 0.20917475, 0.50661534],
      dtype=float32)]
Fold [4/5] Epoch [0/100] Initial Loss: 0.1412, Training Loss: 0.1412, Initial Validation Loss: 0.1337, Validation Loss: 0.1337,V Acc: 0.3545, Top 70th Acc: 0.4416, Bottom 30th Acc: 0.1515
Fold [4/5] Epoch [10/100] Initial Loss: 0.1412, Training Loss: 0.0141, Initial Validation Loss: 0.1337, Validation Loss: 0.0368,V Acc: 0.7818, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.4545
Fold [4/5] Epoch [20/100] Initial Loss: 0.1412, Training Loss: 0.0052, Initial Validation Loss: 0.1337, Validation Loss: 0.0319,V Acc: 0.8091, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.5152
Fold [4/5] Epoch [30/100] Initial Loss: 0.1412, Training Loss: 0.0042, Initial Validation Loss: 0.1337, Validation Loss: 0.0309,V Acc: 0.8545, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.6667
Fold [4/5] Epoch [40/100] Initial Loss: 0.1412, Training Loss: 0.0040, Initial Validation Loss: 0.1337, Validation Loss: 0.0305,V Acc: 0.8455, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 42  Rolling back to Epoch (base 0): 37  Top Validation Acc: 0.935064935064935
Fold [5/5] Epoch [0/100] Initial Loss: 0.1382, Training Loss: 0.1382, Initial Validation Loss: 0.1338, Validation Loss: 0.1338,V Acc: 0.2593, Top 70th Acc: 0.3553, Bottom 30th Acc: 0.0312
Fold [5/5] Epoch [10/100] Initial Loss: 0.1382, Training Loss: 0.0241, Initial Validation Loss: 0.1338, Validation Loss: 0.0464,V Acc: 0.7963, Top 70th Acc: 0.8816, Bottom 30th Acc: 0.5938
Fold [5/5] Epoch [20/100] Initial Loss: 0.1382, Training Loss: 0.0063, Initial Validation Loss: 0.1338, Validation Loss: 0.0343,V Acc: 0.8519, Top 70th Acc: 0.9079, Bottom 30th Acc: 0.7188
Fold [5/5] Epoch [30/100] Initial Loss: 0.1382, Training Loss: 0.0043, Initial Validation Loss: 0.1338, Validation Loss: 0.0308,V Acc: 0.8704, Top 70th Acc: 0.9079, Bottom 30th Acc: 0.7812
Fold [5/5] Epoch [40/100] Initial Loss: 0.1382, Training Loss: 0.0039, Initial Validation Loss: 0.1338, Validation Loss: 0.0296,V Acc: 0.8704, Top 70th Acc: 0.9079, Bottom 30th Acc: 0.7812
Fold [5/5] Epoch [50/100] Initial Loss: 0.1382, Training Loss: 0.0037, Initial Validation Loss: 0.1338, Validation Loss: 0.0286,V Acc: 0.8889, Top 70th Acc: 0.9211, Bottom 30th Acc: 0.8125
Fold [5/5] Epoch [60/100] Initial Loss: 0.1382, Training Loss: 0.0036, Initial Validation Loss: 0.1338, Validation Loss: 0.0284,V Acc: 0.8889, Top 70th Acc: 0.9211, Bottom 30th Acc: 0.8125
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.9473684210526315
27 4 [array([0.490014  , 0.12106396, 0.05714407, 0.08958191, 0.24219614],
      dtype=float32)]
Running train_nn.py with seed 28
CUDA:False
Training samples count:  550
Training on 30 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1352, Training Loss: 0.1352, Initial Validation Loss: 0.1375, Validation Loss: 0.1375,V Acc: 0.2883, Top 70th Acc: 0.3462, Bottom 30th Acc: 0.1515
Fold [1/5] Epoch [10/100] Initial Loss: 0.1352, Training Loss: 0.0378, Initial Validation Loss: 0.1375, Validation Loss: 0.0429,V Acc: 0.8468, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.5758
Fold [1/5] Epoch [20/100] Initial Loss: 0.1352, Training Loss: 0.0190, Initial Validation Loss: 0.1375, Validation Loss: 0.0331,V Acc: 0.8649, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.6364
Fold [1/5] Epoch [30/100] Initial Loss: 0.1352, Training Loss: 0.0162, Initial Validation Loss: 0.1375, Validation Loss: 0.0321,V Acc: 0.8739, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 30  Rolling back to Epoch (base 0): 25  Top Validation Acc: 0.9743589743589743
Fold [2/5] Epoch [0/100] Initial Loss: 0.1387, Training Loss: 0.1387, Initial Validation Loss: 0.1316, Validation Loss: 0.1316,V Acc: 0.3153, Top 70th Acc: 0.3590, Bottom 30th Acc: 0.2121
Fold [2/5] Epoch [10/100] Initial Loss: 0.1387, Training Loss: 0.0438, Initial Validation Loss: 0.1316, Validation Loss: 0.0454,V Acc: 0.7838, Top 70th Acc: 0.8718, Bottom 30th Acc: 0.5758
Fold [2/5] Epoch [20/100] Initial Loss: 0.1387, Training Loss: 0.0190, Initial Validation Loss: 0.1316, Validation Loss: 0.0321,V Acc: 0.8108, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.5152
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.9230769230769231
28 1 [array([0.5071577 , 0.05647898, 0.17768374, 0.10776541, 0.15091418],
      dtype=float32)]
Fold [3/5] Epoch [0/100] Initial Loss: 0.1393, Training Loss: 0.1393, Initial Validation Loss: 0.1318, Validation Loss: 0.1318,V Acc: 0.2909, Top 70th Acc: 0.3506, Bottom 30th Acc: 0.1515
Fold [3/5] Epoch [10/100] Initial Loss: 0.1393, Training Loss: 0.0320, Initial Validation Loss: 0.1318, Validation Loss: 0.0351,V Acc: 0.8636, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6667
Fold [3/5] Epoch [20/100] Initial Loss: 0.1393, Training Loss: 0.0190, Initial Validation Loss: 0.1318, Validation Loss: 0.0319,V Acc: 0.8000, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.4242
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.974025974025974
Fold [4/5] Epoch [0/100] Initial Loss: 0.1395, Training Loss: 0.1395, Initial Validation Loss: 0.1370, Validation Loss: 0.1370,V Acc: 0.3727, Top 70th Acc: 0.3896, Bottom 30th Acc: 0.3333
Fold [4/5] Epoch [10/100] Initial Loss: 0.1395, Training Loss: 0.0326, Initial Validation Loss: 0.1370, Validation Loss: 0.0511,V Acc: 0.7455, Top 70th Acc: 0.8701, Bottom 30th Acc: 0.4545
Fold [4/5] Epoch [20/100] Initial Loss: 0.1395, Training Loss: 0.0193, Initial Validation Loss: 0.1370, Validation Loss: 0.0402,V Acc: 0.8273, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 28  Rolling back to Epoch (base 0): 23  Top Validation Acc: 0.935064935064935
Fold [5/5] Epoch [0/100] Initial Loss: 0.1380, Training Loss: 0.1380, Initial Validation Loss: 0.1276, Validation Loss: 0.1276,V Acc: 0.3611, Top 70th Acc: 0.3947, Bottom 30th Acc: 0.2812
Fold [5/5] Epoch [10/100] Initial Loss: 0.1380, Training Loss: 0.0347, Initial Validation Loss: 0.1276, Validation Loss: 0.0368,V Acc: 0.8333, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.5938
Fold [5/5] Epoch [20/100] Initial Loss: 0.1380, Training Loss: 0.0191, Initial Validation Loss: 0.1276, Validation Loss: 0.0311,V Acc: 0.8148, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.5312
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.9342105263157895
Running train_nn.py with seed 29
CUDA:False
Training samples count:  550
Training on 30 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1366, Training Loss: 0.1366, Initial Validation Loss: 0.1391, Validation Loss: 0.1391,V Acc: 0.3243, Top 70th Acc: 0.3205, Bottom 30th Acc: 0.3333
Fold [1/5] Epoch [10/100] Initial Loss: 0.1366, Training Loss: 0.0289, Initial Validation Loss: 0.1391, Validation Loss: 0.0394,V Acc: 0.8378, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.6364
Fold [1/5] Epoch [20/100] Initial Loss: 0.1366, Training Loss: 0.0177, Initial Validation Loss: 0.1391, Validation Loss: 0.0321,V Acc: 0.8739, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.7273
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.9358974358974359
29 0 [array([0.7301977 , 0.07156719, 0.0188625 , 0.04799647, 0.13137612],
      dtype=float32)]
Fold [2/5] Epoch [0/100] Initial Loss: 0.1393, Training Loss: 0.1393, Initial Validation Loss: 0.1367, Validation Loss: 0.1367,V Acc: 0.2973, Top 70th Acc: 0.3590, Bottom 30th Acc: 0.1515
Fold [2/5] Epoch [10/100] Initial Loss: 0.1393, Training Loss: 0.0417, Initial Validation Loss: 0.1367, Validation Loss: 0.0477,V Acc: 0.7928, Top 70th Acc: 0.8718, Bottom 30th Acc: 0.6061
Fold [2/5] Epoch [20/100] Initial Loss: 0.1393, Training Loss: 0.0233, Initial Validation Loss: 0.1367, Validation Loss: 0.0325,V Acc: 0.8468, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.6061
Fold [2/5] Epoch [30/100] Initial Loss: 0.1393, Training Loss: 0.0181, Initial Validation Loss: 0.1367, Validation Loss: 0.0300,V Acc: 0.8288, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.4848
Stopping early at Epoch (base 0): 35  Rolling back to Epoch (base 0): 30  Top Validation Acc: 0.9615384615384616
Fold [3/5] Epoch [0/100] Initial Loss: 0.1391, Training Loss: 0.1391, Initial Validation Loss: 0.1294, Validation Loss: 0.1294,V Acc: 0.3182, Top 70th Acc: 0.3766, Bottom 30th Acc: 0.1818
Fold [3/5] Epoch [10/100] Initial Loss: 0.1391, Training Loss: 0.0357, Initial Validation Loss: 0.1294, Validation Loss: 0.0349,V Acc: 0.8091, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.5455
Fold [3/5] Epoch [20/100] Initial Loss: 0.1391, Training Loss: 0.0197, Initial Validation Loss: 0.1294, Validation Loss: 0.0243,V Acc: 0.8727, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.974025974025974
Fold [4/5] Epoch [0/100] Initial Loss: 0.1395, Training Loss: 0.1395, Initial Validation Loss: 0.1312, Validation Loss: 0.1312,V Acc: 0.2545, Top 70th Acc: 0.2208, Bottom 30th Acc: 0.3333
Fold [4/5] Epoch [10/100] Initial Loss: 0.1395, Training Loss: 0.0410, Initial Validation Loss: 0.1312, Validation Loss: 0.0428,V Acc: 0.7727, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.4545
Fold [4/5] Epoch [20/100] Initial Loss: 0.1395, Training Loss: 0.0182, Initial Validation Loss: 0.1312, Validation Loss: 0.0305,V Acc: 0.8091, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.5152
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.948051948051948
Fold [5/5] Epoch [0/100] Initial Loss: 0.1418, Training Loss: 0.1418, Initial Validation Loss: 0.1346, Validation Loss: 0.1346,V Acc: 0.2037, Top 70th Acc: 0.1579, Bottom 30th Acc: 0.3125
Fold [5/5] Epoch [10/100] Initial Loss: 0.1418, Training Loss: 0.0393, Initial Validation Loss: 0.1346, Validation Loss: 0.0511,V Acc: 0.7500, Top 70th Acc: 0.8421, Bottom 30th Acc: 0.5312
Fold [5/5] Epoch [20/100] Initial Loss: 0.1418, Training Loss: 0.0197, Initial Validation Loss: 0.1346, Validation Loss: 0.0404,V Acc: 0.7870, Top 70th Acc: 0.8947, Bottom 30th Acc: 0.5312
Stopping early at Epoch (base 0): 27  Rolling back to Epoch (base 0): 22  Top Validation Acc: 0.881578947368421
Running train_nn.py with seed 30
CUDA:False
Training samples count:  550
Training on 30 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1349, Training Loss: 0.1349, Initial Validation Loss: 0.1338, Validation Loss: 0.1338,V Acc: 0.3243, Top 70th Acc: 0.3974, Bottom 30th Acc: 0.1515
Fold [1/5] Epoch [10/100] Initial Loss: 0.1349, Training Loss: 0.0313, Initial Validation Loss: 0.1338, Validation Loss: 0.0438,V Acc: 0.7928, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.5152
Fold [2/5] Epoch [20/100] Initial Loss: 0.1335, Training Loss: 0.0789, Initial Validation Loss: 0.1248, Validation Loss: 0.0766,V Acc: 0.6667, Top 70th Acc: 0.7564, Bottom 30th Acc: 0.4545
Stopping early at Epoch (base 0): 27  Rolling back to Epoch (base 0): 22  Top Validation Acc: 0.7307692307692307
Fold [3/5] Epoch [0/100] Initial Loss: 0.1332, Training Loss: 0.1332, Initial Validation Loss: 0.1281, Validation Loss: 0.1281,V Acc: 0.5455, Top 70th Acc: 0.6753, Bottom 30th Acc: 0.2424
Fold [3/5] Epoch [10/100] Initial Loss: 0.1332, Training Loss: 0.0794, Initial Validation Loss: 0.1281, Validation Loss: 0.0866,V Acc: 0.5818, Top 70th Acc: 0.7013, Bottom 30th Acc: 0.3030
Fold [3/5] Epoch [20/100] Initial Loss: 0.1332, Training Loss: 0.0775, Initial Validation Loss: 0.1281, Validation Loss: 0.0851,V Acc: 0.6000, Top 70th Acc: 0.7143, Bottom 30th Acc: 0.3333
Fold [3/5] Epoch [30/100] Initial Loss: 0.1332, Training Loss: 0.0767, Initial Validation Loss: 0.1281, Validation Loss: 0.0844,V Acc: 0.6000, Top 70th Acc: 0.6883, Bottom 30th Acc: 0.3939
Stopping early at Epoch (base 0): 32  Rolling back to Epoch (base 0): 27  Top Validation Acc: 0.7012987012987013
26 2 [array([0.13889119, 0.32800415, 0.16274798, 0.23378465, 0.13657196],
      dtype=float32)]
Fold [4/5] Epoch [0/100] Initial Loss: 0.1398, Training Loss: 0.1398, Initial Validation Loss: 0.1288, Validation Loss: 0.1288,V Acc: 0.4091, Top 70th Acc: 0.5195, Bottom 30th Acc: 0.1515
Fold [4/5] Epoch [10/100] Initial Loss: 0.1398, Training Loss: 0.0836, Initial Validation Loss: 0.1288, Validation Loss: 0.0706,V Acc: 0.6455, Top 70th Acc: 0.7662, Bottom 30th Acc: 0.3636
Fold [4/5] Epoch [20/100] Initial Loss: 0.1398, Training Loss: 0.0812, Initial Validation Loss: 0.1288, Validation Loss: 0.0683,V Acc: 0.6727, Top 70th Acc: 0.7922, Bottom 30th Acc: 0.3939
Fold [4/5] Epoch [30/100] Initial Loss: 0.1398, Training Loss: 0.0804, Initial Validation Loss: 0.1288, Validation Loss: 0.0684,V Acc: 0.6727, Top 70th Acc: 0.8052, Bottom 30th Acc: 0.3636
Stopping early at Epoch (base 0): 32  Rolling back to Epoch (base 0): 27  Top Validation Acc: 0.7922077922077922
Fold [5/5] Epoch [0/100] Initial Loss: 0.1359, Training Loss: 0.1359, Initial Validation Loss: 0.1281, Validation Loss: 0.1281,V Acc: 0.2778, Top 70th Acc: 0.3421, Bottom 30th Acc: 0.1250
Fold [5/5] Epoch [10/100] Initial Loss: 0.1359, Training Loss: 0.0785, Initial Validation Loss: 0.1281, Validation Loss: 0.0833,V Acc: 0.6111, Top 70th Acc: 0.7368, Bottom 30th Acc: 0.3125
Fold [5/5] Epoch [20/100] Initial Loss: 0.1359, Training Loss: 0.0762, Initial Validation Loss: 0.1281, Validation Loss: 0.0820,V Acc: 0.6019, Top 70th Acc: 0.7237, Bottom 30th Acc: 0.3125
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.7236842105263158
Running train_nn.py with seed 27
CUDA:False
Training samples count:  550
Training on 2 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1397, Training Loss: 0.1397, Initial Validation Loss: 0.1311, Validation Loss: 0.1311,V Acc: 0.5045, Top 70th Acc: 0.5897, Bottom 30th Acc: 0.3030
Fold [1/5] Epoch [10/100] Initial Loss: 0.1397, Training Loss: 0.0813, Initial Validation Loss: 0.1311, Validation Loss: 0.0806,V Acc: 0.6126, Top 70th Acc: 0.7308, Bottom 30th Acc: 0.3333
Fold [1/5] Epoch [20/100] Initial Loss: 0.1397, Training Loss: 0.0791, Initial Validation Loss: 0.1311, Validation Loss: 0.0795,V Acc: 0.6216, Top 70th Acc: 0.7308, Bottom 30th Acc: 0.3636
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.7435897435897436
Fold [2/5] Epoch [0/100] Initial Loss: 0.1368, Training Loss: 0.1368, Initial Validation Loss: 0.1341, Validation Loss: 0.1341,V Acc: 0.2793, Top 70th Acc: 0.3718, Bottom 30th Acc: 0.0606
Fold [2/5] Epoch [10/100] Initial Loss: 0.1368, Training Loss: 0.0806, Initial Validation Loss: 0.1341, Validation Loss: 0.0862,V Acc: 0.6126, Top 70th Acc: 0.7692, Bottom 30th Acc: 0.2424
Stopping early at Epoch (base 0): 17  Rolling back to Epoch (base 0): 12  Top Validation Acc: 0.7435897435897436
Fold [3/5] Epoch [0/100] Initial Loss: 0.1407, Training Loss: 0.1407, Initial Validation Loss: 0.1336, Validation Loss: 0.1336,V Acc: 0.2545, Top 70th Acc: 0.2857, Bottom 30th Acc: 0.1818
Fold [3/5] Epoch [10/100] Initial Loss: 0.1407, Training Loss: 0.0819, Initial Validation Loss: 0.1336, Validation Loss: 0.0776,V Acc: 0.6545, Top 70th Acc: 0.7403, Bottom 30th Acc: 0.4545
Fold [3/5] Epoch [20/100] Initial Loss: 0.1407, Training Loss: 0.0789, Initial Validation Loss: 0.1336, Validation Loss: 0.0755,V Acc: 0.6364, Top 70th Acc: 0.7403, Bottom 30th Acc: 0.3939
Fold [3/5] Epoch [30/100] Initial Loss: 0.1407, Training Loss: 0.0782, Initial Validation Loss: 0.1336, Validation Loss: 0.0747,V Acc: 0.6727, Top 70th Acc: 0.7273, Bottom 30th Acc: 0.5455
Fold [3/5] Epoch [40/100] Initial Loss: 0.1407, Training Loss: 0.0776, Initial Validation Loss: 0.1336, Validation Loss: 0.0746,V Acc: 0.6545, Top 70th Acc: 0.7532, Bottom 30th Acc: 0.4242
Stopping early at Epoch (base 0): 46  Rolling back to Epoch (base 0): 41  Top Validation Acc: 0.7792207792207793
Fold [4/5] Epoch [0/100] Initial Loss: 0.1301, Training Loss: 0.1301, Initial Validation Loss: 0.1151, Validation Loss: 0.1151,V Acc: 0.5091, Top 70th Acc: 0.5844, Bottom 30th Acc: 0.3333
Fold [4/5] Epoch [10/100] Initial Loss: 0.1301, Training Loss: 0.0789, Initial Validation Loss: 0.1151, Validation Loss: 0.0867,V Acc: 0.5636, Top 70th Acc: 0.6753, Bottom 30th Acc: 0.3030
Stopping early at Epoch (base 0): 14  Rolling back to Epoch (base 0): 9  Top Validation Acc: 0.6623376623376623
Fold [5/5] Epoch [0/100] Initial Loss: 0.1301, Training Loss: 0.1301, Initial Validation Loss: 0.1190, Validation Loss: 0.1190,V Acc: 0.5000, Top 70th Acc: 0.4868, Bottom 30th Acc: 0.5312
Fold [5/5] Epoch [10/100] Initial Loss: 0.1301, Training Loss: 0.0830, Initial Validation Loss: 0.1190, Validation Loss: 0.0711,V Acc: 0.6759, Top 70th Acc: 0.8026, Bottom 30th Acc: 0.3750
Fold [5/5] Epoch [20/100] Initial Loss: 0.1301, Training Loss: 0.0816, Initial Validation Loss: 0.1190, Validation Loss: 0.0686,V Acc: 0.6852, Top 70th Acc: 0.8158, Bottom 30th Acc: 0.3750
Fold [5/5] Epoch [30/100] Initial Loss: 0.1301, Training Loss: 0.0811, Initial Validation Loss: 0.1190, Validation Loss: 0.0687,V Acc: 0.6759, Top 70th Acc: 0.8158, Bottom 30th Acc: 0.3438
Fold [5/5] Epoch [40/100] Initial Loss: 0.1301, Training Loss: 0.0809, Initial Validation Loss: 0.1190, Validation Loss: 0.0670,V Acc: 0.6944, Top 70th Acc: 0.8289, Bottom 30th Acc: 0.3750
Stopping early at Epoch (base 0): 47  Rolling back to Epoch (base 0): 42  Top Validation Acc: 0.8157894736842105
27 4 [array([0.15437096, 0.33106226, 0.14902799, 0.21527678, 0.15026203],
      dtype=float32)]
Running train_nn.py with seed 28
CUDA:False
Training samples count:  550
Training on 2 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1382, Training Loss: 0.1382, Initial Validation Loss: 0.1334, Validation Loss: 0.1334,V Acc: 0.3153, Top 70th Acc: 0.3590, Bottom 30th Acc: 0.2121
Fold [1/5] Epoch [10/100] Initial Loss: 0.1382, Training Loss: 0.0796, Initial Validation Loss: 0.1334, Validation Loss: 0.0873,V Acc: 0.6486, Top 70th Acc: 0.7564, Bottom 30th Acc: 0.3939
Fold [1/5] Epoch [20/100] Initial Loss: 0.1382, Training Loss: 0.0774, Initial Validation Loss: 0.1334, Validation Loss: 0.0854,V Acc: 0.6486, Top 70th Acc: 0.7564, Bottom 30th Acc: 0.3939
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.7435897435897436
Fold [2/5] Epoch [0/100] Initial Loss: 0.1401, Training Loss: 0.1401, Initial Validation Loss: 0.1281, Validation Loss: 0.1281,V Acc: 0.2973, Top 70th Acc: 0.3590, Bottom 30th Acc: 0.1515
Fold [2/5] Epoch [10/100] Initial Loss: 0.1401, Training Loss: 0.0826, Initial Validation Loss: 0.1281, Validation Loss: 0.0754,V Acc: 0.5946, Top 70th Acc: 0.7308, Bottom 30th Acc: 0.2727
Fold [2/5] Epoch [20/100] Initial Loss: 0.1401, Training Loss: 0.0806, Initial Validation Loss: 0.1281, Validation Loss: 0.0731,V Acc: 0.5946, Top 70th Acc: 0.7436, Bottom 30th Acc: 0.2424
Fold [2/5] Epoch [30/100] Initial Loss: 0.1401, Training Loss: 0.0800, Initial Validation Loss: 0.1281, Validation Loss: 0.0726,V Acc: 0.5856, Top 70th Acc: 0.7436, Bottom 30th Acc: 0.2121
Stopping early at Epoch (base 0): 40  Rolling back to Epoch (base 0): 35  Top Validation Acc: 0.9487179487179487
Fold [2/5] Epoch [0/100] Initial Loss: 0.1387, Training Loss: 0.1387, Initial Validation Loss: 0.1321, Validation Loss: 0.1321,V Acc: 0.3243, Top 70th Acc: 0.3590, Bottom 30th Acc: 0.2424
Fold [2/5] Epoch [10/100] Initial Loss: 0.1387, Training Loss: 0.0353, Initial Validation Loss: 0.1321, Validation Loss: 0.0355,V Acc: 0.8018, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.5455
Fold [2/5] Epoch [20/100] Initial Loss: 0.1387, Training Loss: 0.0230, Initial Validation Loss: 0.1321, Validation Loss: 0.0293,V Acc: 0.8378, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.9102564102564102
28 1 [array([0.46875134, 0.06534105, 0.13617784, 0.14023201, 0.18949786],
      dtype=float32)]
Fold [3/5] Epoch [0/100] Initial Loss: 0.1382, Training Loss: 0.1382, Initial Validation Loss: 0.1259, Validation Loss: 0.1259,V Acc: 0.3545, Top 70th Acc: 0.4286, Bottom 30th Acc: 0.1818
Fold [3/5] Epoch [10/100] Initial Loss: 0.1382, Training Loss: 0.0341, Initial Validation Loss: 0.1259, Validation Loss: 0.0335,V Acc: 0.8455, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.5758
Fold [3/5] Epoch [20/100] Initial Loss: 0.1382, Training Loss: 0.0239, Initial Validation Loss: 0.1259, Validation Loss: 0.0298,V Acc: 0.8545, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.974025974025974
Fold [4/5] Epoch [0/100] Initial Loss: 0.1381, Training Loss: 0.1381, Initial Validation Loss: 0.1392, Validation Loss: 0.1392,V Acc: 0.3455, Top 70th Acc: 0.3636, Bottom 30th Acc: 0.3030
Fold [4/5] Epoch [10/100] Initial Loss: 0.1381, Training Loss: 0.0338, Initial Validation Loss: 0.1392, Validation Loss: 0.0486,V Acc: 0.8000, Top 70th Acc: 0.8961, Bottom 30th Acc: 0.5758
Fold [4/5] Epoch [20/100] Initial Loss: 0.1381, Training Loss: 0.0216, Initial Validation Loss: 0.1392, Validation Loss: 0.0407,V Acc: 0.8364, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 27  Rolling back to Epoch (base 0): 22  Top Validation Acc: 0.9090909090909091
Fold [5/5] Epoch [0/100] Initial Loss: 0.1388, Training Loss: 0.1388, Initial Validation Loss: 0.1308, Validation Loss: 0.1308,V Acc: 0.2407, Top 70th Acc: 0.2105, Bottom 30th Acc: 0.3125
Fold [5/5] Epoch [10/100] Initial Loss: 0.1388, Training Loss: 0.0460, Initial Validation Loss: 0.1308, Validation Loss: 0.0436,V Acc: 0.7963, Top 70th Acc: 0.8816, Bottom 30th Acc: 0.5938
Fold [5/5] Epoch [20/100] Initial Loss: 0.1388, Training Loss: 0.0263, Initial Validation Loss: 0.1308, Validation Loss: 0.0294,V Acc: 0.8426, Top 70th Acc: 0.9079, Bottom 30th Acc: 0.6875
Stopping early at Epoch (base 0): 29  Rolling back to Epoch (base 0): 24  Top Validation Acc: 0.9473684210526315
Running train_nn.py with seed 29
CUDA:False
Training samples count:  550
Training on 20 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1383, Training Loss: 0.1383, Initial Validation Loss: 0.1397, Validation Loss: 0.1397,V Acc: 0.3514, Top 70th Acc: 0.4359, Bottom 30th Acc: 0.1515
Fold [1/5] Epoch [10/100] Initial Loss: 0.1383, Training Loss: 0.0423, Initial Validation Loss: 0.1397, Validation Loss: 0.0475,V Acc: 0.8288, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.6364
Fold [1/5] Epoch [20/100] Initial Loss: 0.1383, Training Loss: 0.0248, Initial Validation Loss: 0.1397, Validation Loss: 0.0328,V Acc: 0.8378, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.5455
Fold [1/5] Epoch [30/100] Initial Loss: 0.1383, Training Loss: 0.0217, Initial Validation Loss: 0.1397, Validation Loss: 0.0306,V Acc: 0.8829, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.7273
Stopping early at Epoch (base 0): 31  Rolling back to Epoch (base 0): 26  Top Validation Acc: 0.9487179487179487
29 0 [array([0.4149651 , 0.13129193, 0.11186147, 0.25248846, 0.08939305],
      dtype=float32)]
Fold [2/5] Epoch [0/100] Initial Loss: 0.1370, Training Loss: 0.1370, Initial Validation Loss: 0.1340, Validation Loss: 0.1340,V Acc: 0.3243, Top 70th Acc: 0.3462, Bottom 30th Acc: 0.2727
Fold [2/5] Epoch [10/100] Initial Loss: 0.1370, Training Loss: 0.0363, Initial Validation Loss: 0.1340, Validation Loss: 0.0354,V Acc: 0.8468, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.5758
Fold [2/5] Epoch [20/100] Initial Loss: 0.1370, Training Loss: 0.0232, Initial Validation Loss: 0.1340, Validation Loss: 0.0301,V Acc: 0.8559, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 29  Rolling back to Epoch (base 0): 24  Top Validation Acc: 0.9743589743589743
Fold [3/5] Epoch [0/100] Initial Loss: 0.1420, Training Loss: 0.1420, Initial Validation Loss: 0.1317, Validation Loss: 0.1317,V Acc: 0.2545, Top 70th Acc: 0.2857, Bottom 30th Acc: 0.1818
Fold [3/5] Epoch [10/100] Initial Loss: 0.1420, Training Loss: 0.0322, Initial Validation Loss: 0.1317, Validation Loss: 0.0339,V Acc: 0.8636, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.7273
Fold [3/5] Epoch [20/100] Initial Loss: 0.1420, Training Loss: 0.0221, Initial Validation Loss: 0.1317, Validation Loss: 0.0277,V Acc: 0.8636, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 21  Rolling back to Epoch (base 0): 16  Top Validation Acc: 0.935064935064935
Fold [4/5] Epoch [0/100] Initial Loss: 0.1379, Training Loss: 0.1379, Initial Validation Loss: 0.1299, Validation Loss: 0.1299,V Acc: 0.4000, Top 70th Acc: 0.4156, Bottom 30th Acc: 0.3636
Fold [4/5] Epoch [10/100] Initial Loss: 0.1379, Training Loss: 0.0359, Initial Validation Loss: 0.1299, Validation Loss: 0.0390,V Acc: 0.7909, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.4848
Fold [4/5] Epoch [20/100] Initial Loss: 0.1379, Training Loss: 0.0220, Initial Validation Loss: 0.1299, Validation Loss: 0.0317,V Acc: 0.8273, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.5152
Stopping early at Epoch (base 0): 28  Rolling back to Epoch (base 0): 23  Top Validation Acc: 0.961038961038961
Fold [5/5] Epoch [0/100] Initial Loss: 0.1412, Training Loss: 0.1412, Initial Validation Loss: 0.1332, Validation Loss: 0.1332,V Acc: 0.2500, Top 70th Acc: 0.3421, Bottom 30th Acc: 0.0312
Fold [5/5] Epoch [10/100] Initial Loss: 0.1412, Training Loss: 0.0369, Initial Validation Loss: 0.1332, Validation Loss: 0.0458,V Acc: 0.7778, Top 70th Acc: 0.9079, Bottom 30th Acc: 0.4688
Fold [5/5] Epoch [20/100] Initial Loss: 0.1412, Training Loss: 0.0212, Initial Validation Loss: 0.1332, Validation Loss: 0.0371,V Acc: 0.7870, Top 70th Acc: 0.9079, Bottom 30th Acc: 0.5000
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.9078947368421053
Running train_nn.py with seed 30
CUDA:False
Training samples count:  550
Training on 20 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1388, Training Loss: 0.1388, Initial Validation Loss: 0.1352, Validation Loss: 0.1352,V Acc: 0.3784, Top 70th Acc: 0.4615, Bottom 30th Acc: 0.1818
Fold [1/5] Epoch [10/100] Initial Loss: 0.1388, Training Loss: 0.0336, Initial Validation Loss: 0.1352, Validation Loss: 0.0443,V Acc: 0.8018, Top 70th Acc: 0.8846, Bottom 30th Acc: 0.6061
Fold [1/5] Epoch [20/100] Initial Loss: 0.1388, Training Loss: 0.0218, Initial Validation Loss: 0.1352, Validation Loss: 0.0363,V Acc: 0.8288, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.5758
Fold [1/5] Epoch [30/100] Initial Loss: 0.1388, Training Loss: 0.0195, Initial Validation Loss: 0.1352, Validation Loss: 0.0360,V Acc: 0.8198, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 34  Rolling back to Epoch (base 0): 29  Top Validation Acc: 0.9230769230769231
Fold [2/5] Epoch [0/100] Initial Loss: 0.1336, Training Loss: 0.1336, Initial Validation Loss: 0.1254, Validation Loss: 0.1254,V Acc: 0.4505, Top 70th Acc: 0.5385, Bottom 30th Acc: 0.2424
Fold [2/5] Epoch [10/100] Initial Loss: 0.1336, Training Loss: 0.0440, Initial Validation Loss: 0.1254, Validation Loss: 0.0478,V Acc: 0.7658, Top 70th Acc: 0.8590, Bottom 30th Acc: 0.5455
Fold [2/5] Epoch [20/100] Initial Loss: 0.1336, Training Loss: 0.0310, Initial Validation Loss: 0.1254, Validation Loss: 0.0407,V Acc: 0.8108, Top 70th Acc: 0.8846, Bottom 30th Acc: 0.6364
Fold [3/5] Epoch [10/100] Initial Loss: 0.1417, Training Loss: 0.0287, Initial Validation Loss: 0.1336, Validation Loss: 0.0429,V Acc: 0.8091, Top 70th Acc: 0.8961, Bottom 30th Acc: 0.6061
Fold [3/5] Epoch [20/100] Initial Loss: 0.1417, Training Loss: 0.0141, Initial Validation Loss: 0.1336, Validation Loss: 0.0351,V Acc: 0.8455, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.6970
Fold [3/5] Epoch [30/100] Initial Loss: 0.1417, Training Loss: 0.0119, Initial Validation Loss: 0.1336, Validation Loss: 0.0352,V Acc: 0.8364, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 33  Rolling back to Epoch (base 0): 28  Top Validation Acc: 0.8961038961038961
Fold [4/5] Epoch [0/100] Initial Loss: 0.1381, Training Loss: 0.1381, Initial Validation Loss: 0.1361, Validation Loss: 0.1361,V Acc: 0.2545, Top 70th Acc: 0.3377, Bottom 30th Acc: 0.0606
Fold [4/5] Epoch [10/100] Initial Loss: 0.1381, Training Loss: 0.0389, Initial Validation Loss: 0.1361, Validation Loss: 0.0374,V Acc: 0.8818, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.6667
Fold [4/5] Epoch [20/100] Initial Loss: 0.1381, Training Loss: 0.0158, Initial Validation Loss: 0.1361, Validation Loss: 0.0258,V Acc: 0.8909, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 27  Rolling back to Epoch (base 0): 22  Top Validation Acc: 0.974025974025974
Fold [5/5] Epoch [0/100] Initial Loss: 0.1369, Training Loss: 0.1369, Initial Validation Loss: 0.1312, Validation Loss: 0.1312,V Acc: 0.3333, Top 70th Acc: 0.3684, Bottom 30th Acc: 0.2500
Fold [5/5] Epoch [10/100] Initial Loss: 0.1369, Training Loss: 0.0458, Initial Validation Loss: 0.1312, Validation Loss: 0.0601,V Acc: 0.6852, Top 70th Acc: 0.8553, Bottom 30th Acc: 0.2812
Fold [5/5] Epoch [20/100] Initial Loss: 0.1369, Training Loss: 0.0198, Initial Validation Loss: 0.1312, Validation Loss: 0.0432,V Acc: 0.7778, Top 70th Acc: 0.9211, Bottom 30th Acc: 0.4375
Fold [5/5] Epoch [30/100] Initial Loss: 0.1369, Training Loss: 0.0137, Initial Validation Loss: 0.1312, Validation Loss: 0.0383,V Acc: 0.7778, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.4062
Fold [5/5] Epoch [40/100] Initial Loss: 0.1369, Training Loss: 0.0118, Initial Validation Loss: 0.1312, Validation Loss: 0.0359,V Acc: 0.8056, Top 70th Acc: 0.9211, Bottom 30th Acc: 0.5312
Stopping early at Epoch (base 0): 46  Rolling back to Epoch (base 0): 41  Top Validation Acc: 0.9210526315789473
27 4 [array([0.74844456, 0.05862645, 0.04236878, 0.04613162, 0.10442853],
      dtype=float32)]
Running train_nn.py with seed 28
CUDA:False
Training samples count:  550
Training on 40 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1369, Training Loss: 0.1369, Initial Validation Loss: 0.1383, Validation Loss: 0.1383,V Acc: 0.2523, Top 70th Acc: 0.3462, Bottom 30th Acc: 0.0303
Fold [1/5] Epoch [10/100] Initial Loss: 0.1369, Training Loss: 0.0288, Initial Validation Loss: 0.1383, Validation Loss: 0.0376,V Acc: 0.8739, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.6364
Fold [1/5] Epoch [20/100] Initial Loss: 0.1369, Training Loss: 0.0140, Initial Validation Loss: 0.1383, Validation Loss: 0.0299,V Acc: 0.8649, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 22  Rolling back to Epoch (base 0): 17  Top Validation Acc: 0.9487179487179487
Fold [2/5] Epoch [0/100] Initial Loss: 0.1387, Training Loss: 0.1387, Initial Validation Loss: 0.1306, Validation Loss: 0.1306,V Acc: 0.3964, Top 70th Acc: 0.4872, Bottom 30th Acc: 0.1818
Fold [2/5] Epoch [10/100] Initial Loss: 0.1387, Training Loss: 0.0285, Initial Validation Loss: 0.1306, Validation Loss: 0.0333,V Acc: 0.8468, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.6667
Fold [2/5] Epoch [20/100] Initial Loss: 0.1387, Training Loss: 0.0144, Initial Validation Loss: 0.1306, Validation Loss: 0.0260,V Acc: 0.8378, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.9487179487179487
28 1 [array([0.45726126, 0.06975435, 0.08448967, 0.0641418 , 0.32435292],
      dtype=float32)]
Fold [3/5] Epoch [0/100] Initial Loss: 0.1394, Training Loss: 0.1394, Initial Validation Loss: 0.1338, Validation Loss: 0.1338,V Acc: 0.2545, Top 70th Acc: 0.2987, Bottom 30th Acc: 0.1515
Fold [3/5] Epoch [10/100] Initial Loss: 0.1394, Training Loss: 0.0300, Initial Validation Loss: 0.1338, Validation Loss: 0.0353,V Acc: 0.8545, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6364
Fold [3/5] Epoch [20/100] Initial Loss: 0.1394, Training Loss: 0.0147, Initial Validation Loss: 0.1338, Validation Loss: 0.0297,V Acc: 0.8545, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.948051948051948
Fold [4/5] Epoch [0/100] Initial Loss: 0.1403, Training Loss: 0.1403, Initial Validation Loss: 0.1399, Validation Loss: 0.1399,V Acc: 0.2636, Top 70th Acc: 0.2468, Bottom 30th Acc: 0.3030
Fold [4/5] Epoch [10/100] Initial Loss: 0.1403, Training Loss: 0.0337, Initial Validation Loss: 0.1399, Validation Loss: 0.0479,V Acc: 0.7909, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.4848
Fold [4/5] Epoch [20/100] Initial Loss: 0.1403, Training Loss: 0.0146, Initial Validation Loss: 0.1399, Validation Loss: 0.0357,V Acc: 0.8364, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 27  Rolling back to Epoch (base 0): 22  Top Validation Acc: 0.961038961038961
Fold [5/5] Epoch [0/100] Initial Loss: 0.1363, Training Loss: 0.1363, Initial Validation Loss: 0.1245, Validation Loss: 0.1245,V Acc: 0.4074, Top 70th Acc: 0.4342, Bottom 30th Acc: 0.3438
Fold [5/5] Epoch [10/100] Initial Loss: 0.1363, Training Loss: 0.0270, Initial Validation Loss: 0.1245, Validation Loss: 0.0330,V Acc: 0.8148, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.5000
Fold [5/5] Epoch [20/100] Initial Loss: 0.1363, Training Loss: 0.0128, Initial Validation Loss: 0.1245, Validation Loss: 0.0275,V Acc: 0.8611, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.6250
Fold [5/5] Epoch [30/100] Initial Loss: 0.1363, Training Loss: 0.0105, Initial Validation Loss: 0.1245, Validation Loss: 0.0279,V Acc: 0.8519, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.5938
Stopping early at Epoch (base 0): 34  Rolling back to Epoch (base 0): 29  Top Validation Acc: 0.9605263157894737
Running train_nn.py with seed 29
CUDA:False
Training samples count:  550
Training on 40 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1389, Training Loss: 0.1389, Initial Validation Loss: 0.1407, Validation Loss: 0.1407,V Acc: 0.3423, Top 70th Acc: 0.3333, Bottom 30th Acc: 0.3636
Fold [1/5] Epoch [10/100] Initial Loss: 0.1389, Training Loss: 0.0303, Initial Validation Loss: 0.1407, Validation Loss: 0.0439,V Acc: 0.8198, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.6061
Fold [1/5] Epoch [20/100] Initial Loss: 0.1389, Training Loss: 0.0151, Initial Validation Loss: 0.1407, Validation Loss: 0.0381,V Acc: 0.8378, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.6061
Fold [1/5] Epoch [30/100] Initial Loss: 0.1389, Training Loss: 0.0122, Initial Validation Loss: 0.1407, Validation Loss: 0.0342,V Acc: 0.8378, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 36  Rolling back to Epoch (base 0): 31  Top Validation Acc: 0.9615384615384616
29 0 [array([0.8229173 , 0.04916751, 0.01546589, 0.05360041, 0.05884893],
      dtype=float32)]
Fold [2/5] Epoch [0/100] Initial Loss: 0.1387, Training Loss: 0.1387, Initial Validation Loss: 0.1383, Validation Loss: 0.1383,V Acc: 0.2523, Top 70th Acc: 0.3333, Bottom 30th Acc: 0.0606
Fold [2/5] Epoch [10/100] Initial Loss: 0.1387, Training Loss: 0.0481, Initial Validation Loss: 0.1383, Validation Loss: 0.0507,V Acc: 0.7658, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.3939
Fold [2/5] Epoch [20/100] Initial Loss: 0.1387, Training Loss: 0.0261, Initial Validation Loss: 0.1383, Validation Loss: 0.0361,V Acc: 0.8198, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.5758
Fold [2/5] Epoch [30/100] Initial Loss: 0.1387, Training Loss: 0.0150, Initial Validation Loss: 0.1383, Validation Loss: 0.0285,V Acc: 0.8739, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.7273
Fold [2/5] Epoch [40/100] Initial Loss: 0.1387, Training Loss: 0.0127, Initial Validation Loss: 0.1383, Validation Loss: 0.0292,V Acc: 0.8739, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.7273training rf with seed 1
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 40 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 2
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 40 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 3
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 40 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 4
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 40 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 5
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 40 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 6
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 40 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 7
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 40 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 8
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 40 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 9
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 40 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 10
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 40 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 11
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 40 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 12
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 40 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 13
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 40 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 14
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 40 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 15
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 40 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 16
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 40 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 17
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 40 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 18
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 40 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 19
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 40 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 20
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 40 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 21
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 40 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 22
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 40 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 23
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 40 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 24
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 40 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 25
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 40 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 26
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 40 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 27
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 40 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 28
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 40 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 29
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 40 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 30
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 40 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 31
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 40 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 32
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 40 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 33
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 39 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 34
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 40 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 35
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 40 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 36
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 40 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 37
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 40 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 38
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 40 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 39
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 40 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 40
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 40 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 41
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 40 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 42
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 40 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 43
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 40 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 44
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 40 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 45
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442 9  Top Validation Acc: 0.9871794871794872
41 0 [array([0.7354369 , 0.04444966, 0.02623023, 0.06394448, 0.12993877],
      dtype=float32)]
Fold [2/5] Epoch [0/100] Initial Loss: 0.1405, Training Loss: 0.1405, Initial Validation Loss: 0.1277, Validation Loss: 0.1277,V Acc: 0.4414, Top 70th Acc: 0.4872, Bottom 30th Acc: 0.3333
Fold [2/5] Epoch [10/100] Initial Loss: 0.1405, Training Loss: 0.0239, Initial Validation Loss: 0.1277, Validation Loss: 0.0226,V Acc: 0.8919, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.7273
Stopping early at Epoch (base 0): 17  Rolling back to Epoch (base 0): 12  Top Validation Acc: 0.9615384615384616
Fold [3/5] Epoch [0/100] Initial Loss: 0.1353, Training Loss: 0.1353, Initial Validation Loss: 0.1273, Validation Loss: 0.1273,V Acc: 0.3818, Top 70th Acc: 0.4416, Bottom 30th Acc: 0.2424
Fold [3/5] Epoch [10/100] Initial Loss: 0.1353, Training Loss: 0.0252, Initial Validation Loss: 0.1273, Validation Loss: 0.0420,V Acc: 0.8182, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.5455
Fold [3/5] Epoch [20/100] Initial Loss: 0.1353, Training Loss: 0.0174, Initial Validation Loss: 0.1273, Validation Loss: 0.0378,V Acc: 0.8091, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.5152
Stopping early at Epoch (base 0): 20  Rolling back to Epoch (base 0): 15  Top Validation Acc: 0.935064935064935
Fold [4/5] Epoch [0/100] Initial Loss: 0.1295, Training Loss: 0.1295, Initial Validation Loss: 0.1146, Validation Loss: 0.1146,V Acc: 0.5182, Top 70th Acc: 0.6104, Bottom 30th Acc: 0.3030
Fold [4/5] Epoch [10/100] Initial Loss: 0.1295, Training Loss: 0.0276, Initial Validation Loss: 0.1146, Validation Loss: 0.0238,V Acc: 0.8909, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.6970
Fold [4/5] Epoch [20/100] Initial Loss: 0.1295, Training Loss: 0.0193, Initial Validation Loss: 0.1146, Validation Loss: 0.0234,V Acc: 0.8818, Top 70th Acc: 0.9870, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 29  Rolling back to Epoch (base 0): 24  Top Validation Acc: 0.961038961038961
Fold [5/5] Epoch [0/100] Initial Loss: 0.1300, Training Loss: 0.1300, Initial Validation Loss: 0.1121, Validation Loss: 0.1121,V Acc: 0.5556, Top 70th Acc: 0.6842, Bottom 30th Acc: 0.2500
Fold [5/5] Epoch [10/100] Initial Loss: 0.1300, Training Loss: 0.0234, Initial Validation Loss: 0.1121, Validation Loss: 0.0332,V Acc: 0.8148, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.5000
Fold [5/5] Epoch [20/100] Initial Loss: 0.1300, Training Loss: 0.0181, Initial Validation Loss: 0.1121, Validation Loss: 0.0302,V Acc: 0.8611, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.6562
Stopping early at Epoch (base 0): 21  Rolling back to Epoch (base 0): 16  Top Validation Acc: 0.9473684210526315
Running train_nn.py with seed 42
CUDA:False
Training samples count:  550
Training on 21 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1362, Training Loss: 0.1362, Initial Validation Loss: 0.1284, Validation Loss: 0.1284,V Acc: 0.4054, Top 70th Acc: 0.5385, Bottom 30th Acc: 0.0909
Fold [1/5] Epoch [10/100] Initial Loss: 0.1362, Training Loss: 0.0244, Initial Validation Loss: 0.1284, Validation Loss: 0.0418,V Acc: 0.8288, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.6364
Fold [1/5] Epoch [20/100] Initial Loss: 0.1362, Training Loss: 0.0159, Initial Validation Loss: 0.1284, Validation Loss: 0.0355,V Acc: 0.8559, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.7273
Stopping early at Epoch (base 0): 22  Rolling back to Epoch (base 0): 17  Top Validation Acc: 0.9102564102564102
Fold [2/5] Epoch [0/100] Initial Loss: 0.1346, Training Loss: 0.1346, Initial Validation Loss: 0.1198, Validation Loss: 0.1198,V Acc: 0.5135, Top 70th Acc: 0.6282, Bottom 30th Acc: 0.2424
Fold [2/5] Epoch [10/100] Initial Loss: 0.1346, Training Loss: 0.0239, Initial Validation Loss: 0.1198, Validation Loss: 0.0324,V Acc: 0.8288, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 14  Rolling back to Epoch (base 0): 9  Top Validation Acc: 0.9487179487179487
42 1 [array([0.7317014 , 0.03958216, 0.06025794, 0.09949375, 0.06896479],
      dtype=float32)]
Fold [3/5] Epoch [0/100] Initial Loss: 0.1376, Training Loss: 0.1376, Initial Validation Loss: 0.1271, Validation Loss: 0.1271,V Acc: 0.3909, Top 70th Acc: 0.4805, Bottom 30th Acc: 0.1818
Fold [3/5] Epoch [10/100] Initial Loss: 0.1376, Training Loss: 0.0248, Initial Validation Loss: 0.1271, Validation Loss: 0.0288,V Acc: 0.8818, Top 70th Acc: 0.9870, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 15  Rolling back to Epoch (base 0): 10  Top Validation Acc: 0.961038961038961
Fold [4/5] Epoch [0/100] Initial Loss: 0.1331, Training Loss: 0.1331, Initial Validation Loss: 0.1252, Validation Loss: 0.1252,V Acc: 0.4364, Top 70th Acc: 0.5195, Bottom 30th Acc: 0.2424
Fold [4/5] Epoch [10/100] Initial Loss: 0.1331, Training Loss: 0.0235, Initial Validation Loss: 0.1252, Validation Loss: 0.0187,V Acc: 0.9182, Top 70th Acc: 0.9870, Bottom 30th Acc: 0.7576
Stopping early at Epoch (base 0): 16  Rolling back to Epoch (base 0): 11  Top Validation Acc: 0.974025974025974
Fold [5/5] Epoch [0/100] Initial Loss: 0.1266, Training Loss: 0.1266, Initial Validation Loss: 0.1130, Validation Loss: 0.1130,V Acc: 0.5648, Top 70th Acc: 0.7105, Bottom 30th Acc: 0.2188
Fold [5/5] Epoch [10/100] Initial Loss: 0.1266, Training Loss: 0.0259, Initial Validation Loss: 0.1130, Validation Loss: 0.0254,V Acc: 0.8889, Top 70th Acc: 0.9737, Bottom 30th Acc: 0.6875
Fold [5/5] Epoch [20/100] Initial Loss: 0.1266, Training Loss: 0.0195, Initial Validation Loss: 0.1130, Validation Loss: 0.0189,V Acc: 0.9167, Top 70th Acc: 0.9868, Bottom 30th Acc: 0.7500
Stopping early at Epoch (base 0): 27  Rolling back to Epoch (base 0): 22  Top Validation Acc: 0.9868421052631579
Running train_nn.py with seed 43
CUDA:False
Training samples count:  550
Training on 21 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1382, Training Loss: 0.1382, Initial Validation Loss: 0.1273, Validation Loss: 0.1273,V Acc: 0.3514, Top 70th Acc: 0.3974, Bottom 30th Acc: 0.2424
Fold [1/5] Epoch [10/100] Initial Loss: 0.1382, Training Loss: 0.0236, Initial Validation Loss: 0.1273, Validation Loss: 0.0255,V Acc: 0.8559, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.6061
Fold [1/5] Epoch [20/100] Initial Loss: 0.1382, Training Loss: 0.0155, Initial Validation Loss: 0.1273, Validation Loss: 0.0261,V Acc: 0.8649, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.9871794871794872
Fold [2/5] Epoch [0/100] Initial Loss: 0.1406, Training Loss: 0.1406, Initial Validation Loss: 0.1284, Validation Loss: 0.1284,V Acc: 0.4234, Top 70th Acc: 0.4744, Bottom 30th Acc: 0.3030
Fold [2/5] Epoch [10/100] Initial Loss: 0.1406, Training Loss: 0.0228, Initial Validation Loss: 0.1284, Validation Loss: 0.0370,V Acc: 0.8198, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.5455
Fold [2/5] Epoch [20/100] Initial Loss: 0.1406, Training Loss: 0.0153, Initial Validation Loss: 0.1284, Validation Loss: 0.0319,V Acc: 0.8198, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.5152
Stopping early at Epoch (base 0): 21  Rolling back to Epoch (base 0): 16  Top Validation Acc: 0.9358974358974359
Fold [3/5] Epoch [0/100] Initial Loss: 0.1357, Training Loss: 0.1357, Initial Validation Loss: 0.1303, Validation Loss: 0.1303,V Acc: 0.3727, Top 70th Acc: 0.5195, Bottom 30th Acc: 0.0303
Fold [3/5] Epoch [10/100] Initial Loss: 0.1357, Training Loss: 0.0267, Initial Validation Loss: 0.1303, Validation Loss: 0.0269,V Acc: 0.9000, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.7273
Stopping early at Epoch (base 0): 19  Rolling back to Epoch (base 0): 14  Top Validation Acc: 0.974025974025974
43 2 [array([0.8118756 , 0.02144537, 0.05085491, 0.05727315, 0.058551  ],
      dtype=float32)]
Fold [4/5] Epoch [0/100] Initial Loss: 0.1457, Training Loss: 0.1457, Initial Validation Loss: 0.1383, Validation Loss: 0.1383,V Acc: 0.3364, Top 70th Acc: 0.3636, Bottom 30th Acc: 0.2727
Fold [4/5] Epoch [10/100] Initial Loss: 0.1457, Training Loss: 0.0296, Initial Validation Loss: 0.1383, Validation Loss: 0.0353,V Acc: 0.8545, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 16  Rolling back to Epoch (base 0): 11  Top Validation Acc: /home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)

Stopping early at Epoch (base 0): 32  Rolling back to Epoch (base 0): 27  Top Validation Acc: 0.7692307692307693
28 1 [array([0.13462354, 0.35455054, 0.14424951, 0.21914293, 0.14743356],
      dtype=float32)]
Fold [3/5] Epoch [0/100] Initial Loss: 0.1360, Training Loss: 0.1360, Initial Validation Loss: 0.1219, Validation Loss: 0.1219,V Acc: 0.4364, Top 70th Acc: 0.5584, Bottom 30th Acc: 0.1515
Fold [3/5] Epoch [10/100] Initial Loss: 0.1360, Training Loss: 0.0818, Initial Validation Loss: 0.1219, Validation Loss: 0.0776,V Acc: 0.6273, Top 70th Acc: 0.7532, Bottom 30th Acc: 0.3333
Fold [3/5] Epoch [20/100] Initial Loss: 0.1360, Training Loss: 0.0792, Initial Validation Loss: 0.1219, Validation Loss: 0.0756,V Acc: 0.6455, Top 70th Acc: 0.7792, Bottom 30th Acc: 0.3333
Stopping early at Epoch (base 0): 28  Rolling back to Epoch (base 0): 23  Top Validation Acc: 0.7792207792207793
Fold [4/5] Epoch [0/100] Initial Loss: 0.1389, Training Loss: 0.1389, Initial Validation Loss: 0.1392, Validation Loss: 0.1392,V Acc: 0.2545, Top 70th Acc: 0.2987, Bottom 30th Acc: 0.1515
Fold [4/5] Epoch [10/100] Initial Loss: 0.1389, Training Loss: 0.0783, Initial Validation Loss: 0.1392, Validation Loss: 0.0918,V Acc: 0.5727, Top 70th Acc: 0.6753, Bottom 30th Acc: 0.3333
Stopping early at Epoch (base 0): 19  Rolling back to Epoch (base 0): 14  Top Validation Acc: 0.6753246753246753
Fold [5/5] Epoch [0/100] Initial Loss: 0.1344, Training Loss: 0.1344, Initial Validation Loss: 0.1218, Validation Loss: 0.1218,V Acc: 0.5185, Top 70th Acc: 0.5921, Bottom 30th Acc: 0.3438
Fold [5/5] Epoch [10/100] Initial Loss: 0.1344, Training Loss: 0.0839, Initial Validation Loss: 0.1218, Validation Loss: 0.0739,V Acc: 0.6667, Top 70th Acc: 0.7632, Bottom 30th Acc: 0.4375
Fold [5/5] Epoch [20/100] Initial Loss: 0.1344, Training Loss: 0.0812, Initial Validation Loss: 0.1218, Validation Loss: 0.0719,V Acc: 0.6852, Top 70th Acc: 0.7500, Bottom 30th Acc: 0.5312
Stopping early at Epoch (base 0): 29  Rolling back to Epoch (base 0): 24  Top Validation Acc: 0.75
Running train_nn.py with seed 29
CUDA:False
Training samples count:  550
Training on 2 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1383, Training Loss: 0.1383, Initial Validation Loss: 0.1383, Validation Loss: 0.1383,V Acc: 0.3423, Top 70th Acc: 0.4359, Bottom 30th Acc: 0.1212
Fold [1/5] Epoch [10/100] Initial Loss: 0.1383, Training Loss: 0.0814, Initial Validation Loss: 0.1383, Validation Loss: 0.0816,V Acc: 0.6486, Top 70th Acc: 0.7821, Bottom 30th Acc: 0.3333
Fold [1/5] Epoch [20/100] Initial Loss: 0.1383, Training Loss: 0.0793, Initial Validation Loss: 0.1383, Validation Loss: 0.0794,V Acc: 0.6396, Top 70th Acc: 0.7821, Bottom 30th Acc: 0.3030
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.7948717948717948
29 0 [array([0.14432128, 0.3577254 , 0.1326925 , 0.20678966, 0.15847112],
      dtype=float32)]
Fold [2/5] Epoch [0/100] Initial Loss: 0.1335, Training Loss: 0.1335, Initial Validation Loss: 0.1276, Validation Loss: 0.1276,V Acc: 0.4955, Top 70th Acc: 0.6154, Bottom 30th Acc: 0.2121
Fold [2/5] Epoch [10/100] Initial Loss: 0.1335, Training Loss: 0.0817, Initial Validation Loss: 0.1276, Validation Loss: 0.0792,V Acc: 0.6486, Top 70th Acc: 0.7564, Bottom 30th Acc: 0.3939
Fold [2/5] Epoch [20/100] Initial Loss: 0.1335, Training Loss: 0.0797, Initial Validation Loss: 0.1276, Validation Loss: 0.0764,V Acc: 0.6667, Top 70th Acc: 0.7821, Bottom 30th Acc: 0.3939
Fold [2/5] Epoch [30/100] Initial Loss: 0.1335, Training Loss: 0.0789, Initial Validation Loss: 0.1276, Validation Loss: 0.0764,V Acc: 0.6486, Top 70th Acc: 0.7564, Bottom 30th Acc: 0.3939
Fold [2/5] Epoch [40/100] Initial Loss: 0.1335, Training Loss: 0.0783, Initial Validation Loss: 0.1276, Validation Loss: 0.0752,V Acc: 0.6396, Top 70th Acc: 0.7692, Bottom 30th Acc: 0.3333
Fold [2/5] Epoch [50/100] Initial Loss: 0.1335, Training Loss: 0.0782, Initial Validation Loss: 0.1276, Validation Loss: 0.0745,V Acc: 0.6577, Top 70th Acc: 0.7821, Bottom 30th Acc: 0.3636
Fold [2/5] Epoch [60/100] Initial Loss: 0.1335, Training Loss: 0.0780, Initial Validation Loss: 0.1276, Validation Loss: 0.0743,V Acc: 0.6577, Top 70th Acc: 0.7692, Bottom 30th Acc: 0.3939
Stopping early at Epoch (base 0): 61  Rolling back to Epoch (base 0): 56  Top Validation Acc: 0.7692307692307693
Fold [3/5] Epoch [0/100] Initial Loss: 0.1380, Training Loss: 0.1380, Initial Validation Loss: 0.1230, Validation Loss: 0.1230,V Acc: 0.3818, Top 70th Acc: 0.4675, Bottom 30th Acc: 0.1818
Fold [3/5] Epoch [10/100] Initial Loss: 0.1380, Training Loss: 0.0834, Initial Validation Loss: 0.1230, Validation Loss: 0.0717,V Acc: 0.6000, Top 70th Acc: 0.7143, Bottom 30th Acc: 0.3333
Fold [3/5] Epoch [20/100] Initial Loss: 0.1380, Training Loss: 0.0811, Initial Validation Loss: 0.1230, Validation Loss: 0.0693,V Acc: 0.6273, Top 70th Acc: 0.7532, Bottom 30th Acc: 0.3333
Fold [3/5] Epoch [30/100] Initial Loss: 0.1380, Training Loss: 0.0801, Initial Validation Loss: 0.1230, Validation Loss: 0.0699,V Acc: 0.6455, Top 70th Acc: 0.7532, Bottom 30th Acc: 0.3939
Stopping early at Epoch (base 0): 31  Rolling back to Epoch (base 0): 26  Top Validation Acc: 0.7532467532467533
Fold [4/5] Epoch [0/100] Initial Loss: 0.1358, Training Loss: 0.1358, Initial Validation Loss: 0.1269, Validation Loss: 0.1269,V Acc: 0.3455, Top 70th Acc: 0.4286, Bottom 30th Acc: 0.1515
Fold [4/5] Epoch [10/100] Initial Loss: 0.1358, Training Loss: 0.0794, Initial Validation Loss: 0.1269, Validation Loss: 0.0840,V Acc: 0.5909, Top 70th Acc: 0.7273, Bottom 30th Acc: 0.2727
Fold [4/5] Epoch [20/100] Initial Loss: 0.1358, Training Loss: 0.0774, Initial Validation Loss: 0.1269, Validation Loss: 0.0824,V Acc: 0.6091, Top 70th Acc: 0.7532, Bottom 30th Acc: 0.2727
Fold [4/5] Epoch [30/100] Initial Loss: 0.1358, Training Loss: 0.0766, Initial Validation Loss: 0.1269, Validation Loss: 0.0818,V Acc: 0.6273, Top 70th Acc: 0.7532, Bottom 30th Acc: 0.3333
Fold [4/5] Epoch [40/100] Initial Loss: 0.1358, Training Loss: 0.0763, Initial Validation Loss: 0.1269, Validation Loss: 0.0809,V Acc: 0.6182, Top 70th Acc: 0.7403, Bottom 30th Acc: 0.3333
Stopping early at Epoch (base 0): 49  Rolling back to Epoch (base 0): 44  Top Validation Acc: 0.7532467532467533
Fold [5/5] Epoch [0/100] Initial Loss: 0.1394, Training Loss: 0.1394, Initial Validation Loss: 0.1301, Validation Loss: 0.1301,V Acc: 0.4537, Top 70th Acc: 0.5526, Bottom 30th Acc: 0.2188
Fold [5/5] Epoch [10/100] Initial Loss: 0.1394, Training Loss: 0.0786, Initial Validation Loss: 0.1301, Validation Loss: 0.0861,V Acc: 0.6111, Top 70th Acc: 0.6842, Bottom 30th Acc: 0.4375
Fold [5/5] Epoch [20/100] Initial Loss: 0.1394, Training Loss: 0.0768, Initial Validation Loss: 0.1301, Validation Loss: 0.0845,V Acc: 0.6111, Top 70th Acc: 0.6842, Bottom 30th Acc: 0.4375
Fold [5/5] Epoch [30/100] Initial Loss: 0.1394, Training Loss: 0.0760, Initial Validation Loss: 0.1301, Validation Loss: 0.0843,V Acc: 0.6111, Top 70th Acc: 0.6842, Bottom 30th Acc: 0.4375
Fold [5/5] Epoch [40/100] Initial Loss: 0.1394, Training Loss: 0.0757, Initial Validation Loss: 0.1301, Validation Loss: 0.0841,V Acc: 0.5926, Top 70th Acc: 0.6842, Bottom 30th Acc: 0.3750
Stopping early at Epoch (base 0): 48  Rolling back to Epoch (base 0): 43  Top Validation Acc: 0.6842105263157895
Running train_nn.py with seed 30
CUDA:False
Training samples count:  550
Training on 2 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1268, Training Loss: 0.1268, Initial Validation Loss: 0.1196, Validation Loss: 0.1196,V Acc: 0.4685, Top 70th Acc: 0.4744, Bottom 30th Acc: 0.4545
Fold [1/5] Epoch [10/100] Initial Loss: 0.1268, Training Loss: 0.0828, Initial Validation Loss: 0.1196, Validation Loss: 0.0796,V Acc: 0.6486, Top 70th Acc: 0.7436, Bottom 30th Acc: 0.4242
Fold [1/5] Epoch [20/100] Initial Loss: 0.1268, Training Loss: 0.0808, Initial Validation Loss: 0.1196, Validation Loss: 0.0771,V Acc: 0.6667, Top 70th Acc: 0.7821, Bottom 30th Acc: 0.3939
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.782051282051282
Fold [2/5] Epoch [0/100] Initial Loss: 0.1385, Training Loss: 0.1385, Initial Validation Loss: 0.1331, Validation Loss: 0.1331,V Acc: 0.2703, Top 70th Acc: 0.3462, Bottom 30th Acc: 0.0909
Fold [2/5] Epoch [30/100] Initial Loss: 0.1336, Training Loss: 0.0229, Initial Validation Loss: 0.1254, Validation Loss: 0.0386,V Acc: 0.8018, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 38  Rolling back to Epoch (base 0): 33  Top Validation Acc: 0.8974358974358975
Fold [3/5] Epoch [0/100] Initial Loss: 0.1381, Training Loss: 0.1381, Initial Validation Loss: 0.1322, Validation Loss: 0.1322,V Acc: 0.2636, Top 70th Acc: 0.3117, Bottom 30th Acc: 0.1515
Fold [3/5] Epoch [10/100] Initial Loss: 0.1381, Training Loss: 0.0318, Initial Validation Loss: 0.1322, Validation Loss: 0.0400,V Acc: 0.7909, Top 70th Acc: 0.8961, Bottom 30th Acc: 0.5455
Fold [3/5] Epoch [20/100] Initial Loss: 0.1381, Training Loss: 0.0219, Initial Validation Loss: 0.1322, Validation Loss: 0.0355,V Acc: 0.8000, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.4545
Stopping early at Epoch (base 0): 21  Rolling back to Epoch (base 0): 16  Top Validation Acc: 0.935064935064935
Fold [4/5] Epoch [0/100] Initial Loss: 0.1369, Training Loss: 0.1369, Initial Validation Loss: 0.1335, Validation Loss: 0.1335,V Acc: 0.2545, Top 70th Acc: 0.3506, Bottom 30th Acc: 0.0303
Fold [4/5] Epoch [10/100] Initial Loss: 0.1369, Training Loss: 0.0305, Initial Validation Loss: 0.1335, Validation Loss: 0.0339,V Acc: 0.8545, Top 70th Acc: 0.8831, Bottom 30th Acc: 0.7879
Fold [4/5] Epoch [20/100] Initial Loss: 0.1369, Training Loss: 0.0229, Initial Validation Loss: 0.1335, Validation Loss: 0.0302,V Acc: 0.8455, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.922077922077922
Fold [5/5] Epoch [0/100] Initial Loss: 0.1362, Training Loss: 0.1362, Initial Validation Loss: 0.1321, Validation Loss: 0.1321,V Acc: 0.3333, Top 70th Acc: 0.3816, Bottom 30th Acc: 0.2188
Fold [5/5] Epoch [10/100] Initial Loss: 0.1362, Training Loss: 0.0362, Initial Validation Loss: 0.1321, Validation Loss: 0.0399,V Acc: 0.8426, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.5625
Fold [5/5] Epoch [20/100] Initial Loss: 0.1362, Training Loss: 0.0234, Initial Validation Loss: 0.1321, Validation Loss: 0.0336,V Acc: 0.8333, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.5938
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.9473684210526315
30 4 [array([0.21377796, 0.09145346, 0.36874273, 0.19422211, 0.13180374],
      dtype=float32)]
Running train_nn.py with seed 31
CUDA:False
Training samples count:  550
Training on 20 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1374, Training Loss: 0.1374, Initial Validation Loss: 0.1338, Validation Loss: 0.1338,V Acc: 0.3333, Top 70th Acc: 0.3974, Bottom 30th Acc: 0.1818
Fold [1/5] Epoch [10/100] Initial Loss: 0.1374, Training Loss: 0.0357, Initial Validation Loss: 0.1338, Validation Loss: 0.0443,V Acc: 0.8108, Top 70th Acc: 0.8846, Bottom 30th Acc: 0.6364
Fold [1/5] Epoch [20/100] Initial Loss: 0.1374, Training Loss: 0.0230, Initial Validation Loss: 0.1338, Validation Loss: 0.0391,V Acc: 0.8378, Top 70th Acc: 0.8718, Bottom 30th Acc: 0.7576
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.8846153846153846
31 0 [array([0.37320045, 0.06707124, 0.1821326 , 0.21637432, 0.16122133],
      dtype=float32)]
Fold [2/5] Epoch [0/100] Initial Loss: 0.1380, Training Loss: 0.1380, Initial Validation Loss: 0.1300, Validation Loss: 0.1300,V Acc: 0.3063, Top 70th Acc: 0.3718, Bottom 30th Acc: 0.1515
Fold [2/5] Epoch [10/100] Initial Loss: 0.1380, Training Loss: 0.0329, Initial Validation Loss: 0.1300, Validation Loss: 0.0309,V Acc: 0.8378, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.5152
Stopping early at Epoch (base 0): 19  Rolling back to Epoch (base 0): 14  Top Validation Acc: 0.9743589743589743
Fold [3/5] Epoch [0/100] Initial Loss: 0.1389, Training Loss: 0.1389, Initial Validation Loss: 0.1358, Validation Loss: 0.1358,V Acc: 0.2545, Top 70th Acc: 0.3506, Bottom 30th Acc: 0.0303
Fold [3/5] Epoch [10/100] Initial Loss: 0.1389, Training Loss: 0.0324, Initial Validation Loss: 0.1358, Validation Loss: 0.0387,V Acc: 0.8455, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.6970
Fold [3/5] Epoch [20/100] Initial Loss: 0.1389, Training Loss: 0.0244, Initial Validation Loss: 0.1358, Validation Loss: 0.0338,V Acc: 0.8727, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.7879
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.8961038961038961
Fold [4/5] Epoch [0/100] Initial Loss: 0.1385, Training Loss: 0.1385, Initial Validation Loss: 0.1357, Validation Loss: 0.1357,V Acc: 0.2545, Top 70th Acc: 0.3117, Bottom 30th Acc: 0.1212
Fold [4/5] Epoch [10/100] Initial Loss: 0.1385, Training Loss: 0.0355, Initial Validation Loss: 0.1357, Validation Loss: 0.0413,V Acc: 0.8091, Top 70th Acc: 0.8961, Bottom 30th Acc: 0.6061
Fold [4/5] Epoch [20/100] Initial Loss: 0.1385, Training Loss: 0.0240, Initial Validation Loss: 0.1357, Validation Loss: 0.0356,V Acc: 0.8455, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.922077922077922
Fold [5/5] Epoch [0/100] Initial Loss: 0.1455, Training Loss: 0.1455, Initial Validation Loss: 0.1349, Validation Loss: 0.1349,V Acc: 0.3426, Top 70th Acc: 0.4211, Bottom 30th Acc: 0.1562
Fold [5/5] Epoch [10/100] Initial Loss: 0.1455, Training Loss: 0.0460, Initial Validation Loss: 0.1349, Validation Loss: 0.0462,V Acc: 0.8056, Top 70th Acc: 0.8947, Bottom 30th Acc: 0.5938
Fold [5/5] Epoch [20/100] Initial Loss: 0.1455, Training Loss: 0.0240, Initial Validation Loss: 0.1349, Validation Loss: 0.0321,V Acc: 0.8519, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.6250
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.9473684210526315
Running train_nn.py with seed 32
CUDA:False
Training samples count:  550
Training on 20 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1404, Training Loss: 0.1404, Initial Validation Loss: 0.1382, Validation Loss: 0.1382,V Acc: 0.2613, Top 70th Acc: 0.3077, Bottom 30th Acc: 0.1515
Fold [1/5] Epoch [10/100] Initial Loss: 0.1404, Training Loss: 0.0367, Initial Validation Loss: 0.1382, Validation Loss: 0.0407,V Acc: 0.8378, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.6061
Fold [1/5] Epoch [20/100] Initial Loss: 0.1404, Training Loss: 0.0231, Initial Validation Loss: 0.1382, Validation Loss: 0.0327,V Acc: 0.8649, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.7576
Stopping early at Epoch (base 0): 29  Rolling back to Epoch (base 0): 24  Top Validation Acc: 0.9102564102564102
Fold [2/5] Epoch [0/100] Initial Loss: 0.1381, Training Loss: 0.1381, Initial Validation Loss: 0.1359, Validation Loss: 0.1359,V Acc: 0.2613, Top 70th Acc: 0.3590, Bottom 30th Acc: 0.0303
Fold [2/5] Epoch [10/100] Initial Loss: 0.1381, Training Loss: 0.0408, Initial Validation Loss: 0.1359, Validation Loss: 0.0455,V Acc: 0.7748, Top 70th Acc: 0.8718, Bottom 30th Acc: 0.5455
Fold [2/5] Epoch [20/100] Initial Loss: 0.1381, Training Loss: 0.0240, Initial Validation Loss: 0.1359, Validation Loss: 0.0323,V Acc: 0.8288, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 28  Rolling back to Epoch (base 0): 23  Top Validation Acc: 0.9615384615384616
Fold [3/5] Epoch [0/100] Initial Loss: 0.1371, Training Loss: 0.1371, Initial Validation Loss: 0.1287, Validation Loss: 0.1287,V Acc: 0.3455, Top 70th Acc: 0.3896, Bottom 30th Acc: 0.2424
Fold [3/5] Epoch [10/100] Initial Loss: 0.1371, Training Loss: 0.0340, Initial Validation Loss: 0.1287, Validation Loss: 0.0390,V Acc: 0.8273, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 19  Rolling back to Epoch (base 0): 14  Top Validation Acc: 0.8961038961038961
32 2 [array([0.31269678, 0.11173047, 0.1323739 , 0.22874962, 0.2144493 ],
      dtype=float32)]
Fold [4/5] Epoch [0/100] Initial Loss: 0.1409, Training Loss: 0.1409, Initial Validation Loss: 0.1352, Validation Loss: 0.1352,V Acc: 0.2909, Top 70th Acc: 0.3636, Bottom 30th Acc: 0.1212
Fold [4/5] Epoch [10/100] Initial Loss: 0.1409, Training Loss: 0.0412, Initial Validation Loss: 0.1352, Validation Loss: 0.0522,V Acc: 0.7545, Top 70th Acc: 0.8442, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 40  Rolling back to Epoch (base 0): 35  Top Validation Acc: 0.9358974358974359
Fold [3/5] Epoch [0/100] Initial Loss: 0.1398, Training Loss: 0.1398, Initial Validation Loss: 0.1328, Validation Loss: 0.1328,V Acc: 0.2818, Top 70th Acc: 0.2727, Bottom 30th Acc: 0.3030
Fold [3/5] Epoch [10/100] Initial Loss: 0.1398, Training Loss: 0.0362, Initial Validation Loss: 0.1328, Validation Loss: 0.0358,V Acc: 0.8091, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.4848
Fold [3/5] Epoch [20/100] Initial Loss: 0.1398, Training Loss: 0.0161, Initial Validation Loss: 0.1328, Validation Loss: 0.0249,V Acc: 0.8636, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.6970
Fold [3/5] Epoch [30/100] Initial Loss: 0.1398, Training Loss: 0.0127, Initial Validation Loss: 0.1328, Validation Loss: 0.0242,V Acc: 0.8727, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 33  Rolling back to Epoch (base 0): 28  Top Validation Acc: 0.961038961038961
Fold [4/5] Epoch [0/100] Initial Loss: 0.1381, Training Loss: 0.1381, Initial Validation Loss: 0.1323, Validation Loss: 0.1323,V Acc: 0.3364, Top 70th Acc: 0.4026, Bottom 30th Acc: 0.1818
Fold [4/5] Epoch [10/100] Initial Loss: 0.1381, Training Loss: 0.0357, Initial Validation Loss: 0.1323, Validation Loss: 0.0378,V Acc: 0.8000, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.4545
Stopping early at Epoch (base 0): 19  Rolling back to Epoch (base 0): 14  Top Validation Acc: 0.948051948051948
Fold [5/5] Epoch [0/100] Initial Loss: 0.1408, Training Loss: 0.1408, Initial Validation Loss: 0.1333, Validation Loss: 0.1333,V Acc: 0.3148, Top 70th Acc: 0.3421, Bottom 30th Acc: 0.2500
Fold [5/5] Epoch [10/100] Initial Loss: 0.1408, Training Loss: 0.0305, Initial Validation Loss: 0.1333, Validation Loss: 0.0426,V Acc: 0.7778, Top 70th Acc: 0.8816, Bottom 30th Acc: 0.5312
Fold [5/5] Epoch [20/100] Initial Loss: 0.1408, Training Loss: 0.0148, Initial Validation Loss: 0.1333, Validation Loss: 0.0367,V Acc: 0.7778, Top 70th Acc: 0.9211, Bottom 30th Acc: 0.4375
Stopping early at Epoch (base 0): 20  Rolling back to Epoch (base 0): 15  Top Validation Acc: 0.9210526315789473
Running train_nn.py with seed 30
CUDA:False
Training samples count:  550
Training on 40 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1382, Training Loss: 0.1382, Initial Validation Loss: 0.1369, Validation Loss: 0.1369,V Acc: 0.3063, Top 70th Acc: 0.2949, Bottom 30th Acc: 0.3333
Fold [1/5] Epoch [10/100] Initial Loss: 0.1382, Training Loss: 0.0353, Initial Validation Loss: 0.1369, Validation Loss: 0.0451,V Acc: 0.7838, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.4848
Fold [1/5] Epoch [20/100] Initial Loss: 0.1382, Training Loss: 0.0138, Initial Validation Loss: 0.1369, Validation Loss: 0.0313,V Acc: 0.8378, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.5455
Fold [1/5] Epoch [30/100] Initial Loss: 0.1382, Training Loss: 0.0115, Initial Validation Loss: 0.1369, Validation Loss: 0.0299,V Acc: 0.8378, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 31  Rolling back to Epoch (base 0): 26  Top Validation Acc: 0.9615384615384616
Fold [2/5] Epoch [0/100] Initial Loss: 0.1399, Training Loss: 0.1399, Initial Validation Loss: 0.1352, Validation Loss: 0.1352,V Acc: 0.2793, Top 70th Acc: 0.3205, Bottom 30th Acc: 0.1818
Fold [2/5] Epoch [10/100] Initial Loss: 0.1399, Training Loss: 0.0284, Initial Validation Loss: 0.1352, Validation Loss: 0.0384,V Acc: 0.7928, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.4545
Fold [2/5] Epoch [20/100] Initial Loss: 0.1399, Training Loss: 0.0145, Initial Validation Loss: 0.1352, Validation Loss: 0.0285,V Acc: 0.8378, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 28  Rolling back to Epoch (base 0): 23  Top Validation Acc: 0.9615384615384616
Fold [3/5] Epoch [0/100] Initial Loss: 0.1378, Training Loss: 0.1378, Initial Validation Loss: 0.1315, Validation Loss: 0.1315,V Acc: 0.3818, Top 70th Acc: 0.4286, Bottom 30th Acc: 0.2727
Fold [3/5] Epoch [10/100] Initial Loss: 0.1378, Training Loss: 0.0379, Initial Validation Loss: 0.1315, Validation Loss: 0.0385,V Acc: 0.8273, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.6061
Fold [3/5] Epoch [20/100] Initial Loss: 0.1378, Training Loss: 0.0138, Initial Validation Loss: 0.1315, Validation Loss: 0.0287,V Acc: 0.8636, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 21  Rolling back to Epoch (base 0): 16  Top Validation Acc: 0.935064935064935
Fold [4/5] Epoch [0/100] Initial Loss: 0.1411, Training Loss: 0.1411, Initial Validation Loss: 0.1351, Validation Loss: 0.1351,V Acc: 0.2545, Top 70th Acc: 0.3117, Bottom 30th Acc: 0.1212
Fold [4/5] Epoch [10/100] Initial Loss: 0.1411, Training Loss: 0.0319, Initial Validation Loss: 0.1351, Validation Loss: 0.0392,V Acc: 0.8000, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.5152
Fold [4/5] Epoch [20/100] Initial Loss: 0.1411, Training Loss: 0.0153, Initial Validation Loss: 0.1351, Validation Loss: 0.0282,V Acc: 0.8364, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.5455
Fold [4/5] Epoch [30/100] Initial Loss: 0.1411, Training Loss: 0.0126, Initial Validation Loss: 0.1351, Validation Loss: 0.0267,V Acc: 0.8455, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 34  Rolling back to Epoch (base 0): 29  Top Validation Acc: 0.961038961038961
Fold [5/5] Epoch [0/100] Initial Loss: 0.1381, Training Loss: 0.1381, Initial Validation Loss: 0.1333, Validation Loss: 0.1333,V Acc: 0.2870, Top 70th Acc: 0.3684, Bottom 30th Acc: 0.0938
Fold [5/5] Epoch [10/100] Initial Loss: 0.1381, Training Loss: 0.0298, Initial Validation Loss: 0.1333, Validation Loss: 0.0356,V Acc: 0.8611, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.6562
Fold [5/5] Epoch [20/100] Initial Loss: 0.1381, Training Loss: 0.0140, Initial Validation Loss: 0.1333, Validation Loss: 0.0259,V Acc: 0.8981, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.7812
Fold [5/5] Epoch [30/100] Initial Loss: 0.1381, Training Loss: 0.0118, Initial Validation Loss: 0.1333, Validation Loss: 0.0265,V Acc: 0.9167, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.8125
Stopping early at Epoch (base 0): 32  Rolling back to Epoch (base 0): 27  Top Validation Acc: 0.9605263157894737
30 4 [array([0.7213421 , 0.03411864, 0.07411178, 0.06380872, 0.10661893],
      dtype=float32)]
Running train_nn.py with seed 31
CUDA:False
Training samples count:  550
Training on 40 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1405, Training Loss: 0.1405, Initial Validation Loss: 0.1370, Validation Loss: 0.1370,V Acc: 0.2703, Top 70th Acc: 0.2564, Bottom 30th Acc: 0.3030
Fold [1/5] Epoch [10/100] Initial Loss: 0.1405, Training Loss: 0.0448, Initial Validation Loss: 0.1370, Validation Loss: 0.0504,V Acc: 0.7297, Top 70th Acc: 0.8974, Bottom 30th Acc: 0.3333
Fold [1/5] Epoch [20/100] Initial Loss: 0.1405, Training Loss: 0.0167, Initial Validation Loss: 0.1370, Validation Loss: 0.0320,V Acc: 0.8198, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.4848
Fold [1/5] Epoch [30/100] Initial Loss: 0.1405, Training Loss: 0.0124, Initial Validation Loss: 0.1370, Validation Loss: 0.0287,V Acc: 0.8108, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.4545
Stopping early at Epoch (base 0): 32  Rolling back to Epoch (base 0): 27  Top Validation Acc: 0.9615384615384616
31 0 [array([0.4795269 , 0.0917235 , 0.097982  , 0.06819534, 0.26257214],
      dtype=float32)]
Fold [2/5] Epoch [0/100] Initial Loss: 0.1370, Training Loss: 0.1370, Initial Validation Loss: 0.1266, Validation Loss: 0.1266,V Acc: 0.3874, Top 70th Acc: 0.5256, Bottom 30th Acc: 0.0606
Fold [2/5] Epoch [10/100] Initial Loss: 0.1370, Training Loss: 0.0260, Initial Validation Loss: 0.1266, Validation Loss: 0.0281,V Acc: 0.8739, Top 70th Acc: 0.9872, Bottom 30th Acc: 0.6061
Fold [2/5] Epoch [20/100] Initial Loss: 0.1370, Training Loss: 0.0153, Initial Validation Loss: 0.1266, Validation Loss: 0.0232,V Acc: 0.8829, Top 70th Acc: 0.9872, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 27  Rolling back to Epoch (base 0): 22  Top Validation Acc: 0.9871794871794872
Fold [3/5] Epoch [0/100] Initial Loss: 0.1389, Training Loss: 0.1389, Initial Validation Loss: 0.1374, Validation Loss: 0.1374,V Acc: 0.2545, Top 70th Acc: 0.2208, Bottom 30th Acc: 0.3333
Fold [1/5] Epoch [20/100] Initial Loss: 0.1349, Training Loss: 0.0174, Initial Validation Loss: 0.1338, Validation Loss: 0.0340,V Acc: 0.8198, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.4848
Fold [1/5] Epoch [30/100] Initial Loss: 0.1349, Training Loss: 0.0153, Initial Validation Loss: 0.1338, Validation Loss: 0.0328,V Acc: 0.8288, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 30  Rolling back to Epoch (base 0): 25  Top Validation Acc: 0.9358974358974359
Fold [2/5] Epoch [0/100] Initial Loss: 0.1384, Training Loss: 0.1384, Initial Validation Loss: 0.1346, Validation Loss: 0.1346,V Acc: 0.3514, Top 70th Acc: 0.3590, Bottom 30th Acc: 0.3333
Fold [2/5] Epoch [10/100] Initial Loss: 0.1384, Training Loss: 0.0280, Initial Validation Loss: 0.1346, Validation Loss: 0.0336,V Acc: 0.8198, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.5455
Fold [2/5] Epoch [20/100] Initial Loss: 0.1384, Training Loss: 0.0178, Initial Validation Loss: 0.1346, Validation Loss: 0.0296,V Acc: 0.8198, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.5152
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.9615384615384616
Fold [3/5] Epoch [0/100] Initial Loss: 0.1407, Training Loss: 0.1407, Initial Validation Loss: 0.1309, Validation Loss: 0.1309,V Acc: 0.4091, Top 70th Acc: 0.4416, Bottom 30th Acc: 0.3333
Fold [3/5] Epoch [10/100] Initial Loss: 0.1407, Training Loss: 0.0244, Initial Validation Loss: 0.1309, Validation Loss: 0.0331,V Acc: 0.8091, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.4545
Fold [3/5] Epoch [20/100] Initial Loss: 0.1407, Training Loss: 0.0156, Initial Validation Loss: 0.1309, Validation Loss: 0.0308,V Acc: 0.8364, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 21  Rolling back to Epoch (base 0): 16  Top Validation Acc: 0.974025974025974
Fold [4/5] Epoch [0/100] Initial Loss: 0.1402, Training Loss: 0.1402, Initial Validation Loss: 0.1326, Validation Loss: 0.1326,V Acc: 0.3364, Top 70th Acc: 0.3766, Bottom 30th Acc: 0.2424
Fold [4/5] Epoch [10/100] Initial Loss: 0.1402, Training Loss: 0.0283, Initial Validation Loss: 0.1326, Validation Loss: 0.0301,V Acc: 0.8818, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.6970
Fold [4/5] Epoch [20/100] Initial Loss: 0.1402, Training Loss: 0.0190, Initial Validation Loss: 0.1326, Validation Loss: 0.0251,V Acc: 0.8909, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.935064935064935
Fold [5/5] Epoch [0/100] Initial Loss: 0.1361, Training Loss: 0.1361, Initial Validation Loss: 0.1306, Validation Loss: 0.1306,V Acc: 0.3148, Top 70th Acc: 0.3289, Bottom 30th Acc: 0.2812
Fold [5/5] Epoch [10/100] Initial Loss: 0.1361, Training Loss: 0.0403, Initial Validation Loss: 0.1306, Validation Loss: 0.0475,V Acc: 0.7963, Top 70th Acc: 0.8816, Bottom 30th Acc: 0.5938
Fold [5/5] Epoch [20/100] Initial Loss: 0.1361, Training Loss: 0.0203, Initial Validation Loss: 0.1306, Validation Loss: 0.0298,V Acc: 0.8611, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.6250
Fold [5/5] Epoch [30/100] Initial Loss: 0.1361, Training Loss: 0.0165, Initial Validation Loss: 0.1306, Validation Loss: 0.0266,V Acc: 0.8704, Top 70th Acc: 0.9868, Bottom 30th Acc: 0.5938
Stopping early at Epoch (base 0): 33  Rolling back to Epoch (base 0): 28  Top Validation Acc: 0.9736842105263158
30 4 [array([0.6485555 , 0.1115592 , 0.03661277, 0.06227565, 0.14099675],
      dtype=float32)]
Running train_nn.py with seed 31
CUDA:False
Training samples count:  550
Training on 30 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1388, Training Loss: 0.1388, Initial Validation Loss: 0.1358, Validation Loss: 0.1358,V Acc: 0.2613, Top 70th Acc: 0.2821, Bottom 30th Acc: 0.2121
Fold [1/5] Epoch [10/100] Initial Loss: 0.1388, Training Loss: 0.0286, Initial Validation Loss: 0.1358, Validation Loss: 0.0343,V Acc: 0.8378, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.6364
Fold [1/5] Epoch [20/100] Initial Loss: 0.1388, Training Loss: 0.0181, Initial Validation Loss: 0.1358, Validation Loss: 0.0307,V Acc: 0.8559, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.9615384615384616
31 0 [array([0.5520813 , 0.10904317, 0.0740947 , 0.10217989, 0.16260093],
      dtype=float32)]
Fold [2/5] Epoch [0/100] Initial Loss: 0.1404, Training Loss: 0.1404, Initial Validation Loss: 0.1329, Validation Loss: 0.1329,V Acc: 0.2703, Top 70th Acc: 0.3462, Bottom 30th Acc: 0.0909
Fold [2/5] Epoch [10/100] Initial Loss: 0.1404, Training Loss: 0.0322, Initial Validation Loss: 0.1329, Validation Loss: 0.0325,V Acc: 0.8468, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.5758
Fold [2/5] Epoch [20/100] Initial Loss: 0.1404, Training Loss: 0.0202, Initial Validation Loss: 0.1329, Validation Loss: 0.0230,V Acc: 0.9279, Top 70th Acc: 0.9872, Bottom 30th Acc: 0.7879
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.9615384615384616
Fold [3/5] Epoch [0/100] Initial Loss: 0.1359, Training Loss: 0.1359, Initial Validation Loss: 0.1342, Validation Loss: 0.1342,V Acc: 0.3909, Top 70th Acc: 0.4675, Bottom 30th Acc: 0.2121
Fold [3/5] Epoch [10/100] Initial Loss: 0.1359, Training Loss: 0.0299, Initial Validation Loss: 0.1342, Validation Loss: 0.0431,V Acc: 0.8273, Top 70th Acc: 0.8831, Bottom 30th Acc: 0.6970
Fold [3/5] Epoch [20/100] Initial Loss: 0.1359, Training Loss: 0.0188, Initial Validation Loss: 0.1342, Validation Loss: 0.0367,V Acc: 0.8273, Top 70th Acc: 0.8961, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.9090909090909091
Fold [4/5] Epoch [0/100] Initial Loss: 0.1370, Training Loss: 0.1370, Initial Validation Loss: 0.1334, Validation Loss: 0.1334,V Acc: 0.2545, Top 70th Acc: 0.3377, Bottom 30th Acc: 0.0606
Fold [4/5] Epoch [10/100] Initial Loss: 0.1370, Training Loss: 0.0314, Initial Validation Loss: 0.1334, Validation Loss: 0.0410,V Acc: 0.7909, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.5152
Fold [4/5] Epoch [20/100] Initial Loss: 0.1370, Training Loss: 0.0183, Initial Validation Loss: 0.1334, Validation Loss: 0.0348,V Acc: 0.8364, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.6667
Fold [4/5] Epoch [30/100] Initial Loss: 0.1370, Training Loss: 0.0160, Initial Validation Loss: 0.1334, Validation Loss: 0.0346,V Acc: 0.8455, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 33  Rolling back to Epoch (base 0): 28  Top Validation Acc: 0.922077922077922
Fold [5/5] Epoch [0/100] Initial Loss: 0.1405, Training Loss: 0.1405, Initial Validation Loss: 0.1349, Validation Loss: 0.1349,V Acc: 0.1204, Top 70th Acc: 0.1447, Bottom 30th Acc: 0.0625
Fold [5/5] Epoch [10/100] Initial Loss: 0.1405, Training Loss: 0.0345, Initial Validation Loss: 0.1349, Validation Loss: 0.0380,V Acc: 0.8148, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.5000
Fold [5/5] Epoch [20/100] Initial Loss: 0.1405, Training Loss: 0.0184, Initial Validation Loss: 0.1349, Validation Loss: 0.0329,V Acc: 0.8241, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.5625
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.9342105263157895
Running train_nn.py with seed 32
CUDA:False
Training samples count:  550
Training on 30 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1375, Training Loss: 0.1375, Initial Validation Loss: 0.1370, Validation Loss: 0.1370,V Acc: 0.3514, Top 70th Acc: 0.3846, Bottom 30th Acc: 0.2727
Fold [1/5] Epoch [10/100] Initial Loss: 0.1375, Training Loss: 0.0310, Initial Validation Loss: 0.1370, Validation Loss: 0.0356,V Acc: 0.8468, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.5455
Fold [1/5] Epoch [20/100] Initial Loss: 0.1375, Training Loss: 0.0180, Initial Validation Loss: 0.1370, Validation Loss: 0.0289,V Acc: 0.8649, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.6667
Fold [1/5] Epoch [30/100] Initial Loss: 0.1375, Training Loss: 0.0151, Initial Validation Loss: 0.1370, Validation Loss: 0.0292,V Acc: 0.8468, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 30  Rolling back to Epoch (base 0): 25  Top Validation Acc:
Stopping early at Epoch (base 0): 69  Rolling back to Epoch (base 0): 64  Top Validation Acc: 0.9210526315789473
Running train_nn.py with seed 24
CUDA:False
Training samples count:  550
Training on 163 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1392, Training Loss: 0.1392, Initial Validation Loss: 0.1405, Validation Loss: 0.1405,V Acc: 0.3874, Top 70th Acc: 0.3974, Bottom 30th Acc: 0.3636
Fold [1/5] Epoch [10/100] Initial Loss: 0.1392, Training Loss: 0.0140, Initial Validation Loss: 0.1405, Validation Loss: 0.0320,V Acc: 0.8468, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.5455
Fold [1/5] Epoch [20/100] Initial Loss: 0.1392, Training Loss: 0.0044, Initial Validation Loss: 0.1405, Validation Loss: 0.0274,V Acc: 0.8739, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.6667
Fold [1/5] Epoch [30/100] Initial Loss: 0.1392, Training Loss: 0.0035, Initial Validation Loss: 0.1405, Validation Loss: 0.0274,V Acc: 0.8649, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 32  Rolling back to Epoch (base 0): 27  Top Validation Acc: 0.9615384615384616
Fold [2/5] Epoch [0/100] Initial Loss: 0.1404, Training Loss: 0.1404, Initial Validation Loss: 0.1320, Validation Loss: 0.1320,V Acc: 0.2973, Top 70th Acc: 0.3462, Bottom 30th Acc: 0.1818
Fold [2/5] Epoch [10/100] Initial Loss: 0.1404, Training Loss: 0.0197, Initial Validation Loss: 0.1320, Validation Loss: 0.0457,V Acc: 0.7748, Top 70th Acc: 0.8846, Bottom 30th Acc: 0.5152
Fold [2/5] Epoch [20/100] Initial Loss: 0.1404, Training Loss: 0.0049, Initial Validation Loss: 0.1320, Validation Loss: 0.0365,V Acc: 0.8288, Top 70th Acc: 0.8974, Bottom 30th Acc: 0.6667
Fold [2/5] Epoch [30/100] Initial Loss: 0.1404, Training Loss: 0.0038, Initial Validation Loss: 0.1320, Validation Loss: 0.0352,V Acc: 0.8468, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 37  Rolling back to Epoch (base 0): 32  Top Validation Acc: 0.9358974358974359
Fold [3/5] Epoch [0/100] Initial Loss: 0.1394, Training Loss: 0.1394, Initial Validation Loss: 0.1336, Validation Loss: 0.1336,V Acc: 0.2545, Top 70th Acc: 0.2987, Bottom 30th Acc: 0.1515
Fold [3/5] Epoch [10/100] Initial Loss: 0.1394, Training Loss: 0.0221, Initial Validation Loss: 0.1336, Validation Loss: 0.0418,V Acc: 0.7545, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.3636
Stopping early at Epoch (base 0): 18  Rolling back to Epoch (base 0): 13  Top Validation Acc: 0.935064935064935
24 2 [array([0.22376195, 0.14450493, 0.09045133, 0.15317847, 0.38810337],
      dtype=float32)]
Fold [4/5] Epoch [0/100] Initial Loss: 0.1395, Training Loss: 0.1395, Initial Validation Loss: 0.1375, Validation Loss: 0.1375,V Acc: 0.2636, Top 70th Acc: 0.3636, Bottom 30th Acc: 0.0303
Fold [4/5] Epoch [10/100] Initial Loss: 0.1395, Training Loss: 0.0147, Initial Validation Loss: 0.1375, Validation Loss: 0.0308,V Acc: 0.8636, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.6061
Fold [4/5] Epoch [20/100] Initial Loss: 0.1395, Training Loss: 0.0044, Initial Validation Loss: 0.1375, Validation Loss: 0.0251,V Acc: 0.8909, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.7273
Stopping early at Epoch (base 0): 29  Rolling back to Epoch (base 0): 24  Top Validation Acc: 0.974025974025974
Fold [5/5] Epoch [0/100] Initial Loss: 0.1391, Training Loss: 0.1391, Initial Validation Loss: 0.1301, Validation Loss: 0.1301,V Acc: 0.2685, Top 70th Acc: 0.3289, Bottom 30th Acc: 0.1250
Fold [5/5] Epoch [10/100] Initial Loss: 0.1391, Training Loss: 0.0260, Initial Validation Loss: 0.1301, Validation Loss: 0.0351,V Acc: 0.8426, Top 70th Acc: 0.9211, Bottom 30th Acc: 0.6562
Fold [5/5] Epoch [20/100] Initial Loss: 0.1391, Training Loss: 0.0055, Initial Validation Loss: 0.1301, Validation Loss: 0.0221,V Acc: 0.8889, Top 70th Acc: 0.9737, Bottom 30th Acc: 0.6875
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.9736842105263158
Running train_nn.py with seed 25
CUDA:False
Training samples count:  550
Training on 163 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1416, Training Loss: 0.1416, Initial Validation Loss: 0.1359, Validation Loss: 0.1359,V Acc: 0.2523, Top 70th Acc: 0.3462, Bottom 30th Acc: 0.0303
Fold [1/5] Epoch [10/100] Initial Loss: 0.1416, Training Loss: 0.0124, Initial Validation Loss: 0.1359, Validation Loss: 0.0295,V Acc: 0.8288, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.5758
Fold [1/5] Epoch [20/100] Initial Loss: 0.1416, Training Loss: 0.0047, Initial Validation Loss: 0.1359, Validation Loss: 0.0260,V Acc: 0.8739, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.7273
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.9487179487179487
Fold [2/5] Epoch [0/100] Initial Loss: 0.1404, Training Loss: 0.1404, Initial Validation Loss: 0.1391, Validation Loss: 0.1391,V Acc: 0.2523, Top 70th Acc: 0.3590, Bottom 30th Acc: 0.0000
Fold [2/5] Epoch [10/100] Initial Loss: 0.1404, Training Loss: 0.0175, Initial Validation Loss: 0.1391, Validation Loss: 0.0311,V Acc: 0.8829, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.6667
Fold [2/5] Epoch [20/100] Initial Loss: 0.1404, Training Loss: 0.0048, Initial Validation Loss: 0.1391, Validation Loss: 0.0263,V Acc: 0.8829, Top 70th Acc: 0.9872, Bottom 30th Acc: 0.6364
Fold [2/5] Epoch [30/100] Initial Loss: 0.1404, Training Loss: 0.0037, Initial Validation Loss: 0.1391, Validation Loss: 0.0252,V Acc: 0.8919, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 36  Rolling back to Epoch (base 0): 31  Top Validation Acc: 0.9743589743589743
Fold [3/5] Epoch [0/100] Initial Loss: 0.1391, Training Loss: 0.1391, Initial Validation Loss: 0.1312, Validation Loss: 0.1312,V Acc: 0.2545, Top 70th Acc: 0.3506, Bottom 30th Acc: 0.0303
Fold [3/5] Epoch [10/100] Initial Loss: 0.1391, Training Loss: 0.0309, Initial Validation Loss: 0.1312, Validation Loss: 0.0451,V Acc: 0.7727, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.3939
Fold [3/5] Epoch [20/100] Initial Loss: 0.1391, Training Loss: 0.0069, Initial Validation Loss: 0.1312, Validation Loss: 0.0290,V Acc: 0.8636, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6667
Fold [3/5] Epoch [30/100] Initial Loss: 0.1391, Training Loss: 0.0041, Initial Validation Loss: 0.1312, Validation Loss: 0.0282,V Acc: 0.8636, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 32  Rolling back to Epoch (base 0): 27  Top Validation Acc: 0.935064935064935
Fold [4/5] Epoch [0/100] Initial Loss: 0.1425, Training Loss: 0.1425, Initial Validation Loss: 0.1366, Validation Loss: 0.1366,V Acc: 0.3364, Top 70th Acc: 0.3766, Bottom 30th Acc: 0.2424
Fold [4/5] Epoch [10/100] Initial Loss: 0.1425, Training Loss: 0.0312, Initial Validation Loss: 0.1366, Validation Loss: 0.0443,V Acc: 0.8091, Top 70th Acc: 0.8831, Bottom 30th Acc: 0.6364
Fold [4/5] Epoch [20/100] Initial Loss: 0.1425, Training Loss: 0.0067, Initial Validation Loss: 0.1366, Validation Loss: 0.0289,V Acc: 0.8909, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.7273
Fold [4/5] Epoch [30/100] Initial Loss: 0.1425, Training Loss: 0.0043, Initial Validation Loss: 0.1366, Validation Loss: 0.0271,V Acc: 0.8909, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.7576
Fold [4/5] Epoch [40/100] Initial Loss: 0.1425, Training Loss: 0.0038, Initial Validation Loss: 0.1366, Validation Loss: 0.0258,V Acc: 0.9091, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.7576
Fold [4/5] Epoch [50/100] Initial Loss: 0.1425, Training Loss: 0.0036, Initial Validation Loss: 0.1366, Validation Loss: 0.0261,V Acc: 0.9000, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.7576
Stopping early at Epoch (base 0): 51  Rolling back to Epoch (base 0): 46  Top Validation Acc: 0.961038961038961
25 3 [array([0.4270319 , 0.06657978, 0.09634899, 0.18042247, 0.2296168 ],
      dtype=float32)]
Fold [5/5] Epoch [0/100] Initial Loss: 0.1384, Training Loss: 0.1384, Initial Validation Loss: 0.1316, Validation Loss: 0.1316,V Acc: 0.2500, Top 70th Acc: 0.3026, Bottom 30th Acc: 0.1250
Fold [5/5] Epoch [10/100] Initial Loss: 0.1384, Training Loss: 0.0251, Initial Validation Loss: 0.1316, Validation Loss: 0.0370,V Acc: 0.8333, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.5625
Fold [5/5] Epoch [20/100] Initial Loss: 0.1384, Training Loss: 0.0053, Initial Validation Loss: 0.1316, Validation Loss: 0.0222,V Acc: 0.9074, Top 70th Acc: 0.9868, Bottom 30th Acc: 0.7188/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
0.922077922077922
Fold [5/5] Epoch [0/100] Initial Loss: 0.1296, Training Loss: 0.1296, Initial Validation Loss: 0.1176, Validation Loss: 0.1176,V Acc: 0.4815, Top 70th Acc: 0.5921, Bottom 30th Acc: 0.2188
Fold [5/5] Epoch [10/100] Initial Loss: 0.1296, Training Loss: 0.0260, Initial Validation Loss: 0.1176, Validation Loss: 0.0246,V Acc: 0.8796, Top 70th Acc: 0.9868, Bottom 30th Acc: 0.6250
Fold [5/5] Epoch [20/100] Initial Loss: 0.1296, Training Loss: 0.0202, Initial Validation Loss: 0.1176, Validation Loss: 0.0225,V Acc: 0.8796, Top 70th Acc: 1.0000, Bottom 30th Acc: 0.5938
Stopping early at Epoch (base 0): 21  Rolling back to Epoch (base 0): 16  Top Validation Acc: 0.9868421052631579
Running train_nn.py with seed 44
CUDA:False
Training samples count:  550
Training on 21 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1319, Training Loss: 0.1319, Initial Validation Loss: 0.1177, Validation Loss: 0.1177,V Acc: 0.5135, Top 70th Acc: 0.6667, Bottom 30th Acc: 0.1515
Fold [1/5] Epoch [10/100] Initial Loss: 0.1319, Training Loss: 0.0301, Initial Validation Loss: 0.1177, Validation Loss: 0.0345,V Acc: 0.8559, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.6970
Fold [1/5] Epoch [20/100] Initial Loss: 0.1319, Training Loss: 0.0179, Initial Validation Loss: 0.1177, Validation Loss: 0.0310,V Acc: 0.8378, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.9615384615384616
Fold [2/5] Epoch [0/100] Initial Loss: 0.1288, Training Loss: 0.1288, Initial Validation Loss: 0.1202, Validation Loss: 0.1202,V Acc: 0.4865, Top 70th Acc: 0.5385, Bottom 30th Acc: 0.3636
Fold [2/5] Epoch [10/100] Initial Loss: 0.1288, Training Loss: 0.0329, Initial Validation Loss: 0.1202, Validation Loss: 0.0458,V Acc: 0.7748, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.4545
Fold [2/5] Epoch [20/100] Initial Loss: 0.1288, Training Loss: 0.0219, Initial Validation Loss: 0.1202, Validation Loss: 0.0397,V Acc: 0.7838, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.4545
Fold [2/5] Epoch [30/100] Initial Loss: 0.1288, Training Loss: 0.0157, Initial Validation Loss: 0.1202, Validation Loss: 0.0350,V Acc: 0.8198, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 37  Rolling back to Epoch (base 0): 32  Top Validation Acc: 0.9102564102564102
Fold [3/5] Epoch [0/100] Initial Loss: 0.1321, Training Loss: 0.1321, Initial Validation Loss: 0.1206, Validation Loss: 0.1206,V Acc: 0.4455, Top 70th Acc: 0.5325, Bottom 30th Acc: 0.2424
Fold [3/5] Epoch [10/100] Initial Loss: 0.1321, Training Loss: 0.0282, Initial Validation Loss: 0.1206, Validation Loss: 0.0348,V Acc: 0.8455, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.5758
Fold [3/5] Epoch [20/100] Initial Loss: 0.1321, Training Loss: 0.0177, Initial Validation Loss: 0.1206, Validation Loss: 0.0319,V Acc: 0.8364, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 27  Rolling back to Epoch (base 0): 22  Top Validation Acc: 0.9090909090909091
44 2 [array([0.8643564 , 0.01250502, 0.01455778, 0.06094367, 0.04763715],
      dtype=float32)]
Fold [4/5] Epoch [0/100] Initial Loss: 0.1372, Training Loss: 0.1372, Initial Validation Loss: 0.1291, Validation Loss: 0.1291,V Acc: 0.4091, Top 70th Acc: 0.5584, Bottom 30th Acc: 0.0606
Fold [4/5] Epoch [10/100] Initial Loss: 0.1372, Training Loss: 0.0378, Initial Validation Loss: 0.1291, Validation Loss: 0.0347,V Acc: 0.8364, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.5758
Fold [4/5] Epoch [20/100] Initial Loss: 0.1372, Training Loss: 0.0234, Initial Validation Loss: 0.1291, Validation Loss: 0.0246,V Acc: 0.8545, Top 70th Acc: 0.9870, Bottom 30th Acc: 0.5455
Fold [4/5] Epoch [30/100] Initial Loss: 0.1372, Training Loss: 0.0211, Initial Validation Loss: 0.1291, Validation Loss: 0.0210,V Acc: 0.8909, Top 70th Acc: 0.9870, Bottom 30th Acc: 0.6667
Fold [4/5] Epoch [40/100] Initial Loss: 0.1372, Training Loss: 0.0162, Initial Validation Loss: 0.1291, Validation Loss: 0.0187,V Acc: 0.9000, Top 70th Acc: 0.9870, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 46  Rolling back to Epoch (base 0): 41  Top Validation Acc: 1.0
Fold [5/5] Epoch [0/100] Initial Loss: 0.1381, Training Loss: 0.1381, Initial Validation Loss: 0.1294, Validation Loss: 0.1294,V Acc: 0.4630, Top 70th Acc: 0.5395, Bottom 30th Acc: 0.2812
Fold [5/5] Epoch [10/100] Initial Loss: 0.1381, Training Loss: 0.0275, Initial Validation Loss: 0.1294, Validation Loss: 0.0250,V Acc: 0.8889, Top 70th Acc: 0.9737, Bottom 30th Acc: 0.6875
Fold [5/5] Epoch [20/100] Initial Loss: 0.1381, Training Loss: 0.0190, Initial Validation Loss: 0.1294, Validation Loss: 0.0230,V Acc: 0.8981, Top 70th Acc: 0.9868, Bottom 30th Acc: 0.6875
Stopping early at Epoch (base 0): 29  Rolling back to Epoch (base 0): 24  Top Validation Acc: 0.9473684210526315
Running train_nn.py with seed 45
CUDA:False
Training samples count:  550
Training on 21 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1367, Training Loss: 0.1367, Initial Validation Loss: 0.1245, Validation Loss: 0.1245,V Acc: 0.5405, Top 70th Acc: 0.5769, Bottom 30th Acc: 0.4545
Fold [1/5] Epoch [10/100] Initial Loss: 0.1367, Training Loss: 0.0237, Initial Validation Loss: 0.1245, Validation Loss: 0.0337,V Acc: 0.8468, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.6061
Fold [1/5] Epoch [20/100] Initial Loss: 0.1367, Training Loss: 0.0187, Initial Validation Loss: 0.1245, Validation Loss: 0.0423,V Acc: 0.8198, Top 70th Acc: 0.8846, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 21  Rolling back to Epoch (base 0): 16  Top Validation Acc: 0.9358974358974359
45 0 [array([0.8026896 , 0.02237268, 0.022888  , 0.0790702 , 0.07297952],
      dtype=float32)]
Fold [2/5] Epoch [0/100] Initial Loss: 0.1325, Training Loss: 0.1325, Initial Validation Loss: 0.1217, Validation Loss: 0.1217,V Acc: 0.4234, Top 70th Acc: 0.5641, Bottom 30th Acc: 0.0909
Fold [2/5] Epoch [10/100] Initial Loss: 0.1325, Training Loss: 0.0253, Initial Validation Loss: 0.1217, Validation Loss: 0.0345,V Acc: 0.8649, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.6970
Fold [2/5] Epoch [20/100] Initial Loss: 0.1325, Training Loss: 0.0184, Initial Validation Loss: 0.1217, Validation Loss: 0.0357,V Acc: 0.8559, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.6970
Fold [2/5] Epoch [30/100] Initial Loss: 0.1325, Training Loss: 0.0146, Initial Validation Loss: 0.1217, Validation Loss: 0.0311,V Acc: 0.8739, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.7273
Stopping early at Epoch (base 0): 30  Rolling back to Epoch (base 0): 25  Top Validation Acc: 0.9358974358974359
Fold [3/5] Epoch [0/100] Initial Loss: 0.1358, Training Loss: 0.1358, Initial Validation Loss: 0.1234, Validation Loss: 0.1234,V Acc: 0.4636, Top 70th Acc: 0.4805, Bottom 30th Acc: 0.4242
Fold [3/5] Epoch [10/100] Initial Loss: 0.1358, Training Loss: 0.0224, Initial Validation Loss: 0.1234, Validation Loss: 0.0354,V Acc: 0.7909, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.5152
Fold [3/5] Epoch [20/100] Initial Loss: 0.1358, Training Loss: 0.0184, Initial Validation Loss: 0.1234, Validation Loss: 0.0287,V Acc: 0.8273, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.5152
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.922077922077922
Fold [4/5] Epoch [0/100] Initial Loss: 0.1305, Training Loss: 0.1305, Initial Validation Loss: 0.1178, Validation Loss: 0.1178,V Acc: 0.5182, Top 70th Acc: 0.6494, Bottom 30th Acc: 0.2121
Fold [4/5] Epoch [10/100] Initial Loss: 0.1305, Training Loss: 0.0251, Initial Validation Loss: 0.1178, Validation Loss: 0.0250,V Acc: 0.9091, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.7576
Stopping early at Epoch (base 0): 18  Rolling back to Epoch (base 0): 13  Top Validation Acc: 0.974025974025974
Fold [5/5] Epoch [0/100] Initial Loss: 0.1378, Training Loss: 0.1378, Initial Validation Loss: 0.1302, Validation Loss: 0.1302,V Acc: 0.4444, Top 70th Acc: 0.5395, Bottom 30th Acc: 0.2188
Fold [5/5] Epoch [10/100] Initial Loss: 0.1378, Training Loss: 0.0251, Initial Validation Loss: 0.1302, Validation Loss: 0.0258,V Acc: 0.8889, Top 70th Acc: 0.9737, Bottom 30th Acc: 0.6875
Fold [5/5] Epoch [20/100] Initial Loss: 0.1378, Training Loss: 0.0176, Initial Validation Loss: 0.1302, Validation Loss: 0.0206,V Acc: 0.9074, Top 70th Acc: 0.9737, Bottom 30th Acc: 0.7500/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)

Fold [3/5] Epoch [10/100] Initial Loss: 0.1389, Training Loss: 0.0321, Initial Validation Loss: 0.1374, Validation Loss: 0.0387,V Acc: 0.8182, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.5455
Fold [3/5] Epoch [20/100] Initial Loss: 0.1389, Training Loss: 0.0144, Initial Validation Loss: 0.1374, Validation Loss: 0.0306,V Acc: 0.8182, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.4848
Stopping early at Epoch (base 0): 22  Rolling back to Epoch (base 0): 17  Top Validation Acc: 0.961038961038961
Fold [4/5] Epoch [0/100] Initial Loss: 0.1375, Training Loss: 0.1375, Initial Validation Loss: 0.1348, Validation Loss: 0.1348,V Acc: 0.3091, Top 70th Acc: 0.3117, Bottom 30th Acc: 0.3030
Fold [4/5] Epoch [10/100] Initial Loss: 0.1375, Training Loss: 0.0334, Initial Validation Loss: 0.1348, Validation Loss: 0.0386,V Acc: 0.8364, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.6364
Fold [4/5] Epoch [20/100] Initial Loss: 0.1375, Training Loss: 0.0170, Initial Validation Loss: 0.1348, Validation Loss: 0.0296,V Acc: 0.8364, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.5758
Fold [4/5] Epoch [30/100] Initial Loss: 0.1375, Training Loss: 0.0137, Initial Validation Loss: 0.1348, Validation Loss: 0.0268,V Acc: 0.8364, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 39  Rolling back to Epoch (base 0): 34  Top Validation Acc: 0.935064935064935
Fold [5/5] Epoch [0/100] Initial Loss: 0.1398, Training Loss: 0.1398, Initial Validation Loss: 0.1346, Validation Loss: 0.1346,V Acc: 0.2407, Top 70th Acc: 0.2763, Bottom 30th Acc: 0.1562
Fold [5/5] Epoch [10/100] Initial Loss: 0.1398, Training Loss: 0.0356, Initial Validation Loss: 0.1346, Validation Loss: 0.0404,V Acc: 0.7963, Top 70th Acc: 0.9211, Bottom 30th Acc: 0.5000
Fold [5/5] Epoch [20/100] Initial Loss: 0.1398, Training Loss: 0.0157, Initial Validation Loss: 0.1346, Validation Loss: 0.0309,V Acc: 0.8426, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.5625
Fold [5/5] Epoch [30/100] Initial Loss: 0.1398, Training Loss: 0.0115, Initial Validation Loss: 0.1346, Validation Loss: 0.0306,V Acc: 0.8611, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.6250
Stopping early at Epoch (base 0): 31  Rolling back to Epoch (base 0): 26  Top Validation Acc: 0.9605263157894737
Running train_nn.py with seed 32
CUDA:False
Training samples count:  550
Training on 40 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1455, Training Loss: 0.1455, Initial Validation Loss: 0.1409, Validation Loss: 0.1409,V Acc: 0.2613, Top 70th Acc: 0.2692, Bottom 30th Acc: 0.2424
Fold [1/5] Epoch [10/100] Initial Loss: 0.1455, Training Loss: 0.0318, Initial Validation Loss: 0.1409, Validation Loss: 0.0419,V Acc: 0.7928, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.5152
Fold [1/5] Epoch [20/100] Initial Loss: 0.1455, Training Loss: 0.0151, Initial Validation Loss: 0.1409, Validation Loss: 0.0312,V Acc: 0.8468, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.6364
Fold [1/5] Epoch [30/100] Initial Loss: 0.1455, Training Loss: 0.0111, Initial Validation Loss: 0.1409, Validation Loss: 0.0313,V Acc: 0.8468, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 30  Rolling back to Epoch (base 0): 25  Top Validation Acc: 0.9358974358974359
Fold [2/5] Epoch [0/100] Initial Loss: 0.1406, Training Loss: 0.1406, Initial Validation Loss: 0.1402, Validation Loss: 0.1402,V Acc: 0.2342, Top 70th Acc: 0.2692, Bottom 30th Acc: 0.1515
Fold [2/5] Epoch [10/100] Initial Loss: 0.1406, Training Loss: 0.0347, Initial Validation Loss: 0.1402, Validation Loss: 0.0425,V Acc: 0.8378, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.6061
Fold [2/5] Epoch [20/100] Initial Loss: 0.1406, Training Loss: 0.0145, Initial Validation Loss: 0.1402, Validation Loss: 0.0330,V Acc: 0.8559, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.9615384615384616
Fold [3/5] Epoch [0/100] Initial Loss: 0.1387, Training Loss: 0.1387, Initial Validation Loss: 0.1315, Validation Loss: 0.1315,V Acc: 0.2636, Top 70th Acc: 0.3506, Bottom 30th Acc: 0.0606
Fold [3/5] Epoch [10/100] Initial Loss: 0.1387, Training Loss: 0.0294, Initial Validation Loss: 0.1315, Validation Loss: 0.0399,V Acc: 0.7909, Top 70th Acc: 0.8831, Bottom 30th Acc: 0.5758
Fold [3/5] Epoch [20/100] Initial Loss: 0.1387, Training Loss: 0.0147, Initial Validation Loss: 0.1315, Validation Loss: 0.0313,V Acc: 0.8000, Top 70th Acc: 0.8961, Bottom 30th Acc: 0.5758
Fold [3/5] Epoch [30/100] Initial Loss: 0.1387, Training Loss: 0.0123, Initial Validation Loss: 0.1315, Validation Loss: 0.0306,V Acc: 0.8091, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 32  Rolling back to Epoch (base 0): 27  Top Validation Acc: 0.922077922077922
32 2 [array([0.5059234 , 0.13836794, 0.0364236 , 0.04782978, 0.27145535],
      dtype=float32)]
Fold [4/5] Epoch [0/100] Initial Loss: 0.1391, Training Loss: 0.1391, Initial Validation Loss: 0.1349, Validation Loss: 0.1349,V Acc: 0.2545, Top 70th Acc: 0.3377, Bottom 30th Acc: 0.0606
Fold [4/5] Epoch [10/100] Initial Loss: 0.1391, Training Loss: 0.0333, Initial Validation Loss: 0.1349, Validation Loss: 0.0460,V Acc: 0.7727, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.4545
Fold [4/5] Epoch [20/100] Initial Loss: 0.1391, Training Loss: 0.0160, Initial Validation Loss: 0.1349, Validation Loss: 0.0370,V Acc: 0.8182, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.5758
Fold [4/5] Epoch [30/100] Initial Loss: 0.1391, Training Loss: 0.0124, Initial Validation Loss: 0.1349, Validation Loss: 0.0359,V Acc: 0.8455, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 33  Rolling back to Epoch (base 0): 28  Top Validation Acc: 0.935064935064935
Fold [5/5] Epoch [0/100] Initial Loss: 0.1391, Training Loss: 0.1391, Initial Validation Loss: 0.1288, Validation Loss: 0.1288,V Acc: 0.3241, Top 70th Acc: 0.3421, Bottom 30th Acc: 0.2812
Fold [5/5] Epoch [10/100] Initial Loss: 0.1391, Training Loss: 0.0328, Initial Validation Loss: 0.1288, Validation Loss: 0.0356,V Acc: 0.8426, Top 70th Acc: 0.9079, Bottom 30th Acc: 0.6875
Fold [5/5] Epoch [20/100] Initial Loss: 0.1391, Training Loss: 0.0149, Initial Validation Loss: 0.1288, Validation Loss: 0.0272,V Acc: 0.8704, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.6562
Fold [5/5] Epoch [30/100] Initial Loss: 0.1391, Training Loss: 0.0128, Initial Validation Loss: 0.1288, Validation Loss: 0.0266,V Acc: 0.8611, Top 70th Acc: 0.9737, Bottom 30th Acc: 0.5938
Stopping early at Epoch (base 0): 34  Rolling back to Epoch (base 0): 29  Top Validation Acc: 0.9736842105263158
Running train_nn.py with seed 33
CUDA:False
Training samples count:  550
Training on 39 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1372, Training Loss: 0.1372, Initial Validation Loss: 0.1348, Validation Loss: 0.1348,V Acc: 0.3243, Top 70th Acc: 0.3590, Bottom 30th Acc: 0.2424
Fold [1/5] Epoch [10/100] Initial Loss: 0.1372, Training Loss: 0.0307, Initial Validation Loss: 0.1348, Validation Loss: 0.0443,V Acc: 0.7928, Top 70th Acc: 0.8974, Bottom 30th Acc: 0.5455
Fold [1/5] Epoch [20/100] Initial Loss: 0.1372, Training Loss: 0.0162, Initial Validation Loss: 0.1348, Validation Loss: 0.0375,V Acc: 0.8108, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.9230769230769231
Fold [2/5] Epoch [0/100] Initial Loss: 0.1368, Training Loss: 0.1368, Initial Validation Loss: 0.1404, Validation Loss: 0.1404,V Acc: 0.4414, Top 70th Acc: 0.4487, Bottom 30th Acc: 0.4242
Fold [2/5] Epoch [10/100] Initial Loss: 0.1368, Training Loss: 0.0301, Initial Validation Loss: 0.1404, Validation Loss: 0.0336,V Acc: 0.8649, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.6364
Fold [2/5] Epoch [20/100] Initial Loss: 0.1368, Training Loss: 0.0152, Initial Validation Loss: 0.1404, Validation Loss: 0.0296,V Acc: 0.8649, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.9743589743589743
33 1 [array([0.644234  , 0.07086366, 0.09516106, 0.07739761, 0.11234368],
      dtype=float32)]
Fold [3/5] Epoch [0/100] Initial Loss: 0.1388, Training Loss: 0.1388, Initial Validation Loss: 0.1286, Validation Loss: 0.1286,V Acc: 0.3727, Top 70th Acc: 0.4805, Bottom 30th Acc: 0.1212
Fold [2/5] Epoch [10/100] Initial Loss: 0.1385, Training Loss: 0.0784, Initial Validation Loss: 0.1331, Validation Loss: 0.0908,V Acc: 0.5586, Top 70th Acc: 0.6667, Bottom 30th Acc: 0.3030
Fold [2/5] Epoch [20/100] Initial Loss: 0.1385, Training Loss: 0.0762, Initial Validation Loss: 0.1331, Validation Loss: 0.0901,V Acc: 0.5495, Top 70th Acc: 0.6538, Bottom 30th Acc: 0.3030
Stopping early at Epoch (base 0): 27  Rolling back to Epoch (base 0): 22  Top Validation Acc: 0.6794871794871795
Fold [3/5] Epoch [0/100] Initial Loss: 0.1377, Training Loss: 0.1377, Initial Validation Loss: 0.1275, Validation Loss: 0.1275,V Acc: 0.4182, Top 70th Acc: 0.5455, Bottom 30th Acc: 0.1212
Fold [3/5] Epoch [10/100] Initial Loss: 0.1377, Training Loss: 0.0818, Initial Validation Loss: 0.1275, Validation Loss: 0.0773,V Acc: 0.6273, Top 70th Acc: 0.7403, Bottom 30th Acc: 0.3636
Stopping early at Epoch (base 0): 19  Rolling back to Epoch (base 0): 14  Top Validation Acc: 0.7402597402597403
Fold [4/5] Epoch [0/100] Initial Loss: 0.1379, Training Loss: 0.1379, Initial Validation Loss: 0.1314, Validation Loss: 0.1314,V Acc: 0.4545, Top 70th Acc: 0.4545, Bottom 30th Acc: 0.4545
Fold [4/5] Epoch [10/100] Initial Loss: 0.1379, Training Loss: 0.0813, Initial Validation Loss: 0.1314, Validation Loss: 0.0778,V Acc: 0.6636, Top 70th Acc: 0.7403, Bottom 30th Acc: 0.4848
Fold [4/5] Epoch [20/100] Initial Loss: 0.1379, Training Loss: 0.0787, Initial Validation Loss: 0.1314, Validation Loss: 0.0766,V Acc: 0.6727, Top 70th Acc: 0.7273, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 29  Rolling back to Epoch (base 0): 24  Top Validation Acc: 0.7402597402597403
Fold [5/5] Epoch [0/100] Initial Loss: 0.1378, Training Loss: 0.1378, Initial Validation Loss: 0.1321, Validation Loss: 0.1321,V Acc: 0.2500, Top 70th Acc: 0.3421, Bottom 30th Acc: 0.0312
Fold [5/5] Epoch [10/100] Initial Loss: 0.1378, Training Loss: 0.0815, Initial Validation Loss: 0.1321, Validation Loss: 0.0806,V Acc: 0.6296, Top 70th Acc: 0.7763, Bottom 30th Acc: 0.2812
Fold [5/5] Epoch [20/100] Initial Loss: 0.1378, Training Loss: 0.0793, Initial Validation Loss: 0.1321, Validation Loss: 0.0797,V Acc: 0.6481, Top 70th Acc: 0.7763, Bottom 30th Acc: 0.3438
Stopping early at Epoch (base 0): 21  Rolling back to Epoch (base 0): 16  Top Validation Acc: 0.7763157894736842
30 4 [array([0.13056679, 0.3492673 , 0.17954862, 0.19400397, 0.14661326],
      dtype=float32)]
Running train_nn.py with seed 31
CUDA:False
Training samples count:  550
Training on 2 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1354, Training Loss: 0.1354, Initial Validation Loss: 0.1298, Validation Loss: 0.1298,V Acc: 0.4865, Top 70th Acc: 0.5385, Bottom 30th Acc: 0.3636
Fold [1/5] Epoch [10/100] Initial Loss: 0.1354, Training Loss: 0.0793, Initial Validation Loss: 0.1298, Validation Loss: 0.0865,V Acc: 0.6126, Top 70th Acc: 0.7179, Bottom 30th Acc: 0.3636
Fold [1/5] Epoch [20/100] Initial Loss: 0.1354, Training Loss: 0.0769, Initial Validation Loss: 0.1298, Validation Loss: 0.0854,V Acc: 0.6036, Top 70th Acc: 0.7436, Bottom 30th Acc: 0.2727
Stopping early at Epoch (base 0): 29  Rolling back to Epoch (base 0): 24  Top Validation Acc: 0.717948717948718
31 0 [array([0.1498682 , 0.3366848 , 0.15608744, 0.23487572, 0.12248385],
      dtype=float32)]
Fold [2/5] Epoch [0/100] Initial Loss: 0.1336, Training Loss: 0.1336, Initial Validation Loss: 0.1233, Validation Loss: 0.1233,V Acc: 0.4775, Top 70th Acc: 0.4487, Bottom 30th Acc: 0.5455
Fold [2/5] Epoch [10/100] Initial Loss: 0.1336, Training Loss: 0.0828, Initial Validation Loss: 0.1233, Validation Loss: 0.0773,V Acc: 0.6306, Top 70th Acc: 0.7051, Bottom 30th Acc: 0.4545
Fold [2/5] Epoch [20/100] Initial Loss: 0.1336, Training Loss: 0.0799, Initial Validation Loss: 0.1233, Validation Loss: 0.0747,V Acc: 0.6216, Top 70th Acc: 0.7436, Bottom 30th Acc: 0.3333
Fold [2/5] Epoch [30/100] Initial Loss: 0.1336, Training Loss: 0.0788, Initial Validation Loss: 0.1233, Validation Loss: 0.0742,V Acc: 0.6216, Top 70th Acc: 0.7564, Bottom 30th Acc: 0.3030
Fold [2/5] Epoch [40/100] Initial Loss: 0.1336, Training Loss: 0.0783, Initial Validation Loss: 0.1233, Validation Loss: 0.0736,V Acc: 0.6126, Top 70th Acc: 0.7692, Bottom 30th Acc: 0.2424
Stopping early at Epoch (base 0): 41  Rolling back to Epoch (base 0): 36  Top Validation Acc: 0.7435897435897436
Fold [3/5] Epoch [0/100] Initial Loss: 0.1411, Training Loss: 0.1411, Initial Validation Loss: 0.1356, Validation Loss: 0.1356,V Acc: 0.3364, Top 70th Acc: 0.3636, Bottom 30th Acc: 0.2727
Fold [3/5] Epoch [10/100] Initial Loss: 0.1411, Training Loss: 0.0816, Initial Validation Loss: 0.1356, Validation Loss: 0.0830,V Acc: 0.6091, Top 70th Acc: 0.7273, Bottom 30th Acc: 0.3333
Fold [3/5] Epoch [20/100] Initial Loss: 0.1411, Training Loss: 0.0784, Initial Validation Loss: 0.1356, Validation Loss: 0.0807,V Acc: 0.6000, Top 70th Acc: 0.7532, Bottom 30th Acc: 0.2424
Fold [3/5] Epoch [30/100] Initial Loss: 0.1411, Training Loss: 0.0778, Initial Validation Loss: 0.1356, Validation Loss: 0.0801,V Acc: 0.6091, Top 70th Acc: 0.7403, Bottom 30th Acc: 0.3030
Fold [3/5] Epoch [40/100] Initial Loss: 0.1411, Training Loss: 0.0771, Initial Validation Loss: 0.1356, Validation Loss: 0.0793,V Acc: 0.6182, Top 70th Acc: 0.7403, Bottom 30th Acc: 0.3333
Stopping early at Epoch (base 0): 42  Rolling back to Epoch (base 0): 37  Top Validation Acc: 0.7402597402597403
Fold [4/5] Epoch [0/100] Initial Loss: 0.1349, Training Loss: 0.1349, Initial Validation Loss: 0.1263, Validation Loss: 0.1263,V Acc: 0.3182, Top 70th Acc: 0.3636, Bottom 30th Acc: 0.2121
Fold [4/5] Epoch [10/100] Initial Loss: 0.1349, Training Loss: 0.0812, Initial Validation Loss: 0.1263, Validation Loss: 0.0790,V Acc: 0.6545, Top 70th Acc: 0.7273, Bottom 30th Acc: 0.4848
Fold [4/5] Epoch [20/100] Initial Loss: 0.1349, Training Loss: 0.0791, Initial Validation Loss: 0.1263, Validation Loss: 0.0771,V Acc: 0.6636, Top 70th Acc: 0.7403, Bottom 30th Acc: 0.4848
Fold [4/5] Epoch [30/100] Initial Loss: 0.1349, Training Loss: 0.0786, Initial Validation Loss: 0.1263, Validation Loss: 0.0765,V Acc: 0.6545, Top 70th Acc: 0.7403, Bottom 30th Acc: 0.4545
Fold [4/5] Epoch [40/100] Initial Loss: 0.1349, Training Loss: 0.0784, Initial Validation Loss: 0.1263, Validation Loss: 0.0755,V Acc: 0.6818, Top 70th Acc: 0.7662, Bottom 30th Acc: 0.4848
Fold [4/5] Epoch [50/100] Initial Loss: 0.1349, Training Loss: 0.0780, Initial Validation Loss: 0.1263, Validation Loss: 0.0759,V Acc: 0.6727, Top 70th Acc: 0.7532, Bottom 30th Acc: 0.4848
Stopping early at Epoch (base 0): 58  Rolling back to Epoch (base 0): 53  Top Validation Acc: 0.7662337662337663
Fold [5/5] Epoch [0/100] Initial Loss: 0.1368, Training Loss: 0.1368, Initial Validation Loss: 0.1284, Validation Loss: 0.1284,V Acc: 0.4907, Top 70th Acc: 0.4737, Bottom 30th Acc: 0.5312
Fold [5/5] Epoch [10/100] Initial Loss: 0.1368, Training Loss: 0.0811, Initial Validation Loss: 0.1284, Validation Loss: 0.0760,V Acc: 0.6389, Top 70th Acc: 0.7632, Bottom 30th Acc: 0.3438
Fold [5/5] Epoch [20/100] Initial Loss: 0.1368, Training Loss: 0.0792, Initial Validation Loss: 0.1284, Validation Loss: 0.0744,V Acc: 0.6481, Top 70th Acc: 0.7895, Bottom 30th Acc: 0.3125
Fold [5/5] Epoch [30/100] Initial Loss: 0.1368, Training Loss: 0.0784, Initial Validation Loss: 0.1284, Validation Loss: 0.0741,V Acc: 0.6389, Top 70th Acc: 0.7500, Bottom 30th Acc: 0.3750
Fold [5/5] Epoch [40/100] Initial Loss: 0.1368, Training Loss: 0.0784, Initial Validation Loss: 0.1284, Validation Loss: 0.0734,V Acc: 0.6667, Top 70th Acc: 0.7763, Bottom 30th Acc: 0.4062
Fold [5/5] Epoch [50/100] Initial Loss: 0.1368, Training Loss: 0.0781, Initial Validation Loss: 0.1284, Validation Loss: 0.0732,V Acc: 0.6574, Top 70th Acc: 0.7500, Bottom 30th Acc: 0.4375
Fold [5/5] Epoch [60/100] Initial Loss: 0.1368, Training Loss: 0.0778, Initial Validation Loss: 0.1284, Validation Loss: 0.0734,V Acc: 0.6574, Top 70th Acc: 0.7500, Bottom 30th Acc: 0.4375
Stopping early at Epoch (base 0): 63  Rolling back to Epoch (base 0): 58  Top Validation Acc: 0.7236842105263158
Running train_nn.py with seed 32
CUDA:False
Training samples count:  550
Training on 2 features
Fold [4/5] Epoch [20/100] Initial Loss: 0.1409, Training Loss: 0.0249, Initial Validation Loss: 0.1352, Validation Loss: 0.0409,V Acc: 0.8364, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.6364
Fold [4/5] Epoch [30/100] Initial Loss: 0.1409, Training Loss: 0.0209, Initial Validation Loss: 0.1352, Validation Loss: 0.0400,V Acc: 0.8545, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.7273
Stopping early at Epoch (base 0): 30  Rolling back to Epoch (base 0): 25  Top Validation Acc: 0.9090909090909091
Fold [5/5] Epoch [0/100] Initial Loss: 0.1384, Training Loss: 0.1384, Initial Validation Loss: 0.1295, Validation Loss: 0.1295,V Acc: 0.3056, Top 70th Acc: 0.3816, Bottom 30th Acc: 0.1250
Fold [5/5] Epoch [10/100] Initial Loss: 0.1384, Training Loss: 0.0362, Initial Validation Loss: 0.1295, Validation Loss: 0.0384,V Acc: 0.8519, Top 70th Acc: 0.9211, Bottom 30th Acc: 0.6875
Fold [5/5] Epoch [20/100] Initial Loss: 0.1384, Training Loss: 0.0249, Initial Validation Loss: 0.1295, Validation Loss: 0.0287,V Acc: 0.8333, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.5312
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.9473684210526315
Running train_nn.py with seed 33
CUDA:False
Training samples count:  550
Training on 20 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1372, Training Loss: 0.1372, Initial Validation Loss: 0.1348, Validation Loss: 0.1348,V Acc: 0.4234, Top 70th Acc: 0.4744, Bottom 30th Acc: 0.3030
Fold [1/5] Epoch [10/100] Initial Loss: 0.1372, Training Loss: 0.0378, Initial Validation Loss: 0.1348, Validation Loss: 0.0444,V Acc: 0.8018, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.5455
Fold [1/5] Epoch [20/100] Initial Loss: 0.1372, Training Loss: 0.0247, Initial Validation Loss: 0.1348, Validation Loss: 0.0359,V Acc: 0.8468, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.5758
Fold [1/5] Epoch [30/100] Initial Loss: 0.1372, Training Loss: 0.0213, Initial Validation Loss: 0.1348, Validation Loss: 0.0341,V Acc: 0.8288, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 37  Rolling back to Epoch (base 0): 32  Top Validation Acc: 0.9487179487179487
Fold [2/5] Epoch [0/100] Initial Loss: 0.1379, Training Loss: 0.1379, Initial Validation Loss: 0.1396, Validation Loss: 0.1396,V Acc: 0.3153, Top 70th Acc: 0.4103, Bottom 30th Acc: 0.0909
Fold [2/5] Epoch [10/100] Initial Loss: 0.1379, Training Loss: 0.0411, Initial Validation Loss: 0.1396, Validation Loss: 0.0404,V Acc: 0.8649, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.6667
Fold [2/5] Epoch [20/100] Initial Loss: 0.1379, Training Loss: 0.0239, Initial Validation Loss: 0.1396, Validation Loss: 0.0268,V Acc: 0.8649, Top 70th Acc: 0.9872, Bottom 30th Acc: 0.5758
Fold [2/5] Epoch [30/100] Initial Loss: 0.1379, Training Loss: 0.0212, Initial Validation Loss: 0.1396, Validation Loss: 0.0264,V Acc: 0.8559, Top 70th Acc: 0.9872, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 30  Rolling back to Epoch (base 0): 25  Top Validation Acc: 0.9871794871794872
33 1 [array([0.47020608, 0.09739885, 0.12397753, 0.1686077 , 0.13980979],
      dtype=float32)]
Fold [3/5] Epoch [0/100] Initial Loss: 0.1425, Training Loss: 0.1425, Initial Validation Loss: 0.1318, Validation Loss: 0.1318,V Acc: 0.2545, Top 70th Acc: 0.2987, Bottom 30th Acc: 0.1515
Fold [3/5] Epoch [10/100] Initial Loss: 0.1425, Training Loss: 0.0406, Initial Validation Loss: 0.1318, Validation Loss: 0.0441,V Acc: 0.7545, Top 70th Acc: 0.8831, Bottom 30th Acc: 0.4545
Fold [3/5] Epoch [20/100] Initial Loss: 0.1425, Training Loss: 0.0228, Initial Validation Loss: 0.1318, Validation Loss: 0.0313,V Acc: 0.8000, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.4545
Stopping early at Epoch (base 0): 27  Rolling back to Epoch (base 0): 22  Top Validation Acc: 0.935064935064935
Fold [4/5] Epoch [0/100] Initial Loss: 0.1368, Training Loss: 0.1368, Initial Validation Loss: 0.1261, Validation Loss: 0.1261,V Acc: 0.3636, Top 70th Acc: 0.3896, Bottom 30th Acc: 0.3030
Fold [4/5] Epoch [10/100] Initial Loss: 0.1368, Training Loss: 0.0305, Initial Validation Loss: 0.1261, Validation Loss: 0.0356,V Acc: 0.8455, Top 70th Acc: 0.8961, Bottom 30th Acc: 0.7273
Fold [4/5] Epoch [20/100] Initial Loss: 0.1368, Training Loss: 0.0208, Initial Validation Loss: 0.1261, Validation Loss: 0.0333,V Acc: 0.8455, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 21  Rolling back to Epoch (base 0): 16  Top Validation Acc: 0.922077922077922
Fold [5/5] Epoch [0/100] Initial Loss: 0.1389, Training Loss: 0.1389, Initial Validation Loss: 0.1350, Validation Loss: 0.1350,V Acc: 0.2500, Top 70th Acc: 0.3026, Bottom 30th Acc: 0.1250
Fold [5/5] Epoch [10/100] Initial Loss: 0.1389, Training Loss: 0.0355, Initial Validation Loss: 0.1350, Validation Loss: 0.0426,V Acc: 0.8148, Top 70th Acc: 0.8816, Bottom 30th Acc: 0.6562
Fold [5/5] Epoch [20/100] Initial Loss: 0.1389, Training Loss: 0.0211, Initial Validation Loss: 0.1350, Validation Loss: 0.0341,V Acc: 0.8426, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.6250
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.9342105263157895
Running train_nn.py with seed 34
CUDA:False
Training samples count:  550
Training on 20 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1393, Training Loss: 0.1393, Initial Validation Loss: 0.1313, Validation Loss: 0.1313,V Acc: 0.3874, Top 70th Acc: 0.4615, Bottom 30th Acc: 0.2121
Fold [1/5] Epoch [10/100] Initial Loss: 0.1393, Training Loss: 0.0394, Initial Validation Loss: 0.1313, Validation Loss: 0.0396,V Acc: 0.7658, Top 70th Acc: 0.8974, Bottom 30th Acc: 0.4545
Fold [1/5] Epoch [20/100] Initial Loss: 0.1393, Training Loss: 0.0264, Initial Validation Loss: 0.1313, Validation Loss: 0.0304,V Acc: 0.8108, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.5758
Fold [1/5] Epoch [30/100] Initial Loss: 0.1393, Training Loss: 0.0239, Initial Validation Loss: 0.1313, Validation Loss: 0.0291,V Acc: 0.8288, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 34  Rolling back to Epoch (base 0): 29  Top Validation Acc: 0.9230769230769231
Fold [2/5] Epoch [0/100] Initial Loss: 0.1357, Training Loss: 0.1357, Initial Validation Loss: 0.1325, Validation Loss: 0.1325,V Acc: 0.3333, Top 70th Acc: 0.3974, Bottom 30th Acc: 0.1818
Fold [2/5] Epoch [10/100] Initial Loss: 0.1357, Training Loss: 0.0415, Initial Validation Loss: 0.1325, Validation Loss: 0.0498,V Acc: 0.7477, Top 70th Acc: 0.8718, Bottom 30th Acc: 0.4545
Fold [2/5] Epoch [20/100] Initial Loss: 0.1357, Training Loss: 0.0240, Initial Validation Loss: 0.1325, Validation Loss: 0.0418,V Acc: 0.7658, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.4242
Fold [2/5] Epoch [30/100] Initial Loss: 0.1357, Training Loss: 0.0204, Initial Validation Loss: 0.1325, Validation Loss: 0.0403,V Acc: 0.7928, Top 70th Acc: 0.8974, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 30  Rolling back to Epoch (base 0): 25  Top Validation Acc: 0.8974358974358975
34 1 [array([0.3303913 , 0.04798115, 0.27545696, 0.15057972, 0.19559096],
      dtype=float32)]
Fold [3/5] Epoch [0/100] Initial Loss: 0.1394, Training Loss: 0.1394, Initial Validation Loss: 0.1376, Validation Loss: 0.1376,V Acc: 0.2909, Top 70th Acc: 0.3247, Bottom 30th Acc: 0.2121
Fold [3/5] Epoch [10/100] Initial Loss: 0.1394, Training Loss: 0.0413, Initial Validation Loss: 0.1376, Validation Loss: 0.0475,V Acc: 0.8091, Top 70th Acc: 0.8831, Bottom 30th Acc: 0.6364
Fold [3/5] Epoch [20/100] Initial Loss: 0.1394, Training Loss: 0.0235, Initial Validation Loss: 0.1376, Validation Loss: 0.0347,V Acc: 0.8545, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.935064935064935
Fold [4/5] Epoch [0/100] Initial Loss: 0.1390, Training Loss: 0.1390, Initial Validation Loss: 0.1353, Validation Loss: 0.1353,V Acc: 0.2545, Top 70th Acc: 0.2857, Bottom 30th Acc: 0.1818
Fold [4/5] Epoch [10/100] Initial Loss: 0.1390, Training Loss: 0.0462, Initial Validation Loss: 0.1353, Validation Loss: 0.0532,V Acc: 0.8000, Top 70th Acc: 0.8831, Bottom 30th Acc: 0.6061
Fold [4/5] Epoch [20/100] Initial Loss: 0.1390, Training Loss: 0.0274, Initial Validation Loss: 0.1353, Validation Loss: 0.0367,V Acc: 0.8545, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.6667 0.9358974358974359
Fold [2/5] Epoch [0/100] Initial Loss: 0.1392, Training Loss: 0.1392, Initial Validation Loss: 0.1394, Validation Loss: 0.1394,V Acc: 0.2613, Top 70th Acc: 0.3077, Bottom 30th Acc: 0.1515
Fold [2/5] Epoch [10/100] Initial Loss: 0.1392, Training Loss: 0.0428, Initial Validation Loss: 0.1394, Validation Loss: 0.0478,V Acc: 0.7838, Top 70th Acc: 0.8846, Bottom 30th Acc: 0.5455
Fold [2/5] Epoch [20/100] Initial Loss: 0.1392, Training Loss: 0.0217, Initial Validation Loss: 0.1394, Validation Loss: 0.0350,V Acc: 0.8468, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.6364
Fold [2/5] Epoch [30/100] Initial Loss: 0.1392, Training Loss: 0.0169, Initial Validation Loss: 0.1394, Validation Loss: 0.0340,V Acc: 0.8378, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 35  Rolling back to Epoch (base 0): 30  Top Validation Acc: 0.9487179487179487
Fold [3/5] Epoch [0/100] Initial Loss: 0.1364, Training Loss: 0.1364, Initial Validation Loss: 0.1294, Validation Loss: 0.1294,V Acc: 0.4273, Top 70th Acc: 0.4675, Bottom 30th Acc: 0.3333
Fold [3/5] Epoch [10/100] Initial Loss: 0.1364, Training Loss: 0.0260, Initial Validation Loss: 0.1294, Validation Loss: 0.0361,V Acc: 0.8364, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 19  Rolling back to Epoch (base 0): 14  Top Validation Acc: 0.948051948051948
32 2 [array([0.6361055 , 0.12249524, 0.03079708, 0.07756241, 0.13303979],
      dtype=float32)]
Fold [4/5] Epoch [0/100] Initial Loss: 0.1393, Training Loss: 0.1393, Initial Validation Loss: 0.1355, Validation Loss: 0.1355,V Acc: 0.3000, Top 70th Acc: 0.3636, Bottom 30th Acc: 0.1515
Fold [4/5] Epoch [10/100] Initial Loss: 0.1393, Training Loss: 0.0301, Initial Validation Loss: 0.1355, Validation Loss: 0.0423,V Acc: 0.8182, Top 70th Acc: 0.8961, Bottom 30th Acc: 0.6364
Fold [4/5] Epoch [20/100] Initial Loss: 0.1393, Training Loss: 0.0176, Initial Validation Loss: 0.1355, Validation Loss: 0.0386,V Acc: 0.8182, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 21  Rolling back to Epoch (base 0): 16  Top Validation Acc: 0.8961038961038961
Fold [5/5] Epoch [0/100] Initial Loss: 0.1397, Training Loss: 0.1397, Initial Validation Loss: 0.1309, Validation Loss: 0.1309,V Acc: 0.2685, Top 70th Acc: 0.2763, Bottom 30th Acc: 0.2500
Fold [5/5] Epoch [10/100] Initial Loss: 0.1397, Training Loss: 0.0389, Initial Validation Loss: 0.1309, Validation Loss: 0.0374,V Acc: 0.8056, Top 70th Acc: 0.9079, Bottom 30th Acc: 0.5625
Fold [5/5] Epoch [20/100] Initial Loss: 0.1397, Training Loss: 0.0211, Initial Validation Loss: 0.1309, Validation Loss: 0.0264,V Acc: 0.8611, Top 70th Acc: 0.9868, Bottom 30th Acc: 0.5625
Fold [5/5] Epoch [30/100] Initial Loss: 0.1397, Training Loss: 0.0178, Initial Validation Loss: 0.1309, Validation Loss: 0.0254,V Acc: 0.8796, Top 70th Acc: 0.9868, Bottom 30th Acc: 0.6250
Stopping early at Epoch (base 0): 30  Rolling back to Epoch (base 0): 25  Top Validation Acc: 0.9868421052631579
Running train_nn.py with seed 33
CUDA:False
Training samples count:  550
Training on 30 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1382, Training Loss: 0.1382, Initial Validation Loss: 0.1353, Validation Loss: 0.1353,V Acc: 0.2793, Top 70th Acc: 0.3077, Bottom 30th Acc: 0.2121
Fold [1/5] Epoch [10/100] Initial Loss: 0.1382, Training Loss: 0.0375, Initial Validation Loss: 0.1353, Validation Loss: 0.0464,V Acc: 0.7838, Top 70th Acc: 0.8846, Bottom 30th Acc: 0.5455
Fold [1/5] Epoch [20/100] Initial Loss: 0.1382, Training Loss: 0.0258, Initial Validation Loss: 0.1353, Validation Loss: 0.0371,V Acc: 0.8288, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.5152
Fold [1/5] Epoch [30/100] Initial Loss: 0.1382, Training Loss: 0.0193, Initial Validation Loss: 0.1353, Validation Loss: 0.0313,V Acc: 0.8468, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 34  Rolling back to Epoch (base 0): 29  Top Validation Acc: 0.9871794871794872
Fold [2/5] Epoch [0/100] Initial Loss: 0.1363, Training Loss: 0.1363, Initial Validation Loss: 0.1401, Validation Loss: 0.1401,V Acc: 0.2703, Top 70th Acc: 0.3718, Bottom 30th Acc: 0.0303
Fold [2/5] Epoch [10/100] Initial Loss: 0.1363, Training Loss: 0.0274, Initial Validation Loss: 0.1401, Validation Loss: 0.0294,V Acc: 0.9189, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.8182
Fold [2/5] Epoch [20/100] Initial Loss: 0.1363, Training Loss: 0.0182, Initial Validation Loss: 0.1401, Validation Loss: 0.0255,V Acc: 0.9009, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.7576
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.9615384615384616
33 1 [array([0.67642903, 0.08266129, 0.07288492, 0.0822553 , 0.08576938],
      dtype=float32)]
Fold [3/5] Epoch [0/100] Initial Loss: 0.1409, Training Loss: 0.1409, Initial Validation Loss: 0.1297, Validation Loss: 0.1297,V Acc: 0.2909, Top 70th Acc: 0.3506, Bottom 30th Acc: 0.1515
Fold [3/5] Epoch [10/100] Initial Loss: 0.1409, Training Loss: 0.0524, Initial Validation Loss: 0.1297, Validation Loss: 0.0520,V Acc: 0.7364, Top 70th Acc: 0.8701, Bottom 30th Acc: 0.4242
Fold [3/5] Epoch [20/100] Initial Loss: 0.1409, Training Loss: 0.0207, Initial Validation Loss: 0.1297, Validation Loss: 0.0321,V Acc: 0.8000, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.4848
Stopping early at Epoch (base 0): 28  Rolling back to Epoch (base 0): 23  Top Validation Acc: 0.935064935064935
Fold [4/5] Epoch [0/100] Initial Loss: 0.1420, Training Loss: 0.1420, Initial Validation Loss: 0.1296, Validation Loss: 0.1296,V Acc: 0.2636, Top 70th Acc: 0.3117, Bottom 30th Acc: 0.1515
Fold [4/5] Epoch [10/100] Initial Loss: 0.1420, Training Loss: 0.0283, Initial Validation Loss: 0.1296, Validation Loss: 0.0367,V Acc: 0.8182, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.6061
Fold [4/5] Epoch [20/100] Initial Loss: 0.1420, Training Loss: 0.0169, Initial Validation Loss: 0.1296, Validation Loss: 0.0334,V Acc: 0.8273, Top 70th Acc: 0.8961, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.9090909090909091
Fold [5/5] Epoch [0/100] Initial Loss: 0.1365, Training Loss: 0.1365, Initial Validation Loss: 0.1347, Validation Loss: 0.1347,V Acc: 0.3704, Top 70th Acc: 0.3947, Bottom 30th Acc: 0.3125
Fold [5/5] Epoch [10/100] Initial Loss: 0.1365, Training Loss: 0.0310, Initial Validation Loss: 0.1347, Validation Loss: 0.0375,V Acc: 0.7963, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.4375
Fold [5/5] Epoch [20/100] Initial Loss: 0.1365, Training Loss: 0.0184, Initial Validation Loss: 0.1347, Validation Loss: 0.0321,V Acc: 0.8148, Top 70th Acc: 0.9868, Bottom 30th Acc: 0.4062
Stopping early at Epoch (base 0): 21  Rolling back to Epoch (base 0): 16  Top Validation Acc: 0.9868421052631579
Running train_nn.py with seed 34
CUDA:False
Training samples count:  550
Training on 30 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1419, Training Loss: 0.1419, Initial Validation Loss: 0.1345, Validation Loss: 0.1345,V Acc: 0.2252, Top 70th Acc: 0.2308, Bottom 30th Acc: 0.2121
Fold [1/5] Epoch [10/100] Initial Loss: 0.1419, Training Loss: 0.0446, Initial Validation Loss: 0.1345, Validation Loss: 0.0445,V Acc: 0.7658, Top 70th Acc: 0.8846, Bottom 30th Acc: 0.4848
Fold [1/5] Epoch [20/100] Initial Loss: 0.1419, Training Loss: 0.0208, Initial Validation Loss: 0.1345, Validation Loss: 0.0247,V Acc: 0.8559, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.6061
Fold [1/5] Epoch [30/100] Initial Loss: 0.1419, Training Loss: 0.0182, Initial Validation Loss: 0.1345, Validation Loss: 0.0242,V Acc: 0.8559, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 34  Rolling back to Epoch (base 0): 29  Top Validation Acc: 0.9487179487179487
Fold [2/5] Epoch [0/100] Initial Loss: 0.1402, Training Loss: 0.1402, Initial Validation Loss: 0.1377, Validation Loss: 0.1377,V Acc: 0.2523, Top 70th Acc: 0.2949, Bottom 30th Acc: 0.1515
Fold [2/5] Epoch [10/100] Initial Loss: 0.1402, Training Loss: 0.0437, Initial Validation Loss: 0.1377, Validation Loss: 0.0534,V Acc: 0.7658, Top 70th Acc: 0.8590, Bottom 30th Acc: 0.5455
Fold [2/5] Epoch [20/100] Initial Loss: 0.1402, Training Loss: 0.0185, Initial Validation Loss: 0.1377, Validation Loss: 0.0446,V Acc: 0.8108, Top 70th Acc: 0.8590, Bottom 30th Acc: 0.6970
Fold [5/5] Epoch [30/100] Initial Loss: 0.1378, Training Loss: 0.0159, Initial Validation Loss: 0.1302, Validation Loss: 0.0205,V Acc: 0.9074, Top 70th Acc: 0.9737, Bottom 30th Acc: 0.7500
Stopping early at Epoch (base 0): 33  Rolling back to Epoch (base 0): 28  Top Validation Acc: 0.9736842105263158
Running train_nn.py with seed 46
CUDA:False
Training samples count:  550
Training on 21 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1248, Training Loss: 0.1248, Initial Validation Loss: 0.1092, Validation Loss: 0.1092,V Acc: 0.5676, Top 70th Acc: 0.6795, Bottom 30th Acc: 0.3030
Fold [1/5] Epoch [10/100] Initial Loss: 0.1248, Training Loss: 0.0264, Initial Validation Loss: 0.1092, Validation Loss: 0.0361,V Acc: 0.8198, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.5152
Fold [1/5] Epoch [20/100] Initial Loss: 0.1248, Training Loss: 0.0185, Initial Validation Loss: 0.1092, Validation Loss: 0.0300,V Acc: 0.8468, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 22  Rolling back to Epoch (base 0): 17  Top Validation Acc: 0.9487179487179487
46 0 [array([0.77723384, 0.00494196, 0.03607556, 0.09009368, 0.09165496],
      dtype=float32)]
Fold [2/5] Epoch [0/100] Initial Loss: 0.1372, Training Loss: 0.1372, Initial Validation Loss: 0.1205, Validation Loss: 0.1205,V Acc: 0.6036, Top 70th Acc: 0.6923, Bottom 30th Acc: 0.3939
Fold [2/5] Epoch [10/100] Initial Loss: 0.1372, Training Loss: 0.0215, Initial Validation Loss: 0.1205, Validation Loss: 0.0320,V Acc: 0.8378, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.5152
Stopping early at Epoch (base 0): 18  Rolling back to Epoch (base 0): 13  Top Validation Acc: 0.9743589743589743
Fold [3/5] Epoch [0/100] Initial Loss: 0.1320, Training Loss: 0.1320, Initial Validation Loss: 0.1227, Validation Loss: 0.1227,V Acc: 0.4364, Top 70th Acc: 0.5844, Bottom 30th Acc: 0.0909
Fold [3/5] Epoch [10/100] Initial Loss: 0.1320, Training Loss: 0.0309, Initial Validation Loss: 0.1227, Validation Loss: 0.0321,V Acc: 0.8545, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6364
Fold [3/5] Epoch [20/100] Initial Loss: 0.1320, Training Loss: 0.0186, Initial Validation Loss: 0.1227, Validation Loss: 0.0271,V Acc: 0.8727, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.7879
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.935064935064935
Fold [4/5] Epoch [0/100] Initial Loss: 0.1300, Training Loss: 0.1300, Initial Validation Loss: 0.1160, Validation Loss: 0.1160,V Acc: 0.4636, Top 70th Acc: 0.5584, Bottom 30th Acc: 0.2424
Fold [4/5] Epoch [10/100] Initial Loss: 0.1300, Training Loss: 0.0256, Initial Validation Loss: 0.1160, Validation Loss: 0.0258,V Acc: 0.9000, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.7273
Stopping early at Epoch (base 0): 14  Rolling back to Epoch (base 0): 9  Top Validation Acc: 0.948051948051948
Fold [5/5] Epoch [0/100] Initial Loss: 0.1252, Training Loss: 0.1252, Initial Validation Loss: 0.1139, Validation Loss: 0.1139,V Acc: 0.4167, Top 70th Acc: 0.5526, Bottom 30th Acc: 0.0938
Fold [5/5] Epoch [10/100] Initial Loss: 0.1252, Training Loss: 0.0263, Initial Validation Loss: 0.1139, Validation Loss: 0.0336,V Acc: 0.8519, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.6250
Fold [5/5] Epoch [20/100] Initial Loss: 0.1252, Training Loss: 0.0167, Initial Validation Loss: 0.1139, Validation Loss: 0.0306,V Acc: 0.8333, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.5625
Stopping early at Epoch (base 0): 27  Rolling back to Epoch (base 0): 22  Top Validation Acc: 0.9473684210526315
Running train_nn.py with seed 47
CUDA:False
Training samples count:  550
Training on 21 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1338, Training Loss: 0.1338, Initial Validation Loss: 0.1190, Validation Loss: 0.1190,V Acc: 0.4595, Top 70th Acc: 0.5769, Bottom 30th Acc: 0.1818
Fold [1/5] Epoch [10/100] Initial Loss: 0.1338, Training Loss: 0.0227, Initial Validation Loss: 0.1190, Validation Loss: 0.0286,V Acc: 0.8198, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 17  Rolling back to Epoch (base 0): 12  Top Validation Acc: 0.9230769230769231
Fold [2/5] Epoch [0/100] Initial Loss: 0.1351, Training Loss: 0.1351, Initial Validation Loss: 0.1345, Validation Loss: 0.1345,V Acc: 0.5045, Top 70th Acc: 0.5769, Bottom 30th Acc: 0.3333
Fold [2/5] Epoch [10/100] Initial Loss: 0.1351, Training Loss: 0.0282, Initial Validation Loss: 0.1345, Validation Loss: 0.0337,V Acc: 0.8919, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.7273
Stopping early at Epoch (base 0): 18  Rolling back to Epoch (base 0): 13  Top Validation Acc: 0.9743589743589743
Fold [3/5] Epoch [0/100] Initial Loss: 0.1297, Training Loss: 0.1297, Initial Validation Loss: 0.1230, Validation Loss: 0.1230,V Acc: 0.6000, Top 70th Acc: 0.6623, Bottom 30th Acc: 0.4545
Fold [3/5] Epoch [10/100] Initial Loss: 0.1297, Training Loss: 0.0290, Initial Validation Loss: 0.1230, Validation Loss: 0.0290,V Acc: 0.9000, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.7273
Fold [3/5] Epoch [20/100] Initial Loss: 0.1297, Training Loss: 0.0173, Initial Validation Loss: 0.1230, Validation Loss: 0.0234,V Acc: 0.8909, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 22  Rolling back to Epoch (base 0): 17  Top Validation Acc: 0.974025974025974
Fold [4/5] Epoch [0/100] Initial Loss: 0.1381, Training Loss: 0.1381, Initial Validation Loss: 0.1252, Validation Loss: 0.1252,V Acc: 0.4364, Top 70th Acc: 0.5325, Bottom 30th Acc: 0.2121
Fold [4/5] Epoch [10/100] Initial Loss: 0.1381, Training Loss: 0.0291, Initial Validation Loss: 0.1252, Validation Loss: 0.0289,V Acc: 0.8455, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.5758
Fold [4/5] Epoch [20/100] Initial Loss: 0.1381, Training Loss: 0.0164, Initial Validation Loss: 0.1252, Validation Loss: 0.0239,V Acc: 0.8727, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.961038961038961
47 3 [array([0.8160342 , 0.01904256, 0.04183262, 0.06102798, 0.06206261],
      dtype=float32)]
Fold [5/5] Epoch [0/100] Initial Loss: 0.1369, Training Loss: 0.1369, Initial Validation Loss: 0.1209, Validation Loss: 0.1209,V Acc: 0.4259, Top 70th Acc: 0.5921, Bottom 30th Acc: 0.0312
Fold [5/5] Epoch [10/100] Initial Loss: 0.1369, Training Loss: 0.0304, Initial Validation Loss: 0.1209, Validation Loss: 0.0394,V Acc: 0.8148, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.5000
Stopping early at Epoch (base 0): 18  Rolling back to Epoch (base 0): 13  Top Validation Acc: 0.9342105263157895
Running train_nn.py with seed 48
CUDA:False
Training samples count:  550
Training on 21 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1274, Training Loss: 0.1274, Initial Validation Loss: 0.1114, Validation Loss: 0.1114,V Acc: 0.6126, Top 70th Acc: 0.7051, Bottom 30th Acc: 0.3939
Fold [1/5] Epoch [10/100] Initial Loss: 0.1274, Training Loss: 0.0337, Initial Validation Loss: 0.1114, Validation Loss: 0.0441,V Acc: 0.7658, Top 70th Acc: 0.8846, Bottom 30th Acc: 0.4848
Fold [1/5] Epoch [20/100] Initial Loss: 0.1274, Training Loss: 0.0223, Initial Validation Loss: 0.1114, Validation Loss: 0.0293,V Acc: 0.8559, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.6667
Fold [1/5] Epoch [30/100] Initial Loss: 0.1274, Training Loss: 0.0186, Initial Validation Loss: 0.1114, Validation Loss: 0.0315,V Acc: 0.8468, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 31  Rolling back to Epoch (base 0): 26  Top Validation Acc: 0.9615384615384616
Fold [2/5] Epoch [0/100] Initial Loss: 0.1355, Training Loss: 0.1355, Initial Validation Loss: 0.1315, Validation Loss: 0.1315,V Acc: 0.3964, Top 70th Acc: 0.5513, Bottom 30th Acc: 0.0303
Fold [2/5] Epoch [10/100] Initial Loss: 0.1355, Training Loss: 0.0324, Initial Validation Loss: 0.1315, Validation Loss: 0.0212,V Acc: 0.9369, Top 70th Acc: 1.0000, Bottom 30th Acc: 0.7879
Fold [2/5] Epoch [20/100] Initial Loss: 0.1355, Training Loss: 0.0227, Initial Validation Loss: 0.1315, Validation Loss: 0.0175,V Acc: 0.9189, Top 70th Acc: 0.9872, Bottom 30th Acc: 0.7576
Stopping early at Epoch (base 0): 20  Rolling back to Epoch (base 0): 15  Top Validation Acc: 0.9871794871794872
48 1 [array([0.72910964, 0.02182109, 0.03167932, 0.10499705, 0.11239282],
      dtype=float32)]
Fold [5/5] Epoch [30/100] Initial Loss: 0.1384, Training Loss: 0.0040, Initial Validation Loss: 0.1316, Validation Loss: 0.0218,V Acc: 0.8981, Top 70th Acc: 0.9868, Bottom 30th Acc: 0.6875
Stopping early at Epoch (base 0): 32  Rolling back to Epoch (base 0): 27  Top Validation Acc: 0.9868421052631579
Running train_nn.py with seed 26
CUDA:False
Training samples count:  550
Training on 163 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1389, Training Loss: 0.1389, Initial Validation Loss: 0.1354, Validation Loss: 0.1354,V Acc: 0.4595, Top 70th Acc: 0.5256, Bottom 30th Acc: 0.3030
Fold [1/5] Epoch [10/100] Initial Loss: 0.1389, Training Loss: 0.0142, Initial Validation Loss: 0.1354, Validation Loss: 0.0324,V Acc: 0.8649, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.6061
Fold [1/5] Epoch [20/100] Initial Loss: 0.1389, Training Loss: 0.0047, Initial Validation Loss: 0.1354, Validation Loss: 0.0288,V Acc: 0.8559, Top 70th Acc: 0.9872, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.9743589743589743
Fold [2/5] Epoch [0/100] Initial Loss: 0.1408, Training Loss: 0.1408, Initial Validation Loss: 0.1365, Validation Loss: 0.1365,V Acc: 0.2793, Top 70th Acc: 0.3333, Bottom 30th Acc: 0.1515
Fold [2/5] Epoch [10/100] Initial Loss: 0.1408, Training Loss: 0.0151, Initial Validation Loss: 0.1365, Validation Loss: 0.0264,V Acc: 0.8739, Top 70th Acc: 0.9872, Bottom 30th Acc: 0.6061
Fold [2/5] Epoch [20/100] Initial Loss: 0.1408, Training Loss: 0.0052, Initial Validation Loss: 0.1365, Validation Loss: 0.0219,V Acc: 0.8829, Top 70th Acc: 0.9872, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 27  Rolling back to Epoch (base 0): 22  Top Validation Acc: 0.9871794871794872
Fold [3/5] Epoch [0/100] Initial Loss: 0.1393, Training Loss: 0.1393, Initial Validation Loss: 0.1341, Validation Loss: 0.1341,V Acc: 0.3182, Top 70th Acc: 0.4026, Bottom 30th Acc: 0.1212
Fold [3/5] Epoch [10/100] Initial Loss: 0.1393, Training Loss: 0.0136, Initial Validation Loss: 0.1341, Validation Loss: 0.0336,V Acc: 0.8273, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.5152
Fold [3/5] Epoch [20/100] Initial Loss: 0.1393, Training Loss: 0.0044, Initial Validation Loss: 0.1341, Validation Loss: 0.0302,V Acc: 0.8091, Top 70th Acc: 0.9870, Bottom 30th Acc: 0.3939
Fold [3/5] Epoch [30/100] Initial Loss: 0.1393, Training Loss: 0.0035, Initial Validation Loss: 0.1341, Validation Loss: 0.0284,V Acc: 0.8545, Top 70th Acc: 1.0000, Bottom 30th Acc: 0.5152
Fold [3/5] Epoch [40/100] Initial Loss: 0.1393, Training Loss: 0.0033, Initial Validation Loss: 0.1341, Validation Loss: 0.0281,V Acc: 0.8727, Top 70th Acc: 0.9870, Bottom 30th Acc: 0.6061
Fold [3/5] Epoch [50/100] Initial Loss: 0.1393, Training Loss: 0.0032, Initial Validation Loss: 0.1341, Validation Loss: 0.0272,V Acc: 0.8909, Top 70th Acc: 0.9870, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 59  Rolling back to Epoch (base 0): 54  Top Validation Acc: 0.987012987012987
26 2 [array([0.34359843, 0.09927586, 0.05956819, 0.13619077, 0.36136672],
      dtype=float32)]
Fold [4/5] Epoch [0/100] Initial Loss: 0.1386, Training Loss: 0.1386, Initial Validation Loss: 0.1283, Validation Loss: 0.1283,V Acc: 0.2545, Top 70th Acc: 0.3636, Bottom 30th Acc: 0.0000
Fold [4/5] Epoch [10/100] Initial Loss: 0.1386, Training Loss: 0.0121, Initial Validation Loss: 0.1283, Validation Loss: 0.0273,V Acc: 0.8727, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.6667
Fold [4/5] Epoch [20/100] Initial Loss: 0.1386, Training Loss: 0.0047, Initial Validation Loss: 0.1283, Validation Loss: 0.0246,V Acc: 0.8455, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 20  Rolling back to Epoch (base 0): 15  Top Validation Acc: 0.974025974025974
Fold [5/5] Epoch [0/100] Initial Loss: 0.1412, Training Loss: 0.1412, Initial Validation Loss: 0.1336, Validation Loss: 0.1336,V Acc: 0.3611, Top 70th Acc: 0.4342, Bottom 30th Acc: 0.1875
Fold [5/5] Epoch [10/100] Initial Loss: 0.1412, Training Loss: 0.0219, Initial Validation Loss: 0.1336, Validation Loss: 0.0432,V Acc: 0.8148, Top 70th Acc: 0.8816, Bottom 30th Acc: 0.6562
Fold [5/5] Epoch [20/100] Initial Loss: 0.1412, Training Loss: 0.0064, Initial Validation Loss: 0.1336, Validation Loss: 0.0351,V Acc: 0.8333, Top 70th Acc: 0.9211, Bottom 30th Acc: 0.6250
Fold [5/5] Epoch [30/100] Initial Loss: 0.1412, Training Loss: 0.0045, Initial Validation Loss: 0.1336, Validation Loss: 0.0323,V Acc: 0.8611, Top 70th Acc: 0.9211, Bottom 30th Acc: 0.7188
Fold [5/5] Epoch [40/100] Initial Loss: 0.1412, Training Loss: 0.0040, Initial Validation Loss: 0.1336, Validation Loss: 0.0303,V Acc: 0.8796, Top 70th Acc: 0.9211, Bottom 30th Acc: 0.7812
Fold [5/5] Epoch [50/100] Initial Loss: 0.1412, Training Loss: 0.0037, Initial Validation Loss: 0.1336, Validation Loss: 0.0297,V Acc: 0.8981, Top 70th Acc: 0.9211, Bottom 30th Acc: 0.8438
Stopping early at Epoch (base 0): 53  Rolling back to Epoch (base 0): 48  Top Validation Acc: 0.9210526315789473
Running train_nn.py with seed 27
CUDA:False
Training samples count:  550
Training on 163 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1382, Training Loss: 0.1382, Initial Validation Loss: 0.1354, Validation Loss: 0.1354,V Acc: 0.3063, Top 70th Acc: 0.3846, Bottom 30th Acc: 0.1212
Fold [1/5] Epoch [10/100] Initial Loss: 0.1382, Training Loss: 0.0234, Initial Validation Loss: 0.1354, Validation Loss: 0.0391,V Acc: 0.8378, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.6364
Fold [1/5] Epoch [20/100] Initial Loss: 0.1382, Training Loss: 0.0055, Initial Validation Loss: 0.1354, Validation Loss: 0.0299,V Acc: 0.8559, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.6364
Fold [1/5] Epoch [30/100] Initial Loss: 0.1382, Training Loss: 0.0041, Initial Validation Loss: 0.1354, Validation Loss: 0.0289,V Acc: 0.8468, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.6061
Fold [1/5] Epoch [40/100] Initial Loss: 0.1382, Training Loss: 0.0038, Initial Validation Loss: 0.1354, Validation Loss: 0.0281,V Acc: 0.8739, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 45  Rolling back to Epoch (base 0): 40  Top Validation Acc: 0.9487179487179487
Fold [2/5] Epoch [0/100] Initial Loss: 0.1385, Training Loss: 0.1385, Initial Validation Loss: 0.1365, Validation Loss: 0.1365,V Acc: 0.2523, Top 70th Acc: 0.3333, Bottom 30th Acc: 0.0606
Fold [2/5] Epoch [10/100] Initial Loss: 0.1385, Training Loss: 0.0261, Initial Validation Loss: 0.1365, Validation Loss: 0.0403,V Acc: 0.8468, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.6667
Fold [2/5] Epoch [20/100] Initial Loss: 0.1385, Training Loss: 0.0049, Initial Validation Loss: 0.1365, Validation Loss: 0.0290,V Acc: 0.8468, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 28  Rolling back to Epoch (base 0): 23  Top Validation Acc: 0.9615384615384616
Fold [3/5] Epoch [0/100] Initial Loss: 0.1389, Training Loss: 0.1389, Initial Validation Loss: 0.1305, Validation Loss: 0.1305,V Acc: 0.4273, Top 70th Acc: 0.5455, Bottom 30th Acc: 0.1515
Fold [3/5] Epoch [10/100] Initial Loss: 0.1389, Training Loss: 0.0111, Initial Validation Loss: 0.1305, Validation Loss: 0.0360,V Acc: 0.8000, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.4848
Fold [3/5] Epoch [20/100] Initial Loss: 0.1389, Training Loss: 0.0041, Initial Validation Loss: 0.1305, Validation Loss: 0.0291,V Acc: 0.8273, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.5152
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.948051948051948
Fold [4/5] Epoch [0/100] Initial Loss: 0.1386, Training Loss: 0.1386, Initial Validation Loss: 0.1360, Validation Loss: 0.1360,V Acc: 0.2636, Top 70th Acc: 0.3506, Bottom 30th Acc: 0.0606
Fold [4/5] Epoch [10/100] Initial Loss: 0.1386, Training Loss: 0.0133, Initial Validation Loss: 0.1360, Validation Loss: 0.0279,V Acc: 0.8636, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.6061
Fold [4/5] Epoch [20/100] Initial Loss: 0.1386, Training Loss: 0.0047, Initial Validation Loss: 0.1360, Validation Loss: 0.0252,V Acc: 0.8727, Top 70th Acc: 1.0000, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 28  Rolling back to Epoch (base 0): 23  Top Validation Acc:
Training on 20 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 46
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 20 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 47
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 20 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 48
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 20 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 49
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 20 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 50
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 20 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 51
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 20 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 52
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 20 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 53
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 20 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 54
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 20 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 55
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 20 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 56
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 20 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 57
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 20 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 58
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 20 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 59
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 20 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 60
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 20 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 61
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 20 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 62
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 20 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 63
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 20 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 64
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 20 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 65
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 20 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 66
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 20 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 67
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 20 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 68
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 20 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 69
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 20 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 70
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 20 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 71
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 20 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 72
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 20 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 73
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 20 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 74
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 20 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 75
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 20 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 76
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 20 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 77
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 20 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 78
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 20 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 79
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 20 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 80
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 20 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 81
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 20 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 82
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 20 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 83
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 20 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 84
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 20 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 85
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 20 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 86
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 20 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 87
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 20 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 88
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 20 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 89
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 20 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 90
Training size: 439
Fold [1/5] Epoch [0/100] Initial Loss: 0.1309, Training Loss: 0.1309, Initial Validation Loss: 0.1248, Validation Loss: 0.1248,V Acc: 0.4685, Top 70th Acc: 0.5897, Bottom 30th Acc: 0.1818
Fold [1/5] Epoch [10/100] Initial Loss: 0.1309, Training Loss: 0.0807, Initial Validation Loss: 0.1248, Validation Loss: 0.0793,V Acc: 0.6306, Top 70th Acc: 0.7564, Bottom 30th Acc: 0.3333
Fold [1/5] Epoch [20/100] Initial Loss: 0.1309, Training Loss: 0.0792, Initial Validation Loss: 0.1248, Validation Loss: 0.0781,V Acc: 0.6396, Top 70th Acc: 0.7564, Bottom 30th Acc: 0.3636
Stopping early at Epoch (base 0): 29  Rolling back to Epoch (base 0): 24  Top Validation Acc: 0.7692307692307693
Fold [2/5] Epoch [0/100] Initial Loss: 0.1344, Training Loss: 0.1344, Initial Validation Loss: 0.1290, Validation Loss: 0.1290,V Acc: 0.3964, Top 70th Acc: 0.4359, Bottom 30th Acc: 0.3030
Fold [2/5] Epoch [10/100] Initial Loss: 0.1344, Training Loss: 0.0819, Initial Validation Loss: 0.1290, Validation Loss: 0.0803,V Acc: 0.6306, Top 70th Acc: 0.7436, Bottom 30th Acc: 0.3636
Fold [2/5] Epoch [20/100] Initial Loss: 0.1344, Training Loss: 0.0799, Initial Validation Loss: 0.1290, Validation Loss: 0.0774,V Acc: 0.6396, Top 70th Acc: 0.7436, Bottom 30th Acc: 0.3939
Stopping early at Epoch (base 0): 22  Rolling back to Epoch (base 0): 17  Top Validation Acc: 0.7435897435897436
Fold [3/5] Epoch [0/100] Initial Loss: 0.1422, Training Loss: 0.1422, Initial Validation Loss: 0.1333, Validation Loss: 0.1333,V Acc: 0.3364, Top 70th Acc: 0.3247, Bottom 30th Acc: 0.3636
Fold [3/5] Epoch [10/100] Initial Loss: 0.1422, Training Loss: 0.0826, Initial Validation Loss: 0.1333, Validation Loss: 0.0791,V Acc: 0.6545, Top 70th Acc: 0.7403, Bottom 30th Acc: 0.4545
Fold [3/5] Epoch [20/100] Initial Loss: 0.1422, Training Loss: 0.0799, Initial Validation Loss: 0.1333, Validation Loss: 0.0770,V Acc: 0.6364, Top 70th Acc: 0.7403, Bottom 30th Acc: 0.3939
Fold [3/5] Epoch [30/100] Initial Loss: 0.1422, Training Loss: 0.0791, Initial Validation Loss: 0.1333, Validation Loss: 0.0771,V Acc: 0.6364, Top 70th Acc: 0.7143, Bottom 30th Acc: 0.4545
Stopping early at Epoch (base 0): 30  Rolling back to Epoch (base 0): 25  Top Validation Acc: 0.7142857142857143
32 2 [array([0.13806023, 0.33768475, 0.15811953, 0.23060663, 0.13552883],
      dtype=float32)]
Fold [4/5] Epoch [0/100] Initial Loss: 0.1338, Training Loss: 0.1338, Initial Validation Loss: 0.1246, Validation Loss: 0.1246,V Acc: 0.4091, Top 70th Acc: 0.4286, Bottom 30th Acc: 0.3636
Fold [4/5] Epoch [10/100] Initial Loss: 0.1338, Training Loss: 0.0745, Initial Validation Loss: 0.1246, Validation Loss: 0.0928,V Acc: 0.5909, Top 70th Acc: 0.6883, Bottom 30th Acc: 0.3636
Stopping early at Epoch (base 0): 14  Rolling back to Epoch (base 0): 9  Top Validation Acc: 0.6883116883116883
Fold [5/5] Epoch [0/100] Initial Loss: 0.1296, Training Loss: 0.1296, Initial Validation Loss: 0.1118, Validation Loss: 0.1118,V Acc: 0.4815, Top 70th Acc: 0.4737, Bottom 30th Acc: 0.5000
Fold [5/5] Epoch [10/100] Initial Loss: 0.1296, Training Loss: 0.0818, Initial Validation Loss: 0.1118, Validation Loss: 0.0742,V Acc: 0.6389, Top 70th Acc: 0.7632, Bottom 30th Acc: 0.3438
Fold [5/5] Epoch [20/100] Initial Loss: 0.1296, Training Loss: 0.0805, Initial Validation Loss: 0.1118, Validation Loss: 0.0714,V Acc: 0.6481, Top 70th Acc: 0.7763, Bottom 30th Acc: 0.3438
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.7894736842105263
Running train_nn.py with seed 33
CUDA:False
Training samples count:  550
Training on 2 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1323, Training Loss: 0.1323, Initial Validation Loss: 0.1257, Validation Loss: 0.1257,V Acc: 0.5225, Top 70th Acc: 0.6538, Bottom 30th Acc: 0.2121
Fold [1/5] Epoch [10/100] Initial Loss: 0.1323, Training Loss: 0.0807, Initial Validation Loss: 0.1257, Validation Loss: 0.0842,V Acc: 0.6126, Top 70th Acc: 0.7308, Bottom 30th Acc: 0.3333
Fold [1/5] Epoch [20/100] Initial Loss: 0.1323, Training Loss: 0.0776, Initial Validation Loss: 0.1257, Validation Loss: 0.0842,V Acc: 0.5766, Top 70th Acc: 0.7179, Bottom 30th Acc: 0.2424
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.7307692307692307
Fold [2/5] Epoch [0/100] Initial Loss: 0.1342, Training Loss: 0.1342, Initial Validation Loss: 0.1369, Validation Loss: 0.1369,V Acc: 0.4955, Top 70th Acc: 0.5513, Bottom 30th Acc: 0.3636
Fold [2/5] Epoch [10/100] Initial Loss: 0.1342, Training Loss: 0.0795, Initial Validation Loss: 0.1369, Validation Loss: 0.0841,V Acc: 0.6306, Top 70th Acc: 0.7436, Bottom 30th Acc: 0.3636
Fold [2/5] Epoch [20/100] Initial Loss: 0.1342, Training Loss: 0.0771, Initial Validation Loss: 0.1369, Validation Loss: 0.0822,V Acc: 0.6667, Top 70th Acc: 0.7308, Bottom 30th Acc: 0.5152
Fold [2/5] Epoch [30/100] Initial Loss: 0.1342, Training Loss: 0.0759, Initial Validation Loss: 0.1369, Validation Loss: 0.0816,V Acc: 0.6667, Top 70th Acc: 0.7308, Bottom 30th Acc: 0.5152
Fold [2/5] Epoch [40/100] Initial Loss: 0.1342, Training Loss: 0.0758, Initial Validation Loss: 0.1369, Validation Loss: 0.0815,V Acc: 0.6757, Top 70th Acc: 0.7564, Bottom 30th Acc: 0.4848
Stopping early at Epoch (base 0): 40  Rolling back to Epoch (base 0): 35  Top Validation Acc: 0.7564102564102564
33 1 [array([0.14670159, 0.32747948, 0.14482698, 0.24404925, 0.13694261],
      dtype=float32)]
Fold [3/5] Epoch [0/100] Initial Loss: 0.1358, Training Loss: 0.1358, Initial Validation Loss: 0.1190, Validation Loss: 0.1190,V Acc: 0.5364, Top 70th Acc: 0.6753, Bottom 30th Acc: 0.2121
Fold [3/5] Epoch [10/100] Initial Loss: 0.1358, Training Loss: 0.0833, Initial Validation Loss: 0.1190, Validation Loss: 0.0716,V Acc: 0.6636, Top 70th Acc: 0.7662, Bottom 30th Acc: 0.4242
Fold [3/5] Epoch [20/100] Initial Loss: 0.1358, Training Loss: 0.0810, Initial Validation Loss: 0.1190, Validation Loss: 0.0690,V Acc: 0.6727, Top 70th Acc: 0.7662, Bottom 30th Acc: 0.4545
Fold [3/5] Epoch [30/100] Initial Loss: 0.1358, Training Loss: 0.0804, Initial Validation Loss: 0.1190, Validation Loss: 0.0687,V Acc: 0.6818, Top 70th Acc: 0.7532, Bottom 30th Acc: 0.5152
Stopping early at Epoch (base 0): 33  Rolling back to Epoch (base 0): 28  Top Validation Acc: 0.7662337662337663
Fold [4/5] Epoch [0/100] Initial Loss: 0.1401, Training Loss: 0.1401, Initial Validation Loss: 0.1266, Validation Loss: 0.1266,V Acc: 0.3000, Top 70th Acc: 0.3636, Bottom 30th Acc: 0.1515
Fold [4/5] Epoch [10/100] Initial Loss: 0.1401, Training Loss: 0.0812, Initial Validation Loss: 0.1266, Validation Loss: 0.0791,V Acc: 0.6091, Top 70th Acc: 0.6883, Bottom 30th Acc: 0.4242
Fold [4/5] Epoch [20/100] Initial Loss: 0.1401, Training Loss: 0.0781, Initial Validation Loss: 0.1266, Validation Loss: 0.0790,V Acc: 0.6000, Top 70th Acc: 0.6753, Bottom 30th Acc: 0.4242
Stopping early at Epoch (base 0): 20  Rolling back to Epoch (base 0): 15  Top Validation Acc: 0.6753246753246753
Fold [5/5] Epoch [0/100] Initial Loss: 0.1345, Training Loss: 0.1345, Initial Validation Loss: 0.1289, Validation Loss: 0.1289,V Acc: 0.3148, Top 70th Acc: 0.3816, Bottom 30th Acc: 0.1562
Fold [5/5] Epoch [10/100] Initial Loss: 0.1345, Training Loss: 0.0798, Initial Validation Loss: 0.1289, Validation Loss: 0.0801,V Acc: 0.6111, Top 70th Acc: 0.7500, Bottom 30th Acc: 0.2812
Fold [5/5] Epoch [20/100] Initial Loss: 0.1345, Training Loss: 0.0778, Initial Validation Loss: 0.1289, Validation Loss: 0.0789,V Acc: 0.6111, Top 70th Acc: 0.7500, Bottom 30th Acc: 0.2812
Fold [5/5] Epoch [30/100] Initial Loss: 0.1345, Training Loss: 0.0774, Initial Validation Loss: 0.1289, Validation Loss: 0.0786,V Acc: 0.6111, Top 70th Acc: 0.7500, Bottom 30th Acc: 0.2812
Stopping early at Epoch (base 0): 30  Rolling back to Epoch (base 0): 25  Top Validation Acc: 0.75
Running train_nn.py with seed 34
CUDA:False
Training samples count:  550
Training on 2 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1396, Training Loss: 0.1396, Initial Validation Loss: 0.1262, Validation Loss: 0.1262,V Acc: 0.3604, Top 70th Acc: 0.4359, Bottom 30th Acc: 0.1818
Fold [1/5] Epoch [10/100] Initial Loss: 0.1396, Training Loss: 0.0847, Initial Validation Loss: 0.1262, Validation Loss: 0.0715,V Acc: 0.6757, Top 70th Acc: 0.7692, Bottom 30th Acc: 0.4545
Fold [2/5] Epoch [30/100] Initial Loss: 0.1402, Training Loss: 0.0153, Initial Validation Loss: 0.1377, Validation Loss: 0.0416,V Acc: 0.8108, Top 70th Acc: 0.8718, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 39  Rolling back to Epoch (base 0): 34  Top Validation Acc: 0.8846153846153846
34 1 [array([0.74714667, 0.04993682, 0.01909689, 0.07285362, 0.11096594],
      dtype=float32)]
Fold [3/5] Epoch [0/100] Initial Loss: 0.1356, Training Loss: 0.1356, Initial Validation Loss: 0.1331, Validation Loss: 0.1331,V Acc: 0.4091, Top 70th Acc: 0.4545, Bottom 30th Acc: 0.3030
Fold [3/5] Epoch [10/100] Initial Loss: 0.1356, Training Loss: 0.0329, Initial Validation Loss: 0.1331, Validation Loss: 0.0456,V Acc: 0.7727, Top 70th Acc: 0.8831, Bottom 30th Acc: 0.5152
Fold [3/5] Epoch [20/100] Initial Loss: 0.1356, Training Loss: 0.0189, Initial Validation Loss: 0.1331, Validation Loss: 0.0329,V Acc: 0.8545, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.6667
Fold [3/5] Epoch [30/100] Initial Loss: 0.1356, Training Loss: 0.0164, Initial Validation Loss: 0.1331, Validation Loss: 0.0330,V Acc: 0.8364, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 31  Rolling back to Epoch (base 0): 26  Top Validation Acc: 0.948051948051948
Fold [4/5] Epoch [0/100] Initial Loss: 0.1361, Training Loss: 0.1361, Initial Validation Loss: 0.1310, Validation Loss: 0.1310,V Acc: 0.3545, Top 70th Acc: 0.3766, Bottom 30th Acc: 0.3030
Fold [4/5] Epoch [10/100] Initial Loss: 0.1361, Training Loss: 0.0324, Initial Validation Loss: 0.1310, Validation Loss: 0.0461,V Acc: 0.7818, Top 70th Acc: 0.8961, Bottom 30th Acc: 0.5152
Fold [4/5] Epoch [20/100] Initial Loss: 0.1361, Training Loss: 0.0176, Initial Validation Loss: 0.1310, Validation Loss: 0.0389,V Acc: 0.8000, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.4848
Fold [4/5] Epoch [30/100] Initial Loss: 0.1361, Training Loss: 0.0156, Initial Validation Loss: 0.1310, Validation Loss: 0.0385,V Acc: 0.8000, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.4848
Stopping early at Epoch (base 0): 31  Rolling back to Epoch (base 0): 26  Top Validation Acc: 0.935064935064935
Fold [5/5] Epoch [0/100] Initial Loss: 0.1385, Training Loss: 0.1385, Initial Validation Loss: 0.1313, Validation Loss: 0.1313,V Acc: 0.4352, Top 70th Acc: 0.5395, Bottom 30th Acc: 0.1875
Fold [5/5] Epoch [10/100] Initial Loss: 0.1385, Training Loss: 0.0360, Initial Validation Loss: 0.1313, Validation Loss: 0.0402,V Acc: 0.8148, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.5312
Fold [5/5] Epoch [20/100] Initial Loss: 0.1385, Training Loss: 0.0199, Initial Validation Loss: 0.1313, Validation Loss: 0.0280,V Acc: 0.8981, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.7500
Stopping early at Epoch (base 0): 27  Rolling back to Epoch (base 0): 22  Top Validation Acc: 0.9605263157894737
Running train_nn.py with seed 35
CUDA:False
Training samples count:  550
Training on 30 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1401, Training Loss: 0.1401, Initial Validation Loss: 0.1362, Validation Loss: 0.1362,V Acc: 0.2883, Top 70th Acc: 0.3462, Bottom 30th Acc: 0.1515
Fold [1/5] Epoch [10/100] Initial Loss: 0.1401, Training Loss: 0.0393, Initial Validation Loss: 0.1362, Validation Loss: 0.0431,V Acc: 0.7928, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.5152
Fold [1/5] Epoch [20/100] Initial Loss: 0.1401, Training Loss: 0.0204, Initial Validation Loss: 0.1362, Validation Loss: 0.0322,V Acc: 0.8468, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 28  Rolling back to Epoch (base 0): 23  Top Validation Acc: 0.9487179487179487
Fold [2/5] Epoch [0/100] Initial Loss: 0.1370, Training Loss: 0.1370, Initial Validation Loss: 0.1381, Validation Loss: 0.1381,V Acc: 0.2432, Top 70th Acc: 0.3205, Bottom 30th Acc: 0.0606
Fold [2/5] Epoch [10/100] Initial Loss: 0.1370, Training Loss: 0.0436, Initial Validation Loss: 0.1381, Validation Loss: 0.0530,V Acc: 0.7748, Top 70th Acc: 0.8590, Bottom 30th Acc: 0.5758
Fold [2/5] Epoch [20/100] Initial Loss: 0.1370, Training Loss: 0.0190, Initial Validation Loss: 0.1381, Validation Loss: 0.0344,V Acc: 0.8288, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.5758
Fold [2/5] Epoch [30/100] Initial Loss: 0.1370, Training Loss: 0.0161, Initial Validation Loss: 0.1381, Validation Loss: 0.0339,V Acc: 0.8378, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 34  Rolling back to Epoch (base 0): 29  Top Validation Acc: 0.9358974358974359
Fold [3/5] Epoch [0/100] Initial Loss: 0.1392, Training Loss: 0.1392, Initial Validation Loss: 0.1360, Validation Loss: 0.1360,V Acc: 0.3182, Top 70th Acc: 0.3636, Bottom 30th Acc: 0.2121
Fold [3/5] Epoch [10/100] Initial Loss: 0.1392, Training Loss: 0.0315, Initial Validation Loss: 0.1360, Validation Loss: 0.0325,V Acc: 0.8909, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.6970
Fold [3/5] Epoch [20/100] Initial Loss: 0.1392, Training Loss: 0.0199, Initial Validation Loss: 0.1360, Validation Loss: 0.0263,V Acc: 0.9000, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.7273
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.948051948051948
Fold [4/5] Epoch [0/100] Initial Loss: 0.1395, Training Loss: 0.1395, Initial Validation Loss: 0.1320, Validation Loss: 0.1320,V Acc: 0.2545, Top 70th Acc: 0.2987, Bottom 30th Acc: 0.1515
Fold [4/5] Epoch [10/100] Initial Loss: 0.1395, Training Loss: 0.0244, Initial Validation Loss: 0.1320, Validation Loss: 0.0396,V Acc: 0.8091, Top 70th Acc: 0.8961, Bottom 30th Acc: 0.6061
Fold [4/5] Epoch [20/100] Initial Loss: 0.1395, Training Loss: 0.0165, Initial Validation Loss: 0.1320, Validation Loss: 0.0369,V Acc: 0.8364, Top 70th Acc: 0.8961, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 20  Rolling back to Epoch (base 0): 15  Top Validation Acc: 0.8961038961038961
Fold [5/5] Epoch [0/100] Initial Loss: 0.1388, Training Loss: 0.1388, Initial Validation Loss: 0.1250, Validation Loss: 0.1250,V Acc: 0.3611, Top 70th Acc: 0.3947, Bottom 30th Acc: 0.2812
Fold [5/5] Epoch [10/100] Initial Loss: 0.1388, Training Loss: 0.0351, Initial Validation Loss: 0.1250, Validation Loss: 0.0401,V Acc: 0.7685, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.3750
Fold [5/5] Epoch [20/100] Initial Loss: 0.1388, Training Loss: 0.0193, Initial Validation Loss: 0.1250, Validation Loss: 0.0301,V Acc: 0.8333, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.5625
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.9342105263157895
35 4 [array([0.6863735 , 0.15151156, 0.01441961, 0.08283564, 0.06485975],
      dtype=float32)]
Running train_nn.py with seed 36
CUDA:False
Training samples count:  550
Training on 30 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1406, Training Loss: 0.1406, Initial Validation Loss: 0.1338, Validation Loss: 0.1338,V Acc: 0.2432, Top 70th Acc: 0.2692, Bottom 30th Acc: 0.1818
Fold [1/5] Epoch [10/100] Initial Loss: 0.1406, Training Loss: 0.0370, Initial Validation Loss: 0.1338, Validation Loss: 0.0414,V Acc: 0.7838, Top 70th Acc: 0.8974, Bottom 30th Acc: 0.5152
Fold [1/5] Epoch [20/100] Initial Loss: 0.1406, Training Loss: 0.0191, Initial Validation Loss: 0.1338, Validation Loss: 0.0300,V Acc: 0.8468, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.9615384615384616
Fold [2/5] Epoch [0/100] Initial Loss: 0.1376, Training Loss: 0.1376, Initial Validation Loss: 0.1367, Validation Loss: 0.1367,V Acc: 0.3784, Top 70th Acc: 0.3974, Bottom 30th Acc: 0.3333
Fold [2/5] Epoch [10/100] Initial Loss: 0.1376, Training Loss: 0.0352, Initial Validation Loss: 0.1367, Validation Loss: 0.0528,V Acc: 0.7477, Top 70th Acc: 0.8846, Bottom 30th Acc: 0.4242
Fold [2/5] Epoch [20/100] Initial Loss: 0.1376, Training Loss: 0.0177, Initial Validation Loss: 0.1367, Validation Loss: 0.0424,V Acc: 0.7658, Top 70th Acc: 0.8974, Bottom 30th Acc: 0.4545
Stopping early at Epoch (base 0): 20  Rolling back to Epoch (base 0): 15  Top Validation Acc: 0.8974358974358975
Fold [3/5] Epoch [0/100] Initial Loss: 0.1406, Training Loss: 0.1406, Initial Validation Loss: 0.1392, Validation Loss: 0.1392,V Acc: 0.2727, Top 70th Acc: 0.3636, Bottom 30th Acc: 0.0606
Fold [3/5] Epoch [10/100] Initial Loss: 0.1388, Training Loss: 0.0431, Initial Validation Loss: 0.1286, Validation Loss: 0.0455,V Acc: 0.7818, Top 70th Acc: 0.8701, Bottom 30th Acc: 0.5758
Fold [3/5] Epoch [20/100] Initial Loss: 0.1388, Training Loss: 0.0173, Initial Validation Loss: 0.1286, Validation Loss: 0.0276,V Acc: 0.8364, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 29  Rolling back to Epoch (base 0): 24  Top Validation Acc: 0.961038961038961
Fold [4/5] Epoch [0/100] Initial Loss: 0.1416, Training Loss: 0.1416, Initial Validation Loss: 0.1299, Validation Loss: 0.1299,V Acc: 0.3455, Top 70th Acc: 0.4416, Bottom 30th Acc: 0.1212
Fold [4/5] Epoch [10/100] Initial Loss: 0.1416, Training Loss: 0.0330, Initial Validation Loss: 0.1299, Validation Loss: 0.0372,V Acc: 0.8182, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.6061
Fold [4/5] Epoch [20/100] Initial Loss: 0.1416, Training Loss: 0.0177, Initial Validation Loss: 0.1299, Validation Loss: 0.0332,V Acc: 0.8091, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.4848
Fold [4/5] Epoch [30/100] Initial Loss: 0.1416, Training Loss: 0.0145, Initial Validation Loss: 0.1299, Validation Loss: 0.0329,V Acc: 0.8091, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.5152
Stopping early at Epoch (base 0): 33  Rolling back to Epoch (base 0): 28  Top Validation Acc: 0.935064935064935
Fold [5/5] Epoch [0/100] Initial Loss: 0.1435, Training Loss: 0.1435, Initial Validation Loss: 0.1359, Validation Loss: 0.1359,V Acc: 0.2407, Top 70th Acc: 0.2763, Bottom 30th Acc: 0.1562
Fold [5/5] Epoch [10/100] Initial Loss: 0.1435, Training Loss: 0.0359, Initial Validation Loss: 0.1359, Validation Loss: 0.0460,V Acc: 0.7870, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.4375
Fold [5/5] Epoch [20/100] Initial Loss: 0.1435, Training Loss: 0.0162, Initial Validation Loss: 0.1359, Validation Loss: 0.0326,V Acc: 0.8426, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.5625
Stopping early at Epoch (base 0): 28  Rolling back to Epoch (base 0): 23  Top Validation Acc: 0.9605263157894737
Running train_nn.py with seed 34
CUDA:False
Training samples count:  550
Training on 40 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1399, Training Loss: 0.1399, Initial Validation Loss: 0.1317, Validation Loss: 0.1317,V Acc: 0.3153, Top 70th Acc: 0.3462, Bottom 30th Acc: 0.2424
Fold [1/5] Epoch [10/100] Initial Loss: 0.1399, Training Loss: 0.0258, Initial Validation Loss: 0.1317, Validation Loss: 0.0264,V Acc: 0.8198, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.4848
Fold [1/5] Epoch [20/100] Initial Loss: 0.1399, Training Loss: 0.0145, Initial Validation Loss: 0.1317, Validation Loss: 0.0223,V Acc: 0.8468, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.9358974358974359
Fold [2/5] Epoch [0/100] Initial Loss: 0.1412, Training Loss: 0.1412, Initial Validation Loss: 0.1389, Validation Loss: 0.1389,V Acc: 0.2793, Top 70th Acc: 0.2692, Bottom 30th Acc: 0.3030
Fold [2/5] Epoch [10/100] Initial Loss: 0.1412, Training Loss: 0.0308, Initial Validation Loss: 0.1389, Validation Loss: 0.0437,V Acc: 0.7928, Top 70th Acc: 0.8974, Bottom 30th Acc: 0.5455
Fold [2/5] Epoch [20/100] Initial Loss: 0.1412, Training Loss: 0.0136, Initial Validation Loss: 0.1389, Validation Loss: 0.0388,V Acc: 0.7928, Top 70th Acc: 0.8974, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 22  Rolling back to Epoch (base 0): 17  Top Validation Acc: 0.9230769230769231
34 1 [array([0.46240953, 0.09364557, 0.08391991, 0.11837339, 0.24165165],
      dtype=float32)]
Fold [3/5] Epoch [0/100] Initial Loss: 0.1382, Training Loss: 0.1382, Initial Validation Loss: 0.1371, Validation Loss: 0.1371,V Acc: 0.2727, Top 70th Acc: 0.2987, Bottom 30th Acc: 0.2121
Fold [3/5] Epoch [10/100] Initial Loss: 0.1382, Training Loss: 0.0376, Initial Validation Loss: 0.1371, Validation Loss: 0.0485,V Acc: 0.8091, Top 70th Acc: 0.8701, Bottom 30th Acc: 0.6667
Fold [3/5] Epoch [20/100] Initial Loss: 0.1382, Training Loss: 0.0159, Initial Validation Loss: 0.1371, Validation Loss: 0.0330,V Acc: 0.8727, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6970
Fold [3/5] Epoch [30/100] Initial Loss: 0.1382, Training Loss: 0.0120, Initial Validation Loss: 0.1371, Validation Loss: 0.0304,V Acc: 0.8545, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 36  Rolling back to Epoch (base 0): 31  Top Validation Acc: 0.922077922077922
Fold [4/5] Epoch [0/100] Initial Loss: 0.1382, Training Loss: 0.1382, Initial Validation Loss: 0.1355, Validation Loss: 0.1355,V Acc: 0.2545, Top 70th Acc: 0.2857, Bottom 30th Acc: 0.1818
Fold [4/5] Epoch [10/100] Initial Loss: 0.1382, Training Loss: 0.0403, Initial Validation Loss: 0.1355, Validation Loss: 0.0553,V Acc: 0.7636, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.4242
Fold [4/5] Epoch [20/100] Initial Loss: 0.1382, Training Loss: 0.0208, Initial Validation Loss: 0.1355, Validation Loss: 0.0484,V Acc: 0.7636, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.4242
Fold [4/5] Epoch [30/100] Initial Loss: 0.1382, Training Loss: 0.0148, Initial Validation Loss: 0.1355, Validation Loss: 0.0425,V Acc: 0.8091, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.5152
Fold [4/5] Epoch [40/100] Initial Loss: 0.1382, Training Loss: 0.0115, Initial Validation Loss: 0.1355, Validation Loss: 0.0376,V Acc: 0.8273, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.5152
Fold [4/5] Epoch [50/100] Initial Loss: 0.1382, Training Loss: 0.0101, Initial Validation Loss: 0.1355, Validation Loss: 0.0356,V Acc: 0.8455, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.6364
Fold [4/5] Epoch [60/100] Initial Loss: 0.1382, Training Loss: 0.0093, Initial Validation Loss: 0.1355, Validation Loss: 0.0349,V Acc: 0.8273, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 60  Rolling back to Epoch (base 0): 55  Top Validation Acc: 0.948051948051948
Fold [5/5] Epoch [0/100] Initial Loss: 0.1384, Training Loss: 0.1384, Initial Validation Loss: 0.1296, Validation Loss: 0.1296,V Acc: 0.3333, Top 70th Acc: 0.3947, Bottom 30th Acc: 0.1875
Fold [5/5] Epoch [10/100] Initial Loss: 0.1384, Training Loss: 0.0336, Initial Validation Loss: 0.1296, Validation Loss: 0.0394,V Acc: 0.7870, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.3750
Fold [5/5] Epoch [20/100] Initial Loss: 0.1384, Training Loss: 0.0161, Initial Validation Loss: 0.1296, Validation Loss: 0.0267,V Acc: 0.8611, Top 70th Acc: 1.0000, Bottom 30th Acc: 0.5312
Fold [5/5] Epoch [30/100] Initial Loss: 0.1384, Training Loss: 0.0131, Initial Validation Loss: 0.1296, Validation Loss: 0.0269,V Acc: 0.8519, Top 70th Acc: 0.9737, Bottom 30th Acc: 0.5625
Stopping early at Epoch (base 0): 33  Rolling back to Epoch (base 0): 28  Top Validation Acc: 0.9736842105263158
Running train_nn.py with seed 35
CUDA:False
Training samples count:  550
Training on 40 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1384, Training Loss: 0.1384, Initial Validation Loss: 0.1374, Validation Loss: 0.1374,V Acc: 0.2523, Top 70th Acc: 0.3333, Bottom 30th Acc: 0.0606
Fold [1/5] Epoch [10/100] Initial Loss: 0.1384, Training Loss: 0.0311, Initial Validation Loss: 0.1374, Validation Loss: 0.0423,V Acc: 0.7568, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.3939
Fold [1/5] Epoch [20/100] Initial Loss: 0.1384, Training Loss: 0.0140, Initial Validation Loss: 0.1374, Validation Loss: 0.0323,V Acc: 0.8468, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 28  Rolling back to Epoch (base 0): 23  Top Validation Acc: 0.9358974358974359
Fold [2/5] Epoch [0/100] Initial Loss: 0.1375, Training Loss: 0.1375, Initial Validation Loss: 0.1373, Validation Loss: 0.1373,V Acc: 0.3604, Top 70th Acc: 0.3974, Bottom 30th Acc: 0.2727
Fold [2/5] Epoch [10/100] Initial Loss: 0.1375, Training Loss: 0.0321, Initial Validation Loss: 0.1373, Validation Loss: 0.0408,V Acc: 0.8378, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.5758
Fold [2/5] Epoch [20/100] Initial Loss: 0.1375, Training Loss: 0.0159, Initial Validation Loss: 0.1373, Validation Loss: 0.0285,V Acc: 0.8739, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.6667
Fold [2/5] Epoch [30/100] Initial Loss: 0.1375, Training Loss: 0.0125, Initial Validation Loss: 0.1373, Validation Loss: 0.0277,V Acc: 0.8829, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.6970
Fold [3/5] Epoch [0/100] Initial Loss: 0.1310, Training Loss: 0.1310, Initial Validation Loss: 0.1164, Validation Loss: 0.1164,V Acc: 0.5182, Top 70th Acc: 0.6623, Bottom 30th Acc: 0.1818
Fold [3/5] Epoch [10/100] Initial Loss: 0.1310, Training Loss: 0.0193, Initial Validation Loss: 0.1164, Validation Loss: 0.0435,V Acc: 0.7909, Top 70th Acc: 0.8961, Bottom 30th Acc: 0.5455
Fold [3/5] Epoch [20/100] Initial Loss: 0.1310, Training Loss: 0.0133, Initial Validation Loss: 0.1164, Validation Loss: 0.0463,V Acc: 0.7818, Top 70th Acc: 0.8831, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 21  Rolling back to Epoch (base 0): 16  Top Validation Acc: 0.8961038961038961
Fold [4/5] Epoch [0/100] Initial Loss: 0.1312, Training Loss: 0.1312, Initial Validation Loss: 0.1142, Validation Loss: 0.1142,V Acc: 0.4545, Top 70th Acc: 0.5714, Bottom 30th Acc: 0.1818
Fold [4/5] Epoch [10/100] Initial Loss: 0.1312, Training Loss: 0.0227, Initial Validation Loss: 0.1142, Validation Loss: 0.0290,V Acc: 0.8545, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6364
Fold [4/5] Epoch [20/100] Initial Loss: 0.1312, Training Loss: 0.0161, Initial Validation Loss: 0.1142, Validation Loss: 0.0269,V Acc: 0.8364, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 20  Rolling back to Epoch (base 0): 15  Top Validation Acc: 0.961038961038961
Fold [5/5] Epoch [0/100] Initial Loss: 0.1350, Training Loss: 0.1350, Initial Validation Loss: 0.1200, Validation Loss: 0.1200,V Acc: 0.4907, Top 70th Acc: 0.5789, Bottom 30th Acc: 0.2812
Fold [5/5] Epoch [10/100] Initial Loss: 0.1350, Training Loss: 0.0235, Initial Validation Loss: 0.1200, Validation Loss: 0.0194,V Acc: 0.9259, Top 70th Acc: 0.9868, Bottom 30th Acc: 0.7812
Stopping early at Epoch (base 0): 19  Rolling back to Epoch (base 0): 14  Top Validation Acc: 0.9868421052631579
Running train_nn.py with seed 49
CUDA:False
Training samples count:  550
Training on 21 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1266, Training Loss: 0.1266, Initial Validation Loss: 0.1055, Validation Loss: 0.1055,V Acc: 0.5586, Top 70th Acc: 0.6923, Bottom 30th Acc: 0.2424
Fold [1/5] Epoch [10/100] Initial Loss: 0.1266, Training Loss: 0.0234, Initial Validation Loss: 0.1055, Validation Loss: 0.0264,V Acc: 0.8919, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.7576
Fold [1/5] Epoch [20/100] Initial Loss: 0.1266, Training Loss: 0.0167, Initial Validation Loss: 0.1055, Validation Loss: 0.0220,V Acc: 0.9009, Top 70th Acc: 0.9872, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.9615384615384616
Fold [2/5] Epoch [0/100] Initial Loss: 0.1290, Training Loss: 0.1290, Initial Validation Loss: 0.1197, Validation Loss: 0.1197,V Acc: 0.4685, Top 70th Acc: 0.5897, Bottom 30th Acc: 0.1818
Fold [2/5] Epoch [10/100] Initial Loss: 0.1290, Training Loss: 0.0255, Initial Validation Loss: 0.1197, Validation Loss: 0.0326,V Acc: 0.8919, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.7273
Fold [2/5] Epoch [20/100] Initial Loss: 0.1290, Training Loss: 0.0213, Initial Validation Loss: 0.1197, Validation Loss: 0.0272,V Acc: 0.9009, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.7273
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.9743589743589743
Fold [3/5] Epoch [0/100] Initial Loss: 0.1360, Training Loss: 0.1360, Initial Validation Loss: 0.1256, Validation Loss: 0.1256,V Acc: 0.4455, Top 70th Acc: 0.5584, Bottom 30th Acc: 0.1818
Fold [3/5] Epoch [10/100] Initial Loss: 0.1360, Training Loss: 0.0334, Initial Validation Loss: 0.1256, Validation Loss: 0.0418,V Acc: 0.8273, Top 70th Acc: 0.8831, Bottom 30th Acc: 0.6970
Fold [3/5] Epoch [20/100] Initial Loss: 0.1360, Training Loss: 0.0228, Initial Validation Loss: 0.1256, Validation Loss: 0.0343,V Acc: 0.8182, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.935064935064935
Fold [4/5] Epoch [0/100] Initial Loss: 0.1264, Training Loss: 0.1264, Initial Validation Loss: 0.1158, Validation Loss: 0.1158,V Acc: 0.5909, Top 70th Acc: 0.6753, Bottom 30th Acc: 0.3939
Fold [4/5] Epoch [10/100] Initial Loss: 0.1264, Training Loss: 0.0263, Initial Validation Loss: 0.1158, Validation Loss: 0.0270,V Acc: 0.8545, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.6061
Fold [4/5] Epoch [20/100] Initial Loss: 0.1264, Training Loss: 0.0175, Initial Validation Loss: 0.1158, Validation Loss: 0.0247,V Acc: 0.8818, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 21  Rolling back to Epoch (base 0): 16  Top Validation Acc: 0.974025974025974
Fold [5/5] Epoch [0/100] Initial Loss: 0.1338, Training Loss: 0.1338, Initial Validation Loss: 0.1203, Validation Loss: 0.1203,V Acc: 0.4352, Top 70th Acc: 0.5789, Bottom 30th Acc: 0.0938
Fold [5/5] Epoch [10/100] Initial Loss: 0.1338, Training Loss: 0.0210, Initial Validation Loss: 0.1203, Validation Loss: 0.0352,V Acc: 0.8426, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.5938
Fold [5/5] Epoch [20/100] Initial Loss: 0.1338, Training Loss: 0.0150, Initial Validation Loss: 0.1203, Validation Loss: 0.0316,V Acc: 0.8611, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.6250
Stopping early at Epoch (base 0): 20  Rolling back to Epoch (base 0): 15  Top Validation Acc: 0.9605263157894737
49 4 [array([0.7843374 , 0.02827094, 0.03516441, 0.06577614, 0.08645107],
      dtype=float32)]
Running train_nn.py with seed 50
CUDA:False
Training samples count:  550
Training on 21 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1318, Training Loss: 0.1318, Initial Validation Loss: 0.1266, Validation Loss: 0.1266,V Acc: 0.4505, Top 70th Acc: 0.5128, Bottom 30th Acc: 0.3030
Fold [1/5] Epoch [10/100] Initial Loss: 0.1318, Training Loss: 0.0309, Initial Validation Loss: 0.1266, Validation Loss: 0.0336,V Acc: 0.8559, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 17  Rolling back to Epoch (base 0): 12  Top Validation Acc: 0.9487179487179487
Fold [2/5] Epoch [0/100] Initial Loss: 0.1413, Training Loss: 0.1413, Initial Validation Loss: 0.1294, Validation Loss: 0.1294,V Acc: 0.3333, Top 70th Acc: 0.3590, Bottom 30th Acc: 0.2727
Fold [2/5] Epoch [10/100] Initial Loss: 0.1413, Training Loss: 0.0245, Initial Validation Loss: 0.1294, Validation Loss: 0.0374,V Acc: 0.8378, Top 70th Acc: 0.8974, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 16  Rolling back to Epoch (base 0): 11  Top Validation Acc: 0.8717948717948718
Fold [3/5] Epoch [0/100] Initial Loss: 0.1270, Training Loss: 0.1270, Initial Validation Loss: 0.1176, Validation Loss: 0.1176,V Acc: 0.4636, Top 70th Acc: 0.5844, Bottom 30th Acc: 0.1818
Fold [3/5] Epoch [10/100] Initial Loss: 0.1270, Training Loss: 0.0251, Initial Validation Loss: 0.1176, Validation Loss: 0.0412,V Acc: 0.7727, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.3636
Fold [3/5] Epoch [20/100] Initial Loss: 0.1270, Training Loss: 0.0162, Initial Validation Loss: 0.1176, Validation Loss: 0.0362,V Acc: 0.8182, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.5152
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.922077922077922
Fold [4/5] Epoch [0/100] Initial Loss: 0.1336, Training Loss: 0.1336, Initial Validation Loss: 0.1213, Validation Loss: 0.1213,V Acc: 0.4636, Top 70th Acc: 0.5844, Bottom 30th Acc: 0.1818
Fold [4/5] Epoch [10/100] Initial Loss: 0.1336, Training Loss: 0.0258, Initial Validation Loss: 0.1213, Validation Loss: 0.0264,V Acc: 0.8727, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.6667
Fold [4/5] Epoch [20/100] Initial Loss: 0.1336, Training Loss: 0.0190, Initial Validation Loss: 0.1213, Validation Loss: 0.0248,V Acc: 0.8727, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 20  Rolling back to Epoch (base 0): 15  Top Validation Acc: 0.974025974025974
Fold [5/5] Epoch [0/100] Initial Loss: 0.1361, Training Loss: 0.1361, Initial Validation Loss: 0.1206, Validation Loss: 0.1206,V Acc: 0.5093, Top 70th Acc: 0.5658, Bottom 30th Acc: 0.3750
Fold [5/5] Epoch [10/100] Initial Loss: 0.1361, Training Loss: 0.0243, Initial Validation Loss: 0.1206, Validation Loss: 0.0261,V Acc: 0.8426, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.5625
Fold [4/5] Epoch [30/100] Initial Loss: 0.1390, Training Loss: 0.0217, Initial Validation Loss: 0.1353, Validation Loss: 0.0357,V Acc: 0.8455, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 31  Rolling back to Epoch (base 0): 26  Top Validation Acc: 0.9090909090909091
Fold [5/5] Epoch [0/100] Initial Loss: 0.1374, Training Loss: 0.1374, Initial Validation Loss: 0.1298, Validation Loss: 0.1298,V Acc: 0.2685, Top 70th Acc: 0.3421, Bottom 30th Acc: 0.0938
Fold [5/5] Epoch [10/100] Initial Loss: 0.1374, Training Loss: 0.0414, Initial Validation Loss: 0.1298, Validation Loss: 0.0430,V Acc: 0.8241, Top 70th Acc: 0.9079, Bottom 30th Acc: 0.6250
Fold [5/5] Epoch [20/100] Initial Loss: 0.1374, Training Loss: 0.0245, Initial Validation Loss: 0.1298, Validation Loss: 0.0334,V Acc: 0.8889, Top 70th Acc: 0.9211, Bottom 30th Acc: 0.8125
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.9210526315789473
Running train_nn.py with seed 35
CUDA:False
Training samples count:  550
Training on 20 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1431, Training Loss: 0.1431, Initial Validation Loss: 0.1360, Validation Loss: 0.1360,V Acc: 0.2973, Top 70th Acc: 0.3718, Bottom 30th Acc: 0.1212
Fold [1/5] Epoch [10/100] Initial Loss: 0.1431, Training Loss: 0.0429, Initial Validation Loss: 0.1360, Validation Loss: 0.0495,V Acc: 0.8018, Top 70th Acc: 0.8974, Bottom 30th Acc: 0.5758
Fold [1/5] Epoch [20/100] Initial Loss: 0.1431, Training Loss: 0.0242, Initial Validation Loss: 0.1360, Validation Loss: 0.0328,V Acc: 0.8468, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.6667
Fold [1/5] Epoch [30/100] Initial Loss: 0.1431, Training Loss: 0.0218, Initial Validation Loss: 0.1360, Validation Loss: 0.0316,V Acc: 0.8378, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 33  Rolling back to Epoch (base 0): 28  Top Validation Acc: 0.9358974358974359
Fold [2/5] Epoch [0/100] Initial Loss: 0.1369, Training Loss: 0.1369, Initial Validation Loss: 0.1376, Validation Loss: 0.1376,V Acc: 0.3784, Top 70th Acc: 0.4231, Bottom 30th Acc: 0.2727
Fold [2/5] Epoch [10/100] Initial Loss: 0.1369, Training Loss: 0.0417, Initial Validation Loss: 0.1376, Validation Loss: 0.0483,V Acc: 0.8378, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.6667
Fold [2/5] Epoch [20/100] Initial Loss: 0.1369, Training Loss: 0.0249, Initial Validation Loss: 0.1376, Validation Loss: 0.0356,V Acc: 0.8649, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.6970
Fold [2/5] Epoch [30/100] Initial Loss: 0.1369, Training Loss: 0.0223, Initial Validation Loss: 0.1376, Validation Loss: 0.0334,V Acc: 0.8739, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 31  Rolling back to Epoch (base 0): 26  Top Validation Acc: 0.9358974358974359
Fold [3/5] Epoch [0/100] Initial Loss: 0.1390, Training Loss: 0.1390, Initial Validation Loss: 0.1366, Validation Loss: 0.1366,V Acc: 0.2545, Top 70th Acc: 0.3117, Bottom 30th Acc: 0.1212
Fold [3/5] Epoch [10/100] Initial Loss: 0.1390, Training Loss: 0.0427, Initial Validation Loss: 0.1366, Validation Loss: 0.0387,V Acc: 0.8000, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.5152
Fold [3/5] Epoch [20/100] Initial Loss: 0.1390, Training Loss: 0.0276, Initial Validation Loss: 0.1366, Validation Loss: 0.0270,V Acc: 0.8909, Top 70th Acc: 0.9870, Bottom 30th Acc: 0.6667
Fold [3/5] Epoch [30/100] Initial Loss: 0.1390, Training Loss: 0.0242, Initial Validation Loss: 0.1366, Validation Loss: 0.0259,V Acc: 0.8909, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.7273
Stopping early at Epoch (base 0): 31  Rolling back to Epoch (base 0): 26  Top Validation Acc: 0.948051948051948
Fold [4/5] Epoch [0/100] Initial Loss: 0.1384, Training Loss: 0.1384, Initial Validation Loss: 0.1318, Validation Loss: 0.1318,V Acc: 0.2545, Top 70th Acc: 0.3377, Bottom 30th Acc: 0.0606
Fold [4/5] Epoch [10/100] Initial Loss: 0.1384, Training Loss: 0.0417, Initial Validation Loss: 0.1318, Validation Loss: 0.0514,V Acc: 0.7636, Top 70th Acc: 0.8571, Bottom 30th Acc: 0.5455
Fold [4/5] Epoch [20/100] Initial Loss: 0.1384, Training Loss: 0.0233, Initial Validation Loss: 0.1318, Validation Loss: 0.0407,V Acc: 0.7818, Top 70th Acc: 0.8961, Bottom 30th Acc: 0.5152
Stopping early at Epoch (base 0): 28  Rolling back to Epoch (base 0): 23  Top Validation Acc: 0.8701298701298701
Fold [5/5] Epoch [0/100] Initial Loss: 0.1374, Training Loss: 0.1374, Initial Validation Loss: 0.1261, Validation Loss: 0.1261,V Acc: 0.3333, Top 70th Acc: 0.3684, Bottom 30th Acc: 0.2500
Fold [5/5] Epoch [10/100] Initial Loss: 0.1374, Training Loss: 0.0351, Initial Validation Loss: 0.1261, Validation Loss: 0.0378,V Acc: 0.8241, Top 70th Acc: 0.8947, Bottom 30th Acc: 0.6562
Fold [5/5] Epoch [20/100] Initial Loss: 0.1374, Training Loss: 0.0248, Initial Validation Loss: 0.1261, Validation Loss: 0.0333,V Acc: 0.8148, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.5312
Stopping early at Epoch (base 0): 20  Rolling back to Epoch (base 0): 15  Top Validation Acc: 0.9342105263157895
35 4 [array([0.3494651 , 0.12946069, 0.09931462, 0.19202118, 0.22973844],
      dtype=float32)]
Running train_nn.py with seed 36
CUDA:False
Training samples count:  550
Training on 20 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1426, Training Loss: 0.1426, Initial Validation Loss: 0.1303, Validation Loss: 0.1303,V Acc: 0.3964, Top 70th Acc: 0.4744, Bottom 30th Acc: 0.2121
Fold [1/5] Epoch [10/100] Initial Loss: 0.1426, Training Loss: 0.0377, Initial Validation Loss: 0.1303, Validation Loss: 0.0460,V Acc: 0.7928, Top 70th Acc: 0.8718, Bottom 30th Acc: 0.6061
Fold [1/5] Epoch [20/100] Initial Loss: 0.1426, Training Loss: 0.0241, Initial Validation Loss: 0.1303, Validation Loss: 0.0329,V Acc: 0.8288, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 29  Rolling back to Epoch (base 0): 24  Top Validation Acc: 0.9358974358974359
Fold [2/5] Epoch [0/100] Initial Loss: 0.1390, Training Loss: 0.1390, Initial Validation Loss: 0.1354, Validation Loss: 0.1354,V Acc: 0.4144, Top 70th Acc: 0.4872, Bottom 30th Acc: 0.2424
Fold [2/5] Epoch [10/100] Initial Loss: 0.1390, Training Loss: 0.0404, Initial Validation Loss: 0.1354, Validation Loss: 0.0591,V Acc: 0.7027, Top 70th Acc: 0.8077, Bottom 30th Acc: 0.4545
Fold [2/5] Epoch [20/100] Initial Loss: 0.1390, Training Loss: 0.0232, Initial Validation Loss: 0.1354, Validation Loss: 0.0423,V Acc: 0.8018, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.8717948717948718
Fold [3/5] Epoch [0/100] Initial Loss: 0.1451, Training Loss: 0.1451, Initial Validation Loss: 0.1421, Validation Loss: 0.1421,V Acc: 0.2636, Top 70th Acc: 0.3117, Bottom 30th Acc: 0.1515
Fold [3/5] Epoch [10/100] Initial Loss: 0.1451, Training Loss: 0.0393, Initial Validation Loss: 0.1421, Validation Loss: 0.0425,V Acc: 0.8455, Top 70th Acc: 0.8961, Bottom 30th Acc: 0.7273
Fold [3/5] Epoch [20/100] Initial Loss: 0.1451, Training Loss: 0.0240, Initial Validation Loss: 0.1421, Validation Loss: 0.0345,V Acc: 0.8545, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 21  Rolling back to Epoch (base 0): 16  Top Validation Acc: 0.935064935064935
Fold [4/5] Epoch [0/100] Initial Loss: 0.1390, Training Loss: 0.1390, Initial Validation Loss: 0.1318, Validation Loss: 0.1318,V Acc: 0.2727, Top 70th Acc: 0.3377, Bottom 30th Acc: 0.1212
Fold [4/5] Epoch [10/100] Initial Loss: 0.1390, Training Loss: 0.0407, Initial Validation Loss: 0.1318, Validation Loss: 0.0429,V Acc: 0.7909, Top 70th Acc: 0.8831, Bottom 30th Acc: 0.5758
Fold [4/5] Epoch [20/100] Initial Loss: 0.1390, Training Loss: 0.0233, Initial Validation Loss: 0.1318, Validation Loss: 0.0381,V Acc: 0.7727, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.4545
Stopping early at Epoch (base 0): 28  Rolling back to Epoch (base 0): 23  Top Validation Acc: 0.9090909090909091
Fold [5/5] Epoch [0/100] Initial Loss: 0.1383, Training Loss: 0.1383, Initial Validation Loss: 0.1301, Validation Loss: 0.1301,V Acc: 0.3426, Top 70th Acc: 0.3421, Bottom 30th Acc: 0.3438
Fold [5/5] Epoch [10/100] Initial Loss: 0.1383, Training Loss: 0.0416, Initial Validation Loss: 0.1301, Validation Loss: 0.0314,V Acc: 0.8519, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.5938 1.0
Fold [5/5] Epoch [0/100] Initial Loss: 0.1390, Training Loss: 0.1390, Initial Validation Loss: 0.1343, Validation Loss: 0.1343,V Acc: 0.2407, Top 70th Acc: 0.2763, Bottom 30th Acc: 0.1562
Fold [5/5] Epoch [10/100] Initial Loss: 0.1390, Training Loss: 0.0245, Initial Validation Loss: 0.1343, Validation Loss: 0.0513,V Acc: 0.7407, Top 70th Acc: 0.8289, Bottom 30th Acc: 0.5312
Stopping early at Epoch (base 0): 19  Rolling back to Epoch (base 0): 14  Top Validation Acc: 0.881578947368421
27 4 [array([0.20243129, 0.05372932, 0.04611581, 0.26699182, 0.43073177],
      dtype=float32)]
Running train_nn.py with seed 28
CUDA:False
Training samples count:  550
Training on 163 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1381, Training Loss: 0.1381, Initial Validation Loss: 0.1387, Validation Loss: 0.1387,V Acc: 0.2613, Top 70th Acc: 0.3590, Bottom 30th Acc: 0.0303
Fold [1/5] Epoch [10/100] Initial Loss: 0.1381, Training Loss: 0.0180, Initial Validation Loss: 0.1387, Validation Loss: 0.0440,V Acc: 0.8018, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.5152
Fold [1/5] Epoch [20/100] Initial Loss: 0.1381, Training Loss: 0.0058, Initial Validation Loss: 0.1387, Validation Loss: 0.0385,V Acc: 0.8378, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.9358974358974359
Fold [2/5] Epoch [0/100] Initial Loss: 0.1395, Training Loss: 0.1395, Initial Validation Loss: 0.1327, Validation Loss: 0.1327,V Acc: 0.2793, Top 70th Acc: 0.3590, Bottom 30th Acc: 0.0909
Fold [2/5] Epoch [10/100] Initial Loss: 0.1395, Training Loss: 0.0144, Initial Validation Loss: 0.1327, Validation Loss: 0.0331,V Acc: 0.8108, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.4848
Fold [2/5] Epoch [20/100] Initial Loss: 0.1395, Training Loss: 0.0049, Initial Validation Loss: 0.1327, Validation Loss: 0.0302,V Acc: 0.8378, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.9487179487179487
28 1 [array([0.15019651, 0.07102719, 0.10196908, 0.19372207, 0.48308513],
      dtype=float32)]
Fold [3/5] Epoch [0/100] Initial Loss: 0.1382, Training Loss: 0.1382, Initial Validation Loss: 0.1307, Validation Loss: 0.1307,V Acc: 0.3455, Top 70th Acc: 0.4286, Bottom 30th Acc: 0.1515
Fold [3/5] Epoch [10/100] Initial Loss: 0.1382, Training Loss: 0.0144, Initial Validation Loss: 0.1307, Validation Loss: 0.0374,V Acc: 0.7909, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.5152
Fold [3/5] Epoch [20/100] Initial Loss: 0.1382, Training Loss: 0.0055, Initial Validation Loss: 0.1307, Validation Loss: 0.0348,V Acc: 0.8091, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.5455
Fold [3/5] Epoch [30/100] Initial Loss: 0.1382, Training Loss: 0.0043, Initial Validation Loss: 0.1307, Validation Loss: 0.0329,V Acc: 0.8091, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.5455
Fold [3/5] Epoch [40/100] Initial Loss: 0.1382, Training Loss: 0.0039, Initial Validation Loss: 0.1307, Validation Loss: 0.0319,V Acc: 0.8000, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.5152
Stopping early at Epoch (base 0): 47  Rolling back to Epoch (base 0): 42  Top Validation Acc: 0.922077922077922
Fold [4/5] Epoch [0/100] Initial Loss: 0.1412, Training Loss: 0.1412, Initial Validation Loss: 0.1379, Validation Loss: 0.1379,V Acc: 0.2091, Top 70th Acc: 0.2987, Bottom 30th Acc: 0.0000
Fold [4/5] Epoch [10/100] Initial Loss: 0.1412, Training Loss: 0.0192, Initial Validation Loss: 0.1379, Validation Loss: 0.0403,V Acc: 0.8364, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.5455
Fold [4/5] Epoch [20/100] Initial Loss: 0.1412, Training Loss: 0.0046, Initial Validation Loss: 0.1379, Validation Loss: 0.0292,V Acc: 0.8636, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.6061
Fold [4/5] Epoch [30/100] Initial Loss: 0.1412, Training Loss: 0.0038, Initial Validation Loss: 0.1379, Validation Loss: 0.0297,V Acc: 0.8818, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 30  Rolling back to Epoch (base 0): 25  Top Validation Acc: 0.961038961038961
Fold [5/5] Epoch [0/100] Initial Loss: 0.1372, Training Loss: 0.1372, Initial Validation Loss: 0.1274, Validation Loss: 0.1274,V Acc: 0.4074, Top 70th Acc: 0.5132, Bottom 30th Acc: 0.1562
Fold [5/5] Epoch [10/100] Initial Loss: 0.1372, Training Loss: 0.0114, Initial Validation Loss: 0.1274, Validation Loss: 0.0343,V Acc: 0.8148, Top 70th Acc: 0.9211, Bottom 30th Acc: 0.5625
Fold [5/5] Epoch [20/100] Initial Loss: 0.1372, Training Loss: 0.0047, Initial Validation Loss: 0.1274, Validation Loss: 0.0324,V Acc: 0.8148, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.5000
Stopping early at Epoch (base 0): 21  Rolling back to Epoch (base 0): 16  Top Validation Acc: 0.9473684210526315
Running train_nn.py with seed 29
CUDA:False
Training samples count:  550
Training on 163 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1368, Training Loss: 0.1368, Initial Validation Loss: 0.1379, Validation Loss: 0.1379,V Acc: 0.3243, Top 70th Acc: 0.3974, Bottom 30th Acc: 0.1515
Fold [1/5] Epoch [10/100] Initial Loss: 0.1368, Training Loss: 0.0154, Initial Validation Loss: 0.1379, Validation Loss: 0.0335,V Acc: 0.9009, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.7576
Fold [1/5] Epoch [20/100] Initial Loss: 0.1368, Training Loss: 0.0047, Initial Validation Loss: 0.1379, Validation Loss: 0.0282,V Acc: 0.9009, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.7576
Stopping early at Epoch (base 0): 29  Rolling back to Epoch (base 0): 24  Top Validation Acc: 0.9871794871794872
29 0 [array([0.26297408, 0.12003989, 0.08340459, 0.28384668, 0.24973485],
      dtype=float32)]
Fold [2/5] Epoch [0/100] Initial Loss: 0.1370, Training Loss: 0.1370, Initial Validation Loss: 0.1358, Validation Loss: 0.1358,V Acc: 0.2793, Top 70th Acc: 0.3590, Bottom 30th Acc: 0.0909
Fold [2/5] Epoch [10/100] Initial Loss: 0.1370, Training Loss: 0.0144, Initial Validation Loss: 0.1358, Validation Loss: 0.0276,V Acc: 0.8829, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.6970
Fold [2/5] Epoch [20/100] Initial Loss: 0.1370, Training Loss: 0.0049, Initial Validation Loss: 0.1358, Validation Loss: 0.0223,V Acc: 0.8919, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.6970
Fold [2/5] Epoch [30/100] Initial Loss: 0.1370, Training Loss: 0.0038, Initial Validation Loss: 0.1358, Validation Loss: 0.0213,V Acc: 0.8829, Top 70th Acc: 0.9872, Bottom 30th Acc: 0.6364
Fold [2/5] Epoch [40/100] Initial Loss: 0.1370, Training Loss: 0.0036, Initial Validation Loss: 0.1358, Validation Loss: 0.0209,V Acc: 0.8739, Top 70th Acc: 1.0000, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 47  Rolling back to Epoch (base 0): 42  Top Validation Acc: 0.9871794871794872
Fold [3/5] Epoch [0/100] Initial Loss: 0.1379, Training Loss: 0.1379, Initial Validation Loss: 0.1293, Validation Loss: 0.1293,V Acc: 0.3364, Top 70th Acc: 0.3896, Bottom 30th Acc: 0.2121
Fold [3/5] Epoch [10/100] Initial Loss: 0.1379, Training Loss: 0.0214, Initial Validation Loss: 0.1293, Validation Loss: 0.0385,V Acc: 0.7636, Top 70th Acc: 0.8831, Bottom 30th Acc: 0.4848
Fold [3/5] Epoch [20/100] Initial Loss: 0.1379, Training Loss: 0.0054, Initial Validation Loss: 0.1293, Validation Loss: 0.0328,V Acc: 0.7818, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.4848
Fold [3/5] Epoch [30/100] Initial Loss: 0.1379, Training Loss: 0.0043, Initial Validation Loss: 0.1293, Validation Loss: 0.0332,V Acc: 0.8000, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 33  Rolling back to Epoch (base 0): 28  Top Validation Acc: 0.9090909090909091
Fold [4/5] Epoch [0/100] Initial Loss: 0.1409, Training Loss: 0.1409, Initial Validation Loss: 0.1327, Validation Loss: 0.1327,V Acc: 0.3455, Top 70th Acc: 0.4026, Bottom 30th Acc: 0.2121
Fold [4/5] Epoch [10/100] Initial Loss: 0.1409, Training Loss: 0.0186, Initial Validation Loss: 0.1327, Validation Loss: 0.0375,V Acc: 0.8364, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.5758
Fold [4/5] Epoch [20/100] Initial Loss: 0.1409, Training Loss: 0.0045, Initial Validation Loss: 0.1327, Validation Loss: 0.0323,V Acc: 0.8091, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.4242
Stopping early at Epoch (base 0): 28  Rolling back to Epoch (base 0): 23  Top Validation Acc:
Fold [3/5] Epoch [10/100] Initial Loss: 0.1406, Training Loss: 0.0400, Initial Validation Loss: 0.1392, Validation Loss: 0.0444,V Acc: 0.7818, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.4848
Fold [3/5] Epoch [20/100] Initial Loss: 0.1406, Training Loss: 0.0210, Initial Validation Loss: 0.1392, Validation Loss: 0.0299,V Acc: 0.8545, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.6061
Fold [3/5] Epoch [30/100] Initial Loss: 0.1406, Training Loss: 0.0182, Initial Validation Loss: 0.1392, Validation Loss: 0.0297,V Acc: 0.8545, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 31  Rolling back to Epoch (base 0): 26  Top Validation Acc: 0.948051948051948
Fold [4/5] Epoch [0/100] Initial Loss: 0.1383, Training Loss: 0.1383, Initial Validation Loss: 0.1316, Validation Loss: 0.1316,V Acc: 0.2545, Top 70th Acc: 0.3506, Bottom 30th Acc: 0.0303
Fold [4/5] Epoch [10/100] Initial Loss: 0.1383, Training Loss: 0.0342, Initial Validation Loss: 0.1316, Validation Loss: 0.0391,V Acc: 0.8545, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.7273
Fold [4/5] Epoch [20/100] Initial Loss: 0.1383, Training Loss: 0.0185, Initial Validation Loss: 0.1316, Validation Loss: 0.0348,V Acc: 0.8545, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.7273
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.9090909090909091
Fold [5/5] Epoch [0/100] Initial Loss: 0.1373, Training Loss: 0.1373, Initial Validation Loss: 0.1294, Validation Loss: 0.1294,V Acc: 0.4352, Top 70th Acc: 0.5263, Bottom 30th Acc: 0.2188
Fold [5/5] Epoch [10/100] Initial Loss: 0.1373, Training Loss: 0.0368, Initial Validation Loss: 0.1294, Validation Loss: 0.0328,V Acc: 0.8519, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.5938
Fold [5/5] Epoch [20/100] Initial Loss: 0.1373, Training Loss: 0.0205, Initial Validation Loss: 0.1294, Validation Loss: 0.0249,V Acc: 0.8704, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.6562
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.9605263157894737
36 4 [array([0.5467913 , 0.19217576, 0.04074201, 0.14587711, 0.07441381],
      dtype=float32)]
Running train_nn.py with seed 37
CUDA:False
Training samples count:  550
Training on 30 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1377, Training Loss: 0.1377, Initial Validation Loss: 0.1349, Validation Loss: 0.1349,V Acc: 0.3153, Top 70th Acc: 0.3590, Bottom 30th Acc: 0.2121
Fold [1/5] Epoch [10/100] Initial Loss: 0.1377, Training Loss: 0.0345, Initial Validation Loss: 0.1349, Validation Loss: 0.0322,V Acc: 0.8829, Top 70th Acc: 0.9872, Bottom 30th Acc: 0.6364
Fold [1/5] Epoch [20/100] Initial Loss: 0.1377, Training Loss: 0.0206, Initial Validation Loss: 0.1349, Validation Loss: 0.0236,V Acc: 0.8649, Top 70th Acc: 0.9872, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 22  Rolling back to Epoch (base 0): 17  Top Validation Acc: 0.9871794871794872
Fold [2/5] Epoch [0/100] Initial Loss: 0.1384, Training Loss: 0.1384, Initial Validation Loss: 0.1407, Validation Loss: 0.1407,V Acc: 0.1802, Top 70th Acc: 0.1923, Bottom 30th Acc: 0.1515
Fold [2/5] Epoch [10/100] Initial Loss: 0.1384, Training Loss: 0.0379, Initial Validation Loss: 0.1407, Validation Loss: 0.0478,V Acc: 0.8108, Top 70th Acc: 0.8974, Bottom 30th Acc: 0.6061
Fold [2/5] Epoch [20/100] Initial Loss: 0.1384, Training Loss: 0.0175, Initial Validation Loss: 0.1407, Validation Loss: 0.0409,V Acc: 0.7748, Top 70th Acc: 0.8974, Bottom 30th Acc: 0.4848
Stopping early at Epoch (base 0): 27  Rolling back to Epoch (base 0): 22  Top Validation Acc: 0.9102564102564102
Fold [3/5] Epoch [0/100] Initial Loss: 0.1401, Training Loss: 0.1401, Initial Validation Loss: 0.1313, Validation Loss: 0.1313,V Acc: 0.3091, Top 70th Acc: 0.3636, Bottom 30th Acc: 0.1818
Fold [3/5] Epoch [10/100] Initial Loss: 0.1401, Training Loss: 0.0279, Initial Validation Loss: 0.1313, Validation Loss: 0.0345,V Acc: 0.8273, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.5455
Fold [3/5] Epoch [20/100] Initial Loss: 0.1401, Training Loss: 0.0182, Initial Validation Loss: 0.1313, Validation Loss: 0.0323,V Acc: 0.8000, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.4545
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.948051948051948
Fold [4/5] Epoch [0/100] Initial Loss: 0.1337, Training Loss: 0.1337, Initial Validation Loss: 0.1277, Validation Loss: 0.1277,V Acc: 0.5000, Top 70th Acc: 0.5974, Bottom 30th Acc: 0.2727
Fold [4/5] Epoch [10/100] Initial Loss: 0.1337, Training Loss: 0.0376, Initial Validation Loss: 0.1277, Validation Loss: 0.0506,V Acc: 0.7273, Top 70th Acc: 0.8701, Bottom 30th Acc: 0.3939
Fold [4/5] Epoch [20/100] Initial Loss: 0.1337, Training Loss: 0.0253, Initial Validation Loss: 0.1277, Validation Loss: 0.0428,V Acc: 0.8000, Top 70th Acc: 0.8961, Bottom 30th Acc: 0.5758
Fold [4/5] Epoch [30/100] Initial Loss: 0.1337, Training Loss: 0.0185, Initial Validation Loss: 0.1277, Validation Loss: 0.0380,V Acc: 0.8273, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 37  Rolling back to Epoch (base 0): 32  Top Validation Acc: 0.948051948051948
Fold [5/5] Epoch [0/100] Initial Loss: 0.1398, Training Loss: 0.1398, Initial Validation Loss: 0.1290, Validation Loss: 0.1290,V Acc: 0.4074, Top 70th Acc: 0.4211, Bottom 30th Acc: 0.3750
Fold [5/5] Epoch [10/100] Initial Loss: 0.1398, Training Loss: 0.0320, Initial Validation Loss: 0.1290, Validation Loss: 0.0402,V Acc: 0.8241, Top 70th Acc: 0.9079, Bottom 30th Acc: 0.6250
Fold [5/5] Epoch [20/100] Initial Loss: 0.1398, Training Loss: 0.0176, Initial Validation Loss: 0.1290, Validation Loss: 0.0345,V Acc: 0.8241, Top 70th Acc: 0.9211, Bottom 30th Acc: 0.5938
Stopping early at Epoch (base 0): 29  Rolling back to Epoch (base 0): 24  Top Validation Acc: 0.9078947368421053
37 4 [array([0.6199234 , 0.09454615, 0.03065103, 0.08898133, 0.16589807],
      dtype=float32)]
Running train_nn.py with seed 38
CUDA:False
Training samples count:  550
Training on 30 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1389, Training Loss: 0.1389, Initial Validation Loss: 0.1364, Validation Loss: 0.1364,V Acc: 0.2703, Top 70th Acc: 0.3333, Bottom 30th Acc: 0.1212
Fold [1/5] Epoch [10/100] Initial Loss: 0.1389, Training Loss: 0.0422, Initial Validation Loss: 0.1364, Validation Loss: 0.0514,V Acc: 0.7748, Top 70th Acc: 0.8974, Bottom 30th Acc: 0.4848
Fold [1/5] Epoch [20/100] Initial Loss: 0.1389, Training Loss: 0.0198, Initial Validation Loss: 0.1364, Validation Loss: 0.0351,V Acc: 0.8378, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.5758
Fold [1/5] Epoch [30/100] Initial Loss: 0.1389, Training Loss: 0.0159, Initial Validation Loss: 0.1364, Validation Loss: 0.0326,V Acc: 0.8288, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 32  Rolling back to Epoch (base 0): 27  Top Validation Acc: 0.9487179487179487
Fold [2/5] Epoch [0/100] Initial Loss: 0.1399, Training Loss: 0.1399, Initial Validation Loss: 0.1297, Validation Loss: 0.1297,V Acc: 0.3333, Top 70th Acc: 0.4359, Bottom 30th Acc: 0.0909
Fold [2/5] Epoch [10/100] Initial Loss: 0.1399, Training Loss: 0.0301, Initial Validation Loss: 0.1297, Validation Loss: 0.0469,V Acc: 0.7297, Top 70th Acc: 0.8462, Bottom 30th Acc: 0.4545
Fold [2/5] Epoch [20/100] Initial Loss: 0.1399, Training Loss: 0.0162, Initial Validation Loss: 0.1297, Validation Loss: 0.0443,V Acc: 0.7748, Top 70th Acc: 0.8718, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 22  Rolling back to Epoch (base 0): 17  Top Validation Acc: 0.8717948717948718
Fold [3/5] Epoch [0/100] Initial Loss: 0.1379, Training Loss: 0.1379, Initial Validation Loss: 0.1372, Validation Loss: 0.1372,V Acc: 0.3455, Top 70th Acc: 0.4286, Bottom 30th Acc: 0.1515
Fold [3/5] Epoch [10/100] Initial Loss: 0.1379, Training Loss: 0.0378, Initial Validation Loss: 0.1372, Validation Loss: 0.0438,V Acc: 0.7909, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.4545
Fold [3/5] Epoch [20/100] Initial Loss: 0.1379, Training Loss: 0.0258, Initial Validation Loss: 0.1372, Validation Loss: 0.0401,V Acc: 0.8000, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.4545
Fold [3/5] Epoch [30/100] Initial Loss: 0.1379, Training Loss: 0.0180, Initial Validation Loss: 0.1372, Validation Loss: 0.0340,V Acc: 0.8091, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.4242
Stopping early at Epoch (base 0): 38  Rolling back to Epoch (base 0): 33  Top Validation Acc: 0.9615384615384616
Fold [3/5] Epoch [0/100] Initial Loss: 0.1380, Training Loss: 0.1380, Initial Validation Loss: 0.1370, Validation Loss: 0.1370,V Acc: 0.2545, Top 70th Acc: 0.3377, Bottom 30th Acc: 0.0606
Fold [3/5] Epoch [10/100] Initial Loss: 0.1380, Training Loss: 0.0295, Initial Validation Loss: 0.1370, Validation Loss: 0.0289,V Acc: 0.8909, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.7273
Fold [3/5] Epoch [20/100] Initial Loss: 0.1380, Training Loss: 0.0149, Initial Validation Loss: 0.1370, Validation Loss: 0.0230,V Acc: 0.8818, Top 70th Acc: 0.9870, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 22  Rolling back to Epoch (base 0): 17  Top Validation Acc: 0.987012987012987
Fold [4/5] Epoch [0/100] Initial Loss: 0.1397, Training Loss: 0.1397, Initial Validation Loss: 0.1322, Validation Loss: 0.1322,V Acc: 0.2727, Top 70th Acc: 0.3117, Bottom 30th Acc: 0.1818
Fold [4/5] Epoch [10/100] Initial Loss: 0.1397, Training Loss: 0.0260, Initial Validation Loss: 0.1322, Validation Loss: 0.0363,V Acc: 0.8273, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.5152
Fold [4/5] Epoch [20/100] Initial Loss: 0.1397, Training Loss: 0.0136, Initial Validation Loss: 0.1322, Validation Loss: 0.0317,V Acc: 0.8273, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.5152
Stopping early at Epoch (base 0): 27  Rolling back to Epoch (base 0): 22  Top Validation Acc: 0.961038961038961
Fold [5/5] Epoch [0/100] Initial Loss: 0.1415, Training Loss: 0.1415, Initial Validation Loss: 0.1280, Validation Loss: 0.1280,V Acc: 0.3519, Top 70th Acc: 0.4211, Bottom 30th Acc: 0.1875
Fold [5/5] Epoch [10/100] Initial Loss: 0.1415, Training Loss: 0.0211, Initial Validation Loss: 0.1280, Validation Loss: 0.0303,V Acc: 0.8426, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.6250
Fold [5/5] Epoch [20/100] Initial Loss: 0.1415, Training Loss: 0.0128, Initial Validation Loss: 0.1280, Validation Loss: 0.0302,V Acc: 0.8611, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.6875
Stopping early at Epoch (base 0): 22  Rolling back to Epoch (base 0): 17  Top Validation Acc: 0.9210526315789473
35 4 [array([0.5556619 , 0.12474006, 0.05989882, 0.09389845, 0.16580069],
      dtype=float32)]
Running train_nn.py with seed 36
CUDA:False
Training samples count:  550
Training on 40 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1412, Training Loss: 0.1412, Initial Validation Loss: 0.1335, Validation Loss: 0.1335,V Acc: 0.3333, Top 70th Acc: 0.3846, Bottom 30th Acc: 0.2121
Fold [1/5] Epoch [10/100] Initial Loss: 0.1412, Training Loss: 0.0287, Initial Validation Loss: 0.1335, Validation Loss: 0.0370,V Acc: 0.8378, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.6061
Fold [1/5] Epoch [20/100] Initial Loss: 0.1412, Training Loss: 0.0149, Initial Validation Loss: 0.1335, Validation Loss: 0.0311,V Acc: 0.8378, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.9615384615384616
Fold [2/5] Epoch [0/100] Initial Loss: 0.1383, Training Loss: 0.1383, Initial Validation Loss: 0.1395, Validation Loss: 0.1395,V Acc: 0.2523, Top 70th Acc: 0.2949, Bottom 30th Acc: 0.1515
Fold [2/5] Epoch [10/100] Initial Loss: 0.1383, Training Loss: 0.0379, Initial Validation Loss: 0.1395, Validation Loss: 0.0593,V Acc: 0.7027, Top 70th Acc: 0.8205, Bottom 30th Acc: 0.4242
Fold [2/5] Epoch [20/100] Initial Loss: 0.1383, Training Loss: 0.0138, Initial Validation Loss: 0.1395, Validation Loss: 0.0416,V Acc: 0.7838, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.4545
Fold [2/5] Epoch [30/100] Initial Loss: 0.1383, Training Loss: 0.0110, Initial Validation Loss: 0.1395, Validation Loss: 0.0418,V Acc: 0.7838, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.4848
Stopping early at Epoch (base 0): 34  Rolling back to Epoch (base 0): 29  Top Validation Acc: 0.9230769230769231
Fold [3/5] Epoch [0/100] Initial Loss: 0.1368, Training Loss: 0.1368, Initial Validation Loss: 0.1369, Validation Loss: 0.1369,V Acc: 0.3545, Top 70th Acc: 0.4156, Bottom 30th Acc: 0.2121
Fold [3/5] Epoch [10/100] Initial Loss: 0.1368, Training Loss: 0.0334, Initial Validation Loss: 0.1369, Validation Loss: 0.0411,V Acc: 0.8273, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.6364
Fold [3/5] Epoch [20/100] Initial Loss: 0.1368, Training Loss: 0.0177, Initial Validation Loss: 0.1369, Validation Loss: 0.0320,V Acc: 0.8545, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.6970
Fold [3/5] Epoch [30/100] Initial Loss: 0.1368, Training Loss: 0.0140, Initial Validation Loss: 0.1369, Validation Loss: 0.0309,V Acc: 0.8455, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 31  Rolling back to Epoch (base 0): 26  Top Validation Acc: 0.935064935064935
Fold [4/5] Epoch [0/100] Initial Loss: 0.1383, Training Loss: 0.1383, Initial Validation Loss: 0.1317, Validation Loss: 0.1317,V Acc: 0.3182, Top 70th Acc: 0.3377, Bottom 30th Acc: 0.2727
Fold [4/5] Epoch [10/100] Initial Loss: 0.1383, Training Loss: 0.0282, Initial Validation Loss: 0.1317, Validation Loss: 0.0419,V Acc: 0.7818, Top 70th Acc: 0.8831, Bottom 30th Acc: 0.5455
Fold [4/5] Epoch [20/100] Initial Loss: 0.1383, Training Loss: 0.0144, Initial Validation Loss: 0.1317, Validation Loss: 0.0326,V Acc: 0.8182, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.5455
Fold [4/5] Epoch [30/100] Initial Loss: 0.1383, Training Loss: 0.0116, Initial Validation Loss: 0.1317, Validation Loss: 0.0319,V Acc: 0.8545, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.6667
Fold [4/5] Epoch [40/100] Initial Loss: 0.1383, Training Loss: 0.0107, Initial Validation Loss: 0.1317, Validation Loss: 0.0315,V Acc: 0.8182, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 42  Rolling back to Epoch (base 0): 37  Top Validation Acc: 0.922077922077922
Fold [5/5] Epoch [0/100] Initial Loss: 0.1404, Training Loss: 0.1404, Initial Validation Loss: 0.1313, Validation Loss: 0.1313,V Acc: 0.3333, Top 70th Acc: 0.3816, Bottom 30th Acc: 0.2188
Fold [5/5] Epoch [10/100] Initial Loss: 0.1404, Training Loss: 0.0353, Initial Validation Loss: 0.1313, Validation Loss: 0.0339,V Acc: 0.8611, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.6562
Fold [5/5] Epoch [20/100] Initial Loss: 0.1404, Training Loss: 0.0143, Initial Validation Loss: 0.1313, Validation Loss: 0.0253,V Acc: 0.8889, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.7188
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.9605263157894737
36 4 [array([0.38257653, 0.07051887, 0.09321642, 0.10415585, 0.34953234],
      dtype=float32)]
Running train_nn.py with seed 37
CUDA:False
Training samples count:  550
Training on 40 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1384, Training Loss: 0.1384, Initial Validation Loss: 0.1386, Validation Loss: 0.1386,V Acc: 0.2613, Top 70th Acc: 0.2308, Bottom 30th Acc: 0.3333
Fold [1/5] Epoch [10/100] Initial Loss: 0.1384, Training Loss: 0.0284, Initial Validation Loss: 0.1386, Validation Loss: 0.0325,V Acc: 0.8559, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.6061
Fold [1/5] Epoch [20/100] Initial Loss: 0.1384, Training Loss: 0.0144, Initial Validation Loss: 0.1386, Validation Loss: 0.0246,V Acc: 0.8919, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.6970
Fold [1/5] Epoch [30/100] Initial Loss: 0.1384, Training Loss: 0.0123, Initial Validation Loss: 0.1386, Validation Loss: 0.0245,V Acc: 0.8919, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 31  Rolling back to Epoch (base 0): 26  Top Validation Acc: 0.9743589743589743
Fold [2/5] Epoch [0/100] Initial Loss: 0.1400, Training Loss: 0.1400, Initial Validation Loss: 0.1387, Validation Loss: 0.1387,V Acc: 0.2793, Top 70th Acc: 0.3205, Bottom 30th Acc: 0.1818
Fold [2/5] Epoch [10/100] Initial Loss: 0.1400, Training Loss: 0.0374, Initial Validation Loss: 0.1387, Validation Loss: 0.0477,V Acc: 0.8198, Top 70th Acc: 0.8718, Bottom 30th Acc: 0.6970
Fold [2/5] Epoch [20/100] Initial Loss: 0.1400, Training Loss: 0.0150, Initial Validation Loss: 0.1387, Validation Loss: 0.0310,V Acc: 0.8649, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.6970
Fold [2/5] Epoch [30/100] Initial Loss: 0.1400, Training Loss: 0.0121, Initial Validation Loss: 0.1387, Validation Loss: 0.0312,V Acc: 0.8649, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.6667
Fold [5/5] Epoch [20/100] Initial Loss: 0.1361, Training Loss: 0.0169, Initial Validation Loss: 0.1206, Validation Loss: 0.0208,V Acc: 0.8611, Top 70th Acc: 0.9868, Bottom 30th Acc: 0.5625
Stopping early at Epoch (base 0): 21  Rolling back to Epoch (base 0): 16  Top Validation Acc: 0.9736842105263158
50 4 [array([0.77738345, 0.02081316, 0.01843933, 0.09791929, 0.08544468],
      dtype=float32)]
Running train_nn.py with seed 51
CUDA:False
Training samples count:  550
Training on 21 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1298, Training Loss: 0.1298, Initial Validation Loss: 0.1184, Validation Loss: 0.1184,V Acc: 0.4324, Top 70th Acc: 0.5128, Bottom 30th Acc: 0.2424
Fold [1/5] Epoch [10/100] Initial Loss: 0.1298, Training Loss: 0.0239, Initial Validation Loss: 0.1184, Validation Loss: 0.0232,V Acc: 0.9009, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.7273
Fold [1/5] Epoch [20/100] Initial Loss: 0.1298, Training Loss: 0.0194, Initial Validation Loss: 0.1184, Validation Loss: 0.0211,V Acc: 0.8829, Top 70th Acc: 0.9872, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 21  Rolling back to Epoch (base 0): 16  Top Validation Acc: 0.9871794871794872
51 0 [array([0.8167541 , 0.02395527, 0.04649816, 0.05282298, 0.0599695 ],
      dtype=float32)]
Fold [2/5] Epoch [0/100] Initial Loss: 0.1277, Training Loss: 0.1277, Initial Validation Loss: 0.1081, Validation Loss: 0.1081,V Acc: 0.5135, Top 70th Acc: 0.5897, Bottom 30th Acc: 0.3333
Fold [2/5] Epoch [10/100] Initial Loss: 0.1277, Training Loss: 0.0217, Initial Validation Loss: 0.1081, Validation Loss: 0.0357,V Acc: 0.8198, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.6061
Fold [2/5] Epoch [20/100] Initial Loss: 0.1277, Training Loss: 0.0158, Initial Validation Loss: 0.1081, Validation Loss: 0.0405,V Acc: 0.8108, Top 70th Acc: 0.8974, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.9230769230769231
Fold [3/5] Epoch [0/100] Initial Loss: 0.1368, Training Loss: 0.1368, Initial Validation Loss: 0.1278, Validation Loss: 0.1278,V Acc: 0.4455, Top 70th Acc: 0.5195, Bottom 30th Acc: 0.2727
Fold [3/5] Epoch [10/100] Initial Loss: 0.1368, Training Loss: 0.0292, Initial Validation Loss: 0.1278, Validation Loss: 0.0322,V Acc: 0.8545, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.6061
Fold [3/5] Epoch [20/100] Initial Loss: 0.1368, Training Loss: 0.0197, Initial Validation Loss: 0.1278, Validation Loss: 0.0247,V Acc: 0.8727, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.961038961038961
Fold [4/5] Epoch [0/100] Initial Loss: 0.1332, Training Loss: 0.1332, Initial Validation Loss: 0.1190, Validation Loss: 0.1190,V Acc: 0.4182, Top 70th Acc: 0.5065, Bottom 30th Acc: 0.2121
Fold [4/5] Epoch [10/100] Initial Loss: 0.1332, Training Loss: 0.0280, Initial Validation Loss: 0.1190, Validation Loss: 0.0382,V Acc: 0.8364, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.6061
Fold [4/5] Epoch [20/100] Initial Loss: 0.1332, Training Loss: 0.0180, Initial Validation Loss: 0.1190, Validation Loss: 0.0333,V Acc: 0.8364, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.6061
Fold [4/5] Epoch [30/100] Initial Loss: 0.1332, Training Loss: 0.0156, Initial Validation Loss: 0.1190, Validation Loss: 0.0255,V Acc: 0.8545, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 33  Rolling back to Epoch (base 0): 28  Top Validation Acc: 0.961038961038961
Fold [5/5] Epoch [0/100] Initial Loss: 0.1318, Training Loss: 0.1318, Initial Validation Loss: 0.1248, Validation Loss: 0.1248,V Acc: 0.4815, Top 70th Acc: 0.6579, Bottom 30th Acc: 0.0625
Fold [5/5] Epoch [10/100] Initial Loss: 0.1318, Training Loss: 0.0225, Initial Validation Loss: 0.1248, Validation Loss: 0.0230,V Acc: 0.9074, Top 70th Acc: 0.9868, Bottom 30th Acc: 0.7188
Fold [5/5] Epoch [20/100] Initial Loss: 0.1318, Training Loss: 0.0169, Initial Validation Loss: 0.1248, Validation Loss: 0.0232,V Acc: 0.8981, Top 70th Acc: 0.9868, Bottom 30th Acc: 0.6875
Stopping early at Epoch (base 0): 20  Rolling back to Epoch (base 0): 15  Top Validation Acc: 0.9868421052631579
Running train_nn.py with seed 52
CUDA:False
Training samples count:  550
Training on 21 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1380, Training Loss: 0.1380, Initial Validation Loss: 0.1293, Validation Loss: 0.1293,V Acc: 0.3604, Top 70th Acc: 0.3974, Bottom 30th Acc: 0.2727
Fold [1/5] Epoch [10/100] Initial Loss: 0.1380, Training Loss: 0.0272, Initial Validation Loss: 0.1293, Validation Loss: 0.0308,V Acc: 0.8378, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.5455
Fold [1/5] Epoch [20/100] Initial Loss: 0.1380, Training Loss: 0.0194, Initial Validation Loss: 0.1293, Validation Loss: 0.0241,V Acc: 0.8829, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.9487179487179487
Fold [2/5] Epoch [0/100] Initial Loss: 0.1323, Training Loss: 0.1323, Initial Validation Loss: 0.1174, Validation Loss: 0.1174,V Acc: 0.5045, Top 70th Acc: 0.5897, Bottom 30th Acc: 0.3030
Fold [2/5] Epoch [10/100] Initial Loss: 0.1323, Training Loss: 0.0234, Initial Validation Loss: 0.1174, Validation Loss: 0.0301,V Acc: 0.8468, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 16  Rolling back to Epoch (base 0): 11  Top Validation Acc: 0.9615384615384616
Fold [3/5] Epoch [0/100] Initial Loss: 0.1361, Training Loss: 0.1361, Initial Validation Loss: 0.1246, Validation Loss: 0.1246,V Acc: 0.4727, Top 70th Acc: 0.5065, Bottom 30th Acc: 0.3939
Fold [3/5] Epoch [10/100] Initial Loss: 0.1361, Training Loss: 0.0233, Initial Validation Loss: 0.1246, Validation Loss: 0.0266,V Acc: 0.8909, Top 70th Acc: 0.9870, Bottom 30th Acc: 0.6667
Fold [3/5] Epoch [20/100] Initial Loss: 0.1361, Training Loss: 0.0190, Initial Validation Loss: 0.1246, Validation Loss: 0.0231,V Acc: 0.8636, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.961038961038961
52 2 [array([0.74318534, 0.02381904, 0.03282739, 0.12274695, 0.07742132],
      dtype=float32)]
Fold [4/5] Epoch [0/100] Initial Loss: 0.1341, Training Loss: 0.1341, Initial Validation Loss: 0.1253, Validation Loss: 0.1253,V Acc: 0.5273, Top 70th Acc: 0.6234, Bottom 30th Acc: 0.3030
Fold [4/5] Epoch [10/100] Initial Loss: 0.1341, Training Loss: 0.0210, Initial Validation Loss: 0.1253, Validation Loss: 0.0400,V Acc: 0.8273, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.6061
Fold [4/5] Epoch [20/100] Initial Loss: 0.1341, Training Loss: 0.0161, Initial Validation Loss: 0.1253, Validation Loss: 0.0312,V Acc: 0.8909, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.7273
Stopping early at Epoch (base 0): 28  Rolling back to Epoch (base 0): 23  Top Validation Acc: 0.922077922077922
Fold [5/5] Epoch [0/100] Initial Loss: 0.1361, Training Loss: 0.1361, Initial Validation Loss: 0.1188, Validation Loss: 0.1188,V Acc: 0.4352, Top 70th Acc: 0.5526, Bottom 30th Acc: 0.1562
Fold [5/5] Epoch [10/100] Initial Loss: 0.1361, Training Loss: 0.0240, Initial Validation Loss: 0.1188, Validation Loss: 0.0287,V Acc: 0.8519, Top 70th Acc: 0.9737, Bottom 30th Acc: 0.5625
Fold [5/5] Epoch [20/100] Initial Loss: 0.1361, Training Loss: 0.0168, Initial Validation Loss: 0.1188, Validation Loss: 0.0265,V Acc: 0.8981, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.7812
Stopping early at Epoch (base 0): 28  Rolling back to Epoch (base 0): 23  Top Validation Acc: 0.9210526315789473
Running train_nn.py with seed 53
CUDA:False
Training samples count:  550
Training on 21 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1374, Training Loss: 0.1374, Initial Validation Loss: 0.1317, Validation Loss: 0.1317,V Acc: 0.4054, Top 70th Acc: 0.4615, Bottom 30th Acc: 0.2727
Fold [1/5] Epoch [10/100] Initial Loss: 0.1374, Training Loss: 0.0209, Initial Validation Loss: 0.1317, Validation Loss: 0.0361,V Acc: 0.8198, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 15  Rolling back to Epoch (base 0): 10  Top Validation Acc: 0.9102564102564102
Fold [2/5] Epoch [0/100] Initial Loss: 0.1384, Training Loss: 0.1384, Initial Validation Loss: 0.1280, Validation Loss: 0.1280,V Acc: 0.4595, Top 70th Acc: 0.5641, Bottom 30th Acc: 0.2121
Fold [5/5] Epoch [20/100] Initial Loss: 0.1383, Training Loss: 0.0252, Initial Validation Loss: 0.1301, Validation Loss: 0.0246,V Acc: 0.8981, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.8125
Stopping early at Epoch (base 0): 27  Rolling back to Epoch (base 0): 22  Top Validation Acc: 0.9342105263157895
36 4 [array([0.2958484 , 0.08516599, 0.11368235, 0.35515895, 0.15014428],
      dtype=float32)]
Running train_nn.py with seed 37
CUDA:False
Training samples count:  550
Training on 20 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1384, Training Loss: 0.1384, Initial Validation Loss: 0.1376, Validation Loss: 0.1376,V Acc: 0.2613, Top 70th Acc: 0.3077, Bottom 30th Acc: 0.1515
Fold [1/5] Epoch [10/100] Initial Loss: 0.1384, Training Loss: 0.0435, Initial Validation Loss: 0.1376, Validation Loss: 0.0366,V Acc: 0.8559, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.6061
Fold [1/5] Epoch [20/100] Initial Loss: 0.1384, Training Loss: 0.0261, Initial Validation Loss: 0.1376, Validation Loss: 0.0253,V Acc: 0.8649, Top 70th Acc: 0.9872, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 29  Rolling back to Epoch (base 0): 24  Top Validation Acc: 0.9743589743589743
Fold [2/5] Epoch [0/100] Initial Loss: 0.1363, Training Loss: 0.1363, Initial Validation Loss: 0.1360, Validation Loss: 0.1360,V Acc: 0.3874, Top 70th Acc: 0.4744, Bottom 30th Acc: 0.1818
Fold [2/5] Epoch [10/100] Initial Loss: 0.1363, Training Loss: 0.0364, Initial Validation Loss: 0.1360, Validation Loss: 0.0452,V Acc: 0.8288, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.6364
Fold [2/5] Epoch [20/100] Initial Loss: 0.1363, Training Loss: 0.0225, Initial Validation Loss: 0.1360, Validation Loss: 0.0383,V Acc: 0.7928, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.4848
Stopping early at Epoch (base 0): 27  Rolling back to Epoch (base 0): 22  Top Validation Acc: 0.9230769230769231
Fold [3/5] Epoch [0/100] Initial Loss: 0.1399, Training Loss: 0.1399, Initial Validation Loss: 0.1332, Validation Loss: 0.1332,V Acc: 0.2545, Top 70th Acc: 0.2468, Bottom 30th Acc: 0.2727
Fold [3/5] Epoch [10/100] Initial Loss: 0.1399, Training Loss: 0.0428, Initial Validation Loss: 0.1332, Validation Loss: 0.0457,V Acc: 0.7818, Top 70th Acc: 0.8961, Bottom 30th Acc: 0.5152
Fold [3/5] Epoch [20/100] Initial Loss: 0.1399, Training Loss: 0.0281, Initial Validation Loss: 0.1332, Validation Loss: 0.0348,V Acc: 0.8273, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.5758
Fold [3/5] Epoch [30/100] Initial Loss: 0.1399, Training Loss: 0.0240, Initial Validation Loss: 0.1332, Validation Loss: 0.0308,V Acc: 0.8636, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.7273
Fold [3/5] Epoch [40/100] Initial Loss: 0.1399, Training Loss: 0.0218, Initial Validation Loss: 0.1332, Validation Loss: 0.0289,V Acc: 0.8455, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.5758
Fold [3/5] Epoch [50/100] Initial Loss: 0.1399, Training Loss: 0.0210, Initial Validation Loss: 0.1332, Validation Loss: 0.0287,V Acc: 0.8545, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 52  Rolling back to Epoch (base 0): 47  Top Validation Acc: 0.961038961038961
Fold [4/5] Epoch [0/100] Initial Loss: 0.1360, Training Loss: 0.1360, Initial Validation Loss: 0.1326, Validation Loss: 0.1326,V Acc: 0.3091, Top 70th Acc: 0.3636, Bottom 30th Acc: 0.1818
Fold [4/5] Epoch [10/100] Initial Loss: 0.1360, Training Loss: 0.0354, Initial Validation Loss: 0.1326, Validation Loss: 0.0438,V Acc: 0.7909, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.5152
Fold [4/5] Epoch [20/100] Initial Loss: 0.1360, Training Loss: 0.0227, Initial Validation Loss: 0.1326, Validation Loss: 0.0388,V Acc: 0.8091, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 20  Rolling back to Epoch (base 0): 15  Top Validation Acc: 0.9090909090909091
Fold [5/5] Epoch [0/100] Initial Loss: 0.1392, Training Loss: 0.1392, Initial Validation Loss: 0.1298, Validation Loss: 0.1298,V Acc: 0.2500, Top 70th Acc: 0.2500, Bottom 30th Acc: 0.2500
Fold [5/5] Epoch [10/100] Initial Loss: 0.1392, Training Loss: 0.0396, Initial Validation Loss: 0.1298, Validation Loss: 0.0496,V Acc: 0.7130, Top 70th Acc: 0.8289, Bottom 30th Acc: 0.4375
Fold [5/5] Epoch [20/100] Initial Loss: 0.1392, Training Loss: 0.0233, Initial Validation Loss: 0.1298, Validation Loss: 0.0393,V Acc: 0.7685, Top 70th Acc: 0.8816, Bottom 30th Acc: 0.5000
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.8947368421052632
37 4 [array([0.22877383, 0.09715944, 0.10908951, 0.24845006, 0.31652716],
      dtype=float32)]
Running train_nn.py with seed 38
CUDA:False
Training samples count:  550
Training on 20 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1395, Training Loss: 0.1395, Initial Validation Loss: 0.1360, Validation Loss: 0.1360,V Acc: 0.2703, Top 70th Acc: 0.3462, Bottom 30th Acc: 0.0909
Fold [1/5] Epoch [10/100] Initial Loss: 0.1395, Training Loss: 0.0474, Initial Validation Loss: 0.1360, Validation Loss: 0.0527,V Acc: 0.7928, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.5152
Fold [1/5] Epoch [20/100] Initial Loss: 0.1395, Training Loss: 0.0249, Initial Validation Loss: 0.1360, Validation Loss: 0.0366,V Acc: 0.8559, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.9102564102564102
Fold [2/5] Epoch [0/100] Initial Loss: 0.1386, Training Loss: 0.1386, Initial Validation Loss: 0.1317, Validation Loss: 0.1317,V Acc: 0.2973, Top 70th Acc: 0.3205, Bottom 30th Acc: 0.2424
Fold [2/5] Epoch [10/100] Initial Loss: 0.1386, Training Loss: 0.0477, Initial Validation Loss: 0.1317, Validation Loss: 0.0559,V Acc: 0.7387, Top 70th Acc: 0.8205, Bottom 30th Acc: 0.5455
Fold [2/5] Epoch [20/100] Initial Loss: 0.1386, Training Loss: 0.0238, Initial Validation Loss: 0.1317, Validation Loss: 0.0432,V Acc: 0.7928, Top 70th Acc: 0.8718, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.8717948717948718
Fold [3/5] Epoch [0/100] Initial Loss: 0.1379, Training Loss: 0.1379, Initial Validation Loss: 0.1390, Validation Loss: 0.1390,V Acc: 0.2727, Top 70th Acc: 0.3247, Bottom 30th Acc: 0.1515
Fold [3/5] Epoch [10/100] Initial Loss: 0.1379, Training Loss: 0.0365, Initial Validation Loss: 0.1390, Validation Loss: 0.0415,V Acc: 0.8182, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.5758
Fold [3/5] Epoch [20/100] Initial Loss: 0.1379, Training Loss: 0.0247, Initial Validation Loss: 0.1390, Validation Loss: 0.0348,V Acc: 0.8273, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.935064935064935
Fold [4/5] Epoch [0/100] Initial Loss: 0.1376, Training Loss: 0.1376, Initial Validation Loss: 0.1344, Validation Loss: 0.1344,V Acc: 0.2818, Top 70th Acc: 0.3506, Bottom 30th Acc: 0.1212
Fold [4/5] Epoch [10/100] Initial Loss: 0.1376, Training Loss: 0.0347, Initial Validation Loss: 0.1344, Validation Loss: 0.0294,V Acc: 0.8636, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6667
Fold [4/5] Epoch [20/100] Initial Loss: 0.1376, Training Loss: 0.0238, Initial Validation Loss: 0.1344, Validation Loss: 0.0267,V Acc: 0.8727, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.7273
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.935064935064935
Fold [5/5] Epoch [0/100] Initial Loss: 0.1376, Training Loss: 0.1376, Initial Validation Loss: 0.1251, Validation Loss: 0.1251,V Acc: 0.2870, Top 70th Acc: 0.3684, Bottom 30th Acc: 0.0938
Fold [5/5] Epoch [10/100] Initial Loss: 0.1376, Training Loss: 0.0311, Initial Validation Loss: 0.1251, Validation Loss: 0.0405,V Acc: 0.7963, Top 70th Acc: 0.9079, Bottom 30th Acc: 0.5312
Fold [5/5] Epoch [20/100] Initial Loss: 0.1376, Training Loss: 0.0225, Initial Validation Loss: 0.1251, Validation Loss: 0.0364,V Acc: 0.8426, Top 70th Acc: 0.9079, Bottom 30th Acc: 0.6875
Fold [5/5] Epoch [30/100] Initial Loss: 0.1376, Training Loss: 0.0214, Initial Validation Loss: 0.1251, Validation Loss: 0.0347,V Acc: 0.8333, Top 70th Acc: 0.9211, Bottom 30th Acc: 0.6250
Stopping early at Epoch (base 0): 37  Rolling back to Epoch (base 0): 32  Top Validation Acc:
Fold [1/5] Epoch [20/100] Initial Loss: 0.1396, Training Loss: 0.0823, Initial Validation Loss: 0.1262, Validation Loss: 0.0674,V Acc: 0.7117, Top 70th Acc: 0.7949, Bottom 30th Acc: 0.5152
Fold [1/5] Epoch [30/100] Initial Loss: 0.1396, Training Loss: 0.0813, Initial Validation Loss: 0.1262, Validation Loss: 0.0664,V Acc: 0.7117, Top 70th Acc: 0.7949, Bottom 30th Acc: 0.5152
Fold [1/5] Epoch [40/100] Initial Loss: 0.1396, Training Loss: 0.0810, Initial Validation Loss: 0.1262, Validation Loss: 0.0654,V Acc: 0.7117, Top 70th Acc: 0.7949, Bottom 30th Acc: 0.5152
Fold [1/5] Epoch [50/100] Initial Loss: 0.1396, Training Loss: 0.0806, Initial Validation Loss: 0.1262, Validation Loss: 0.0654,V Acc: 0.7117, Top 70th Acc: 0.7949, Bottom 30th Acc: 0.5152
Stopping early at Epoch (base 0): 51  Rolling back to Epoch (base 0): 46  Top Validation Acc: 0.782051282051282
Fold [2/5] Epoch [0/100] Initial Loss: 0.1360, Training Loss: 0.1360, Initial Validation Loss: 0.1308, Validation Loss: 0.1308,V Acc: 0.3604, Top 70th Acc: 0.3590, Bottom 30th Acc: 0.3636
Fold [2/5] Epoch [10/100] Initial Loss: 0.1360, Training Loss: 0.0790, Initial Validation Loss: 0.1308, Validation Loss: 0.0888,V Acc: 0.5766, Top 70th Acc: 0.6795, Bottom 30th Acc: 0.3333
Fold [2/5] Epoch [20/100] Initial Loss: 0.1360, Training Loss: 0.0765, Initial Validation Loss: 0.1308, Validation Loss: 0.0869,V Acc: 0.5676, Top 70th Acc: 0.7308, Bottom 30th Acc: 0.1818
Stopping early at Epoch (base 0): 27  Rolling back to Epoch (base 0): 22  Top Validation Acc: 0.717948717948718
34 1 [array([0.12756845, 0.3808679 , 0.14492206, 0.22061564, 0.12602602],
      dtype=float32)]
Fold [3/5] Epoch [0/100] Initial Loss: 0.1361, Training Loss: 0.1361, Initial Validation Loss: 0.1314, Validation Loss: 0.1314,V Acc: 0.4182, Top 70th Acc: 0.5195, Bottom 30th Acc: 0.1818
Fold [3/5] Epoch [10/100] Initial Loss: 0.1361, Training Loss: 0.0808, Initial Validation Loss: 0.1314, Validation Loss: 0.0805,V Acc: 0.6455, Top 70th Acc: 0.7532, Bottom 30th Acc: 0.3939
Fold [3/5] Epoch [20/100] Initial Loss: 0.1361, Training Loss: 0.0790, Initial Validation Loss: 0.1314, Validation Loss: 0.0784,V Acc: 0.6545, Top 70th Acc: 0.7532, Bottom 30th Acc: 0.4242
Fold [3/5] Epoch [30/100] Initial Loss: 0.1361, Training Loss: 0.0781, Initial Validation Loss: 0.1314, Validation Loss: 0.0779,V Acc: 0.6455, Top 70th Acc: 0.7662, Bottom 30th Acc: 0.3636
Stopping early at Epoch (base 0): 33  Rolling back to Epoch (base 0): 28  Top Validation Acc: 0.7662337662337663
Fold [4/5] Epoch [0/100] Initial Loss: 0.1361, Training Loss: 0.1361, Initial Validation Loss: 0.1254, Validation Loss: 0.1254,V Acc: 0.2727, Top 70th Acc: 0.3247, Bottom 30th Acc: 0.1515
Fold [4/5] Epoch [10/100] Initial Loss: 0.1361, Training Loss: 0.0819, Initial Validation Loss: 0.1254, Validation Loss: 0.0810,V Acc: 0.6455, Top 70th Acc: 0.7792, Bottom 30th Acc: 0.3333
Fold [4/5] Epoch [20/100] Initial Loss: 0.1361, Training Loss: 0.0789, Initial Validation Loss: 0.1254, Validation Loss: 0.0786,V Acc: 0.6182, Top 70th Acc: 0.7403, Bottom 30th Acc: 0.3333
Fold [4/5] Epoch [30/100] Initial Loss: 0.1361, Training Loss: 0.0777, Initial Validation Loss: 0.1254, Validation Loss: 0.0772,V Acc: 0.6273, Top 70th Acc: 0.7792, Bottom 30th Acc: 0.2727
Stopping early at Epoch (base 0): 35  Rolling back to Epoch (base 0): 30  Top Validation Acc: 0.7532467532467533
Fold [5/5] Epoch [0/100] Initial Loss: 0.1358, Training Loss: 0.1358, Initial Validation Loss: 0.1235, Validation Loss: 0.1235,V Acc: 0.3611, Top 70th Acc: 0.4737, Bottom 30th Acc: 0.0938
Fold [5/5] Epoch [10/100] Initial Loss: 0.1358, Training Loss: 0.0785, Initial Validation Loss: 0.1235, Validation Loss: 0.0856,V Acc: 0.5833, Top 70th Acc: 0.6579, Bottom 30th Acc: 0.4062
Stopping early at Epoch (base 0): 18  Rolling back to Epoch (base 0): 13  Top Validation Acc: 0.6447368421052632
Running train_nn.py with seed 35
CUDA:False
Training samples count:  550
Training on 2 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1401, Training Loss: 0.1401, Initial Validation Loss: 0.1344, Validation Loss: 0.1344,V Acc: 0.3514, Top 70th Acc: 0.3846, Bottom 30th Acc: 0.2727
Fold [1/5] Epoch [10/100] Initial Loss: 0.1401, Training Loss: 0.0809, Initial Validation Loss: 0.1344, Validation Loss: 0.0806,V Acc: 0.6577, Top 70th Acc: 0.7436, Bottom 30th Acc: 0.4545
Fold [1/5] Epoch [20/100] Initial Loss: 0.1401, Training Loss: 0.0792, Initial Validation Loss: 0.1344, Validation Loss: 0.0792,V Acc: 0.6667, Top 70th Acc: 0.7564, Bottom 30th Acc: 0.4545
Fold [1/5] Epoch [30/100] Initial Loss: 0.1401, Training Loss: 0.0789, Initial Validation Loss: 0.1344, Validation Loss: 0.0780,V Acc: 0.6667, Top 70th Acc: 0.7564, Bottom 30th Acc: 0.4545
Stopping early at Epoch (base 0): 37  Rolling back to Epoch (base 0): 32  Top Validation Acc: 0.7564102564102564
Fold [2/5] Epoch [0/100] Initial Loss: 0.1401, Training Loss: 0.1401, Initial Validation Loss: 0.1358, Validation Loss: 0.1358,V Acc: 0.3243, Top 70th Acc: 0.4487, Bottom 30th Acc: 0.0303
Fold [2/5] Epoch [10/100] Initial Loss: 0.1401, Training Loss: 0.0820, Initial Validation Loss: 0.1358, Validation Loss: 0.0808,V Acc: 0.6577, Top 70th Acc: 0.7564, Bottom 30th Acc: 0.4242
Fold [2/5] Epoch [20/100] Initial Loss: 0.1401, Training Loss: 0.0790, Initial Validation Loss: 0.1358, Validation Loss: 0.0789,V Acc: 0.6577, Top 70th Acc: 0.7436, Bottom 30th Acc: 0.4545
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.7564102564102564
Fold [3/5] Epoch [0/100] Initial Loss: 0.1359, Training Loss: 0.1359, Initial Validation Loss: 0.1313, Validation Loss: 0.1313,V Acc: 0.3909, Top 70th Acc: 0.5065, Bottom 30th Acc: 0.1212
Fold [3/5] Epoch [10/100] Initial Loss: 0.1359, Training Loss: 0.0820, Initial Validation Loss: 0.1313, Validation Loss: 0.0768,V Acc: 0.6545, Top 70th Acc: 0.7922, Bottom 30th Acc: 0.3333
Fold [3/5] Epoch [20/100] Initial Loss: 0.1359, Training Loss: 0.0801, Initial Validation Loss: 0.1313, Validation Loss: 0.0745,V Acc: 0.6636, Top 70th Acc: 0.7922, Bottom 30th Acc: 0.3636
Fold [3/5] Epoch [30/100] Initial Loss: 0.1359, Training Loss: 0.0795, Initial Validation Loss: 0.1313, Validation Loss: 0.0739,V Acc: 0.6545, Top 70th Acc: 0.7922, Bottom 30th Acc: 0.3333
Stopping early at Epoch (base 0): 31  Rolling back to Epoch (base 0): 26  Top Validation Acc: 0.7662337662337663
Fold [4/5] Epoch [0/100] Initial Loss: 0.1389, Training Loss: 0.1389, Initial Validation Loss: 0.1294, Validation Loss: 0.1294,V Acc: 0.3545, Top 70th Acc: 0.4286, Bottom 30th Acc: 0.1818
Fold [4/5] Epoch [10/100] Initial Loss: 0.1389, Training Loss: 0.0785, Initial Validation Loss: 0.1294, Validation Loss: 0.0882,V Acc: 0.5727, Top 70th Acc: 0.6364, Bottom 30th Acc: 0.4242
Fold [4/5] Epoch [20/100] Initial Loss: 0.1389, Training Loss: 0.0766, Initial Validation Loss: 0.1294, Validation Loss: 0.0871,V Acc: 0.5909, Top 70th Acc: 0.6364, Bottom 30th Acc: 0.4848
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.6623376623376623
Fold [5/5] Epoch [0/100] Initial Loss: 0.1397, Training Loss: 0.1397, Initial Validation Loss: 0.1268, Validation Loss: 0.1268,V Acc: 0.3704, Top 70th Acc: 0.4342, Bottom 30th Acc: 0.2188
Fold [5/5] Epoch [10/100] Initial Loss: 0.1397, Training Loss: 0.0819, Initial Validation Loss: 0.1268, Validation Loss: 0.0778,V Acc: 0.5741, Top 70th Acc: 0.7105, Bottom 30th Acc: 0.2500
Fold [5/5] Epoch [20/100] Initial Loss: 0.1397, Training Loss: 0.0794, Initial Validation Loss: 0.1268, Validation Loss: 0.0763,V Acc: 0.5833, Top 70th Acc: 0.7105, Bottom 30th Acc: 0.2812
Stopping early at Epoch (base 0): 29  Rolling back to Epoch (base 0): 24  Top Validation Acc: 0.7105263157894737
35 4 [array([0.14643766, 0.36791727, 0.13564797, 0.21845938, 0.13153769],
      dtype=float32)]
Running train_nn.py with seed 36
CUDA:False
Training samples count:  550
Training on 2 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1381, Training Loss: 0.1381, Initial Validation Loss: 0.1277, Validation Loss: 0.1277,V Acc: 0.3333, Top 70th Acc: 0.3846, Bottom 30th Acc: 0.2121
Fold [1/5] Epoch [10/100] Initial Loss: 0.1381, Training Loss: 0.0822, Initial Validation Loss: 0.1277, Validation Loss: 0.0796,V Acc: 0.5946, Top 70th Acc: 0.7051, Bottom 30th Acc: 0.3333
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 20 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 91
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 20 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 92
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 20 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 93
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 20 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 94
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 20 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 95
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 20 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 96
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 20 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 97
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 20 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 98
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 20 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 99
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 20 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 100
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 20 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5

Training size: 440
Training size: 440
Training size: 442
Training on 163 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 46
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 163 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 47
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 163 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 48
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 163 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 49
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 163 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 50
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 163 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 51
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 163 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 52
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 163 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 53
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 163 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 54
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 163 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 55
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 163 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 56
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 163 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 57
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 163 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 58
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 163 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 59
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 163 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 60
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 163 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 61
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 163 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 62
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 163 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 63
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 163 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 64
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 163 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 65
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 163 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 66
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 163 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 67
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 163 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 68
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 163 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 69
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 163 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 70
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 163 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 71
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 163 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 72
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 163 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 73
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 163 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 74
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 163 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 75
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 163 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 76
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 163 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 77
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 163 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 78
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 163 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 79
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 163 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 80
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 163 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 81
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 163 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 82
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 163 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 83
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 163 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 84
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 163 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 85
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 163 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 86
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 163 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 87
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 163 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 88
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 163 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 89
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Stopping early at Epoch (base 0): 32  Rolling back to Epoch (base 0): 27  Top Validation Acc: 0.9487179487179487
Fold [3/5] Epoch [0/100] Initial Loss: 0.1388, Training Loss: 0.1388, Initial Validation Loss: 0.1328, Validation Loss: 0.1328,V Acc: 0.2545, Top 70th Acc: 0.3247, Bottom 30th Acc: 0.0909
Fold [3/5] Epoch [10/100] Initial Loss: 0.1388, Training Loss: 0.0299, Initial Validation Loss: 0.1328, Validation Loss: 0.0374,V Acc: 0.8091, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.5758
Fold [3/5] Epoch [20/100] Initial Loss: 0.1388, Training Loss: 0.0140, Initial Validation Loss: 0.1328, Validation Loss: 0.0289,V Acc: 0.8455, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.948051948051948
Fold [4/5] Epoch [0/100] Initial Loss: 0.1378, Training Loss: 0.1378, Initial Validation Loss: 0.1332, Validation Loss: 0.1332,V Acc: 0.3000, Top 70th Acc: 0.3506, Bottom 30th Acc: 0.1818
Fold [4/5] Epoch [10/100] Initial Loss: 0.1378, Training Loss: 0.0276, Initial Validation Loss: 0.1332, Validation Loss: 0.0388,V Acc: 0.8000, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.4848
Fold [4/5] Epoch [20/100] Initial Loss: 0.1378, Training Loss: 0.0131, Initial Validation Loss: 0.1332, Validation Loss: 0.0332,V Acc: 0.8364, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 21  Rolling back to Epoch (base 0): 16  Top Validation Acc: 0.961038961038961
Fold [5/5] Epoch [0/100] Initial Loss: 0.1385, Training Loss: 0.1385, Initial Validation Loss: 0.1286, Validation Loss: 0.1286,V Acc: 0.2685, Top 70th Acc: 0.3158, Bottom 30th Acc: 0.1562
Fold [5/5] Epoch [10/100] Initial Loss: 0.1385, Training Loss: 0.0295, Initial Validation Loss: 0.1286, Validation Loss: 0.0362,V Acc: 0.8611, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.6875
Fold [5/5] Epoch [20/100] Initial Loss: 0.1385, Training Loss: 0.0151, Initial Validation Loss: 0.1286, Validation Loss: 0.0312,V Acc: 0.8333, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.5625
Stopping early at Epoch (base 0): 29  Rolling back to Epoch (base 0): 24  Top Validation Acc: 0.9342105263157895
37 4 [array([0.4114001 , 0.05721245, 0.05566516, 0.11671709, 0.35900518],
      dtype=float32)]
Running train_nn.py with seed 38
CUDA:False
Training samples count:  550
Training on 40 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1389, Training Loss: 0.1389, Initial Validation Loss: 0.1368, Validation Loss: 0.1368,V Acc: 0.2523, Top 70th Acc: 0.3462, Bottom 30th Acc: 0.0303
Fold [1/5] Epoch [10/100] Initial Loss: 0.1389, Training Loss: 0.0362, Initial Validation Loss: 0.1368, Validation Loss: 0.0497,V Acc: 0.7568, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.3939
Fold [1/5] Epoch [20/100] Initial Loss: 0.1389, Training Loss: 0.0148, Initial Validation Loss: 0.1368, Validation Loss: 0.0363,V Acc: 0.8108, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.9230769230769231
Fold [2/5] Epoch [0/100] Initial Loss: 0.1401, Training Loss: 0.1401, Initial Validation Loss: 0.1324, Validation Loss: 0.1324,V Acc: 0.3153, Top 70th Acc: 0.2692, Bottom 30th Acc: 0.4242
Fold [2/5] Epoch [10/100] Initial Loss: 0.1401, Training Loss: 0.0221, Initial Validation Loss: 0.1324, Validation Loss: 0.0380,V Acc: 0.7928, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.4848
Stopping early at Epoch (base 0): 19  Rolling back to Epoch (base 0): 14  Top Validation Acc: 0.8846153846153846
Fold [3/5] Epoch [0/100] Initial Loss: 0.1371, Training Loss: 0.1371, Initial Validation Loss: 0.1367, Validation Loss: 0.1367,V Acc: 0.4455, Top 70th Acc: 0.4416, Bottom 30th Acc: 0.4545
Fold [3/5] Epoch [10/100] Initial Loss: 0.1371, Training Loss: 0.0239, Initial Validation Loss: 0.1367, Validation Loss: 0.0362,V Acc: 0.8364, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.5758
Fold [3/5] Epoch [20/100] Initial Loss: 0.1371, Training Loss: 0.0139, Initial Validation Loss: 0.1367, Validation Loss: 0.0315,V Acc: 0.8455, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.5758
Fold [3/5] Epoch [30/100] Initial Loss: 0.1371, Training Loss: 0.0118, Initial Validation Loss: 0.1367, Validation Loss: 0.0311,V Acc: 0.8364, Top 70th Acc: 0.9870, Bottom 30th Acc: 0.4848
Stopping early at Epoch (base 0): 30  Rolling back to Epoch (base 0): 25  Top Validation Acc: 0.987012987012987
Fold [4/5] Epoch [0/100] Initial Loss: 0.1404, Training Loss: 0.1404, Initial Validation Loss: 0.1363, Validation Loss: 0.1363,V Acc: 0.2455, Top 70th Acc: 0.3117, Bottom 30th Acc: 0.0909
Fold [4/5] Epoch [10/100] Initial Loss: 0.1404, Training Loss: 0.0319, Initial Validation Loss: 0.1363, Validation Loss: 0.0288,V Acc: 0.8727, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.6667
Fold [4/5] Epoch [20/100] Initial Loss: 0.1404, Training Loss: 0.0157, Initial Validation Loss: 0.1363, Validation Loss: 0.0212,V Acc: 0.8818, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 28  Rolling back to Epoch (base 0): 23  Top Validation Acc: 0.961038961038961
Fold [5/5] Epoch [0/100] Initial Loss: 0.1376, Training Loss: 0.1376, Initial Validation Loss: 0.1282, Validation Loss: 0.1282,V Acc: 0.2593, Top 70th Acc: 0.3553, Bottom 30th Acc: 0.0312
Fold [5/5] Epoch [10/100] Initial Loss: 0.1376, Training Loss: 0.0260, Initial Validation Loss: 0.1282, Validation Loss: 0.0384,V Acc: 0.8056, Top 70th Acc: 0.9079, Bottom 30th Acc: 0.5625
Fold [5/5] Epoch [20/100] Initial Loss: 0.1376, Training Loss: 0.0142, Initial Validation Loss: 0.1282, Validation Loss: 0.0324,V Acc: 0.8241, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.5000
Fold [5/5] Epoch [30/100] Initial Loss: 0.1376, Training Loss: 0.0115, Initial Validation Loss: 0.1282, Validation Loss: 0.0310,V Acc: 0.8519, Top 70th Acc: 0.9737, Bottom 30th Acc: 0.5625
Stopping early at Epoch (base 0): 35  Rolling back to Epoch (base 0): 30  Top Validation Acc: 0.9605263157894737
38 4 [array([0.37049356, 0.07127092, 0.1096025 , 0.1400114 , 0.30862156],
      dtype=float32)]
Running train_nn.py with seed 39
CUDA:False
Training samples count:  550
Training on 40 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1397, Training Loss: 0.1397, Initial Validation Loss: 0.1339, Validation Loss: 0.1339,V Acc: 0.3333, Top 70th Acc: 0.3974, Bottom 30th Acc: 0.1818
Fold [1/5] Epoch [10/100] Initial Loss: 0.1397, Training Loss: 0.0264, Initial Validation Loss: 0.1339, Validation Loss: 0.0359,V Acc: 0.8559, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.7273
Fold [1/5] Epoch [20/100] Initial Loss: 0.1397, Training Loss: 0.0129, Initial Validation Loss: 0.1339, Validation Loss: 0.0279,V Acc: 0.8468, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.5758
Fold [1/5] Epoch [30/100] Initial Loss: 0.1397, Training Loss: 0.0110, Initial Validation Loss: 0.1339, Validation Loss: 0.0272,V Acc: 0.8649, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 38  Rolling back to Epoch (base 0): 33  Top Validation Acc: 0.9615384615384616
Fold [2/5] Epoch [0/100] Initial Loss: 0.1402, Training Loss: 0.1402, Initial Validation Loss: 0.1350, Validation Loss: 0.1350,V Acc: 0.2613, Top 70th Acc: 0.2692, Bottom 30th Acc: 0.2424
Fold [2/5] Epoch [10/100] Initial Loss: 0.1402, Training Loss: 0.0219, Initial Validation Loss: 0.1350, Validation Loss: 0.0322,V Acc: 0.8378, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.5455
Fold [2/5] Epoch [20/100] Initial Loss: 0.1402, Training Loss: 0.0142, Initial Validation Loss: 0.1350, Validation Loss: 0.0278,V Acc: 0.8649, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.9615384615384616
39 1 [array([0.5554923 , 0.07681619, 0.06288681, 0.08513825, 0.2196664 ],
      dtype=float32)]
Fold [3/5] Epoch [0/100] Initial Loss: 0.1405, Training Loss: 0.1405, Initial Validation Loss: 0.1330, Validation Loss: 0.1330,V Acc: 0.3909, Top 70th Acc: 0.4286, Bottom 30th Acc: 0.3030
Fold [3/5] Epoch [10/100] Initial Loss: 0.1405, Training Loss: 0.0282, Initial Validation Loss: 0.1330, Validation Loss: 0.0401,V Acc: 0.8000, Top 70th Acc: 0.8961, Bottom 30th Acc: 0.5758
Fold [3/5] Epoch [20/100] Initial Loss: 0.1405, Training Loss: 0.0136, Initial Validation Loss: 0.1330, Validation Loss: 0.0328,V Acc: 0.8000, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.4848
Stopping early at Epoch (base 0): 37  Rolling back to Epoch (base 0): 32  Top Validation Acc: 0.974025974025974
Fold [4/5] Epoch [0/100] Initial Loss: 0.1421, Training Loss: 0.1421, Initial Validation Loss: 0.1350, Validation Loss: 0.1350,V Acc: 0.3182, Top 70th Acc: 0.3377, Bottom 30th Acc: 0.2727
Fold [4/5] Epoch [10/100] Initial Loss: 0.1421, Training Loss: 0.0490, Initial Validation Loss: 0.1350, Validation Loss: 0.0470,V Acc: 0.7909, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.4545
Fold [4/5] Epoch [20/100] Initial Loss: 0.1421, Training Loss: 0.0224, Initial Validation Loss: 0.1350, Validation Loss: 0.0262,V Acc: 0.8636, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 27  Rolling back to Epoch (base 0): 22  Top Validation Acc: 0.948051948051948
Fold [5/5] Epoch [0/100] Initial Loss: 0.1387, Training Loss: 0.1387, Initial Validation Loss: 0.1276, Validation Loss: 0.1276,V Acc: 0.3981, Top 70th Acc: 0.4605, Bottom 30th Acc: 0.2500
Fold [5/5] Epoch [10/100] Initial Loss: 0.1387, Training Loss: 0.0300, Initial Validation Loss: 0.1276, Validation Loss: 0.0397,V Acc: 0.7963, Top 70th Acc: 0.9211, Bottom 30th Acc: 0.5000
Fold [5/5] Epoch [20/100] Initial Loss: 0.1387, Training Loss: 0.0180, Initial Validation Loss: 0.1276, Validation Loss: 0.0353,V Acc: 0.8056, Top 70th Acc: 0.9211, Bottom 30th Acc: 0.5312
Stopping early at Epoch (base 0): 27  Rolling back to Epoch (base 0): 22  Top Validation Acc: 0.9210526315789473
38 4 [array([0.3226744 , 0.04975672, 0.09033744, 0.06159599, 0.47563538],
      dtype=float32)]
Running train_nn.py with seed 39
CUDA:False
Training samples count:  550
Training on 30 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1388, Training Loss: 0.1388, Initial Validation Loss: 0.1361, Validation Loss: 0.1361,V Acc: 0.2973, Top 70th Acc: 0.3333, Bottom 30th Acc: 0.2121
Fold [1/5] Epoch [10/100] Initial Loss: 0.1388, Training Loss: 0.0355, Initial Validation Loss: 0.1361, Validation Loss: 0.0427,V Acc: 0.8108, Top 70th Acc: 0.8846, Bottom 30th Acc: 0.6364
Fold [1/5] Epoch [20/100] Initial Loss: 0.1388, Training Loss: 0.0182, Initial Validation Loss: 0.1361, Validation Loss: 0.0295,V Acc: 0.8468, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 29  Rolling back to Epoch (base 0): 24  Top Validation Acc: 0.9615384615384616
Fold [2/5] Epoch [0/100] Initial Loss: 0.1376, Training Loss: 0.1376, Initial Validation Loss: 0.1325, Validation Loss: 0.1325,V Acc: 0.2793, Top 70th Acc: 0.3718, Bottom 30th Acc: 0.0606
Fold [2/5] Epoch [10/100] Initial Loss: 0.1376, Training Loss: 0.0291, Initial Validation Loss: 0.1325, Validation Loss: 0.0346,V Acc: 0.8468, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.5758
Fold [2/5] Epoch [20/100] Initial Loss: 0.1376, Training Loss: 0.0180, Initial Validation Loss: 0.1325, Validation Loss: 0.0308,V Acc: 0.8198, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.4848
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.9615384615384616
39 1 [array([0.5215426 , 0.08404055, 0.03588594, 0.1138835 , 0.24464735],
      dtype=float32)]
Fold [3/5] Epoch [0/100] Initial Loss: 0.1383, Training Loss: 0.1383, Initial Validation Loss: 0.1316, Validation Loss: 0.1316,V Acc: 0.2909, Top 70th Acc: 0.3247, Bottom 30th Acc: 0.2121
Fold [3/5] Epoch [10/100] Initial Loss: 0.1383, Training Loss: 0.0344, Initial Validation Loss: 0.1316, Validation Loss: 0.0438,V Acc: 0.7636, Top 70th Acc: 0.8831, Bottom 30th Acc: 0.4848
Fold [3/5] Epoch [20/100] Initial Loss: 0.1383, Training Loss: 0.0175, Initial Validation Loss: 0.1316, Validation Loss: 0.0331,V Acc: 0.8000, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.5152
Stopping early at Epoch (base 0): 29  Rolling back to Epoch (base 0): 24  Top Validation Acc: 0.922077922077922
Fold [4/5] Epoch [0/100] Initial Loss: 0.1382, Training Loss: 0.1382, Initial Validation Loss: 0.1374, Validation Loss: 0.1374,V Acc: 0.4455, Top 70th Acc: 0.5195, Bottom 30th Acc: 0.2727
Fold [4/5] Epoch [10/100] Initial Loss: 0.1382, Training Loss: 0.0299, Initial Validation Loss: 0.1374, Validation Loss: 0.0297,V Acc: 0.8818, Top 70th Acc: 0.9870, Bottom 30th Acc: 0.6364
Fold [4/5] Epoch [20/100] Initial Loss: 0.1382, Training Loss: 0.0195, Initial Validation Loss: 0.1374, Validation Loss: 0.0236,V Acc: 0.8727, Top 70th Acc: 0.9870, Bottom 30th Acc: 0.6061
Fold [4/5] Epoch [30/100] Initial Loss: 0.1382, Training Loss: 0.0176, Initial Validation Loss: 0.1374, Validation Loss: 0.0215,V Acc: 0.8818, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 36  Rolling back to Epoch (base 0): 31  Top Validation Acc: 0.987012987012987
Fold [5/5] Epoch [0/100] Initial Loss: 0.1364, Training Loss: 0.1364, Initial Validation Loss: 0.1305, Validation Loss: 0.1305,V Acc: 0.4074, Top 70th Acc: 0.4211, Bottom 30th Acc: 0.3750
Fold [5/5] Epoch [10/100] Initial Loss: 0.1364, Training Loss: 0.0298, Initial Validation Loss: 0.1305, Validation Loss: 0.0396,V Acc: 0.8241, Top 70th Acc: 0.9079, Bottom 30th Acc: 0.6250
Fold [5/5] Epoch [20/100] Initial Loss: 0.1364, Training Loss: 0.0182, Initial Validation Loss: 0.1305, Validation Loss: 0.0317,V Acc: 0.8148, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.5000
Fold [5/5] Epoch [30/100] Initial Loss: 0.1364, Training Loss: 0.0163, Initial Validation Loss: 0.1305, Validation Loss: 0.0310,V Acc: 0.8148, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.5000
Stopping early at Epoch (base 0): 34  Rolling back to Epoch (base 0): 29  Top Validation Acc: 0.9473684210526315
Running train_nn.py with seed 40
CUDA:False
Training samples count:  550
Training on 30 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1372, Training Loss: 0.1372, Initial Validation Loss: 0.1370, Validation Loss: 0.1370,V Acc: 0.3423, Top 70th Acc: 0.4103, Bottom 30th Acc: 0.1818
Fold [1/5] Epoch [10/100] Initial Loss: 0.1372, Training Loss: 0.0323, Initial Validation Loss: 0.1370, Validation Loss: 0.0381,V Acc: 0.8468, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.6364
Fold [1/5] Epoch [20/100] Initial Loss: 0.1372, Training Loss: 0.0188, Initial Validation Loss: 0.1370, Validation Loss: 0.0273,V Acc: 0.8829, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.6667
Fold [1/5] Epoch [30/100] Initial Loss: 0.1372, Training Loss: 0.0160, Initial Validation Loss: 0.1370, Validation Loss: 0.0246,V Acc: 0.8829, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.6667
Fold [1/5] Epoch [40/100] Initial Loss: 0.1372, Training Loss: 0.0147, Initial Validation Loss: 0.1370, Validation Loss: 0.0253,V Acc: 0.8829, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 40  Rolling back to Epoch (base 0): 35  Top Validation Acc: 0.9615384615384616
Fold [2/5] Epoch [0/100] Initial Loss: 0.1366, Training Loss: 0.1366, Initial Validation Loss: 0.1309, Validation Loss: 0.1309,V Acc: 0.3784, Top 70th Acc: 0.4359, Bottom 30th Acc: 0.2424
Fold [2/5] Epoch [10/100] Initial Loss: 0.1366, Training Loss: 0.0281, Initial Validation Loss: 0.1309, Validation Loss: 0.0286,V Acc: 0.8378, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.6364
Fold [2/5] Epoch [20/100] Initial Loss: 0.1366, Training Loss: 0.0183, Initial Validation Loss: 0.1309, Validation Loss: 0.0246,V Acc: 0.8468, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 20  Rolling back to Epoch (base 0): 15  Top Validation Acc: 0.9230769230769231
40 1 [array([0.5634166 , 0.03739525, 0.05877131, 0.13451123, 0.20590559],
      dtype=float32)]
Fold [3/5] Epoch [0/100] Initial Loss: 0.1388, Training Loss: 0.1388, Initial Validation Loss: 0.1338, Validation Loss: 0.1338,V Acc: 0.3000, Top 70th Acc: 0.3506, Bottom 30th Acc: 0.1818
Fold [3/5] Epoch [10/100] Initial Loss: 0.1388, Training Loss: 0.0237, Initial Validation Loss: 0.1338, Validation Loss: 0.0317,V Acc: 0.8455, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.5455
Fold [3/5] Epoch [20/100] Initial Loss: 0.1388, Training Loss: 0.0156, Initial Validation Loss: 0.1338, Validation Loss: 0.0310,V Acc: 0.8455, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.961038961038961
Fold [4/5] Epoch [0/100] Initial Loss: 0.1379, Training Loss: 0.1379, Initial Validation Loss: 0.1335, Validation Loss: 0.1335,V Acc: 0.2909, Top 70th Acc: 0.3636, Bottom 30th Acc: 0.1212/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)

Fold [2/5] Epoch [10/100] Initial Loss: 0.1384, Training Loss: 0.0217, Initial Validation Loss: 0.1280, Validation Loss: 0.0297,V Acc: 0.8468, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 19  Rolling back to Epoch (base 0): 14  Top Validation Acc: 0.9487179487179487
Fold [3/5] Epoch [0/100] Initial Loss: 0.1395, Training Loss: 0.1395, Initial Validation Loss: 0.1288, Validation Loss: 0.1288,V Acc: 0.4273, Top 70th Acc: 0.5325, Bottom 30th Acc: 0.1818
Fold [3/5] Epoch [10/100] Initial Loss: 0.1395, Training Loss: 0.0255, Initial Validation Loss: 0.1288, Validation Loss: 0.0304,V Acc: 0.8455, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.5758
Fold [3/5] Epoch [20/100] Initial Loss: 0.1395, Training Loss: 0.0174, Initial Validation Loss: 0.1288, Validation Loss: 0.0269,V Acc: 0.8727, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.6667
Fold [3/5] Epoch [30/100] Initial Loss: 0.1395, Training Loss: 0.0150, Initial Validation Loss: 0.1288, Validation Loss: 0.0218,V Acc: 0.8727, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 31  Rolling back to Epoch (base 0): 26  Top Validation Acc: 0.961038961038961
Fold [4/5] Epoch [0/100] Initial Loss: 0.1330, Training Loss: 0.1330, Initial Validation Loss: 0.1238, Validation Loss: 0.1238,V Acc: 0.4182, Top 70th Acc: 0.5065, Bottom 30th Acc: 0.2121
Fold [4/5] Epoch [10/100] Initial Loss: 0.1330, Training Loss: 0.0235, Initial Validation Loss: 0.1238, Validation Loss: 0.0293,V Acc: 0.8636, Top 70th Acc: 1.0000, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 19  Rolling back to Epoch (base 0): 14  Top Validation Acc: 0.987012987012987
53 3 [array([0.8471192 , 0.01401667, 0.02597664, 0.08903048, 0.02385707],
      dtype=float32)]
Fold [5/5] Epoch [0/100] Initial Loss: 0.1409, Training Loss: 0.1409, Initial Validation Loss: 0.1353, Validation Loss: 0.1353,V Acc: 0.1481, Top 70th Acc: 0.1447, Bottom 30th Acc: 0.1562
Fold [5/5] Epoch [10/100] Initial Loss: 0.1409, Training Loss: 0.0241, Initial Validation Loss: 0.1353, Validation Loss: 0.0270,V Acc: 0.8704, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.6562
Fold [5/5] Epoch [20/100] Initial Loss: 0.1409, Training Loss: 0.0190, Initial Validation Loss: 0.1353, Validation Loss: 0.0211,V Acc: 0.8981, Top 70th Acc: 0.9737, Bottom 30th Acc: 0.7188
Stopping early at Epoch (base 0): 21  Rolling back to Epoch (base 0): 16  Top Validation Acc: 0.9868421052631579
Running train_nn.py with seed 54
CUDA:False
Training samples count:  550
Training on 21 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1329, Training Loss: 0.1329, Initial Validation Loss: 0.1276, Validation Loss: 0.1276,V Acc: 0.5315, Top 70th Acc: 0.6538, Bottom 30th Acc: 0.2424
Fold [1/5] Epoch [10/100] Initial Loss: 0.1329, Training Loss: 0.0227, Initial Validation Loss: 0.1276, Validation Loss: 0.0215,V Acc: 0.9279, Top 70th Acc: 1.0000, Bottom 30th Acc: 0.7576
Fold [1/5] Epoch [20/100] Initial Loss: 0.1329, Training Loss: 0.0191, Initial Validation Loss: 0.1276, Validation Loss: 0.0218,V Acc: 0.9009, Top 70th Acc: 1.0000, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 22  Rolling back to Epoch (base 0): 17  Top Validation Acc: 1.0
Fold [2/5] Epoch [0/100] Initial Loss: 0.1298, Training Loss: 0.1298, Initial Validation Loss: 0.1178, Validation Loss: 0.1178,V Acc: 0.5676, Top 70th Acc: 0.7051, Bottom 30th Acc: 0.2424
Fold [2/5] Epoch [10/100] Initial Loss: 0.1298, Training Loss: 0.0226, Initial Validation Loss: 0.1178, Validation Loss: 0.0203,V Acc: 0.8829, Top 70th Acc: 0.9872, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 15  Rolling back to Epoch (base 0): 10  Top Validation Acc: 0.9615384615384616
Fold [3/5] Epoch [0/100] Initial Loss: 0.1380, Training Loss: 0.1380, Initial Validation Loss: 0.1208, Validation Loss: 0.1208,V Acc: 0.4182, Top 70th Acc: 0.4675, Bottom 30th Acc: 0.3030
Fold [3/5] Epoch [10/100] Initial Loss: 0.1380, Training Loss: 0.0262, Initial Validation Loss: 0.1208, Validation Loss: 0.0331,V Acc: 0.8364, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 16  Rolling back to Epoch (base 0): 11  Top Validation Acc: 0.935064935064935
Fold [4/5] Epoch [0/100] Initial Loss: 0.1326, Training Loss: 0.1326, Initial Validation Loss: 0.1142, Validation Loss: 0.1142,V Acc: 0.6000, Top 70th Acc: 0.6364, Bottom 30th Acc: 0.5152
Fold [4/5] Epoch [10/100] Initial Loss: 0.1326, Training Loss: 0.0283, Initial Validation Loss: 0.1142, Validation Loss: 0.0380,V Acc: 0.8091, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.5455
Fold [4/5] Epoch [20/100] Initial Loss: 0.1326, Training Loss: 0.0190, Initial Validation Loss: 0.1142, Validation Loss: 0.0283,V Acc: 0.8727, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 29  Rolling back to Epoch (base 0): 24  Top Validation Acc: 0.974025974025974
54 3 [array([0.7465666 , 0.03129978, 0.03228231, 0.07497602, 0.11487532],
      dtype=float32)]
Fold [5/5] Epoch [0/100] Initial Loss: 0.1322, Training Loss: 0.1322, Initial Validation Loss: 0.1136, Validation Loss: 0.1136,V Acc: 0.4907, Top 70th Acc: 0.5921, Bottom 30th Acc: 0.2500
Fold [5/5] Epoch [10/100] Initial Loss: 0.1322, Training Loss: 0.0260, Initial Validation Loss: 0.1136, Validation Loss: 0.0420,V Acc: 0.8056, Top 70th Acc: 0.9079, Bottom 30th Acc: 0.5625
Stopping early at Epoch (base 0): 12  Rolling back to Epoch (base 0): 7  Top Validation Acc: 0.9078947368421053
Running train_nn.py with seed 55
CUDA:False
Training samples count:  550
Training on 21 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1344, Training Loss: 0.1344, Initial Validation Loss: 0.1241, Validation Loss: 0.1241,V Acc: 0.5676, Top 70th Acc: 0.6538, Bottom 30th Acc: 0.3636
Fold [1/5] Epoch [10/100] Initial Loss: 0.1344, Training Loss: 0.0276, Initial Validation Loss: 0.1241, Validation Loss: 0.0396,V Acc: 0.8108, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 19  Rolling back to Epoch (base 0): 14  Top Validation Acc: 0.9615384615384616
Fold [2/5] Epoch [0/100] Initial Loss: 0.1284, Training Loss: 0.1284, Initial Validation Loss: 0.1194, Validation Loss: 0.1194,V Acc: 0.4054, Top 70th Acc: 0.5128, Bottom 30th Acc: 0.1515
Fold [2/5] Epoch [10/100] Initial Loss: 0.1284, Training Loss: 0.0235, Initial Validation Loss: 0.1194, Validation Loss: 0.0392,V Acc: 0.8378, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 19  Rolling back to Epoch (base 0): 14  Top Validation Acc: 0.9487179487179487
Fold [3/5] Epoch [0/100] Initial Loss: 0.1344, Training Loss: 0.1344, Initial Validation Loss: 0.1146, Validation Loss: 0.1146,V Acc: 0.5545, Top 70th Acc: 0.6364, Bottom 30th Acc: 0.3636
Fold [3/5] Epoch [10/100] Initial Loss: 0.1344, Training Loss: 0.0245, Initial Validation Loss: 0.1146, Validation Loss: 0.0345,V Acc: 0.8545, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.6970
Fold [3/5] Epoch [20/100] Initial Loss: 0.1344, Training Loss: 0.0170, Initial Validation Loss: 0.1146, Validation Loss: 0.0333,V Acc: 0.8364, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.948051948051948
55 2 [array([0.7514479 , 0.04517263, 0.02090129, 0.0663567 , 0.11612138],
      dtype=float32)]
Fold [4/5] Epoch [0/100] Initial Loss: 0.1350, Training Loss: 0.1350, Initial Validation Loss: 0.1255, Validation Loss: 0.1255,V Acc: 0.4364, Top 70th Acc: 0.5844, Bottom 30th Acc: 0.0909
Fold [4/5] Epoch [10/100] Initial Loss: 0.1350, Training Loss: 0.0262, Initial Validation Loss: 0.1255, Validation Loss: 0.0228,V Acc: 0.8909, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 18  Rolling back to Epoch (base 0): 13  Top Validation Acc: 0.987012987012987
Fold [5/5] Epoch [0/100] Initial Loss: 0.1342, Training Loss: 0.1342, Initial Validation Loss: 0.1232, Validation Loss: 0.1232,V Acc: 0.4722, Top 70th Acc: 0.5526, Bottom 30th Acc: 0.2812
Fold [5/5] Epoch [10/100] Initial Loss: 0.1342, Training Loss: 0.0208, Initial Validation Loss: 0.1232, Validation Loss: 0.0336,V Acc: 0.8241, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.5312
Fold [5/5] Epoch [20/100] Initial Loss: 0.1342, Training Loss: 0.0169, Initial Validation Loss: 0.1232, Validation Loss: 0.0301,V Acc: 0.8426, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.5625 0.974025974025974
Fold [5/5] Epoch [0/100] Initial Loss: 0.1388, Training Loss: 0.1388, Initial Validation Loss: 0.1324, Validation Loss: 0.1324,V Acc: 0.4259, Top 70th Acc: 0.4868, Bottom 30th Acc: 0.2812
Fold [5/5] Epoch [10/100] Initial Loss: 0.1388, Training Loss: 0.0137, Initial Validation Loss: 0.1324, Validation Loss: 0.0403,V Acc: 0.8056, Top 70th Acc: 0.9211, Bottom 30th Acc: 0.5312
Fold [5/5] Epoch [20/100] Initial Loss: 0.1388, Training Loss: 0.0045, Initial Validation Loss: 0.1324, Validation Loss: 0.0332,V Acc: 0.8426, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.5938
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.9210526315789473
Running train_nn.py with seed 30
CUDA:False
Training samples count:  550
Training on 163 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1372, Training Loss: 0.1372, Initial Validation Loss: 0.1354, Validation Loss: 0.1354,V Acc: 0.2793, Top 70th Acc: 0.3205, Bottom 30th Acc: 0.1818
Fold [1/5] Epoch [10/100] Initial Loss: 0.1372, Training Loss: 0.0201, Initial Validation Loss: 0.1354, Validation Loss: 0.0405,V Acc: 0.7928, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.4848
Fold [1/5] Epoch [20/100] Initial Loss: 0.1372, Training Loss: 0.0048, Initial Validation Loss: 0.1354, Validation Loss: 0.0306,V Acc: 0.8198, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.4545
Fold [1/5] Epoch [30/100] Initial Loss: 0.1372, Training Loss: 0.0038, Initial Validation Loss: 0.1354, Validation Loss: 0.0287,V Acc: 0.8378, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.5152
Stopping early at Epoch (base 0): 31  Rolling back to Epoch (base 0): 26  Top Validation Acc: 0.9743589743589743
Fold [2/5] Epoch [0/100] Initial Loss: 0.1401, Training Loss: 0.1401, Initial Validation Loss: 0.1368, Validation Loss: 0.1368,V Acc: 0.2523, Top 70th Acc: 0.2821, Bottom 30th Acc: 0.1818
Fold [2/5] Epoch [10/100] Initial Loss: 0.1401, Training Loss: 0.0137, Initial Validation Loss: 0.1368, Validation Loss: 0.0347,V Acc: 0.8288, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.5152
Fold [2/5] Epoch [20/100] Initial Loss: 0.1401, Training Loss: 0.0049, Initial Validation Loss: 0.1368, Validation Loss: 0.0295,V Acc: 0.8559, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.9487179487179487
Fold [3/5] Epoch [0/100] Initial Loss: 0.1373, Training Loss: 0.1373, Initial Validation Loss: 0.1303, Validation Loss: 0.1303,V Acc: 0.3364, Top 70th Acc: 0.3636, Bottom 30th Acc: 0.2727
Fold [3/5] Epoch [10/100] Initial Loss: 0.1373, Training Loss: 0.0211, Initial Validation Loss: 0.1303, Validation Loss: 0.0428,V Acc: 0.7909, Top 70th Acc: 0.8961, Bottom 30th Acc: 0.5455
Fold [3/5] Epoch [20/100] Initial Loss: 0.1373, Training Loss: 0.0066, Initial Validation Loss: 0.1303, Validation Loss: 0.0385,V Acc: 0.8182, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.5758
Fold [3/5] Epoch [30/100] Initial Loss: 0.1373, Training Loss: 0.0048, Initial Validation Loss: 0.1303, Validation Loss: 0.0378,V Acc: 0.7818, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.4848
Fold [3/5] Epoch [40/100] Initial Loss: 0.1373, Training Loss: 0.0043, Initial Validation Loss: 0.1303, Validation Loss: 0.0367,V Acc: 0.8000, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.5455
Fold [3/5] Epoch [50/100] Initial Loss: 0.1373, Training Loss: 0.0040, Initial Validation Loss: 0.1303, Validation Loss: 0.0346,V Acc: 0.8000, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.5152
Fold [3/5] Epoch [60/100] Initial Loss: 0.1373, Training Loss: 0.0038, Initial Validation Loss: 0.1303, Validation Loss: 0.0332,V Acc: 0.8091, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.5455
Fold [3/5] Epoch [70/100] Initial Loss: 0.1373, Training Loss: 0.0036, Initial Validation Loss: 0.1303, Validation Loss: 0.0324,V Acc: 0.8182, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.6061
Fold [3/5] Epoch [80/100] Initial Loss: 0.1373, Training Loss: 0.0035, Initial Validation Loss: 0.1303, Validation Loss: 0.0311,V Acc: 0.8273, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.6061
Fold [3/5] Epoch [90/100] Initial Loss: 0.1373, Training Loss: 0.0034, Initial Validation Loss: 0.1303, Validation Loss: 0.0297,V Acc: 0.8273, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 95  Rolling back to Epoch (base 0): 90  Top Validation Acc: 0.922077922077922
Fold [4/5] Epoch [0/100] Initial Loss: 0.1401, Training Loss: 0.1401, Initial Validation Loss: 0.1341, Validation Loss: 0.1341,V Acc: 0.3545, Top 70th Acc: 0.3636, Bottom 30th Acc: 0.3333
Fold [4/5] Epoch [10/100] Initial Loss: 0.1401, Training Loss: 0.0143, Initial Validation Loss: 0.1341, Validation Loss: 0.0315,V Acc: 0.8455, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.6667
Fold [4/5] Epoch [20/100] Initial Loss: 0.1401, Training Loss: 0.0044, Initial Validation Loss: 0.1341, Validation Loss: 0.0265,V Acc: 0.8909, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.7576
Fold [4/5] Epoch [30/100] Initial Loss: 0.1401, Training Loss: 0.0037, Initial Validation Loss: 0.1341, Validation Loss: 0.0263,V Acc: 0.8818, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.7273
Stopping early at Epoch (base 0): 33  Rolling back to Epoch (base 0): 28  Top Validation Acc: 0.948051948051948
Fold [5/5] Epoch [0/100] Initial Loss: 0.1380, Training Loss: 0.1380, Initial Validation Loss: 0.1341, Validation Loss: 0.1341,V Acc: 0.2500, Top 70th Acc: 0.3289, Bottom 30th Acc: 0.0625
Fold [5/5] Epoch [10/100] Initial Loss: 0.1380, Training Loss: 0.0315, Initial Validation Loss: 0.1341, Validation Loss: 0.0446,V Acc: 0.8056, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.5000
Fold [5/5] Epoch [20/100] Initial Loss: 0.1380, Training Loss: 0.0053, Initial Validation Loss: 0.1341, Validation Loss: 0.0231,V Acc: 0.9167, Top 70th Acc: 0.9737, Bottom 30th Acc: 0.7812
Fold [5/5] Epoch [30/100] Initial Loss: 0.1380, Training Loss: 0.0039, Initial Validation Loss: 0.1341, Validation Loss: 0.0219,V Acc: 0.9074, Top 70th Acc: 0.9737, Bottom 30th Acc: 0.7500
Stopping early at Epoch (base 0): 37  Rolling back to Epoch (base 0): 32  Top Validation Acc: 0.9736842105263158
30 4 [array([0.27087545, 0.03691733, 0.13553396, 0.19352746, 0.3631457 ],
      dtype=float32)]
Running train_nn.py with seed 31
CUDA:False
Training samples count:  550
Training on 163 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1446, Training Loss: 0.1446, Initial Validation Loss: 0.1359, Validation Loss: 0.1359,V Acc: 0.3063, Top 70th Acc: 0.2949, Bottom 30th Acc: 0.3333
Fold [1/5] Epoch [10/100] Initial Loss: 0.1446, Training Loss: 0.0219, Initial Validation Loss: 0.1359, Validation Loss: 0.0425,V Acc: 0.8108, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.5758
Fold [1/5] Epoch [20/100] Initial Loss: 0.1446, Training Loss: 0.0065, Initial Validation Loss: 0.1359, Validation Loss: 0.0346,V Acc: 0.8288, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.6061
Fold [1/5] Epoch [30/100] Initial Loss: 0.1446, Training Loss: 0.0045, Initial Validation Loss: 0.1359, Validation Loss: 0.0326,V Acc: 0.8198, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 31  Rolling back to Epoch (base 0): 26  Top Validation Acc: 0.9487179487179487
31 0 [array([0.0564034 , 0.02614599, 0.04998778, 0.17150128, 0.69596153],
      dtype=float32)]
Fold [2/5] Epoch [0/100] Initial Loss: 0.1398, Training Loss: 0.1398, Initial Validation Loss: 0.1332, Validation Loss: 0.1332,V Acc: 0.3604, Top 70th Acc: 0.3718, Bottom 30th Acc: 0.3333
Fold [2/5] Epoch [10/100] Initial Loss: 0.1398, Training Loss: 0.0267, Initial Validation Loss: 0.1332, Validation Loss: 0.0349,V Acc: 0.8288, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.5152
Fold [2/5] Epoch [20/100] Initial Loss: 0.1398, Training Loss: 0.0064, Initial Validation Loss: 0.1332, Validation Loss: 0.0292,V Acc: 0.8829, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 27  Rolling back to Epoch (base 0): 22  Top Validation Acc: 0.9743589743589743
Fold [3/5] Epoch [0/100] Initial Loss: 0.1379, Training Loss: 0.1379, Initial Validation Loss: 0.1358, Validation Loss: 0.1358,V Acc: 0.3273, Top 70th Acc: 0.4156, Bottom 30th Acc: 0.1212
Fold [3/5] Epoch [10/100] Initial Loss: 0.1379, Training Loss: 0.0158, Initial Validation Loss: 0.1358, Validation Loss: 0.0313,V Acc: 0.8273, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.5152
Fold [1/5] Epoch [20/100] Initial Loss: 0.1381, Training Loss: 0.0797, Initial Validation Loss: 0.1277, Validation Loss: 0.0774,V Acc: 0.6036, Top 70th Acc: 0.7051, Bottom 30th Acc: 0.3636
Fold [1/5] Epoch [30/100] Initial Loss: 0.1381, Training Loss: 0.0786, Initial Validation Loss: 0.1277, Validation Loss: 0.0769,V Acc: 0.6126, Top 70th Acc: 0.7179, Bottom 30th Acc: 0.3636
Fold [1/5] Epoch [40/100] Initial Loss: 0.1381, Training Loss: 0.0778, Initial Validation Loss: 0.1277, Validation Loss: 0.0763,V Acc: 0.6306, Top 70th Acc: 0.7564, Bottom 30th Acc: 0.3333
Fold [1/5] Epoch [50/100] Initial Loss: 0.1381, Training Loss: 0.0772, Initial Validation Loss: 0.1277, Validation Loss: 0.0758,V Acc: 0.6306, Top 70th Acc: 0.7051, Bottom 30th Acc: 0.4545
Stopping early at Epoch (base 0): 52  Rolling back to Epoch (base 0): 47  Top Validation Acc: 0.7307692307692307
Fold [2/5] Epoch [0/100] Initial Loss: 0.1378, Training Loss: 0.1378, Initial Validation Loss: 0.1341, Validation Loss: 0.1341,V Acc: 0.3964, Top 70th Acc: 0.3333, Bottom 30th Acc: 0.5455
Fold [2/5] Epoch [10/100] Initial Loss: 0.1378, Training Loss: 0.0762, Initial Validation Loss: 0.1341, Validation Loss: 0.0997,V Acc: 0.5315, Top 70th Acc: 0.6538, Bottom 30th Acc: 0.2424
Fold [2/5] Epoch [20/100] Initial Loss: 0.1378, Training Loss: 0.0735, Initial Validation Loss: 0.1341, Validation Loss: 0.0996,V Acc: 0.5495, Top 70th Acc: 0.6538, Bottom 30th Acc: 0.3030
Stopping early at Epoch (base 0): 22  Rolling back to Epoch (base 0): 17  Top Validation Acc: 0.6538461538461539
Fold [3/5] Epoch [0/100] Initial Loss: 0.1347, Training Loss: 0.1347, Initial Validation Loss: 0.1322, Validation Loss: 0.1322,V Acc: 0.4000, Top 70th Acc: 0.4675, Bottom 30th Acc: 0.2424
Fold [3/5] Epoch [10/100] Initial Loss: 0.1347, Training Loss: 0.0814, Initial Validation Loss: 0.1322, Validation Loss: 0.0794,V Acc: 0.6364, Top 70th Acc: 0.7013, Bottom 30th Acc: 0.4848
Fold [3/5] Epoch [20/100] Initial Loss: 0.1347, Training Loss: 0.0793, Initial Validation Loss: 0.1322, Validation Loss: 0.0782,V Acc: 0.6455, Top 70th Acc: 0.7143, Bottom 30th Acc: 0.4848
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.7012987012987013
Fold [4/5] Epoch [0/100] Initial Loss: 0.1396, Training Loss: 0.1396, Initial Validation Loss: 0.1310, Validation Loss: 0.1310,V Acc: 0.3545, Top 70th Acc: 0.4026, Bottom 30th Acc: 0.2424
Fold [4/5] Epoch [10/100] Initial Loss: 0.1396, Training Loss: 0.0845, Initial Validation Loss: 0.1310, Validation Loss: 0.0728,V Acc: 0.6727, Top 70th Acc: 0.8182, Bottom 30th Acc: 0.3333
Fold [4/5] Epoch [20/100] Initial Loss: 0.1396, Training Loss: 0.0822, Initial Validation Loss: 0.1310, Validation Loss: 0.0700,V Acc: 0.6364, Top 70th Acc: 0.8052, Bottom 30th Acc: 0.2424
Fold [4/5] Epoch [30/100] Initial Loss: 0.1396, Training Loss: 0.0816, Initial Validation Loss: 0.1310, Validation Loss: 0.0691,V Acc: 0.6727, Top 70th Acc: 0.8182, Bottom 30th Acc: 0.3333
Fold [4/5] Epoch [40/100] Initial Loss: 0.1396, Training Loss: 0.0812, Initial Validation Loss: 0.1310, Validation Loss: 0.0688,V Acc: 0.6636, Top 70th Acc: 0.8052, Bottom 30th Acc: 0.3333
Stopping early at Epoch (base 0): 43  Rolling back to Epoch (base 0): 38  Top Validation Acc: 0.8181818181818182
Fold [5/5] Epoch [0/100] Initial Loss: 0.1388, Training Loss: 0.1388, Initial Validation Loss: 0.1295, Validation Loss: 0.1295,V Acc: 0.3056, Top 70th Acc: 0.3026, Bottom 30th Acc: 0.3125
Fold [5/5] Epoch [10/100] Initial Loss: 0.1388, Training Loss: 0.0825, Initial Validation Loss: 0.1295, Validation Loss: 0.0760,V Acc: 0.6759, Top 70th Acc: 0.7763, Bottom 30th Acc: 0.4375
Fold [5/5] Epoch [20/100] Initial Loss: 0.1388, Training Loss: 0.0804, Initial Validation Loss: 0.1295, Validation Loss: 0.0728,V Acc: 0.6667, Top 70th Acc: 0.7763, Bottom 30th Acc: 0.4062
Fold [5/5] Epoch [30/100] Initial Loss: 0.1388, Training Loss: 0.0797, Initial Validation Loss: 0.1295, Validation Loss: 0.0719,V Acc: 0.6574, Top 70th Acc: 0.7763, Bottom 30th Acc: 0.3750
Stopping early at Epoch (base 0): 30  Rolling back to Epoch (base 0): 25  Top Validation Acc: 0.7763157894736842
36 4 [array([0.16086917, 0.29215115, 0.1597797 , 0.23800802, 0.14919199],
      dtype=float32)]
Running train_nn.py with seed 37
CUDA:False
Training samples count:  550
Training on 2 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1303, Training Loss: 0.1303, Initial Validation Loss: 0.1221, Validation Loss: 0.1221,V Acc: 0.4775, Top 70th Acc: 0.5256, Bottom 30th Acc: 0.3636
Fold [1/5] Epoch [10/100] Initial Loss: 0.1303, Training Loss: 0.0793, Initial Validation Loss: 0.1221, Validation Loss: 0.0828,V Acc: 0.6216, Top 70th Acc: 0.7308, Bottom 30th Acc: 0.3636
Stopping early at Epoch (base 0): 15  Rolling back to Epoch (base 0): 10  Top Validation Acc: 0.7435897435897436
Fold [2/5] Epoch [0/100] Initial Loss: 0.1322, Training Loss: 0.1322, Initial Validation Loss: 0.1300, Validation Loss: 0.1300,V Acc: 0.3874, Top 70th Acc: 0.5128, Bottom 30th Acc: 0.0909
Fold [2/5] Epoch [10/100] Initial Loss: 0.1322, Training Loss: 0.0779, Initial Validation Loss: 0.1300, Validation Loss: 0.0926,V Acc: 0.6036, Top 70th Acc: 0.6795, Bottom 30th Acc: 0.4242
Fold [2/5] Epoch [20/100] Initial Loss: 0.1322, Training Loss: 0.0753, Initial Validation Loss: 0.1300, Validation Loss: 0.0923,V Acc: 0.6126, Top 70th Acc: 0.6667, Bottom 30th Acc: 0.4848
Stopping early at Epoch (base 0): 21  Rolling back to Epoch (base 0): 16  Top Validation Acc: 0.6923076923076923
Fold [3/5] Epoch [0/100] Initial Loss: 0.1384, Training Loss: 0.1384, Initial Validation Loss: 0.1296, Validation Loss: 0.1296,V Acc: 0.2818, Top 70th Acc: 0.3766, Bottom 30th Acc: 0.0606
Fold [3/5] Epoch [10/100] Initial Loss: 0.1384, Training Loss: 0.0819, Initial Validation Loss: 0.1296, Validation Loss: 0.0784,V Acc: 0.6182, Top 70th Acc: 0.7922, Bottom 30th Acc: 0.2121
Fold [3/5] Epoch [20/100] Initial Loss: 0.1384, Training Loss: 0.0795, Initial Validation Loss: 0.1296, Validation Loss: 0.0765,V Acc: 0.6364, Top 70th Acc: 0.7792, Bottom 30th Acc: 0.3030
Fold [3/5] Epoch [30/100] Initial Loss: 0.1384, Training Loss: 0.0788, Initial Validation Loss: 0.1296, Validation Loss: 0.0759,V Acc: 0.6000, Top 70th Acc: 0.7662, Bottom 30th Acc: 0.2121
Stopping early at Epoch (base 0): 35  Rolling back to Epoch (base 0): 30  Top Validation Acc: 0.7922077922077922
Fold [4/5] Epoch [0/100] Initial Loss: 0.1371, Training Loss: 0.1371, Initial Validation Loss: 0.1289, Validation Loss: 0.1289,V Acc: 0.4909, Top 70th Acc: 0.5714, Bottom 30th Acc: 0.3030
Fold [4/5] Epoch [10/100] Initial Loss: 0.1371, Training Loss: 0.0833, Initial Validation Loss: 0.1289, Validation Loss: 0.0758,V Acc: 0.6364, Top 70th Acc: 0.7532, Bottom 30th Acc: 0.3636
Fold [4/5] Epoch [20/100] Initial Loss: 0.1371, Training Loss: 0.0807, Initial Validation Loss: 0.1289, Validation Loss: 0.0723,V Acc: 0.6636, Top 70th Acc: 0.7532, Bottom 30th Acc: 0.4545
Fold [4/5] Epoch [30/100] Initial Loss: 0.1371, Training Loss: 0.0800, Initial Validation Loss: 0.1289, Validation Loss: 0.0720,V Acc: 0.6545, Top 70th Acc: 0.7792, Bottom 30th Acc: 0.3636
Stopping early at Epoch (base 0): 33  Rolling back to Epoch (base 0): 28  Top Validation Acc: 0.7792207792207793
Fold [5/5] Epoch [0/100] Initial Loss: 0.1366, Training Loss: 0.1366, Initial Validation Loss: 0.1208, Validation Loss: 0.1208,V Acc: 0.3426, Top 70th Acc: 0.3553, Bottom 30th Acc: 0.3125
Fold [5/5] Epoch [10/100] Initial Loss: 0.1366, Training Loss: 0.0838, Initial Validation Loss: 0.1208, Validation Loss: 0.0742,V Acc: 0.6389, Top 70th Acc: 0.7368, Bottom 30th Acc: 0.4062
Fold [5/5] Epoch [20/100] Initial Loss: 0.1366, Training Loss: 0.0810, Initial Validation Loss: 0.1208, Validation Loss: 0.0715,V Acc: 0.6481, Top 70th Acc: 0.7368, Bottom 30th Acc: 0.4375
Fold [5/5] Epoch [30/100] Initial Loss: 0.1366, Training Loss: 0.0798, Initial Validation Loss: 0.1208, Validation Loss: 0.0716,V Acc: 0.6389, Top 70th Acc: 0.7632, Bottom 30th Acc: 0.3438
Fold [5/5] Epoch [40/100] Initial Loss: 0.1366, Training Loss: 0.0793, Initial Validation Loss: 0.1208, Validation Loss: 0.0705,V Acc: 0.6389, Top 70th Acc: 0.7500, Bottom 30th Acc: 0.3750 0.9210526315789473
38 4 [array([0.29939777, 0.14771074, 0.25075474, 0.1888229 , 0.11331388],
      dtype=float32)]
Running train_nn.py with seed 39
CUDA:False
Training samples count:  550
Training on 20 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1362, Training Loss: 0.1362, Initial Validation Loss: 0.1311, Validation Loss: 0.1311,V Acc: 0.3784, Top 70th Acc: 0.4103, Bottom 30th Acc: 0.3030
Fold [1/5] Epoch [10/100] Initial Loss: 0.1362, Training Loss: 0.0369, Initial Validation Loss: 0.1311, Validation Loss: 0.0433,V Acc: 0.7928, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.4848
Fold [1/5] Epoch [20/100] Initial Loss: 0.1362, Training Loss: 0.0219, Initial Validation Loss: 0.1311, Validation Loss: 0.0325,V Acc: 0.8829, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.7879
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.9230769230769231
Fold [2/5] Epoch [0/100] Initial Loss: 0.1375, Training Loss: 0.1375, Initial Validation Loss: 0.1325, Validation Loss: 0.1325,V Acc: 0.3604, Top 70th Acc: 0.3718, Bottom 30th Acc: 0.3333
Fold [2/5] Epoch [10/100] Initial Loss: 0.1375, Training Loss: 0.0453, Initial Validation Loss: 0.1325, Validation Loss: 0.0466,V Acc: 0.7748, Top 70th Acc: 0.8846, Bottom 30th Acc: 0.5152
Fold [2/5] Epoch [20/100] Initial Loss: 0.1375, Training Loss: 0.0244, Initial Validation Loss: 0.1325, Validation Loss: 0.0368,V Acc: 0.8108, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.5758
Fold [2/5] Epoch [30/100] Initial Loss: 0.1375, Training Loss: 0.0217, Initial Validation Loss: 0.1325, Validation Loss: 0.0348,V Acc: 0.8288, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 38  Rolling back to Epoch (base 0): 33  Top Validation Acc: 0.9102564102564102
39 1 [array([0.45957598, 0.05231158, 0.04635715, 0.27360594, 0.16814937],
      dtype=float32)]
Fold [3/5] Epoch [0/100] Initial Loss: 0.1431, Training Loss: 0.1431, Initial Validation Loss: 0.1336, Validation Loss: 0.1336,V Acc: 0.4000, Top 70th Acc: 0.4416, Bottom 30th Acc: 0.3030
Fold [3/5] Epoch [10/100] Initial Loss: 0.1431, Training Loss: 0.0437, Initial Validation Loss: 0.1336, Validation Loss: 0.0505,V Acc: 0.7727, Top 70th Acc: 0.8571, Bottom 30th Acc: 0.5758
Fold [3/5] Epoch [20/100] Initial Loss: 0.1431, Training Loss: 0.0248, Initial Validation Loss: 0.1336, Validation Loss: 0.0329,V Acc: 0.8545, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.6667
Fold [3/5] Epoch [30/100] Initial Loss: 0.1431, Training Loss: 0.0219, Initial Validation Loss: 0.1336, Validation Loss: 0.0309,V Acc: 0.8545, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.6667
Fold [3/5] Epoch [40/100] Initial Loss: 0.1431, Training Loss: 0.0208, Initial Validation Loss: 0.1336, Validation Loss: 0.0311,V Acc: 0.8545, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 43  Rolling back to Epoch (base 0): 38  Top Validation Acc: 0.961038961038961
Fold [4/5] Epoch [0/100] Initial Loss: 0.1399, Training Loss: 0.1399, Initial Validation Loss: 0.1395, Validation Loss: 0.1395,V Acc: 0.3000, Top 70th Acc: 0.2987, Bottom 30th Acc: 0.3030
Fold [4/5] Epoch [10/100] Initial Loss: 0.1399, Training Loss: 0.0335, Initial Validation Loss: 0.1395, Validation Loss: 0.0317,V Acc: 0.8909, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.7273
Fold [4/5] Epoch [20/100] Initial Loss: 0.1399, Training Loss: 0.0250, Initial Validation Loss: 0.1395, Validation Loss: 0.0261,V Acc: 0.8909, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.7273
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.961038961038961
Fold [5/5] Epoch [0/100] Initial Loss: 0.1393, Training Loss: 0.1393, Initial Validation Loss: 0.1335, Validation Loss: 0.1335,V Acc: 0.2500, Top 70th Acc: 0.3158, Bottom 30th Acc: 0.0938
Fold [5/5] Epoch [10/100] Initial Loss: 0.1393, Training Loss: 0.0322, Initial Validation Loss: 0.1335, Validation Loss: 0.0367,V Acc: 0.8148, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.5000
Fold [5/5] Epoch [20/100] Initial Loss: 0.1393, Training Loss: 0.0221, Initial Validation Loss: 0.1335, Validation Loss: 0.0313,V Acc: 0.8241, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.5000
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.9473684210526315
Running train_nn.py with seed 40
CUDA:False
Training samples count:  550
Training on 20 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1356, Training Loss: 0.1356, Initial Validation Loss: 0.1355, Validation Loss: 0.1355,V Acc: 0.2613, Top 70th Acc: 0.3590, Bottom 30th Acc: 0.0303
Fold [1/5] Epoch [10/100] Initial Loss: 0.1356, Training Loss: 0.0372, Initial Validation Loss: 0.1355, Validation Loss: 0.0436,V Acc: 0.7928, Top 70th Acc: 0.8718, Bottom 30th Acc: 0.6061
Fold [1/5] Epoch [20/100] Initial Loss: 0.1356, Training Loss: 0.0238, Initial Validation Loss: 0.1355, Validation Loss: 0.0348,V Acc: 0.8018, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.4848
Fold [1/5] Epoch [30/100] Initial Loss: 0.1356, Training Loss: 0.0219, Initial Validation Loss: 0.1355, Validation Loss: 0.0326,V Acc: 0.8198, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.5152
Fold [1/5] Epoch [40/100] Initial Loss: 0.1356, Training Loss: 0.0211, Initial Validation Loss: 0.1355, Validation Loss: 0.0324,V Acc: 0.8559, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 48  Rolling back to Epoch (base 0): 43  Top Validation Acc: 0.9487179487179487
Fold [2/5] Epoch [0/100] Initial Loss: 0.1370, Training Loss: 0.1370, Initial Validation Loss: 0.1314, Validation Loss: 0.1314,V Acc: 0.2523, Top 70th Acc: 0.3333, Bottom 30th Acc: 0.0606
Fold [2/5] Epoch [10/100] Initial Loss: 0.1370, Training Loss: 0.0332, Initial Validation Loss: 0.1314, Validation Loss: 0.0362,V Acc: 0.8198, Top 70th Acc: 0.8846, Bottom 30th Acc: 0.6667
Fold [2/5] Epoch [20/100] Initial Loss: 0.1370, Training Loss: 0.0240, Initial Validation Loss: 0.1314, Validation Loss: 0.0318,V Acc: 0.8198, Top 70th Acc: 0.8846, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.9102564102564102
40 1 [array([0.500844  , 0.05875726, 0.04679193, 0.23580404, 0.15780273],
      dtype=float32)]
Fold [3/5] Epoch [0/100] Initial Loss: 0.1365, Training Loss: 0.1365, Initial Validation Loss: 0.1302, Validation Loss: 0.1302,V Acc: 0.4091, Top 70th Acc: 0.4675, Bottom 30th Acc: 0.2727
Fold [3/5] Epoch [10/100] Initial Loss: 0.1365, Training Loss: 0.0345, Initial Validation Loss: 0.1302, Validation Loss: 0.0420,V Acc: 0.7909, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.4848
Fold [3/5] Epoch [20/100] Initial Loss: 0.1365, Training Loss: 0.0231, Initial Validation Loss: 0.1302, Validation Loss: 0.0344,V Acc: 0.8545, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.922077922077922
Fold [4/5] Epoch [0/100] Initial Loss: 0.1400, Training Loss: 0.1400, Initial Validation Loss: 0.1338, Validation Loss: 0.1338,V Acc: 0.2909, Top 70th Acc: 0.3506, Bottom 30th Acc: 0.1515
Fold [4/5] Epoch [10/100] Initial Loss: 0.1400, Training Loss: 0.0356, Initial Validation Loss: 0.1338, Validation Loss: 0.0439,V Acc: 0.8182, Top 70th Acc: 0.8831, Bottom 30th Acc: 0.6667
Fold [4/5] Epoch [20/100] Initial Loss: 0.1400, Training Loss: 0.0232, Initial Validation Loss: 0.1338, Validation Loss: 0.0350,V Acc: 0.8364, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 27  Rolling back to Epoch (base 0): 22  Top Validation Acc: 0.935064935064935
Fold [5/5] Epoch [0/100] Initial Loss: 0.1382, Training Loss: 0.1382, Initial Validation Loss: 0.1294, Validation Loss: 0.1294,V Acc: 0.3611, Top 70th Acc: 0.4079, Bottom 30th Acc: 0.2500
Fold [5/5] Epoch [10/100] Initial Loss: 0.1382, Training Loss: 0.0316, Initial Validation Loss: 0.1294, Validation Loss: 0.0378,V Acc: 0.8241, Top 70th Acc: 0.9079, Bottom 30th Acc: 0.6250
Fold [5/5] Epoch [20/100] Initial Loss: 0.1382, Training Loss: 0.0230, Initial Validation Loss: 0.1294, Validation Loss: 0.0339,V Acc: 0.8241, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.5625
Fold [5/5] Epoch [30/100] Initial Loss: 0.1382, Training Loss: 0.0209, Initial Validation Loss: 0.1294, Validation Loss: 0.0335,V Acc: 0.8241, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.5625
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.9342105263157895
Running train_nn.py with seed 56
CUDA:False
Training samples count:  550
Training on 21 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1275, Training Loss: 0.1275, Initial Validation Loss: 0.1180, Validation Loss: 0.1180,V Acc: 0.5315, Top 70th Acc: 0.5641, Bottom 30th Acc: 0.4545
Fold [1/5] Epoch [10/100] Initial Loss: 0.1275, Training Loss: 0.0224, Initial Validation Loss: 0.1180, Validation Loss: 0.0427,V Acc: 0.7928, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.4848
Fold [1/5] Epoch [20/100] Initial Loss: 0.1275, Training Loss: 0.0174, Initial Validation Loss: 0.1180, Validation Loss: 0.0337,V Acc: 0.8559, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.9615384615384616
Fold [2/5] Epoch [0/100] Initial Loss: 0.1332, Training Loss: 0.1332, Initial Validation Loss: 0.1230, Validation Loss: 0.1230,V Acc: 0.4775, Top 70th Acc: 0.6282, Bottom 30th Acc: 0.1212
Fold [2/5] Epoch [10/100] Initial Loss: 0.1332, Training Loss: 0.0245, Initial Validation Loss: 0.1230, Validation Loss: 0.0198,V Acc: 0.9099, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.7879
Stopping early at Epoch (base 0): 19  Rolling back to Epoch (base 0): 14  Top Validation Acc: 0.9743589743589743
Fold [3/5] Epoch [0/100] Initial Loss: 0.1357, Training Loss: 0.1357, Initial Validation Loss: 0.1273, Validation Loss: 0.1273,V Acc: 0.5909, Top 70th Acc: 0.7013, Bottom 30th Acc: 0.3333
Fold [3/5] Epoch [10/100] Initial Loss: 0.1357, Training Loss: 0.0288, Initial Validation Loss: 0.1273, Validation Loss: 0.0379,V Acc: 0.8182, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.6061
Fold [3/5] Epoch [20/100] Initial Loss: 0.1357, Training Loss: 0.0182, Initial Validation Loss: 0.1273, Validation Loss: 0.0235,V Acc: 0.8818, Top 70th Acc: 0.9870, Bottom 30th Acc: 0.6364
Fold [3/5] Epoch [30/100] Initial Loss: 0.1357, Training Loss: 0.0160, Initial Validation Loss: 0.1273, Validation Loss: 0.0218,V Acc: 0.9091, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.7576
Stopping early at Epoch (base 0): 32  Rolling back to Epoch (base 0): 27  Top Validation Acc: 0.974025974025974
Fold [4/5] Epoch [0/100] Initial Loss: 0.1312, Training Loss: 0.1312, Initial Validation Loss: 0.1207, Validation Loss: 0.1207,V Acc: 0.4182, Top 70th Acc: 0.5325, Bottom 30th Acc: 0.1515
Fold [4/5] Epoch [10/100] Initial Loss: 0.1312, Training Loss: 0.0230, Initial Validation Loss: 0.1207, Validation Loss: 0.0359,V Acc: 0.8636, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.7273
Stopping early at Epoch (base 0): 17  Rolling back to Epoch (base 0): 12  Top Validation Acc: 0.935064935064935
56 3 [array([0.69996065, 0.02253574, 0.02391438, 0.14340405, 0.11018516],
      dtype=float32)]
Fold [5/5] Epoch [0/100] Initial Loss: 0.1404, Training Loss: 0.1404, Initial Validation Loss: 0.1264, Validation Loss: 0.1264,V Acc: 0.3704, Top 70th Acc: 0.5132, Bottom 30th Acc: 0.0312
Fold [5/5] Epoch [10/100] Initial Loss: 0.1404, Training Loss: 0.0234, Initial Validation Loss: 0.1264, Validation Loss: 0.0289,V Acc: 0.8333, Top 70th Acc: 0.9737, Bottom 30th Acc: 0.5000
Fold [5/5] Epoch [20/100] Initial Loss: 0.1404, Training Loss: 0.0174, Initial Validation Loss: 0.1264, Validation Loss: 0.0309,V Acc: 0.8241, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.5000
Stopping early at Epoch (base 0): 20  Rolling back to Epoch (base 0): 15  Top Validation Acc: 0.9605263157894737
Running train_nn.py with seed 57
CUDA:False
Training samples count:  550
Training on 21 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1372, Training Loss: 0.1372, Initial Validation Loss: 0.1253, Validation Loss: 0.1253,V Acc: 0.3784, Top 70th Acc: 0.4872, Bottom 30th Acc: 0.1212
Fold [1/5] Epoch [10/100] Initial Loss: 0.1372, Training Loss: 0.0275, Initial Validation Loss: 0.1253, Validation Loss: 0.0299,V Acc: 0.8468, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.5758
Fold [1/5] Epoch [20/100] Initial Loss: 0.1372, Training Loss: 0.0205, Initial Validation Loss: 0.1253, Validation Loss: 0.0272,V Acc: 0.8829, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.9743589743589743
57 0 [array([0.6179779 , 0.02902099, 0.07176127, 0.09175239, 0.18948741],
      dtype=float32)]
Fold [2/5] Epoch [0/100] Initial Loss: 0.1340, Training Loss: 0.1340, Initial Validation Loss: 0.1279, Validation Loss: 0.1279,V Acc: 0.4144, Top 70th Acc: 0.5000, Bottom 30th Acc: 0.2121
Fold [2/5] Epoch [10/100] Initial Loss: 0.1340, Training Loss: 0.0229, Initial Validation Loss: 0.1279, Validation Loss: 0.0259,V Acc: 0.8919, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.6970
Fold [2/5] Epoch [20/100] Initial Loss: 0.1340, Training Loss: 0.0181, Initial Validation Loss: 0.1279, Validation Loss: 0.0252,V Acc: 0.8739, Top 70th Acc: 0.9872, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 21  Rolling back to Epoch (base 0): 16  Top Validation Acc: 0.9743589743589743
Fold [3/5] Epoch [0/100] Initial Loss: 0.1389, Training Loss: 0.1389, Initial Validation Loss: 0.1343, Validation Loss: 0.1343,V Acc: 0.4364, Top 70th Acc: 0.5065, Bottom 30th Acc: 0.2727
Fold [3/5] Epoch [10/100] Initial Loss: 0.1389, Training Loss: 0.0248, Initial Validation Loss: 0.1343, Validation Loss: 0.0395,V Acc: 0.7909, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.4848
Stopping early at Epoch (base 0): 17  Rolling back to Epoch (base 0): 12  Top Validation Acc: 0.935064935064935
Fold [4/5] Epoch [0/100] Initial Loss: 0.1300, Training Loss: 0.1300, Initial Validation Loss: 0.1203, Validation Loss: 0.1203,V Acc: 0.4636, Top 70th Acc: 0.6234, Bottom 30th Acc: 0.0909
Fold [4/5] Epoch [10/100] Initial Loss: 0.1300, Training Loss: 0.0226, Initial Validation Loss: 0.1203, Validation Loss: 0.0293,V Acc: 0.8273, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.5152
Fold [4/5] Epoch [20/100] Initial Loss: 0.1300, Training Loss: 0.0177, Initial Validation Loss: 0.1203, Validation Loss: 0.0320,V Acc: 0.8364, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 20  Rolling back to Epoch (base 0): 15  Top Validation Acc: 0.948051948051948
Fold [5/5] Epoch [0/100] Initial Loss: 0.1367, Training Loss: 0.1367, Initial Validation Loss: 0.1222, Validation Loss: 0.1222,V Acc: 0.4815, Top 70th Acc: 0.5658, Bottom 30th Acc: 0.2812
Fold [5/5] Epoch [10/100] Initial Loss: 0.1367, Training Loss: 0.0332, Initial Validation Loss: 0.1222, Validation Loss: 0.0366,V Acc: 0.8333, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.5938
Fold [5/5] Epoch [20/100] Initial Loss: 0.1367, Training Loss: 0.0183, Initial Validation Loss: 0.1222, Validation Loss: 0.0269,V Acc: 0.8981, Top 70th Acc: 0.9211, Bottom 30th Acc: 0.8438
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.9210526315789473
Running train_nn.py with seed 58
CUDA:False
Training samples count:  550
Training on 21 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1324, Training Loss: 0.1324, Initial Validation Loss: 0.1261, Validation Loss: 0.1261,V Acc: 0.5045, Top 70th Acc: 0.5513, Bottom 30th Acc: 0.3939
Fold [1/5] Epoch [10/100] Initial Loss: 0.1324, Training Loss: 0.0254, Initial Validation Loss: 0.1261, Validation Loss: 0.0313,V Acc: 0.8829, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 19  Rolling back to Epoch (base 0): 14  Top Validation Acc: 0.9487179487179487
Fold [2/5] Epoch [0/100] Initial Loss: 0.1340, Training Loss: 0.1340, Initial Validation Loss: 0.1247, Validation Loss: 0.1247,V Acc: 0.4955, Top 70th Acc: 0.6282, Bottom 30th Acc: 0.1818
Fold [2/5] Epoch [10/100] Initial Loss: 0.1340, Training Loss: 0.0265, Initial Validation Loss: 0.1247, Validation Loss: 0.0286,V Acc: 0.8829, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.8182
Stopping early at Epoch (base 0): 18  Rolling back to Epoch (base 0): 13  Top Validation Acc: 0.9102564102564102
58 1 [array([0.65358615, 0.03568499, 0.03362336, 0.06488061, 0.21222478],
      dtype=float32)]
Fold [3/5] Epoch [0/100] Initial Loss: 0.1304, Training Loss: 0.1304, Initial Validation Loss: 0.1160, Validation Loss: 0.1160,V Acc: 0.5455, Top 70th Acc: 0.6104, Bottom 30th Acc: 0.3939
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.935064935064935
Fold [4/5] Epoch [0/100] Initial Loss: 0.1364, Training Loss: 0.1364, Initial Validation Loss: 0.1381, Validation Loss: 0.1381,V Acc: 0.3091, Top 70th Acc: 0.2338, Bottom 30th Acc: 0.4848
Fold [4/5] Epoch [10/100] Initial Loss: 0.1364, Training Loss: 0.0316, Initial Validation Loss: 0.1381, Validation Loss: 0.0375,V Acc: 0.8545, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6364
Fold [4/5] Epoch [20/100] Initial Loss: 0.1364, Training Loss: 0.0164, Initial Validation Loss: 0.1381, Validation Loss: 0.0279,V Acc: 0.8818, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.6667
Fold [4/5] Epoch [30/100] Initial Loss: 0.1364, Training Loss: 0.0135, Initial Validation Loss: 0.1381, Validation Loss: 0.0261,V Acc: 0.8909, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 30  Rolling back to Epoch (base 0): 25  Top Validation Acc: 0.974025974025974
Fold [5/5] Epoch [0/100] Initial Loss: 0.1379, Training Loss: 0.1379, Initial Validation Loss: 0.1273, Validation Loss: 0.1273,V Acc: 0.3796, Top 70th Acc: 0.4868, Bottom 30th Acc: 0.1250
Fold [5/5] Epoch [10/100] Initial Loss: 0.1379, Training Loss: 0.0331, Initial Validation Loss: 0.1273, Validation Loss: 0.0427,V Acc: 0.7500, Top 70th Acc: 0.9211, Bottom 30th Acc: 0.3438
Fold [5/5] Epoch [20/100] Initial Loss: 0.1379, Training Loss: 0.0160, Initial Validation Loss: 0.1273, Validation Loss: 0.0347,V Acc: 0.7870, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.4062
Fold [5/5] Epoch [30/100] Initial Loss: 0.1379, Training Loss: 0.0119, Initial Validation Loss: 0.1273, Validation Loss: 0.0322,V Acc: 0.7870, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.4062
Fold [5/5] Epoch [40/100] Initial Loss: 0.1379, Training Loss: 0.0108, Initial Validation Loss: 0.1273, Validation Loss: 0.0296,V Acc: 0.8148, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.5000
Stopping early at Epoch (base 0): 42  Rolling back to Epoch (base 0): 37  Top Validation Acc: 0.9473684210526315
Running train_nn.py with seed 40
CUDA:False
Training samples count:  550
Training on 40 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1399, Training Loss: 0.1399, Initial Validation Loss: 0.1387, Validation Loss: 0.1387,V Acc: 0.2703, Top 70th Acc: 0.3462, Bottom 30th Acc: 0.0909
Fold [1/5] Epoch [10/100] Initial Loss: 0.1399, Training Loss: 0.0349, Initial Validation Loss: 0.1387, Validation Loss: 0.0381,V Acc: 0.8649, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.6667
Fold [1/5] Epoch [20/100] Initial Loss: 0.1399, Training Loss: 0.0176, Initial Validation Loss: 0.1387, Validation Loss: 0.0270,V Acc: 0.8559, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.9615384615384616
Fold [2/5] Epoch [0/100] Initial Loss: 0.1395, Training Loss: 0.1395, Initial Validation Loss: 0.1323, Validation Loss: 0.1323,V Acc: 0.2703, Top 70th Acc: 0.3462, Bottom 30th Acc: 0.0909
Fold [2/5] Epoch [10/100] Initial Loss: 0.1395, Training Loss: 0.0332, Initial Validation Loss: 0.1323, Validation Loss: 0.0390,V Acc: 0.8018, Top 70th Acc: 0.8846, Bottom 30th Acc: 0.6061
Fold [2/5] Epoch [20/100] Initial Loss: 0.1395, Training Loss: 0.0166, Initial Validation Loss: 0.1323, Validation Loss: 0.0263,V Acc: 0.8198, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.5152
Fold [2/5] Epoch [30/100] Initial Loss: 0.1395, Training Loss: 0.0131, Initial Validation Loss: 0.1323, Validation Loss: 0.0254,V Acc: 0.8378, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 31  Rolling back to Epoch (base 0): 26  Top Validation Acc: 0.9487179487179487
40 1 [array([0.44634026, 0.0563934 , 0.05996161, 0.09073641, 0.34656838],
      dtype=float32)]
Fold [3/5] Epoch [0/100] Initial Loss: 0.1412, Training Loss: 0.1412, Initial Validation Loss: 0.1366, Validation Loss: 0.1366,V Acc: 0.2545, Top 70th Acc: 0.3247, Bottom 30th Acc: 0.0909
Fold [3/5] Epoch [10/100] Initial Loss: 0.1412, Training Loss: 0.0446, Initial Validation Loss: 0.1366, Validation Loss: 0.0449,V Acc: 0.7818, Top 70th Acc: 0.8961, Bottom 30th Acc: 0.5152
Fold [3/5] Epoch [20/100] Initial Loss: 0.1412, Training Loss: 0.0169, Initial Validation Loss: 0.1366, Validation Loss: 0.0296,V Acc: 0.8545, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 28  Rolling back to Epoch (base 0): 23  Top Validation Acc: 0.961038961038961
Fold [4/5] Epoch [0/100] Initial Loss: 0.1370, Training Loss: 0.1370, Initial Validation Loss: 0.1322, Validation Loss: 0.1322,V Acc: 0.3545, Top 70th Acc: 0.4286, Bottom 30th Acc: 0.1818
Fold [4/5] Epoch [10/100] Initial Loss: 0.1370, Training Loss: 0.0320, Initial Validation Loss: 0.1322, Validation Loss: 0.0491,V Acc: 0.7818, Top 70th Acc: 0.8961, Bottom 30th Acc: 0.5152
Fold [4/5] Epoch [20/100] Initial Loss: 0.1370, Training Loss: 0.0208, Initial Validation Loss: 0.1322, Validation Loss: 0.0448,V Acc: 0.7909, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.4848
Fold [4/5] Epoch [30/100] Initial Loss: 0.1370, Training Loss: 0.0149, Initial Validation Loss: 0.1322, Validation Loss: 0.0375,V Acc: 0.8182, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.5455
Fold [4/5] Epoch [40/100] Initial Loss: 0.1370, Training Loss: 0.0124, Initial Validation Loss: 0.1322, Validation Loss: 0.0340,V Acc: 0.8182, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.4848
Fold [4/5] Epoch [50/100] Initial Loss: 0.1370, Training Loss: 0.0113, Initial Validation Loss: 0.1322, Validation Loss: 0.0326,V Acc: 0.8273, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.5152
Stopping early at Epoch (base 0): 54  Rolling back to Epoch (base 0): 49  Top Validation Acc: 0.961038961038961
Fold [5/5] Epoch [0/100] Initial Loss: 0.1410, Training Loss: 0.1410, Initial Validation Loss: 0.1303, Validation Loss: 0.1303,V Acc: 0.3519, Top 70th Acc: 0.4474, Bottom 30th Acc: 0.1250
Fold [5/5] Epoch [10/100] Initial Loss: 0.1410, Training Loss: 0.0257, Initial Validation Loss: 0.1303, Validation Loss: 0.0369,V Acc: 0.8333, Top 70th Acc: 0.9079, Bottom 30th Acc: 0.6562
Stopping early at Epoch (base 0): 18  Rolling back to Epoch (base 0): 13  Top Validation Acc: 0.9342105263157895
Running train_nn.py with seed 41
CUDA:False
Training samples count:  550
Training on 40 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1373, Training Loss: 0.1373, Initial Validation Loss: 0.1350, Validation Loss: 0.1350,V Acc: 0.3694, Top 70th Acc: 0.4359, Bottom 30th Acc: 0.2121
Fold [1/5] Epoch [10/100] Initial Loss: 0.1373, Training Loss: 0.0404, Initial Validation Loss: 0.1350, Validation Loss: 0.0579,V Acc: 0.7297, Top 70th Acc: 0.8333, Bottom 30th Acc: 0.4848
Fold [1/5] Epoch [20/100] Initial Loss: 0.1373, Training Loss: 0.0170, Initial Validation Loss: 0.1350, Validation Loss: 0.0380,V Acc: 0.7838, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.4545
Fold [1/5] Epoch [30/100] Initial Loss: 0.1373, Training Loss: 0.0119, Initial Validation Loss: 0.1350, Validation Loss: 0.0356,V Acc: 0.7838, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.4242
Stopping early at Epoch (base 0): 38  Rolling back to Epoch (base 0): 33  Top Validation Acc: 0.9487179487179487
41 0 [array([0.24647474, 0.06278639, 0.02928908, 0.12700428, 0.53444546],
      dtype=float32)]
Fold [2/5] Epoch [0/100] Initial Loss: 0.1412, Training Loss: 0.1412, Initial Validation Loss: 0.1320, Validation Loss: 0.1320,V Acc: 0.3333, Top 70th Acc: 0.3974, Bottom 30th Acc: 0.1818
Fold [2/5] Epoch [10/100] Initial Loss: 0.1412, Training Loss: 0.0367, Initial Validation Loss: 0.1320, Validation Loss: 0.0411,V Acc: 0.7748, Top 70th Acc: 0.8718, Bottom 30th Acc: 0.5455
Fold [2/5] Epoch [20/100] Initial Loss: 0.1412, Training Loss: 0.0154, Initial Validation Loss: 0.1320, Validation Loss: 0.0306,V Acc: 0.8018, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.4848
Fold [2/5] Epoch [30/100] Initial Loss: 0.1412, Training Loss: 0.0117, Initial Validation Loss: 0.1320, Validation Loss: 0.0282,V Acc: 0.8468, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.6364
Fold [2/5] Epoch [40/100] Initial Loss: 0.1412, Training Loss: 0.0104, Initial Validation Loss: 0.1320, Validation Loss: 0.0291,V Acc: 0.8378, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.6061
Fold [4/5] Epoch [10/100] Initial Loss: 0.1379, Training Loss: 0.0352, Initial Validation Loss: 0.1335, Validation Loss: 0.0502,V Acc: 0.7636, Top 70th Acc: 0.8701, Bottom 30th Acc: 0.5152
Fold [4/5] Epoch [20/100] Initial Loss: 0.1379, Training Loss: 0.0205, Initial Validation Loss: 0.1335, Validation Loss: 0.0389,V Acc: 0.8091, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.4848
Fold [4/5] Epoch [30/100] Initial Loss: 0.1379, Training Loss: 0.0156, Initial Validation Loss: 0.1335, Validation Loss: 0.0339,V Acc: 0.8455, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6061
Fold [4/5] Epoch [40/100] Initial Loss: 0.1379, Training Loss: 0.0142, Initial Validation Loss: 0.1335, Validation Loss: 0.0330,V Acc: 0.8455, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 44  Rolling back to Epoch (base 0): 39  Top Validation Acc: 0.935064935064935
Fold [5/5] Epoch [0/100] Initial Loss: 0.1387, Training Loss: 0.1387, Initial Validation Loss: 0.1294, Validation Loss: 0.1294,V Acc: 0.3241, Top 70th Acc: 0.3947, Bottom 30th Acc: 0.1562
Fold [5/5] Epoch [10/100] Initial Loss: 0.1387, Training Loss: 0.0244, Initial Validation Loss: 0.1294, Validation Loss: 0.0354,V Acc: 0.8056, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.4688
Stopping early at Epoch (base 0): 17  Rolling back to Epoch (base 0): 12  Top Validation Acc: 0.9210526315789473
Running train_nn.py with seed 41
CUDA:False
Training samples count:  550
Training on 30 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1384, Training Loss: 0.1384, Initial Validation Loss: 0.1376, Validation Loss: 0.1376,V Acc: 0.1982, Top 70th Acc: 0.2179, Bottom 30th Acc: 0.1515
Fold [1/5] Epoch [10/100] Initial Loss: 0.1384, Training Loss: 0.0332, Initial Validation Loss: 0.1376, Validation Loss: 0.0469,V Acc: 0.7297, Top 70th Acc: 0.8846, Bottom 30th Acc: 0.3636
Fold [1/5] Epoch [20/100] Initial Loss: 0.1384, Training Loss: 0.0187, Initial Validation Loss: 0.1376, Validation Loss: 0.0371,V Acc: 0.8198, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 28  Rolling back to Epoch (base 0): 23  Top Validation Acc: 0.9102564102564102
41 0 [array([0.4706251 , 0.22295769, 0.03389189, 0.11880805, 0.15371734],
      dtype=float32)]
Fold [2/5] Epoch [0/100] Initial Loss: 0.1404, Training Loss: 0.1404, Initial Validation Loss: 0.1332, Validation Loss: 0.1332,V Acc: 0.2703, Top 70th Acc: 0.2308, Bottom 30th Acc: 0.3636
Fold [2/5] Epoch [10/100] Initial Loss: 0.1404, Training Loss: 0.0388, Initial Validation Loss: 0.1332, Validation Loss: 0.0388,V Acc: 0.7928, Top 70th Acc: 0.8974, Bottom 30th Acc: 0.5455
Fold [2/5] Epoch [20/100] Initial Loss: 0.1404, Training Loss: 0.0176, Initial Validation Loss: 0.1332, Validation Loss: 0.0293,V Acc: 0.8198, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 21  Rolling back to Epoch (base 0): 16  Top Validation Acc: 0.9102564102564102
Fold [3/5] Epoch [0/100] Initial Loss: 0.1398, Training Loss: 0.1398, Initial Validation Loss: 0.1356, Validation Loss: 0.1356,V Acc: 0.3455, Top 70th Acc: 0.4416, Bottom 30th Acc: 0.1212
Fold [3/5] Epoch [10/100] Initial Loss: 0.1398, Training Loss: 0.0270, Initial Validation Loss: 0.1356, Validation Loss: 0.0412,V Acc: 0.7909, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.5152
Fold [3/5] Epoch [20/100] Initial Loss: 0.1398, Training Loss: 0.0175, Initial Validation Loss: 0.1356, Validation Loss: 0.0341,V Acc: 0.7909, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.4545
Fold [3/5] Epoch [30/100] Initial Loss: 0.1398, Training Loss: 0.0158, Initial Validation Loss: 0.1356, Validation Loss: 0.0340,V Acc: 0.8182, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.4848
Stopping early at Epoch (base 0): 33  Rolling back to Epoch (base 0): 28  Top Validation Acc: 0.974025974025974
Fold [4/5] Epoch [0/100] Initial Loss: 0.1350, Training Loss: 0.1350, Initial Validation Loss: 0.1308, Validation Loss: 0.1308,V Acc: 0.3273, Top 70th Acc: 0.3506, Bottom 30th Acc: 0.2727
Fold [4/5] Epoch [10/100] Initial Loss: 0.1350, Training Loss: 0.0377, Initial Validation Loss: 0.1308, Validation Loss: 0.0416,V Acc: 0.8000, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.4848
Fold [4/5] Epoch [20/100] Initial Loss: 0.1350, Training Loss: 0.0187, Initial Validation Loss: 0.1308, Validation Loss: 0.0274,V Acc: 0.8909, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.6970
Fold [4/5] Epoch [30/100] Initial Loss: 0.1350, Training Loss: 0.0157, Initial Validation Loss: 0.1308, Validation Loss: 0.0262,V Acc: 0.8818, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 31  Rolling back to Epoch (base 0): 26  Top Validation Acc: 0.961038961038961
Fold [5/5] Epoch [0/100] Initial Loss: 0.1413, Training Loss: 0.1413, Initial Validation Loss: 0.1314, Validation Loss: 0.1314,V Acc: 0.2778, Top 70th Acc: 0.3158, Bottom 30th Acc: 0.1875
Fold [5/5] Epoch [10/100] Initial Loss: 0.1413, Training Loss: 0.0303, Initial Validation Loss: 0.1314, Validation Loss: 0.0368,V Acc: 0.8519, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.6250
Fold [5/5] Epoch [20/100] Initial Loss: 0.1413, Training Loss: 0.0173, Initial Validation Loss: 0.1314, Validation Loss: 0.0303,V Acc: 0.8519, Top 70th Acc: 0.9737, Bottom 30th Acc: 0.5625
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.9605263157894737
Running train_nn.py with seed 42
CUDA:False
Training samples count:  550
Training on 30 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1376, Training Loss: 0.1376, Initial Validation Loss: 0.1345, Validation Loss: 0.1345,V Acc: 0.3243, Top 70th Acc: 0.3333, Bottom 30th Acc: 0.3030
Fold [1/5] Epoch [10/100] Initial Loss: 0.1376, Training Loss: 0.0314, Initial Validation Loss: 0.1345, Validation Loss: 0.0434,V Acc: 0.8198, Top 70th Acc: 0.8974, Bottom 30th Acc: 0.6364
Fold [1/5] Epoch [20/100] Initial Loss: 0.1376, Training Loss: 0.0173, Initial Validation Loss: 0.1345, Validation Loss: 0.0363,V Acc: 0.8559, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 22  Rolling back to Epoch (base 0): 17  Top Validation Acc: 0.9230769230769231
Fold [2/5] Epoch [0/100] Initial Loss: 0.1403, Training Loss: 0.1403, Initial Validation Loss: 0.1329, Validation Loss: 0.1329,V Acc: 0.2703, Top 70th Acc: 0.3205, Bottom 30th Acc: 0.1515
Fold [2/5] Epoch [10/100] Initial Loss: 0.1403, Training Loss: 0.0421, Initial Validation Loss: 0.1329, Validation Loss: 0.0470,V Acc: 0.7297, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.3030
Fold [2/5] Epoch [20/100] Initial Loss: 0.1403, Training Loss: 0.0178, Initial Validation Loss: 0.1329, Validation Loss: 0.0336,V Acc: 0.8559, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.6970
Fold [2/5] Epoch [30/100] Initial Loss: 0.1403, Training Loss: 0.0148, Initial Validation Loss: 0.1329, Validation Loss: 0.0332,V Acc: 0.8198, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 30  Rolling back to Epoch (base 0): 25  Top Validation Acc: 0.9358974358974359
42 1 [array([0.5642504 , 0.09722912, 0.127517  , 0.11027666, 0.10072682],
      dtype=float32)]
Fold [3/5] Epoch [0/100] Initial Loss: 0.1384, Training Loss: 0.1384, Initial Validation Loss: 0.1317, Validation Loss: 0.1317,V Acc: 0.2545, Top 70th Acc: 0.3377, Bottom 30th Acc: 0.0606
Fold [3/5] Epoch [10/100] Initial Loss: 0.1384, Training Loss: 0.0352, Initial Validation Loss: 0.1317, Validation Loss: 0.0396,V Acc: 0.8091, Top 70th Acc: 0.8961, Bottom 30th Acc: 0.6061
Fold [3/5] Epoch [20/100] Initial Loss: 0.1384, Training Loss: 0.0169, Initial Validation Loss: 0.1317, Validation Loss: 0.0324,V Acc: 0.8273, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 29  Rolling back to Epoch (base 0): 24  Top Validation Acc: 0.9090909090909091
Fold [4/5] Epoch [0/100] Initial Loss: 0.1339, Training Loss: 0.1339, Initial Validation Loss: 0.1318, Validation Loss: 0.1318,V Acc: 0.3909, Top 70th Acc: 0.5325, Bottom 30th Acc: 0.0606
Fold [4/5] Epoch [10/100] Initial Loss: 0.1339, Training Loss: 0.0248, Initial Validation Loss: 0.1318, Validation Loss: 0.0288,V Acc: 0.8636, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.6364
Fold [4/5] Epoch [20/100] Initial Loss: 0.1339, Training Loss: 0.0179, Initial Validation Loss: 0.1318, Validation Loss: 0.0275,V Acc: 0.8364, Top 70th Acc: 0.9870, Bottom 30th Acc: 0.4848
Fold [3/5] Epoch [20/100] Initial Loss: 0.1379, Training Loss: 0.0048, Initial Validation Loss: 0.1358, Validation Loss: 0.0234,V Acc: 0.8727, Top 70th Acc: 0.9870, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.987012987012987
Fold [4/5] Epoch [0/100] Initial Loss: 0.1396, Training Loss: 0.1396, Initial Validation Loss: 0.1369, Validation Loss: 0.1369,V Acc: 0.2545, Top 70th Acc: 0.2338, Bottom 30th Acc: 0.3030
Fold [4/5] Epoch [10/100] Initial Loss: 0.1396, Training Loss: 0.0133, Initial Validation Loss: 0.1369, Validation Loss: 0.0321,V Acc: 0.8545, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.6667
Fold [4/5] Epoch [20/100] Initial Loss: 0.1396, Training Loss: 0.0050, Initial Validation Loss: 0.1369, Validation Loss: 0.0289,V Acc: 0.8545, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.961038961038961
Fold [5/5] Epoch [0/100] Initial Loss: 0.1400, Training Loss: 0.1400, Initial Validation Loss: 0.1336, Validation Loss: 0.1336,V Acc: 0.2500, Top 70th Acc: 0.3289, Bottom 30th Acc: 0.0625
Fold [5/5] Epoch [10/100] Initial Loss: 0.1400, Training Loss: 0.0161, Initial Validation Loss: 0.1336, Validation Loss: 0.0350,V Acc: 0.8611, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.6250
Fold [5/5] Epoch [20/100] Initial Loss: 0.1400, Training Loss: 0.0056, Initial Validation Loss: 0.1336, Validation Loss: 0.0320,V Acc: 0.8519, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.6250
Stopping early at Epoch (base 0): 28  Rolling back to Epoch (base 0): 23  Top Validation Acc: 0.9342105263157895
Running train_nn.py with seed 32
CUDA:False
Training samples count:  550
Training on 163 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1370, Training Loss: 0.1370, Initial Validation Loss: 0.1371, Validation Loss: 0.1371,V Acc: 0.3063, Top 70th Acc: 0.3590, Bottom 30th Acc: 0.1818
Fold [1/5] Epoch [10/100] Initial Loss: 0.1370, Training Loss: 0.0187, Initial Validation Loss: 0.1371, Validation Loss: 0.0321,V Acc: 0.8378, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.5152
Fold [1/5] Epoch [20/100] Initial Loss: 0.1370, Training Loss: 0.0047, Initial Validation Loss: 0.1371, Validation Loss: 0.0257,V Acc: 0.8829, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 21  Rolling back to Epoch (base 0): 16  Top Validation Acc: 0.9615384615384616
Fold [2/5] Epoch [0/100] Initial Loss: 0.1404, Training Loss: 0.1404, Initial Validation Loss: 0.1380, Validation Loss: 0.1380,V Acc: 0.2523, Top 70th Acc: 0.3333, Bottom 30th Acc: 0.0606
Fold [2/5] Epoch [10/100] Initial Loss: 0.1404, Training Loss: 0.0173, Initial Validation Loss: 0.1380, Validation Loss: 0.0323,V Acc: 0.8378, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.5455
Fold [2/5] Epoch [20/100] Initial Loss: 0.1404, Training Loss: 0.0052, Initial Validation Loss: 0.1380, Validation Loss: 0.0266,V Acc: 0.8739, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.9615384615384616
Fold [3/5] Epoch [0/100] Initial Loss: 0.1394, Training Loss: 0.1394, Initial Validation Loss: 0.1323, Validation Loss: 0.1323,V Acc: 0.2727, Top 70th Acc: 0.2857, Bottom 30th Acc: 0.2424
Fold [3/5] Epoch [10/100] Initial Loss: 0.1394, Training Loss: 0.0126, Initial Validation Loss: 0.1323, Validation Loss: 0.0318,V Acc: 0.8091, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.5152
Fold [3/5] Epoch [20/100] Initial Loss: 0.1394, Training Loss: 0.0046, Initial Validation Loss: 0.1323, Validation Loss: 0.0283,V Acc: 0.7727, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.3030
Fold [3/5] Epoch [30/100] Initial Loss: 0.1394, Training Loss: 0.0039, Initial Validation Loss: 0.1323, Validation Loss: 0.0275,V Acc: 0.7727, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.3333
Stopping early at Epoch (base 0): 36  Rolling back to Epoch (base 0): 31  Top Validation Acc: 0.961038961038961
32 2 [array([0.27275917, 0.07065828, 0.10076565, 0.17497955, 0.38083732],
      dtype=float32)]
Fold [4/5] Epoch [0/100] Initial Loss: 0.1394, Training Loss: 0.1394, Initial Validation Loss: 0.1354, Validation Loss: 0.1354,V Acc: 0.3636, Top 70th Acc: 0.4026, Bottom 30th Acc: 0.2727
Fold [4/5] Epoch [10/100] Initial Loss: 0.1394, Training Loss: 0.0256, Initial Validation Loss: 0.1354, Validation Loss: 0.0459,V Acc: 0.8000, Top 70th Acc: 0.8831, Bottom 30th Acc: 0.6061
Fold [4/5] Epoch [20/100] Initial Loss: 0.1394, Training Loss: 0.0053, Initial Validation Loss: 0.1354, Validation Loss: 0.0352,V Acc: 0.8182, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 29  Rolling back to Epoch (base 0): 24  Top Validation Acc: 0.922077922077922
Fold [5/5] Epoch [0/100] Initial Loss: 0.1397, Training Loss: 0.1397, Initial Validation Loss: 0.1291, Validation Loss: 0.1291,V Acc: 0.2500, Top 70th Acc: 0.3553, Bottom 30th Acc: 0.0000
Fold [5/5] Epoch [10/100] Initial Loss: 0.1397, Training Loss: 0.0125, Initial Validation Loss: 0.1291, Validation Loss: 0.0288,V Acc: 0.8889, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.7188
Fold [5/5] Epoch [20/100] Initial Loss: 0.1397, Training Loss: 0.0045, Initial Validation Loss: 0.1291, Validation Loss: 0.0258,V Acc: 0.8519, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.6250
Stopping early at Epoch (base 0): 20  Rolling back to Epoch (base 0): 15  Top Validation Acc: 0.9473684210526315
Running train_nn.py with seed 33
CUDA:False
Training samples count:  550
Training on 163 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1400, Training Loss: 0.1400, Initial Validation Loss: 0.1364, Validation Loss: 0.1364,V Acc: 0.3784, Top 70th Acc: 0.4103, Bottom 30th Acc: 0.3030
Fold [1/5] Epoch [10/100] Initial Loss: 0.1400, Training Loss: 0.0250, Initial Validation Loss: 0.1364, Validation Loss: 0.0406,V Acc: 0.8559, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.6364
Fold [1/5] Epoch [20/100] Initial Loss: 0.1400, Training Loss: 0.0051, Initial Validation Loss: 0.1364, Validation Loss: 0.0282,V Acc: 0.8739, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.6667
Fold [1/5] Epoch [30/100] Initial Loss: 0.1400, Training Loss: 0.0041, Initial Validation Loss: 0.1364, Validation Loss: 0.0279,V Acc: 0.8559, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 30  Rolling back to Epoch (base 0): 25  Top Validation Acc: 0.9615384615384616
Fold [2/5] Epoch [0/100] Initial Loss: 0.1380, Training Loss: 0.1380, Initial Validation Loss: 0.1416, Validation Loss: 0.1416,V Acc: 0.3604, Top 70th Acc: 0.4359, Bottom 30th Acc: 0.1818
Fold [2/5] Epoch [10/100] Initial Loss: 0.1380, Training Loss: 0.0318, Initial Validation Loss: 0.1416, Validation Loss: 0.0497,V Acc: 0.7658, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.4242
Fold [2/5] Epoch [20/100] Initial Loss: 0.1380, Training Loss: 0.0057, Initial Validation Loss: 0.1416, Validation Loss: 0.0264,V Acc: 0.8829, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.6667
Fold [2/5] Epoch [30/100] Initial Loss: 0.1380, Training Loss: 0.0039, Initial Validation Loss: 0.1416, Validation Loss: 0.0256,V Acc: 0.9009, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.7273
Stopping early at Epoch (base 0): 31  Rolling back to Epoch (base 0): 26  Top Validation Acc: 0.9743589743589743
33 1 [array([0.2882137 , 0.05285976, 0.05451234, 0.22675699, 0.37765718],
      dtype=float32)]
Fold [3/5] Epoch [0/100] Initial Loss: 0.1386, Training Loss: 0.1386, Initial Validation Loss: 0.1292, Validation Loss: 0.1292,V Acc: 0.3182, Top 70th Acc: 0.3896, Bottom 30th Acc: 0.1515
Fold [3/5] Epoch [10/100] Initial Loss: 0.1386, Training Loss: 0.0104, Initial Validation Loss: 0.1292, Validation Loss: 0.0322,V Acc: 0.8273, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.5455
Fold [3/5] Epoch [20/100] Initial Loss: 0.1386, Training Loss: 0.0045, Initial Validation Loss: 0.1292, Validation Loss: 0.0303,V Acc: 0.8455, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 27  Rolling back to Epoch (base 0): 22  Top Validation Acc: 0.948051948051948
Fold [4/5] Epoch [0/100] Initial Loss: 0.1424, Training Loss: 0.1424, Initial Validation Loss: 0.1303, Validation Loss: 0.1303,V Acc: 0.3636, Top 70th Acc: 0.4156, Bottom 30th Acc: 0.2424
Stopping early at Epoch (base 0): 32  Rolling back to Epoch (base 0): 27  Top Validation Acc: 0.9210526315789473
Running train_nn.py with seed 41
CUDA:False
Training samples count:  550
Training on 20 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1391, Training Loss: 0.1391, Initial Validation Loss: 0.1351, Validation Loss: 0.1351,V Acc: 0.3063, Top 70th Acc: 0.3462, Bottom 30th Acc: 0.2121
Fold [1/5] Epoch [10/100] Initial Loss: 0.1391, Training Loss: 0.0318, Initial Validation Loss: 0.1351, Validation Loss: 0.0471,V Acc: 0.8108, Top 70th Acc: 0.8718, Bottom 30th Acc: 0.6667
Fold [1/5] Epoch [20/100] Initial Loss: 0.1391, Training Loss: 0.0203, Initial Validation Loss: 0.1351, Validation Loss: 0.0385,V Acc: 0.8378, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.8974358974358975
41 0 [array([0.55302364, 0.06683373, 0.11753377, 0.1370469 , 0.12556192],
      dtype=float32)]
Fold [2/5] Epoch [0/100] Initial Loss: 0.1370, Training Loss: 0.1370, Initial Validation Loss: 0.1293, Validation Loss: 0.1293,V Acc: 0.3784, Top 70th Acc: 0.3846, Bottom 30th Acc: 0.3636
Fold [2/5] Epoch [10/100] Initial Loss: 0.1370, Training Loss: 0.0366, Initial Validation Loss: 0.1293, Validation Loss: 0.0375,V Acc: 0.7838, Top 70th Acc: 0.8846, Bottom 30th Acc: 0.5455
Fold [2/5] Epoch [20/100] Initial Loss: 0.1370, Training Loss: 0.0224, Initial Validation Loss: 0.1293, Validation Loss: 0.0299,V Acc: 0.8108, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.5455
Fold [2/5] Epoch [30/100] Initial Loss: 0.1370, Training Loss: 0.0201, Initial Validation Loss: 0.1293, Validation Loss: 0.0294,V Acc: 0.8108, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.5152
Stopping early at Epoch (base 0): 36  Rolling back to Epoch (base 0): 31  Top Validation Acc: 0.9487179487179487
Fold [3/5] Epoch [0/100] Initial Loss: 0.1387, Training Loss: 0.1387, Initial Validation Loss: 0.1368, Validation Loss: 0.1368,V Acc: 0.3182, Top 70th Acc: 0.3247, Bottom 30th Acc: 0.3030
Fold [3/5] Epoch [10/100] Initial Loss: 0.1387, Training Loss: 0.0439, Initial Validation Loss: 0.1368, Validation Loss: 0.0531,V Acc: 0.7364, Top 70th Acc: 0.8571, Bottom 30th Acc: 0.4545
Fold [3/5] Epoch [20/100] Initial Loss: 0.1387, Training Loss: 0.0234, Initial Validation Loss: 0.1368, Validation Loss: 0.0378,V Acc: 0.8182, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.5455
Fold [3/5] Epoch [30/100] Initial Loss: 0.1387, Training Loss: 0.0205, Initial Validation Loss: 0.1368, Validation Loss: 0.0353,V Acc: 0.8182, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.5152
Stopping early at Epoch (base 0): 38  Rolling back to Epoch (base 0): 33  Top Validation Acc: 0.948051948051948
Fold [4/5] Epoch [0/100] Initial Loss: 0.1390, Training Loss: 0.1390, Initial Validation Loss: 0.1354, Validation Loss: 0.1354,V Acc: 0.3000, Top 70th Acc: 0.3247, Bottom 30th Acc: 0.2424
Fold [4/5] Epoch [10/100] Initial Loss: 0.1390, Training Loss: 0.0352, Initial Validation Loss: 0.1354, Validation Loss: 0.0342,V Acc: 0.8818, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.7273
Fold [4/5] Epoch [20/100] Initial Loss: 0.1390, Training Loss: 0.0219, Initial Validation Loss: 0.1354, Validation Loss: 0.0288,V Acc: 0.8727, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 22  Rolling back to Epoch (base 0): 17  Top Validation Acc: 0.961038961038961
Fold [5/5] Epoch [0/100] Initial Loss: 0.1389, Training Loss: 0.1389, Initial Validation Loss: 0.1310, Validation Loss: 0.1310,V Acc: 0.2963, Top 70th Acc: 0.3289, Bottom 30th Acc: 0.2188
Fold [5/5] Epoch [10/100] Initial Loss: 0.1389, Training Loss: 0.0308, Initial Validation Loss: 0.1310, Validation Loss: 0.0374,V Acc: 0.8611, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.6875
Fold [5/5] Epoch [20/100] Initial Loss: 0.1389, Training Loss: 0.0221, Initial Validation Loss: 0.1310, Validation Loss: 0.0318,V Acc: 0.8704, Top 70th Acc: 0.9737, Bottom 30th Acc: 0.6250
Stopping early at Epoch (base 0): 29  Rolling back to Epoch (base 0): 24  Top Validation Acc: 0.9473684210526315
Running train_nn.py with seed 42
CUDA:False
Training samples count:  550
Training on 20 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1374, Training Loss: 0.1374, Initial Validation Loss: 0.1286, Validation Loss: 0.1286,V Acc: 0.3784, Top 70th Acc: 0.4103, Bottom 30th Acc: 0.3030
Fold [1/5] Epoch [10/100] Initial Loss: 0.1374, Training Loss: 0.0359, Initial Validation Loss: 0.1286, Validation Loss: 0.0502,V Acc: 0.7568, Top 70th Acc: 0.8590, Bottom 30th Acc: 0.5152
Fold [1/5] Epoch [20/100] Initial Loss: 0.1374, Training Loss: 0.0223, Initial Validation Loss: 0.1286, Validation Loss: 0.0409,V Acc: 0.8018, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.5152
Fold [1/5] Epoch [30/100] Initial Loss: 0.1374, Training Loss: 0.0189, Initial Validation Loss: 0.1286, Validation Loss: 0.0388,V Acc: 0.8198, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.6061
Fold [1/5] Epoch [40/100] Initial Loss: 0.1374, Training Loss: 0.0176, Initial Validation Loss: 0.1286, Validation Loss: 0.0397,V Acc: 0.8108, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 43  Rolling back to Epoch (base 0): 38  Top Validation Acc: 0.9358974358974359
Fold [2/5] Epoch [0/100] Initial Loss: 0.1384, Training Loss: 0.1384, Initial Validation Loss: 0.1325, Validation Loss: 0.1325,V Acc: 0.2793, Top 70th Acc: 0.2949, Bottom 30th Acc: 0.2424
Fold [2/5] Epoch [10/100] Initial Loss: 0.1384, Training Loss: 0.0343, Initial Validation Loss: 0.1325, Validation Loss: 0.0519,V Acc: 0.7207, Top 70th Acc: 0.8590, Bottom 30th Acc: 0.3939
Fold [2/5] Epoch [20/100] Initial Loss: 0.1384, Training Loss: 0.0230, Initial Validation Loss: 0.1325, Validation Loss: 0.0380,V Acc: 0.7838, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.4848
Stopping early at Epoch (base 0): 28  Rolling back to Epoch (base 0): 23  Top Validation Acc: 0.9358974358974359
42 1 [array([0.24722417, 0.05867438, 0.21282642, 0.27549106, 0.20578396],
      dtype=float32)]
Fold [3/5] Epoch [0/100] Initial Loss: 0.1369, Training Loss: 0.1369, Initial Validation Loss: 0.1316, Validation Loss: 0.1316,V Acc: 0.2727, Top 70th Acc: 0.2987, Bottom 30th Acc: 0.2121
Fold [3/5] Epoch [10/100] Initial Loss: 0.1369, Training Loss: 0.0387, Initial Validation Loss: 0.1316, Validation Loss: 0.0409,V Acc: 0.8091, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.5758
Fold [3/5] Epoch [20/100] Initial Loss: 0.1369, Training Loss: 0.0229, Initial Validation Loss: 0.1316, Validation Loss: 0.0328,V Acc: 0.8273, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.9090909090909091
Fold [4/5] Epoch [0/100] Initial Loss: 0.1379, Training Loss: 0.1379, Initial Validation Loss: 0.1357, Validation Loss: 0.1357,V Acc: 0.2545, Top 70th Acc: 0.3506, Bottom 30th Acc: 0.0303
Fold [4/5] Epoch [10/100] Initial Loss: 0.1379, Training Loss: 0.0355, Initial Validation Loss: 0.1357, Validation Loss: 0.0310,V Acc: 0.8545, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.6061
Fold [4/5] Epoch [20/100] Initial Loss: 0.1379, Training Loss: 0.0254, Initial Validation Loss: 0.1357, Validation Loss: 0.0238,V Acc: 0.9000, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.7576
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.961038961038961
Fold [5/5] Epoch [0/100] Initial Loss: 0.1377, Training Loss: 0.1377, Initial Validation Loss: 0.1329, Validation Loss: 0.1329,V Acc: 0.2593, Top 70th Acc: 0.3158, Bottom 30th Acc: 0.1250
Fold [5/5] Epoch [10/100] Initial Loss: 0.1377, Training Loss: 0.0407, Initial Validation Loss: 0.1329, Validation Loss: 0.0416,V Acc: 0.8333, Top 70th Acc: 0.9079, Bottom 30th Acc: 0.6562
Fold [5/5] Epoch [20/100] Initial Loss: 0.1377, Training Loss: 0.0271, Initial Validation Loss: 0.1329, Validation Loss: 0.0312,V Acc: 0.8611, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.6250
Fold [5/5] Epoch [30/100] Initial Loss: 0.1377, Training Loss: 0.0230, Initial Validation Loss: 0.1329, Validation Loss: 0.0280,V Acc: 0.8796, Top 70th Acc: 0.9737, Bottom 30th Acc: 0.6562
Stopping early at Epoch (base 0): 38  Rolling back to Epoch (base 0): 33  Top Validation Acc:
Stopping early at Epoch (base 0): 42  Rolling back to Epoch (base 0): 37  Top Validation Acc: 0.7368421052631579
37 4 [array([0.12867148, 0.3580456 , 0.1300759 , 0.24082328, 0.14238372],
      dtype=float32)]
Running train_nn.py with seed 38
CUDA:False
Training samples count:  550
Training on 2 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1299, Training Loss: 0.1299, Initial Validation Loss: 0.1175, Validation Loss: 0.1175,V Acc: 0.4685, Top 70th Acc: 0.5385, Bottom 30th Acc: 0.3030
Fold [1/5] Epoch [10/100] Initial Loss: 0.1299, Training Loss: 0.0802, Initial Validation Loss: 0.1175, Validation Loss: 0.0820,V Acc: 0.6126, Top 70th Acc: 0.7692, Bottom 30th Acc: 0.2424
Fold [1/5] Epoch [20/100] Initial Loss: 0.1299, Training Loss: 0.0786, Initial Validation Loss: 0.1175, Validation Loss: 0.0805,V Acc: 0.6306, Top 70th Acc: 0.7692, Bottom 30th Acc: 0.3030
Stopping early at Epoch (base 0): 21  Rolling back to Epoch (base 0): 16  Top Validation Acc: 0.7692307692307693
Fold [2/5] Epoch [0/100] Initial Loss: 0.1383, Training Loss: 0.1383, Initial Validation Loss: 0.1291, Validation Loss: 0.1291,V Acc: 0.5225, Top 70th Acc: 0.5641, Bottom 30th Acc: 0.4242
Fold [2/5] Epoch [10/100] Initial Loss: 0.1383, Training Loss: 0.0814, Initial Validation Loss: 0.1291, Validation Loss: 0.0776,V Acc: 0.6216, Top 70th Acc: 0.7308, Bottom 30th Acc: 0.3636
Fold [2/5] Epoch [20/100] Initial Loss: 0.1383, Training Loss: 0.0794, Initial Validation Loss: 0.1291, Validation Loss: 0.0762,V Acc: 0.6216, Top 70th Acc: 0.7179, Bottom 30th Acc: 0.3939
Fold [2/5] Epoch [30/100] Initial Loss: 0.1383, Training Loss: 0.0789, Initial Validation Loss: 0.1291, Validation Loss: 0.0764,V Acc: 0.6396, Top 70th Acc: 0.7308, Bottom 30th Acc: 0.4242
Stopping early at Epoch (base 0): 30  Rolling back to Epoch (base 0): 25  Top Validation Acc: 0.7307692307692307
Fold [3/5] Epoch [0/100] Initial Loss: 0.1315, Training Loss: 0.1315, Initial Validation Loss: 0.1268, Validation Loss: 0.1268,V Acc: 0.4818, Top 70th Acc: 0.5584, Bottom 30th Acc: 0.3030
Fold [3/5] Epoch [10/100] Initial Loss: 0.1315, Training Loss: 0.0784, Initial Validation Loss: 0.1268, Validation Loss: 0.0881,V Acc: 0.6273, Top 70th Acc: 0.7143, Bottom 30th Acc: 0.4242
Fold [3/5] Epoch [20/100] Initial Loss: 0.1315, Training Loss: 0.0765, Initial Validation Loss: 0.1268, Validation Loss: 0.0875,V Acc: 0.6091, Top 70th Acc: 0.7013, Bottom 30th Acc: 0.3939
Fold [3/5] Epoch [30/100] Initial Loss: 0.1315, Training Loss: 0.0755, Initial Validation Loss: 0.1268, Validation Loss: 0.0872,V Acc: 0.6273, Top 70th Acc: 0.7013, Bottom 30th Acc: 0.4545
Stopping early at Epoch (base 0): 37  Rolling back to Epoch (base 0): 32  Top Validation Acc: 0.7012987012987013
Fold [4/5] Epoch [0/100] Initial Loss: 0.1344, Training Loss: 0.1344, Initial Validation Loss: 0.1195, Validation Loss: 0.1195,V Acc: 0.5273, Top 70th Acc: 0.5974, Bottom 30th Acc: 0.3636
Fold [4/5] Epoch [10/100] Initial Loss: 0.1344, Training Loss: 0.0826, Initial Validation Loss: 0.1195, Validation Loss: 0.0720,V Acc: 0.7000, Top 70th Acc: 0.7792, Bottom 30th Acc: 0.5152
Fold [4/5] Epoch [20/100] Initial Loss: 0.1344, Training Loss: 0.0810, Initial Validation Loss: 0.1195, Validation Loss: 0.0699,V Acc: 0.7000, Top 70th Acc: 0.7792, Bottom 30th Acc: 0.5152
Fold [4/5] Epoch [30/100] Initial Loss: 0.1344, Training Loss: 0.0804, Initial Validation Loss: 0.1195, Validation Loss: 0.0689,V Acc: 0.7000, Top 70th Acc: 0.7922, Bottom 30th Acc: 0.4848
Fold [4/5] Epoch [40/100] Initial Loss: 0.1344, Training Loss: 0.0796, Initial Validation Loss: 0.1195, Validation Loss: 0.0686,V Acc: 0.6818, Top 70th Acc: 0.7922, Bottom 30th Acc: 0.4242
Fold [4/5] Epoch [50/100] Initial Loss: 0.1344, Training Loss: 0.0788, Initial Validation Loss: 0.1195, Validation Loss: 0.0689,V Acc: 0.6909, Top 70th Acc: 0.7922, Bottom 30th Acc: 0.4545
Stopping early at Epoch (base 0): 59  Rolling back to Epoch (base 0): 54  Top Validation Acc: 0.7922077922077922
Fold [5/5] Epoch [0/100] Initial Loss: 0.1403, Training Loss: 0.1403, Initial Validation Loss: 0.1208, Validation Loss: 0.1208,V Acc: 0.4259, Top 70th Acc: 0.5658, Bottom 30th Acc: 0.0938
Fold [5/5] Epoch [10/100] Initial Loss: 0.1403, Training Loss: 0.0799, Initial Validation Loss: 0.1208, Validation Loss: 0.0804,V Acc: 0.5833, Top 70th Acc: 0.6842, Bottom 30th Acc: 0.3438
Stopping early at Epoch (base 0): 15  Rolling back to Epoch (base 0): 10  Top Validation Acc: 0.6447368421052632
38 4 [array([0.12561099, 0.3705846 , 0.14506711, 0.18331054, 0.17542672],
      dtype=float32)]
Running train_nn.py with seed 39
CUDA:False
Training samples count:  550
Training on 2 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1414, Training Loss: 0.1414, Initial Validation Loss: 0.1336, Validation Loss: 0.1336,V Acc: 0.4054, Top 70th Acc: 0.5000, Bottom 30th Acc: 0.1818
Fold [1/5] Epoch [10/100] Initial Loss: 0.1414, Training Loss: 0.0815, Initial Validation Loss: 0.1336, Validation Loss: 0.0814,V Acc: 0.6126, Top 70th Acc: 0.7051, Bottom 30th Acc: 0.3939
Fold [1/5] Epoch [20/100] Initial Loss: 0.1414, Training Loss: 0.0790, Initial Validation Loss: 0.1336, Validation Loss: 0.0783,V Acc: 0.6396, Top 70th Acc: 0.7179, Bottom 30th Acc: 0.4545
Fold [1/5] Epoch [30/100] Initial Loss: 0.1414, Training Loss: 0.0782, Initial Validation Loss: 0.1336, Validation Loss: 0.0776,V Acc: 0.6396, Top 70th Acc: 0.7308, Bottom 30th Acc: 0.4242
Fold [1/5] Epoch [40/100] Initial Loss: 0.1414, Training Loss: 0.0775, Initial Validation Loss: 0.1336, Validation Loss: 0.0770,V Acc: 0.6577, Top 70th Acc: 0.7308, Bottom 30th Acc: 0.4848
Stopping early at Epoch (base 0): 48  Rolling back to Epoch (base 0): 43  Top Validation Acc: 0.7307692307692307
Fold [2/5] Epoch [0/100] Initial Loss: 0.1358, Training Loss: 0.1358, Initial Validation Loss: 0.1271, Validation Loss: 0.1271,V Acc: 0.4234, Top 70th Acc: 0.5128, Bottom 30th Acc: 0.2121
Fold [2/5] Epoch [10/100] Initial Loss: 0.1358, Training Loss: 0.0820, Initial Validation Loss: 0.1271, Validation Loss: 0.0823,V Acc: 0.6126, Top 70th Acc: 0.7179, Bottom 30th Acc: 0.3636
Fold [2/5] Epoch [20/100] Initial Loss: 0.1358, Training Loss: 0.0788, Initial Validation Loss: 0.1271, Validation Loss: 0.0798,V Acc: 0.6216, Top 70th Acc: 0.7436, Bottom 30th Acc: 0.3333
Fold [2/5] Epoch [30/100] Initial Loss: 0.1358, Training Loss: 0.0781, Initial Validation Loss: 0.1271, Validation Loss: 0.0792,V Acc: 0.6216, Top 70th Acc: 0.7051, Bottom 30th Acc: 0.4242
Stopping early at Epoch (base 0): 36  Rolling back to Epoch (base 0): 31  Top Validation Acc: 0.7435897435897436
39 1 [array([0.13556446, 0.36021188, 0.12875679, 0.24327111, 0.13219577],
      dtype=float32)]
Fold [3/5] Epoch [0/100] Initial Loss: 0.1335, Training Loss: 0.1335, Initial Validation Loss: 0.1209, Validation Loss: 0.1209,V Acc: 0.4000, Top 70th Acc: 0.4935, Bottom 30th Acc: 0.1818
Fold [3/5] Epoch [10/100] Initial Loss: 0.1335, Training Loss: 0.0809, Initial Validation Loss: 0.1209, Validation Loss: 0.0857,V Acc: 0.6091, Top 70th Acc: 0.6883, Bottom 30th Acc: 0.4242
Fold [3/5] Epoch [20/100] Initial Loss: 0.1335, Training Loss: 0.0782, Initial Validation Loss: 0.1209, Validation Loss: 0.0835,V Acc: 0.6182, Top 70th Acc: 0.6883, Bottom 30th Acc: 0.4545
Fold [3/5] Epoch [30/100] Initial Loss: 0.1335, Training Loss: 0.0775, Initial Validation Loss: 0.1209, Validation Loss: 0.0823,V Acc: 0.6091, Top 70th Acc: 0.7013, Bottom 30th Acc: 0.3939
Fold [3/5] Epoch [40/100] Initial Loss: 0.1335, Training Loss: 0.0766, Initial Validation Loss: 0.1209, Validation Loss: 0.0834,V Acc: 0.6091, Top 70th Acc: 0.6883, Bottom 30th Acc: 0.4242
Stopping early at Epoch (base 0): 44  Rolling back to Epoch (base 0): 39  Top Validation Acc: 0.7142857142857143
Fold [4/5] Epoch [0/100] Initial Loss: 0.1338, Training Loss: 0.1338, Initial Validation Loss: 0.1302, Validation Loss: 0.1302,V Acc: 0.5000, Top 70th Acc: 0.5584, Bottom 30th Acc: 0.3636
Fold [4/5] Epoch [10/100] Initial Loss: 0.1338, Training Loss: 0.0824, Initial Validation Loss: 0.1302, Validation Loss: 0.0758,V Acc: 0.6727, Top 70th Acc: 0.7403, Bottom 30th Acc: 0.5152
Fold [4/5] Epoch [20/100] Initial Loss: 0.1338, Training Loss: 0.0796, Initial Validation Loss: 0.1302, Validation Loss: 0.0733,V Acc: 0.7091, Top 70th Acc: 0.7792, Bottom 30th Acc: 0.5455
Fold [3/5] Epoch [10/100] Initial Loss: 0.1304, Training Loss: 0.0252, Initial Validation Loss: 0.1160, Validation Loss: 0.0313,V Acc: 0.8636, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6667
Fold [3/5] Epoch [20/100] Initial Loss: 0.1304, Training Loss: 0.0180, Initial Validation Loss: 0.1160, Validation Loss: 0.0301,V Acc: 0.8545, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 21  Rolling back to Epoch (base 0): 16  Top Validation Acc: 0.948051948051948
Fold [4/5] Epoch [0/100] Initial Loss: 0.1375, Training Loss: 0.1375, Initial Validation Loss: 0.1268, Validation Loss: 0.1268,V Acc: 0.4636, Top 70th Acc: 0.5455, Bottom 30th Acc: 0.2727
Fold [4/5] Epoch [10/100] Initial Loss: 0.1375, Training Loss: 0.0293, Initial Validation Loss: 0.1268, Validation Loss: 0.0308,V Acc: 0.8545, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6364
Fold [4/5] Epoch [20/100] Initial Loss: 0.1375, Training Loss: 0.0195, Initial Validation Loss: 0.1268, Validation Loss: 0.0241,V Acc: 0.8818, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.974025974025974
Fold [5/5] Epoch [0/100] Initial Loss: 0.1336, Training Loss: 0.1336, Initial Validation Loss: 0.1197, Validation Loss: 0.1197,V Acc: 0.4167, Top 70th Acc: 0.5526, Bottom 30th Acc: 0.0938
Fold [5/5] Epoch [10/100] Initial Loss: 0.1336, Training Loss: 0.0242, Initial Validation Loss: 0.1197, Validation Loss: 0.0323,V Acc: 0.8333, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.5938
Fold [5/5] Epoch [20/100] Initial Loss: 0.1336, Training Loss: 0.0178, Initial Validation Loss: 0.1197, Validation Loss: 0.0295,V Acc: 0.8611, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.6562
Stopping early at Epoch (base 0): 20  Rolling back to Epoch (base 0): 15  Top Validation Acc: 0.9473684210526315
Running train_nn.py with seed 59
CUDA:False
Training samples count:  550
Training on 21 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1310, Training Loss: 0.1310, Initial Validation Loss: 0.1106, Validation Loss: 0.1106,V Acc: 0.6396, Top 70th Acc: 0.7821, Bottom 30th Acc: 0.3030
Fold [1/5] Epoch [10/100] Initial Loss: 0.1310, Training Loss: 0.0228, Initial Validation Loss: 0.1106, Validation Loss: 0.0362,V Acc: 0.8378, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 17  Rolling back to Epoch (base 0): 12  Top Validation Acc: 0.9358974358974359
Fold [2/5] Epoch [0/100] Initial Loss: 0.1343, Training Loss: 0.1343, Initial Validation Loss: 0.1251, Validation Loss: 0.1251,V Acc: 0.4414, Top 70th Acc: 0.5385, Bottom 30th Acc: 0.2121
Fold [2/5] Epoch [10/100] Initial Loss: 0.1343, Training Loss: 0.0304, Initial Validation Loss: 0.1251, Validation Loss: 0.0379,V Acc: 0.7928, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.4545
Fold [2/5] Epoch [20/100] Initial Loss: 0.1343, Training Loss: 0.0200, Initial Validation Loss: 0.1251, Validation Loss: 0.0295,V Acc: 0.8198, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 27  Rolling back to Epoch (base 0): 22  Top Validation Acc: 0.9102564102564102
Fold [3/5] Epoch [0/100] Initial Loss: 0.1272, Training Loss: 0.1272, Initial Validation Loss: 0.1102, Validation Loss: 0.1102,V Acc: 0.4636, Top 70th Acc: 0.5974, Bottom 30th Acc: 0.1515
Fold [3/5] Epoch [10/100] Initial Loss: 0.1272, Training Loss: 0.0228, Initial Validation Loss: 0.1102, Validation Loss: 0.0332,V Acc: 0.8545, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 19  Rolling back to Epoch (base 0): 14  Top Validation Acc: 0.987012987012987
Fold [4/5] Epoch [0/100] Initial Loss: 0.1352, Training Loss: 0.1352, Initial Validation Loss: 0.1307, Validation Loss: 0.1307,V Acc: 0.2909, Top 70th Acc: 0.3506, Bottom 30th Acc: 0.1515
Fold [4/5] Epoch [10/100] Initial Loss: 0.1352, Training Loss: 0.0248, Initial Validation Loss: 0.1307, Validation Loss: 0.0277,V Acc: 0.8727, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 17  Rolling back to Epoch (base 0): 12  Top Validation Acc: 0.948051948051948
Fold [5/5] Epoch [0/100] Initial Loss: 0.1339, Training Loss: 0.1339, Initial Validation Loss: 0.1211, Validation Loss: 0.1211,V Acc: 0.4630, Top 70th Acc: 0.5921, Bottom 30th Acc: 0.1562
Fold [5/5] Epoch [10/100] Initial Loss: 0.1339, Training Loss: 0.0228, Initial Validation Loss: 0.1211, Validation Loss: 0.0340,V Acc: 0.8519, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.6250
Fold [5/5] Epoch [20/100] Initial Loss: 0.1339, Training Loss: 0.0163, Initial Validation Loss: 0.1211, Validation Loss: 0.0338,V Acc: 0.8519, Top 70th Acc: 0.9211, Bottom 30th Acc: 0.6875
Stopping early at Epoch (base 0): 22  Rolling back to Epoch (base 0): 17  Top Validation Acc: 0.9605263157894737
59 4 [array([0.67488134, 0.01944063, 0.03300304, 0.13477704, 0.13789795],
      dtype=float32)]
Running train_nn.py with seed 60
CUDA:False
Training samples count:  550
Training on 21 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1345, Training Loss: 0.1345, Initial Validation Loss: 0.1249, Validation Loss: 0.1249,V Acc: 0.4324, Top 70th Acc: 0.5513, Bottom 30th Acc: 0.1515
Fold [1/5] Epoch [10/100] Initial Loss: 0.1345, Training Loss: 0.0274, Initial Validation Loss: 0.1249, Validation Loss: 0.0312,V Acc: 0.8829, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.7273
Fold [1/5] Epoch [20/100] Initial Loss: 0.1345, Training Loss: 0.0164, Initial Validation Loss: 0.1249, Validation Loss: 0.0274,V Acc: 0.9009, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.7879
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.9487179487179487
Fold [2/5] Epoch [0/100] Initial Loss: 0.1350, Training Loss: 0.1350, Initial Validation Loss: 0.1303, Validation Loss: 0.1303,V Acc: 0.3423, Top 70th Acc: 0.4231, Bottom 30th Acc: 0.1515
Fold [2/5] Epoch [10/100] Initial Loss: 0.1350, Training Loss: 0.0239, Initial Validation Loss: 0.1303, Validation Loss: 0.0314,V Acc: 0.8559, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.6061
Fold [2/5] Epoch [20/100] Initial Loss: 0.1350, Training Loss: 0.0178, Initial Validation Loss: 0.1303, Validation Loss: 0.0275,V Acc: 0.8739, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.9743589743589743
Fold [3/5] Epoch [0/100] Initial Loss: 0.1316, Training Loss: 0.1316, Initial Validation Loss: 0.1134, Validation Loss: 0.1134,V Acc: 0.5727, Top 70th Acc: 0.7273, Bottom 30th Acc: 0.2121
Fold [3/5] Epoch [10/100] Initial Loss: 0.1316, Training Loss: 0.0201, Initial Validation Loss: 0.1134, Validation Loss: 0.0307,V Acc: 0.8909, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.7273
Fold [3/5] Epoch [20/100] Initial Loss: 0.1316, Training Loss: 0.0164, Initial Validation Loss: 0.1134, Validation Loss: 0.0331,V Acc: 0.8727, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 21  Rolling back to Epoch (base 0): 16  Top Validation Acc: 0.948051948051948
60 2 [array([0.8013749 , 0.02945272, 0.02622778, 0.05312711, 0.08981758],
      dtype=float32)]
Fold [4/5] Epoch [0/100] Initial Loss: 0.1341, Training Loss: 0.1341, Initial Validation Loss: 0.1220, Validation Loss: 0.1220,V Acc: 0.4273, Top 70th Acc: 0.4805, Bottom 30th Acc: 0.3030
Fold [4/5] Epoch [10/100] Initial Loss: 0.1341, Training Loss: 0.0250, Initial Validation Loss: 0.1220, Validation Loss: 0.0310,V Acc: 0.8273, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.5152
Stopping early at Epoch (base 0): 14  Rolling back to Epoch (base 0): 9  Top Validation Acc: 0.974025974025974
Fold [5/5] Epoch [0/100] Initial Loss: 0.1309, Training Loss: 0.1309, Initial Validation Loss: 0.1102, Validation Loss: 0.1102,V Acc: 0.5000, Top 70th Acc: 0.6053, Bottom 30th Acc: 0.2500
Fold [5/5] Epoch [10/100] Initial Loss: 0.1309, Training Loss: 0.0276, Initial Validation Loss: 0.1102, Validation Loss: 0.0298,V Acc: 0.8704, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.6875
Stopping early at Epoch (base 0): 19  Rolling back to Epoch (base 0): 14  Top Validation Acc: 0.9473684210526315
Running train_nn.py with seed 61
CUDA:False
Training samples count:  550
Training on 21 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1300, Training Loss: 0.1300, Initial Validation Loss: 0.1152, Validation Loss: 0.1152,V Acc: 0.4324, Top 70th Acc: 0.5513, Bottom 30th Acc: 0.1515
Stopping early at Epoch (base 0): 40  Rolling back to Epoch (base 0): 35  Top Validation Acc: 0.9358974358974359
Fold [3/5] Epoch [0/100] Initial Loss: 0.1388, Training Loss: 0.1388, Initial Validation Loss: 0.1344, Validation Loss: 0.1344,V Acc: 0.3727, Top 70th Acc: 0.4156, Bottom 30th Acc: 0.2727
Fold [3/5] Epoch [10/100] Initial Loss: 0.1388, Training Loss: 0.0293, Initial Validation Loss: 0.1344, Validation Loss: 0.0397,V Acc: 0.8273, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.6061
Fold [3/5] Epoch [20/100] Initial Loss: 0.1388, Training Loss: 0.0148, Initial Validation Loss: 0.1344, Validation Loss: 0.0298,V Acc: 0.8273, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.5152
Stopping early at Epoch (base 0): 29  Rolling back to Epoch (base 0): 24  Top Validation Acc: 0.948051948051948
Fold [4/5] Epoch [0/100] Initial Loss: 0.1408, Training Loss: 0.1408, Initial Validation Loss: 0.1352, Validation Loss: 0.1352,V Acc: 0.2909, Top 70th Acc: 0.2727, Bottom 30th Acc: 0.3333
Fold [4/5] Epoch [10/100] Initial Loss: 0.1408, Training Loss: 0.0430, Initial Validation Loss: 0.1352, Validation Loss: 0.0486,V Acc: 0.7636, Top 70th Acc: 0.8831, Bottom 30th Acc: 0.4848
Fold [4/5] Epoch [20/100] Initial Loss: 0.1408, Training Loss: 0.0155, Initial Validation Loss: 0.1352, Validation Loss: 0.0320,V Acc: 0.8364, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 27  Rolling back to Epoch (base 0): 22  Top Validation Acc: 0.948051948051948
Fold [5/5] Epoch [0/100] Initial Loss: 0.1395, Training Loss: 0.1395, Initial Validation Loss: 0.1314, Validation Loss: 0.1314,V Acc: 0.3519, Top 70th Acc: 0.3947, Bottom 30th Acc: 0.2500
Fold [5/5] Epoch [10/100] Initial Loss: 0.1395, Training Loss: 0.0307, Initial Validation Loss: 0.1314, Validation Loss: 0.0362,V Acc: 0.8704, Top 70th Acc: 0.9737, Bottom 30th Acc: 0.6250
Fold [5/5] Epoch [20/100] Initial Loss: 0.1395, Training Loss: 0.0155, Initial Validation Loss: 0.1314, Validation Loss: 0.0313,V Acc: 0.8241, Top 70th Acc: 0.9868, Bottom 30th Acc: 0.4375
Stopping early at Epoch (base 0): 27  Rolling back to Epoch (base 0): 22  Top Validation Acc: 0.9736842105263158
Running train_nn.py with seed 42
CUDA:False
Training samples count:  550
Training on 40 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1379, Training Loss: 0.1379, Initial Validation Loss: 0.1346, Validation Loss: 0.1346,V Acc: 0.2613, Top 70th Acc: 0.3333, Bottom 30th Acc: 0.0909
Fold [1/5] Epoch [10/100] Initial Loss: 0.1379, Training Loss: 0.0403, Initial Validation Loss: 0.1346, Validation Loss: 0.0496,V Acc: 0.7568, Top 70th Acc: 0.8846, Bottom 30th Acc: 0.4545
Fold [1/5] Epoch [20/100] Initial Loss: 0.1379, Training Loss: 0.0152, Initial Validation Loss: 0.1346, Validation Loss: 0.0357,V Acc: 0.8108, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.5152
Stopping early at Epoch (base 0): 22  Rolling back to Epoch (base 0): 17  Top Validation Acc: 0.9230769230769231
Fold [2/5] Epoch [0/100] Initial Loss: 0.1419, Training Loss: 0.1419, Initial Validation Loss: 0.1327, Validation Loss: 0.1327,V Acc: 0.3063, Top 70th Acc: 0.3205, Bottom 30th Acc: 0.2727
Fold [2/5] Epoch [10/100] Initial Loss: 0.1419, Training Loss: 0.0335, Initial Validation Loss: 0.1327, Validation Loss: 0.0450,V Acc: 0.7748, Top 70th Acc: 0.8718, Bottom 30th Acc: 0.5455
Fold [2/5] Epoch [20/100] Initial Loss: 0.1419, Training Loss: 0.0173, Initial Validation Loss: 0.1327, Validation Loss: 0.0398,V Acc: 0.7748, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.4545
Fold [2/5] Epoch [30/100] Initial Loss: 0.1419, Training Loss: 0.0132, Initial Validation Loss: 0.1327, Validation Loss: 0.0363,V Acc: 0.7477, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.3333
Fold [2/5] Epoch [40/100] Initial Loss: 0.1419, Training Loss: 0.0110, Initial Validation Loss: 0.1327, Validation Loss: 0.0350,V Acc: 0.7928, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.5152
Stopping early at Epoch (base 0): 46  Rolling back to Epoch (base 0): 41  Top Validation Acc: 0.9230769230769231
42 1 [array([0.35788247, 0.07931811, 0.14904806, 0.08767755, 0.32607386],
      dtype=float32)]
Fold [3/5] Epoch [0/100] Initial Loss: 0.1388, Training Loss: 0.1388, Initial Validation Loss: 0.1314, Validation Loss: 0.1314,V Acc: 0.3545, Top 70th Acc: 0.4156, Bottom 30th Acc: 0.2121
Fold [3/5] Epoch [10/100] Initial Loss: 0.1388, Training Loss: 0.0309, Initial Validation Loss: 0.1314, Validation Loss: 0.0356,V Acc: 0.8182, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.5152
Fold [3/5] Epoch [20/100] Initial Loss: 0.1388, Training Loss: 0.0163, Initial Validation Loss: 0.1314, Validation Loss: 0.0302,V Acc: 0.8091, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.4848
Fold [3/5] Epoch [30/100] Initial Loss: 0.1388, Training Loss: 0.0119, Initial Validation Loss: 0.1314, Validation Loss: 0.0295,V Acc: 0.8273, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.5152
Stopping early at Epoch (base 0): 30  Rolling back to Epoch (base 0): 25  Top Validation Acc: 0.961038961038961
Fold [4/5] Epoch [0/100] Initial Loss: 0.1423, Training Loss: 0.1423, Initial Validation Loss: 0.1394, Validation Loss: 0.1394,V Acc: 0.2545, Top 70th Acc: 0.2987, Bottom 30th Acc: 0.1515
Fold [4/5] Epoch [10/100] Initial Loss: 0.1423, Training Loss: 0.0373, Initial Validation Loss: 0.1394, Validation Loss: 0.0387,V Acc: 0.8091, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.5758
Fold [4/5] Epoch [20/100] Initial Loss: 0.1423, Training Loss: 0.0176, Initial Validation Loss: 0.1394, Validation Loss: 0.0302,V Acc: 0.8091, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.4545
Fold [4/5] Epoch [30/100] Initial Loss: 0.1423, Training Loss: 0.0131, Initial Validation Loss: 0.1394, Validation Loss: 0.0282,V Acc: 0.8091, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.4545
Stopping early at Epoch (base 0): 30  Rolling back to Epoch (base 0): 25  Top Validation Acc: 0.961038961038961
Fold [5/5] Epoch [0/100] Initial Loss: 0.1396, Training Loss: 0.1396, Initial Validation Loss: 0.1315, Validation Loss: 0.1315,V Acc: 0.3704, Top 70th Acc: 0.4211, Bottom 30th Acc: 0.2500
Fold [5/5] Epoch [10/100] Initial Loss: 0.1396, Training Loss: 0.0243, Initial Validation Loss: 0.1315, Validation Loss: 0.0334,V Acc: 0.8704, Top 70th Acc: 0.9737, Bottom 30th Acc: 0.6250
Fold [5/5] Epoch [20/100] Initial Loss: 0.1396, Training Loss: 0.0142, Initial Validation Loss: 0.1315, Validation Loss: 0.0286,V Acc: 0.8796, Top 70th Acc: 0.9868, Bottom 30th Acc: 0.6250
Stopping early at Epoch (base 0): 28  Rolling back to Epoch (base 0): 23  Top Validation Acc: 0.9868421052631579
Running train_nn.py with seed 43
CUDA:False
Training samples count:  550
Training on 40 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1425, Training Loss: 0.1425, Initial Validation Loss: 0.1316, Validation Loss: 0.1316,V Acc: 0.2613, Top 70th Acc: 0.3462, Bottom 30th Acc: 0.0606
Fold [1/5] Epoch [10/100] Initial Loss: 0.1425, Training Loss: 0.0328, Initial Validation Loss: 0.1316, Validation Loss: 0.0408,V Acc: 0.7477, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.3333
Fold [1/5] Epoch [20/100] Initial Loss: 0.1425, Training Loss: 0.0126, Initial Validation Loss: 0.1316, Validation Loss: 0.0340,V Acc: 0.8198, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.9102564102564102
Fold [2/5] Epoch [0/100] Initial Loss: 0.1415, Training Loss: 0.1415, Initial Validation Loss: 0.1323, Validation Loss: 0.1323,V Acc: 0.2973, Top 70th Acc: 0.3462, Bottom 30th Acc: 0.1818
Fold [2/5] Epoch [10/100] Initial Loss: 0.1415, Training Loss: 0.0222, Initial Validation Loss: 0.1323, Validation Loss: 0.0391,V Acc: 0.7928, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.5152
Fold [2/5] Epoch [20/100] Initial Loss: 0.1415, Training Loss: 0.0123, Initial Validation Loss: 0.1323, Validation Loss: 0.0366,V Acc: 0.7748, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.4242
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.9102564102564102
Fold [3/5] Epoch [0/100] Initial Loss: 0.1363, Training Loss: 0.1363, Initial Validation Loss: 0.1371, Validation Loss: 0.1371,V Acc: 0.2909, Top 70th Acc: 0.3506, Bottom 30th Acc: 0.1515
Fold [3/5] Epoch [10/100] Initial Loss: 0.1363, Training Loss: 0.0257, Initial Validation Loss: 0.1371, Validation Loss: 0.0271,V Acc: 0.9091, Top 70th Acc: 0.9870, Bottom 30th Acc: 0.7273
Stopping early at Epoch (base 0): 20  Rolling back to Epoch (base 0): 15  Top Validation Acc: 0.987012987012987
Fold [5/5] Epoch [0/100] Initial Loss: 0.1377, Training Loss: 0.1377, Initial Validation Loss: 0.1334, Validation Loss: 0.1334,V Acc: 0.2778, Top 70th Acc: 0.3158, Bottom 30th Acc: 0.1875
Fold [5/5] Epoch [10/100] Initial Loss: 0.1377, Training Loss: 0.0329, Initial Validation Loss: 0.1334, Validation Loss: 0.0351,V Acc: 0.8889, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.7812
Fold [5/5] Epoch [20/100] Initial Loss: 0.1377, Training Loss: 0.0168, Initial Validation Loss: 0.1334, Validation Loss: 0.0291,V Acc: 0.8704, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.6562
Stopping early at Epoch (base 0): 20  Rolling back to Epoch (base 0): 15  Top Validation Acc: 0.9605263157894737
Running train_nn.py with seed 43
CUDA:False
Training samples count:  550
Training on 30 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1391, Training Loss: 0.1391, Initial Validation Loss: 0.1323, Validation Loss: 0.1323,V Acc: 0.3153, Top 70th Acc: 0.2692, Bottom 30th Acc: 0.4242
Fold [1/5] Epoch [10/100] Initial Loss: 0.1391, Training Loss: 0.0411, Initial Validation Loss: 0.1323, Validation Loss: 0.0485,V Acc: 0.7297, Top 70th Acc: 0.8590, Bottom 30th Acc: 0.4242
Fold [1/5] Epoch [20/100] Initial Loss: 0.1391, Training Loss: 0.0158, Initial Validation Loss: 0.1323, Validation Loss: 0.0367,V Acc: 0.8108, Top 70th Acc: 0.8974, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.8974358974358975
Fold [2/5] Epoch [0/100] Initial Loss: 0.1373, Training Loss: 0.1373, Initial Validation Loss: 0.1293, Validation Loss: 0.1293,V Acc: 0.3694, Top 70th Acc: 0.4103, Bottom 30th Acc: 0.2727
Fold [2/5] Epoch [10/100] Initial Loss: 0.1373, Training Loss: 0.0312, Initial Validation Loss: 0.1293, Validation Loss: 0.0425,V Acc: 0.7748, Top 70th Acc: 0.8590, Bottom 30th Acc: 0.5758
Fold [2/5] Epoch [20/100] Initial Loss: 0.1373, Training Loss: 0.0161, Initial Validation Loss: 0.1293, Validation Loss: 0.0357,V Acc: 0.7928, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.5152
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.9102564102564102
Fold [3/5] Epoch [0/100] Initial Loss: 0.1387, Training Loss: 0.1387, Initial Validation Loss: 0.1388, Validation Loss: 0.1388,V Acc: 0.2545, Top 70th Acc: 0.3636, Bottom 30th Acc: 0.0000
Fold [3/5] Epoch [10/100] Initial Loss: 0.1387, Training Loss: 0.0407, Initial Validation Loss: 0.1388, Validation Loss: 0.0370,V Acc: 0.8818, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.6970
Fold [3/5] Epoch [20/100] Initial Loss: 0.1387, Training Loss: 0.0202, Initial Validation Loss: 0.1388, Validation Loss: 0.0216,V Acc: 0.9091, Top 70th Acc: 1.0000, Bottom 30th Acc: 0.6970
Fold [3/5] Epoch [30/100] Initial Loss: 0.1387, Training Loss: 0.0165, Initial Validation Loss: 0.1388, Validation Loss: 0.0210,V Acc: 0.8818, Top 70th Acc: 1.0000, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 31  Rolling back to Epoch (base 0): 26  Top Validation Acc: 1.0
43 2 [array([0.60932606, 0.05778153, 0.0399868 , 0.09062484, 0.2022808 ],
      dtype=float32)]
Fold [4/5] Epoch [0/100] Initial Loss: 0.1388, Training Loss: 0.1388, Initial Validation Loss: 0.1371, Validation Loss: 0.1371,V Acc: 0.2545, Top 70th Acc: 0.2727, Bottom 30th Acc: 0.2121
Fold [4/5] Epoch [10/100] Initial Loss: 0.1388, Training Loss: 0.0365, Initial Validation Loss: 0.1371, Validation Loss: 0.0428,V Acc: 0.8545, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.6970
Fold [4/5] Epoch [20/100] Initial Loss: 0.1388, Training Loss: 0.0186, Initial Validation Loss: 0.1371, Validation Loss: 0.0333,V Acc: 0.8545, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.6667
Fold [4/5] Epoch [30/100] Initial Loss: 0.1388, Training Loss: 0.0148, Initial Validation Loss: 0.1371, Validation Loss: 0.0312,V Acc: 0.8364, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 34  Rolling back to Epoch (base 0): 29  Top Validation Acc: 0.948051948051948
Fold [5/5] Epoch [0/100] Initial Loss: 0.1366, Training Loss: 0.1366, Initial Validation Loss: 0.1329, Validation Loss: 0.1329,V Acc: 0.4074, Top 70th Acc: 0.4605, Bottom 30th Acc: 0.2812
Fold [5/5] Epoch [10/100] Initial Loss: 0.1366, Training Loss: 0.0304, Initial Validation Loss: 0.1329, Validation Loss: 0.0311,V Acc: 0.8889, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.7500
Fold [5/5] Epoch [20/100] Initial Loss: 0.1366, Training Loss: 0.0183, Initial Validation Loss: 0.1329, Validation Loss: 0.0225,V Acc: 0.8889, Top 70th Acc: 0.9737, Bottom 30th Acc: 0.6875
Fold [5/5] Epoch [30/100] Initial Loss: 0.1366, Training Loss: 0.0159, Initial Validation Loss: 0.1329, Validation Loss: 0.0218,V Acc: 0.9074, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.7812
Stopping early at Epoch (base 0): 30  Rolling back to Epoch (base 0): 25  Top Validation Acc: 0.9605263157894737
Running train_nn.py with seed 44
CUDA:False
Training samples count:  550
Training on 30 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1366, Training Loss: 0.1366, Initial Validation Loss: 0.1317, Validation Loss: 0.1317,V Acc: 0.4685, Top 70th Acc: 0.5128, Bottom 30th Acc: 0.3636
Fold [1/5] Epoch [10/100] Initial Loss: 0.1366, Training Loss: 0.0274, Initial Validation Loss: 0.1317, Validation Loss: 0.0326,V Acc: 0.8378, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.5758
Fold [1/5] Epoch [20/100] Initial Loss: 0.1366, Training Loss: 0.0178, Initial Validation Loss: 0.1317, Validation Loss: 0.0307,V Acc: 0.8378, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 22  Rolling back to Epoch (base 0): 17  Top Validation Acc: 0.9487179487179487
Fold [2/5] Epoch [0/100] Initial Loss: 0.1392, Training Loss: 0.1392, Initial Validation Loss: 0.1359, Validation Loss: 0.1359,V Acc: 0.2613, Top 70th Acc: 0.3590, Bottom 30th Acc: 0.0303
Fold [2/5] Epoch [10/100] Initial Loss: 0.1392, Training Loss: 0.0379, Initial Validation Loss: 0.1359, Validation Loss: 0.0387,V Acc: 0.8468, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.6667
Fold [2/5] Epoch [20/100] Initial Loss: 0.1392, Training Loss: 0.0190, Initial Validation Loss: 0.1359, Validation Loss: 0.0297,V Acc: 0.8288, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.5152
Fold [2/5] Epoch [30/100] Initial Loss: 0.1392, Training Loss: 0.0163, Initial Validation Loss: 0.1359, Validation Loss: 0.0292,V Acc: 0.8378, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.5455
Fold [2/5] Epoch [40/100] Initial Loss: 0.1392, Training Loss: 0.0148, Initial Validation Loss: 0.1359, Validation Loss: 0.0285,V Acc: 0.8378, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.5152
Fold [2/5] Epoch [50/100] Initial Loss: 0.1392, Training Loss: 0.0142, Initial Validation Loss: 0.1359, Validation Loss: 0.0290,V Acc: 0.8288, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.4848
Fold [2/5] Epoch [60/100] Initial Loss: 0.1392, Training Loss: 0.0137, Initial Validation Loss: 0.1359, Validation Loss: 0.0285,V Acc: 0.8198, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.4545
Stopping early at Epoch (base 0): 61  Rolling back to Epoch (base 0): 56  Top Validation Acc: 0.9743589743589743
Fold [3/5] Epoch [0/100] Initial Loss: 0.1405, Training Loss: 0.1405, Initial Validation Loss: 0.1364, Validation Loss: 0.1364,V Acc: 0.2364, Top 70th Acc: 0.2338, Bottom 30th Acc: 0.2424
Fold [3/5] Epoch [10/100] Initial Loss: 0.1405, Training Loss: 0.0342, Initial Validation Loss: 0.1364, Validation Loss: 0.0422,V Acc: 0.8364, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.6061
Fold [3/5] Epoch [20/100] Initial Loss: 0.1405, Training Loss: 0.0186, Initial Validation Loss: 0.1364, Validation Loss: 0.0301,V Acc: 0.8909, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.7576
Fold [3/5] Epoch [30/100] Initial Loss: 0.1405, Training Loss: 0.0155, Initial Validation Loss: 0.1364, Validation Loss: 0.0284,V Acc: 0.8818, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.6970
Fold [3/5] Epoch [40/100] Initial Loss: 0.1405, Training Loss: 0.0145, Initial Validation Loss: 0.1364, Validation Loss: 0.0276,V Acc: 0.9182, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.8182
Stopping early at Epoch (base 0): 45  Rolling back to Epoch (base 0): 40  Top Validation Acc: 0.961038961038961/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)

Training on 163 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 90
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 163 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 91
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 163 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 92
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 163 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 93
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 163 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 94
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 163 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 95
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 163 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 96
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 163 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 97
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 163 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 98
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 163 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 99
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 163 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 100
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 163 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5

Fold [4/5] Epoch [30/100] Initial Loss: 0.1338, Training Loss: 0.0786, Initial Validation Loss: 0.1302, Validation Loss: 0.0722,V Acc: 0.7000, Top 70th Acc: 0.7922, Bottom 30th Acc: 0.4848
Stopping early at Epoch (base 0): 37  Rolling back to Epoch (base 0): 32  Top Validation Acc: 0.7662337662337663
Fold [5/5] Epoch [0/100] Initial Loss: 0.1366, Training Loss: 0.1366, Initial Validation Loss: 0.1296, Validation Loss: 0.1296,V Acc: 0.3148, Top 70th Acc: 0.3553, Bottom 30th Acc: 0.2188
Fold [5/5] Epoch [10/100] Initial Loss: 0.1366, Training Loss: 0.0796, Initial Validation Loss: 0.1296, Validation Loss: 0.0840,V Acc: 0.5833, Top 70th Acc: 0.7105, Bottom 30th Acc: 0.2812
Fold [5/5] Epoch [20/100] Initial Loss: 0.1366, Training Loss: 0.0770, Initial Validation Loss: 0.1296, Validation Loss: 0.0826,V Acc: 0.6019, Top 70th Acc: 0.7105, Bottom 30th Acc: 0.3438
Fold [5/5] Epoch [30/100] Initial Loss: 0.1366, Training Loss: 0.0764, Initial Validation Loss: 0.1296, Validation Loss: 0.0819,V Acc: 0.5833, Top 70th Acc: 0.7105, Bottom 30th Acc: 0.2812
Stopping early at Epoch (base 0): 32  Rolling back to Epoch (base 0): 27  Top Validation Acc: 0.6973684210526315
Running train_nn.py with seed 40
CUDA:False
Training samples count:  550
Training on 2 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1383, Training Loss: 0.1383, Initial Validation Loss: 0.1348, Validation Loss: 0.1348,V Acc: 0.3964, Top 70th Acc: 0.3974, Bottom 30th Acc: 0.3939
Fold [1/5] Epoch [10/100] Initial Loss: 0.1383, Training Loss: 0.0826, Initial Validation Loss: 0.1348, Validation Loss: 0.0775,V Acc: 0.6757, Top 70th Acc: 0.7949, Bottom 30th Acc: 0.3939
Fold [1/5] Epoch [20/100] Initial Loss: 0.1383, Training Loss: 0.0809, Initial Validation Loss: 0.1348, Validation Loss: 0.0752,V Acc: 0.6757, Top 70th Acc: 0.7692, Bottom 30th Acc: 0.4545
Stopping early at Epoch (base 0): 28  Rolling back to Epoch (base 0): 23  Top Validation Acc: 0.7692307692307693
Fold [2/5] Epoch [0/100] Initial Loss: 0.1367, Training Loss: 0.1367, Initial Validation Loss: 0.1291, Validation Loss: 0.1291,V Acc: 0.3063, Top 70th Acc: 0.3846, Bottom 30th Acc: 0.1212
Fold [2/5] Epoch [10/100] Initial Loss: 0.1367, Training Loss: 0.0824, Initial Validation Loss: 0.1291, Validation Loss: 0.0804,V Acc: 0.6396, Top 70th Acc: 0.7308, Bottom 30th Acc: 0.4242
Stopping early at Epoch (base 0): 18  Rolling back to Epoch (base 0): 13  Top Validation Acc: 0.717948717948718
40 1 [array([0.15548663, 0.35090113, 0.14541325, 0.20296231, 0.14523669],
      dtype=float32)]
Fold [3/5] Epoch [0/100] Initial Loss: 0.1351, Training Loss: 0.1351, Initial Validation Loss: 0.1289, Validation Loss: 0.1289,V Acc: 0.5091, Top 70th Acc: 0.5844, Bottom 30th Acc: 0.3333
Fold [3/5] Epoch [10/100] Initial Loss: 0.1351, Training Loss: 0.0806, Initial Validation Loss: 0.1289, Validation Loss: 0.0763,V Acc: 0.6455, Top 70th Acc: 0.7532, Bottom 30th Acc: 0.3939
Stopping early at Epoch (base 0): 15  Rolling back to Epoch (base 0): 10  Top Validation Acc: 0.7792207792207793
Fold [4/5] Epoch [0/100] Initial Loss: 0.1386, Training Loss: 0.1386, Initial Validation Loss: 0.1275, Validation Loss: 0.1275,V Acc: 0.4909, Top 70th Acc: 0.5844, Bottom 30th Acc: 0.2727
Fold [4/5] Epoch [10/100] Initial Loss: 0.1386, Training Loss: 0.0781, Initial Validation Loss: 0.1275, Validation Loss: 0.0878,V Acc: 0.5455, Top 70th Acc: 0.6753, Bottom 30th Acc: 0.2424
Stopping early at Epoch (base 0): 17  Rolling back to Epoch (base 0): 12  Top Validation Acc: 0.6883116883116883
Fold [5/5] Epoch [0/100] Initial Loss: 0.1342, Training Loss: 0.1342, Initial Validation Loss: 0.1221, Validation Loss: 0.1221,V Acc: 0.4167, Top 70th Acc: 0.4474, Bottom 30th Acc: 0.3438
Fold [5/5] Epoch [10/100] Initial Loss: 0.1342, Training Loss: 0.0809, Initial Validation Loss: 0.1221, Validation Loss: 0.0773,V Acc: 0.6204, Top 70th Acc: 0.7895, Bottom 30th Acc: 0.2188
Fold [5/5] Epoch [20/100] Initial Loss: 0.1342, Training Loss: 0.0796, Initial Validation Loss: 0.1221, Validation Loss: 0.0761,V Acc: 0.6296, Top 70th Acc: 0.7500, Bottom 30th Acc: 0.3438
Fold [5/5] Epoch [30/100] Initial Loss: 0.1342, Training Loss: 0.0789, Initial Validation Loss: 0.1221, Validation Loss: 0.0760,V Acc: 0.6296, Top 70th Acc: 0.7500, Bottom 30th Acc: 0.3438
Stopping early at Epoch (base 0): 33  Rolling back to Epoch (base 0): 28  Top Validation Acc: 0.7368421052631579
Running train_nn.py with seed 41
CUDA:False
Training samples count:  550
Training on 2 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1343, Training Loss: 0.1343, Initial Validation Loss: 0.1297, Validation Loss: 0.1297,V Acc: 0.4324, Top 70th Acc: 0.4487, Bottom 30th Acc: 0.3939
Fold [1/5] Epoch [10/100] Initial Loss: 0.1343, Training Loss: 0.0770, Initial Validation Loss: 0.1297, Validation Loss: 0.0943,V Acc: 0.5225, Top 70th Acc: 0.6667, Bottom 30th Acc: 0.1818
Fold [1/5] Epoch [20/100] Initial Loss: 0.1343, Training Loss: 0.0744, Initial Validation Loss: 0.1297, Validation Loss: 0.0950,V Acc: 0.5405, Top 70th Acc: 0.7051, Bottom 30th Acc: 0.1515
Stopping early at Epoch (base 0): 20  Rolling back to Epoch (base 0): 15  Top Validation Acc: 0.7051282051282052
41 0 [array([0.1706017 , 0.25653094, 0.15737182, 0.238233  , 0.17726257],
      dtype=float32)]
Fold [2/5] Epoch [0/100] Initial Loss: 0.1361, Training Loss: 0.1361, Initial Validation Loss: 0.1235, Validation Loss: 0.1235,V Acc: 0.4324, Top 70th Acc: 0.5385, Bottom 30th Acc: 0.1818
Fold [2/5] Epoch [10/100] Initial Loss: 0.1361, Training Loss: 0.0823, Initial Validation Loss: 0.1235, Validation Loss: 0.0773,V Acc: 0.6216, Top 70th Acc: 0.7051, Bottom 30th Acc: 0.4242
Fold [2/5] Epoch [20/100] Initial Loss: 0.1361, Training Loss: 0.0799, Initial Validation Loss: 0.1235, Validation Loss: 0.0756,V Acc: 0.6036, Top 70th Acc: 0.6923, Bottom 30th Acc: 0.3939
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.717948717948718
Fold [3/5] Epoch [0/100] Initial Loss: 0.1352, Training Loss: 0.1352, Initial Validation Loss: 0.1321, Validation Loss: 0.1321,V Acc: 0.3000, Top 70th Acc: 0.3766, Bottom 30th Acc: 0.1212
Fold [3/5] Epoch [10/100] Initial Loss: 0.1352, Training Loss: 0.0813, Initial Validation Loss: 0.1321, Validation Loss: 0.0808,V Acc: 0.6636, Top 70th Acc: 0.7922, Bottom 30th Acc: 0.3636
Fold [3/5] Epoch [20/100] Initial Loss: 0.1352, Training Loss: 0.0797, Initial Validation Loss: 0.1321, Validation Loss: 0.0786,V Acc: 0.6727, Top 70th Acc: 0.7792, Bottom 30th Acc: 0.4242
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.7922077922077922
Fold [4/5] Epoch [0/100] Initial Loss: 0.1366, Training Loss: 0.1366, Initial Validation Loss: 0.1314, Validation Loss: 0.1314,V Acc: 0.4182, Top 70th Acc: 0.4416, Bottom 30th Acc: 0.3636
Fold [4/5] Epoch [10/100] Initial Loss: 0.1366, Training Loss: 0.0828, Initial Validation Loss: 0.1314, Validation Loss: 0.0764,V Acc: 0.6636, Top 70th Acc: 0.7922, Bottom 30th Acc: 0.3636
Fold [4/5] Epoch [20/100] Initial Loss: 0.1366, Training Loss: 0.0806, Initial Validation Loss: 0.1314, Validation Loss: 0.0742,V Acc: 0.6727, Top 70th Acc: 0.8052, Bottom 30th Acc: 0.3636
Fold [4/5] Epoch [30/100] Initial Loss: 0.1366, Training Loss: 0.0803, Initial Validation Loss: 0.1314, Validation Loss: 0.0731,V Acc: 0.6727, Top 70th Acc: 0.7922, Bottom 30th Acc: 0.3939
Fold [4/5] Epoch [40/100] Initial Loss: 0.1366, Training Loss: 0.0797, Initial Validation Loss: 0.1314, Validation Loss: 0.0734,V Acc: 0.6909, Top 70th Acc: 0.7922, Bottom 30th Acc: 0.4545
Fold [4/5] Epoch [50/100] Initial Loss: 0.1366, Training Loss: 0.0799, Initial Validation Loss: 0.1314, Validation Loss: 0.0725,V Acc: 0.6818, Top 70th Acc: 0.8052, Bottom 30th Acc: 0.3939
Stopping early at Epoch (base 0): 59  Rolling back to Epoch (base 0): 54  Top Validation Acc: 0.8051948051948052
Fold [5/5] Epoch [0/100] Initial Loss: 0.1295, Training Loss: 0.1295, Initial Validation Loss: 0.1128, Validation Loss: 0.1128,V Acc: 0.5370, Top 70th Acc: 0.6184, Bottom 30th Acc: 0.3438
Fold [5/5] Epoch [10/100] Initial Loss: 0.1295, Training Loss: 0.0810, Initial Validation Loss: 0.1128, Validation Loss: 0.0785,V Acc: 0.6111, Top 70th Acc: 0.7237, Bottom 30th Acc: 0.3438 0.9736842105263158
Running train_nn.py with seed 43
CUDA:False
Training samples count:  550
Training on 20 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1373, Training Loss: 0.1373, Initial Validation Loss: 0.1270, Validation Loss: 0.1270,V Acc: 0.3784, Top 70th Acc: 0.4487, Bottom 30th Acc: 0.2121
Fold [1/5] Epoch [10/100] Initial Loss: 0.1373, Training Loss: 0.0314, Initial Validation Loss: 0.1270, Validation Loss: 0.0474,V Acc: 0.7477, Top 70th Acc: 0.8718, Bottom 30th Acc: 0.4545
Stopping early at Epoch (base 0): 13  Rolling back to Epoch (base 0): 8  Top Validation Acc: 0.8717948717948718
Fold [2/5] Epoch [0/100] Initial Loss: 0.1424, Training Loss: 0.1424, Initial Validation Loss: 0.1325, Validation Loss: 0.1325,V Acc: 0.3063, Top 70th Acc: 0.3077, Bottom 30th Acc: 0.3030
Fold [2/5] Epoch [10/100] Initial Loss: 0.1424, Training Loss: 0.0350, Initial Validation Loss: 0.1325, Validation Loss: 0.0460,V Acc: 0.7748, Top 70th Acc: 0.8846, Bottom 30th Acc: 0.5152
Fold [2/5] Epoch [20/100] Initial Loss: 0.1424, Training Loss: 0.0222, Initial Validation Loss: 0.1325, Validation Loss: 0.0408,V Acc: 0.7748, Top 70th Acc: 0.8590, Bottom 30th Acc: 0.5758
Fold [2/5] Epoch [30/100] Initial Loss: 0.1424, Training Loss: 0.0202, Initial Validation Loss: 0.1325, Validation Loss: 0.0399,V Acc: 0.7838, Top 70th Acc: 0.8846, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 31  Rolling back to Epoch (base 0): 26  Top Validation Acc: 0.9102564102564102
Fold [3/5] Epoch [0/100] Initial Loss: 0.1384, Training Loss: 0.1384, Initial Validation Loss: 0.1389, Validation Loss: 0.1389,V Acc: 0.3727, Top 70th Acc: 0.4545, Bottom 30th Acc: 0.1818
Fold [3/5] Epoch [10/100] Initial Loss: 0.1384, Training Loss: 0.0329, Initial Validation Loss: 0.1389, Validation Loss: 0.0301,V Acc: 0.9273, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.8788
Fold [3/5] Epoch [20/100] Initial Loss: 0.1384, Training Loss: 0.0249, Initial Validation Loss: 0.1389, Validation Loss: 0.0276,V Acc: 0.9182, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.8485
Stopping early at Epoch (base 0): 22  Rolling back to Epoch (base 0): 17  Top Validation Acc: 0.948051948051948
43 2 [array([0.46258107, 0.13598755, 0.15682846, 0.12215374, 0.12244922],
      dtype=float32)]
Fold [4/5] Epoch [0/100] Initial Loss: 0.1359, Training Loss: 0.1359, Initial Validation Loss: 0.1310, Validation Loss: 0.1310,V Acc: 0.3909, Top 70th Acc: 0.4675, Bottom 30th Acc: 0.2121
Fold [4/5] Epoch [10/100] Initial Loss: 0.1359, Training Loss: 0.0300, Initial Validation Loss: 0.1310, Validation Loss: 0.0415,V Acc: 0.8000, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.5455
Fold [4/5] Epoch [20/100] Initial Loss: 0.1359, Training Loss: 0.0235, Initial Validation Loss: 0.1310, Validation Loss: 0.0403,V Acc: 0.8000, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.5152
Stopping early at Epoch (base 0): 21  Rolling back to Epoch (base 0): 16  Top Validation Acc: 0.922077922077922
Fold [5/5] Epoch [0/100] Initial Loss: 0.1366, Training Loss: 0.1366, Initial Validation Loss: 0.1325, Validation Loss: 0.1325,V Acc: 0.4259, Top 70th Acc: 0.4079, Bottom 30th Acc: 0.4688
Fold [5/5] Epoch [10/100] Initial Loss: 0.1366, Training Loss: 0.0391, Initial Validation Loss: 0.1325, Validation Loss: 0.0393,V Acc: 0.8148, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.5312
Fold [5/5] Epoch [20/100] Initial Loss: 0.1366, Training Loss: 0.0263, Initial Validation Loss: 0.1325, Validation Loss: 0.0285,V Acc: 0.8889, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.7188
Fold [5/5] Epoch [30/100] Initial Loss: 0.1366, Training Loss: 0.0232, Initial Validation Loss: 0.1325, Validation Loss: 0.0267,V Acc: 0.8889, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.7188
Stopping early at Epoch (base 0): 37  Rolling back to Epoch (base 0): 32  Top Validation Acc: 0.9605263157894737
Running train_nn.py with seed 44
CUDA:False
Training samples count:  550
Training on 20 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1391, Training Loss: 0.1391, Initial Validation Loss: 0.1347, Validation Loss: 0.1347,V Acc: 0.3514, Top 70th Acc: 0.4615, Bottom 30th Acc: 0.0909
Fold [1/5] Epoch [10/100] Initial Loss: 0.1391, Training Loss: 0.0464, Initial Validation Loss: 0.1347, Validation Loss: 0.0445,V Acc: 0.8108, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.5758
Fold [1/5] Epoch [20/100] Initial Loss: 0.1391, Training Loss: 0.0246, Initial Validation Loss: 0.1347, Validation Loss: 0.0311,V Acc: 0.8649, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.6970
Fold [1/5] Epoch [30/100] Initial Loss: 0.1391, Training Loss: 0.0208, Initial Validation Loss: 0.1347, Validation Loss: 0.0293,V Acc: 0.8739, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 38  Rolling back to Epoch (base 0): 33  Top Validation Acc: 0.9615384615384616
Fold [2/5] Epoch [0/100] Initial Loss: 0.1388, Training Loss: 0.1388, Initial Validation Loss: 0.1346, Validation Loss: 0.1346,V Acc: 0.3964, Top 70th Acc: 0.4231, Bottom 30th Acc: 0.3333
Fold [2/5] Epoch [10/100] Initial Loss: 0.1388, Training Loss: 0.0474, Initial Validation Loss: 0.1346, Validation Loss: 0.0491,V Acc: 0.7477, Top 70th Acc: 0.8718, Bottom 30th Acc: 0.4545
Fold [2/5] Epoch [20/100] Initial Loss: 0.1388, Training Loss: 0.0255, Initial Validation Loss: 0.1346, Validation Loss: 0.0338,V Acc: 0.8198, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.9358974358974359
Fold [3/5] Epoch [0/100] Initial Loss: 0.1403, Training Loss: 0.1403, Initial Validation Loss: 0.1331, Validation Loss: 0.1331,V Acc: 0.3091, Top 70th Acc: 0.4156, Bottom 30th Acc: 0.0606
Fold [3/5] Epoch [10/100] Initial Loss: 0.1403, Training Loss: 0.0418, Initial Validation Loss: 0.1331, Validation Loss: 0.0510,V Acc: 0.7727, Top 70th Acc: 0.8701, Bottom 30th Acc: 0.5455
Fold [3/5] Epoch [20/100] Initial Loss: 0.1403, Training Loss: 0.0236, Initial Validation Loss: 0.1331, Validation Loss: 0.0356,V Acc: 0.8636, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.6970
Fold [3/5] Epoch [30/100] Initial Loss: 0.1403, Training Loss: 0.0204, Initial Validation Loss: 0.1331, Validation Loss: 0.0340,V Acc: 0.8636, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.7576
Stopping early at Epoch (base 0): 30  Rolling back to Epoch (base 0): 25  Top Validation Acc: 0.9090909090909091
44 2 [array([0.52281636, 0.08508671, 0.06584521, 0.20436159, 0.12189013],
      dtype=float32)]
Fold [4/5] Epoch [0/100] Initial Loss: 0.1382, Training Loss: 0.1382, Initial Validation Loss: 0.1322, Validation Loss: 0.1322,V Acc: 0.2636, Top 70th Acc: 0.3636, Bottom 30th Acc: 0.0303
Fold [4/5] Epoch [10/100] Initial Loss: 0.1382, Training Loss: 0.0388, Initial Validation Loss: 0.1322, Validation Loss: 0.0403,V Acc: 0.8091, Top 70th Acc: 0.8961, Bottom 30th Acc: 0.6061
Fold [4/5] Epoch [20/100] Initial Loss: 0.1382, Training Loss: 0.0268, Initial Validation Loss: 0.1322, Validation Loss: 0.0282,V Acc: 0.8818, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.6970
Fold [4/5] Epoch [30/100] Initial Loss: 0.1382, Training Loss: 0.0232, Initial Validation Loss: 0.1322, Validation Loss: 0.0261,V Acc: 0.8364, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 35  Rolling back to Epoch (base 0): 30  Top Validation Acc: 0.974025974025974
Fold [5/5] Epoch [0/100] Initial Loss: 0.1358, Training Loss: 0.1358, Initial Validation Loss: 0.1286, Validation Loss: 0.1286,V Acc: 0.3704, Top 70th Acc: 0.3947, Bottom 30th Acc: 0.3125
Fold [5/5] Epoch [10/100] Initial Loss: 0.1358, Training Loss: 0.0383, Initial Validation Loss: 0.1286, Validation Loss: 0.0429,V Acc: 0.7963, Top 70th Acc: 0.9079, Bottom 30th Acc: 0.5312
Fold [5/5] Epoch [20/100] Initial Loss: 0.1358, Training Loss: 0.0227, Initial Validation Loss: 0.1286, Validation Loss: 0.0366,V Acc: 0.8056, Top 70th Acc: 0.9211, Bottom 30th Acc: 0.5312
Fold [5/5] Epoch [30/100] Initial Loss: 0.1358, Training Loss: 0.0210, Initial Validation Loss: 0.1286, Validation Loss: 0.0368,V Acc: 0.7963, Top 70th Acc: 0.9079, Bottom 30th Acc: 0.5312
Stopping early at Epoch (base 0): 32  Rolling back to Epoch (base 0): 27  Top Validation Acc: 0.9078947368421053
Running train_nn.py with seed 45
CUDA:False
Training samples count: 
Fold [4/5] Epoch [10/100] Initial Loss: 0.1424, Training Loss: 0.0212, Initial Validation Loss: 0.1303, Validation Loss: 0.0354,V Acc: 0.8091, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.5152
Fold [4/5] Epoch [20/100] Initial Loss: 0.1424, Training Loss: 0.0049, Initial Validation Loss: 0.1303, Validation Loss: 0.0302,V Acc: 0.8364, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.948051948051948
Fold [5/5] Epoch [0/100] Initial Loss: 0.1372, Training Loss: 0.1372, Initial Validation Loss: 0.1334, Validation Loss: 0.1334,V Acc: 0.2963, Top 70th Acc: 0.3553, Bottom 30th Acc: 0.1562
Fold [5/5] Epoch [10/100] Initial Loss: 0.1372, Training Loss: 0.0163, Initial Validation Loss: 0.1334, Validation Loss: 0.0367,V Acc: 0.8426, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.6250
Fold [5/5] Epoch [20/100] Initial Loss: 0.1372, Training Loss: 0.0048, Initial Validation Loss: 0.1334, Validation Loss: 0.0308,V Acc: 0.8333, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.5312
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.9473684210526315
Running train_nn.py with seed 34
CUDA:False
Training samples count:  550
Training on 163 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1391, Training Loss: 0.1391, Initial Validation Loss: 0.1317, Validation Loss: 0.1317,V Acc: 0.3604, Top 70th Acc: 0.4487, Bottom 30th Acc: 0.1515
Fold [1/5] Epoch [10/100] Initial Loss: 0.1391, Training Loss: 0.0169, Initial Validation Loss: 0.1317, Validation Loss: 0.0325,V Acc: 0.8108, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.5152
Fold [1/5] Epoch [20/100] Initial Loss: 0.1391, Training Loss: 0.0060, Initial Validation Loss: 0.1317, Validation Loss: 0.0268,V Acc: 0.8288, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.5758
Fold [1/5] Epoch [30/100] Initial Loss: 0.1391, Training Loss: 0.0045, Initial Validation Loss: 0.1317, Validation Loss: 0.0255,V Acc: 0.8288, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.5152
Fold [1/5] Epoch [40/100] Initial Loss: 0.1391, Training Loss: 0.0041, Initial Validation Loss: 0.1317, Validation Loss: 0.0235,V Acc: 0.8288, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.5152
Stopping early at Epoch (base 0): 49  Rolling back to Epoch (base 0): 44  Top Validation Acc: 0.9615384615384616
Fold [2/5] Epoch [0/100] Initial Loss: 0.1368, Training Loss: 0.1368, Initial Validation Loss: 0.1334, Validation Loss: 0.1334,V Acc: 0.4054, Top 70th Acc: 0.4872, Bottom 30th Acc: 0.2121
Fold [2/5] Epoch [10/100] Initial Loss: 0.1368, Training Loss: 0.0136, Initial Validation Loss: 0.1334, Validation Loss: 0.0368,V Acc: 0.8649, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.6667
Fold [2/5] Epoch [20/100] Initial Loss: 0.1368, Training Loss: 0.0045, Initial Validation Loss: 0.1334, Validation Loss: 0.0305,V Acc: 0.8468, Top 70th Acc: 0.9872, Bottom 30th Acc: 0.5152
Fold [2/5] Epoch [30/100] Initial Loss: 0.1368, Training Loss: 0.0038, Initial Validation Loss: 0.1334, Validation Loss: 0.0292,V Acc: 0.8468, Top 70th Acc: 0.9872, Bottom 30th Acc: 0.5152
Fold [2/5] Epoch [40/100] Initial Loss: 0.1368, Training Loss: 0.0036, Initial Validation Loss: 0.1334, Validation Loss: 0.0290,V Acc: 0.8378, Top 70th Acc: 0.9872, Bottom 30th Acc: 0.4848
Stopping early at Epoch (base 0): 44  Rolling back to Epoch (base 0): 39  Top Validation Acc: 0.9871794871794872
34 1 [array([0.35471234, 0.07714019, 0.08250583, 0.1944972 , 0.29114443],
      dtype=float32)]
Fold [3/5] Epoch [0/100] Initial Loss: 0.1379, Training Loss: 0.1379, Initial Validation Loss: 0.1370, Validation Loss: 0.1370,V Acc: 0.2545, Top 70th Acc: 0.3247, Bottom 30th Acc: 0.0909
Fold [3/5] Epoch [10/100] Initial Loss: 0.1379, Training Loss: 0.0389, Initial Validation Loss: 0.1370, Validation Loss: 0.0546,V Acc: 0.7091, Top 70th Acc: 0.8571, Bottom 30th Acc: 0.3636
Fold [3/5] Epoch [20/100] Initial Loss: 0.1379, Training Loss: 0.0072, Initial Validation Loss: 0.1370, Validation Loss: 0.0362,V Acc: 0.8182, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.6061
Fold [3/5] Epoch [30/100] Initial Loss: 0.1379, Training Loss: 0.0045, Initial Validation Loss: 0.1370, Validation Loss: 0.0336,V Acc: 0.8273, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.6061
Fold [3/5] Epoch [40/100] Initial Loss: 0.1379, Training Loss: 0.0040, Initial Validation Loss: 0.1370, Validation Loss: 0.0322,V Acc: 0.8273, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 47  Rolling back to Epoch (base 0): 42  Top Validation Acc: 0.935064935064935
Fold [4/5] Epoch [0/100] Initial Loss: 0.1396, Training Loss: 0.1396, Initial Validation Loss: 0.1352, Validation Loss: 0.1352,V Acc: 0.3091, Top 70th Acc: 0.4026, Bottom 30th Acc: 0.0909
Fold [4/5] Epoch [10/100] Initial Loss: 0.1396, Training Loss: 0.0146, Initial Validation Loss: 0.1352, Validation Loss: 0.0367,V Acc: 0.8364, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.5152
Fold [4/5] Epoch [20/100] Initial Loss: 0.1396, Training Loss: 0.0046, Initial Validation Loss: 0.1352, Validation Loss: 0.0303,V Acc: 0.8455, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 28  Rolling back to Epoch (base 0): 23  Top Validation Acc: 0.974025974025974
Fold [5/5] Epoch [0/100] Initial Loss: 0.1395, Training Loss: 0.1395, Initial Validation Loss: 0.1313, Validation Loss: 0.1313,V Acc: 0.2593, Top 70th Acc: 0.3421, Bottom 30th Acc: 0.0625
Fold [5/5] Epoch [10/100] Initial Loss: 0.1395, Training Loss: 0.0171, Initial Validation Loss: 0.1313, Validation Loss: 0.0349,V Acc: 0.8519, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.5938
Fold [5/5] Epoch [20/100] Initial Loss: 0.1395, Training Loss: 0.0045, Initial Validation Loss: 0.1313, Validation Loss: 0.0268,V Acc: 0.8704, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.6562
Stopping early at Epoch (base 0): 21  Rolling back to Epoch (base 0): 16  Top Validation Acc: 0.9605263157894737
Running train_nn.py with seed 35
CUDA:False
Training samples count:  550
Training on 163 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1380, Training Loss: 0.1380, Initial Validation Loss: 0.1369, Validation Loss: 0.1369,V Acc: 0.2523, Top 70th Acc: 0.3333, Bottom 30th Acc: 0.0606
Fold [1/5] Epoch [10/100] Initial Loss: 0.1380, Training Loss: 0.0245, Initial Validation Loss: 0.1369, Validation Loss: 0.0453,V Acc: 0.7928, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.5152
Fold [1/5] Epoch [20/100] Initial Loss: 0.1380, Training Loss: 0.0061, Initial Validation Loss: 0.1369, Validation Loss: 0.0412,V Acc: 0.7748, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.4545
Stopping early at Epoch (base 0): 21  Rolling back to Epoch (base 0): 16  Top Validation Acc: 0.9102564102564102
Fold [2/5] Epoch [0/100] Initial Loss: 0.1379, Training Loss: 0.1379, Initial Validation Loss: 0.1364, Validation Loss: 0.1364,V Acc: 0.2523, Top 70th Acc: 0.3462, Bottom 30th Acc: 0.0303
Fold [2/5] Epoch [10/100] Initial Loss: 0.1379, Training Loss: 0.0196, Initial Validation Loss: 0.1364, Validation Loss: 0.0430,V Acc: 0.7928, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.4545
Stopping early at Epoch (base 0): 19  Rolling back to Epoch (base 0): 14  Top Validation Acc: 0.9230769230769231
Fold [3/5] Epoch [0/100] Initial Loss: 0.1380, Training Loss: 0.1380, Initial Validation Loss: 0.1365, Validation Loss: 0.1365,V Acc: 0.3455, Top 70th Acc: 0.4286, Bottom 30th Acc: 0.1515
Fold [3/5] Epoch [10/100] Initial Loss: 0.1380, Training Loss: 0.0304, Initial Validation Loss: 0.1365, Validation Loss: 0.0387,V Acc: 0.7636, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.3636
Fold [3/5] Epoch [20/100] Initial Loss: 0.1380, Training Loss: 0.0058, Initial Validation Loss: 0.1365, Validation Loss: 0.0218,V Acc: 0.9000, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.7273
Fold [3/5] Epoch [30/100] Initial Loss: 0.1380, Training Loss: 0.0042, Initial Validation Loss: 0.1365, Validation Loss: 0.0212,V Acc: 0.9091, Top 70th Acc: 0.9870, Bottom 30th Acc: 0.7273
Stopping early at Epoch (base 0): 38  Rolling back to Epoch (base 0): 33  Top Validation Acc: 0.974025974025974
Fold [4/5] Epoch [0/100] Initial Loss: 0.1382, Training Loss: 0.1382, Initial Validation Loss: 0.1334, Validation Loss: 0.1334,V Acc: 0.2545, Top 70th Acc: 0.2987, Bottom 30th Acc: 0.1515
Fold [1/5] Epoch [10/100] Initial Loss: 0.1300, Training Loss: 0.0238, Initial Validation Loss: 0.1152, Validation Loss: 0.0321,V Acc: 0.8468, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 17  Rolling back to Epoch (base 0): 12  Top Validation Acc: 0.9487179487179487
Fold [2/5] Epoch [0/100] Initial Loss: 0.1415, Training Loss: 0.1415, Initial Validation Loss: 0.1327, Validation Loss: 0.1327,V Acc: 0.2793, Top 70th Acc: 0.3590, Bottom 30th Acc: 0.0909
Fold [2/5] Epoch [10/100] Initial Loss: 0.1415, Training Loss: 0.0224, Initial Validation Loss: 0.1327, Validation Loss: 0.0433,V Acc: 0.8378, Top 70th Acc: 0.8974, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 14  Rolling back to Epoch (base 0): 9  Top Validation Acc: 0.9230769230769231
Fold [3/5] Epoch [0/100] Initial Loss: 0.1322, Training Loss: 0.1322, Initial Validation Loss: 0.1172, Validation Loss: 0.1172,V Acc: 0.5545, Top 70th Acc: 0.6753, Bottom 30th Acc: 0.2727
Fold [3/5] Epoch [10/100] Initial Loss: 0.1322, Training Loss: 0.0281, Initial Validation Loss: 0.1172, Validation Loss: 0.0337,V Acc: 0.8273, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.5455
Fold [3/5] Epoch [20/100] Initial Loss: 0.1322, Training Loss: 0.0207, Initial Validation Loss: 0.1172, Validation Loss: 0.0266,V Acc: 0.8818, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.922077922077922
Fold [4/5] Epoch [0/100] Initial Loss: 0.1335, Training Loss: 0.1335, Initial Validation Loss: 0.1230, Validation Loss: 0.1230,V Acc: 0.4455, Top 70th Acc: 0.5065, Bottom 30th Acc: 0.3030
Fold [4/5] Epoch [10/100] Initial Loss: 0.1335, Training Loss: 0.0263, Initial Validation Loss: 0.1230, Validation Loss: 0.0243,V Acc: 0.9000, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.7273
Fold [4/5] Epoch [20/100] Initial Loss: 0.1335, Training Loss: 0.0191, Initial Validation Loss: 0.1230, Validation Loss: 0.0214,V Acc: 0.9000, Top 70th Acc: 0.9870, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 28  Rolling back to Epoch (base 0): 23  Top Validation Acc: 1.0
Fold [5/5] Epoch [0/100] Initial Loss: 0.1354, Training Loss: 0.1354, Initial Validation Loss: 0.1162, Validation Loss: 0.1162,V Acc: 0.5370, Top 70th Acc: 0.6316, Bottom 30th Acc: 0.3125
Fold [5/5] Epoch [10/100] Initial Loss: 0.1354, Training Loss: 0.0255, Initial Validation Loss: 0.1162, Validation Loss: 0.0282,V Acc: 0.8241, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.5625
Stopping early at Epoch (base 0): 17  Rolling back to Epoch (base 0): 12  Top Validation Acc: 0.9210526315789473
61 4 [array([0.5034506 , 0.03219055, 0.04472853, 0.16966492, 0.24996547],
      dtype=float32)]
Running train_nn.py with seed 62
CUDA:False
Training samples count:  550
Training on 21 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1269, Training Loss: 0.1269, Initial Validation Loss: 0.1174, Validation Loss: 0.1174,V Acc: 0.4324, Top 70th Acc: 0.5256, Bottom 30th Acc: 0.2121
Fold [1/5] Epoch [10/100] Initial Loss: 0.1269, Training Loss: 0.0275, Initial Validation Loss: 0.1174, Validation Loss: 0.0348,V Acc: 0.8649, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.7273
Fold [1/5] Epoch [20/100] Initial Loss: 0.1269, Training Loss: 0.0193, Initial Validation Loss: 0.1174, Validation Loss: 0.0305,V Acc: 0.8288, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.4848
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.9615384615384616
Fold [2/5] Epoch [0/100] Initial Loss: 0.1326, Training Loss: 0.1326, Initial Validation Loss: 0.1197, Validation Loss: 0.1197,V Acc: 0.4505, Top 70th Acc: 0.5513, Bottom 30th Acc: 0.2121
Fold [2/5] Epoch [10/100] Initial Loss: 0.1326, Training Loss: 0.0242, Initial Validation Loss: 0.1197, Validation Loss: 0.0332,V Acc: 0.8468, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.6364
Fold [2/5] Epoch [20/100] Initial Loss: 0.1326, Training Loss: 0.0173, Initial Validation Loss: 0.1197, Validation Loss: 0.0357,V Acc: 0.8108, Top 70th Acc: 0.8974, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 20  Rolling back to Epoch (base 0): 15  Top Validation Acc: 0.8974358974358975
62 1 [array([0.61163664, 0.0478096 , 0.05046514, 0.17425704, 0.11583162],
      dtype=float32)]
Fold [3/5] Epoch [0/100] Initial Loss: 0.1300, Training Loss: 0.1300, Initial Validation Loss: 0.1230, Validation Loss: 0.1230,V Acc: 0.4545, Top 70th Acc: 0.5974, Bottom 30th Acc: 0.1212
Fold [3/5] Epoch [10/100] Initial Loss: 0.1300, Training Loss: 0.0259, Initial Validation Loss: 0.1230, Validation Loss: 0.0323,V Acc: 0.8727, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6970
Fold [3/5] Epoch [20/100] Initial Loss: 0.1300, Training Loss: 0.0188, Initial Validation Loss: 0.1230, Validation Loss: 0.0277,V Acc: 0.8636, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 20  Rolling back to Epoch (base 0): 15  Top Validation Acc: 0.974025974025974
Fold [4/5] Epoch [0/100] Initial Loss: 0.1396, Training Loss: 0.1396, Initial Validation Loss: 0.1294, Validation Loss: 0.1294,V Acc: 0.3636, Top 70th Acc: 0.3896, Bottom 30th Acc: 0.3030
Fold [4/5] Epoch [10/100] Initial Loss: 0.1396, Training Loss: 0.0257, Initial Validation Loss: 0.1294, Validation Loss: 0.0389,V Acc: 0.8091, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 18  Rolling back to Epoch (base 0): 13  Top Validation Acc: 0.922077922077922
Fold [5/5] Epoch [0/100] Initial Loss: 0.1312, Training Loss: 0.1312, Initial Validation Loss: 0.1171, Validation Loss: 0.1171,V Acc: 0.5000, Top 70th Acc: 0.5921, Bottom 30th Acc: 0.2812
Fold [5/5] Epoch [10/100] Initial Loss: 0.1312, Training Loss: 0.0298, Initial Validation Loss: 0.1171, Validation Loss: 0.0293,V Acc: 0.8889, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.7500
Fold [5/5] Epoch [20/100] Initial Loss: 0.1312, Training Loss: 0.0199, Initial Validation Loss: 0.1171, Validation Loss: 0.0254,V Acc: 0.8796, Top 70th Acc: 0.9737, Bottom 30th Acc: 0.6562
Stopping early at Epoch (base 0): 28  Rolling back to Epoch (base 0): 23  Top Validation Acc: 0.9868421052631579
Running train_nn.py with seed 63
CUDA:False
Training samples count:  550
Training on 21 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1351, Training Loss: 0.1351, Initial Validation Loss: 0.1299, Validation Loss: 0.1299,V Acc: 0.4595, Top 70th Acc: 0.6154, Bottom 30th Acc: 0.0909
Fold [1/5] Epoch [10/100] Initial Loss: 0.1351, Training Loss: 0.0297, Initial Validation Loss: 0.1299, Validation Loss: 0.0261,V Acc: 0.8919, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.7273
Fold [1/5] Epoch [20/100] Initial Loss: 0.1351, Training Loss: 0.0213, Initial Validation Loss: 0.1299, Validation Loss: 0.0147,V Acc: 0.9459, Top 70th Acc: 1.0000, Bottom 30th Acc: 0.8182
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.9871794871794872
Fold [2/5] Epoch [0/100] Initial Loss: 0.1421, Training Loss: 0.1421, Initial Validation Loss: 0.1322, Validation Loss: 0.1322,V Acc: 0.2523, Top 70th Acc: 0.2821, Bottom 30th Acc: 0.1818
Fold [2/5] Epoch [10/100] Initial Loss: 0.1421, Training Loss: 0.0286, Initial Validation Loss: 0.1322, Validation Loss: 0.0325,V Acc: 0.7928, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.4848
Fold [2/5] Epoch [20/100] Initial Loss: 0.1421, Training Loss: 0.0178, Initial Validation Loss: 0.1322, Validation Loss: 0.0269,V Acc: 0.8559, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.9487179487179487
Fold [3/5] Epoch [0/100] Initial Loss: 0.1352, Training Loss: 0.1352, Initial Validation Loss: 0.1247, Validation Loss: 0.1247,V Acc: 0.5636, Top 70th Acc: 0.7273, Bottom 30th Acc: 0.1818
Fold [3/5] Epoch [10/100] Initial Loss: 0.1352, Training Loss: 0.0237, Initial Validation Loss: 0.1247, Validation Loss: 0.0258,V Acc: 0.9091, Top 70th Acc: 0.9870, Bottom 30th Acc: 0.7273
Stopping early at Epoch (base 0): 15  Rolling back to Epoch (base 0): 10  Top Validation Acc: 0.961038961038961
63 2 [array([0.71290594, 0.02257737, 0.05345741, 0.1631355 , 0.0479237 ],
      dtype=float32)]
Fold [4/5] Epoch [0/100] Initial Loss: 0.1296, Training Loss: 0.1296, Initial Validation Loss: 0.1161, Validation Loss: 0.1161,V Acc: 0.5273, Top 70th Acc: 0.6234, Bottom 30th Acc: 0.3030
Fold [3/5] Epoch [20/100] Initial Loss: 0.1363, Training Loss: 0.0150, Initial Validation Loss: 0.1371, Validation Loss: 0.0214,V Acc: 0.9273, Top 70th Acc: 0.9870, Bottom 30th Acc: 0.7879
Fold [3/5] Epoch [30/100] Initial Loss: 0.1363, Training Loss: 0.0124, Initial Validation Loss: 0.1371, Validation Loss: 0.0215,V Acc: 0.9182, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.7879
Stopping early at Epoch (base 0): 33  Rolling back to Epoch (base 0): 28  Top Validation Acc: 0.987012987012987
43 2 [array([0.56486636, 0.06552194, 0.11675209, 0.09298488, 0.15987465],
      dtype=float32)]
Fold [4/5] Epoch [0/100] Initial Loss: 0.1389, Training Loss: 0.1389, Initial Validation Loss: 0.1364, Validation Loss: 0.1364,V Acc: 0.3273, Top 70th Acc: 0.3896, Bottom 30th Acc: 0.1818
Fold [4/5] Epoch [10/100] Initial Loss: 0.1389, Training Loss: 0.0245, Initial Validation Loss: 0.1364, Validation Loss: 0.0411,V Acc: 0.7727, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.4545
Fold [4/5] Epoch [20/100] Initial Loss: 0.1389, Training Loss: 0.0133, Initial Validation Loss: 0.1364, Validation Loss: 0.0345,V Acc: 0.8000, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.4848
Stopping early at Epoch (base 0): 29  Rolling back to Epoch (base 0): 24  Top Validation Acc: 0.935064935064935
Fold [5/5] Epoch [0/100] Initial Loss: 0.1356, Training Loss: 0.1356, Initial Validation Loss: 0.1336, Validation Loss: 0.1336,V Acc: 0.2500, Top 70th Acc: 0.3553, Bottom 30th Acc: 0.0000
Fold [5/5] Epoch [10/100] Initial Loss: 0.1356, Training Loss: 0.0322, Initial Validation Loss: 0.1336, Validation Loss: 0.0341,V Acc: 0.8704, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.6875
Fold [5/5] Epoch [20/100] Initial Loss: 0.1356, Training Loss: 0.0150, Initial Validation Loss: 0.1336, Validation Loss: 0.0247,V Acc: 0.8611, Top 70th Acc: 0.9868, Bottom 30th Acc: 0.5625
Stopping early at Epoch (base 0): 28  Rolling back to Epoch (base 0): 23  Top Validation Acc: 0.9736842105263158
Running train_nn.py with seed 44
CUDA:False
Training samples count:  550
Training on 40 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1382, Training Loss: 0.1382, Initial Validation Loss: 0.1332, Validation Loss: 0.1332,V Acc: 0.3243, Top 70th Acc: 0.4103, Bottom 30th Acc: 0.1212
Fold [1/5] Epoch [10/100] Initial Loss: 0.1382, Training Loss: 0.0235, Initial Validation Loss: 0.1332, Validation Loss: 0.0337,V Acc: 0.8378, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.5758
Fold [1/5] Epoch [20/100] Initial Loss: 0.1382, Training Loss: 0.0131, Initial Validation Loss: 0.1332, Validation Loss: 0.0308,V Acc: 0.8559, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.9615384615384616
Fold [2/5] Epoch [0/100] Initial Loss: 0.1392, Training Loss: 0.1392, Initial Validation Loss: 0.1353, Validation Loss: 0.1353,V Acc: 0.3063, Top 70th Acc: 0.3462, Bottom 30th Acc: 0.2121
Fold [2/5] Epoch [10/100] Initial Loss: 0.1392, Training Loss: 0.0410, Initial Validation Loss: 0.1353, Validation Loss: 0.0459,V Acc: 0.7568, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.3636
Fold [2/5] Epoch [20/100] Initial Loss: 0.1392, Training Loss: 0.0182, Initial Validation Loss: 0.1353, Validation Loss: 0.0294,V Acc: 0.8378, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.5758
Fold [2/5] Epoch [30/100] Initial Loss: 0.1392, Training Loss: 0.0122, Initial Validation Loss: 0.1353, Validation Loss: 0.0281,V Acc: 0.8468, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 37  Rolling back to Epoch (base 0): 32  Top Validation Acc: 0.9230769230769231
Fold [3/5] Epoch [0/100] Initial Loss: 0.1387, Training Loss: 0.1387, Initial Validation Loss: 0.1355, Validation Loss: 0.1355,V Acc: 0.3636, Top 70th Acc: 0.3896, Bottom 30th Acc: 0.3030
Fold [3/5] Epoch [10/100] Initial Loss: 0.1387, Training Loss: 0.0375, Initial Validation Loss: 0.1355, Validation Loss: 0.0456,V Acc: 0.7818, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.4242
Fold [3/5] Epoch [20/100] Initial Loss: 0.1387, Training Loss: 0.0153, Initial Validation Loss: 0.1355, Validation Loss: 0.0279,V Acc: 0.8818, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.6970
Fold [3/5] Epoch [30/100] Initial Loss: 0.1387, Training Loss: 0.0115, Initial Validation Loss: 0.1355, Validation Loss: 0.0262,V Acc: 0.9000, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.7273
Fold [3/5] Epoch [40/100] Initial Loss: 0.1387, Training Loss: 0.0101, Initial Validation Loss: 0.1355, Validation Loss: 0.0265,V Acc: 0.8909, Top 70th Acc: 0.9870, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 46  Rolling back to Epoch (base 0): 41  Top Validation Acc: 0.987012987012987
44 2 [array([0.6633125 , 0.12210252, 0.03853784, 0.0321939 , 0.14385334],
      dtype=float32)]
Fold [4/5] Epoch [0/100] Initial Loss: 0.1416, Training Loss: 0.1416, Initial Validation Loss: 0.1279, Validation Loss: 0.1279,V Acc: 0.4182, Top 70th Acc: 0.5455, Bottom 30th Acc: 0.1212
Fold [4/5] Epoch [10/100] Initial Loss: 0.1416, Training Loss: 0.0378, Initial Validation Loss: 0.1279, Validation Loss: 0.0419,V Acc: 0.8182, Top 70th Acc: 0.8701, Bottom 30th Acc: 0.6970
Fold [4/5] Epoch [20/100] Initial Loss: 0.1416, Training Loss: 0.0164, Initial Validation Loss: 0.1279, Validation Loss: 0.0224,V Acc: 0.8636, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.6061
Fold [4/5] Epoch [30/100] Initial Loss: 0.1416, Training Loss: 0.0127, Initial Validation Loss: 0.1279, Validation Loss: 0.0207,V Acc: 0.8545, Top 70th Acc: 0.9870, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 31  Rolling back to Epoch (base 0): 26  Top Validation Acc: 0.987012987012987
Fold [5/5] Epoch [0/100] Initial Loss: 0.1370, Training Loss: 0.1370, Initial Validation Loss: 0.1329, Validation Loss: 0.1329,V Acc: 0.2778, Top 70th Acc: 0.3289, Bottom 30th Acc: 0.1562
Fold [5/5] Epoch [10/100] Initial Loss: 0.1370, Training Loss: 0.0378, Initial Validation Loss: 0.1329, Validation Loss: 0.0504,V Acc: 0.7500, Top 70th Acc: 0.8947, Bottom 30th Acc: 0.4062
Fold [5/5] Epoch [20/100] Initial Loss: 0.1370, Training Loss: 0.0138, Initial Validation Loss: 0.1329, Validation Loss: 0.0390,V Acc: 0.8056, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.5000
Fold [5/5] Epoch [30/100] Initial Loss: 0.1370, Training Loss: 0.0116, Initial Validation Loss: 0.1329, Validation Loss: 0.0376,V Acc: 0.8148, Top 70th Acc: 0.9211, Bottom 30th Acc: 0.5625
Fold [5/5] Epoch [40/100] Initial Loss: 0.1370, Training Loss: 0.0109, Initial Validation Loss: 0.1329, Validation Loss: 0.0372,V Acc: 0.8241, Top 70th Acc: 0.9211, Bottom 30th Acc: 0.5938
Stopping early at Epoch (base 0): 41  Rolling back to Epoch (base 0): 36  Top Validation Acc: 0.9210526315789473
Running train_nn.py with seed 45
CUDA:False
Training samples count:  550
Training on 40 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1407, Training Loss: 0.1407, Initial Validation Loss: 0.1339, Validation Loss: 0.1339,V Acc: 0.2523, Top 70th Acc: 0.3077, Bottom 30th Acc: 0.1212
Fold [1/5] Epoch [10/100] Initial Loss: 0.1407, Training Loss: 0.0380, Initial Validation Loss: 0.1339, Validation Loss: 0.0538,V Acc: 0.7027, Top 70th Acc: 0.8333, Bottom 30th Acc: 0.3939
Fold [1/5] Epoch [20/100] Initial Loss: 0.1407, Training Loss: 0.0132, Initial Validation Loss: 0.1339, Validation Loss: 0.0423,V Acc: 0.7748, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.3939
Stopping early at Epoch (base 0): 21  Rolling back to Epoch (base 0): 16  Top Validation Acc: 0.9230769230769231
45 0 [array([0.56075096, 0.07226561, 0.0748776 , 0.13468257, 0.15742323],
      dtype=float32)]
Fold [2/5] Epoch [0/100] Initial Loss: 0.1376, Training Loss: 0.1376, Initial Validation Loss: 0.1368, Validation Loss: 0.1368,V Acc: 0.3333, Top 70th Acc: 0.4231, Bottom 30th Acc: 0.1212
Fold [2/5] Epoch [10/100] Initial Loss: 0.1376, Training Loss: 0.0314, Initial Validation Loss: 0.1368, Validation Loss: 0.0482,V Acc: 0.7658, Top 70th Acc: 0.8846, Bottom 30th Acc: 0.4848
Fold [2/5] Epoch [20/100] Initial Loss: 0.1376, Training Loss: 0.0156, Initial Validation Loss: 0.1368, Validation Loss: 0.0378,V Acc: 0.7928, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.4545
Stopping early at Epoch (base 0): 27  Rolling back to Epoch (base 0): 22  Top Validation Acc:
Training on 30 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 46
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 30 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 47
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 30 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 48
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 30 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 49
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 30 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 50
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 30 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 51
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 30 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 52
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 30 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 53
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 30 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 54
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 30 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 55
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 30 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 56
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 30 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 57
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 30 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 58
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 30 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 59
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 30 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 60
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 30 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 61
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 30 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 62
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 30 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 63
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 30 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 64
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 30 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 65
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 30 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 66
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 30 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 67
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 30 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 68
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 29 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 69
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 30 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 70
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 30 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 71
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 30 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 72
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 30 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 73
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 30 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 74
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 30 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 75
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 30 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 76
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 30 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 77
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 30 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 78
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 30 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 79
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 30 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 80
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 30 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 81
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 30 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 82
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 30 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 83
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 30 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 84
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 30 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 85
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 30 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 86
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 30 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 87
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 30 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 88
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 30 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 89
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 30 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 90
Training size: 439
44 2 [array([0.7734226 , 0.08541889, 0.01282343, 0.0406831 , 0.08765198],
      dtype=float32)]
Fold [4/5] Epoch [0/100] Initial Loss: 0.1398, Training Loss: 0.1398, Initial Validation Loss: 0.1328, Validation Loss: 0.1328,V Acc: 0.2545, Top 70th Acc: 0.3636, Bottom 30th Acc: 0.0000
Fold [4/5] Epoch [10/100] Initial Loss: 0.1398, Training Loss: 0.0433, Initial Validation Loss: 0.1328, Validation Loss: 0.0407,V Acc: 0.8000, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.4848
Fold [4/5] Epoch [20/100] Initial Loss: 0.1398, Training Loss: 0.0207, Initial Validation Loss: 0.1328, Validation Loss: 0.0224,V Acc: 0.8636, Top 70th Acc: 1.0000, Bottom 30th Acc: 0.5455
Fold [4/5] Epoch [30/100] Initial Loss: 0.1398, Training Loss: 0.0171, Initial Validation Loss: 0.1328, Validation Loss: 0.0214,V Acc: 0.8818, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 35  Rolling back to Epoch (base 0): 30  Top Validation Acc: 0.974025974025974
Fold [5/5] Epoch [0/100] Initial Loss: 0.1406, Training Loss: 0.1406, Initial Validation Loss: 0.1340, Validation Loss: 0.1340,V Acc: 0.3241, Top 70th Acc: 0.3553, Bottom 30th Acc: 0.2500
Fold [5/5] Epoch [10/100] Initial Loss: 0.1406, Training Loss: 0.0311, Initial Validation Loss: 0.1340, Validation Loss: 0.0430,V Acc: 0.7778, Top 70th Acc: 0.9211, Bottom 30th Acc: 0.4375
Fold [5/5] Epoch [20/100] Initial Loss: 0.1406, Training Loss: 0.0164, Initial Validation Loss: 0.1340, Validation Loss: 0.0370,V Acc: 0.7870, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.4375
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.9210526315789473
Running train_nn.py with seed 45
CUDA:False
Training samples count:  550
Training on 30 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1383, Training Loss: 0.1383, Initial Validation Loss: 0.1338, Validation Loss: 0.1338,V Acc: 0.2703, Top 70th Acc: 0.2949, Bottom 30th Acc: 0.2121
Fold [1/5] Epoch [10/100] Initial Loss: 0.1383, Training Loss: 0.0306, Initial Validation Loss: 0.1338, Validation Loss: 0.0489,V Acc: 0.7658, Top 70th Acc: 0.8846, Bottom 30th Acc: 0.4848
Fold [1/5] Epoch [20/100] Initial Loss: 0.1383, Training Loss: 0.0180, Initial Validation Loss: 0.1338, Validation Loss: 0.0409,V Acc: 0.8288, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.6364
Fold [1/5] Epoch [30/100] Initial Loss: 0.1383, Training Loss: 0.0143, Initial Validation Loss: 0.1338, Validation Loss: 0.0397,V Acc: 0.7928, Top 70th Acc: 0.8974, Bottom 30th Acc: 0.5455
Fold [1/5] Epoch [40/100] Initial Loss: 0.1383, Training Loss: 0.0134, Initial Validation Loss: 0.1338, Validation Loss: 0.0372,V Acc: 0.8018, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.5152
Stopping early at Epoch (base 0): 45  Rolling back to Epoch (base 0): 40  Top Validation Acc: 0.9230769230769231
45 0 [array([0.5886389 , 0.18258193, 0.0592573 , 0.10551889, 0.06400303],
      dtype=float32)]
Fold [2/5] Epoch [0/100] Initial Loss: 0.1366, Training Loss: 0.1366, Initial Validation Loss: 0.1366, Validation Loss: 0.1366,V Acc: 0.2342, Top 70th Acc: 0.2436, Bottom 30th Acc: 0.2121
Fold [2/5] Epoch [10/100] Initial Loss: 0.1366, Training Loss: 0.0318, Initial Validation Loss: 0.1366, Validation Loss: 0.0407,V Acc: 0.8288, Top 70th Acc: 0.8974, Bottom 30th Acc: 0.6667
Fold [2/5] Epoch [20/100] Initial Loss: 0.1366, Training Loss: 0.0206, Initial Validation Loss: 0.1366, Validation Loss: 0.0393,V Acc: 0.7838, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.4545
Stopping early at Epoch (base 0): 22  Rolling back to Epoch (base 0): 17  Top Validation Acc: 0.9230769230769231
Fold [3/5] Epoch [0/100] Initial Loss: 0.1436, Training Loss: 0.1436, Initial Validation Loss: 0.1321, Validation Loss: 0.1321,V Acc: 0.4182, Top 70th Acc: 0.3506, Bottom 30th Acc: 0.5758
Fold [3/5] Epoch [10/100] Initial Loss: 0.1436, Training Loss: 0.0383, Initial Validation Loss: 0.1321, Validation Loss: 0.0417,V Acc: 0.8000, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.5455
Fold [3/5] Epoch [20/100] Initial Loss: 0.1436, Training Loss: 0.0179, Initial Validation Loss: 0.1321, Validation Loss: 0.0308,V Acc: 0.8091, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.5152
Fold [3/5] Epoch [30/100] Initial Loss: 0.1436, Training Loss: 0.0151, Initial Validation Loss: 0.1321, Validation Loss: 0.0293,V Acc: 0.8273, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.5152
Stopping early at Epoch (base 0): 38  Rolling back to Epoch (base 0): 33  Top Validation Acc: 0.948051948051948
Fold [4/5] Epoch [0/100] Initial Loss: 0.1385, Training Loss: 0.1385, Initial Validation Loss: 0.1358, Validation Loss: 0.1358,V Acc: 0.2545, Top 70th Acc: 0.2987, Bottom 30th Acc: 0.1515
Fold [4/5] Epoch [10/100] Initial Loss: 0.1385, Training Loss: 0.0402, Initial Validation Loss: 0.1358, Validation Loss: 0.0427,V Acc: 0.8000, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.5455
Fold [4/5] Epoch [20/100] Initial Loss: 0.1385, Training Loss: 0.0199, Initial Validation Loss: 0.1358, Validation Loss: 0.0292,V Acc: 0.8364, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.5758
Fold [4/5] Epoch [30/100] Initial Loss: 0.1385, Training Loss: 0.0164, Initial Validation Loss: 0.1358, Validation Loss: 0.0291,V Acc: 0.8455, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 31  Rolling back to Epoch (base 0): 26  Top Validation Acc: 0.948051948051948
Fold [5/5] Epoch [0/100] Initial Loss: 0.1408, Training Loss: 0.1408, Initial Validation Loss: 0.1354, Validation Loss: 0.1354,V Acc: 0.3148, Top 70th Acc: 0.3026, Bottom 30th Acc: 0.3438
Fold [5/5] Epoch [10/100] Initial Loss: 0.1408, Training Loss: 0.0448, Initial Validation Loss: 0.1354, Validation Loss: 0.0466,V Acc: 0.8148, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.5312
Fold [5/5] Epoch [20/100] Initial Loss: 0.1408, Training Loss: 0.0197, Initial Validation Loss: 0.1354, Validation Loss: 0.0269,V Acc: 0.8889, Top 70th Acc: 0.9737, Bottom 30th Acc: 0.6875
Fold [5/5] Epoch [30/100] Initial Loss: 0.1408, Training Loss: 0.0167, Initial Validation Loss: 0.1354, Validation Loss: 0.0259,V Acc: 0.8796, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.6875
Stopping early at Epoch (base 0): 38  Rolling back to Epoch (base 0): 33  Top Validation Acc: 0.9736842105263158
Running train_nn.py with seed 46
CUDA:False
Training samples count:  550
Training on 30 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1352, Training Loss: 0.1352, Initial Validation Loss: 0.1283, Validation Loss: 0.1283,V Acc: 0.4775, Top 70th Acc: 0.4872, Bottom 30th Acc: 0.4545
Fold [1/5] Epoch [10/100] Initial Loss: 0.1352, Training Loss: 0.0358, Initial Validation Loss: 0.1283, Validation Loss: 0.0418,V Acc: 0.8018, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.5455
Fold [1/5] Epoch [20/100] Initial Loss: 0.1352, Training Loss: 0.0202, Initial Validation Loss: 0.1283, Validation Loss: 0.0377,V Acc: 0.7928, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.4848
Stopping early at Epoch (base 0): 28  Rolling back to Epoch (base 0): 23  Top Validation Acc: 0.8974358974358975
46 0 [array([0.5255008 , 0.07713604, 0.02352197, 0.17071363, 0.20312753],
      dtype=float32)]
Fold [2/5] Epoch [0/100] Initial Loss: 0.1404, Training Loss: 0.1404, Initial Validation Loss: 0.1346, Validation Loss: 0.1346,V Acc: 0.2523, Top 70th Acc: 0.2949, Bottom 30th Acc: 0.1515
Fold [2/5] Epoch [10/100] Initial Loss: 0.1404, Training Loss: 0.0370, Initial Validation Loss: 0.1346, Validation Loss: 0.0388,V Acc: 0.8198, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.4848
Fold [2/5] Epoch [20/100] Initial Loss: 0.1404, Training Loss: 0.0192, Initial Validation Loss: 0.1346, Validation Loss: 0.0312,V Acc: 0.8288, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.4848
Fold [2/5] Epoch [30/100] Initial Loss: 0.1404, Training Loss: 0.0161, Initial Validation Loss: 0.1346, Validation Loss: 0.0307,V Acc: 0.8378, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.5152
Stopping early at Epoch (base 0): 30  Rolling back to Epoch (base 0): 25  Top Validation Acc: 0.9743589743589743
Fold [3/5] Epoch [0/100] Initial Loss: 0.1365, Training Loss: 0.1365, Initial Validation Loss: 0.1352, Validation Loss: 0.1352,V Acc: 0.2909, Top 70th Acc: 0.3506, Bottom 30th Acc: 0.1515
Fold [3/5] Epoch [10/100] Initial Loss: 0.1365, Training Loss: 0.0343, Initial Validation Loss: 0.1352, Validation Loss: 0.0458,V Acc: 0.7636, Top 70th Acc: 0.8831, Bottom 30th Acc: 0.4848/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)

Fold [4/5] Epoch [10/100] Initial Loss: 0.1296, Training Loss: 0.0278, Initial Validation Loss: 0.1161, Validation Loss: 0.0365,V Acc: 0.8364, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 17  Rolling back to Epoch (base 0): 12  Top Validation Acc: 0.948051948051948
Fold [5/5] Epoch [0/100] Initial Loss: 0.1337, Training Loss: 0.1337, Initial Validation Loss: 0.1218, Validation Loss: 0.1218,V Acc: 0.5185, Top 70th Acc: 0.5658, Bottom 30th Acc: 0.4062
Fold [5/5] Epoch [10/100] Initial Loss: 0.1337, Training Loss: 0.0278, Initial Validation Loss: 0.1218, Validation Loss: 0.0380,V Acc: 0.8426, Top 70th Acc: 0.9079, Bottom 30th Acc: 0.6875
Stopping early at Epoch (base 0): 19  Rolling back to Epoch (base 0): 14  Top Validation Acc: 0.9473684210526315
Running train_nn.py with seed 64
CUDA:False
Training samples count:  550
Training on 21 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1365, Training Loss: 0.1365, Initial Validation Loss: 0.1256, Validation Loss: 0.1256,V Acc: 0.4865, Top 70th Acc: 0.5000, Bottom 30th Acc: 0.4545
Fold [1/5] Epoch [10/100] Initial Loss: 0.1365, Training Loss: 0.0200, Initial Validation Loss: 0.1256, Validation Loss: 0.0303,V Acc: 0.8378, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.5455
Fold [1/5] Epoch [20/100] Initial Loss: 0.1365, Training Loss: 0.0156, Initial Validation Loss: 0.1256, Validation Loss: 0.0341,V Acc: 0.8378, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 20  Rolling back to Epoch (base 0): 15  Top Validation Acc: 0.9487179487179487
Fold [2/5] Epoch [0/100] Initial Loss: 0.1348, Training Loss: 0.1348, Initial Validation Loss: 0.1226, Validation Loss: 0.1226,V Acc: 0.4414, Top 70th Acc: 0.5641, Bottom 30th Acc: 0.1515
Fold [2/5] Epoch [10/100] Initial Loss: 0.1348, Training Loss: 0.0235, Initial Validation Loss: 0.1226, Validation Loss: 0.0314,V Acc: 0.8468, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 16  Rolling back to Epoch (base 0): 11  Top Validation Acc: 0.9230769230769231
Fold [3/5] Epoch [0/100] Initial Loss: 0.1362, Training Loss: 0.1362, Initial Validation Loss: 0.1294, Validation Loss: 0.1294,V Acc: 0.5909, Top 70th Acc: 0.7013, Bottom 30th Acc: 0.3333
Fold [3/5] Epoch [10/100] Initial Loss: 0.1362, Training Loss: 0.0285, Initial Validation Loss: 0.1294, Validation Loss: 0.0310,V Acc: 0.8455, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6061
Fold [3/5] Epoch [20/100] Initial Loss: 0.1362, Training Loss: 0.0196, Initial Validation Loss: 0.1294, Validation Loss: 0.0268,V Acc: 0.8818, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 20  Rolling back to Epoch (base 0): 15  Top Validation Acc: 0.961038961038961
Fold [4/5] Epoch [0/100] Initial Loss: 0.1378, Training Loss: 0.1378, Initial Validation Loss: 0.1351, Validation Loss: 0.1351,V Acc: 0.2545, Top 70th Acc: 0.3636, Bottom 30th Acc: 0.0000
Fold [4/5] Epoch [10/100] Initial Loss: 0.1378, Training Loss: 0.0309, Initial Validation Loss: 0.1351, Validation Loss: 0.0290,V Acc: 0.8818, Top 70th Acc: 0.9870, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 18  Rolling back to Epoch (base 0): 13  Top Validation Acc: 0.987012987012987
64 3 [array([0.74663675, 0.03753271, 0.01629026, 0.08944879, 0.11009154],
      dtype=float32)]
Fold [5/5] Epoch [0/100] Initial Loss: 0.1388, Training Loss: 0.1388, Initial Validation Loss: 0.1294, Validation Loss: 0.1294,V Acc: 0.3981, Top 70th Acc: 0.5132, Bottom 30th Acc: 0.1250
Fold [5/5] Epoch [10/100] Initial Loss: 0.1388, Training Loss: 0.0248, Initial Validation Loss: 0.1294, Validation Loss: 0.0328,V Acc: 0.8333, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.5938
Fold [5/5] Epoch [20/100] Initial Loss: 0.1388, Training Loss: 0.0172, Initial Validation Loss: 0.1294, Validation Loss: 0.0322,V Acc: 0.8611, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.6875
Fold [5/5] Epoch [30/100] Initial Loss: 0.1388, Training Loss: 0.0163, Initial Validation Loss: 0.1294, Validation Loss: 0.0337,V Acc: 0.8426, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.5938
Stopping early at Epoch (base 0): 32  Rolling back to Epoch (base 0): 27  Top Validation Acc: 0.9342105263157895
Running train_nn.py with seed 65
CUDA:False
Training samples count:  550
Training on 21 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1371, Training Loss: 0.1371, Initial Validation Loss: 0.1291, Validation Loss: 0.1291,V Acc: 0.4324, Top 70th Acc: 0.5769, Bottom 30th Acc: 0.0909
Fold [1/5] Epoch [10/100] Initial Loss: 0.1371, Training Loss: 0.0279, Initial Validation Loss: 0.1291, Validation Loss: 0.0302,V Acc: 0.8649, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.6970
Fold [1/5] Epoch [20/100] Initial Loss: 0.1371, Training Loss: 0.0160, Initial Validation Loss: 0.1291, Validation Loss: 0.0349,V Acc: 0.8378, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.9487179487179487
65 0 [array([0.82088554, 0.00954094, 0.01484788, 0.06420193, 0.0905237 ],
      dtype=float32)]
Fold [2/5] Epoch [0/100] Initial Loss: 0.1374, Training Loss: 0.1374, Initial Validation Loss: 0.1287, Validation Loss: 0.1287,V Acc: 0.4324, Top 70th Acc: 0.5769, Bottom 30th Acc: 0.0909
Fold [2/5] Epoch [10/100] Initial Loss: 0.1374, Training Loss: 0.0316, Initial Validation Loss: 0.1287, Validation Loss: 0.0376,V Acc: 0.8288, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.5758
Fold [2/5] Epoch [20/100] Initial Loss: 0.1374, Training Loss: 0.0174, Initial Validation Loss: 0.1287, Validation Loss: 0.0269,V Acc: 0.8739, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 22  Rolling back to Epoch (base 0): 17  Top Validation Acc: 0.9743589743589743
Fold [3/5] Epoch [0/100] Initial Loss: 0.1308, Training Loss: 0.1308, Initial Validation Loss: 0.1160, Validation Loss: 0.1160,V Acc: 0.4818, Top 70th Acc: 0.5844, Bottom 30th Acc: 0.2424
Fold [3/5] Epoch [10/100] Initial Loss: 0.1308, Training Loss: 0.0249, Initial Validation Loss: 0.1160, Validation Loss: 0.0263,V Acc: 0.8727, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 17  Rolling back to Epoch (base 0): 12  Top Validation Acc: 0.961038961038961
Fold [4/5] Epoch [0/100] Initial Loss: 0.1383, Training Loss: 0.1383, Initial Validation Loss: 0.1280, Validation Loss: 0.1280,V Acc: 0.4636, Top 70th Acc: 0.5325, Bottom 30th Acc: 0.3030
Fold [4/5] Epoch [10/100] Initial Loss: 0.1383, Training Loss: 0.0289, Initial Validation Loss: 0.1280, Validation Loss: 0.0316,V Acc: 0.8455, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6061
Fold [4/5] Epoch [20/100] Initial Loss: 0.1383, Training Loss: 0.0194, Initial Validation Loss: 0.1280, Validation Loss: 0.0286,V Acc: 0.8455, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 21  Rolling back to Epoch (base 0): 16  Top Validation Acc: 0.961038961038961
Fold [5/5] Epoch [0/100] Initial Loss: 0.1328, Training Loss: 0.1328, Initial Validation Loss: 0.1184, Validation Loss: 0.1184,V Acc: 0.5278, Top 70th Acc: 0.6053, Bottom 30th Acc: 0.3438
Fold [5/5] Epoch [10/100] Initial Loss: 0.1328, Training Loss: 0.0239, Initial Validation Loss: 0.1184, Validation Loss: 0.0331,V Acc: 0.8796, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.7500
Fold [5/5] Epoch [20/100] Initial Loss: 0.1328, Training Loss: 0.0180, Initial Validation Loss: 0.1184, Validation Loss: 0.0226,V Acc: 0.9074, Top 70th Acc: 0.9737, Bottom 30th Acc: 0.7500
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.9736842105263158
Running train_nn.py with seed 66
CUDA:False
Training samples count:  550
Training on 21 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1327, Training Loss: 0.1327, Initial Validation Loss: 0.1280, Validation Loss: 0.1280,V Acc: 0.4595, Top 70th Acc: 0.5385, Bottom 30th Acc: 0.2727
Fold [1/5] Epoch [10/100] Initial Loss: 0.1327, Training Loss: 0.0241, Initial Validation Loss: 0.1280, Validation Loss: 0.0370,V Acc: 0.8288, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.5455
Fold [1/5] Epoch [20/100] Initial Loss: 0.1327, Training Loss: 0.0171, Initial Validation Loss: 0.1280, Validation Loss: 0.0350,V Acc: 0.8288, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.5152
Fold [5/5] Epoch [20/100] Initial Loss: 0.1295, Training Loss: 0.0789, Initial Validation Loss: 0.1128, Validation Loss: 0.0768,V Acc: 0.6204, Top 70th Acc: 0.7105, Bottom 30th Acc: 0.4062
Stopping early at Epoch (base 0): 27  Rolling back to Epoch (base 0): 22  Top Validation Acc: 0.7105263157894737
Running train_nn.py with seed 42
CUDA:False
Training samples count:  550
Training on 2 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1383, Training Loss: 0.1383, Initial Validation Loss: 0.1330, Validation Loss: 0.1330,V Acc: 0.3784, Top 70th Acc: 0.4103, Bottom 30th Acc: 0.3030
Fold [1/5] Epoch [10/100] Initial Loss: 0.1383, Training Loss: 0.0786, Initial Validation Loss: 0.1330, Validation Loss: 0.0899,V Acc: 0.6036, Top 70th Acc: 0.7051, Bottom 30th Acc: 0.3636
Fold [1/5] Epoch [20/100] Initial Loss: 0.1383, Training Loss: 0.0763, Initial Validation Loss: 0.1330, Validation Loss: 0.0883,V Acc: 0.6126, Top 70th Acc: 0.7051, Bottom 30th Acc: 0.3939
Fold [1/5] Epoch [30/100] Initial Loss: 0.1383, Training Loss: 0.0757, Initial Validation Loss: 0.1330, Validation Loss: 0.0878,V Acc: 0.6306, Top 70th Acc: 0.7051, Bottom 30th Acc: 0.4545
Stopping early at Epoch (base 0): 33  Rolling back to Epoch (base 0): 28  Top Validation Acc: 0.717948717948718
Fold [2/5] Epoch [0/100] Initial Loss: 0.1359, Training Loss: 0.1359, Initial Validation Loss: 0.1246, Validation Loss: 0.1246,V Acc: 0.4505, Top 70th Acc: 0.4872, Bottom 30th Acc: 0.3636
Fold [2/5] Epoch [10/100] Initial Loss: 0.1359, Training Loss: 0.0804, Initial Validation Loss: 0.1246, Validation Loss: 0.0819,V Acc: 0.6036, Top 70th Acc: 0.7308, Bottom 30th Acc: 0.3030
Fold [2/5] Epoch [20/100] Initial Loss: 0.1359, Training Loss: 0.0781, Initial Validation Loss: 0.1246, Validation Loss: 0.0802,V Acc: 0.6126, Top 70th Acc: 0.7051, Bottom 30th Acc: 0.3939
Stopping early at Epoch (base 0): 21  Rolling back to Epoch (base 0): 16  Top Validation Acc: 0.6923076923076923
42 1 [array([0.12282625, 0.35153323, 0.10535934, 0.23410496, 0.18617624],
      dtype=float32)]
Fold [3/5] Epoch [0/100] Initial Loss: 0.1337, Training Loss: 0.1337, Initial Validation Loss: 0.1227, Validation Loss: 0.1227,V Acc: 0.4636, Top 70th Acc: 0.4935, Bottom 30th Acc: 0.3939
Fold [3/5] Epoch [10/100] Initial Loss: 0.1337, Training Loss: 0.0814, Initial Validation Loss: 0.1227, Validation Loss: 0.0774,V Acc: 0.6182, Top 70th Acc: 0.7403, Bottom 30th Acc: 0.3333
Fold [3/5] Epoch [20/100] Initial Loss: 0.1337, Training Loss: 0.0799, Initial Validation Loss: 0.1227, Validation Loss: 0.0748,V Acc: 0.6182, Top 70th Acc: 0.7532, Bottom 30th Acc: 0.3030
Fold [3/5] Epoch [30/100] Initial Loss: 0.1337, Training Loss: 0.0793, Initial Validation Loss: 0.1227, Validation Loss: 0.0741,V Acc: 0.6273, Top 70th Acc: 0.7273, Bottom 30th Acc: 0.3939
Fold [3/5] Epoch [40/100] Initial Loss: 0.1337, Training Loss: 0.0786, Initial Validation Loss: 0.1227, Validation Loss: 0.0732,V Acc: 0.6364, Top 70th Acc: 0.7532, Bottom 30th Acc: 0.3636
Fold [3/5] Epoch [50/100] Initial Loss: 0.1337, Training Loss: 0.0781, Initial Validation Loss: 0.1227, Validation Loss: 0.0727,V Acc: 0.6182, Top 70th Acc: 0.7532, Bottom 30th Acc: 0.3030
Stopping early at Epoch (base 0): 50  Rolling back to Epoch (base 0): 45  Top Validation Acc: 0.7532467532467533
Fold [4/5] Epoch [0/100] Initial Loss: 0.1317, Training Loss: 0.1317, Initial Validation Loss: 0.1230, Validation Loss: 0.1230,V Acc: 0.5000, Top 70th Acc: 0.5584, Bottom 30th Acc: 0.3636
Fold [4/5] Epoch [10/100] Initial Loss: 0.1317, Training Loss: 0.0809, Initial Validation Loss: 0.1230, Validation Loss: 0.0773,V Acc: 0.6909, Top 70th Acc: 0.7792, Bottom 30th Acc: 0.4848
Fold [4/5] Epoch [20/100] Initial Loss: 0.1317, Training Loss: 0.0798, Initial Validation Loss: 0.1230, Validation Loss: 0.0764,V Acc: 0.7000, Top 70th Acc: 0.7792, Bottom 30th Acc: 0.5152
Fold [4/5] Epoch [30/100] Initial Loss: 0.1317, Training Loss: 0.0792, Initial Validation Loss: 0.1230, Validation Loss: 0.0762,V Acc: 0.6909, Top 70th Acc: 0.7532, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 32  Rolling back to Epoch (base 0): 27  Top Validation Acc: 0.7662337662337663
Fold [5/5] Epoch [0/100] Initial Loss: 0.1362, Training Loss: 0.1362, Initial Validation Loss: 0.1277, Validation Loss: 0.1277,V Acc: 0.5463, Top 70th Acc: 0.4868, Bottom 30th Acc: 0.6875
Fold [5/5] Epoch [10/100] Initial Loss: 0.1362, Training Loss: 0.0826, Initial Validation Loss: 0.1277, Validation Loss: 0.0755,V Acc: 0.6204, Top 70th Acc: 0.7500, Bottom 30th Acc: 0.3125
Fold [5/5] Epoch [20/100] Initial Loss: 0.1362, Training Loss: 0.0796, Initial Validation Loss: 0.1277, Validation Loss: 0.0737,V Acc: 0.6204, Top 70th Acc: 0.7632, Bottom 30th Acc: 0.2812
Stopping early at Epoch (base 0): 27  Rolling back to Epoch (base 0): 22  Top Validation Acc: 0.7763157894736842
Running train_nn.py with seed 43
CUDA:False
Training samples count:  550
Training on 2 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1403, Training Loss: 0.1403, Initial Validation Loss: 0.1291, Validation Loss: 0.1291,V Acc: 0.3514, Top 70th Acc: 0.4487, Bottom 30th Acc: 0.1212
Fold [1/5] Epoch [10/100] Initial Loss: 0.1403, Training Loss: 0.0839, Initial Validation Loss: 0.1291, Validation Loss: 0.0726,V Acc: 0.6667, Top 70th Acc: 0.7436, Bottom 30th Acc: 0.4848
Fold [1/5] Epoch [20/100] Initial Loss: 0.1403, Training Loss: 0.0813, Initial Validation Loss: 0.1291, Validation Loss: 0.0697,V Acc: 0.6847, Top 70th Acc: 0.7308, Bottom 30th Acc: 0.5758
Fold [1/5] Epoch [30/100] Initial Loss: 0.1403, Training Loss: 0.0807, Initial Validation Loss: 0.1291, Validation Loss: 0.0695,V Acc: 0.6847, Top 70th Acc: 0.7308, Bottom 30th Acc: 0.5758
Fold [1/5] Epoch [40/100] Initial Loss: 0.1403, Training Loss: 0.0801, Initial Validation Loss: 0.1291, Validation Loss: 0.0691,V Acc: 0.6757, Top 70th Acc: 0.7308, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 47  Rolling back to Epoch (base 0): 42  Top Validation Acc: 0.7435897435897436
Fold [2/5] Epoch [0/100] Initial Loss: 0.1316, Training Loss: 0.1316, Initial Validation Loss: 0.1169, Validation Loss: 0.1169,V Acc: 0.3784, Top 70th Acc: 0.4872, Bottom 30th Acc: 0.1212
Fold [2/5] Epoch [10/100] Initial Loss: 0.1316, Training Loss: 0.0784, Initial Validation Loss: 0.1169, Validation Loss: 0.0887,V Acc: 0.5586, Top 70th Acc: 0.6154, Bottom 30th Acc: 0.4242
Fold [2/5] Epoch [20/100] Initial Loss: 0.1316, Training Loss: 0.0755, Initial Validation Loss: 0.1169, Validation Loss: 0.0885,V Acc: 0.5315, Top 70th Acc: 0.6282, Bottom 30th Acc: 0.3030
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.6282051282051282
Fold [3/5] Epoch [0/100] Initial Loss: 0.1316, Training Loss: 0.1316, Initial Validation Loss: 0.1271, Validation Loss: 0.1271,V Acc: 0.5455, Top 70th Acc: 0.6364, Bottom 30th Acc: 0.3333
Fold [3/5] Epoch [10/100] Initial Loss: 0.1316, Training Loss: 0.0804, Initial Validation Loss: 0.1271, Validation Loss: 0.0784,V Acc: 0.6545, Top 70th Acc: 0.7662, Bottom 30th Acc: 0.3939
Fold [3/5] Epoch [20/100] Initial Loss: 0.1316, Training Loss: 0.0784, Initial Validation Loss: 0.1271, Validation Loss: 0.0752,V Acc: 0.6818, Top 70th Acc: 0.8182, Bottom 30th Acc: 0.3636
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.8051948051948052
43 2 [array([0.132988  , 0.35820335, 0.13800092, 0.22162172, 0.14918597],
      dtype=float32)]
Fold [4/5] Epoch [0/100] Initial Loss: 0.1352, Training Loss: 0.1352, Initial Validation Loss: 0.1269, Validation Loss: 0.1269,V Acc: 0.4545, Top 70th Acc: 0.5195, Bottom 30th Acc: 0.3030
Fold [4/5] Epoch [10/100] Initial Loss: 0.1352, Training Loss: 0.0820, Initial Validation Loss: 0.1269, Validation Loss: 0.0803,V Acc: 0.6455, Top 70th Acc: 0.7922, Bottom 30th Acc: 0.3030
Fold [4/5] Epoch [20/100] Initial Loss: 0.1352, Training Loss: 0.0795, Initial Validation Loss: 0.1269, Validation Loss: 0.0771,V Acc: 0.6545, Top 70th Acc: 0.7922, Bottom 30th Acc: 0.3333
Fold [4/5] Epoch [30/100] Initial Loss: 0.1352, Training Loss: 0.0786, Initial Validation Loss: 0.1269, Validation Loss: 0.0764,V Acc: 0.6818, Top 70th Acc: 0.7922, Bottom 30th Acc: 0.4242/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
 550
Training on 20 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1401, Training Loss: 0.1401, Initial Validation Loss: 0.1341, Validation Loss: 0.1341,V Acc: 0.3063, Top 70th Acc: 0.2564, Bottom 30th Acc: 0.4242
Fold [1/5] Epoch [10/100] Initial Loss: 0.1401, Training Loss: 0.0339, Initial Validation Loss: 0.1341, Validation Loss: 0.0486,V Acc: 0.7838, Top 70th Acc: 0.8718, Bottom 30th Acc: 0.5758
Fold [1/5] Epoch [20/100] Initial Loss: 0.1401, Training Loss: 0.0212, Initial Validation Loss: 0.1341, Validation Loss: 0.0466,V Acc: 0.7838, Top 70th Acc: 0.8846, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 21  Rolling back to Epoch (base 0): 16  Top Validation Acc: 0.8846153846153846
45 0 [array([0.35632306, 0.1382823 , 0.12200722, 0.15345386, 0.22993354],
      dtype=float32)]
Fold [2/5] Epoch [0/100] Initial Loss: 0.1410, Training Loss: 0.1410, Initial Validation Loss: 0.1350, Validation Loss: 0.1350,V Acc: 0.3604, Top 70th Acc: 0.4487, Bottom 30th Acc: 0.1515
Fold [2/5] Epoch [10/100] Initial Loss: 0.1410, Training Loss: 0.0322, Initial Validation Loss: 0.1350, Validation Loss: 0.0413,V Acc: 0.8198, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.6061
Fold [2/5] Epoch [20/100] Initial Loss: 0.1410, Training Loss: 0.0225, Initial Validation Loss: 0.1350, Validation Loss: 0.0345,V Acc: 0.8378, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.9358974358974359
Fold [3/5] Epoch [0/100] Initial Loss: 0.1394, Training Loss: 0.1394, Initial Validation Loss: 0.1295, Validation Loss: 0.1295,V Acc: 0.4273, Top 70th Acc: 0.4805, Bottom 30th Acc: 0.3030
Fold [3/5] Epoch [10/100] Initial Loss: 0.1394, Training Loss: 0.0384, Initial Validation Loss: 0.1295, Validation Loss: 0.0381,V Acc: 0.8273, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.5758
Fold [3/5] Epoch [20/100] Initial Loss: 0.1394, Training Loss: 0.0235, Initial Validation Loss: 0.1295, Validation Loss: 0.0317,V Acc: 0.8545, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.6667
Fold [3/5] Epoch [30/100] Initial Loss: 0.1394, Training Loss: 0.0209, Initial Validation Loss: 0.1295, Validation Loss: 0.0302,V Acc: 0.8636, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 32  Rolling back to Epoch (base 0): 27  Top Validation Acc: 0.948051948051948
Fold [4/5] Epoch [0/100] Initial Loss: 0.1419, Training Loss: 0.1419, Initial Validation Loss: 0.1337, Validation Loss: 0.1337,V Acc: 0.3455, Top 70th Acc: 0.3896, Bottom 30th Acc: 0.2424
Fold [4/5] Epoch [10/100] Initial Loss: 0.1419, Training Loss: 0.0403, Initial Validation Loss: 0.1337, Validation Loss: 0.0384,V Acc: 0.8091, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.4848
Fold [4/5] Epoch [20/100] Initial Loss: 0.1419, Training Loss: 0.0241, Initial Validation Loss: 0.1337, Validation Loss: 0.0281,V Acc: 0.8636, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 29  Rolling back to Epoch (base 0): 24  Top Validation Acc: 0.974025974025974
Fold [5/5] Epoch [0/100] Initial Loss: 0.1387, Training Loss: 0.1387, Initial Validation Loss: 0.1356, Validation Loss: 0.1356,V Acc: 0.2500, Top 70th Acc: 0.3158, Bottom 30th Acc: 0.0938
Fold [5/5] Epoch [10/100] Initial Loss: 0.1387, Training Loss: 0.0456, Initial Validation Loss: 0.1356, Validation Loss: 0.0496,V Acc: 0.7778, Top 70th Acc: 0.8816, Bottom 30th Acc: 0.5312
Fold [5/5] Epoch [20/100] Initial Loss: 0.1387, Training Loss: 0.0241, Initial Validation Loss: 0.1356, Validation Loss: 0.0339,V Acc: 0.8519, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.6250
Stopping early at Epoch (base 0): 29  Rolling back to Epoch (base 0): 24  Top Validation Acc: 0.9473684210526315
Running train_nn.py with seed 46
CUDA:False
Training samples count:  550
Training on 20 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1413, Training Loss: 0.1413, Initial Validation Loss: 0.1343, Validation Loss: 0.1343,V Acc: 0.3784, Top 70th Acc: 0.4103, Bottom 30th Acc: 0.3030
Fold [1/5] Epoch [10/100] Initial Loss: 0.1413, Training Loss: 0.0318, Initial Validation Loss: 0.1343, Validation Loss: 0.0353,V Acc: 0.8468, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 18  Rolling back to Epoch (base 0): 13  Top Validation Acc: 0.9102564102564102
46 0 [array([0.40329987, 0.12669718, 0.11103351, 0.21960731, 0.13936226],
      dtype=float32)]
Fold [2/5] Epoch [0/100] Initial Loss: 0.1403, Training Loss: 0.1403, Initial Validation Loss: 0.1340, Validation Loss: 0.1340,V Acc: 0.2793, Top 70th Acc: 0.2564, Bottom 30th Acc: 0.3333
Fold [2/5] Epoch [10/100] Initial Loss: 0.1403, Training Loss: 0.0340, Initial Validation Loss: 0.1340, Validation Loss: 0.0396,V Acc: 0.7928, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.4242
Fold [2/5] Epoch [20/100] Initial Loss: 0.1403, Training Loss: 0.0227, Initial Validation Loss: 0.1340, Validation Loss: 0.0326,V Acc: 0.8378, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 27  Rolling back to Epoch (base 0): 22  Top Validation Acc: 0.9487179487179487
Fold [3/5] Epoch [0/100] Initial Loss: 0.1386, Training Loss: 0.1386, Initial Validation Loss: 0.1355, Validation Loss: 0.1355,V Acc: 0.3273, Top 70th Acc: 0.3377, Bottom 30th Acc: 0.3030
Fold [3/5] Epoch [10/100] Initial Loss: 0.1386, Training Loss: 0.0448, Initial Validation Loss: 0.1355, Validation Loss: 0.0517,V Acc: 0.8000, Top 70th Acc: 0.8571, Bottom 30th Acc: 0.6667
Fold [3/5] Epoch [20/100] Initial Loss: 0.1386, Training Loss: 0.0254, Initial Validation Loss: 0.1355, Validation Loss: 0.0312,V Acc: 0.8636, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.6364
Fold [3/5] Epoch [30/100] Initial Loss: 0.1386, Training Loss: 0.0225, Initial Validation Loss: 0.1355, Validation Loss: 0.0306,V Acc: 0.8636, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 33  Rolling back to Epoch (base 0): 28  Top Validation Acc: 0.961038961038961
Fold [4/5] Epoch [0/100] Initial Loss: 0.1415, Training Loss: 0.1415, Initial Validation Loss: 0.1326, Validation Loss: 0.1326,V Acc: 0.3455, Top 70th Acc: 0.4156, Bottom 30th Acc: 0.1818
Fold [4/5] Epoch [10/100] Initial Loss: 0.1415, Training Loss: 0.0445, Initial Validation Loss: 0.1326, Validation Loss: 0.0504,V Acc: 0.7818, Top 70th Acc: 0.8312, Bottom 30th Acc: 0.6667
Fold [4/5] Epoch [20/100] Initial Loss: 0.1415, Training Loss: 0.0248, Initial Validation Loss: 0.1326, Validation Loss: 0.0331,V Acc: 0.8273, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.6061
Fold [4/5] Epoch [30/100] Initial Loss: 0.1415, Training Loss: 0.0212, Initial Validation Loss: 0.1326, Validation Loss: 0.0322,V Acc: 0.8455, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 38  Rolling back to Epoch (base 0): 33  Top Validation Acc: 0.9090909090909091
Fold [5/5] Epoch [0/100] Initial Loss: 0.1411, Training Loss: 0.1411, Initial Validation Loss: 0.1374, Validation Loss: 0.1374,V Acc: 0.2500, Top 70th Acc: 0.2895, Bottom 30th Acc: 0.1562
Fold [5/5] Epoch [10/100] Initial Loss: 0.1411, Training Loss: 0.0457, Initial Validation Loss: 0.1374, Validation Loss: 0.0527,V Acc: 0.7593, Top 70th Acc: 0.8684, Bottom 30th Acc: 0.5000
Fold [5/5] Epoch [20/100] Initial Loss: 0.1411, Training Loss: 0.0228, Initial Validation Loss: 0.1374, Validation Loss: 0.0379,V Acc: 0.8333, Top 70th Acc: 0.9211, Bottom 30th Acc: 0.6250
Stopping early at Epoch (base 0): 27  Rolling back to Epoch (base 0): 22  Top Validation Acc: 0.9342105263157895
Running train_nn.py with seed 47
CUDA:False
Training samples count:  550
Training on 20 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1390, Training Loss: 0.1390, Initial Validation Loss: 0.1279, Validation Loss: 0.1279,V Acc: 0.3784, Top 70th Acc: 0.4615, Bottom 30th Acc: 0.1818
Fold [1/5] Epoch [10/100] Initial Loss: 0.1390, Training Loss: 0.0268, Initial Validation Loss: 0.1279, Validation Loss: 0.0420,V Acc: 0.7838, Top 70th Acc: 0.8590, Bottom 30th Acc: 0.6061
Fold [1/5] Epoch [20/100] Initial Loss: 0.1390, Training Loss: 0.0207, Initial Validation Loss: 0.1279, Validation Loss: 0.0397,V Acc: 0.8108, Top 70th Acc: 0.8590, Bottom 30th Acc: 0.6970
Fold [1/5] Epoch [30/100] Initial Loss: 0.1390, Training Loss: 0.0191, Initial Validation Loss: 0.1279, Validation Loss: 0.0387,V Acc: 0.8018, Top 70th Acc: 0.8590, Bottom 30th Acc: 0.6667 0.9358974358974359
Fold [3/5] Epoch [0/100] Initial Loss: 0.1408, Training Loss: 0.1408, Initial Validation Loss: 0.1305, Validation Loss: 0.1305,V Acc: 0.3727, Top 70th Acc: 0.4416, Bottom 30th Acc: 0.2121
Fold [3/5] Epoch [10/100] Initial Loss: 0.1408, Training Loss: 0.0316, Initial Validation Loss: 0.1305, Validation Loss: 0.0419,V Acc: 0.7727, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.4545
Fold [3/5] Epoch [20/100] Initial Loss: 0.1408, Training Loss: 0.0189, Initial Validation Loss: 0.1305, Validation Loss: 0.0328,V Acc: 0.8455, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.6364
Fold [3/5] Epoch [30/100] Initial Loss: 0.1408, Training Loss: 0.0139, Initial Validation Loss: 0.1305, Validation Loss: 0.0293,V Acc: 0.8636, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.6364
Fold [3/5] Epoch [40/100] Initial Loss: 0.1408, Training Loss: 0.0125, Initial Validation Loss: 0.1305, Validation Loss: 0.0276,V Acc: 0.8727, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 48  Rolling back to Epoch (base 0): 43  Top Validation Acc: 0.961038961038961
Fold [4/5] Epoch [0/100] Initial Loss: 0.1364, Training Loss: 0.1364, Initial Validation Loss: 0.1326, Validation Loss: 0.1326,V Acc: 0.3455, Top 70th Acc: 0.3896, Bottom 30th Acc: 0.2424
Fold [4/5] Epoch [10/100] Initial Loss: 0.1364, Training Loss: 0.0443, Initial Validation Loss: 0.1326, Validation Loss: 0.0470,V Acc: 0.7636, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.4242
Fold [4/5] Epoch [20/100] Initial Loss: 0.1364, Training Loss: 0.0253, Initial Validation Loss: 0.1326, Validation Loss: 0.0338,V Acc: 0.8364, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.6364
Fold [4/5] Epoch [30/100] Initial Loss: 0.1364, Training Loss: 0.0149, Initial Validation Loss: 0.1326, Validation Loss: 0.0276,V Acc: 0.8545, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6364
Fold [4/5] Epoch [40/100] Initial Loss: 0.1364, Training Loss: 0.0124, Initial Validation Loss: 0.1326, Validation Loss: 0.0267,V Acc: 0.8455, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 43  Rolling back to Epoch (base 0): 38  Top Validation Acc: 0.961038961038961
Fold [5/5] Epoch [0/100] Initial Loss: 0.1437, Training Loss: 0.1437, Initial Validation Loss: 0.1365, Validation Loss: 0.1365,V Acc: 0.2315, Top 70th Acc: 0.3026, Bottom 30th Acc: 0.0625
Fold [5/5] Epoch [10/100] Initial Loss: 0.1437, Training Loss: 0.0410, Initial Validation Loss: 0.1365, Validation Loss: 0.0443,V Acc: 0.7870, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.4062
Fold [5/5] Epoch [20/100] Initial Loss: 0.1437, Training Loss: 0.0168, Initial Validation Loss: 0.1365, Validation Loss: 0.0250,V Acc: 0.8704, Top 70th Acc: 0.9868, Bottom 30th Acc: 0.5938
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.9736842105263158
Running train_nn.py with seed 46
CUDA:False
Training samples count:  550
Training on 40 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1383, Training Loss: 0.1383, Initial Validation Loss: 0.1312, Validation Loss: 0.1312,V Acc: 0.4505, Top 70th Acc: 0.5385, Bottom 30th Acc: 0.2424
Fold [1/5] Epoch [10/100] Initial Loss: 0.1383, Training Loss: 0.0335, Initial Validation Loss: 0.1312, Validation Loss: 0.0414,V Acc: 0.7658, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.4242
Fold [1/5] Epoch [20/100] Initial Loss: 0.1383, Training Loss: 0.0160, Initial Validation Loss: 0.1312, Validation Loss: 0.0363,V Acc: 0.8018, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 20  Rolling back to Epoch (base 0): 15  Top Validation Acc: 0.9102564102564102
46 0 [array([0.7027243 , 0.09406521, 0.01085447, 0.10884861, 0.08350737],
      dtype=float32)]
Fold [2/5] Epoch [0/100] Initial Loss: 0.1376, Training Loss: 0.1376, Initial Validation Loss: 0.1319, Validation Loss: 0.1319,V Acc: 0.2613, Top 70th Acc: 0.3205, Bottom 30th Acc: 0.1212
Fold [2/5] Epoch [10/100] Initial Loss: 0.1376, Training Loss: 0.0342, Initial Validation Loss: 0.1319, Validation Loss: 0.0386,V Acc: 0.8108, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.5152
Fold [2/5] Epoch [20/100] Initial Loss: 0.1376, Training Loss: 0.0146, Initial Validation Loss: 0.1319, Validation Loss: 0.0288,V Acc: 0.8198, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.4545
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.9743589743589743
Fold [3/5] Epoch [0/100] Initial Loss: 0.1397, Training Loss: 0.1397, Initial Validation Loss: 0.1374, Validation Loss: 0.1374,V Acc: 0.2818, Top 70th Acc: 0.2857, Bottom 30th Acc: 0.2727
Fold [3/5] Epoch [10/100] Initial Loss: 0.1397, Training Loss: 0.0256, Initial Validation Loss: 0.1374, Validation Loss: 0.0362,V Acc: 0.8727, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.7576
Fold [3/5] Epoch [20/100] Initial Loss: 0.1397, Training Loss: 0.0154, Initial Validation Loss: 0.1374, Validation Loss: 0.0304,V Acc: 0.8818, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.7576
Fold [3/5] Epoch [30/100] Initial Loss: 0.1397, Training Loss: 0.0136, Initial Validation Loss: 0.1374, Validation Loss: 0.0299,V Acc: 0.8818, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.7273
Stopping early at Epoch (base 0): 32  Rolling back to Epoch (base 0): 27  Top Validation Acc: 0.948051948051948
Fold [4/5] Epoch [0/100] Initial Loss: 0.1435, Training Loss: 0.1435, Initial Validation Loss: 0.1352, Validation Loss: 0.1352,V Acc: 0.2273, Top 70th Acc: 0.2597, Bottom 30th Acc: 0.1515
Fold [4/5] Epoch [10/100] Initial Loss: 0.1435, Training Loss: 0.0362, Initial Validation Loss: 0.1352, Validation Loss: 0.0406,V Acc: 0.8000, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.5152
Fold [4/5] Epoch [20/100] Initial Loss: 0.1435, Training Loss: 0.0156, Initial Validation Loss: 0.1352, Validation Loss: 0.0320,V Acc: 0.8455, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.8831168831168831
Fold [5/5] Epoch [0/100] Initial Loss: 0.1370, Training Loss: 0.1370, Initial Validation Loss: 0.1346, Validation Loss: 0.1346,V Acc: 0.4074, Top 70th Acc: 0.4474, Bottom 30th Acc: 0.3125
Fold [5/5] Epoch [10/100] Initial Loss: 0.1370, Training Loss: 0.0400, Initial Validation Loss: 0.1346, Validation Loss: 0.0478,V Acc: 0.7870, Top 70th Acc: 0.8947, Bottom 30th Acc: 0.5312
Fold [5/5] Epoch [20/100] Initial Loss: 0.1370, Training Loss: 0.0149, Initial Validation Loss: 0.1346, Validation Loss: 0.0305,V Acc: 0.8519, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.6250
Fold [5/5] Epoch [30/100] Initial Loss: 0.1370, Training Loss: 0.0120, Initial Validation Loss: 0.1346, Validation Loss: 0.0294,V Acc: 0.8611, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.6562
Stopping early at Epoch (base 0): 33  Rolling back to Epoch (base 0): 28  Top Validation Acc: 0.9473684210526315
Running train_nn.py with seed 47
CUDA:False
Training samples count:  550
Training on 40 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1370, Training Loss: 0.1370, Initial Validation Loss: 0.1266, Validation Loss: 0.1266,V Acc: 0.3514, Top 70th Acc: 0.4744, Bottom 30th Acc: 0.0606
Fold [1/5] Epoch [10/100] Initial Loss: 0.1370, Training Loss: 0.0368, Initial Validation Loss: 0.1266, Validation Loss: 0.0446,V Acc: 0.7928, Top 70th Acc: 0.8974, Bottom 30th Acc: 0.5455
Fold [1/5] Epoch [20/100] Initial Loss: 0.1370, Training Loss: 0.0127, Initial Validation Loss: 0.1266, Validation Loss: 0.0360,V Acc: 0.7928, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.4848
Stopping early at Epoch (base 0): 22  Rolling back to Epoch (base 0): 17  Top Validation Acc: 0.9230769230769231
Fold [2/5] Epoch [0/100] Initial Loss: 0.1404, Training Loss: 0.1404, Initial Validation Loss: 0.1373, Validation Loss: 0.1373,V Acc: 0.3153, Top 70th Acc: 0.4103, Bottom 30th Acc: 0.0909
Fold [2/5] Epoch [10/100] Initial Loss: 0.1404, Training Loss: 0.0227, Initial Validation Loss: 0.1373, Validation Loss: 0.0343,V Acc: 0.8468, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.6061
Fold [2/5] Epoch [20/100] Initial Loss: 0.1404, Training Loss: 0.0135, Initial Validation Loss: 0.1373, Validation Loss: 0.0305,V Acc: 0.8739, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.6667
Fold [2/5] Epoch [30/100] Initial Loss: 0.1404, Training Loss: 0.0117, Initial Validation Loss: 0.1373, Validation Loss: 0.0300,V Acc: 0.8739, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.6970
Fold [4/5] Epoch [10/100] Initial Loss: 0.1382, Training Loss: 0.0221, Initial Validation Loss: 0.1334, Validation Loss: 0.0438,V Acc: 0.7636, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.4242
Fold [4/5] Epoch [20/100] Initial Loss: 0.1382, Training Loss: 0.0048, Initial Validation Loss: 0.1334, Validation Loss: 0.0314,V Acc: 0.8182, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.4545
Fold [4/5] Epoch [30/100] Initial Loss: 0.1382, Training Loss: 0.0037, Initial Validation Loss: 0.1334, Validation Loss: 0.0307,V Acc: 0.8091, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.4848
Stopping early at Epoch (base 0): 31  Rolling back to Epoch (base 0): 26  Top Validation Acc: 0.974025974025974
Fold [5/5] Epoch [0/100] Initial Loss: 0.1391, Training Loss: 0.1391, Initial Validation Loss: 0.1282, Validation Loss: 0.1282,V Acc: 0.2593, Top 70th Acc: 0.3553, Bottom 30th Acc: 0.0312
Fold [5/5] Epoch [10/100] Initial Loss: 0.1391, Training Loss: 0.0162, Initial Validation Loss: 0.1282, Validation Loss: 0.0342,V Acc: 0.8333, Top 70th Acc: 0.9211, Bottom 30th Acc: 0.6250
Fold [5/5] Epoch [20/100] Initial Loss: 0.1391, Training Loss: 0.0046, Initial Validation Loss: 0.1282, Validation Loss: 0.0306,V Acc: 0.8148, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.5000
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.9342105263157895
35 4 [array([0.3670493 , 0.12508135, 0.07550661, 0.20560813, 0.22675471],
      dtype=float32)]
Running train_nn.py with seed 36
CUDA:False
Training samples count:  550
Training on 163 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1405, Training Loss: 0.1405, Initial Validation Loss: 0.1334, Validation Loss: 0.1334,V Acc: 0.2342, Top 70th Acc: 0.2949, Bottom 30th Acc: 0.0909
Fold [1/5] Epoch [10/100] Initial Loss: 0.1405, Training Loss: 0.0139, Initial Validation Loss: 0.1334, Validation Loss: 0.0348,V Acc: 0.8288, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.6061
Fold [1/5] Epoch [20/100] Initial Loss: 0.1405, Training Loss: 0.0045, Initial Validation Loss: 0.1334, Validation Loss: 0.0330,V Acc: 0.8018, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.4242
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.9615384615384616
Fold [2/5] Epoch [0/100] Initial Loss: 0.1371, Training Loss: 0.1371, Initial Validation Loss: 0.1389, Validation Loss: 0.1389,V Acc: 0.2613, Top 70th Acc: 0.2821, Bottom 30th Acc: 0.2121
Fold [2/5] Epoch [10/100] Initial Loss: 0.1371, Training Loss: 0.0117, Initial Validation Loss: 0.1389, Validation Loss: 0.0376,V Acc: 0.8198, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.5152
Fold [2/5] Epoch [20/100] Initial Loss: 0.1371, Training Loss: 0.0044, Initial Validation Loss: 0.1389, Validation Loss: 0.0322,V Acc: 0.8559, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 27  Rolling back to Epoch (base 0): 22  Top Validation Acc: 0.9743589743589743
Fold [3/5] Epoch [0/100] Initial Loss: 0.1387, Training Loss: 0.1387, Initial Validation Loss: 0.1406, Validation Loss: 0.1406,V Acc: 0.2545, Top 70th Acc: 0.3247, Bottom 30th Acc: 0.0909
Fold [3/5] Epoch [10/100] Initial Loss: 0.1387, Training Loss: 0.0204, Initial Validation Loss: 0.1406, Validation Loss: 0.0312,V Acc: 0.8636, Top 70th Acc: 1.0000, Bottom 30th Acc: 0.5455
Fold [3/5] Epoch [20/100] Initial Loss: 0.1387, Training Loss: 0.0059, Initial Validation Loss: 0.1406, Validation Loss: 0.0220,V Acc: 0.8909, Top 70th Acc: 0.9870, Bottom 30th Acc: 0.6667
Fold [3/5] Epoch [30/100] Initial Loss: 0.1387, Training Loss: 0.0046, Initial Validation Loss: 0.1406, Validation Loss: 0.0210,V Acc: 0.9091, Top 70th Acc: 0.9870, Bottom 30th Acc: 0.7273
Stopping early at Epoch (base 0): 33  Rolling back to Epoch (base 0): 28  Top Validation Acc: 0.987012987012987
Fold [4/5] Epoch [0/100] Initial Loss: 0.1390, Training Loss: 0.1390, Initial Validation Loss: 0.1328, Validation Loss: 0.1328,V Acc: 0.2545, Top 70th Acc: 0.2857, Bottom 30th Acc: 0.1818
Fold [4/5] Epoch [10/100] Initial Loss: 0.1390, Training Loss: 0.0111, Initial Validation Loss: 0.1328, Validation Loss: 0.0308,V Acc: 0.8364, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.5455
Fold [4/5] Epoch [20/100] Initial Loss: 0.1390, Training Loss: 0.0042, Initial Validation Loss: 0.1328, Validation Loss: 0.0282,V Acc: 0.8273, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.5152
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.961038961038961
Fold [5/5] Epoch [0/100] Initial Loss: 0.1373, Training Loss: 0.1373, Initial Validation Loss: 0.1311, Validation Loss: 0.1311,V Acc: 0.3333, Top 70th Acc: 0.4211, Bottom 30th Acc: 0.1250
Fold [5/5] Epoch [10/100] Initial Loss: 0.1373, Training Loss: 0.0265, Initial Validation Loss: 0.1311, Validation Loss: 0.0407,V Acc: 0.8056, Top 70th Acc: 0.9079, Bottom 30th Acc: 0.5625
Fold [5/5] Epoch [20/100] Initial Loss: 0.1373, Training Loss: 0.0063, Initial Validation Loss: 0.1311, Validation Loss: 0.0256,V Acc: 0.8889, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.7188
Fold [5/5] Epoch [30/100] Initial Loss: 0.1373, Training Loss: 0.0045, Initial Validation Loss: 0.1311, Validation Loss: 0.0244,V Acc: 0.8889, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.7188
Fold [5/5] Epoch [40/100] Initial Loss: 0.1373, Training Loss: 0.0040, Initial Validation Loss: 0.1311, Validation Loss: 0.0233,V Acc: 0.8981, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.7500
Stopping early at Epoch (base 0): 44  Rolling back to Epoch (base 0): 39  Top Validation Acc: 0.9605263157894737
36 4 [array([0.3149784 , 0.08810155, 0.09019824, 0.1860454 , 0.32067642],
      dtype=float32)]
Running train_nn.py with seed 37
CUDA:False
Training samples count:  550
Training on 163 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1400, Training Loss: 0.1400, Initial Validation Loss: 0.1395, Validation Loss: 0.1395,V Acc: 0.2613, Top 70th Acc: 0.3205, Bottom 30th Acc: 0.1212
Fold [1/5] Epoch [10/100] Initial Loss: 0.1400, Training Loss: 0.0217, Initial Validation Loss: 0.1395, Validation Loss: 0.0365,V Acc: 0.8288, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.5152
Fold [1/5] Epoch [20/100] Initial Loss: 0.1400, Training Loss: 0.0056, Initial Validation Loss: 0.1395, Validation Loss: 0.0258,V Acc: 0.9099, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.8182
Fold [1/5] Epoch [30/100] Initial Loss: 0.1400, Training Loss: 0.0043, Initial Validation Loss: 0.1395, Validation Loss: 0.0233,V Acc: 0.9009, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.7273
Fold [1/5] Epoch [40/100] Initial Loss: 0.1400, Training Loss: 0.0039, Initial Validation Loss: 0.1395, Validation Loss: 0.0224,V Acc: 0.9009, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.7273
Fold [1/5] Epoch [50/100] Initial Loss: 0.1400, Training Loss: 0.0037, Initial Validation Loss: 0.1395, Validation Loss: 0.0221,V Acc: 0.9099, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.7576
Fold [1/5] Epoch [60/100] Initial Loss: 0.1400, Training Loss: 0.0036, Initial Validation Loss: 0.1395, Validation Loss: 0.0217,V Acc: 0.9099, Top 70th Acc: 0.9872, Bottom 30th Acc: 0.7273
Fold [1/5] Epoch [70/100] Initial Loss: 0.1400, Training Loss: 0.0036, Initial Validation Loss: 0.1395, Validation Loss: 0.0216,V Acc: 0.9009, Top 70th Acc: 0.9872, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 70  Rolling back to Epoch (base 0): 65  Top Validation Acc: 0.9871794871794872
Fold [2/5] Epoch [0/100] Initial Loss: 0.1370, Training Loss: 0.1370, Initial Validation Loss: 0.1391, Validation Loss: 0.1391,V Acc: 0.2523, Top 70th Acc: 0.3333, Bottom 30th Acc: 0.0606
Fold [2/5] Epoch [10/100] Initial Loss: 0.1370, Training Loss: 0.0211, Initial Validation Loss: 0.1391, Validation Loss: 0.0351,V Acc: 0.8649, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.6061
Fold [2/5] Epoch [20/100] Initial Loss: 0.1370, Training Loss: 0.0052, Initial Validation Loss: 0.1391, Validation Loss: 0.0230,V Acc: 0.9189, Top 70th Acc: 0.9872, Bottom 30th Acc: 0.7576
Stopping early at Epoch (base 0): 29  Rolling back to Epoch (base 0): 24  Top Validation Acc: 0.9871794871794872
Fold [3/5] Epoch [0/100] Initial Loss: 0.1421, Training Loss: 0.1421, Initial Validation Loss: 0.1331, Validation Loss: 0.1331,V Acc: 0.3727, Top 70th Acc: 0.4286, Bottom 30th Acc: 0.2424
Fold [3/5] Epoch [20/100] Initial Loss: 0.1365, Training Loss: 0.0200, Initial Validation Loss: 0.1352, Validation Loss: 0.0341,V Acc: 0.8455, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.6667
Fold [3/5] Epoch [30/100] Initial Loss: 0.1365, Training Loss: 0.0171, Initial Validation Loss: 0.1352, Validation Loss: 0.0338,V Acc: 0.8364, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.6364
Fold [3/5] Epoch [40/100] Initial Loss: 0.1365, Training Loss: 0.0161, Initial Validation Loss: 0.1352, Validation Loss: 0.0339,V Acc: 0.8273, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 40  Rolling back to Epoch (base 0): 35  Top Validation Acc: 0.922077922077922
Fold [4/5] Epoch [0/100] Initial Loss: 0.1409, Training Loss: 0.1409, Initial Validation Loss: 0.1332, Validation Loss: 0.1332,V Acc: 0.2909, Top 70th Acc: 0.2727, Bottom 30th Acc: 0.3333
Fold [4/5] Epoch [10/100] Initial Loss: 0.1409, Training Loss: 0.0305, Initial Validation Loss: 0.1332, Validation Loss: 0.0380,V Acc: 0.8182, Top 70th Acc: 0.8701, Bottom 30th Acc: 0.6970
Fold [4/5] Epoch [20/100] Initial Loss: 0.1409, Training Loss: 0.0185, Initial Validation Loss: 0.1332, Validation Loss: 0.0333,V Acc: 0.8091, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.922077922077922
Fold [5/5] Epoch [0/100] Initial Loss: 0.1378, Training Loss: 0.1378, Initial Validation Loss: 0.1355, Validation Loss: 0.1355,V Acc: 0.2685, Top 70th Acc: 0.3026, Bottom 30th Acc: 0.1875
Fold [5/5] Epoch [10/100] Initial Loss: 0.1378, Training Loss: 0.0435, Initial Validation Loss: 0.1355, Validation Loss: 0.0545,V Acc: 0.7130, Top 70th Acc: 0.8816, Bottom 30th Acc: 0.3125
Fold [5/5] Epoch [20/100] Initial Loss: 0.1378, Training Loss: 0.0195, Initial Validation Loss: 0.1355, Validation Loss: 0.0387,V Acc: 0.8241, Top 70th Acc: 0.9211, Bottom 30th Acc: 0.5938
Stopping early at Epoch (base 0): 28  Rolling back to Epoch (base 0): 23  Top Validation Acc: 0.9342105263157895
Running train_nn.py with seed 47
CUDA:False
Training samples count:  550
Training on 30 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1375, Training Loss: 0.1375, Initial Validation Loss: 0.1295, Validation Loss: 0.1295,V Acc: 0.3423, Top 70th Acc: 0.3590, Bottom 30th Acc: 0.3030
Fold [1/5] Epoch [10/100] Initial Loss: 0.1375, Training Loss: 0.0372, Initial Validation Loss: 0.1295, Validation Loss: 0.0416,V Acc: 0.8288, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.6364
Fold [1/5] Epoch [20/100] Initial Loss: 0.1375, Training Loss: 0.0186, Initial Validation Loss: 0.1295, Validation Loss: 0.0356,V Acc: 0.7748, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.4545
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.9230769230769231
Fold [2/5] Epoch [0/100] Initial Loss: 0.1370, Training Loss: 0.1370, Initial Validation Loss: 0.1385, Validation Loss: 0.1385,V Acc: 0.2883, Top 70th Acc: 0.3590, Bottom 30th Acc: 0.1212
Fold [2/5] Epoch [10/100] Initial Loss: 0.1370, Training Loss: 0.0344, Initial Validation Loss: 0.1385, Validation Loss: 0.0484,V Acc: 0.7838, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.4848
Fold [2/5] Epoch [20/100] Initial Loss: 0.1370, Training Loss: 0.0176, Initial Validation Loss: 0.1385, Validation Loss: 0.0465,V Acc: 0.7748, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.4545
Stopping early at Epoch (base 0): 22  Rolling back to Epoch (base 0): 17  Top Validation Acc: 0.9230769230769231
Fold [3/5] Epoch [0/100] Initial Loss: 0.1364, Training Loss: 0.1364, Initial Validation Loss: 0.1383, Validation Loss: 0.1383,V Acc: 0.2909, Top 70th Acc: 0.3766, Bottom 30th Acc: 0.0909
Fold [3/5] Epoch [10/100] Initial Loss: 0.1364, Training Loss: 0.0291, Initial Validation Loss: 0.1383, Validation Loss: 0.0349,V Acc: 0.8636, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.6364
Fold [3/5] Epoch [20/100] Initial Loss: 0.1364, Training Loss: 0.0190, Initial Validation Loss: 0.1383, Validation Loss: 0.0301,V Acc: 0.8545, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.5758
Fold [3/5] Epoch [30/100] Initial Loss: 0.1364, Training Loss: 0.0166, Initial Validation Loss: 0.1383, Validation Loss: 0.0294,V Acc: 0.8636, Top 70th Acc: 0.9870, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 36  Rolling back to Epoch (base 0): 31  Top Validation Acc: 0.987012987012987
Fold [4/5] Epoch [0/100] Initial Loss: 0.1383, Training Loss: 0.1383, Initial Validation Loss: 0.1300, Validation Loss: 0.1300,V Acc: 0.3091, Top 70th Acc: 0.3896, Bottom 30th Acc: 0.1212
Fold [4/5] Epoch [10/100] Initial Loss: 0.1383, Training Loss: 0.0338, Initial Validation Loss: 0.1300, Validation Loss: 0.0398,V Acc: 0.8182, Top 70th Acc: 0.8831, Bottom 30th Acc: 0.6667
Fold [4/5] Epoch [20/100] Initial Loss: 0.1383, Training Loss: 0.0201, Initial Validation Loss: 0.1300, Validation Loss: 0.0328,V Acc: 0.8364, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.8961038961038961
47 3 [array([0.5329386 , 0.20739555, 0.03373609, 0.04933113, 0.17659858],
      dtype=float32)]
Fold [5/5] Epoch [0/100] Initial Loss: 0.1390, Training Loss: 0.1390, Initial Validation Loss: 0.1306, Validation Loss: 0.1306,V Acc: 0.2500, Top 70th Acc: 0.3158, Bottom 30th Acc: 0.0938
Fold [5/5] Epoch [10/100] Initial Loss: 0.1390, Training Loss: 0.0320, Initial Validation Loss: 0.1306, Validation Loss: 0.0384,V Acc: 0.7963, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.4375
Fold [5/5] Epoch [20/100] Initial Loss: 0.1390, Training Loss: 0.0197, Initial Validation Loss: 0.1306, Validation Loss: 0.0328,V Acc: 0.8241, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.5625
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.9473684210526315
Running train_nn.py with seed 48
CUDA:False
Training samples count:  550
Training on 30 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1410, Training Loss: 0.1410, Initial Validation Loss: 0.1334, Validation Loss: 0.1334,V Acc: 0.3243, Top 70th Acc: 0.3462, Bottom 30th Acc: 0.2727
Fold [1/5] Epoch [10/100] Initial Loss: 0.1410, Training Loss: 0.0303, Initial Validation Loss: 0.1334, Validation Loss: 0.0335,V Acc: 0.7928, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.4242
Stopping early at Epoch (base 0): 19  Rolling back to Epoch (base 0): 14  Top Validation Acc: 0.9487179487179487
Fold [2/5] Epoch [0/100] Initial Loss: 0.1369, Training Loss: 0.1369, Initial Validation Loss: 0.1361, Validation Loss: 0.1361,V Acc: 0.3063, Top 70th Acc: 0.3846, Bottom 30th Acc: 0.1212
Fold [2/5] Epoch [10/100] Initial Loss: 0.1369, Training Loss: 0.0446, Initial Validation Loss: 0.1361, Validation Loss: 0.0478,V Acc: 0.8018, Top 70th Acc: 0.8846, Bottom 30th Acc: 0.6061
Fold [2/5] Epoch [20/100] Initial Loss: 0.1369, Training Loss: 0.0231, Initial Validation Loss: 0.1361, Validation Loss: 0.0270,V Acc: 0.8919, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.6970
Fold [2/5] Epoch [30/100] Initial Loss: 0.1369, Training Loss: 0.0190, Initial Validation Loss: 0.1361, Validation Loss: 0.0247,V Acc: 0.8919, Top 70th Acc: 0.9872, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 33  Rolling back to Epoch (base 0): 28  Top Validation Acc: 0.9871794871794872
48 1 [array([0.7582678 , 0.03149619, 0.06008368, 0.0895106 , 0.06064164],
      dtype=float32)]
Fold [3/5] Epoch [0/100] Initial Loss: 0.1377, Training Loss: 0.1377, Initial Validation Loss: 0.1332, Validation Loss: 0.1332,V Acc: 0.2545, Top 70th Acc: 0.2987, Bottom 30th Acc: 0.1515
Fold [3/5] Epoch [10/100] Initial Loss: 0.1377, Training Loss: 0.0321, Initial Validation Loss: 0.1332, Validation Loss: 0.0468,V Acc: 0.7818, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.4242
Fold [3/5] Epoch [20/100] Initial Loss: 0.1377, Training Loss: 0.0198, Initial Validation Loss: 0.1332, Validation Loss: 0.0449,V Acc: 0.7818, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.4242
Stopping early at Epoch (base 0): 21  Rolling back to Epoch (base 0): 16  Top Validation Acc: 0.922077922077922
Fold [4/5] Epoch [0/100] Initial Loss: 0.1383, Training Loss: 0.1383, Initial Validation Loss: 0.1317, Validation Loss: 0.1317,V Acc: 0.2909, Top 70th Acc: 0.2597, Bottom 30th Acc: 0.3636
Stopping early at Epoch (base 0): 22  Rolling back to Epoch (base 0): 17  Top Validation Acc: 0.9358974358974359
Fold [2/5] Epoch [0/100] Initial Loss: 0.1311, Training Loss: 0.1311, Initial Validation Loss: 0.1211, Validation Loss: 0.1211,V Acc: 0.4775, Top 70th Acc: 0.5769, Bottom 30th Acc: 0.2424
Fold [2/5] Epoch [10/100] Initial Loss: 0.1311, Training Loss: 0.0205, Initial Validation Loss: 0.1211, Validation Loss: 0.0404,V Acc: 0.7748, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.4545
Stopping early at Epoch (base 0): 17  Rolling back to Epoch (base 0): 12  Top Validation Acc: 0.9102564102564102
Fold [3/5] Epoch [0/100] Initial Loss: 0.1303, Training Loss: 0.1303, Initial Validation Loss: 0.1080, Validation Loss: 0.1080,V Acc: 0.4909, Top 70th Acc: 0.6234, Bottom 30th Acc: 0.1818
Fold [3/5] Epoch [10/100] Initial Loss: 0.1303, Training Loss: 0.0228, Initial Validation Loss: 0.1080, Validation Loss: 0.0259,V Acc: 0.8364, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.5455
Fold [3/5] Epoch [20/100] Initial Loss: 0.1303, Training Loss: 0.0191, Initial Validation Loss: 0.1080, Validation Loss: 0.0230,V Acc: 0.8545, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.935064935064935
Fold [4/5] Epoch [0/100] Initial Loss: 0.1317, Training Loss: 0.1317, Initial Validation Loss: 0.1239, Validation Loss: 0.1239,V Acc: 0.4182, Top 70th Acc: 0.5325, Bottom 30th Acc: 0.1515
Fold [4/5] Epoch [10/100] Initial Loss: 0.1317, Training Loss: 0.0264, Initial Validation Loss: 0.1239, Validation Loss: 0.0240,V Acc: 0.8909, Top 70th Acc: 0.9870, Bottom 30th Acc: 0.6667
Fold [4/5] Epoch [20/100] Initial Loss: 0.1317, Training Loss: 0.0201, Initial Validation Loss: 0.1239, Validation Loss: 0.0208,V Acc: 0.8909, Top 70th Acc: 1.0000, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 20  Rolling back to Epoch (base 0): 15  Top Validation Acc: 1.0
66 3 [array([0.62774384, 0.03088458, 0.03857549, 0.16751717, 0.13527897],
      dtype=float32)]
Fold [5/5] Epoch [0/100] Initial Loss: 0.1395, Training Loss: 0.1395, Initial Validation Loss: 0.1258, Validation Loss: 0.1258,V Acc: 0.2500, Top 70th Acc: 0.3553, Bottom 30th Acc: 0.0000
Fold [5/5] Epoch [10/100] Initial Loss: 0.1395, Training Loss: 0.0225, Initial Validation Loss: 0.1258, Validation Loss: 0.0301,V Acc: 0.8611, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.6562
Stopping early at Epoch (base 0): 18  Rolling back to Epoch (base 0): 13  Top Validation Acc: 0.8947368421052632
Running train_nn.py with seed 67
CUDA:False
Training samples count:  550
Training on 21 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1356, Training Loss: 0.1356, Initial Validation Loss: 0.1250, Validation Loss: 0.1250,V Acc: 0.4595, Top 70th Acc: 0.5769, Bottom 30th Acc: 0.1818
Fold [1/5] Epoch [10/100] Initial Loss: 0.1356, Training Loss: 0.0222, Initial Validation Loss: 0.1250, Validation Loss: 0.0393,V Acc: 0.7928, Top 70th Acc: 0.8846, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 13  Rolling back to Epoch (base 0): 8  Top Validation Acc: 0.9487179487179487
67 0 [array([0.6587379 , 0.04675916, 0.04325631, 0.12077244, 0.13047424],
      dtype=float32)]
Fold [2/5] Epoch [0/100] Initial Loss: 0.1313, Training Loss: 0.1313, Initial Validation Loss: 0.1136, Validation Loss: 0.1136,V Acc: 0.5315, Top 70th Acc: 0.6667, Bottom 30th Acc: 0.2121
Fold [2/5] Epoch [10/100] Initial Loss: 0.1313, Training Loss: 0.0276, Initial Validation Loss: 0.1136, Validation Loss: 0.0281,V Acc: 0.8829, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 18  Rolling back to Epoch (base 0): 13  Top Validation Acc: 0.9743589743589743
Fold [3/5] Epoch [0/100] Initial Loss: 0.1323, Training Loss: 0.1323, Initial Validation Loss: 0.1193, Validation Loss: 0.1193,V Acc: 0.4545, Top 70th Acc: 0.6104, Bottom 30th Acc: 0.0909
Fold [3/5] Epoch [10/100] Initial Loss: 0.1323, Training Loss: 0.0293, Initial Validation Loss: 0.1193, Validation Loss: 0.0348,V Acc: 0.8455, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.6364
Fold [3/5] Epoch [20/100] Initial Loss: 0.1323, Training Loss: 0.0169, Initial Validation Loss: 0.1193, Validation Loss: 0.0311,V Acc: 0.8455, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 20  Rolling back to Epoch (base 0): 15  Top Validation Acc: 0.961038961038961
Fold [4/5] Epoch [0/100] Initial Loss: 0.1306, Training Loss: 0.1306, Initial Validation Loss: 0.1179, Validation Loss: 0.1179,V Acc: 0.4455, Top 70th Acc: 0.5584, Bottom 30th Acc: 0.1818
Fold [4/5] Epoch [10/100] Initial Loss: 0.1306, Training Loss: 0.0248, Initial Validation Loss: 0.1179, Validation Loss: 0.0308,V Acc: 0.8364, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 17  Rolling back to Epoch (base 0): 12  Top Validation Acc: 0.8701298701298701
Fold [5/5] Epoch [0/100] Initial Loss: 0.1291, Training Loss: 0.1291, Initial Validation Loss: 0.1138, Validation Loss: 0.1138,V Acc: 0.5463, Top 70th Acc: 0.6316, Bottom 30th Acc: 0.3438
Fold [5/5] Epoch [10/100] Initial Loss: 0.1291, Training Loss: 0.0304, Initial Validation Loss: 0.1138, Validation Loss: 0.0268,V Acc: 0.8981, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.7812
Fold [5/5] Epoch [20/100] Initial Loss: 0.1291, Training Loss: 0.0225, Initial Validation Loss: 0.1138, Validation Loss: 0.0225,V Acc: 0.8889, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.7188
Fold [5/5] Epoch [30/100] Initial Loss: 0.1291, Training Loss: 0.0189, Initial Validation Loss: 0.1138, Validation Loss: 0.0192,V Acc: 0.8981, Top 70th Acc: 0.9868, Bottom 30th Acc: 0.6875
Stopping early at Epoch (base 0): 37  Rolling back to Epoch (base 0): 32  Top Validation Acc: 0.9868421052631579
Running train_nn.py with seed 68
CUDA:False
Training samples count:  550
Training on 21 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1371, Training Loss: 0.1371, Initial Validation Loss: 0.1322, Validation Loss: 0.1322,V Acc: 0.4685, Top 70th Acc: 0.5128, Bottom 30th Acc: 0.3636
Fold [1/5] Epoch [10/100] Initial Loss: 0.1371, Training Loss: 0.0241, Initial Validation Loss: 0.1322, Validation Loss: 0.0426,V Acc: 0.8198, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.6061
Fold [1/5] Epoch [20/100] Initial Loss: 0.1371, Training Loss: 0.0168, Initial Validation Loss: 0.1322, Validation Loss: 0.0362,V Acc: 0.8288, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 20  Rolling back to Epoch (base 0): 15  Top Validation Acc: 0.9102564102564102
Fold [2/5] Epoch [0/100] Initial Loss: 0.1317, Training Loss: 0.1317, Initial Validation Loss: 0.1221, Validation Loss: 0.1221,V Acc: 0.4234, Top 70th Acc: 0.5769, Bottom 30th Acc: 0.0606
Fold [2/5] Epoch [10/100] Initial Loss: 0.1317, Training Loss: 0.0231, Initial Validation Loss: 0.1221, Validation Loss: 0.0335,V Acc: 0.8288, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.4848
Fold [2/5] Epoch [20/100] Initial Loss: 0.1317, Training Loss: 0.0162, Initial Validation Loss: 0.1221, Validation Loss: 0.0279,V Acc: 0.8468, Top 70th Acc: 0.9872, Bottom 30th Acc: 0.5152
Fold [2/5] Epoch [30/100] Initial Loss: 0.1317, Training Loss: 0.0137, Initial Validation Loss: 0.1221, Validation Loss: 0.0259,V Acc: 0.8829, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 31  Rolling back to Epoch (base 0): 26  Top Validation Acc: 0.9871794871794872
Fold [3/5] Epoch [0/100] Initial Loss: 0.1299, Training Loss: 0.1299, Initial Validation Loss: 0.1127, Validation Loss: 0.1127,V Acc: 0.4455, Top 70th Acc: 0.5584, Bottom 30th Acc: 0.1818
Fold [3/5] Epoch [10/100] Initial Loss: 0.1299, Training Loss: 0.0234, Initial Validation Loss: 0.1127, Validation Loss: 0.0338,V Acc: 0.8455, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.6970
Fold [3/5] Epoch [20/100] Initial Loss: 0.1299, Training Loss: 0.0168, Initial Validation Loss: 0.1127, Validation Loss: 0.0300,V Acc: 0.8545, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 20  Rolling back to Epoch (base 0): 15  Top Validation Acc: 0.922077922077922
Fold [4/5] Epoch [0/100] Initial Loss: 0.1324, Training Loss: 0.1324, Initial Validation Loss: 0.1247, Validation Loss: 0.1247,V Acc: 0.7000, Top 70th Acc: 0.7273, Bottom 30th Acc: 0.6364
Fold [4/5] Epoch [40/100] Initial Loss: 0.1352, Training Loss: 0.0781, Initial Validation Loss: 0.1269, Validation Loss: 0.0764,V Acc: 0.6818, Top 70th Acc: 0.7922, Bottom 30th Acc: 0.4242
Stopping early at Epoch (base 0): 43  Rolling back to Epoch (base 0): 38  Top Validation Acc: 0.8181818181818182
Fold [5/5] Epoch [0/100] Initial Loss: 0.1367, Training Loss: 0.1367, Initial Validation Loss: 0.1319, Validation Loss: 0.1319,V Acc: 0.3611, Top 70th Acc: 0.3816, Bottom 30th Acc: 0.3125
Fold [5/5] Epoch [10/100] Initial Loss: 0.1367, Training Loss: 0.0803, Initial Validation Loss: 0.1319, Validation Loss: 0.0823,V Acc: 0.5926, Top 70th Acc: 0.7632, Bottom 30th Acc: 0.1875
Fold [5/5] Epoch [20/100] Initial Loss: 0.1367, Training Loss: 0.0779, Initial Validation Loss: 0.1319, Validation Loss: 0.0791,V Acc: 0.6204, Top 70th Acc: 0.7632, Bottom 30th Acc: 0.2812
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.7105263157894737
Running train_nn.py with seed 44
CUDA:False
Training samples count:  550
Training on 2 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1432, Training Loss: 0.1432, Initial Validation Loss: 0.1363, Validation Loss: 0.1363,V Acc: 0.2523, Top 70th Acc: 0.3590, Bottom 30th Acc: 0.0000
Fold [1/5] Epoch [10/100] Initial Loss: 0.1432, Training Loss: 0.0821, Initial Validation Loss: 0.1363, Validation Loss: 0.0844,V Acc: 0.6126, Top 70th Acc: 0.6923, Bottom 30th Acc: 0.4242
Fold [1/5] Epoch [20/100] Initial Loss: 0.1432, Training Loss: 0.0792, Initial Validation Loss: 0.1363, Validation Loss: 0.0801,V Acc: 0.6216, Top 70th Acc: 0.7564, Bottom 30th Acc: 0.3030
Fold [1/5] Epoch [30/100] Initial Loss: 0.1432, Training Loss: 0.0788, Initial Validation Loss: 0.1363, Validation Loss: 0.0792,V Acc: 0.6216, Top 70th Acc: 0.7436, Bottom 30th Acc: 0.3333
Stopping early at Epoch (base 0): 31  Rolling back to Epoch (base 0): 26  Top Validation Acc: 0.7435897435897436
Fold [2/5] Epoch [0/100] Initial Loss: 0.1361, Training Loss: 0.1361, Initial Validation Loss: 0.1321, Validation Loss: 0.1321,V Acc: 0.3694, Top 70th Acc: 0.4231, Bottom 30th Acc: 0.2424
Fold [2/5] Epoch [10/100] Initial Loss: 0.1361, Training Loss: 0.0799, Initial Validation Loss: 0.1321, Validation Loss: 0.0864,V Acc: 0.6396, Top 70th Acc: 0.7308, Bottom 30th Acc: 0.4242
Fold [2/5] Epoch [20/100] Initial Loss: 0.1361, Training Loss: 0.0774, Initial Validation Loss: 0.1321, Validation Loss: 0.0841,V Acc: 0.6486, Top 70th Acc: 0.7308, Bottom 30th Acc: 0.4545
Fold [2/5] Epoch [30/100] Initial Loss: 0.1361, Training Loss: 0.0766, Initial Validation Loss: 0.1321, Validation Loss: 0.0845,V Acc: 0.6486, Top 70th Acc: 0.7308, Bottom 30th Acc: 0.4545
Stopping early at Epoch (base 0): 30  Rolling back to Epoch (base 0): 25  Top Validation Acc: 0.7307692307692307
Fold [3/5] Epoch [0/100] Initial Loss: 0.1342, Training Loss: 0.1342, Initial Validation Loss: 0.1243, Validation Loss: 0.1243,V Acc: 0.4636, Top 70th Acc: 0.5325, Bottom 30th Acc: 0.3030
Fold [3/5] Epoch [10/100] Initial Loss: 0.1342, Training Loss: 0.0804, Initial Validation Loss: 0.1243, Validation Loss: 0.0836,V Acc: 0.5455, Top 70th Acc: 0.6883, Bottom 30th Acc: 0.2121
Fold [3/5] Epoch [20/100] Initial Loss: 0.1342, Training Loss: 0.0775, Initial Validation Loss: 0.1243, Validation Loss: 0.0839,V Acc: 0.5455, Top 70th Acc: 0.6883, Bottom 30th Acc: 0.2121
Stopping early at Epoch (base 0): 20  Rolling back to Epoch (base 0): 15  Top Validation Acc: 0.6883116883116883
44 2 [array([0.12920304, 0.3935009 , 0.14133663, 0.20224072, 0.13371873],
      dtype=float32)]
Fold [4/5] Epoch [0/100] Initial Loss: 0.1394, Training Loss: 0.1394, Initial Validation Loss: 0.1339, Validation Loss: 0.1339,V Acc: 0.2545, Top 70th Acc: 0.3247, Bottom 30th Acc: 0.0909
Fold [4/5] Epoch [10/100] Initial Loss: 0.1394, Training Loss: 0.0827, Initial Validation Loss: 0.1339, Validation Loss: 0.0741,V Acc: 0.6364, Top 70th Acc: 0.7532, Bottom 30th Acc: 0.3636
Fold [4/5] Epoch [20/100] Initial Loss: 0.1394, Training Loss: 0.0802, Initial Validation Loss: 0.1339, Validation Loss: 0.0738,V Acc: 0.6364, Top 70th Acc: 0.7403, Bottom 30th Acc: 0.3939
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.7532467532467533
Fold [5/5] Epoch [0/100] Initial Loss: 0.1356, Training Loss: 0.1356, Initial Validation Loss: 0.1263, Validation Loss: 0.1263,V Acc: 0.5648, Top 70th Acc: 0.6579, Bottom 30th Acc: 0.3438
Fold [5/5] Epoch [10/100] Initial Loss: 0.1356, Training Loss: 0.0817, Initial Validation Loss: 0.1263, Validation Loss: 0.0768,V Acc: 0.6667, Top 70th Acc: 0.7763, Bottom 30th Acc: 0.4062
Fold [5/5] Epoch [20/100] Initial Loss: 0.1356, Training Loss: 0.0798, Initial Validation Loss: 0.1263, Validation Loss: 0.0742,V Acc: 0.6944, Top 70th Acc: 0.7763, Bottom 30th Acc: 0.5000
Stopping early at Epoch (base 0): 27  Rolling back to Epoch (base 0): 22  Top Validation Acc: 0.7763157894736842
Running train_nn.py with seed 45
CUDA:False
Training samples count:  550
Training on 2 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1345, Training Loss: 0.1345, Initial Validation Loss: 0.1191, Validation Loss: 0.1191,V Acc: 0.3874, Top 70th Acc: 0.4744, Bottom 30th Acc: 0.1818
Fold [1/5] Epoch [10/100] Initial Loss: 0.1345, Training Loss: 0.0811, Initial Validation Loss: 0.1191, Validation Loss: 0.0785,V Acc: 0.6577, Top 70th Acc: 0.7179, Bottom 30th Acc: 0.5152
Fold [1/5] Epoch [20/100] Initial Loss: 0.1345, Training Loss: 0.0786, Initial Validation Loss: 0.1191, Validation Loss: 0.0776,V Acc: 0.6126, Top 70th Acc: 0.7179, Bottom 30th Acc: 0.3636
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.7435897435897436
45 0 [array([0.13898066, 0.32192135, 0.15463817, 0.2345601 , 0.14989969],
      dtype=float32)]
Fold [2/5] Epoch [0/100] Initial Loss: 0.1385, Training Loss: 0.1385, Initial Validation Loss: 0.1336, Validation Loss: 0.1336,V Acc: 0.3874, Top 70th Acc: 0.5256, Bottom 30th Acc: 0.0606
Fold [2/5] Epoch [10/100] Initial Loss: 0.1385, Training Loss: 0.0786, Initial Validation Loss: 0.1336, Validation Loss: 0.0878,V Acc: 0.5766, Top 70th Acc: 0.6795, Bottom 30th Acc: 0.3333
Fold [2/5] Epoch [20/100] Initial Loss: 0.1385, Training Loss: 0.0764, Initial Validation Loss: 0.1336, Validation Loss: 0.0862,V Acc: 0.5586, Top 70th Acc: 0.6795, Bottom 30th Acc: 0.2727
Fold [2/5] Epoch [30/100] Initial Loss: 0.1385, Training Loss: 0.0759, Initial Validation Loss: 0.1336, Validation Loss: 0.0855,V Acc: 0.5856, Top 70th Acc: 0.6923, Bottom 30th Acc: 0.3333
Stopping early at Epoch (base 0): 31  Rolling back to Epoch (base 0): 26  Top Validation Acc: 0.6923076923076923
Fold [3/5] Epoch [0/100] Initial Loss: 0.1380, Training Loss: 0.1380, Initial Validation Loss: 0.1250, Validation Loss: 0.1250,V Acc: 0.4455, Top 70th Acc: 0.6104, Bottom 30th Acc: 0.0606
Fold [3/5] Epoch [10/100] Initial Loss: 0.1380, Training Loss: 0.0832, Initial Validation Loss: 0.1250, Validation Loss: 0.0732,V Acc: 0.6364, Top 70th Acc: 0.7662, Bottom 30th Acc: 0.3333
Fold [3/5] Epoch [20/100] Initial Loss: 0.1380, Training Loss: 0.0811, Initial Validation Loss: 0.1250, Validation Loss: 0.0700,V Acc: 0.6818, Top 70th Acc: 0.7662, Bottom 30th Acc: 0.4848
Fold [3/5] Epoch [30/100] Initial Loss: 0.1380, Training Loss: 0.0803, Initial Validation Loss: 0.1250, Validation Loss: 0.0683,V Acc: 0.7091, Top 70th Acc: 0.7662, Bottom 30th Acc: 0.5758
Fold [3/5] Epoch [40/100] Initial Loss: 0.1380, Training Loss: 0.0794, Initial Validation Loss: 0.1250, Validation Loss: 0.0706,V Acc: 0.6727, Top 70th Acc: 0.7403, Bottom 30th Acc: 0.5152
Stopping early at Epoch (base 0): 40  Rolling back to Epoch (base 0): 35  Top Validation Acc: 0.7402597402597403
Fold [4/5] Epoch [0/100] Initial Loss: 0.1299, Training Loss: 0.1299, Initial Validation Loss: 0.1142, Validation Loss: 0.1142,V Acc: 0.5364, Top 70th Acc: 0.6234, Bottom 30th Acc: 0.3333
Fold [4/5] Epoch [10/100] Initial Loss: 0.1299, Training Loss: 0.0812, Initial Validation Loss: 0.1142, Validation Loss: 0.0774,V Acc: 0.6273, Top 70th Acc: 0.7922, Bottom 30th Acc: 0.2424
Fold [4/5] Epoch [20/100] Initial Loss: 0.1299, Training Loss: 0.0795, Initial Validation Loss: 0.1142, Validation Loss: 0.0758,V Acc: 0.6364, Top 70th Acc: 0.7792, Bottom 30th Acc: 0.3030
Stopping early at Epoch (base 0): 32  Rolling back to Epoch (base 0): 27  Top Validation Acc: 0.8589743589743589
Fold [2/5] Epoch [0/100] Initial Loss: 0.1355, Training Loss: 0.1355, Initial Validation Loss: 0.1363, Validation Loss: 0.1363,V Acc: 0.3423, Top 70th Acc: 0.3590, Bottom 30th Acc: 0.3030
Fold [2/5] Epoch [10/100] Initial Loss: 0.1355, Training Loss: 0.0432, Initial Validation Loss: 0.1363, Validation Loss: 0.0548,V Acc: 0.7477, Top 70th Acc: 0.8590, Bottom 30th Acc: 0.4848
Fold [2/5] Epoch [20/100] Initial Loss: 0.1355, Training Loss: 0.0234, Initial Validation Loss: 0.1363, Validation Loss: 0.0402,V Acc: 0.8288, Top 70th Acc: 0.8974, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 27  Rolling back to Epoch (base 0): 22  Top Validation Acc: 0.8974358974358975
Fold [3/5] Epoch [0/100] Initial Loss: 0.1370, Training Loss: 0.1370, Initial Validation Loss: 0.1358, Validation Loss: 0.1358,V Acc: 0.3545, Top 70th Acc: 0.4286, Bottom 30th Acc: 0.1818
Fold [3/5] Epoch [10/100] Initial Loss: 0.1370, Training Loss: 0.0320, Initial Validation Loss: 0.1358, Validation Loss: 0.0312,V Acc: 0.8909, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.7273
Fold [3/5] Epoch [20/100] Initial Loss: 0.1370, Training Loss: 0.0239, Initial Validation Loss: 0.1358, Validation Loss: 0.0261,V Acc: 0.8909, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 22  Rolling back to Epoch (base 0): 17  Top Validation Acc: 0.974025974025974
Fold [4/5] Epoch [0/100] Initial Loss: 0.1371, Training Loss: 0.1371, Initial Validation Loss: 0.1275, Validation Loss: 0.1275,V Acc: 0.3727, Top 70th Acc: 0.4935, Bottom 30th Acc: 0.0909
Fold [4/5] Epoch [10/100] Initial Loss: 0.1371, Training Loss: 0.0343, Initial Validation Loss: 0.1275, Validation Loss: 0.0394,V Acc: 0.8273, Top 70th Acc: 0.8961, Bottom 30th Acc: 0.6667
Fold [4/5] Epoch [20/100] Initial Loss: 0.1371, Training Loss: 0.0235, Initial Validation Loss: 0.1275, Validation Loss: 0.0358,V Acc: 0.8091, Top 70th Acc: 0.8961, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.8961038961038961
47 3 [array([0.3309209 , 0.14725056, 0.19488788, 0.15635352, 0.17058718],
      dtype=float32)]
Fold [5/5] Epoch [0/100] Initial Loss: 0.1440, Training Loss: 0.1440, Initial Validation Loss: 0.1323, Validation Loss: 0.1323,V Acc: 0.2407, Top 70th Acc: 0.2632, Bottom 30th Acc: 0.1875
Fold [5/5] Epoch [10/100] Initial Loss: 0.1440, Training Loss: 0.0483, Initial Validation Loss: 0.1323, Validation Loss: 0.0435,V Acc: 0.7870, Top 70th Acc: 0.8684, Bottom 30th Acc: 0.5938
Fold [5/5] Epoch [20/100] Initial Loss: 0.1440, Training Loss: 0.0259, Initial Validation Loss: 0.1323, Validation Loss: 0.0254,V Acc: 0.8796, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.7188
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.9473684210526315
Running train_nn.py with seed 48
CUDA:False
Training samples count:  550
Training on 20 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1415, Training Loss: 0.1415, Initial Validation Loss: 0.1332, Validation Loss: 0.1332,V Acc: 0.3333, Top 70th Acc: 0.3718, Bottom 30th Acc: 0.2424
Fold [1/5] Epoch [10/100] Initial Loss: 0.1415, Training Loss: 0.0458, Initial Validation Loss: 0.1332, Validation Loss: 0.0438,V Acc: 0.8018, Top 70th Acc: 0.8974, Bottom 30th Acc: 0.5758
Fold [1/5] Epoch [20/100] Initial Loss: 0.1415, Training Loss: 0.0244, Initial Validation Loss: 0.1332, Validation Loss: 0.0260,V Acc: 0.8739, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.6970
Fold [1/5] Epoch [30/100] Initial Loss: 0.1415, Training Loss: 0.0215, Initial Validation Loss: 0.1332, Validation Loss: 0.0250,V Acc: 0.9009, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.7879
Stopping early at Epoch (base 0): 32  Rolling back to Epoch (base 0): 27  Top Validation Acc: 0.9358974358974359
Fold [2/5] Epoch [0/100] Initial Loss: 0.1428, Training Loss: 0.1428, Initial Validation Loss: 0.1395, Validation Loss: 0.1395,V Acc: 0.3333, Top 70th Acc: 0.3205, Bottom 30th Acc: 0.3636
Fold [2/5] Epoch [10/100] Initial Loss: 0.1428, Training Loss: 0.0458, Initial Validation Loss: 0.1395, Validation Loss: 0.0443,V Acc: 0.8468, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.6667
Fold [2/5] Epoch [20/100] Initial Loss: 0.1428, Training Loss: 0.0265, Initial Validation Loss: 0.1395, Validation Loss: 0.0306,V Acc: 0.8919, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.7273
Fold [2/5] Epoch [30/100] Initial Loss: 0.1428, Training Loss: 0.0231, Initial Validation Loss: 0.1395, Validation Loss: 0.0288,V Acc: 0.8649, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 31  Rolling back to Epoch (base 0): 26  Top Validation Acc: 0.9615384615384616
48 1 [array([0.21631552, 0.20478228, 0.12830406, 0.3430398 , 0.10755832],
      dtype=float32)]
Fold [3/5] Epoch [0/100] Initial Loss: 0.1383, Training Loss: 0.1383, Initial Validation Loss: 0.1331, Validation Loss: 0.1331,V Acc: 0.3182, Top 70th Acc: 0.3896, Bottom 30th Acc: 0.1515
Fold [3/5] Epoch [10/100] Initial Loss: 0.1383, Training Loss: 0.0307, Initial Validation Loss: 0.1331, Validation Loss: 0.0490,V Acc: 0.7727, Top 70th Acc: 0.8571, Bottom 30th Acc: 0.5758
Fold [3/5] Epoch [20/100] Initial Loss: 0.1383, Training Loss: 0.0193, Initial Validation Loss: 0.1331, Validation Loss: 0.0456,V Acc: 0.8091, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 22  Rolling back to Epoch (base 0): 17  Top Validation Acc: 0.9090909090909091
Fold [4/5] Epoch [0/100] Initial Loss: 0.1387, Training Loss: 0.1387, Initial Validation Loss: 0.1314, Validation Loss: 0.1314,V Acc: 0.3091, Top 70th Acc: 0.3377, Bottom 30th Acc: 0.2424
Fold [4/5] Epoch [10/100] Initial Loss: 0.1387, Training Loss: 0.0316, Initial Validation Loss: 0.1314, Validation Loss: 0.0374,V Acc: 0.8182, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.6061
Fold [4/5] Epoch [20/100] Initial Loss: 0.1387, Training Loss: 0.0227, Initial Validation Loss: 0.1314, Validation Loss: 0.0330,V Acc: 0.8182, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.5758
Fold [4/5] Epoch [30/100] Initial Loss: 0.1387, Training Loss: 0.0206, Initial Validation Loss: 0.1314, Validation Loss: 0.0320,V Acc: 0.8182, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 34  Rolling back to Epoch (base 0): 29  Top Validation Acc: 0.8961038961038961
Fold [5/5] Epoch [0/100] Initial Loss: 0.1397, Training Loss: 0.1397, Initial Validation Loss: 0.1374, Validation Loss: 0.1374,V Acc: 0.2500, Top 70th Acc: 0.1974, Bottom 30th Acc: 0.3750
Fold [5/5] Epoch [10/100] Initial Loss: 0.1397, Training Loss: 0.0444, Initial Validation Loss: 0.1374, Validation Loss: 0.0432,V Acc: 0.7870, Top 70th Acc: 0.9211, Bottom 30th Acc: 0.4688
Fold [5/5] Epoch [20/100] Initial Loss: 0.1397, Training Loss: 0.0239, Initial Validation Loss: 0.1374, Validation Loss: 0.0276,V Acc: 0.8426, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.5938
Fold [5/5] Epoch [30/100] Initial Loss: 0.1397, Training Loss: 0.0207, Initial Validation Loss: 0.1374, Validation Loss: 0.0280,V Acc: 0.8426, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.5625
Stopping early at Epoch (base 0): 32  Rolling back to Epoch (base 0): 27  Top Validation Acc: 0.9473684210526315
Running train_nn.py with seed 49
CUDA:False
Training samples count:  550
Training on 20 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1390, Training Loss: 0.1390, Initial Validation Loss: 0.1308, Validation Loss: 0.1308,V Acc: 0.2613, Top 70th Acc: 0.3590, Bottom 30th Acc: 0.0303
Fold [1/5] Epoch [10/100] Initial Loss: 0.1390, Training Loss: 0.0364, Initial Validation Loss: 0.1308, Validation Loss: 0.0421,V Acc: 0.8018, Top 70th Acc: 0.8974, Bottom 30th Acc: 0.5758
Fold [1/5] Epoch [20/100] Initial Loss: 0.1390, Training Loss: 0.0236, Initial Validation Loss: 0.1308, Validation Loss: 0.0403,V Acc: 0.7838, Top 70th Acc: 0.8846, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 27  Rolling back to Epoch (base 0): 22  Top Validation Acc: 0.8974358974358975
Fold [2/5] Epoch [0/100] Initial Loss: 0.1339, Training Loss: 0.1339, Initial Validation Loss: 0.1341, Validation Loss: 0.1341,V Acc: 0.4054, Top 70th Acc: 0.5000, Bottom 30th Acc: 0.1818
Stopping early at Epoch (base 0): 36  Rolling back to Epoch (base 0): 31  Top Validation Acc: 0.9615384615384616
Fold [3/5] Epoch [0/100] Initial Loss: 0.1390, Training Loss: 0.1390, Initial Validation Loss: 0.1400, Validation Loss: 0.1400,V Acc: 0.2818, Top 70th Acc: 0.3117, Bottom 30th Acc: 0.2121
Fold [3/5] Epoch [10/100] Initial Loss: 0.1390, Training Loss: 0.0329, Initial Validation Loss: 0.1400, Validation Loss: 0.0371,V Acc: 0.8909, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.6970
Fold [3/5] Epoch [20/100] Initial Loss: 0.1390, Training Loss: 0.0143, Initial Validation Loss: 0.1400, Validation Loss: 0.0253,V Acc: 0.9091, Top 70th Acc: 1.0000, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 1.0
Fold [4/5] Epoch [0/100] Initial Loss: 0.1383, Training Loss: 0.1383, Initial Validation Loss: 0.1294, Validation Loss: 0.1294,V Acc: 0.3545, Top 70th Acc: 0.4545, Bottom 30th Acc: 0.1212
Fold [4/5] Epoch [10/100] Initial Loss: 0.1383, Training Loss: 0.0392, Initial Validation Loss: 0.1294, Validation Loss: 0.0473,V Acc: 0.7636, Top 70th Acc: 0.8701, Bottom 30th Acc: 0.5152
Fold [4/5] Epoch [20/100] Initial Loss: 0.1383, Training Loss: 0.0151, Initial Validation Loss: 0.1294, Validation Loss: 0.0301,V Acc: 0.8545, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.6667
Fold [4/5] Epoch [30/100] Initial Loss: 0.1383, Training Loss: 0.0115, Initial Validation Loss: 0.1294, Validation Loss: 0.0291,V Acc: 0.8364, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 31  Rolling back to Epoch (base 0): 26  Top Validation Acc: 0.935064935064935
47 3 [array([0.4001513 , 0.13813429, 0.04469494, 0.10682929, 0.31019023],
      dtype=float32)]
Fold [5/5] Epoch [0/100] Initial Loss: 0.1383, Training Loss: 0.1383, Initial Validation Loss: 0.1295, Validation Loss: 0.1295,V Acc: 0.2685, Top 70th Acc: 0.3289, Bottom 30th Acc: 0.1250
Fold [5/5] Epoch [10/100] Initial Loss: 0.1383, Training Loss: 0.0242, Initial Validation Loss: 0.1295, Validation Loss: 0.0310,V Acc: 0.8611, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.6875
Fold [5/5] Epoch [20/100] Initial Loss: 0.1383, Training Loss: 0.0132, Initial Validation Loss: 0.1295, Validation Loss: 0.0289,V Acc: 0.8426, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.6250
Stopping early at Epoch (base 0): 20  Rolling back to Epoch (base 0): 15  Top Validation Acc: 0.9342105263157895
Running train_nn.py with seed 48
CUDA:False
Training samples count:  550
Training on 40 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1396, Training Loss: 0.1396, Initial Validation Loss: 0.1341, Validation Loss: 0.1341,V Acc: 0.4054, Top 70th Acc: 0.4103, Bottom 30th Acc: 0.3939
Fold [1/5] Epoch [10/100] Initial Loss: 0.1396, Training Loss: 0.0375, Initial Validation Loss: 0.1341, Validation Loss: 0.0417,V Acc: 0.8198, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.6061
Fold [1/5] Epoch [20/100] Initial Loss: 0.1396, Training Loss: 0.0155, Initial Validation Loss: 0.1341, Validation Loss: 0.0330,V Acc: 0.8108, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.4848
Fold [1/5] Epoch [30/100] Initial Loss: 0.1396, Training Loss: 0.0125, Initial Validation Loss: 0.1341, Validation Loss: 0.0307,V Acc: 0.8559, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.6364
Fold [1/5] Epoch [40/100] Initial Loss: 0.1396, Training Loss: 0.0115, Initial Validation Loss: 0.1341, Validation Loss: 0.0300,V Acc: 0.8378, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 44  Rolling back to Epoch (base 0): 39  Top Validation Acc: 0.9487179487179487
Fold [2/5] Epoch [0/100] Initial Loss: 0.1375, Training Loss: 0.1375, Initial Validation Loss: 0.1380, Validation Loss: 0.1380,V Acc: 0.3694, Top 70th Acc: 0.4615, Bottom 30th Acc: 0.1515
Fold [2/5] Epoch [10/100] Initial Loss: 0.1375, Training Loss: 0.0306, Initial Validation Loss: 0.1380, Validation Loss: 0.0369,V Acc: 0.8739, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.7273
Fold [2/5] Epoch [20/100] Initial Loss: 0.1375, Training Loss: 0.0177, Initial Validation Loss: 0.1380, Validation Loss: 0.0257,V Acc: 0.9099, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.7879
Fold [2/5] Epoch [30/100] Initial Loss: 0.1375, Training Loss: 0.0150, Initial Validation Loss: 0.1380, Validation Loss: 0.0233,V Acc: 0.8919, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 35  Rolling back to Epoch (base 0): 30  Top Validation Acc: 0.9743589743589743
48 1 [array([0.6471697 , 0.03703343, 0.06397673, 0.08849769, 0.16332243],
      dtype=float32)]
Fold [3/5] Epoch [0/100] Initial Loss: 0.1386, Training Loss: 0.1386, Initial Validation Loss: 0.1325, Validation Loss: 0.1325,V Acc: 0.2727, Top 70th Acc: 0.3636, Bottom 30th Acc: 0.0606
Fold [3/5] Epoch [10/100] Initial Loss: 0.1386, Training Loss: 0.0414, Initial Validation Loss: 0.1325, Validation Loss: 0.0625,V Acc: 0.7273, Top 70th Acc: 0.7922, Bottom 30th Acc: 0.5758
Fold [3/5] Epoch [20/100] Initial Loss: 0.1386, Training Loss: 0.0159, Initial Validation Loss: 0.1325, Validation Loss: 0.0419,V Acc: 0.7909, Top 70th Acc: 0.8831, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 27  Rolling back to Epoch (base 0): 22  Top Validation Acc: 0.8961038961038961
Fold [4/5] Epoch [0/100] Initial Loss: 0.1372, Training Loss: 0.1372, Initial Validation Loss: 0.1314, Validation Loss: 0.1314,V Acc: 0.2545, Top 70th Acc: 0.3377, Bottom 30th Acc: 0.0606
Fold [4/5] Epoch [10/100] Initial Loss: 0.1372, Training Loss: 0.0301, Initial Validation Loss: 0.1314, Validation Loss: 0.0392,V Acc: 0.8091, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.5758
Fold [4/5] Epoch [20/100] Initial Loss: 0.1372, Training Loss: 0.0152, Initial Validation Loss: 0.1314, Validation Loss: 0.0308,V Acc: 0.8545, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 27  Rolling back to Epoch (base 0): 22  Top Validation Acc: 0.922077922077922
Fold [5/5] Epoch [0/100] Initial Loss: 0.1385, Training Loss: 0.1385, Initial Validation Loss: 0.1358, Validation Loss: 0.1358,V Acc: 0.2593, Top 70th Acc: 0.3421, Bottom 30th Acc: 0.0625
Fold [5/5] Epoch [10/100] Initial Loss: 0.1385, Training Loss: 0.0319, Initial Validation Loss: 0.1358, Validation Loss: 0.0364,V Acc: 0.7963, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.4375
Fold [5/5] Epoch [20/100] Initial Loss: 0.1385, Training Loss: 0.0143, Initial Validation Loss: 0.1358, Validation Loss: 0.0274,V Acc: 0.8333, Top 70th Acc: 0.9737, Bottom 30th Acc: 0.5000
Stopping early at Epoch (base 0): 27  Rolling back to Epoch (base 0): 22  Top Validation Acc: 0.9605263157894737
Running train_nn.py with seed 49
CUDA:False
Training samples count:  550
Training on 40 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1376, Training Loss: 0.1376, Initial Validation Loss: 0.1309, Validation Loss: 0.1309,V Acc: 0.2793, Top 70th Acc: 0.3077, Bottom 30th Acc: 0.2121
Fold [1/5] Epoch [10/100] Initial Loss: 0.1376, Training Loss: 0.0259, Initial Validation Loss: 0.1309, Validation Loss: 0.0362,V Acc: 0.7658, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.3636
Fold [1/5] Epoch [20/100] Initial Loss: 0.1376, Training Loss: 0.0135, Initial Validation Loss: 0.1309, Validation Loss: 0.0310,V Acc: 0.8198, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 29  Rolling back to Epoch (base 0): 24  Top Validation Acc: 0.9358974358974359
Fold [2/5] Epoch [0/100] Initial Loss: 0.1413, Training Loss: 0.1413, Initial Validation Loss: 0.1408, Validation Loss: 0.1408,V Acc: 0.2523, Top 70th Acc: 0.3462, Bottom 30th Acc: 0.0303
Fold [2/5] Epoch [10/100] Initial Loss: 0.1413, Training Loss: 0.0352, Initial Validation Loss: 0.1408, Validation Loss: 0.0384,V Acc: 0.8288, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.5758
Fold [2/5] Epoch [20/100] Initial Loss: 0.1413, Training Loss: 0.0154, Initial Validation Loss: 0.1408, Validation Loss: 0.0271,V Acc: 0.8829, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 28  Rolling back to Epoch (base 0): 23  Top Validation Acc: 0.9487179487179487
Fold [3/5] Epoch [0/100] Initial Loss: 0.1396, Training Loss: 0.1396, Initial Validation Loss: 0.1341, Validation Loss: 0.1341,V Acc: 0.2455, Top 70th Acc: 0.2987, Bottom 30th Acc: 0.1212/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)

Fold [3/5] Epoch [10/100] Initial Loss: 0.1421, Training Loss: 0.0182, Initial Validation Loss: 0.1331, Validation Loss: 0.0407,V Acc: 0.7727, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.4242
Fold [3/5] Epoch [20/100] Initial Loss: 0.1421, Training Loss: 0.0049, Initial Validation Loss: 0.1331, Validation Loss: 0.0341,V Acc: 0.8091, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.5152
Fold [3/5] Epoch [30/100] Initial Loss: 0.1421, Training Loss: 0.0037, Initial Validation Loss: 0.1331, Validation Loss: 0.0312,V Acc: 0.8364, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.5758
Fold [3/5] Epoch [40/100] Initial Loss: 0.1421, Training Loss: 0.0034, Initial Validation Loss: 0.1331, Validation Loss: 0.0310,V Acc: 0.8273, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 45  Rolling back to Epoch (base 0): 40  Top Validation Acc: 0.961038961038961
Fold [4/5] Epoch [0/100] Initial Loss: 0.1403, Training Loss: 0.1403, Initial Validation Loss: 0.1343, Validation Loss: 0.1343,V Acc: 0.2636, Top 70th Acc: 0.3377, Bottom 30th Acc: 0.0909
Fold [4/5] Epoch [10/100] Initial Loss: 0.1403, Training Loss: 0.0169, Initial Validation Loss: 0.1343, Validation Loss: 0.0509,V Acc: 0.7000, Top 70th Acc: 0.8831, Bottom 30th Acc: 0.2727
Fold [4/5] Epoch [20/100] Initial Loss: 0.1403, Training Loss: 0.0053, Initial Validation Loss: 0.1343, Validation Loss: 0.0478,V Acc: 0.7455, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.3636
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.9090909090909091
Fold [5/5] Epoch [0/100] Initial Loss: 0.1385, Training Loss: 0.1385, Initial Validation Loss: 0.1260, Validation Loss: 0.1260,V Acc: 0.3519, Top 70th Acc: 0.4342, Bottom 30th Acc: 0.1562
Fold [5/5] Epoch [10/100] Initial Loss: 0.1385, Training Loss: 0.0158, Initial Validation Loss: 0.1260, Validation Loss: 0.0338,V Acc: 0.8333, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.5625
Fold [5/5] Epoch [20/100] Initial Loss: 0.1385, Training Loss: 0.0056, Initial Validation Loss: 0.1260, Validation Loss: 0.0335,V Acc: 0.8333, Top 70th Acc: 0.9211, Bottom 30th Acc: 0.6250
Stopping early at Epoch (base 0): 20  Rolling back to Epoch (base 0): 15  Top Validation Acc: 0.9210526315789473
37 4 [array([0.15863985, 0.03579404, 0.04761848, 0.2383401 , 0.5196075 ],
      dtype=float32)]
Running train_nn.py with seed 38
CUDA:False
Training samples count:  550
Training on 163 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1381, Training Loss: 0.1381, Initial Validation Loss: 0.1349, Validation Loss: 0.1349,V Acc: 0.2793, Top 70th Acc: 0.3462, Bottom 30th Acc: 0.1212
Fold [1/5] Epoch [10/100] Initial Loss: 0.1381, Training Loss: 0.0177, Initial Validation Loss: 0.1349, Validation Loss: 0.0375,V Acc: 0.8288, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.5758
Fold [1/5] Epoch [20/100] Initial Loss: 0.1381, Training Loss: 0.0048, Initial Validation Loss: 0.1349, Validation Loss: 0.0301,V Acc: 0.8739, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.9615384615384616
Fold [2/5] Epoch [0/100] Initial Loss: 0.1388, Training Loss: 0.1388, Initial Validation Loss: 0.1318, Validation Loss: 0.1318,V Acc: 0.3604, Top 70th Acc: 0.4231, Bottom 30th Acc: 0.2121
Fold [2/5] Epoch [10/100] Initial Loss: 0.1388, Training Loss: 0.0188, Initial Validation Loss: 0.1318, Validation Loss: 0.0562,V Acc: 0.6577, Top 70th Acc: 0.7821, Bottom 30th Acc: 0.3636
Fold [2/5] Epoch [20/100] Initial Loss: 0.1388, Training Loss: 0.0053, Initial Validation Loss: 0.1318, Validation Loss: 0.0499,V Acc: 0.7207, Top 70th Acc: 0.8205, Bottom 30th Acc: 0.4848
Fold [2/5] Epoch [30/100] Initial Loss: 0.1388, Training Loss: 0.0041, Initial Validation Loss: 0.1318, Validation Loss: 0.0486,V Acc: 0.7387, Top 70th Acc: 0.8333, Bottom 30th Acc: 0.5152
Fold [2/5] Epoch [40/100] Initial Loss: 0.1388, Training Loss: 0.0036, Initial Validation Loss: 0.1318, Validation Loss: 0.0469,V Acc: 0.7387, Top 70th Acc: 0.8462, Bottom 30th Acc: 0.4848
Fold [2/5] Epoch [50/100] Initial Loss: 0.1388, Training Loss: 0.0033, Initial Validation Loss: 0.1318, Validation Loss: 0.0455,V Acc: 0.7297, Top 70th Acc: 0.8718, Bottom 30th Acc: 0.3939
Fold [2/5] Epoch [60/100] Initial Loss: 0.1388, Training Loss: 0.0031, Initial Validation Loss: 0.1318, Validation Loss: 0.0444,V Acc: 0.7387, Top 70th Acc: 0.8590, Bottom 30th Acc: 0.4545
Fold [2/5] Epoch [70/100] Initial Loss: 0.1388, Training Loss: 0.0031, Initial Validation Loss: 0.1318, Validation Loss: 0.0440,V Acc: 0.7297, Top 70th Acc: 0.8590, Bottom 30th Acc: 0.4242
Stopping early at Epoch (base 0): 76  Rolling back to Epoch (base 0): 71  Top Validation Acc: 0.8717948717948718
Fold [3/5] Epoch [0/100] Initial Loss: 0.1410, Training Loss: 0.1410, Initial Validation Loss: 0.1385, Validation Loss: 0.1385,V Acc: 0.3727, Top 70th Acc: 0.4286, Bottom 30th Acc: 0.2424
Fold [3/5] Epoch [10/100] Initial Loss: 0.1410, Training Loss: 0.0133, Initial Validation Loss: 0.1385, Validation Loss: 0.0317,V Acc: 0.8636, Top 70th Acc: 0.9870, Bottom 30th Acc: 0.5758
Fold [3/5] Epoch [20/100] Initial Loss: 0.1410, Training Loss: 0.0047, Initial Validation Loss: 0.1385, Validation Loss: 0.0260,V Acc: 0.8636, Top 70th Acc: 0.9870, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.987012987012987
Fold [4/5] Epoch [0/100] Initial Loss: 0.1392, Training Loss: 0.1392, Initial Validation Loss: 0.1350, Validation Loss: 0.1350,V Acc: 0.2727, Top 70th Acc: 0.3377, Bottom 30th Acc: 0.1212
Fold [4/5] Epoch [10/100] Initial Loss: 0.1392, Training Loss: 0.0225, Initial Validation Loss: 0.1350, Validation Loss: 0.0295,V Acc: 0.8818, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.6667
Fold [4/5] Epoch [20/100] Initial Loss: 0.1392, Training Loss: 0.0052, Initial Validation Loss: 0.1350, Validation Loss: 0.0206,V Acc: 0.9091, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.7879
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.961038961038961
Fold [5/5] Epoch [0/100] Initial Loss: 0.1390, Training Loss: 0.1390, Initial Validation Loss: 0.1294, Validation Loss: 0.1294,V Acc: 0.3333, Top 70th Acc: 0.4079, Bottom 30th Acc: 0.1562
Fold [5/5] Epoch [10/100] Initial Loss: 0.1390, Training Loss: 0.0263, Initial Validation Loss: 0.1294, Validation Loss: 0.0411,V Acc: 0.7685, Top 70th Acc: 0.8816, Bottom 30th Acc: 0.5000
Fold [5/5] Epoch [20/100] Initial Loss: 0.1390, Training Loss: 0.0061, Initial Validation Loss: 0.1294, Validation Loss: 0.0319,V Acc: 0.8426, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.5625
Fold [5/5] Epoch [30/100] Initial Loss: 0.1390, Training Loss: 0.0044, Initial Validation Loss: 0.1294, Validation Loss: 0.0313,V Acc: 0.8333, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.5938
Fold [5/5] Epoch [40/100] Initial Loss: 0.1390, Training Loss: 0.0039, Initial Validation Loss: 0.1294, Validation Loss: 0.0306,V Acc: 0.8426, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.5938
Fold [5/5] Epoch [50/100] Initial Loss: 0.1390, Training Loss: 0.0036, Initial Validation Loss: 0.1294, Validation Loss: 0.0303,V Acc: 0.8333, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.5312
Fold [5/5] Epoch [60/100] Initial Loss: 0.1390, Training Loss: 0.0035, Initial Validation Loss: 0.1294, Validation Loss: 0.0296,V Acc: 0.8241, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.5000
Fold [5/5] Epoch [70/100] Initial Loss: 0.1390, Training Loss: 0.0034, Initial Validation Loss: 0.1294, Validation Loss: 0.0295,V Acc: 0.8333, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.5312
Stopping early at Epoch (base 0): 78  Rolling back to Epoch (base 0): 73  Top Validation Acc: 0.9605263157894737
38 4 [array([0.23521966, 0.04440918, 0.09646215, 0.29800102, 0.32590804],
      dtype=float32)]
Running train_nn.py with seed 39
CUDA:False
Training samples count:  550
Training on 163 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1389, Training Loss: 0.1389, Initial Validation Loss: 0.1344, Validation Loss: 0.1344,V Acc: 0.3423, Top 70th Acc: 0.4231, Bottom 30th Acc: 0.1515
Fold [1/5] Epoch [10/100] Initial Loss: 0.1389, Training Loss: 0.0163, Initial Validation Loss: 0.1344, Validation Loss: 0.0352,V Acc: 0.8288, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.5758
Fold [4/5] Epoch [10/100] Initial Loss: 0.1383, Training Loss: 0.0341, Initial Validation Loss: 0.1317, Validation Loss: 0.0409,V Acc: 0.8000, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.5152
Fold [4/5] Epoch [20/100] Initial Loss: 0.1383, Training Loss: 0.0204, Initial Validation Loss: 0.1317, Validation Loss: 0.0342,V Acc: 0.8182, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.5455
Fold [4/5] Epoch [30/100] Initial Loss: 0.1383, Training Loss: 0.0166, Initial Validation Loss: 0.1317, Validation Loss: 0.0331,V Acc: 0.8273, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 33  Rolling back to Epoch (base 0): 28  Top Validation Acc: 0.935064935064935
Fold [5/5] Epoch [0/100] Initial Loss: 0.1369, Training Loss: 0.1369, Initial Validation Loss: 0.1355, Validation Loss: 0.1355,V Acc: 0.3148, Top 70th Acc: 0.3026, Bottom 30th Acc: 0.3438
Fold [5/5] Epoch [10/100] Initial Loss: 0.1369, Training Loss: 0.0461, Initial Validation Loss: 0.1355, Validation Loss: 0.0444,V Acc: 0.8056, Top 70th Acc: 0.8947, Bottom 30th Acc: 0.5938
Fold [5/5] Epoch [20/100] Initial Loss: 0.1369, Training Loss: 0.0215, Initial Validation Loss: 0.1355, Validation Loss: 0.0284,V Acc: 0.8333, Top 70th Acc: 0.9868, Bottom 30th Acc: 0.4688
Fold [5/5] Epoch [30/100] Initial Loss: 0.1369, Training Loss: 0.0172, Initial Validation Loss: 0.1355, Validation Loss: 0.0267,V Acc: 0.8241, Top 70th Acc: 0.9737, Bottom 30th Acc: 0.4688
Stopping early at Epoch (base 0): 30  Rolling back to Epoch (base 0): 25  Top Validation Acc: 0.9736842105263158
Running train_nn.py with seed 49
CUDA:False
Training samples count:  550
Training on 30 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1397, Training Loss: 0.1397, Initial Validation Loss: 0.1311, Validation Loss: 0.1311,V Acc: 0.2883, Top 70th Acc: 0.3590, Bottom 30th Acc: 0.1212
Fold [1/5] Epoch [10/100] Initial Loss: 0.1397, Training Loss: 0.0290, Initial Validation Loss: 0.1311, Validation Loss: 0.0346,V Acc: 0.8198, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.4848
Stopping early at Epoch (base 0): 19  Rolling back to Epoch (base 0): 14  Top Validation Acc: 0.9487179487179487
Fold [2/5] Epoch [0/100] Initial Loss: 0.1404, Training Loss: 0.1404, Initial Validation Loss: 0.1391, Validation Loss: 0.1391,V Acc: 0.4595, Top 70th Acc: 0.5385, Bottom 30th Acc: 0.2727
Fold [2/5] Epoch [10/100] Initial Loss: 0.1404, Training Loss: 0.0341, Initial Validation Loss: 0.1391, Validation Loss: 0.0389,V Acc: 0.8108, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.4848
Fold [2/5] Epoch [20/100] Initial Loss: 0.1404, Training Loss: 0.0206, Initial Validation Loss: 0.1391, Validation Loss: 0.0317,V Acc: 0.8739, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.7576
Stopping early at Epoch (base 0): 27  Rolling back to Epoch (base 0): 22  Top Validation Acc: 0.9230769230769231
Fold [3/5] Epoch [0/100] Initial Loss: 0.1385, Training Loss: 0.1385, Initial Validation Loss: 0.1351, Validation Loss: 0.1351,V Acc: 0.2545, Top 70th Acc: 0.2597, Bottom 30th Acc: 0.2424
Fold [3/5] Epoch [10/100] Initial Loss: 0.1385, Training Loss: 0.0358, Initial Validation Loss: 0.1351, Validation Loss: 0.0453,V Acc: 0.7636, Top 70th Acc: 0.8961, Bottom 30th Acc: 0.4545
Fold [3/5] Epoch [20/100] Initial Loss: 0.1385, Training Loss: 0.0189, Initial Validation Loss: 0.1351, Validation Loss: 0.0360,V Acc: 0.8455, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.9090909090909091
Fold [4/5] Epoch [0/100] Initial Loss: 0.1421, Training Loss: 0.1421, Initial Validation Loss: 0.1352, Validation Loss: 0.1352,V Acc: 0.2727, Top 70th Acc: 0.2987, Bottom 30th Acc: 0.2121
Fold [4/5] Epoch [10/100] Initial Loss: 0.1421, Training Loss: 0.0442, Initial Validation Loss: 0.1352, Validation Loss: 0.0487,V Acc: 0.7636, Top 70th Acc: 0.8701, Bottom 30th Acc: 0.5152
Fold [4/5] Epoch [20/100] Initial Loss: 0.1421, Training Loss: 0.0189, Initial Validation Loss: 0.1352, Validation Loss: 0.0348,V Acc: 0.8182, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 22  Rolling back to Epoch (base 0): 17  Top Validation Acc: 0.948051948051948
Fold [5/5] Epoch [0/100] Initial Loss: 0.1378, Training Loss: 0.1378, Initial Validation Loss: 0.1307, Validation Loss: 0.1307,V Acc: 0.3611, Top 70th Acc: 0.4342, Bottom 30th Acc: 0.1875
Fold [5/5] Epoch [10/100] Initial Loss: 0.1378, Training Loss: 0.0300, Initial Validation Loss: 0.1307, Validation Loss: 0.0391,V Acc: 0.7963, Top 70th Acc: 0.9211, Bottom 30th Acc: 0.5000
Fold [5/5] Epoch [20/100] Initial Loss: 0.1378, Training Loss: 0.0191, Initial Validation Loss: 0.1307, Validation Loss: 0.0353,V Acc: 0.7870, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.4062
Stopping early at Epoch (base 0): 28  Rolling back to Epoch (base 0): 23  Top Validation Acc: 0.9210526315789473
49 4 [array([0.57426363, 0.16497046, 0.07020807, 0.07561039, 0.11494734],
      dtype=float32)]
Running train_nn.py with seed 50
CUDA:False
Training samples count:  550
Training on 30 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1366, Training Loss: 0.1366, Initial Validation Loss: 0.1366, Validation Loss: 0.1366,V Acc: 0.3604, Top 70th Acc: 0.3974, Bottom 30th Acc: 0.2727
Fold [1/5] Epoch [10/100] Initial Loss: 0.1366, Training Loss: 0.0292, Initial Validation Loss: 0.1366, Validation Loss: 0.0337,V Acc: 0.8378, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.5455
Fold [1/5] Epoch [20/100] Initial Loss: 0.1366, Training Loss: 0.0185, Initial Validation Loss: 0.1366, Validation Loss: 0.0285,V Acc: 0.8468, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.9615384615384616
Fold [2/5] Epoch [0/100] Initial Loss: 0.1349, Training Loss: 0.1349, Initial Validation Loss: 0.1283, Validation Loss: 0.1283,V Acc: 0.2883, Top 70th Acc: 0.3718, Bottom 30th Acc: 0.0909
Fold [2/5] Epoch [10/100] Initial Loss: 0.1349, Training Loss: 0.0348, Initial Validation Loss: 0.1283, Validation Loss: 0.0447,V Acc: 0.7568, Top 70th Acc: 0.8718, Bottom 30th Acc: 0.4848
Fold [2/5] Epoch [20/100] Initial Loss: 0.1349, Training Loss: 0.0178, Initial Validation Loss: 0.1283, Validation Loss: 0.0361,V Acc: 0.8378, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 28  Rolling back to Epoch (base 0): 23  Top Validation Acc: 0.9102564102564102
Fold [3/5] Epoch [0/100] Initial Loss: 0.1383, Training Loss: 0.1383, Initial Validation Loss: 0.1334, Validation Loss: 0.1334,V Acc: 0.4636, Top 70th Acc: 0.5844, Bottom 30th Acc: 0.1818
Fold [3/5] Epoch [10/100] Initial Loss: 0.1383, Training Loss: 0.0264, Initial Validation Loss: 0.1334, Validation Loss: 0.0320,V Acc: 0.8818, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 16  Rolling back to Epoch (base 0): 11  Top Validation Acc: 0.948051948051948
Fold [4/5] Epoch [0/100] Initial Loss: 0.1369, Training Loss: 0.1369, Initial Validation Loss: 0.1274, Validation Loss: 0.1274,V Acc: 0.4182, Top 70th Acc: 0.4935, Bottom 30th Acc: 0.2424
Fold [4/5] Epoch [10/100] Initial Loss: 0.1369, Training Loss: 0.0344, Initial Validation Loss: 0.1274, Validation Loss: 0.0373,V Acc: 0.8091, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.4848
Fold [4/5] Epoch [20/100] Initial Loss: 0.1369, Training Loss: 0.0194, Initial Validation Loss: 0.1274, Validation Loss: 0.0290,V Acc: 0.8182, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.4545
Fold [4/5] Epoch [30/100] Initial Loss: 0.1369, Training Loss: 0.0164, Initial Validation Loss: 0.1274, Validation Loss: 0.0267,V Acc: 0.8364, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 35  Rolling back to Epoch (base 0): 30  Top Validation Acc: 0.961038961038961
Fold [5/5] Epoch [0/100] Initial Loss: 0.1403, Training Loss: 0.1403, Initial Validation Loss: 0.1316, Validation Loss: 0.1316,V Acc: 0.2500, Top 70th Acc: 0.3289, Bottom 30th Acc: 0.0625
Fold [5/5] Epoch [10/100] Initial Loss: 0.1403, Training Loss: 0.0404, Initial Validation Loss: 0.1316, Validation Loss: 0.0464,V Acc: 0.7870, Top 70th Acc: 0.8553, Bottom 30th Acc: 0.6250
Fold [5/5] Epoch [20/100] Initial Loss: 0.1403, Training Loss: 0.0186, Initial Validation Loss: 0.1316, Validation Loss: 0.0318,V Acc: 0.8426, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.6250
Fold [4/5] Epoch [10/100] Initial Loss: 0.1324, Training Loss: 0.0261, Initial Validation Loss: 0.1247, Validation Loss: 0.0264,V Acc: 0.8818, Top 70th Acc: 0.9870, Bottom 30th Acc: 0.6364
Fold [4/5] Epoch [20/100] Initial Loss: 0.1324, Training Loss: 0.0205, Initial Validation Loss: 0.1247, Validation Loss: 0.0206,V Acc: 0.9000, Top 70th Acc: 1.0000, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 28  Rolling back to Epoch (base 0): 23  Top Validation Acc: 1.0
Fold [5/5] Epoch [0/100] Initial Loss: 0.1314, Training Loss: 0.1314, Initial Validation Loss: 0.1135, Validation Loss: 0.1135,V Acc: 0.5370, Top 70th Acc: 0.6711, Bottom 30th Acc: 0.2188
Fold [5/5] Epoch [10/100] Initial Loss: 0.1314, Training Loss: 0.0222, Initial Validation Loss: 0.1135, Validation Loss: 0.0346,V Acc: 0.8426, Top 70th Acc: 0.9079, Bottom 30th Acc: 0.6875
Fold [5/5] Epoch [20/100] Initial Loss: 0.1314, Training Loss: 0.0169, Initial Validation Loss: 0.1135, Validation Loss: 0.0239,V Acc: 0.8981, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.7500
Stopping early at Epoch (base 0): 27  Rolling back to Epoch (base 0): 22  Top Validation Acc: 0.9605263157894737
68 4 [array([0.7431694 , 0.02154211, 0.02271118, 0.08361505, 0.12896225],
      dtype=float32)]
Running train_nn.py with seed 69
CUDA:False
Training samples count:  550
Training on 21 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1373, Training Loss: 0.1373, Initial Validation Loss: 0.1247, Validation Loss: 0.1247,V Acc: 0.4865, Top 70th Acc: 0.6154, Bottom 30th Acc: 0.1818
Fold [1/5] Epoch [10/100] Initial Loss: 0.1373, Training Loss: 0.0231, Initial Validation Loss: 0.1247, Validation Loss: 0.0341,V Acc: 0.8288, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.5152
Stopping early at Epoch (base 0): 14  Rolling back to Epoch (base 0): 9  Top Validation Acc: 0.9487179487179487
69 0 [array([0.7335596 , 0.02048633, 0.05864107, 0.08920624, 0.09810675],
      dtype=float32)]
Fold [2/5] Epoch [0/100] Initial Loss: 0.1309, Training Loss: 0.1309, Initial Validation Loss: 0.1253, Validation Loss: 0.1253,V Acc: 0.5045, Top 70th Acc: 0.6026, Bottom 30th Acc: 0.2727
Fold [2/5] Epoch [10/100] Initial Loss: 0.1309, Training Loss: 0.0242, Initial Validation Loss: 0.1253, Validation Loss: 0.0285,V Acc: 0.8739, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 15  Rolling back to Epoch (base 0): 10  Top Validation Acc: 0.9358974358974359
Fold [3/5] Epoch [0/100] Initial Loss: 0.1309, Training Loss: 0.1309, Initial Validation Loss: 0.1137, Validation Loss: 0.1137,V Acc: 0.4455, Top 70th Acc: 0.5844, Bottom 30th Acc: 0.1212
Fold [3/5] Epoch [10/100] Initial Loss: 0.1309, Training Loss: 0.0255, Initial Validation Loss: 0.1137, Validation Loss: 0.0307,V Acc: 0.8364, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.5758
Fold [3/5] Epoch [20/100] Initial Loss: 0.1309, Training Loss: 0.0176, Initial Validation Loss: 0.1137, Validation Loss: 0.0222,V Acc: 0.9000, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.7273
Stopping early at Epoch (base 0): 22  Rolling back to Epoch (base 0): 17  Top Validation Acc: 0.961038961038961
Fold [4/5] Epoch [0/100] Initial Loss: 0.1280, Training Loss: 0.1280, Initial Validation Loss: 0.1167, Validation Loss: 0.1167,V Acc: 0.4545, Top 70th Acc: 0.5844, Bottom 30th Acc: 0.1515
Fold [4/5] Epoch [10/100] Initial Loss: 0.1280, Training Loss: 0.0303, Initial Validation Loss: 0.1167, Validation Loss: 0.0364,V Acc: 0.8545, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 18  Rolling back to Epoch (base 0): 13  Top Validation Acc: 0.935064935064935
Fold [5/5] Epoch [0/100] Initial Loss: 0.1361, Training Loss: 0.1361, Initial Validation Loss: 0.1258, Validation Loss: 0.1258,V Acc: 0.2963, Top 70th Acc: 0.3947, Bottom 30th Acc: 0.0625
Fold [5/5] Epoch [10/100] Initial Loss: 0.1361, Training Loss: 0.0257, Initial Validation Loss: 0.1258, Validation Loss: 0.0287,V Acc: 0.8426, Top 70th Acc: 0.9868, Bottom 30th Acc: 0.5000
Fold [5/5] Epoch [20/100] Initial Loss: 0.1361, Training Loss: 0.0197, Initial Validation Loss: 0.1258, Validation Loss: 0.0394,V Acc: 0.8056, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.4688
Stopping early at Epoch (base 0): 22  Rolling back to Epoch (base 0): 17  Top Validation Acc: 0.9736842105263158
Running train_nn.py with seed 70
CUDA:False
Training samples count:  550
Training on 21 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1334, Training Loss: 0.1334, Initial Validation Loss: 0.1233, Validation Loss: 0.1233,V Acc: 0.4775, Top 70th Acc: 0.4744, Bottom 30th Acc: 0.4848
Fold [1/5] Epoch [10/100] Initial Loss: 0.1334, Training Loss: 0.0228, Initial Validation Loss: 0.1233, Validation Loss: 0.0262,V Acc: 0.9009, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.7273
Fold [1/5] Epoch [20/100] Initial Loss: 0.1334, Training Loss: 0.0162, Initial Validation Loss: 0.1233, Validation Loss: 0.0297,V Acc: 0.8829, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.7273
Stopping early at Epoch (base 0): 21  Rolling back to Epoch (base 0): 16  Top Validation Acc: 0.9743589743589743
Fold [2/5] Epoch [0/100] Initial Loss: 0.1359, Training Loss: 0.1359, Initial Validation Loss: 0.1196, Validation Loss: 0.1196,V Acc: 0.4414, Top 70th Acc: 0.6026, Bottom 30th Acc: 0.0606
Fold [2/5] Epoch [10/100] Initial Loss: 0.1359, Training Loss: 0.0247, Initial Validation Loss: 0.1196, Validation Loss: 0.0243,V Acc: 0.9009, Top 70th Acc: 0.9872, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 17  Rolling back to Epoch (base 0): 12  Top Validation Acc: 0.9615384615384616
70 1 [array([0.73898816, 0.02470426, 0.030861  , 0.12385131, 0.0815952 ],
      dtype=float32)]
Fold [3/5] Epoch [0/100] Initial Loss: 0.1296, Training Loss: 0.1296, Initial Validation Loss: 0.1150, Validation Loss: 0.1150,V Acc: 0.4909, Top 70th Acc: 0.6104, Bottom 30th Acc: 0.2121
Fold [3/5] Epoch [10/100] Initial Loss: 0.1296, Training Loss: 0.0222, Initial Validation Loss: 0.1150, Validation Loss: 0.0293,V Acc: 0.8727, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 19  Rolling back to Epoch (base 0): 14  Top Validation Acc: 0.948051948051948
Fold [4/5] Epoch [0/100] Initial Loss: 0.1323, Training Loss: 0.1323, Initial Validation Loss: 0.1282, Validation Loss: 0.1282,V Acc: 0.4636, Top 70th Acc: 0.5714, Bottom 30th Acc: 0.2121
Fold [4/5] Epoch [10/100] Initial Loss: 0.1323, Training Loss: 0.0278, Initial Validation Loss: 0.1282, Validation Loss: 0.0307,V Acc: 0.8909, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.7273
Fold [4/5] Epoch [20/100] Initial Loss: 0.1323, Training Loss: 0.0194, Initial Validation Loss: 0.1282, Validation Loss: 0.0255,V Acc: 0.9091, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.7879
Fold [4/5] Epoch [30/100] Initial Loss: 0.1323, Training Loss: 0.0165, Initial Validation Loss: 0.1282, Validation Loss: 0.0288,V Acc: 0.8727, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 33  Rolling back to Epoch (base 0): 28  Top Validation Acc: 0.987012987012987
Fold [5/5] Epoch [0/100] Initial Loss: 0.1382, Training Loss: 0.1382, Initial Validation Loss: 0.1179, Validation Loss: 0.1179,V Acc: 0.4444, Top 70th Acc: 0.5921, Bottom 30th Acc: 0.0938
Fold [5/5] Epoch [10/100] Initial Loss: 0.1382, Training Loss: 0.0275, Initial Validation Loss: 0.1179, Validation Loss: 0.0338,V Acc: 0.7870, Top 70th Acc: 0.8947, Bottom 30th Acc: 0.5312
Fold [5/5] Epoch [20/100] Initial Loss: 0.1382, Training Loss: 0.0180, Initial Validation Loss: 0.1179, Validation Loss: 0.0316,V Acc: 0.7870, Top 70th Acc: 0.9079, Bottom 30th Acc: 0.5000
Stopping early at Epoch (base 0): 22  Rolling back to Epoch (base 0): 17  Top Validation Acc: 0.9078947368421053
Running train_nn.py with seed 71
CUDA:False
Training samples count:  550
Training on 21 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1383, Training Loss: 0.1383, Initial Validation Loss: 0.1316, Validation Loss: 0.1316,V Acc: 0.4955, Top 70th Acc: 0.5385, Bottom 30th Acc: 0.3939
Fold [1/5] Epoch [10/100] Initial Loss: 0.1383, Training Loss: 0.0293, Initial Validation Loss: 0.1316, Validation Loss: 0.0241,V Acc: 0.9189, Top 70th Acc: 0.9872, Bottom 30th Acc: 0.7576
Stopping early at Epoch (base 0): 19  Rolling back to Epoch (base 0):
Fold [4/5] Epoch [30/100] Initial Loss: 0.1299, Training Loss: 0.0786, Initial Validation Loss: 0.1142, Validation Loss: 0.0755,V Acc: 0.6364, Top 70th Acc: 0.7662, Bottom 30th Acc: 0.3333
Stopping early at Epoch (base 0): 32  Rolling back to Epoch (base 0): 27  Top Validation Acc: 0.7662337662337663
Fold [5/5] Epoch [0/100] Initial Loss: 0.1321, Training Loss: 0.1321, Initial Validation Loss: 0.1263, Validation Loss: 0.1263,V Acc: 0.3981, Top 70th Acc: 0.4079, Bottom 30th Acc: 0.3750
Fold [5/5] Epoch [10/100] Initial Loss: 0.1321, Training Loss: 0.0798, Initial Validation Loss: 0.1263, Validation Loss: 0.0860,V Acc: 0.6111, Top 70th Acc: 0.7105, Bottom 30th Acc: 0.3750
Fold [5/5] Epoch [20/100] Initial Loss: 0.1321, Training Loss: 0.0775, Initial Validation Loss: 0.1263, Validation Loss: 0.0840,V Acc: 0.6019, Top 70th Acc: 0.6974, Bottom 30th Acc: 0.3750
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.7236842105263158
Running train_nn.py with seed 46
CUDA:False
Training samples count:  550
Training on 2 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1433, Training Loss: 0.1433, Initial Validation Loss: 0.1362, Validation Loss: 0.1362,V Acc: 0.2342, Top 70th Acc: 0.2949, Bottom 30th Acc: 0.0909
Fold [1/5] Epoch [10/100] Initial Loss: 0.1433, Training Loss: 0.0823, Initial Validation Loss: 0.1362, Validation Loss: 0.0847,V Acc: 0.5856, Top 70th Acc: 0.7308, Bottom 30th Acc: 0.2424
Fold [1/5] Epoch [20/100] Initial Loss: 0.1433, Training Loss: 0.0787, Initial Validation Loss: 0.1362, Validation Loss: 0.0823,V Acc: 0.5856, Top 70th Acc: 0.7179, Bottom 30th Acc: 0.2727
Fold [1/5] Epoch [30/100] Initial Loss: 0.1433, Training Loss: 0.0769, Initial Validation Loss: 0.1362, Validation Loss: 0.0815,V Acc: 0.5766, Top 70th Acc: 0.7179, Bottom 30th Acc: 0.2424
Fold [1/5] Epoch [40/100] Initial Loss: 0.1433, Training Loss: 0.0763, Initial Validation Loss: 0.1362, Validation Loss: 0.0813,V Acc: 0.5586, Top 70th Acc: 0.7051, Bottom 30th Acc: 0.2121
Fold [1/5] Epoch [50/100] Initial Loss: 0.1433, Training Loss: 0.0762, Initial Validation Loss: 0.1362, Validation Loss: 0.0803,V Acc: 0.5946, Top 70th Acc: 0.7051, Bottom 30th Acc: 0.3333
Fold [1/5] Epoch [60/100] Initial Loss: 0.1433, Training Loss: 0.0758, Initial Validation Loss: 0.1362, Validation Loss: 0.0803,V Acc: 0.6036, Top 70th Acc: 0.7179, Bottom 30th Acc: 0.3333
Stopping early at Epoch (base 0): 63  Rolling back to Epoch (base 0): 58  Top Validation Acc: 0.6923076923076923
46 0 [array([0.13460825, 0.3526602 , 0.12068295, 0.2642971 , 0.12775147],
      dtype=float32)]
Fold [2/5] Epoch [0/100] Initial Loss: 0.1387, Training Loss: 0.1387, Initial Validation Loss: 0.1286, Validation Loss: 0.1286,V Acc: 0.4865, Top 70th Acc: 0.5641, Bottom 30th Acc: 0.3030
Fold [2/5] Epoch [10/100] Initial Loss: 0.1387, Training Loss: 0.0846, Initial Validation Loss: 0.1286, Validation Loss: 0.0742,V Acc: 0.6306, Top 70th Acc: 0.7692, Bottom 30th Acc: 0.3030
Fold [2/5] Epoch [20/100] Initial Loss: 0.1387, Training Loss: 0.0822, Initial Validation Loss: 0.1286, Validation Loss: 0.0709,V Acc: 0.6396, Top 70th Acc: 0.7692, Bottom 30th Acc: 0.3333
Stopping early at Epoch (base 0): 27  Rolling back to Epoch (base 0): 22  Top Validation Acc: 0.782051282051282
Fold [3/5] Epoch [0/100] Initial Loss: 0.1350, Training Loss: 0.1350, Initial Validation Loss: 0.1302, Validation Loss: 0.1302,V Acc: 0.4182, Top 70th Acc: 0.5195, Bottom 30th Acc: 0.1818
Fold [3/5] Epoch [10/100] Initial Loss: 0.1350, Training Loss: 0.0807, Initial Validation Loss: 0.1302, Validation Loss: 0.0794,V Acc: 0.6364, Top 70th Acc: 0.7662, Bottom 30th Acc: 0.3333
Fold [3/5] Epoch [20/100] Initial Loss: 0.1350, Training Loss: 0.0786, Initial Validation Loss: 0.1302, Validation Loss: 0.0790,V Acc: 0.6455, Top 70th Acc: 0.7532, Bottom 30th Acc: 0.3939
Fold [3/5] Epoch [30/100] Initial Loss: 0.1350, Training Loss: 0.0776, Initial Validation Loss: 0.1302, Validation Loss: 0.0777,V Acc: 0.6455, Top 70th Acc: 0.7532, Bottom 30th Acc: 0.3939
Stopping early at Epoch (base 0): 30  Rolling back to Epoch (base 0): 25  Top Validation Acc: 0.7532467532467533
Fold [4/5] Epoch [0/100] Initial Loss: 0.1353, Training Loss: 0.1353, Initial Validation Loss: 0.1240, Validation Loss: 0.1240,V Acc: 0.3091, Top 70th Acc: 0.3896, Bottom 30th Acc: 0.1212
Fold [4/5] Epoch [10/100] Initial Loss: 0.1353, Training Loss: 0.0805, Initial Validation Loss: 0.1240, Validation Loss: 0.0802,V Acc: 0.6182, Top 70th Acc: 0.7143, Bottom 30th Acc: 0.3939
Fold [4/5] Epoch [20/100] Initial Loss: 0.1353, Training Loss: 0.0787, Initial Validation Loss: 0.1240, Validation Loss: 0.0785,V Acc: 0.6273, Top 70th Acc: 0.7273, Bottom 30th Acc: 0.3939
Fold [4/5] Epoch [30/100] Initial Loss: 0.1353, Training Loss: 0.0781, Initial Validation Loss: 0.1240, Validation Loss: 0.0778,V Acc: 0.6273, Top 70th Acc: 0.7273, Bottom 30th Acc: 0.3939
Stopping early at Epoch (base 0): 38  Rolling back to Epoch (base 0): 33  Top Validation Acc: 0.7142857142857143
Fold [5/5] Epoch [0/100] Initial Loss: 0.1353, Training Loss: 0.1353, Initial Validation Loss: 0.1292, Validation Loss: 0.1292,V Acc: 0.3796, Top 70th Acc: 0.4079, Bottom 30th Acc: 0.3125
Fold [5/5] Epoch [10/100] Initial Loss: 0.1353, Training Loss: 0.0782, Initial Validation Loss: 0.1292, Validation Loss: 0.0872,V Acc: 0.6204, Top 70th Acc: 0.7105, Bottom 30th Acc: 0.4062
Fold [5/5] Epoch [20/100] Initial Loss: 0.1353, Training Loss: 0.0761, Initial Validation Loss: 0.1292, Validation Loss: 0.0862,V Acc: 0.6574, Top 70th Acc: 0.7237, Bottom 30th Acc: 0.5000
Stopping early at Epoch (base 0): 27  Rolling back to Epoch (base 0): 22  Top Validation Acc: 0.7236842105263158
Running train_nn.py with seed 47
CUDA:False
Training samples count:  550
Training on 2 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1399, Training Loss: 0.1399, Initial Validation Loss: 0.1314, Validation Loss: 0.1314,V Acc: 0.3153, Top 70th Acc: 0.4231, Bottom 30th Acc: 0.0606
Fold [1/5] Epoch [10/100] Initial Loss: 0.1399, Training Loss: 0.0813, Initial Validation Loss: 0.1314, Validation Loss: 0.0797,V Acc: 0.6216, Top 70th Acc: 0.7179, Bottom 30th Acc: 0.3939
Fold [1/5] Epoch [20/100] Initial Loss: 0.1399, Training Loss: 0.0791, Initial Validation Loss: 0.1314, Validation Loss: 0.0772,V Acc: 0.6486, Top 70th Acc: 0.7179, Bottom 30th Acc: 0.4848
Stopping early at Epoch (base 0): 22  Rolling back to Epoch (base 0): 17  Top Validation Acc: 0.717948717948718
Fold [2/5] Epoch [0/100] Initial Loss: 0.1345, Training Loss: 0.1345, Initial Validation Loss: 0.1283, Validation Loss: 0.1283,V Acc: 0.4054, Top 70th Acc: 0.5385, Bottom 30th Acc: 0.0909
Fold [2/5] Epoch [10/100] Initial Loss: 0.1345, Training Loss: 0.0801, Initial Validation Loss: 0.1283, Validation Loss: 0.0862,V Acc: 0.5946, Top 70th Acc: 0.6923, Bottom 30th Acc: 0.3636
Fold [2/5] Epoch [20/100] Initial Loss: 0.1345, Training Loss: 0.0774, Initial Validation Loss: 0.1283, Validation Loss: 0.0841,V Acc: 0.5946, Top 70th Acc: 0.6923, Bottom 30th Acc: 0.3636
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.717948717948718
Fold [3/5] Epoch [0/100] Initial Loss: 0.1388, Training Loss: 0.1388, Initial Validation Loss: 0.1385, Validation Loss: 0.1385,V Acc: 0.3909, Top 70th Acc: 0.4545, Bottom 30th Acc: 0.2424
Fold [3/5] Epoch [10/100] Initial Loss: 0.1388, Training Loss: 0.0797, Initial Validation Loss: 0.1385, Validation Loss: 0.0834,V Acc: 0.6364, Top 70th Acc: 0.7273, Bottom 30th Acc: 0.4242
Fold [3/5] Epoch [20/100] Initial Loss: 0.1388, Training Loss: 0.0775, Initial Validation Loss: 0.1385, Validation Loss: 0.0814,V Acc: 0.6273, Top 70th Acc: 0.7403, Bottom 30th Acc: 0.3636
Fold [3/5] Epoch [30/100] Initial Loss: 0.1388, Training Loss: 0.0772, Initial Validation Loss: 0.1385, Validation Loss: 0.0811,V Acc: 0.6273, Top 70th Acc: 0.7532, Bottom 30th Acc: 0.3333
Fold [3/5] Epoch [40/100] Initial Loss: 0.1388, Training Loss: 0.0767, Initial Validation Loss: 0.1385, Validation Loss: 0.0815,V Acc: 0.6364, Top 70th Acc: 0.7403, Bottom 30th Acc: 0.3939
Stopping early at Epoch (base 0): 41  Rolling back to Epoch (base 0): 36  Top Validation Acc: 0.7532467532467533
Fold [2/5] Epoch [10/100] Initial Loss: 0.1339, Training Loss: 0.0359, Initial Validation Loss: 0.1341, Validation Loss: 0.0334,V Acc: 0.8649, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.6667
Fold [2/5] Epoch [20/100] Initial Loss: 0.1339, Training Loss: 0.0253, Initial Validation Loss: 0.1341, Validation Loss: 0.0295,V Acc: 0.9009, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.8182
Stopping early at Epoch (base 0): 29  Rolling back to Epoch (base 0): 24  Top Validation Acc: 0.9358974358974359
Fold [3/5] Epoch [0/100] Initial Loss: 0.1389, Training Loss: 0.1389, Initial Validation Loss: 0.1332, Validation Loss: 0.1332,V Acc: 0.2909, Top 70th Acc: 0.3377, Bottom 30th Acc: 0.1818
Fold [3/5] Epoch [10/100] Initial Loss: 0.1389, Training Loss: 0.0349, Initial Validation Loss: 0.1332, Validation Loss: 0.0411,V Acc: 0.8455, Top 70th Acc: 0.8961, Bottom 30th Acc: 0.7273
Fold [3/5] Epoch [20/100] Initial Loss: 0.1389, Training Loss: 0.0240, Initial Validation Loss: 0.1332, Validation Loss: 0.0334,V Acc: 0.8182, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.9090909090909091
Fold [4/5] Epoch [0/100] Initial Loss: 0.1414, Training Loss: 0.1414, Initial Validation Loss: 0.1368, Validation Loss: 0.1368,V Acc: 0.2545, Top 70th Acc: 0.2208, Bottom 30th Acc: 0.3333
Fold [4/5] Epoch [10/100] Initial Loss: 0.1414, Training Loss: 0.0368, Initial Validation Loss: 0.1368, Validation Loss: 0.0407,V Acc: 0.8091, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.5455
Fold [4/5] Epoch [20/100] Initial Loss: 0.1414, Training Loss: 0.0234, Initial Validation Loss: 0.1368, Validation Loss: 0.0348,V Acc: 0.8273, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 28  Rolling back to Epoch (base 0): 23  Top Validation Acc: 0.922077922077922
Fold [5/5] Epoch [0/100] Initial Loss: 0.1431, Training Loss: 0.1431, Initial Validation Loss: 0.1346, Validation Loss: 0.1346,V Acc: 0.2870, Top 70th Acc: 0.3158, Bottom 30th Acc: 0.2188
Fold [5/5] Epoch [10/100] Initial Loss: 0.1431, Training Loss: 0.0406, Initial Validation Loss: 0.1346, Validation Loss: 0.0415,V Acc: 0.8056, Top 70th Acc: 0.9211, Bottom 30th Acc: 0.5312
Fold [5/5] Epoch [20/100] Initial Loss: 0.1431, Training Loss: 0.0274, Initial Validation Loss: 0.1346, Validation Loss: 0.0312,V Acc: 0.8426, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.6250
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.9342105263157895
49 4 [array([0.27624524, 0.11308001, 0.08499912, 0.21826062, 0.307415  ],
      dtype=float32)]
Running train_nn.py with seed 50
CUDA:False
Training samples count:  550
Training on 20 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1363, Training Loss: 0.1363, Initial Validation Loss: 0.1367, Validation Loss: 0.1367,V Acc: 0.2883, Top 70th Acc: 0.3205, Bottom 30th Acc: 0.2121
Fold [1/5] Epoch [10/100] Initial Loss: 0.1363, Training Loss: 0.0405, Initial Validation Loss: 0.1367, Validation Loss: 0.0421,V Acc: 0.8288, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.6364
Fold [1/5] Epoch [20/100] Initial Loss: 0.1363, Training Loss: 0.0249, Initial Validation Loss: 0.1367, Validation Loss: 0.0298,V Acc: 0.8739, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.6970
Fold [1/5] Epoch [30/100] Initial Loss: 0.1363, Training Loss: 0.0212, Initial Validation Loss: 0.1367, Validation Loss: 0.0300,V Acc: 0.8559, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 32  Rolling back to Epoch (base 0): 27  Top Validation Acc: 0.9230769230769231
Fold [2/5] Epoch [0/100] Initial Loss: 0.1403, Training Loss: 0.1403, Initial Validation Loss: 0.1341, Validation Loss: 0.1341,V Acc: 0.2883, Top 70th Acc: 0.2692, Bottom 30th Acc: 0.3333
Fold [2/5] Epoch [10/100] Initial Loss: 0.1403, Training Loss: 0.0358, Initial Validation Loss: 0.1341, Validation Loss: 0.0424,V Acc: 0.8108, Top 70th Acc: 0.8846, Bottom 30th Acc: 0.6364
Fold [2/5] Epoch [20/100] Initial Loss: 0.1403, Training Loss: 0.0223, Initial Validation Loss: 0.1341, Validation Loss: 0.0342,V Acc: 0.8198, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.8974358974358975
Fold [3/5] Epoch [0/100] Initial Loss: 0.1398, Training Loss: 0.1398, Initial Validation Loss: 0.1334, Validation Loss: 0.1334,V Acc: 0.3091, Top 70th Acc: 0.4026, Bottom 30th Acc: 0.0909
Fold [3/5] Epoch [10/100] Initial Loss: 0.1398, Training Loss: 0.0326, Initial Validation Loss: 0.1334, Validation Loss: 0.0397,V Acc: 0.8091, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.4848
Fold [3/5] Epoch [20/100] Initial Loss: 0.1398, Training Loss: 0.0226, Initial Validation Loss: 0.1334, Validation Loss: 0.0366,V Acc: 0.8273, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.5455
Fold [3/5] Epoch [30/100] Initial Loss: 0.1398, Training Loss: 0.0209, Initial Validation Loss: 0.1334, Validation Loss: 0.0344,V Acc: 0.8545, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 32  Rolling back to Epoch (base 0): 27  Top Validation Acc: 0.922077922077922
Fold [4/5] Epoch [0/100] Initial Loss: 0.1407, Training Loss: 0.1407, Initial Validation Loss: 0.1322, Validation Loss: 0.1322,V Acc: 0.2455, Top 70th Acc: 0.3117, Bottom 30th Acc: 0.0909
Fold [4/5] Epoch [10/100] Initial Loss: 0.1407, Training Loss: 0.0331, Initial Validation Loss: 0.1322, Validation Loss: 0.0308,V Acc: 0.8545, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.6667
Fold [4/5] Epoch [20/100] Initial Loss: 0.1407, Training Loss: 0.0234, Initial Validation Loss: 0.1322, Validation Loss: 0.0245,V Acc: 0.8636, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.6061
Fold [4/5] Epoch [30/100] Initial Loss: 0.1407, Training Loss: 0.0215, Initial Validation Loss: 0.1322, Validation Loss: 0.0240,V Acc: 0.8636, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 31  Rolling back to Epoch (base 0): 26  Top Validation Acc: 0.974025974025974
Fold [5/5] Epoch [0/100] Initial Loss: 0.1384, Training Loss: 0.1384, Initial Validation Loss: 0.1319, Validation Loss: 0.1319,V Acc: 0.2778, Top 70th Acc: 0.3026, Bottom 30th Acc: 0.2188
Fold [5/5] Epoch [10/100] Initial Loss: 0.1384, Training Loss: 0.0355, Initial Validation Loss: 0.1319, Validation Loss: 0.0411,V Acc: 0.8241, Top 70th Acc: 0.9211, Bottom 30th Acc: 0.5938
Fold [5/5] Epoch [20/100] Initial Loss: 0.1384, Training Loss: 0.0214, Initial Validation Loss: 0.1319, Validation Loss: 0.0336,V Acc: 0.8333, Top 70th Acc: 0.9211, Bottom 30th Acc: 0.6250
Stopping early at Epoch (base 0): 28  Rolling back to Epoch (base 0): 23  Top Validation Acc: 0.9342105263157895
50 4 [array([0.36437908, 0.0821378 , 0.13702603, 0.31929994, 0.0971572 ],
      dtype=float32)]
Running train_nn.py with seed 51
CUDA:False
Training samples count:  550
Training on 20 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1397, Training Loss: 0.1397, Initial Validation Loss: 0.1360, Validation Loss: 0.1360,V Acc: 0.3333, Top 70th Acc: 0.2949, Bottom 30th Acc: 0.4242
Fold [1/5] Epoch [10/100] Initial Loss: 0.1397, Training Loss: 0.0369, Initial Validation Loss: 0.1360, Validation Loss: 0.0362,V Acc: 0.8919, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.8182
Fold [1/5] Epoch [20/100] Initial Loss: 0.1397, Training Loss: 0.0241, Initial Validation Loss: 0.1360, Validation Loss: 0.0304,V Acc: 0.8919, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.7879
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.9358974358974359
51 0 [array([0.32143188, 0.14102794, 0.14588934, 0.2572701 , 0.1343808 ],
      dtype=float32)]
Fold [2/5] Epoch [0/100] Initial Loss: 0.1404, Training Loss: 0.1404, Initial Validation Loss: 0.1346, Validation Loss: 0.1346,V Acc: 0.2432, Top 70th Acc: 0.2564, Bottom 30th Acc: 0.2121
Fold [2/5] Epoch [10/100] Initial Loss: 0.1404, Training Loss: 0.0461, Initial Validation Loss: 0.1346, Validation Loss: 0.0483,V Acc: 0.7387, Top 70th Acc: 0.8718, Bottom 30th Acc: 0.4242
Fold [2/5] Epoch [20/100] Initial Loss: 0.1404, Training Loss: 0.0236, Initial Validation Loss: 0.1346, Validation Loss: 0.0334,V Acc: 0.8288, Top 70th Acc: 0.8974, Bottom 30th Acc: 0.6667
Fold [3/5] Epoch [10/100] Initial Loss: 0.1396, Training Loss: 0.0301, Initial Validation Loss: 0.1341, Validation Loss: 0.0401,V Acc: 0.8091, Top 70th Acc: 0.8961, Bottom 30th Acc: 0.6061
Fold [3/5] Epoch [20/100] Initial Loss: 0.1396, Training Loss: 0.0171, Initial Validation Loss: 0.1341, Validation Loss: 0.0336,V Acc: 0.8273, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.5758
Fold [3/5] Epoch [30/100] Initial Loss: 0.1396, Training Loss: 0.0127, Initial Validation Loss: 0.1341, Validation Loss: 0.0298,V Acc: 0.8545, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 34  Rolling back to Epoch (base 0): 29  Top Validation Acc: 0.948051948051948
Fold [4/5] Epoch [0/100] Initial Loss: 0.1396, Training Loss: 0.1396, Initial Validation Loss: 0.1355, Validation Loss: 0.1355,V Acc: 0.2909, Top 70th Acc: 0.2468, Bottom 30th Acc: 0.3939
Fold [4/5] Epoch [10/100] Initial Loss: 0.1396, Training Loss: 0.0279, Initial Validation Loss: 0.1355, Validation Loss: 0.0367,V Acc: 0.8364, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.6061
Fold [4/5] Epoch [20/100] Initial Loss: 0.1396, Training Loss: 0.0141, Initial Validation Loss: 0.1355, Validation Loss: 0.0315,V Acc: 0.8000, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.3939
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.961038961038961
Fold [5/5] Epoch [0/100] Initial Loss: 0.1401, Training Loss: 0.1401, Initial Validation Loss: 0.1322, Validation Loss: 0.1322,V Acc: 0.2500, Top 70th Acc: 0.2763, Bottom 30th Acc: 0.1875
Fold [5/5] Epoch [10/100] Initial Loss: 0.1401, Training Loss: 0.0296, Initial Validation Loss: 0.1322, Validation Loss: 0.0394,V Acc: 0.8333, Top 70th Acc: 0.9211, Bottom 30th Acc: 0.6250
Fold [5/5] Epoch [20/100] Initial Loss: 0.1401, Training Loss: 0.0142, Initial Validation Loss: 0.1322, Validation Loss: 0.0307,V Acc: 0.8519, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.6562
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.9210526315789473
49 4 [array([0.55587006, 0.08762819, 0.06748369, 0.05944812, 0.22956996],
      dtype=float32)]
Running train_nn.py with seed 50
CUDA:False
Training samples count:  550
Training on 40 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1383, Training Loss: 0.1383, Initial Validation Loss: 0.1386, Validation Loss: 0.1386,V Acc: 0.3063, Top 70th Acc: 0.3205, Bottom 30th Acc: 0.2727
Fold [1/5] Epoch [10/100] Initial Loss: 0.1383, Training Loss: 0.0380, Initial Validation Loss: 0.1386, Validation Loss: 0.0431,V Acc: 0.8018, Top 70th Acc: 0.8974, Bottom 30th Acc: 0.5758
Fold [1/5] Epoch [20/100] Initial Loss: 0.1383, Training Loss: 0.0177, Initial Validation Loss: 0.1386, Validation Loss: 0.0290,V Acc: 0.8559, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.6061
Fold [1/5] Epoch [30/100] Initial Loss: 0.1383, Training Loss: 0.0133, Initial Validation Loss: 0.1386, Validation Loss: 0.0261,V Acc: 0.8829, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 39  Rolling back to Epoch (base 0): 34  Top Validation Acc: 0.9871794871794872
Fold [2/5] Epoch [0/100] Initial Loss: 0.1371, Training Loss: 0.1371, Initial Validation Loss: 0.1327, Validation Loss: 0.1327,V Acc: 0.3333, Top 70th Acc: 0.4231, Bottom 30th Acc: 0.1212
Fold [2/5] Epoch [10/100] Initial Loss: 0.1371, Training Loss: 0.0272, Initial Validation Loss: 0.1327, Validation Loss: 0.0384,V Acc: 0.7748, Top 70th Acc: 0.8974, Bottom 30th Acc: 0.4848
Fold [2/5] Epoch [20/100] Initial Loss: 0.1371, Training Loss: 0.0137, Initial Validation Loss: 0.1327, Validation Loss: 0.0365,V Acc: 0.8198, Top 70th Acc: 0.8974, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 21  Rolling back to Epoch (base 0): 16  Top Validation Acc: 0.8974358974358975
Fold [3/5] Epoch [0/100] Initial Loss: 0.1390, Training Loss: 0.1390, Initial Validation Loss: 0.1352, Validation Loss: 0.1352,V Acc: 0.2364, Top 70th Acc: 0.2597, Bottom 30th Acc: 0.1818
Fold [3/5] Epoch [10/100] Initial Loss: 0.1390, Training Loss: 0.0311, Initial Validation Loss: 0.1352, Validation Loss: 0.0354,V Acc: 0.8455, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.5455
Fold [3/5] Epoch [20/100] Initial Loss: 0.1390, Training Loss: 0.0145, Initial Validation Loss: 0.1352, Validation Loss: 0.0301,V Acc: 0.8636, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 21  Rolling back to Epoch (base 0): 16  Top Validation Acc: 0.948051948051948
Fold [4/5] Epoch [0/100] Initial Loss: 0.1418, Training Loss: 0.1418, Initial Validation Loss: 0.1341, Validation Loss: 0.1341,V Acc: 0.2364, Top 70th Acc: 0.2338, Bottom 30th Acc: 0.2424
Fold [4/5] Epoch [10/100] Initial Loss: 0.1418, Training Loss: 0.0275, Initial Validation Loss: 0.1341, Validation Loss: 0.0273,V Acc: 0.8818, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.6970
Fold [4/5] Epoch [20/100] Initial Loss: 0.1418, Training Loss: 0.0156, Initial Validation Loss: 0.1341, Validation Loss: 0.0215,V Acc: 0.8909, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.7273
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.961038961038961
Fold [5/5] Epoch [0/100] Initial Loss: 0.1390, Training Loss: 0.1390, Initial Validation Loss: 0.1325, Validation Loss: 0.1325,V Acc: 0.2500, Top 70th Acc: 0.2500, Bottom 30th Acc: 0.2500
Fold [5/5] Epoch [10/100] Initial Loss: 0.1390, Training Loss: 0.0377, Initial Validation Loss: 0.1325, Validation Loss: 0.0455,V Acc: 0.7870, Top 70th Acc: 0.8816, Bottom 30th Acc: 0.5625
Stopping early at Epoch (base 0): 16  Rolling back to Epoch (base 0): 11  Top Validation Acc: 0.881578947368421
50 4 [array([0.49077082, 0.0609352 , 0.0623491 , 0.1578195 , 0.22812536],
      dtype=float32)]
Running train_nn.py with seed 51
CUDA:False
Training samples count:  550
Training on 40 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1381, Training Loss: 0.1381, Initial Validation Loss: 0.1315, Validation Loss: 0.1315,V Acc: 0.2793, Top 70th Acc: 0.3205, Bottom 30th Acc: 0.1818
Fold [1/5] Epoch [10/100] Initial Loss: 0.1381, Training Loss: 0.0263, Initial Validation Loss: 0.1315, Validation Loss: 0.0318,V Acc: 0.8919, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.7576
Fold [1/5] Epoch [20/100] Initial Loss: 0.1381, Training Loss: 0.0141, Initial Validation Loss: 0.1315, Validation Loss: 0.0266,V Acc: 0.8649, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.9487179487179487
51 0 [array([0.6692247 , 0.10384704, 0.03802454, 0.05116802, 0.13773565],
      dtype=float32)]
Fold [2/5] Epoch [0/100] Initial Loss: 0.1407, Training Loss: 0.1407, Initial Validation Loss: 0.1322, Validation Loss: 0.1322,V Acc: 0.3063, Top 70th Acc: 0.3590, Bottom 30th Acc: 0.1818
Fold [2/5] Epoch [10/100] Initial Loss: 0.1407, Training Loss: 0.0269, Initial Validation Loss: 0.1322, Validation Loss: 0.0359,V Acc: 0.8108, Top 70th Acc: 0.8974, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 17  Rolling back to Epoch (base 0): 12  Top Validation Acc: 0.8717948717948718
Fold [3/5] Epoch [0/100] Initial Loss: 0.1381, Training Loss: 0.1381, Initial Validation Loss: 0.1328, Validation Loss: 0.1328,V Acc: 0.3273, Top 70th Acc: 0.3636, Bottom 30th Acc: 0.2424
Fold [3/5] Epoch [10/100] Initial Loss: 0.1381, Training Loss: 0.0404, Initial Validation Loss: 0.1328, Validation Loss: 0.0461,V Acc: 0.7273, Top 70th Acc: 0.8961, Bottom 30th Acc: 0.3333
Fold [3/5] Epoch [20/100] Initial Loss: 0.1381, Training Loss: 0.0195, Initial Validation Loss: 0.1328, Validation Loss: 0.0297,V Acc: 0.8364, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.5152
Fold [3/5] Epoch [30/100] Initial Loss: 0.1381, Training Loss: 0.0137, Initial Validation Loss: 0.1328, Validation Loss: 0.0258,V Acc: 0.8455, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.5455
Fold [3/5] Epoch [40/100] Initial Loss: 0.1381, Training Loss: 0.0117, Initial Validation Loss: 0.1328, Validation Loss: 0.0253,V Acc: 0.8545, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 41  Rolling back to Epoch (base 0): 36  Top Validation Acc: 0.961038961038961
Fold [4/5] Epoch [0/100] Initial Loss: 0.1402, Training Loss: 0.1402, Initial Validation Loss: 0.1325, Validation Loss: 0.1325,V Acc: 0.2909, Top 70th Acc: 0.3506, Bottom 30th Acc: 0.1515
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 30 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 91
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 30 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 92
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 30 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 93
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 30 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 94
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 30 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 95
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 30 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 96
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 30 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 97
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 30 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 98
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 30 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 99
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 30 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 100
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 30 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
 14  Top Validation Acc: 1.0
Fold [2/5] Epoch [0/100] Initial Loss: 0.1352, Training Loss: 0.1352, Initial Validation Loss: 0.1217, Validation Loss: 0.1217,V Acc: 0.4775, Top 70th Acc: 0.5256, Bottom 30th Acc: 0.3636
Fold [2/5] Epoch [10/100] Initial Loss: 0.1352, Training Loss: 0.0292, Initial Validation Loss: 0.1217, Validation Loss: 0.0305,V Acc: 0.8829, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.7273
Fold [2/5] Epoch [20/100] Initial Loss: 0.1352, Training Loss: 0.0188, Initial Validation Loss: 0.1217, Validation Loss: 0.0354,V Acc: 0.8559, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 21  Rolling back to Epoch (base 0): 16  Top Validation Acc: 0.9615384615384616
Fold [3/5] Epoch [0/100] Initial Loss: 0.1331, Training Loss: 0.1331, Initial Validation Loss: 0.1147, Validation Loss: 0.1147,V Acc: 0.6000, Top 70th Acc: 0.6883, Bottom 30th Acc: 0.3939
Fold [3/5] Epoch [10/100] Initial Loss: 0.1331, Training Loss: 0.0229, Initial Validation Loss: 0.1147, Validation Loss: 0.0455,V Acc: 0.7818, Top 70th Acc: 0.8571, Bottom 30th Acc: 0.6061
Fold [3/5] Epoch [20/100] Initial Loss: 0.1331, Training Loss: 0.0145, Initial Validation Loss: 0.1147, Validation Loss: 0.0431,V Acc: 0.7818, Top 70th Acc: 0.8701, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 20  Rolling back to Epoch (base 0): 15  Top Validation Acc: 0.8701298701298701
Fold [4/5] Epoch [0/100] Initial Loss: 0.1316, Training Loss: 0.1316, Initial Validation Loss: 0.1189, Validation Loss: 0.1189,V Acc: 0.5273, Top 70th Acc: 0.5844, Bottom 30th Acc: 0.3939
Fold [4/5] Epoch [10/100] Initial Loss: 0.1316, Training Loss: 0.0199, Initial Validation Loss: 0.1189, Validation Loss: 0.0274,V Acc: 0.8727, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 14  Rolling back to Epoch (base 0): 9  Top Validation Acc: 0.974025974025974
71 3 [array([0.5856857 , 0.04214989, 0.06010186, 0.10927764, 0.202785  ],
      dtype=float32)]
Fold [5/5] Epoch [0/100] Initial Loss: 0.1307, Training Loss: 0.1307, Initial Validation Loss: 0.1216, Validation Loss: 0.1216,V Acc: 0.5741, Top 70th Acc: 0.6711, Bottom 30th Acc: 0.3438
Fold [5/5] Epoch [10/100] Initial Loss: 0.1307, Training Loss: 0.0234, Initial Validation Loss: 0.1216, Validation Loss: 0.0290,V Acc: 0.8519, Top 70th Acc: 0.9211, Bottom 30th Acc: 0.6875
Fold [5/5] Epoch [20/100] Initial Loss: 0.1307, Training Loss: 0.0185, Initial Validation Loss: 0.1216, Validation Loss: 0.0237,V Acc: 0.8796, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.7188
Stopping early at Epoch (base 0): 20  Rolling back to Epoch (base 0): 15  Top Validation Acc: 0.9473684210526315
Running train_nn.py with seed 72
CUDA:False
Training samples count:  550
Training on 21 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1301, Training Loss: 0.1301, Initial Validation Loss: 0.1182, Validation Loss: 0.1182,V Acc: 0.5135, Top 70th Acc: 0.6154, Bottom 30th Acc: 0.2727
Fold [1/5] Epoch [10/100] Initial Loss: 0.1301, Training Loss: 0.0228, Initial Validation Loss: 0.1182, Validation Loss: 0.0318,V Acc: 0.8649, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 19  Rolling back to Epoch (base 0): 14  Top Validation Acc: 0.9615384615384616
Fold [2/5] Epoch [0/100] Initial Loss: 0.1374, Training Loss: 0.1374, Initial Validation Loss: 0.1262, Validation Loss: 0.1262,V Acc: 0.4324, Top 70th Acc: 0.4744, Bottom 30th Acc: 0.3333
Fold [2/5] Epoch [10/100] Initial Loss: 0.1374, Training Loss: 0.0250, Initial Validation Loss: 0.1262, Validation Loss: 0.0236,V Acc: 0.8829, Top 70th Acc: 0.9872, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 16  Rolling back to Epoch (base 0): 11  Top Validation Acc: 0.9743589743589743
Fold [3/5] Epoch [0/100] Initial Loss: 0.1365, Training Loss: 0.1365, Initial Validation Loss: 0.1252, Validation Loss: 0.1252,V Acc: 0.3909, Top 70th Acc: 0.5195, Bottom 30th Acc: 0.0909
Fold [3/5] Epoch [10/100] Initial Loss: 0.1365, Training Loss: 0.0228, Initial Validation Loss: 0.1252, Validation Loss: 0.0323,V Acc: 0.8455, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.5758
Fold [3/5] Epoch [20/100] Initial Loss: 0.1365, Training Loss: 0.0162, Initial Validation Loss: 0.1252, Validation Loss: 0.0320,V Acc: 0.8091, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.4545
Stopping early at Epoch (base 0): 21  Rolling back to Epoch (base 0): 16  Top Validation Acc: 0.948051948051948
Fold [4/5] Epoch [0/100] Initial Loss: 0.1327, Training Loss: 0.1327, Initial Validation Loss: 0.1260, Validation Loss: 0.1260,V Acc: 0.3636, Top 70th Acc: 0.4935, Bottom 30th Acc: 0.0606
Fold [4/5] Epoch [10/100] Initial Loss: 0.1327, Training Loss: 0.0232, Initial Validation Loss: 0.1260, Validation Loss: 0.0381,V Acc: 0.8273, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.6364
Fold [4/5] Epoch [20/100] Initial Loss: 0.1327, Training Loss: 0.0186, Initial Validation Loss: 0.1260, Validation Loss: 0.0337,V Acc: 0.8182, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.5152
Stopping early at Epoch (base 0): 20  Rolling back to Epoch (base 0): 15  Top Validation Acc: 0.948051948051948
72 3 [array([0.6958186 , 0.02280889, 0.07122223, 0.10608116, 0.10406906],
      dtype=float32)]
Fold [5/5] Epoch [0/100] Initial Loss: 0.1393, Training Loss: 0.1393, Initial Validation Loss: 0.1254, Validation Loss: 0.1254,V Acc: 0.4167, Top 70th Acc: 0.5132, Bottom 30th Acc: 0.1875
Fold [5/5] Epoch [10/100] Initial Loss: 0.1393, Training Loss: 0.0285, Initial Validation Loss: 0.1254, Validation Loss: 0.0297,V Acc: 0.8519, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.5938
Fold [5/5] Epoch [20/100] Initial Loss: 0.1393, Training Loss: 0.0193, Initial Validation Loss: 0.1254, Validation Loss: 0.0220,V Acc: 0.8796, Top 70th Acc: 0.9737, Bottom 30th Acc: 0.6562
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.9473684210526315
Running train_nn.py with seed 73
CUDA:False
Training samples count:  550
Training on 21 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1353, Training Loss: 0.1353, Initial Validation Loss: 0.1277, Validation Loss: 0.1277,V Acc: 0.3874, Top 70th Acc: 0.4744, Bottom 30th Acc: 0.1818
Fold [1/5] Epoch [10/100] Initial Loss: 0.1353, Training Loss: 0.0274, Initial Validation Loss: 0.1277, Validation Loss: 0.0383,V Acc: 0.7928, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.4848
Fold [1/5] Epoch [20/100] Initial Loss: 0.1353, Training Loss: 0.0162, Initial Validation Loss: 0.1277, Validation Loss: 0.0334,V Acc: 0.8468, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 20  Rolling back to Epoch (base 0): 15  Top Validation Acc: 0.9615384615384616
73 0 [array([0.79301435, 0.01428711, 0.04144656, 0.08021086, 0.07104109],
      dtype=float32)]
Fold [2/5] Epoch [0/100] Initial Loss: 0.1370, Training Loss: 0.1370, Initial Validation Loss: 0.1238, Validation Loss: 0.1238,V Acc: 0.3063, Top 70th Acc: 0.3590, Bottom 30th Acc: 0.1818
Fold [2/5] Epoch [10/100] Initial Loss: 0.1370, Training Loss: 0.0234, Initial Validation Loss: 0.1238, Validation Loss: 0.0395,V Acc: 0.7928, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.4848
Stopping early at Epoch (base 0): 14  Rolling back to Epoch (base 0): 9  Top Validation Acc: 0.9615384615384616
Fold [3/5] Epoch [0/100] Initial Loss: 0.1300, Training Loss: 0.1300, Initial Validation Loss: 0.1151, Validation Loss: 0.1151,V Acc: 0.4909, Top 70th Acc: 0.5195, Bottom 30th Acc: 0.4242
Fold [3/5] Epoch [10/100] Initial Loss: 0.1300, Training Loss: 0.0227, Initial Validation Loss: 0.1151, Validation Loss: 0.0297,V Acc: 0.8727, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6970
Fold [3/5] Epoch [20/100] Initial Loss: 0.1300, Training Loss: 0.0185, Initial Validation Loss: 0.1151, Validation Loss: 0.0221,V Acc: 0.9091, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.7576
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.961038961038961
Fold [4/5] Epoch [0/100] Initial Loss: 0.1288, Training Loss: 0.1288, Initial Validation Loss: 0.1202, Validation Loss: 0.1202,V Acc: 0.5455, Top 70th Acc: 0.6234, Bottom 30th Acc: 0.3636
Fold [4/5] Epoch [10/100] Initial Loss: 0.1288, Training Loss: 0.0245, Initial Validation Loss: 0.1202, Validation Loss: 0.0341,V Acc: 0.8364, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.9473684210526315
50 4 [array([0.6998757 , 0.05924276, 0.04178886, 0.09996614, 0.09912656],
      dtype=float32)]
Running train_nn.py with seed 51
CUDA:False
Training samples count:  550
Training on 30 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1391, Training Loss: 0.1391, Initial Validation Loss: 0.1338, Validation Loss: 0.1338,V Acc: 0.3694, Top 70th Acc: 0.4487, Bottom 30th Acc: 0.1818
Fold [1/5] Epoch [10/100] Initial Loss: 0.1391, Training Loss: 0.0280, Initial Validation Loss: 0.1338, Validation Loss: 0.0326,V Acc: 0.8739, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.7273
Fold [1/5] Epoch [20/100] Initial Loss: 0.1391, Training Loss: 0.0186, Initial Validation Loss: 0.1338, Validation Loss: 0.0298,V Acc: 0.8829, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.7879
Stopping early at Epoch (base 0): 20  Rolling back to Epoch (base 0): 15  Top Validation Acc: 0.9230769230769231
51 0 [array([0.6171018 , 0.15919493, 0.06375249, 0.09624745, 0.06370342],
      dtype=float32)]
Fold [2/5] Epoch [0/100] Initial Loss: 0.1371, Training Loss: 0.1371, Initial Validation Loss: 0.1306, Validation Loss: 0.1306,V Acc: 0.3964, Top 70th Acc: 0.4615, Bottom 30th Acc: 0.2424
Fold [2/5] Epoch [10/100] Initial Loss: 0.1371, Training Loss: 0.0276, Initial Validation Loss: 0.1306, Validation Loss: 0.0372,V Acc: 0.7928, Top 70th Acc: 0.8846, Bottom 30th Acc: 0.5758
Fold [2/5] Epoch [20/100] Initial Loss: 0.1371, Training Loss: 0.0166, Initial Validation Loss: 0.1306, Validation Loss: 0.0370,V Acc: 0.7928, Top 70th Acc: 0.8846, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.8461538461538461
Fold [3/5] Epoch [0/100] Initial Loss: 0.1376, Training Loss: 0.1376, Initial Validation Loss: 0.1348, Validation Loss: 0.1348,V Acc: 0.3909, Top 70th Acc: 0.4675, Bottom 30th Acc: 0.2121
Fold [3/5] Epoch [10/100] Initial Loss: 0.1376, Training Loss: 0.0384, Initial Validation Loss: 0.1348, Validation Loss: 0.0461,V Acc: 0.7364, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.3030
Fold [3/5] Epoch [20/100] Initial Loss: 0.1376, Training Loss: 0.0215, Initial Validation Loss: 0.1348, Validation Loss: 0.0328,V Acc: 0.8182, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.4848
Fold [3/5] Epoch [30/100] Initial Loss: 0.1376, Training Loss: 0.0171, Initial Validation Loss: 0.1348, Validation Loss: 0.0308,V Acc: 0.8182, Top 70th Acc: 1.0000, Bottom 30th Acc: 0.3939
Stopping early at Epoch (base 0): 31  Rolling back to Epoch (base 0): 26  Top Validation Acc: 1.0
Fold [4/5] Epoch [0/100] Initial Loss: 0.1382, Training Loss: 0.1382, Initial Validation Loss: 0.1337, Validation Loss: 0.1337,V Acc: 0.3182, Top 70th Acc: 0.3506, Bottom 30th Acc: 0.2424
Fold [4/5] Epoch [10/100] Initial Loss: 0.1382, Training Loss: 0.0306, Initial Validation Loss: 0.1337, Validation Loss: 0.0430,V Acc: 0.7909, Top 70th Acc: 0.8831, Bottom 30th Acc: 0.5758
Fold [4/5] Epoch [20/100] Initial Loss: 0.1382, Training Loss: 0.0191, Initial Validation Loss: 0.1337, Validation Loss: 0.0360,V Acc: 0.8091, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.5455
Fold [4/5] Epoch [30/100] Initial Loss: 0.1382, Training Loss: 0.0162, Initial Validation Loss: 0.1337, Validation Loss: 0.0339,V Acc: 0.8182, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.5152
Fold [4/5] Epoch [40/100] Initial Loss: 0.1382, Training Loss: 0.0145, Initial Validation Loss: 0.1337, Validation Loss: 0.0328,V Acc: 0.8273, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 43  Rolling back to Epoch (base 0): 38  Top Validation Acc: 0.948051948051948
Fold [5/5] Epoch [0/100] Initial Loss: 0.1386, Training Loss: 0.1386, Initial Validation Loss: 0.1385, Validation Loss: 0.1385,V Acc: 0.2500, Top 70th Acc: 0.2368, Bottom 30th Acc: 0.2812
Fold [5/5] Epoch [10/100] Initial Loss: 0.1386, Training Loss: 0.0336, Initial Validation Loss: 0.1385, Validation Loss: 0.0385,V Acc: 0.8426, Top 70th Acc: 0.9868, Bottom 30th Acc: 0.5000
Fold [5/5] Epoch [20/100] Initial Loss: 0.1386, Training Loss: 0.0220, Initial Validation Loss: 0.1385, Validation Loss: 0.0307,V Acc: 0.8981, Top 70th Acc: 1.0000, Bottom 30th Acc: 0.6562
Fold [5/5] Epoch [30/100] Initial Loss: 0.1386, Training Loss: 0.0180, Initial Validation Loss: 0.1385, Validation Loss: 0.0294,V Acc: 0.8889, Top 70th Acc: 0.9737, Bottom 30th Acc: 0.6875
Stopping early at Epoch (base 0): 38  Rolling back to Epoch (base 0): 33  Top Validation Acc: 0.9736842105263158
Running train_nn.py with seed 52
CUDA:False
Training samples count:  550
Training on 30 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1374, Training Loss: 0.1374, Initial Validation Loss: 0.1317, Validation Loss: 0.1317,V Acc: 0.2703, Top 70th Acc: 0.3590, Bottom 30th Acc: 0.0606
Fold [1/5] Epoch [10/100] Initial Loss: 0.1374, Training Loss: 0.0421, Initial Validation Loss: 0.1317, Validation Loss: 0.0418,V Acc: 0.8108, Top 70th Acc: 0.8846, Bottom 30th Acc: 0.6364
Fold [1/5] Epoch [20/100] Initial Loss: 0.1374, Training Loss: 0.0189, Initial Validation Loss: 0.1317, Validation Loss: 0.0283,V Acc: 0.8468, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.6667
Fold [1/5] Epoch [30/100] Initial Loss: 0.1374, Training Loss: 0.0156, Initial Validation Loss: 0.1317, Validation Loss: 0.0281,V Acc: 0.8468, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 30  Rolling back to Epoch (base 0): 25  Top Validation Acc: 0.9358974358974359
Fold [2/5] Epoch [0/100] Initial Loss: 0.1361, Training Loss: 0.1361, Initial Validation Loss: 0.1310, Validation Loss: 0.1310,V Acc: 0.3243, Top 70th Acc: 0.3846, Bottom 30th Acc: 0.1818
Fold [2/5] Epoch [10/100] Initial Loss: 0.1361, Training Loss: 0.0334, Initial Validation Loss: 0.1310, Validation Loss: 0.0396,V Acc: 0.8378, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.6364
Fold [2/5] Epoch [20/100] Initial Loss: 0.1361, Training Loss: 0.0180, Initial Validation Loss: 0.1310, Validation Loss: 0.0313,V Acc: 0.8468, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 22  Rolling back to Epoch (base 0): 17  Top Validation Acc: 0.9487179487179487
Fold [3/5] Epoch [0/100] Initial Loss: 0.1392, Training Loss: 0.1392, Initial Validation Loss: 0.1369, Validation Loss: 0.1369,V Acc: 0.2364, Top 70th Acc: 0.2468, Bottom 30th Acc: 0.2121
Fold [3/5] Epoch [10/100] Initial Loss: 0.1392, Training Loss: 0.0352, Initial Validation Loss: 0.1369, Validation Loss: 0.0388,V Acc: 0.8364, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.6364
Fold [3/5] Epoch [20/100] Initial Loss: 0.1392, Training Loss: 0.0187, Initial Validation Loss: 0.1369, Validation Loss: 0.0322,V Acc: 0.8273, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.922077922077922
52 2 [array([0.45742804, 0.09612079, 0.04578121, 0.11147047, 0.2891996 ],
      dtype=float32)]
Fold [4/5] Epoch [0/100] Initial Loss: 0.1350, Training Loss: 0.1350, Initial Validation Loss: 0.1340, Validation Loss: 0.1340,V Acc: 0.4364, Top 70th Acc: 0.5195, Bottom 30th Acc: 0.2424
Fold [4/5] Epoch [10/100] Initial Loss: 0.1350, Training Loss: 0.0225, Initial Validation Loss: 0.1340, Validation Loss: 0.0394,V Acc: 0.8364, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.5758
Fold [4/5] Epoch [20/100] Initial Loss: 0.1350, Training Loss: 0.0154, Initial Validation Loss: 0.1340, Validation Loss: 0.0372,V Acc: 0.8273, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 20  Rolling back to Epoch (base 0): 15  Top Validation Acc: 0.948051948051948
Fold [5/5] Epoch [0/100] Initial Loss: 0.1404, Training Loss: 0.1404, Initial Validation Loss: 0.1303, Validation Loss: 0.1303,V Acc: 0.2870, Top 70th Acc: 0.3026, Bottom 30th Acc: 0.2500
Fold [5/5] Epoch [10/100] Initial Loss: 0.1404, Training Loss: 0.0353, Initial Validation Loss: 0.1303, Validation Loss: 0.0373,V Acc: 0.8519, Top 70th Acc: 0.9211, Bottom 30th Acc: 0.6875
Stopping early at Epoch (base 0): 19  Rolling back to Epoch (base 0): 14  Top Validation Acc: 0.9342105263157895
Running train_nn.py with seed 53
CUDA:False
Training samples count:  
Stopping early at Epoch (base 0): 19  Rolling back to Epoch (base 0): 14  Top Validation Acc: 0.9358974358974359
Fold [2/5] Epoch [0/100] Initial Loss: 0.1425, Training Loss: 0.1425, Initial Validation Loss: 0.1355, Validation Loss: 0.1355,V Acc: 0.3333, Top 70th Acc: 0.3462, Bottom 30th Acc: 0.3030
Fold [2/5] Epoch [10/100] Initial Loss: 0.1425, Training Loss: 0.0141, Initial Validation Loss: 0.1355, Validation Loss: 0.0288,V Acc: 0.8288, Top 70th Acc: 0.9872, Bottom 30th Acc: 0.4545
Fold [2/5] Epoch [20/100] Initial Loss: 0.1425, Training Loss: 0.0047, Initial Validation Loss: 0.1355, Validation Loss: 0.0286,V Acc: 0.8288, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.4848
Stopping early at Epoch (base 0): 20  Rolling back to Epoch (base 0): 15  Top Validation Acc: 0.9743589743589743
39 1 [array([0.29584447, 0.04043439, 0.06663626, 0.17949912, 0.41758585],
      dtype=float32)]
Fold [3/5] Epoch [0/100] Initial Loss: 0.1442, Training Loss: 0.1442, Initial Validation Loss: 0.1330, Validation Loss: 0.1330,V Acc: 0.2545, Top 70th Acc: 0.3117, Bottom 30th Acc: 0.1212
Fold [3/5] Epoch [10/100] Initial Loss: 0.1442, Training Loss: 0.0199, Initial Validation Loss: 0.1330, Validation Loss: 0.0438,V Acc: 0.7727, Top 70th Acc: 0.8831, Bottom 30th Acc: 0.5152
Fold [3/5] Epoch [20/100] Initial Loss: 0.1442, Training Loss: 0.0056, Initial Validation Loss: 0.1330, Validation Loss: 0.0408,V Acc: 0.8091, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 21  Rolling back to Epoch (base 0): 16  Top Validation Acc: 0.9090909090909091
Fold [4/5] Epoch [0/100] Initial Loss: 0.1378, Training Loss: 0.1378, Initial Validation Loss: 0.1375, Validation Loss: 0.1375,V Acc: 0.3091, Top 70th Acc: 0.4156, Bottom 30th Acc: 0.0606
Fold [4/5] Epoch [10/100] Initial Loss: 0.1378, Training Loss: 0.0152, Initial Validation Loss: 0.1375, Validation Loss: 0.0354,V Acc: 0.8273, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.5455
Fold [4/5] Epoch [20/100] Initial Loss: 0.1378, Training Loss: 0.0056, Initial Validation Loss: 0.1375, Validation Loss: 0.0317,V Acc: 0.8545, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.948051948051948
Fold [5/5] Epoch [0/100] Initial Loss: 0.1374, Training Loss: 0.1374, Initial Validation Loss: 0.1312, Validation Loss: 0.1312,V Acc: 0.3889, Top 70th Acc: 0.4868, Bottom 30th Acc: 0.1562
Fold [5/5] Epoch [10/100] Initial Loss: 0.1374, Training Loss: 0.0156, Initial Validation Loss: 0.1312, Validation Loss: 0.0269,V Acc: 0.8611, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.6562
Fold [5/5] Epoch [20/100] Initial Loss: 0.1374, Training Loss: 0.0048, Initial Validation Loss: 0.1312, Validation Loss: 0.0225,V Acc: 0.8611, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.6250
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.9605263157894737
Running train_nn.py with seed 40
CUDA:False
Training samples count:  550
Training on 163 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1379, Training Loss: 0.1379, Initial Validation Loss: 0.1387, Validation Loss: 0.1387,V Acc: 0.3243, Top 70th Acc: 0.3718, Bottom 30th Acc: 0.2121
Fold [1/5] Epoch [10/100] Initial Loss: 0.1379, Training Loss: 0.0280, Initial Validation Loss: 0.1387, Validation Loss: 0.0404,V Acc: 0.8559, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.6667
Fold [1/5] Epoch [20/100] Initial Loss: 0.1379, Training Loss: 0.0050, Initial Validation Loss: 0.1387, Validation Loss: 0.0253,V Acc: 0.8919, Top 70th Acc: 0.9872, Bottom 30th Acc: 0.6667
Fold [1/5] Epoch [30/100] Initial Loss: 0.1379, Training Loss: 0.0036, Initial Validation Loss: 0.1387, Validation Loss: 0.0245,V Acc: 0.8829, Top 70th Acc: 0.9872, Bottom 30th Acc: 0.6364
Fold [1/5] Epoch [40/100] Initial Loss: 0.1379, Training Loss: 0.0034, Initial Validation Loss: 0.1387, Validation Loss: 0.0243,V Acc: 0.8919, Top 70th Acc: 0.9872, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 41  Rolling back to Epoch (base 0): 36  Top Validation Acc: 0.9871794871794872
Fold [2/5] Epoch [0/100] Initial Loss: 0.1405, Training Loss: 0.1405, Initial Validation Loss: 0.1350, Validation Loss: 0.1350,V Acc: 0.2523, Top 70th Acc: 0.3462, Bottom 30th Acc: 0.0303
Fold [2/5] Epoch [10/100] Initial Loss: 0.1405, Training Loss: 0.0304, Initial Validation Loss: 0.1350, Validation Loss: 0.0418,V Acc: 0.8018, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.5455
Fold [2/5] Epoch [20/100] Initial Loss: 0.1405, Training Loss: 0.0068, Initial Validation Loss: 0.1350, Validation Loss: 0.0307,V Acc: 0.8378, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.6061
Fold [2/5] Epoch [30/100] Initial Loss: 0.1405, Training Loss: 0.0047, Initial Validation Loss: 0.1350, Validation Loss: 0.0295,V Acc: 0.8559, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 36  Rolling back to Epoch (base 0): 31  Top Validation Acc: 0.9487179487179487
40 1 [array([0.4655338 , 0.03832021, 0.05136859, 0.20780087, 0.23697649],
      dtype=float32)]
Fold [3/5] Epoch [0/100] Initial Loss: 0.1364, Training Loss: 0.1364, Initial Validation Loss: 0.1309, Validation Loss: 0.1309,V Acc: 0.3636, Top 70th Acc: 0.3766, Bottom 30th Acc: 0.3333
Fold [3/5] Epoch [10/100] Initial Loss: 0.1364, Training Loss: 0.0131, Initial Validation Loss: 0.1309, Validation Loss: 0.0294,V Acc: 0.8545, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6364
Fold [3/5] Epoch [20/100] Initial Loss: 0.1364, Training Loss: 0.0047, Initial Validation Loss: 0.1309, Validation Loss: 0.0233,V Acc: 0.8818, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.6667
Fold [3/5] Epoch [30/100] Initial Loss: 0.1364, Training Loss: 0.0040, Initial Validation Loss: 0.1309, Validation Loss: 0.0232,V Acc: 0.8909, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 36  Rolling back to Epoch (base 0): 31  Top Validation Acc: 0.974025974025974
Fold [4/5] Epoch [0/100] Initial Loss: 0.1386, Training Loss: 0.1386, Initial Validation Loss: 0.1360, Validation Loss: 0.1360,V Acc: 0.3364, Top 70th Acc: 0.3247, Bottom 30th Acc: 0.3636
Fold [4/5] Epoch [10/100] Initial Loss: 0.1386, Training Loss: 0.0232, Initial Validation Loss: 0.1360, Validation Loss: 0.0390,V Acc: 0.8455, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.6364
Fold [4/5] Epoch [20/100] Initial Loss: 0.1386, Training Loss: 0.0054, Initial Validation Loss: 0.1360, Validation Loss: 0.0295,V Acc: 0.8727, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.948051948051948
Fold [5/5] Epoch [0/100] Initial Loss: 0.1392, Training Loss: 0.1392, Initial Validation Loss: 0.1307, Validation Loss: 0.1307,V Acc: 0.2593, Top 70th Acc: 0.3026, Bottom 30th Acc: 0.1562
Fold [5/5] Epoch [10/100] Initial Loss: 0.1392, Training Loss: 0.0275, Initial Validation Loss: 0.1307, Validation Loss: 0.0410,V Acc: 0.7963, Top 70th Acc: 0.8947, Bottom 30th Acc: 0.5625
Fold [5/5] Epoch [20/100] Initial Loss: 0.1392, Training Loss: 0.0058, Initial Validation Loss: 0.1307, Validation Loss: 0.0297,V Acc: 0.8241, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.5625
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.9342105263157895
Running train_nn.py with seed 41
CUDA:False
Training samples count:  550
Training on 163 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1394, Training Loss: 0.1394, Initial Validation Loss: 0.1347, Validation Loss: 0.1347,V Acc: 0.3874, Top 70th Acc: 0.4487, Bottom 30th Acc: 0.2424
Fold [1/5] Epoch [10/100] Initial Loss: 0.1394, Training Loss: 0.0185, Initial Validation Loss: 0.1347, Validation Loss: 0.0396,V Acc: 0.7838, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.4242
Fold [1/5] Epoch [20/100] Initial Loss: 0.1394, Training Loss: 0.0049, Initial Validation Loss: 0.1347, Validation Loss: 0.0337,V Acc: 0.8108, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.5152
Stopping early at Epoch (base 0): 21  Rolling back to Epoch (base 0): 16  Top Validation Acc: 0.9358974358974359
41 0 [array([0.26223898, 0.10216537, 0.07804918, 0.22061221, 0.33693433],
      dtype=float32)]
Fold [2/5] Epoch [0/100] Initial Loss: 0.1417, Training Loss: 0.1417, Initial Validation Loss: 0.1318, Validation Loss: 0.1318,V Acc: 0.3874, Top 70th Acc: 0.4615, Bottom 30th Acc: 0.2121
Fold [4/5] Epoch [0/100] Initial Loss: 0.1362, Training Loss: 0.1362, Initial Validation Loss: 0.1238, Validation Loss: 0.1238,V Acc: 0.5182, Top 70th Acc: 0.5584, Bottom 30th Acc: 0.4242
Fold [4/5] Epoch [10/100] Initial Loss: 0.1362, Training Loss: 0.0823, Initial Validation Loss: 0.1238, Validation Loss: 0.0770,V Acc: 0.6364, Top 70th Acc: 0.7143, Bottom 30th Acc: 0.4545
Fold [4/5] Epoch [20/100] Initial Loss: 0.1362, Training Loss: 0.0800, Initial Validation Loss: 0.1238, Validation Loss: 0.0746,V Acc: 0.6545, Top 70th Acc: 0.7532, Bottom 30th Acc: 0.4242
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.7272727272727273
47 3 [array([0.13541086, 0.36042714, 0.14788458, 0.2286811 , 0.12759632],
      dtype=float32)]
Fold [5/5] Epoch [0/100] Initial Loss: 0.1314, Training Loss: 0.1314, Initial Validation Loss: 0.1170, Validation Loss: 0.1170,V Acc: 0.5278, Top 70th Acc: 0.5658, Bottom 30th Acc: 0.4375
Fold [5/5] Epoch [10/100] Initial Loss: 0.1314, Training Loss: 0.0811, Initial Validation Loss: 0.1170, Validation Loss: 0.0772,V Acc: 0.5926, Top 70th Acc: 0.7500, Bottom 30th Acc: 0.2188
Fold [5/5] Epoch [20/100] Initial Loss: 0.1314, Training Loss: 0.0785, Initial Validation Loss: 0.1170, Validation Loss: 0.0768,V Acc: 0.6019, Top 70th Acc: 0.7500, Bottom 30th Acc: 0.2500
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.75
Running train_nn.py with seed 48
CUDA:False
Training samples count:  550
Training on 2 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1428, Training Loss: 0.1428, Initial Validation Loss: 0.1296, Validation Loss: 0.1296,V Acc: 0.2973, Top 70th Acc: 0.3462, Bottom 30th Acc: 0.1818
Fold [1/5] Epoch [10/100] Initial Loss: 0.1428, Training Loss: 0.0837, Initial Validation Loss: 0.1296, Validation Loss: 0.0719,V Acc: 0.6757, Top 70th Acc: 0.7949, Bottom 30th Acc: 0.3939
Fold [1/5] Epoch [20/100] Initial Loss: 0.1428, Training Loss: 0.0818, Initial Validation Loss: 0.1296, Validation Loss: 0.0698,V Acc: 0.6757, Top 70th Acc: 0.7949, Bottom 30th Acc: 0.3939
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.7948717948717948
Fold [2/5] Epoch [0/100] Initial Loss: 0.1365, Training Loss: 0.1365, Initial Validation Loss: 0.1342, Validation Loss: 0.1342,V Acc: 0.3063, Top 70th Acc: 0.4359, Bottom 30th Acc: 0.0000
Fold [2/5] Epoch [10/100] Initial Loss: 0.1365, Training Loss: 0.0798, Initial Validation Loss: 0.1342, Validation Loss: 0.0864,V Acc: 0.6396, Top 70th Acc: 0.7051, Bottom 30th Acc: 0.4848
Fold [2/5] Epoch [20/100] Initial Loss: 0.1365, Training Loss: 0.0768, Initial Validation Loss: 0.1342, Validation Loss: 0.0846,V Acc: 0.6036, Top 70th Acc: 0.7051, Bottom 30th Acc: 0.3636
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.6923076923076923
48 1 [array([0.1455676 , 0.32802016, 0.16514532, 0.23275322, 0.1285137 ],
      dtype=float32)]
Fold [3/5] Epoch [0/100] Initial Loss: 0.1348, Training Loss: 0.1348, Initial Validation Loss: 0.1238, Validation Loss: 0.1238,V Acc: 0.5000, Top 70th Acc: 0.5325, Bottom 30th Acc: 0.4242
Fold [3/5] Epoch [10/100] Initial Loss: 0.1348, Training Loss: 0.0782, Initial Validation Loss: 0.1238, Validation Loss: 0.0861,V Acc: 0.5818, Top 70th Acc: 0.6883, Bottom 30th Acc: 0.3333
Fold [3/5] Epoch [20/100] Initial Loss: 0.1348, Training Loss: 0.0766, Initial Validation Loss: 0.1238, Validation Loss: 0.0839,V Acc: 0.5909, Top 70th Acc: 0.6623, Bottom 30th Acc: 0.4242
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.6623376623376623
Fold [4/5] Epoch [0/100] Initial Loss: 0.1359, Training Loss: 0.1359, Initial Validation Loss: 0.1240, Validation Loss: 0.1240,V Acc: 0.3727, Top 70th Acc: 0.3636, Bottom 30th Acc: 0.3939
Fold [4/5] Epoch [10/100] Initial Loss: 0.1359, Training Loss: 0.0823, Initial Validation Loss: 0.1240, Validation Loss: 0.0744,V Acc: 0.6364, Top 70th Acc: 0.7532, Bottom 30th Acc: 0.3636
Fold [4/5] Epoch [20/100] Initial Loss: 0.1359, Training Loss: 0.0805, Initial Validation Loss: 0.1240, Validation Loss: 0.0712,V Acc: 0.6182, Top 70th Acc: 0.7662, Bottom 30th Acc: 0.2727
Fold [4/5] Epoch [30/100] Initial Loss: 0.1359, Training Loss: 0.0797, Initial Validation Loss: 0.1240, Validation Loss: 0.0703,V Acc: 0.6364, Top 70th Acc: 0.7792, Bottom 30th Acc: 0.3030
Fold [4/5] Epoch [40/100] Initial Loss: 0.1359, Training Loss: 0.0793, Initial Validation Loss: 0.1240, Validation Loss: 0.0698,V Acc: 0.6182, Top 70th Acc: 0.7662, Bottom 30th Acc: 0.2727
Stopping early at Epoch (base 0): 44  Rolling back to Epoch (base 0): 39  Top Validation Acc: 0.7662337662337663
Fold [5/5] Epoch [0/100] Initial Loss: 0.1394, Training Loss: 0.1394, Initial Validation Loss: 0.1281, Validation Loss: 0.1281,V Acc: 0.5185, Top 70th Acc: 0.6447, Bottom 30th Acc: 0.2188
Fold [5/5] Epoch [10/100] Initial Loss: 0.1394, Training Loss: 0.0799, Initial Validation Loss: 0.1281, Validation Loss: 0.0823,V Acc: 0.6296, Top 70th Acc: 0.7763, Bottom 30th Acc: 0.2812
Fold [5/5] Epoch [20/100] Initial Loss: 0.1394, Training Loss: 0.0782, Initial Validation Loss: 0.1281, Validation Loss: 0.0808,V Acc: 0.6389, Top 70th Acc: 0.7632, Bottom 30th Acc: 0.3438
Fold [5/5] Epoch [30/100] Initial Loss: 0.1394, Training Loss: 0.0778, Initial Validation Loss: 0.1281, Validation Loss: 0.0801,V Acc: 0.6481, Top 70th Acc: 0.7763, Bottom 30th Acc: 0.3438
Stopping early at Epoch (base 0): 30  Rolling back to Epoch (base 0): 25  Top Validation Acc: 0.7763157894736842
Running train_nn.py with seed 49
CUDA:False
Training samples count:  550
Training on 2 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1319, Training Loss: 0.1319, Initial Validation Loss: 0.1195, Validation Loss: 0.1195,V Acc: 0.4234, Top 70th Acc: 0.4231, Bottom 30th Acc: 0.4242
Fold [1/5] Epoch [10/100] Initial Loss: 0.1319, Training Loss: 0.0799, Initial Validation Loss: 0.1195, Validation Loss: 0.0834,V Acc: 0.5946, Top 70th Acc: 0.6795, Bottom 30th Acc: 0.3939
Fold [1/5] Epoch [20/100] Initial Loss: 0.1319, Training Loss: 0.0774, Initial Validation Loss: 0.1195, Validation Loss: 0.0815,V Acc: 0.6036, Top 70th Acc: 0.6923, Bottom 30th Acc: 0.3939
Fold [1/5] Epoch [30/100] Initial Loss: 0.1319, Training Loss: 0.0764, Initial Validation Loss: 0.1195, Validation Loss: 0.0811,V Acc: 0.6126, Top 70th Acc: 0.6795, Bottom 30th Acc: 0.4545
Fold [1/5] Epoch [40/100] Initial Loss: 0.1319, Training Loss: 0.0759, Initial Validation Loss: 0.1195, Validation Loss: 0.0804,V Acc: 0.6306, Top 70th Acc: 0.7051, Bottom 30th Acc: 0.4545
Stopping early at Epoch (base 0): 47  Rolling back to Epoch (base 0): 42  Top Validation Acc: 0.7051282051282052
Fold [2/5] Epoch [0/100] Initial Loss: 0.1282, Training Loss: 0.1282, Initial Validation Loss: 0.1193, Validation Loss: 0.1193,V Acc: 0.6577, Top 70th Acc: 0.6923, Bottom 30th Acc: 0.5758
Fold [2/5] Epoch [10/100] Initial Loss: 0.1282, Training Loss: 0.0816, Initial Validation Loss: 0.1193, Validation Loss: 0.0760,V Acc: 0.6847, Top 70th Acc: 0.7692, Bottom 30th Acc: 0.4848
Fold [2/5] Epoch [20/100] Initial Loss: 0.1282, Training Loss: 0.0800, Initial Validation Loss: 0.1193, Validation Loss: 0.0734,V Acc: 0.6757, Top 70th Acc: 0.7821, Bottom 30th Acc: 0.4242
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.7692307692307693
Fold [3/5] Epoch [0/100] Initial Loss: 0.1424, Training Loss: 0.1424, Initial Validation Loss: 0.1316, Validation Loss: 0.1316,V Acc: 0.2909, Top 70th Acc: 0.3506, Bottom 30th Acc: 0.1515
Fold [3/5] Epoch [10/100] Initial Loss: 0.1424, Training Loss: 0.0799, Initial Validation Loss: 0.1316, Validation Loss: 0.0832,V Acc: 0.5909, Top 70th Acc: 0.7143, Bottom 30th Acc: 0.3030
Fold [3/5] Epoch [20/100] Initial Loss: 0.1424, Training Loss: 0.0782, Initial Validation Loss: 0.1316, Validation Loss: 0.0819,V Acc: 0.6091, Top 70th Acc: 0.7273, Bottom 30th Acc: 0.3333
Fold [3/5] Epoch [30/100] Initial Loss: 0.1424, Training Loss: 0.0776, Initial Validation Loss: 0.1316, Validation Loss: 0.0819,V Acc: 0.6091, Top 70th Acc: 0.7143, Bottom 30th Acc: 0.3636
Stopping early at Epoch (base 0):
Stopping early at Epoch (base 0): 28  Rolling back to Epoch (base 0): 23  Top Validation Acc: 0.8974358974358975
Fold [3/5] Epoch [0/100] Initial Loss: 0.1358, Training Loss: 0.1358, Initial Validation Loss: 0.1278, Validation Loss: 0.1278,V Acc: 0.3818, Top 70th Acc: 0.4935, Bottom 30th Acc: 0.1212
Fold [3/5] Epoch [10/100] Initial Loss: 0.1358, Training Loss: 0.0336, Initial Validation Loss: 0.1278, Validation Loss: 0.0347,V Acc: 0.8455, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.5758
Fold [3/5] Epoch [20/100] Initial Loss: 0.1358, Training Loss: 0.0240, Initial Validation Loss: 0.1278, Validation Loss: 0.0302,V Acc: 0.8364, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.961038961038961
Fold [4/5] Epoch [0/100] Initial Loss: 0.1383, Training Loss: 0.1383, Initial Validation Loss: 0.1342, Validation Loss: 0.1342,V Acc: 0.2273, Top 70th Acc: 0.2727, Bottom 30th Acc: 0.1212
Fold [4/5] Epoch [10/100] Initial Loss: 0.1383, Training Loss: 0.0352, Initial Validation Loss: 0.1342, Validation Loss: 0.0390,V Acc: 0.8091, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.5455
Fold [4/5] Epoch [20/100] Initial Loss: 0.1383, Training Loss: 0.0226, Initial Validation Loss: 0.1342, Validation Loss: 0.0343,V Acc: 0.8545, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.948051948051948
Fold [5/5] Epoch [0/100] Initial Loss: 0.1355, Training Loss: 0.1355, Initial Validation Loss: 0.1355, Validation Loss: 0.1355,V Acc: 0.3241, Top 70th Acc: 0.3684, Bottom 30th Acc: 0.2188
Fold [5/5] Epoch [10/100] Initial Loss: 0.1355, Training Loss: 0.0330, Initial Validation Loss: 0.1355, Validation Loss: 0.0434,V Acc: 0.8333, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.5625
Fold [5/5] Epoch [20/100] Initial Loss: 0.1355, Training Loss: 0.0234, Initial Validation Loss: 0.1355, Validation Loss: 0.0350,V Acc: 0.8519, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.5938
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.9473684210526315
Running train_nn.py with seed 52
CUDA:False
Training samples count:  550
Training on 20 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1399, Training Loss: 0.1399, Initial Validation Loss: 0.1340, Validation Loss: 0.1340,V Acc: 0.2613, Top 70th Acc: 0.2949, Bottom 30th Acc: 0.1818
Fold [1/5] Epoch [10/100] Initial Loss: 0.1399, Training Loss: 0.0455, Initial Validation Loss: 0.1340, Validation Loss: 0.0440,V Acc: 0.7838, Top 70th Acc: 0.8846, Bottom 30th Acc: 0.5455
Fold [1/5] Epoch [20/100] Initial Loss: 0.1399, Training Loss: 0.0249, Initial Validation Loss: 0.1340, Validation Loss: 0.0292,V Acc: 0.8559, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.7273
Fold [1/5] Epoch [30/100] Initial Loss: 0.1399, Training Loss: 0.0219, Initial Validation Loss: 0.1340, Validation Loss: 0.0287,V Acc: 0.8468, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 30  Rolling back to Epoch (base 0): 25  Top Validation Acc: 0.9230769230769231
Fold [2/5] Epoch [0/100] Initial Loss: 0.1343, Training Loss: 0.1343, Initial Validation Loss: 0.1288, Validation Loss: 0.1288,V Acc: 0.3333, Top 70th Acc: 0.4487, Bottom 30th Acc: 0.0606
Fold [2/5] Epoch [10/100] Initial Loss: 0.1343, Training Loss: 0.0358, Initial Validation Loss: 0.1288, Validation Loss: 0.0395,V Acc: 0.8288, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.6061
Fold [2/5] Epoch [20/100] Initial Loss: 0.1343, Training Loss: 0.0233, Initial Validation Loss: 0.1288, Validation Loss: 0.0297,V Acc: 0.8649, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.6667
Fold [2/5] Epoch [30/100] Initial Loss: 0.1343, Training Loss: 0.0214, Initial Validation Loss: 0.1288, Validation Loss: 0.0285,V Acc: 0.8559, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 30  Rolling back to Epoch (base 0): 25  Top Validation Acc: 0.9487179487179487
Fold [3/5] Epoch [0/100] Initial Loss: 0.1397, Training Loss: 0.1397, Initial Validation Loss: 0.1358, Validation Loss: 0.1358,V Acc: 0.3000, Top 70th Acc: 0.3766, Bottom 30th Acc: 0.1212
Fold [3/5] Epoch [10/100] Initial Loss: 0.1397, Training Loss: 0.0321, Initial Validation Loss: 0.1358, Validation Loss: 0.0430,V Acc: 0.8091, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.5758
Fold [3/5] Epoch [20/100] Initial Loss: 0.1397, Training Loss: 0.0218, Initial Validation Loss: 0.1358, Validation Loss: 0.0392,V Acc: 0.8273, Top 70th Acc: 0.8961, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.9090909090909091
52 2 [array([0.29245496, 0.04389215, 0.04869197, 0.30981776, 0.30514318],
      dtype=float32)]
Fold [4/5] Epoch [0/100] Initial Loss: 0.1397, Training Loss: 0.1397, Initial Validation Loss: 0.1340, Validation Loss: 0.1340,V Acc: 0.4091, Top 70th Acc: 0.4805, Bottom 30th Acc: 0.2424
Fold [4/5] Epoch [10/100] Initial Loss: 0.1397, Training Loss: 0.0324, Initial Validation Loss: 0.1340, Validation Loss: 0.0484,V Acc: 0.8000, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.4848
Fold [4/5] Epoch [20/100] Initial Loss: 0.1397, Training Loss: 0.0211, Initial Validation Loss: 0.1340, Validation Loss: 0.0418,V Acc: 0.8182, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.5455
Fold [4/5] Epoch [30/100] Initial Loss: 0.1397, Training Loss: 0.0190, Initial Validation Loss: 0.1340, Validation Loss: 0.0427,V Acc: 0.8455, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 31  Rolling back to Epoch (base 0): 26  Top Validation Acc: 0.922077922077922
Fold [5/5] Epoch [0/100] Initial Loss: 0.1399, Training Loss: 0.1399, Initial Validation Loss: 0.1291, Validation Loss: 0.1291,V Acc: 0.2500, Top 70th Acc: 0.3289, Bottom 30th Acc: 0.0625
Fold [5/5] Epoch [10/100] Initial Loss: 0.1399, Training Loss: 0.0344, Initial Validation Loss: 0.1291, Validation Loss: 0.0351,V Acc: 0.8426, Top 70th Acc: 0.8947, Bottom 30th Acc: 0.7188
Fold [5/5] Epoch [20/100] Initial Loss: 0.1399, Training Loss: 0.0229, Initial Validation Loss: 0.1291, Validation Loss: 0.0295,V Acc: 0.8611, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.6875
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.9210526315789473
Running train_nn.py with seed 53
CUDA:False
Training samples count:  550
Training on 20 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1390, Training Loss: 0.1390, Initial Validation Loss: 0.1368, Validation Loss: 0.1368,V Acc: 0.3063, Top 70th Acc: 0.3590, Bottom 30th Acc: 0.1818
Fold [1/5] Epoch [10/100] Initial Loss: 0.1390, Training Loss: 0.0354, Initial Validation Loss: 0.1368, Validation Loss: 0.0442,V Acc: 0.8198, Top 70th Acc: 0.8974, Bottom 30th Acc: 0.6364
Fold [1/5] Epoch [20/100] Initial Loss: 0.1390, Training Loss: 0.0242, Initial Validation Loss: 0.1368, Validation Loss: 0.0358,V Acc: 0.8288, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.6061
Fold [1/5] Epoch [30/100] Initial Loss: 0.1390, Training Loss: 0.0217, Initial Validation Loss: 0.1368, Validation Loss: 0.0367,V Acc: 0.8198, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 30  Rolling back to Epoch (base 0): 25  Top Validation Acc: 0.9358974358974359
Fold [2/5] Epoch [0/100] Initial Loss: 0.1366, Training Loss: 0.1366, Initial Validation Loss: 0.1278, Validation Loss: 0.1278,V Acc: 0.3874, Top 70th Acc: 0.4359, Bottom 30th Acc: 0.2727
Fold [2/5] Epoch [10/100] Initial Loss: 0.1366, Training Loss: 0.0321, Initial Validation Loss: 0.1278, Validation Loss: 0.0376,V Acc: 0.8198, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.6061
Fold [2/5] Epoch [20/100] Initial Loss: 0.1366, Training Loss: 0.0210, Initial Validation Loss: 0.1278, Validation Loss: 0.0380,V Acc: 0.7748, Top 70th Acc: 0.8974, Bottom 30th Acc: 0.4848
Stopping early at Epoch (base 0): 21  Rolling back to Epoch (base 0): 16  Top Validation Acc: 0.9102564102564102
Fold [3/5] Epoch [0/100] Initial Loss: 0.1402, Training Loss: 0.1402, Initial Validation Loss: 0.1342, Validation Loss: 0.1342,V Acc: 0.3545, Top 70th Acc: 0.3506, Bottom 30th Acc: 0.3636
Fold [3/5] Epoch [10/100] Initial Loss: 0.1402, Training Loss: 0.0438, Initial Validation Loss: 0.1342, Validation Loss: 0.0391,V Acc: 0.8182, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.6061
Fold [4/5] Epoch [10/100] Initial Loss: 0.1402, Training Loss: 0.0304, Initial Validation Loss: 0.1325, Validation Loss: 0.0411,V Acc: 0.8182, Top 70th Acc: 0.8961, Bottom 30th Acc: 0.6364
Fold [4/5] Epoch [20/100] Initial Loss: 0.1402, Training Loss: 0.0137, Initial Validation Loss: 0.1325, Validation Loss: 0.0303,V Acc: 0.8545, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.6061
Fold [4/5] Epoch [30/100] Initial Loss: 0.1402, Training Loss: 0.0110, Initial Validation Loss: 0.1325, Validation Loss: 0.0295,V Acc: 0.8455, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 33  Rolling back to Epoch (base 0): 28  Top Validation Acc: 0.974025974025974
Fold [5/5] Epoch [0/100] Initial Loss: 0.1341, Training Loss: 0.1341, Initial Validation Loss: 0.1321, Validation Loss: 0.1321,V Acc: 0.4722, Top 70th Acc: 0.5395, Bottom 30th Acc: 0.3125
Fold [5/5] Epoch [10/100] Initial Loss: 0.1341, Training Loss: 0.0244, Initial Validation Loss: 0.1321, Validation Loss: 0.0322,V Acc: 0.8981, Top 70th Acc: 0.9868, Bottom 30th Acc: 0.6875
Fold [5/5] Epoch [20/100] Initial Loss: 0.1341, Training Loss: 0.0131, Initial Validation Loss: 0.1321, Validation Loss: 0.0299,V Acc: 0.8704, Top 70th Acc: 0.9868, Bottom 30th Acc: 0.5938
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.9868421052631579
Running train_nn.py with seed 52
CUDA:False
Training samples count:  550
Training on 40 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1405, Training Loss: 0.1405, Initial Validation Loss: 0.1330, Validation Loss: 0.1330,V Acc: 0.4234, Top 70th Acc: 0.5385, Bottom 30th Acc: 0.1515
Fold [1/5] Epoch [10/100] Initial Loss: 0.1405, Training Loss: 0.0261, Initial Validation Loss: 0.1330, Validation Loss: 0.0288,V Acc: 0.8829, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.6667
Fold [1/5] Epoch [20/100] Initial Loss: 0.1405, Training Loss: 0.0136, Initial Validation Loss: 0.1330, Validation Loss: 0.0257,V Acc: 0.8559, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 22  Rolling back to Epoch (base 0): 17  Top Validation Acc: 0.9615384615384616
Fold [2/5] Epoch [0/100] Initial Loss: 0.1411, Training Loss: 0.1411, Initial Validation Loss: 0.1336, Validation Loss: 0.1336,V Acc: 0.3243, Top 70th Acc: 0.3462, Bottom 30th Acc: 0.2727
Fold [2/5] Epoch [10/100] Initial Loss: 0.1411, Training Loss: 0.0375, Initial Validation Loss: 0.1336, Validation Loss: 0.0440,V Acc: 0.7477, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.3636
Fold [2/5] Epoch [20/100] Initial Loss: 0.1411, Training Loss: 0.0167, Initial Validation Loss: 0.1336, Validation Loss: 0.0275,V Acc: 0.8559, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.6061
Fold [2/5] Epoch [30/100] Initial Loss: 0.1411, Training Loss: 0.0125, Initial Validation Loss: 0.1336, Validation Loss: 0.0256,V Acc: 0.8649, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 31  Rolling back to Epoch (base 0): 26  Top Validation Acc: 0.9743589743589743
Fold [3/5] Epoch [0/100] Initial Loss: 0.1389, Training Loss: 0.1389, Initial Validation Loss: 0.1357, Validation Loss: 0.1357,V Acc: 0.3364, Top 70th Acc: 0.4026, Bottom 30th Acc: 0.1818
Fold [3/5] Epoch [10/100] Initial Loss: 0.1389, Training Loss: 0.0272, Initial Validation Loss: 0.1357, Validation Loss: 0.0336,V Acc: 0.8727, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.6667
Fold [3/5] Epoch [20/100] Initial Loss: 0.1389, Training Loss: 0.0147, Initial Validation Loss: 0.1357, Validation Loss: 0.0315,V Acc: 0.8273, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.5152
Stopping early at Epoch (base 0): 20  Rolling back to Epoch (base 0): 15  Top Validation Acc: 0.961038961038961
52 2 [array([0.43036327, 0.03222735, 0.10706708, 0.14872997, 0.28161243],
      dtype=float32)]
Fold [4/5] Epoch [0/100] Initial Loss: 0.1381, Training Loss: 0.1381, Initial Validation Loss: 0.1386, Validation Loss: 0.1386,V Acc: 0.3091, Top 70th Acc: 0.3377, Bottom 30th Acc: 0.2424
Fold [4/5] Epoch [10/100] Initial Loss: 0.1381, Training Loss: 0.0355, Initial Validation Loss: 0.1386, Validation Loss: 0.0538,V Acc: 0.7727, Top 70th Acc: 0.8831, Bottom 30th Acc: 0.5152
Fold [4/5] Epoch [20/100] Initial Loss: 0.1381, Training Loss: 0.0144, Initial Validation Loss: 0.1386, Validation Loss: 0.0413,V Acc: 0.8455, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.935064935064935
Fold [5/5] Epoch [0/100] Initial Loss: 0.1395, Training Loss: 0.1395, Initial Validation Loss: 0.1296, Validation Loss: 0.1296,V Acc: 0.3333, Top 70th Acc: 0.3421, Bottom 30th Acc: 0.3125
Fold [5/5] Epoch [10/100] Initial Loss: 0.1395, Training Loss: 0.0327, Initial Validation Loss: 0.1296, Validation Loss: 0.0388,V Acc: 0.8148, Top 70th Acc: 0.9211, Bottom 30th Acc: 0.5625
Fold [5/5] Epoch [20/100] Initial Loss: 0.1395, Training Loss: 0.0187, Initial Validation Loss: 0.1296, Validation Loss: 0.0341,V Acc: 0.7963, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.4375
Fold [5/5] Epoch [30/100] Initial Loss: 0.1395, Training Loss: 0.0146, Initial Validation Loss: 0.1296, Validation Loss: 0.0297,V Acc: 0.8056, Top 70th Acc: 0.9737, Bottom 30th Acc: 0.4062
Fold [5/5] Epoch [40/100] Initial Loss: 0.1395, Training Loss: 0.0121, Initial Validation Loss: 0.1296, Validation Loss: 0.0270,V Acc: 0.8056, Top 70th Acc: 0.9868, Bottom 30th Acc: 0.3750
Stopping early at Epoch (base 0): 48  Rolling back to Epoch (base 0): 43  Top Validation Acc: 0.9868421052631579
Running train_nn.py with seed 53
CUDA:False
Training samples count:  550
Training on 40 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1380, Training Loss: 0.1380, Initial Validation Loss: 0.1356, Validation Loss: 0.1356,V Acc: 0.3153, Top 70th Acc: 0.3462, Bottom 30th Acc: 0.2424
Fold [1/5] Epoch [10/100] Initial Loss: 0.1380, Training Loss: 0.0336, Initial Validation Loss: 0.1356, Validation Loss: 0.0434,V Acc: 0.8108, Top 70th Acc: 0.8974, Bottom 30th Acc: 0.6061
Fold [1/5] Epoch [20/100] Initial Loss: 0.1380, Training Loss: 0.0145, Initial Validation Loss: 0.1356, Validation Loss: 0.0293,V Acc: 0.8378, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 29  Rolling back to Epoch (base 0): 24  Top Validation Acc: 0.9487179487179487
Fold [2/5] Epoch [0/100] Initial Loss: 0.1398, Training Loss: 0.1398, Initial Validation Loss: 0.1337, Validation Loss: 0.1337,V Acc: 0.2523, Top 70th Acc: 0.2692, Bottom 30th Acc: 0.2121
Fold [2/5] Epoch [10/100] Initial Loss: 0.1398, Training Loss: 0.0290, Initial Validation Loss: 0.1337, Validation Loss: 0.0369,V Acc: 0.8108, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.5152
Fold [2/5] Epoch [20/100] Initial Loss: 0.1398, Training Loss: 0.0135, Initial Validation Loss: 0.1337, Validation Loss: 0.0315,V Acc: 0.8468, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 22  Rolling back to Epoch (base 0): 17  Top Validation Acc: 0.9230769230769231
Fold [3/5] Epoch [0/100] Initial Loss: 0.1402, Training Loss: 0.1402, Initial Validation Loss: 0.1321, Validation Loss: 0.1321,V Acc: 0.4273, Top 70th Acc: 0.4805, Bottom 30th Acc: 0.3030
Fold [3/5] Epoch [10/100] Initial Loss: 0.1402, Training Loss: 0.0281, Initial Validation Loss: 0.1321, Validation Loss: 0.0302,V Acc: 0.8364, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.5455
Fold [3/5] Epoch [20/100] Initial Loss: 0.1402, Training Loss: 0.0145, Initial Validation Loss: 0.1321, Validation Loss: 0.0244,V Acc: 0.8364, Top 70th Acc: 0.9870, Bottom 30th Acc: 0.4848
Fold [3/5] Epoch [30/100] Initial Loss: 0.1402, Training Loss: 0.0117, Initial Validation Loss: 0.1321, Validation Loss: 0.0242,V Acc: 0.8545, Top 70th Acc: 1.0000, Bottom 30th Acc: 0.5152
Stopping early at Epoch (base 0): 30  Rolling back to Epoch (base 0): 25  Top Validation Acc: 1.0
Fold [4/5] Epoch [0/100] Initial Loss: 0.1393, Training Loss: 0.1393, Initial Validation Loss: 0.1357, Validation Loss: 0.1357,V Acc: 0.3273, Top 70th Acc: 0.3247, Bottom 30th Acc: 0.3333
Fold [4/5] Epoch [10/100] Initial Loss: 0.1393, Training Loss: 0.0254, Initial Validation Loss: 0.1357, Validation Loss: 0.0284,V Acc: 0.8909, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.6970
Fold [4/5] Epoch [20/100] Initial Loss: 0.1288, Training Loss: 0.0179, Initial Validation Loss: 0.1202, Validation Loss: 0.0328,V Acc: 0.8545, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 28  Rolling back to Epoch (base 0): 23  Top Validation Acc: 0.9090909090909091
Fold [5/5] Epoch [0/100] Initial Loss: 0.1232, Training Loss: 0.1232, Initial Validation Loss: 0.1084, Validation Loss: 0.1084,V Acc: 0.5370, Top 70th Acc: 0.6447, Bottom 30th Acc: 0.2812
Fold [5/5] Epoch [10/100] Initial Loss: 0.1232, Training Loss: 0.0201, Initial Validation Loss: 0.1084, Validation Loss: 0.0261,V Acc: 0.8981, Top 70th Acc: 0.9868, Bottom 30th Acc: 0.6875
Stopping early at Epoch (base 0): 17  Rolling back to Epoch (base 0): 12  Top Validation Acc: 0.9868421052631579
Running train_nn.py with seed 74
CUDA:False
Training samples count:  550
Training on 21 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1331, Training Loss: 0.1331, Initial Validation Loss: 0.1175, Validation Loss: 0.1175,V Acc: 0.5315, Top 70th Acc: 0.6410, Bottom 30th Acc: 0.2727
Fold [1/5] Epoch [10/100] Initial Loss: 0.1331, Training Loss: 0.0228, Initial Validation Loss: 0.1175, Validation Loss: 0.0238,V Acc: 0.8829, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 17  Rolling back to Epoch (base 0): 12  Top Validation Acc: 0.9487179487179487
Fold [2/5] Epoch [0/100] Initial Loss: 0.1332, Training Loss: 0.1332, Initial Validation Loss: 0.1266, Validation Loss: 0.1266,V Acc: 0.3514, Top 70th Acc: 0.4231, Bottom 30th Acc: 0.1818
Fold [2/5] Epoch [10/100] Initial Loss: 0.1332, Training Loss: 0.0258, Initial Validation Loss: 0.1266, Validation Loss: 0.0431,V Acc: 0.8198, Top 70th Acc: 0.8846, Bottom 30th Acc: 0.6667
Fold [2/5] Epoch [20/100] Initial Loss: 0.1332, Training Loss: 0.0179, Initial Validation Loss: 0.1266, Validation Loss: 0.0300,V Acc: 0.8378, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.9358974358974359
Fold [3/5] Epoch [0/100] Initial Loss: 0.1296, Training Loss: 0.1296, Initial Validation Loss: 0.1172, Validation Loss: 0.1172,V Acc: 0.4455, Top 70th Acc: 0.5455, Bottom 30th Acc: 0.2121
Fold [3/5] Epoch [10/100] Initial Loss: 0.1296, Training Loss: 0.0253, Initial Validation Loss: 0.1172, Validation Loss: 0.0259,V Acc: 0.8818, Top 70th Acc: 0.9870, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 15  Rolling back to Epoch (base 0): 10  Top Validation Acc: 0.961038961038961
74 2 [array([0.6313745 , 0.02759517, 0.03684415, 0.14649972, 0.15768644],
      dtype=float32)]
Fold [4/5] Epoch [0/100] Initial Loss: 0.1336, Training Loss: 0.1336, Initial Validation Loss: 0.1243, Validation Loss: 0.1243,V Acc: 0.4273, Top 70th Acc: 0.4416, Bottom 30th Acc: 0.3939
Fold [4/5] Epoch [10/100] Initial Loss: 0.1336, Training Loss: 0.0219, Initial Validation Loss: 0.1243, Validation Loss: 0.0315,V Acc: 0.8364, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 11  Rolling back to Epoch (base 0): 6  Top Validation Acc: 0.935064935064935
Fold [5/5] Epoch [0/100] Initial Loss: 0.1260, Training Loss: 0.1260, Initial Validation Loss: 0.1028, Validation Loss: 0.1028,V Acc: 0.5648, Top 70th Acc: 0.6447, Bottom 30th Acc: 0.3750
Fold [5/5] Epoch [10/100] Initial Loss: 0.1260, Training Loss: 0.0208, Initial Validation Loss: 0.1028, Validation Loss: 0.0371,V Acc: 0.8056, Top 70th Acc: 0.8947, Bottom 30th Acc: 0.5938
Stopping early at Epoch (base 0): 14  Rolling back to Epoch (base 0): 9  Top Validation Acc: 0.9210526315789473
Running train_nn.py with seed 75
CUDA:False
Training samples count:  550
Training on 21 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1259, Training Loss: 0.1259, Initial Validation Loss: 0.1139, Validation Loss: 0.1139,V Acc: 0.4685, Top 70th Acc: 0.5769, Bottom 30th Acc: 0.2121
Fold [1/5] Epoch [10/100] Initial Loss: 0.1259, Training Loss: 0.0237, Initial Validation Loss: 0.1139, Validation Loss: 0.0383,V Acc: 0.8198, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.5152
Stopping early at Epoch (base 0): 14  Rolling back to Epoch (base 0): 9  Top Validation Acc: 0.9358974358974359
Fold [2/5] Epoch [0/100] Initial Loss: 0.1359, Training Loss: 0.1359, Initial Validation Loss: 0.1306, Validation Loss: 0.1306,V Acc: 0.4775, Top 70th Acc: 0.5385, Bottom 30th Acc: 0.3333
Fold [2/5] Epoch [10/100] Initial Loss: 0.1359, Training Loss: 0.0260, Initial Validation Loss: 0.1306, Validation Loss: 0.0326,V Acc: 0.8649, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.6061
Fold [2/5] Epoch [20/100] Initial Loss: 0.1359, Training Loss: 0.0197, Initial Validation Loss: 0.1306, Validation Loss: 0.0264,V Acc: 0.8919, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.9487179487179487
Fold [3/5] Epoch [0/100] Initial Loss: 0.1342, Training Loss: 0.1342, Initial Validation Loss: 0.1172, Validation Loss: 0.1172,V Acc: 0.5727, Top 70th Acc: 0.6883, Bottom 30th Acc: 0.3030
Fold [3/5] Epoch [10/100] Initial Loss: 0.1342, Training Loss: 0.0270, Initial Validation Loss: 0.1172, Validation Loss: 0.0250,V Acc: 0.8818, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.6970
Fold [3/5] Epoch [20/100] Initial Loss: 0.1342, Training Loss: 0.0185, Initial Validation Loss: 0.1172, Validation Loss: 0.0222,V Acc: 0.9000, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.7576
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.948051948051948
Fold [4/5] Epoch [0/100] Initial Loss: 0.1292, Training Loss: 0.1292, Initial Validation Loss: 0.1090, Validation Loss: 0.1090,V Acc: 0.4364, Top 70th Acc: 0.5455, Bottom 30th Acc: 0.1818
Fold [4/5] Epoch [10/100] Initial Loss: 0.1292, Training Loss: 0.0216, Initial Validation Loss: 0.1090, Validation Loss: 0.0257,V Acc: 0.8364, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 14  Rolling back to Epoch (base 0): 9  Top Validation Acc: 0.9090909090909091
Fold [5/5] Epoch [0/100] Initial Loss: 0.1350, Training Loss: 0.1350, Initial Validation Loss: 0.1292, Validation Loss: 0.1292,V Acc: 0.3796, Top 70th Acc: 0.4605, Bottom 30th Acc: 0.1875
Fold [5/5] Epoch [10/100] Initial Loss: 0.1350, Training Loss: 0.0321, Initial Validation Loss: 0.1292, Validation Loss: 0.0340,V Acc: 0.8796, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.7500
Fold [5/5] Epoch [20/100] Initial Loss: 0.1350, Training Loss: 0.0204, Initial Validation Loss: 0.1292, Validation Loss: 0.0321,V Acc: 0.8796, Top 70th Acc: 0.9737, Bottom 30th Acc: 0.6562
Stopping early at Epoch (base 0): 20  Rolling back to Epoch (base 0): 15  Top Validation Acc: 0.9736842105263158
75 4 [array([0.7854482 , 0.03763411, 0.00659826, 0.08340931, 0.08691008],
      dtype=float32)]
Running train_nn.py with seed 76
CUDA:False
Training samples count:  550
Training on 21 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1342, Training Loss: 0.1342, Initial Validation Loss: 0.1271, Validation Loss: 0.1271,V Acc: 0.4144, Top 70th Acc: 0.5128, Bottom 30th Acc: 0.1818
Fold [1/5] Epoch [10/100] Initial Loss: 0.1342, Training Loss: 0.0277, Initial Validation Loss: 0.1271, Validation Loss: 0.0290,V Acc: 0.8649, Top 70th Acc: 0.9872, Bottom 30th Acc: 0.5758
Fold [1/5] Epoch [20/100] Initial Loss: 0.1342, Training Loss: 0.0200, Initial Validation Loss: 0.1271, Validation Loss: 0.0191,V Acc: 0.9099, Top 70th Acc: 0.9872, Bottom 30th Acc: 0.7273
Fold [1/5] Epoch [30/100] Initial Loss: 0.1342, Training Loss: 0.0175, Initial Validation Loss: 0.1271, Validation Loss: 0.0164,V Acc: 0.9009, Top 70th Acc: 1.0000, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 35  Rolling back to Epoch (base 0): 30  Top Validation Acc: 1.0
Fold [2/5] Epoch [0/100] Initial Loss: 0.1305, Training Loss: 0.1305, Initial Validation Loss: 0.1155, Validation Loss: 0.1155,V Acc: 0.4234, Top 70th Acc: 0.4872, Bottom 30th Acc: 0.2727
Fold [2/5] Epoch [10/100] Initial Loss: 0.1305, Training Loss: 0.0268, Initial Validation Loss: 0.1155, Validation Loss: 0.0304,V Acc: 0.8468, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.5758
Fold [2/5] Epoch [20/100] Initial Loss: 0.1305, Training Loss: 0.0169, Initial Validation Loss: 0.1155, Validation Loss: 0.0220,V Acc: 0.9009, Top 70th Acc: 0.9872, Bottom 30th Acc: 0.6970550
Training on 30 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1380, Training Loss: 0.1380, Initial Validation Loss: 0.1348, Validation Loss: 0.1348,V Acc: 0.3874, Top 70th Acc: 0.4359, Bottom 30th Acc: 0.2727
Fold [1/5] Epoch [10/100] Initial Loss: 0.1380, Training Loss: 0.0379, Initial Validation Loss: 0.1348, Validation Loss: 0.0458,V Acc: 0.7928, Top 70th Acc: 0.8718, Bottom 30th Acc: 0.6061
Fold [1/5] Epoch [20/100] Initial Loss: 0.1380, Training Loss: 0.0191, Initial Validation Loss: 0.1348, Validation Loss: 0.0311,V Acc: 0.8468, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 29  Rolling back to Epoch (base 0): 24  Top Validation Acc: 0.9871794871794872
Fold [2/5] Epoch [0/100] Initial Loss: 0.1384, Training Loss: 0.1384, Initial Validation Loss: 0.1294, Validation Loss: 0.1294,V Acc: 0.3063, Top 70th Acc: 0.3590, Bottom 30th Acc: 0.1818
Fold [2/5] Epoch [10/100] Initial Loss: 0.1384, Training Loss: 0.0312, Initial Validation Loss: 0.1294, Validation Loss: 0.0367,V Acc: 0.8198, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 19  Rolling back to Epoch (base 0): 14  Top Validation Acc: 0.9102564102564102
Fold [3/5] Epoch [0/100] Initial Loss: 0.1390, Training Loss: 0.1390, Initial Validation Loss: 0.1325, Validation Loss: 0.1325,V Acc: 0.3091, Top 70th Acc: 0.3896, Bottom 30th Acc: 0.1212
Fold [3/5] Epoch [10/100] Initial Loss: 0.1390, Training Loss: 0.0415, Initial Validation Loss: 0.1325, Validation Loss: 0.0396,V Acc: 0.8455, Top 70th Acc: 0.8831, Bottom 30th Acc: 0.7576
Fold [3/5] Epoch [20/100] Initial Loss: 0.1390, Training Loss: 0.0196, Initial Validation Loss: 0.1325, Validation Loss: 0.0236,V Acc: 0.8727, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.6364
Fold [3/5] Epoch [30/100] Initial Loss: 0.1390, Training Loss: 0.0170, Initial Validation Loss: 0.1325, Validation Loss: 0.0237,V Acc: 0.8818, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 36  Rolling back to Epoch (base 0): 31  Top Validation Acc: 0.974025974025974
Fold [4/5] Epoch [0/100] Initial Loss: 0.1370, Training Loss: 0.1370, Initial Validation Loss: 0.1340, Validation Loss: 0.1340,V Acc: 0.3364, Top 70th Acc: 0.3766, Bottom 30th Acc: 0.2424
Fold [4/5] Epoch [10/100] Initial Loss: 0.1370, Training Loss: 0.0342, Initial Validation Loss: 0.1340, Validation Loss: 0.0362,V Acc: 0.8545, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.6061
Fold [4/5] Epoch [20/100] Initial Loss: 0.1370, Training Loss: 0.0190, Initial Validation Loss: 0.1340, Validation Loss: 0.0254,V Acc: 0.8727, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.961038961038961
53 3 [array([0.71205676, 0.08917274, 0.0374204 , 0.06563804, 0.09571211],
      dtype=float32)]
Fold [5/5] Epoch [0/100] Initial Loss: 0.1360, Training Loss: 0.1360, Initial Validation Loss: 0.1326, Validation Loss: 0.1326,V Acc: 0.3056, Top 70th Acc: 0.3026, Bottom 30th Acc: 0.3125
Fold [5/5] Epoch [10/100] Initial Loss: 0.1360, Training Loss: 0.0282, Initial Validation Loss: 0.1326, Validation Loss: 0.0355,V Acc: 0.8241, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.5625
Fold [5/5] Epoch [20/100] Initial Loss: 0.1360, Training Loss: 0.0178, Initial Validation Loss: 0.1326, Validation Loss: 0.0290,V Acc: 0.8704, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.6875
Stopping early at Epoch (base 0): 29  Rolling back to Epoch (base 0): 24  Top Validation Acc: 0.9605263157894737
Running train_nn.py with seed 54
CUDA:False
Training samples count:  550
Training on 30 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1394, Training Loss: 0.1394, Initial Validation Loss: 0.1380, Validation Loss: 0.1380,V Acc: 0.3423, Top 70th Acc: 0.3974, Bottom 30th Acc: 0.2121
Fold [1/5] Epoch [10/100] Initial Loss: 0.1394, Training Loss: 0.0278, Initial Validation Loss: 0.1380, Validation Loss: 0.0306,V Acc: 0.9009, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.7273
Stopping early at Epoch (base 0): 19  Rolling back to Epoch (base 0): 14  Top Validation Acc: 0.9743589743589743
Fold [2/5] Epoch [0/100] Initial Loss: 0.1412, Training Loss: 0.1412, Initial Validation Loss: 0.1363, Validation Loss: 0.1363,V Acc: 0.2523, Top 70th Acc: 0.3333, Bottom 30th Acc: 0.0606
Fold [2/5] Epoch [10/100] Initial Loss: 0.1412, Training Loss: 0.0337, Initial Validation Loss: 0.1363, Validation Loss: 0.0298,V Acc: 0.8829, Top 70th Acc: 0.9872, Bottom 30th Acc: 0.6364
Fold [2/5] Epoch [20/100] Initial Loss: 0.1412, Training Loss: 0.0201, Initial Validation Loss: 0.1363, Validation Loss: 0.0204,V Acc: 0.9099, Top 70th Acc: 1.0000, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 28  Rolling back to Epoch (base 0): 23  Top Validation Acc: 0.9871794871794872
Fold [3/5] Epoch [0/100] Initial Loss: 0.1371, Training Loss: 0.1371, Initial Validation Loss: 0.1304, Validation Loss: 0.1304,V Acc: 0.3091, Top 70th Acc: 0.3506, Bottom 30th Acc: 0.2121
Fold [3/5] Epoch [10/100] Initial Loss: 0.1371, Training Loss: 0.0249, Initial Validation Loss: 0.1304, Validation Loss: 0.0367,V Acc: 0.8273, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.6364
Fold [3/5] Epoch [20/100] Initial Loss: 0.1371, Training Loss: 0.0170, Initial Validation Loss: 0.1304, Validation Loss: 0.0342,V Acc: 0.8636, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.7576
Stopping early at Epoch (base 0): 20  Rolling back to Epoch (base 0): 15  Top Validation Acc: 0.9090909090909091
Fold [4/5] Epoch [0/100] Initial Loss: 0.1393, Training Loss: 0.1393, Initial Validation Loss: 0.1330, Validation Loss: 0.1330,V Acc: 0.2727, Top 70th Acc: 0.3247, Bottom 30th Acc: 0.1515
Fold [4/5] Epoch [10/100] Initial Loss: 0.1393, Training Loss: 0.0305, Initial Validation Loss: 0.1330, Validation Loss: 0.0401,V Acc: 0.8091, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.5758
Fold [4/5] Epoch [20/100] Initial Loss: 0.1393, Training Loss: 0.0162, Initial Validation Loss: 0.1330, Validation Loss: 0.0321,V Acc: 0.8273, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 27  Rolling back to Epoch (base 0): 22  Top Validation Acc: 0.922077922077922
54 3 [array([0.6435344 , 0.13246265, 0.05081552, 0.09536433, 0.07782316],
      dtype=float32)]
Fold [5/5] Epoch [0/100] Initial Loss: 0.1376, Training Loss: 0.1376, Initial Validation Loss: 0.1291, Validation Loss: 0.1291,V Acc: 0.4074, Top 70th Acc: 0.5000, Bottom 30th Acc: 0.1875
Fold [5/5] Epoch [10/100] Initial Loss: 0.1376, Training Loss: 0.0412, Initial Validation Loss: 0.1291, Validation Loss: 0.0458,V Acc: 0.7778, Top 70th Acc: 0.9079, Bottom 30th Acc: 0.4688
Fold [5/5] Epoch [20/100] Initial Loss: 0.1376, Training Loss: 0.0226, Initial Validation Loss: 0.1291, Validation Loss: 0.0336,V Acc: 0.7963, Top 70th Acc: 0.9737, Bottom 30th Acc: 0.3750
Fold [5/5] Epoch [30/100] Initial Loss: 0.1376, Training Loss: 0.0163, Initial Validation Loss: 0.1291, Validation Loss: 0.0309,V Acc: 0.8519, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.6250
Stopping early at Epoch (base 0): 37  Rolling back to Epoch (base 0): 32  Top Validation Acc: 0.9473684210526315
Running train_nn.py with seed 55
CUDA:False
Training samples count:  550
Training on 30 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1394, Training Loss: 0.1394, Initial Validation Loss: 0.1376, Validation Loss: 0.1376,V Acc: 0.2432, Top 70th Acc: 0.2179, Bottom 30th Acc: 0.3030
Fold [1/5] Epoch [10/100] Initial Loss: 0.1394, Training Loss: 0.0326, Initial Validation Loss: 0.1376, Validation Loss: 0.0400,V Acc: 0.8378, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.6364
Fold [1/5] Epoch [20/100] Initial Loss: 0.1394, Training Loss: 0.0197, Initial Validation Loss: 0.1376, Validation Loss: 0.0319,V Acc: 0.8378, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.9487179487179487
Fold [2/5] Epoch [0/100] Initial Loss: 0.1388, Training Loss: 0.1388, Initial Validation Loss: 0.1383, Validation Loss: 0.1383,V Acc: 0.2523, Top 70th Acc: 0.2949, Bottom 30th Acc: 0.1515
Fold [2/5] Epoch [10/100] Initial Loss: 0.1388, Training Loss: 0.0370, Initial Validation Loss: 0.1383, Validation Loss: 0.0432,V Acc: 0.7838, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.3939 36  Rolling back to Epoch (base 0): 31  Top Validation Acc: 0.7272727272727273
Fold [4/5] Epoch [0/100] Initial Loss: 0.1411, Training Loss: 0.1411, Initial Validation Loss: 0.1336, Validation Loss: 0.1336,V Acc: 0.3273, Top 70th Acc: 0.4156, Bottom 30th Acc: 0.1212
Fold [4/5] Epoch [10/100] Initial Loss: 0.1411, Training Loss: 0.0811, Initial Validation Loss: 0.1336, Validation Loss: 0.0786,V Acc: 0.6091, Top 70th Acc: 0.7403, Bottom 30th Acc: 0.3030
Fold [4/5] Epoch [20/100] Initial Loss: 0.1411, Training Loss: 0.0786, Initial Validation Loss: 0.1336, Validation Loss: 0.0783,V Acc: 0.6091, Top 70th Acc: 0.7532, Bottom 30th Acc: 0.2727
Stopping early at Epoch (base 0): 22  Rolling back to Epoch (base 0): 17  Top Validation Acc: 0.7532467532467533
Fold [5/5] Epoch [0/100] Initial Loss: 0.1330, Training Loss: 0.1330, Initial Validation Loss: 0.1167, Validation Loss: 0.1167,V Acc: 0.5000, Top 70th Acc: 0.5395, Bottom 30th Acc: 0.4062
Fold [5/5] Epoch [10/100] Initial Loss: 0.1330, Training Loss: 0.0810, Initial Validation Loss: 0.1167, Validation Loss: 0.0786,V Acc: 0.6296, Top 70th Acc: 0.7368, Bottom 30th Acc: 0.3750
Fold [5/5] Epoch [20/100] Initial Loss: 0.1330, Training Loss: 0.0791, Initial Validation Loss: 0.1167, Validation Loss: 0.0775,V Acc: 0.6389, Top 70th Acc: 0.7500, Bottom 30th Acc: 0.3750
Stopping early at Epoch (base 0): 27  Rolling back to Epoch (base 0): 22  Top Validation Acc: 0.7236842105263158
49 4 [array([0.1578734 , 0.31443536, 0.14795877, 0.22366987, 0.15606248],
      dtype=float32)]
Running train_nn.py with seed 50
CUDA:False
Training samples count:  550
Training on 2 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1394, Training Loss: 0.1394, Initial Validation Loss: 0.1381, Validation Loss: 0.1381,V Acc: 0.2432, Top 70th Acc: 0.2564, Bottom 30th Acc: 0.2121
Fold [1/5] Epoch [10/100] Initial Loss: 0.1394, Training Loss: 0.0791, Initial Validation Loss: 0.1381, Validation Loss: 0.0895,V Acc: 0.5586, Top 70th Acc: 0.6795, Bottom 30th Acc: 0.2727
Fold [1/5] Epoch [20/100] Initial Loss: 0.1394, Training Loss: 0.0768, Initial Validation Loss: 0.1381, Validation Loss: 0.0879,V Acc: 0.5766, Top 70th Acc: 0.6923, Bottom 30th Acc: 0.3030
Fold [1/5] Epoch [30/100] Initial Loss: 0.1394, Training Loss: 0.0760, Initial Validation Loss: 0.1381, Validation Loss: 0.0880,V Acc: 0.5676, Top 70th Acc: 0.7051, Bottom 30th Acc: 0.2424
Stopping early at Epoch (base 0): 32  Rolling back to Epoch (base 0): 27  Top Validation Acc: 0.6923076923076923
Fold [2/5] Epoch [0/100] Initial Loss: 0.1351, Training Loss: 0.1351, Initial Validation Loss: 0.1206, Validation Loss: 0.1206,V Acc: 0.5315, Top 70th Acc: 0.6154, Bottom 30th Acc: 0.3333
Fold [2/5] Epoch [10/100] Initial Loss: 0.1351, Training Loss: 0.0808, Initial Validation Loss: 0.1206, Validation Loss: 0.0779,V Acc: 0.6216, Top 70th Acc: 0.7051, Bottom 30th Acc: 0.4242
Fold [2/5] Epoch [20/100] Initial Loss: 0.1351, Training Loss: 0.0792, Initial Validation Loss: 0.1206, Validation Loss: 0.0767,V Acc: 0.6036, Top 70th Acc: 0.7436, Bottom 30th Acc: 0.2727
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.717948717948718
Fold [3/5] Epoch [0/100] Initial Loss: 0.1346, Training Loss: 0.1346, Initial Validation Loss: 0.1263, Validation Loss: 0.1263,V Acc: 0.4909, Top 70th Acc: 0.5325, Bottom 30th Acc: 0.3939
Fold [3/5] Epoch [10/100] Initial Loss: 0.1346, Training Loss: 0.0821, Initial Validation Loss: 0.1263, Validation Loss: 0.0781,V Acc: 0.6545, Top 70th Acc: 0.7792, Bottom 30th Acc: 0.3636
Fold [3/5] Epoch [20/100] Initial Loss: 0.1346, Training Loss: 0.0791, Initial Validation Loss: 0.1263, Validation Loss: 0.0766,V Acc: 0.6364, Top 70th Acc: 0.7792, Bottom 30th Acc: 0.3030
Fold [3/5] Epoch [30/100] Initial Loss: 0.1346, Training Loss: 0.0781, Initial Validation Loss: 0.1263, Validation Loss: 0.0760,V Acc: 0.6636, Top 70th Acc: 0.7792, Bottom 30th Acc: 0.3939
Stopping early at Epoch (base 0): 37  Rolling back to Epoch (base 0): 32  Top Validation Acc: 0.7792207792207793
Fold [4/5] Epoch [0/100] Initial Loss: 0.1353, Training Loss: 0.1353, Initial Validation Loss: 0.1243, Validation Loss: 0.1243,V Acc: 0.5364, Top 70th Acc: 0.5325, Bottom 30th Acc: 0.5455
Fold [4/5] Epoch [10/100] Initial Loss: 0.1353, Training Loss: 0.0845, Initial Validation Loss: 0.1243, Validation Loss: 0.0738,V Acc: 0.7182, Top 70th Acc: 0.7792, Bottom 30th Acc: 0.5758
Fold [4/5] Epoch [20/100] Initial Loss: 0.1353, Training Loss: 0.0817, Initial Validation Loss: 0.1243, Validation Loss: 0.0708,V Acc: 0.7364, Top 70th Acc: 0.7532, Bottom 30th Acc: 0.6970
Fold [4/5] Epoch [30/100] Initial Loss: 0.1353, Training Loss: 0.0807, Initial Validation Loss: 0.1243, Validation Loss: 0.0707,V Acc: 0.7091, Top 70th Acc: 0.7532, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 30  Rolling back to Epoch (base 0): 25  Top Validation Acc: 0.7532467532467533
Fold [5/5] Epoch [0/100] Initial Loss: 0.1326, Training Loss: 0.1326, Initial Validation Loss: 0.1186, Validation Loss: 0.1186,V Acc: 0.3796, Top 70th Acc: 0.5263, Bottom 30th Acc: 0.0312
Fold [5/5] Epoch [10/100] Initial Loss: 0.1326, Training Loss: 0.0804, Initial Validation Loss: 0.1186, Validation Loss: 0.0826,V Acc: 0.5648, Top 70th Acc: 0.6842, Bottom 30th Acc: 0.2812
Fold [5/5] Epoch [20/100] Initial Loss: 0.1326, Training Loss: 0.0780, Initial Validation Loss: 0.1186, Validation Loss: 0.0802,V Acc: 0.5833, Top 70th Acc: 0.7237, Bottom 30th Acc: 0.2500
Fold [5/5] Epoch [30/100] Initial Loss: 0.1326, Training Loss: 0.0771, Initial Validation Loss: 0.1186, Validation Loss: 0.0800,V Acc: 0.5741, Top 70th Acc: 0.7105, Bottom 30th Acc: 0.2500
Fold [5/5] Epoch [40/100] Initial Loss: 0.1326, Training Loss: 0.0768, Initial Validation Loss: 0.1186, Validation Loss: 0.0792,V Acc: 0.5833, Top 70th Acc: 0.7237, Bottom 30th Acc: 0.2500
Fold [5/5] Epoch [50/100] Initial Loss: 0.1326, Training Loss: 0.0763, Initial Validation Loss: 0.1186, Validation Loss: 0.0792,V Acc: 0.5926, Top 70th Acc: 0.7237, Bottom 30th Acc: 0.2812
Stopping early at Epoch (base 0): 52  Rolling back to Epoch (base 0): 47  Top Validation Acc: 0.7236842105263158
50 4 [array([0.13936771, 0.3069163 , 0.14818881, 0.24876536, 0.15676184],
      dtype=float32)]
Running train_nn.py with seed 51
CUDA:False
Training samples count:  550
Training on 2 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1400, Training Loss: 0.1400, Initial Validation Loss: 0.1334, Validation Loss: 0.1334,V Acc: 0.2523, Top 70th Acc: 0.3462, Bottom 30th Acc: 0.0303
Fold [1/5] Epoch [10/100] Initial Loss: 0.1400, Training Loss: 0.0804, Initial Validation Loss: 0.1334, Validation Loss: 0.0820,V Acc: 0.5856, Top 70th Acc: 0.7308, Bottom 30th Acc: 0.2424
Fold [1/5] Epoch [20/100] Initial Loss: 0.1400, Training Loss: 0.0780, Initial Validation Loss: 0.1334, Validation Loss: 0.0810,V Acc: 0.5946, Top 70th Acc: 0.7308, Bottom 30th Acc: 0.2727
Stopping early at Epoch (base 0): 27  Rolling back to Epoch (base 0): 22  Top Validation Acc: 0.7435897435897436
51 0 [array([0.146917  , 0.36002344, 0.14184271, 0.2266362 , 0.12458064],
      dtype=float32)]
Fold [2/5] Epoch [0/100] Initial Loss: 0.1328, Training Loss: 0.1328, Initial Validation Loss: 0.1232, Validation Loss: 0.1232,V Acc: 0.3874, Top 70th Acc: 0.4615, Bottom 30th Acc: 0.2121
Fold [2/5] Epoch [10/100] Initial Loss: 0.1328, Training Loss: 0.0813, Initial Validation Loss: 0.1232, Validation Loss: 0.0820,V Acc: 0.6396, Top 70th Acc: 0.7051, Bottom 30th Acc: 0.4848
Fold [2/5] Epoch [20/100] Initial Loss: 0.1328, Training Loss: 0.0795, Initial Validation Loss: 0.1232, Validation Loss: 0.0787,V Acc: 0.6306, Top 70th Acc: 0.6923, Bottom 30th Acc: 0.4848
Fold [2/5] Epoch [30/100] Initial Loss: 0.1328, Training Loss: 0.0786, Initial Validation Loss: 0.1232, Validation Loss: 0.0775,V Acc: 0.6216, Top 70th Acc: 0.6923, Bottom 30th Acc: 0.4545
Stopping early at Epoch (base 0): 34  Rolling back to Epoch (base 0): 29  Top Validation Acc: 0.7051282051282052
Fold [3/5] Epoch [0/100] Initial Loss: 0.1456, Training Loss: 0.1456, Initial Validation Loss: 0.1346, Validation Loss: 0.1346,V Acc: 0.4364, Top 70th Acc: 0.6104, Bottom 30th Acc: 0.0303
Fold [3/5] Epoch [10/100] Initial Loss: 0.1456, Training Loss: 0.0836, Initial Validation Loss: 0.1346, Validation Loss: 0.0720,V Acc: 0.6727, Top 70th Acc: 0.8052, Bottom 30th Acc: 0.3636/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)

Fold [3/5] Epoch [20/100] Initial Loss: 0.1402, Training Loss: 0.0260, Initial Validation Loss: 0.1342, Validation Loss: 0.0249,V Acc: 0.8455, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.5455
Fold [3/5] Epoch [30/100] Initial Loss: 0.1402, Training Loss: 0.0235, Initial Validation Loss: 0.1342, Validation Loss: 0.0249,V Acc: 0.8727, Top 70th Acc: 0.9870, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 34  Rolling back to Epoch (base 0): 29  Top Validation Acc: 0.974025974025974
Fold [4/5] Epoch [0/100] Initial Loss: 0.1391, Training Loss: 0.1391, Initial Validation Loss: 0.1361, Validation Loss: 0.1361,V Acc: 0.3364, Top 70th Acc: 0.3896, Bottom 30th Acc: 0.2121
Fold [4/5] Epoch [10/100] Initial Loss: 0.1391, Training Loss: 0.0489, Initial Validation Loss: 0.1361, Validation Loss: 0.0501,V Acc: 0.7909, Top 70th Acc: 0.8831, Bottom 30th Acc: 0.5758
Fold [4/5] Epoch [20/100] Initial Loss: 0.1391, Training Loss: 0.0302, Initial Validation Loss: 0.1361, Validation Loss: 0.0328,V Acc: 0.8182, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.4848
Fold [4/5] Epoch [30/100] Initial Loss: 0.1391, Training Loss: 0.0244, Initial Validation Loss: 0.1361, Validation Loss: 0.0284,V Acc: 0.8727, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.6364
Fold [4/5] Epoch [40/100] Initial Loss: 0.1391, Training Loss: 0.0230, Initial Validation Loss: 0.1361, Validation Loss: 0.0268,V Acc: 0.9000, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.7273
Fold [4/5] Epoch [50/100] Initial Loss: 0.1391, Training Loss: 0.0220, Initial Validation Loss: 0.1361, Validation Loss: 0.0275,V Acc: 0.8818, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.7273
Stopping early at Epoch (base 0): 52  Rolling back to Epoch (base 0): 47  Top Validation Acc: 0.961038961038961
53 3 [array([0.32215893, 0.06452962, 0.14222184, 0.25446725, 0.21662235],
      dtype=float32)]
Fold [5/5] Epoch [0/100] Initial Loss: 0.1392, Training Loss: 0.1392, Initial Validation Loss: 0.1347, Validation Loss: 0.1347,V Acc: 0.2500, Top 70th Acc: 0.2632, Bottom 30th Acc: 0.2188
Fold [5/5] Epoch [10/100] Initial Loss: 0.1392, Training Loss: 0.0431, Initial Validation Loss: 0.1347, Validation Loss: 0.0447,V Acc: 0.7778, Top 70th Acc: 0.8947, Bottom 30th Acc: 0.5000
Fold [5/5] Epoch [20/100] Initial Loss: 0.1392, Training Loss: 0.0257, Initial Validation Loss: 0.1347, Validation Loss: 0.0323,V Acc: 0.8704, Top 70th Acc: 0.9211, Bottom 30th Acc: 0.7500
Stopping early at Epoch (base 0): 28  Rolling back to Epoch (base 0): 23  Top Validation Acc: 0.9473684210526315
Running train_nn.py with seed 54
CUDA:False
Training samples count:  550
Training on 20 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1422, Training Loss: 0.1422, Initial Validation Loss: 0.1426, Validation Loss: 0.1426,V Acc: 0.2793, Top 70th Acc: 0.2821, Bottom 30th Acc: 0.2727
Fold [1/5] Epoch [10/100] Initial Loss: 0.1422, Training Loss: 0.0488, Initial Validation Loss: 0.1426, Validation Loss: 0.0497,V Acc: 0.8018, Top 70th Acc: 0.8846, Bottom 30th Acc: 0.6061
Fold [1/5] Epoch [20/100] Initial Loss: 0.1422, Training Loss: 0.0240, Initial Validation Loss: 0.1426, Validation Loss: 0.0287,V Acc: 0.8919, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.6970
Fold [1/5] Epoch [30/100] Initial Loss: 0.1422, Training Loss: 0.0210, Initial Validation Loss: 0.1426, Validation Loss: 0.0274,V Acc: 0.8829, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 38  Rolling back to Epoch (base 0): 33  Top Validation Acc: 0.9743589743589743
Fold [2/5] Epoch [0/100] Initial Loss: 0.1411, Training Loss: 0.1411, Initial Validation Loss: 0.1348, Validation Loss: 0.1348,V Acc: 0.2523, Top 70th Acc: 0.3333, Bottom 30th Acc: 0.0606
Fold [2/5] Epoch [10/100] Initial Loss: 0.1411, Training Loss: 0.0349, Initial Validation Loss: 0.1348, Validation Loss: 0.0305,V Acc: 0.8919, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.6970
Fold [2/5] Epoch [20/100] Initial Loss: 0.1411, Training Loss: 0.0227, Initial Validation Loss: 0.1348, Validation Loss: 0.0267,V Acc: 0.8559, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 21  Rolling back to Epoch (base 0): 16  Top Validation Acc: 0.9743589743589743
Fold [3/5] Epoch [0/100] Initial Loss: 0.1389, Training Loss: 0.1389, Initial Validation Loss: 0.1305, Validation Loss: 0.1305,V Acc: 0.3455, Top 70th Acc: 0.3766, Bottom 30th Acc: 0.2727
Fold [3/5] Epoch [10/100] Initial Loss: 0.1389, Training Loss: 0.0295, Initial Validation Loss: 0.1305, Validation Loss: 0.0377,V Acc: 0.8364, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.6364
Fold [3/5] Epoch [20/100] Initial Loss: 0.1389, Training Loss: 0.0211, Initial Validation Loss: 0.1305, Validation Loss: 0.0333,V Acc: 0.8636, Top 70th Acc: 0.8961, Bottom 30th Acc: 0.7879
Fold [3/5] Epoch [30/100] Initial Loss: 0.1389, Training Loss: 0.0193, Initial Validation Loss: 0.1305, Validation Loss: 0.0315,V Acc: 0.8545, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.6970
Fold [3/5] Epoch [40/100] Initial Loss: 0.1389, Training Loss: 0.0181, Initial Validation Loss: 0.1305, Validation Loss: 0.0310,V Acc: 0.8545, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 40  Rolling back to Epoch (base 0): 35  Top Validation Acc: 0.922077922077922
Fold [4/5] Epoch [0/100] Initial Loss: 0.1390, Training Loss: 0.1390, Initial Validation Loss: 0.1323, Validation Loss: 0.1323,V Acc: 0.3636, Top 70th Acc: 0.4935, Bottom 30th Acc: 0.0606
Fold [4/5] Epoch [10/100] Initial Loss: 0.1390, Training Loss: 0.0360, Initial Validation Loss: 0.1323, Validation Loss: 0.0461,V Acc: 0.7909, Top 70th Acc: 0.8571, Bottom 30th Acc: 0.6364
Fold [4/5] Epoch [20/100] Initial Loss: 0.1390, Training Loss: 0.0227, Initial Validation Loss: 0.1323, Validation Loss: 0.0374,V Acc: 0.8091, Top 70th Acc: 0.8831, Bottom 30th Acc: 0.6364
Fold [4/5] Epoch [30/100] Initial Loss: 0.1390, Training Loss: 0.0189, Initial Validation Loss: 0.1323, Validation Loss: 0.0355,V Acc: 0.8273, Top 70th Acc: 0.8701, Bottom 30th Acc: 0.7273
Stopping early at Epoch (base 0): 35  Rolling back to Epoch (base 0): 30  Top Validation Acc: 0.8831168831168831
54 3 [array([0.31073734, 0.06399535, 0.0984078 , 0.30569166, 0.22116786],
      dtype=float32)]
Fold [5/5] Epoch [0/100] Initial Loss: 0.1398, Training Loss: 0.1398, Initial Validation Loss: 0.1326, Validation Loss: 0.1326,V Acc: 0.3611, Top 70th Acc: 0.4342, Bottom 30th Acc: 0.1875
Fold [5/5] Epoch [10/100] Initial Loss: 0.1398, Training Loss: 0.0399, Initial Validation Loss: 0.1326, Validation Loss: 0.0416,V Acc: 0.7778, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.4062
Fold [5/5] Epoch [20/100] Initial Loss: 0.1398, Training Loss: 0.0231, Initial Validation Loss: 0.1326, Validation Loss: 0.0306,V Acc: 0.8241, Top 70th Acc: 0.9737, Bottom 30th Acc: 0.4688
Stopping early at Epoch (base 0): 27  Rolling back to Epoch (base 0): 22  Top Validation Acc: 0.9605263157894737
Running train_nn.py with seed 55
CUDA:False
Training samples count:  550
Training on 20 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1383, Training Loss: 0.1383, Initial Validation Loss: 0.1371, Validation Loss: 0.1371,V Acc: 0.2613, Top 70th Acc: 0.3462, Bottom 30th Acc: 0.0606
Fold [1/5] Epoch [10/100] Initial Loss: 0.1383, Training Loss: 0.0365, Initial Validation Loss: 0.1371, Validation Loss: 0.0406,V Acc: 0.8378, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.6667
Fold [1/5] Epoch [20/100] Initial Loss: 0.1383, Training Loss: 0.0247, Initial Validation Loss: 0.1371, Validation Loss: 0.0322,V Acc: 0.8468, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.6061
Fold [1/5] Epoch [30/100] Initial Loss: 0.1383, Training Loss: 0.0225, Initial Validation Loss: 0.1371, Validation Loss: 0.0308,V Acc: 0.8468, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 33  Rolling back to Epoch (base 0): 28  Top Validation Acc: 0.9487179487179487
Fold [2/5] Epoch [0/100] Initial Loss: 0.1336, Training Loss: 0.1336, Initial Validation Loss: 0.1313, Validation Loss: 0.1313,V Acc: 0.4505, Top 70th Acc: 0.5513, Bottom 30th Acc: 0.2121
Fold [2/5] Epoch [10/100] Initial Loss: 0.1336, Training Loss: 0.0288, Initial Validation Loss: 0.1313, Validation Loss: 0.0356,V Acc: 0.8559, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.6667
Fold [2/5] Epoch [10/100] Initial Loss: 0.1417, Training Loss: 0.0148, Initial Validation Loss: 0.1318, Validation Loss: 0.0273,V Acc: 0.8739, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.7273
Fold [2/5] Epoch [20/100] Initial Loss: 0.1417, Training Loss: 0.0049, Initial Validation Loss: 0.1318, Validation Loss: 0.0236,V Acc: 0.8559, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.9487179487179487
Fold [3/5] Epoch [0/100] Initial Loss: 0.1401, Training Loss: 0.1401, Initial Validation Loss: 0.1381, Validation Loss: 0.1381,V Acc: 0.2636, Top 70th Acc: 0.3377, Bottom 30th Acc: 0.0909
Fold [3/5] Epoch [10/100] Initial Loss: 0.1401, Training Loss: 0.0218, Initial Validation Loss: 0.1381, Validation Loss: 0.0432,V Acc: 0.7818, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.4545
Fold [3/5] Epoch [20/100] Initial Loss: 0.1401, Training Loss: 0.0052, Initial Validation Loss: 0.1381, Validation Loss: 0.0343,V Acc: 0.8091, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.5152
Fold [3/5] Epoch [30/100] Initial Loss: 0.1401, Training Loss: 0.0041, Initial Validation Loss: 0.1381, Validation Loss: 0.0338,V Acc: 0.8273, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 30  Rolling back to Epoch (base 0): 25  Top Validation Acc: 0.948051948051948
Fold [4/5] Epoch [0/100] Initial Loss: 0.1392, Training Loss: 0.1392, Initial Validation Loss: 0.1356, Validation Loss: 0.1356,V Acc: 0.2545, Top 70th Acc: 0.3117, Bottom 30th Acc: 0.1212
Fold [4/5] Epoch [10/100] Initial Loss: 0.1392, Training Loss: 0.0163, Initial Validation Loss: 0.1356, Validation Loss: 0.0362,V Acc: 0.8545, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.6667
Fold [4/5] Epoch [20/100] Initial Loss: 0.1392, Training Loss: 0.0049, Initial Validation Loss: 0.1356, Validation Loss: 0.0292,V Acc: 0.8727, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.7273
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.922077922077922
Fold [5/5] Epoch [0/100] Initial Loss: 0.1393, Training Loss: 0.1393, Initial Validation Loss: 0.1315, Validation Loss: 0.1315,V Acc: 0.3704, Top 70th Acc: 0.4868, Bottom 30th Acc: 0.0938
Fold [5/5] Epoch [10/100] Initial Loss: 0.1393, Training Loss: 0.0238, Initial Validation Loss: 0.1315, Validation Loss: 0.0399,V Acc: 0.7963, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.4688
Fold [5/5] Epoch [20/100] Initial Loss: 0.1393, Training Loss: 0.0064, Initial Validation Loss: 0.1315, Validation Loss: 0.0358,V Acc: 0.8333, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.5938
Fold [5/5] Epoch [30/100] Initial Loss: 0.1393, Training Loss: 0.0045, Initial Validation Loss: 0.1315, Validation Loss: 0.0335,V Acc: 0.8333, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.5625
Stopping early at Epoch (base 0): 33  Rolling back to Epoch (base 0): 28  Top Validation Acc: 0.9473684210526315
Running train_nn.py with seed 42
CUDA:False
Training samples count:  550
Training on 163 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1396, Training Loss: 0.1396, Initial Validation Loss: 0.1350, Validation Loss: 0.1350,V Acc: 0.2973, Top 70th Acc: 0.4103, Bottom 30th Acc: 0.0303
Fold [1/5] Epoch [10/100] Initial Loss: 0.1396, Training Loss: 0.0156, Initial Validation Loss: 0.1350, Validation Loss: 0.0362,V Acc: 0.8288, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.5758
Fold [1/5] Epoch [20/100] Initial Loss: 0.1396, Training Loss: 0.0051, Initial Validation Loss: 0.1350, Validation Loss: 0.0289,V Acc: 0.8559, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 21  Rolling back to Epoch (base 0): 16  Top Validation Acc: 0.9358974358974359
Fold [2/5] Epoch [0/100] Initial Loss: 0.1406, Training Loss: 0.1406, Initial Validation Loss: 0.1336, Validation Loss: 0.1336,V Acc: 0.2523, Top 70th Acc: 0.3590, Bottom 30th Acc: 0.0000
Fold [2/5] Epoch [10/100] Initial Loss: 0.1406, Training Loss: 0.0122, Initial Validation Loss: 0.1336, Validation Loss: 0.0380,V Acc: 0.7928, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.5152
Fold [2/5] Epoch [20/100] Initial Loss: 0.1406, Training Loss: 0.0051, Initial Validation Loss: 0.1336, Validation Loss: 0.0347,V Acc: 0.8018, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.5455
Fold [2/5] Epoch [30/100] Initial Loss: 0.1406, Training Loss: 0.0037, Initial Validation Loss: 0.1336, Validation Loss: 0.0342,V Acc: 0.8198, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 36  Rolling back to Epoch (base 0): 31  Top Validation Acc: 0.9230769230769231
42 1 [array([0.39884648, 0.04970962, 0.11720922, 0.1920531 , 0.24218154],
      dtype=float32)]
Fold [3/5] Epoch [0/100] Initial Loss: 0.1368, Training Loss: 0.1368, Initial Validation Loss: 0.1316, Validation Loss: 0.1316,V Acc: 0.3636, Top 70th Acc: 0.4156, Bottom 30th Acc: 0.2424
Fold [3/5] Epoch [10/100] Initial Loss: 0.1368, Training Loss: 0.0193, Initial Validation Loss: 0.1316, Validation Loss: 0.0350,V Acc: 0.8273, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.6061
Fold [3/5] Epoch [20/100] Initial Loss: 0.1368, Training Loss: 0.0056, Initial Validation Loss: 0.1316, Validation Loss: 0.0289,V Acc: 0.8727, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.961038961038961
Fold [4/5] Epoch [0/100] Initial Loss: 0.1369, Training Loss: 0.1369, Initial Validation Loss: 0.1336, Validation Loss: 0.1336,V Acc: 0.3182, Top 70th Acc: 0.3896, Bottom 30th Acc: 0.1515
Fold [4/5] Epoch [10/100] Initial Loss: 0.1369, Training Loss: 0.0148, Initial Validation Loss: 0.1336, Validation Loss: 0.0280,V Acc: 0.8636, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.6061
Fold [4/5] Epoch [20/100] Initial Loss: 0.1369, Training Loss: 0.0052, Initial Validation Loss: 0.1336, Validation Loss: 0.0241,V Acc: 0.8727, Top 70th Acc: 0.9870, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.987012987012987
Fold [5/5] Epoch [0/100] Initial Loss: 0.1394, Training Loss: 0.1394, Initial Validation Loss: 0.1346, Validation Loss: 0.1346,V Acc: 0.3056, Top 70th Acc: 0.3026, Bottom 30th Acc: 0.3125
Fold [5/5] Epoch [10/100] Initial Loss: 0.1394, Training Loss: 0.0275, Initial Validation Loss: 0.1346, Validation Loss: 0.0488,V Acc: 0.8333, Top 70th Acc: 0.8947, Bottom 30th Acc: 0.6875
Fold [5/5] Epoch [20/100] Initial Loss: 0.1394, Training Loss: 0.0049, Initial Validation Loss: 0.1346, Validation Loss: 0.0380,V Acc: 0.8426, Top 70th Acc: 0.9211, Bottom 30th Acc: 0.6562
Fold [5/5] Epoch [30/100] Initial Loss: 0.1394, Training Loss: 0.0038, Initial Validation Loss: 0.1346, Validation Loss: 0.0376,V Acc: 0.8426, Top 70th Acc: 0.9079, Bottom 30th Acc: 0.6875
Fold [5/5] Epoch [40/100] Initial Loss: 0.1394, Training Loss: 0.0035, Initial Validation Loss: 0.1346, Validation Loss: 0.0372,V Acc: 0.8426, Top 70th Acc: 0.9079, Bottom 30th Acc: 0.6875
Fold [5/5] Epoch [50/100] Initial Loss: 0.1394, Training Loss: 0.0034, Initial Validation Loss: 0.1346, Validation Loss: 0.0369,V Acc: 0.8333, Top 70th Acc: 0.9211, Bottom 30th Acc: 0.6250
Stopping early at Epoch (base 0): 53  Rolling back to Epoch (base 0): 48  Top Validation Acc: 0.9210526315789473
Running train_nn.py with seed 43
CUDA:False
Training samples count:  550
Training on 163 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1399, Training Loss: 0.1399, Initial Validation Loss: 0.1321, Validation Loss: 0.1321,V Acc: 0.2432, Top 70th Acc: 0.3077, Bottom 30th Acc: 0.0909
Fold [1/5] Epoch [10/100] Initial Loss: 0.1399, Training Loss: 0.0218, Initial Validation Loss: 0.1321, Validation Loss: 0.0417,V Acc: 0.7748, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.4545
Fold [1/5] Epoch [20/100] Initial Loss: 0.1399, Training Loss: 0.0054, Initial Validation Loss: 0.1321, Validation Loss: 0.0375,V Acc: 0.7838, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.4848
Fold [1/5] Epoch [30/100] Initial Loss: 0.1399, Training Loss: 0.0042, Initial Validation Loss: 0.1321, Validation Loss: 0.0356,V Acc: 0.8108, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.5152
Fold [1/5] Epoch [40/100] Initial Loss: 0.1399, Training Loss: 0.0039, Initial Validation Loss: 0.1321, Validation Loss: 0.0343,V Acc: 0.8108, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.5152
Fold [4/5] Epoch [20/100] Initial Loss: 0.1393, Training Loss: 0.0150, Initial Validation Loss: 0.1357, Validation Loss: 0.0238,V Acc: 0.8818, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 28  Rolling back to Epoch (base 0): 23  Top Validation Acc: 0.974025974025974
53 3 [array([0.5836091 , 0.03376157, 0.12721857, 0.12295335, 0.13245735],
      dtype=float32)]
Fold [5/5] Epoch [0/100] Initial Loss: 0.1336, Training Loss: 0.1336, Initial Validation Loss: 0.1292, Validation Loss: 0.1292,V Acc: 0.3426, Top 70th Acc: 0.4342, Bottom 30th Acc: 0.1250
Fold [5/5] Epoch [10/100] Initial Loss: 0.1336, Training Loss: 0.0277, Initial Validation Loss: 0.1292, Validation Loss: 0.0345,V Acc: 0.8704, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.7188
Fold [5/5] Epoch [20/100] Initial Loss: 0.1336, Training Loss: 0.0140, Initial Validation Loss: 0.1292, Validation Loss: 0.0272,V Acc: 0.8889, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.7188
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.9605263157894737
Running train_nn.py with seed 54
CUDA:False
Training samples count:  550
Training on 40 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1376, Training Loss: 0.1376, Initial Validation Loss: 0.1374, Validation Loss: 0.1374,V Acc: 0.4324, Top 70th Acc: 0.5256, Bottom 30th Acc: 0.2121
Fold [1/5] Epoch [10/100] Initial Loss: 0.1376, Training Loss: 0.0294, Initial Validation Loss: 0.1374, Validation Loss: 0.0367,V Acc: 0.8739, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.6667
Fold [1/5] Epoch [20/100] Initial Loss: 0.1376, Training Loss: 0.0145, Initial Validation Loss: 0.1374, Validation Loss: 0.0315,V Acc: 0.8739, Top 70th Acc: 1.0000, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 1.0
Fold [2/5] Epoch [0/100] Initial Loss: 0.1393, Training Loss: 0.1393, Initial Validation Loss: 0.1343, Validation Loss: 0.1343,V Acc: 0.3874, Top 70th Acc: 0.4359, Bottom 30th Acc: 0.2727
Fold [2/5] Epoch [10/100] Initial Loss: 0.1393, Training Loss: 0.0392, Initial Validation Loss: 0.1343, Validation Loss: 0.0393,V Acc: 0.7838, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.4545
Fold [2/5] Epoch [20/100] Initial Loss: 0.1393, Training Loss: 0.0165, Initial Validation Loss: 0.1343, Validation Loss: 0.0226,V Acc: 0.9009, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.8182
Stopping early at Epoch (base 0): 28  Rolling back to Epoch (base 0): 23  Top Validation Acc: 0.9358974358974359
Fold [3/5] Epoch [0/100] Initial Loss: 0.1357, Training Loss: 0.1357, Initial Validation Loss: 0.1263, Validation Loss: 0.1263,V Acc: 0.4091, Top 70th Acc: 0.4416, Bottom 30th Acc: 0.3333
Fold [3/5] Epoch [10/100] Initial Loss: 0.1357, Training Loss: 0.0294, Initial Validation Loss: 0.1263, Validation Loss: 0.0455,V Acc: 0.7909, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.5152
Fold [3/5] Epoch [20/100] Initial Loss: 0.1357, Training Loss: 0.0141, Initial Validation Loss: 0.1263, Validation Loss: 0.0336,V Acc: 0.8455, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.6970
Fold [3/5] Epoch [30/100] Initial Loss: 0.1357, Training Loss: 0.0113, Initial Validation Loss: 0.1263, Validation Loss: 0.0341,V Acc: 0.8364, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.6061
Fold [3/5] Epoch [40/100] Initial Loss: 0.1357, Training Loss: 0.0103, Initial Validation Loss: 0.1263, Validation Loss: 0.0332,V Acc: 0.8455, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 40  Rolling back to Epoch (base 0): 35  Top Validation Acc: 0.935064935064935
Fold [4/5] Epoch [0/100] Initial Loss: 0.1440, Training Loss: 0.1440, Initial Validation Loss: 0.1337, Validation Loss: 0.1337,V Acc: 0.3091, Top 70th Acc: 0.3506, Bottom 30th Acc: 0.2121
Fold [4/5] Epoch [10/100] Initial Loss: 0.1440, Training Loss: 0.0284, Initial Validation Loss: 0.1337, Validation Loss: 0.0388,V Acc: 0.8273, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.6364
Fold [4/5] Epoch [20/100] Initial Loss: 0.1440, Training Loss: 0.0130, Initial Validation Loss: 0.1337, Validation Loss: 0.0321,V Acc: 0.8273, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.6061
Fold [4/5] Epoch [30/100] Initial Loss: 0.1440, Training Loss: 0.0104, Initial Validation Loss: 0.1337, Validation Loss: 0.0319,V Acc: 0.8364, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 31  Rolling back to Epoch (base 0): 26  Top Validation Acc: 0.935064935064935
54 3 [array([0.6829861 , 0.10796474, 0.04678129, 0.05407482, 0.108193  ],
      dtype=float32)]
Fold [5/5] Epoch [0/100] Initial Loss: 0.1380, Training Loss: 0.1380, Initial Validation Loss: 0.1321, Validation Loss: 0.1321,V Acc: 0.3148, Top 70th Acc: 0.2763, Bottom 30th Acc: 0.4062
Fold [5/5] Epoch [10/100] Initial Loss: 0.1380, Training Loss: 0.0247, Initial Validation Loss: 0.1321, Validation Loss: 0.0311,V Acc: 0.8426, Top 70th Acc: 0.9737, Bottom 30th Acc: 0.5312
Fold [5/5] Epoch [20/100] Initial Loss: 0.1380, Training Loss: 0.0132, Initial Validation Loss: 0.1321, Validation Loss: 0.0270,V Acc: 0.8519, Top 70th Acc: 0.9737, Bottom 30th Acc: 0.5625
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.9736842105263158
Running train_nn.py with seed 55
CUDA:False
Training samples count:  550
Training on 40 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1403, Training Loss: 0.1403, Initial Validation Loss: 0.1359, Validation Loss: 0.1359,V Acc: 0.3423, Top 70th Acc: 0.3590, Bottom 30th Acc: 0.3030
Fold [1/5] Epoch [10/100] Initial Loss: 0.1403, Training Loss: 0.0392, Initial Validation Loss: 0.1359, Validation Loss: 0.0427,V Acc: 0.8108, Top 70th Acc: 0.8974, Bottom 30th Acc: 0.6061
Fold [1/5] Epoch [20/100] Initial Loss: 0.1403, Training Loss: 0.0191, Initial Validation Loss: 0.1359, Validation Loss: 0.0309,V Acc: 0.8198, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.4848
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.9743589743589743
Fold [2/5] Epoch [0/100] Initial Loss: 0.1365, Training Loss: 0.1365, Initial Validation Loss: 0.1347, Validation Loss: 0.1347,V Acc: 0.3153, Top 70th Acc: 0.2949, Bottom 30th Acc: 0.3636
Fold [2/5] Epoch [10/100] Initial Loss: 0.1365, Training Loss: 0.0277, Initial Validation Loss: 0.1347, Validation Loss: 0.0326,V Acc: 0.8739, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.6970
Fold [2/5] Epoch [20/100] Initial Loss: 0.1365, Training Loss: 0.0147, Initial Validation Loss: 0.1347, Validation Loss: 0.0270,V Acc: 0.8919, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.7576
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.9487179487179487
Fold [3/5] Epoch [0/100] Initial Loss: 0.1372, Training Loss: 0.1372, Initial Validation Loss: 0.1268, Validation Loss: 0.1268,V Acc: 0.2818, Top 70th Acc: 0.3506, Bottom 30th Acc: 0.1212
Fold [3/5] Epoch [10/100] Initial Loss: 0.1372, Training Loss: 0.0317, Initial Validation Loss: 0.1268, Validation Loss: 0.0490,V Acc: 0.7364, Top 70th Acc: 0.8442, Bottom 30th Acc: 0.4848
Fold [3/5] Epoch [20/100] Initial Loss: 0.1372, Training Loss: 0.0132, Initial Validation Loss: 0.1268, Validation Loss: 0.0366,V Acc: 0.7909, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.5152
Fold [3/5] Epoch [30/100] Initial Loss: 0.1372, Training Loss: 0.0106, Initial Validation Loss: 0.1268, Validation Loss: 0.0362,V Acc: 0.8091, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 36  Rolling back to Epoch (base 0): 31  Top Validation Acc: 0.9090909090909091
55 2 [array([0.8174659 , 0.02788922, 0.04192146, 0.0527204 , 0.06000311],
      dtype=float32)]
Fold [4/5] Epoch [0/100] Initial Loss: 0.1400, Training Loss: 0.1400, Initial Validation Loss: 0.1355, Validation Loss: 0.1355,V Acc: 0.2909, Top 70th Acc: 0.2727, Bottom 30th Acc: 0.3333
Fold [4/5] Epoch [10/100] Initial Loss: 0.1400, Training Loss: 0.0430, Initial Validation Loss: 0.1355, Validation Loss: 0.0467,V Acc: 0.7909, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.5152
Fold [4/5] Epoch [20/100] Initial Loss: 0.1400, Training Loss: 0.0167, Initial Validation Loss: 0.1355, Validation Loss: 0.0248,V Acc: 0.8636, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.9871794871794872
Fold [3/5] Epoch [0/100] Initial Loss: 0.1366, Training Loss: 0.1366, Initial Validation Loss: 0.1271, Validation Loss: 0.1271,V Acc: 0.4909, Top 70th Acc: 0.5325, Bottom 30th Acc: 0.3939
Fold [3/5] Epoch [10/100] Initial Loss: 0.1366, Training Loss: 0.0274, Initial Validation Loss: 0.1271, Validation Loss: 0.0365,V Acc: 0.8455, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 16  Rolling back to Epoch (base 0): 11  Top Validation Acc: 0.9090909090909091
Fold [4/5] Epoch [0/100] Initial Loss: 0.1335, Training Loss: 0.1335, Initial Validation Loss: 0.1262, Validation Loss: 0.1262,V Acc: 0.5545, Top 70th Acc: 0.6883, Bottom 30th Acc: 0.2424
Fold [4/5] Epoch [10/100] Initial Loss: 0.1335, Training Loss: 0.0278, Initial Validation Loss: 0.1262, Validation Loss: 0.0348,V Acc: 0.8545, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 16  Rolling back to Epoch (base 0): 11  Top Validation Acc: 0.935064935064935
76 3 [array([0.75495684, 0.02068084, 0.06027415, 0.07079218, 0.09329603],
      dtype=float32)]
Fold [5/5] Epoch [0/100] Initial Loss: 0.1337, Training Loss: 0.1337, Initial Validation Loss: 0.1176, Validation Loss: 0.1176,V Acc: 0.4444, Top 70th Acc: 0.5658, Bottom 30th Acc: 0.1562
Fold [5/5] Epoch [10/100] Initial Loss: 0.1337, Training Loss: 0.0241, Initial Validation Loss: 0.1176, Validation Loss: 0.0391,V Acc: 0.8056, Top 70th Acc: 0.9211, Bottom 30th Acc: 0.5312
Stopping early at Epoch (base 0): 19  Rolling back to Epoch (base 0): 14  Top Validation Acc: 0.881578947368421
Running train_nn.py with seed 77
CUDA:False
Training samples count:  550
Training on 21 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1374, Training Loss: 0.1374, Initial Validation Loss: 0.1341, Validation Loss: 0.1341,V Acc: 0.4324, Top 70th Acc: 0.5513, Bottom 30th Acc: 0.1515
Fold [1/5] Epoch [10/100] Initial Loss: 0.1374, Training Loss: 0.0237, Initial Validation Loss: 0.1341, Validation Loss: 0.0297,V Acc: 0.8739, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 15  Rolling back to Epoch (base 0): 10  Top Validation Acc: 0.9230769230769231
Fold [2/5] Epoch [0/100] Initial Loss: 0.1319, Training Loss: 0.1319, Initial Validation Loss: 0.1150, Validation Loss: 0.1150,V Acc: 0.4324, Top 70th Acc: 0.5385, Bottom 30th Acc: 0.1818
Fold [2/5] Epoch [10/100] Initial Loss: 0.1319, Training Loss: 0.0241, Initial Validation Loss: 0.1150, Validation Loss: 0.0341,V Acc: 0.8378, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 16  Rolling back to Epoch (base 0): 11  Top Validation Acc: 0.9102564102564102
Fold [3/5] Epoch [0/100] Initial Loss: 0.1264, Training Loss: 0.1264, Initial Validation Loss: 0.1098, Validation Loss: 0.1098,V Acc: 0.5091, Top 70th Acc: 0.6104, Bottom 30th Acc: 0.2727
Fold [3/5] Epoch [10/100] Initial Loss: 0.1264, Training Loss: 0.0236, Initial Validation Loss: 0.1098, Validation Loss: 0.0370,V Acc: 0.8545, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 13  Rolling back to Epoch (base 0): 8  Top Validation Acc: 0.948051948051948
Fold [4/5] Epoch [0/100] Initial Loss: 0.1310, Training Loss: 0.1310, Initial Validation Loss: 0.1190, Validation Loss: 0.1190,V Acc: 0.4818, Top 70th Acc: 0.6104, Bottom 30th Acc: 0.1818
Fold [4/5] Epoch [10/100] Initial Loss: 0.1310, Training Loss: 0.0356, Initial Validation Loss: 0.1190, Validation Loss: 0.0413,V Acc: 0.8000, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.5455
Fold [4/5] Epoch [20/100] Initial Loss: 0.1310, Training Loss: 0.0194, Initial Validation Loss: 0.1190, Validation Loss: 0.0278,V Acc: 0.8909, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.961038961038961
Fold [5/5] Epoch [0/100] Initial Loss: 0.1373, Training Loss: 0.1373, Initial Validation Loss: 0.1279, Validation Loss: 0.1279,V Acc: 0.4815, Top 70th Acc: 0.5263, Bottom 30th Acc: 0.3750
Fold [5/5] Epoch [10/100] Initial Loss: 0.1373, Training Loss: 0.0304, Initial Validation Loss: 0.1279, Validation Loss: 0.0488,V Acc: 0.7778, Top 70th Acc: 0.8947, Bottom 30th Acc: 0.5000
Fold [5/5] Epoch [20/100] Initial Loss: 0.1373, Training Loss: 0.0219, Initial Validation Loss: 0.1279, Validation Loss: 0.0277,V Acc: 0.8519, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.5938
Stopping early at Epoch (base 0): 27  Rolling back to Epoch (base 0): 22  Top Validation Acc: 0.9473684210526315
77 4 [array([0.73986405, 0.0275943 , 0.01464609, 0.14452407, 0.07337146],
      dtype=float32)]
Running train_nn.py with seed 78
CUDA:False
Training samples count:  550
Training on 21 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1333, Training Loss: 0.1333, Initial Validation Loss: 0.1231, Validation Loss: 0.1231,V Acc: 0.4685, Top 70th Acc: 0.6154, Bottom 30th Acc: 0.1212
Fold [1/5] Epoch [10/100] Initial Loss: 0.1333, Training Loss: 0.0305, Initial Validation Loss: 0.1231, Validation Loss: 0.0283,V Acc: 0.8919, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.7273
Fold [1/5] Epoch [20/100] Initial Loss: 0.1333, Training Loss: 0.0194, Initial Validation Loss: 0.1231, Validation Loss: 0.0235,V Acc: 0.8919, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.9871794871794872
Fold [2/5] Epoch [0/100] Initial Loss: 0.1241, Training Loss: 0.1241, Initial Validation Loss: 0.1083, Validation Loss: 0.1083,V Acc: 0.5946, Top 70th Acc: 0.6667, Bottom 30th Acc: 0.4242
Fold [2/5] Epoch [10/100] Initial Loss: 0.1241, Training Loss: 0.0218, Initial Validation Loss: 0.1083, Validation Loss: 0.0348,V Acc: 0.8198, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.5152
Stopping early at Epoch (base 0): 19  Rolling back to Epoch (base 0): 14  Top Validation Acc: 0.9487179487179487
Fold [3/5] Epoch [0/100] Initial Loss: 0.1305, Training Loss: 0.1305, Initial Validation Loss: 0.1247, Validation Loss: 0.1247,V Acc: 0.4545, Top 70th Acc: 0.5195, Bottom 30th Acc: 0.3030
Fold [3/5] Epoch [10/100] Initial Loss: 0.1305, Training Loss: 0.0266, Initial Validation Loss: 0.1247, Validation Loss: 0.0379,V Acc: 0.8091, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.4848
Fold [3/5] Epoch [20/100] Initial Loss: 0.1305, Training Loss: 0.0183, Initial Validation Loss: 0.1247, Validation Loss: 0.0286,V Acc: 0.8727, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 27  Rolling back to Epoch (base 0): 22  Top Validation Acc: 0.961038961038961
Fold [4/5] Epoch [0/100] Initial Loss: 0.1328, Training Loss: 0.1328, Initial Validation Loss: 0.1195, Validation Loss: 0.1195,V Acc: 0.6091, Top 70th Acc: 0.6753, Bottom 30th Acc: 0.4545
Fold [4/5] Epoch [10/100] Initial Loss: 0.1328, Training Loss: 0.0250, Initial Validation Loss: 0.1195, Validation Loss: 0.0343,V Acc: 0.8091, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.4848
Stopping early at Epoch (base 0): 16  Rolling back to Epoch (base 0): 11  Top Validation Acc: 0.948051948051948
78 3 [array([0.7115625 , 0.02154474, 0.03390987, 0.09643915, 0.13654377],
      dtype=float32)]
Fold [5/5] Epoch [0/100] Initial Loss: 0.1338, Training Loss: 0.1338, Initial Validation Loss: 0.1191, Validation Loss: 0.1191,V Acc: 0.5000, Top 70th Acc: 0.6184, Bottom 30th Acc: 0.2188
Fold [5/5] Epoch [10/100] Initial Loss: 0.1338, Training Loss: 0.0248, Initial Validation Loss: 0.1191, Validation Loss: 0.0267,V Acc: 0.8796, Top 70th Acc: 0.9737, Bottom 30th Acc: 0.6562
Fold [5/5] Epoch [20/100] Initial Loss: 0.1338, Training Loss: 0.0193, Initial Validation Loss: 0.1191, Validation Loss: 0.0244,V Acc: 0.8611, Top 70th Acc: 0.9737, Bottom 30th Acc: 0.5938
Stopping early at Epoch (base 0): 22  Rolling back to Epoch (base 0): 17  Top Validation Acc: 0.9605263157894737
Running train_nn.py with seed 79
CUDA:False
Training samples count:  550
Training on 21 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1275, Training Loss: 0.1275, Initial Validation Loss: 0.1107, Validation Loss: 0.1107,V Acc: 0.4595, Top 70th Acc: 0.5513, Bottom 30th Acc: 0.2424
Fold [1/5] Epoch [10/100] Initial Loss: 0.1275, Training Loss: 0.0279, Initial Validation Loss: 0.1107, Validation Loss: 0.0319,V Acc: 0.8559, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.6667
Fold [2/5] Epoch [20/100] Initial Loss: 0.1388, Training Loss: 0.0200, Initial Validation Loss: 0.1383, Validation Loss: 0.0357,V Acc: 0.8378, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.5758
Fold [2/5] Epoch [30/100] Initial Loss: 0.1388, Training Loss: 0.0170, Initial Validation Loss: 0.1383, Validation Loss: 0.0323,V Acc: 0.8198, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.5152
Fold [2/5] Epoch [40/100] Initial Loss: 0.1388, Training Loss: 0.0159, Initial Validation Loss: 0.1383, Validation Loss: 0.0300,V Acc: 0.8468, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 45  Rolling back to Epoch (base 0): 40  Top Validation Acc: 0.9487179487179487
Fold [3/5] Epoch [0/100] Initial Loss: 0.1379, Training Loss: 0.1379, Initial Validation Loss: 0.1258, Validation Loss: 0.1258,V Acc: 0.3273, Top 70th Acc: 0.3506, Bottom 30th Acc: 0.2727
Fold [3/5] Epoch [10/100] Initial Loss: 0.1379, Training Loss: 0.0268, Initial Validation Loss: 0.1258, Validation Loss: 0.0407,V Acc: 0.7818, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.4848
Fold [3/5] Epoch [20/100] Initial Loss: 0.1379, Training Loss: 0.0171, Initial Validation Loss: 0.1258, Validation Loss: 0.0359,V Acc: 0.8091, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.935064935064935
55 2 [array([0.75565904, 0.05967411, 0.03409847, 0.06814738, 0.082421  ],
      dtype=float32)]
Fold [4/5] Epoch [0/100] Initial Loss: 0.1379, Training Loss: 0.1379, Initial Validation Loss: 0.1351, Validation Loss: 0.1351,V Acc: 0.3909, Top 70th Acc: 0.4545, Bottom 30th Acc: 0.2424
Fold [4/5] Epoch [10/100] Initial Loss: 0.1379, Training Loss: 0.0373, Initial Validation Loss: 0.1351, Validation Loss: 0.0324,V Acc: 0.8727, Top 70th Acc: 0.9870, Bottom 30th Acc: 0.6061
Fold [4/5] Epoch [20/100] Initial Loss: 0.1379, Training Loss: 0.0219, Initial Validation Loss: 0.1351, Validation Loss: 0.0260,V Acc: 0.8818, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 28  Rolling back to Epoch (base 0): 23  Top Validation Acc: 1.0
Fold [5/5] Epoch [0/100] Initial Loss: 0.1406, Training Loss: 0.1406, Initial Validation Loss: 0.1321, Validation Loss: 0.1321,V Acc: 0.2963, Top 70th Acc: 0.3553, Bottom 30th Acc: 0.1562
Fold [5/5] Epoch [10/100] Initial Loss: 0.1406, Training Loss: 0.0262, Initial Validation Loss: 0.1321, Validation Loss: 0.0389,V Acc: 0.7870, Top 70th Acc: 0.9079, Bottom 30th Acc: 0.5000
Fold [5/5] Epoch [20/100] Initial Loss: 0.1406, Training Loss: 0.0174, Initial Validation Loss: 0.1321, Validation Loss: 0.0349,V Acc: 0.8056, Top 70th Acc: 0.9211, Bottom 30th Acc: 0.5312
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.9210526315789473
Running train_nn.py with seed 56
CUDA:False
Training samples count:  550
Training on 30 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1395, Training Loss: 0.1395, Initial Validation Loss: 0.1367, Validation Loss: 0.1367,V Acc: 0.2883, Top 70th Acc: 0.3590, Bottom 30th Acc: 0.1212
Fold [1/5] Epoch [10/100] Initial Loss: 0.1395, Training Loss: 0.0288, Initial Validation Loss: 0.1367, Validation Loss: 0.0438,V Acc: 0.7838, Top 70th Acc: 0.8846, Bottom 30th Acc: 0.5455
Fold [1/5] Epoch [20/100] Initial Loss: 0.1395, Training Loss: 0.0179, Initial Validation Loss: 0.1367, Validation Loss: 0.0377,V Acc: 0.8198, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 27  Rolling back to Epoch (base 0): 22  Top Validation Acc: 0.9230769230769231
Fold [2/5] Epoch [0/100] Initial Loss: 0.1367, Training Loss: 0.1367, Initial Validation Loss: 0.1343, Validation Loss: 0.1343,V Acc: 0.3243, Top 70th Acc: 0.3846, Bottom 30th Acc: 0.1818
Fold [2/5] Epoch [10/100] Initial Loss: 0.1367, Training Loss: 0.0347, Initial Validation Loss: 0.1343, Validation Loss: 0.0357,V Acc: 0.8378, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.6061
Fold [2/5] Epoch [20/100] Initial Loss: 0.1367, Training Loss: 0.0194, Initial Validation Loss: 0.1343, Validation Loss: 0.0260,V Acc: 0.8919, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.7576
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.9487179487179487
Fold [3/5] Epoch [0/100] Initial Loss: 0.1368, Training Loss: 0.1368, Initial Validation Loss: 0.1315, Validation Loss: 0.1315,V Acc: 0.3818, Top 70th Acc: 0.4805, Bottom 30th Acc: 0.1515
Fold [3/5] Epoch [10/100] Initial Loss: 0.1368, Training Loss: 0.0319, Initial Validation Loss: 0.1315, Validation Loss: 0.0385,V Acc: 0.8091, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.5152
Fold [3/5] Epoch [20/100] Initial Loss: 0.1368, Training Loss: 0.0182, Initial Validation Loss: 0.1315, Validation Loss: 0.0323,V Acc: 0.8636, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.6970
Fold [3/5] Epoch [30/100] Initial Loss: 0.1368, Training Loss: 0.0163, Initial Validation Loss: 0.1315, Validation Loss: 0.0314,V Acc: 0.8727, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.7273
Stopping early at Epoch (base 0): 32  Rolling back to Epoch (base 0): 27  Top Validation Acc: 0.935064935064935
Fold [4/5] Epoch [0/100] Initial Loss: 0.1387, Training Loss: 0.1387, Initial Validation Loss: 0.1345, Validation Loss: 0.1345,V Acc: 0.3364, Top 70th Acc: 0.3506, Bottom 30th Acc: 0.3030
Fold [4/5] Epoch [10/100] Initial Loss: 0.1387, Training Loss: 0.0344, Initial Validation Loss: 0.1345, Validation Loss: 0.0395,V Acc: 0.8364, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.5152
Fold [4/5] Epoch [20/100] Initial Loss: 0.1387, Training Loss: 0.0172, Initial Validation Loss: 0.1345, Validation Loss: 0.0310,V Acc: 0.8545, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.961038961038961
56 3 [array([0.59156126, 0.07330684, 0.05874184, 0.18469861, 0.09169149],
      dtype=float32)]
Fold [5/5] Epoch [0/100] Initial Loss: 0.1413, Training Loss: 0.1413, Initial Validation Loss: 0.1329, Validation Loss: 0.1329,V Acc: 0.2407, Top 70th Acc: 0.3026, Bottom 30th Acc: 0.0938
Fold [5/5] Epoch [10/100] Initial Loss: 0.1413, Training Loss: 0.0433, Initial Validation Loss: 0.1329, Validation Loss: 0.0414,V Acc: 0.8241, Top 70th Acc: 0.9079, Bottom 30th Acc: 0.6250
Fold [5/5] Epoch [20/100] Initial Loss: 0.1413, Training Loss: 0.0204, Initial Validation Loss: 0.1329, Validation Loss: 0.0266,V Acc: 0.8519, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.5938
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.9605263157894737
Running train_nn.py with seed 57
CUDA:False
Training samples count:  550
Training on 30 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1413, Training Loss: 0.1413, Initial Validation Loss: 0.1335, Validation Loss: 0.1335,V Acc: 0.2613, Top 70th Acc: 0.3462, Bottom 30th Acc: 0.0606
Fold [1/5] Epoch [10/100] Initial Loss: 0.1413, Training Loss: 0.0450, Initial Validation Loss: 0.1335, Validation Loss: 0.0535,V Acc: 0.7568, Top 70th Acc: 0.8590, Bottom 30th Acc: 0.5152
Fold [1/5] Epoch [20/100] Initial Loss: 0.1413, Training Loss: 0.0203, Initial Validation Loss: 0.1335, Validation Loss: 0.0350,V Acc: 0.8468, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.6667
Fold [1/5] Epoch [30/100] Initial Loss: 0.1413, Training Loss: 0.0158, Initial Validation Loss: 0.1335, Validation Loss: 0.0327,V Acc: 0.8468, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 32  Rolling back to Epoch (base 0): 27  Top Validation Acc: 0.9358974358974359
57 0 [array([0.5821603 , 0.17675637, 0.02637827, 0.1029742 , 0.11173088],
      dtype=float32)]
Fold [2/5] Epoch [0/100] Initial Loss: 0.1382, Training Loss: 0.1382, Initial Validation Loss: 0.1380, Validation Loss: 0.1380,V Acc: 0.3153, Top 70th Acc: 0.3718, Bottom 30th Acc: 0.1818
Fold [2/5] Epoch [10/100] Initial Loss: 0.1382, Training Loss: 0.0289, Initial Validation Loss: 0.1380, Validation Loss: 0.0382,V Acc: 0.8288, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.5758
Fold [2/5] Epoch [20/100] Initial Loss: 0.1382, Training Loss: 0.0185, Initial Validation Loss: 0.1380, Validation Loss: 0.0323,V Acc: 0.8649, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.7273
Fold [3/5] Epoch [20/100] Initial Loss: 0.1456, Training Loss: 0.0818, Initial Validation Loss: 0.1346, Validation Loss: 0.0691,V Acc: 0.6909, Top 70th Acc: 0.8182, Bottom 30th Acc: 0.3939
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.8311688311688312
Fold [4/5] Epoch [0/100] Initial Loss: 0.1354, Training Loss: 0.1354, Initial Validation Loss: 0.1263, Validation Loss: 0.1263,V Acc: 0.3636, Top 70th Acc: 0.4026, Bottom 30th Acc: 0.2727
Fold [4/5] Epoch [10/100] Initial Loss: 0.1354, Training Loss: 0.0803, Initial Validation Loss: 0.1263, Validation Loss: 0.0810,V Acc: 0.6000, Top 70th Acc: 0.7273, Bottom 30th Acc: 0.3030
Fold [4/5] Epoch [20/100] Initial Loss: 0.1354, Training Loss: 0.0786, Initial Validation Loss: 0.1263, Validation Loss: 0.0801,V Acc: 0.6273, Top 70th Acc: 0.7143, Bottom 30th Acc: 0.4242
Stopping early at Epoch (base 0): 22  Rolling back to Epoch (base 0): 17  Top Validation Acc: 0.7402597402597403
Fold [5/5] Epoch [0/100] Initial Loss: 0.1314, Training Loss: 0.1314, Initial Validation Loss: 0.1290, Validation Loss: 0.1290,V Acc: 0.3611, Top 70th Acc: 0.4211, Bottom 30th Acc: 0.2188
Fold [5/5] Epoch [10/100] Initial Loss: 0.1314, Training Loss: 0.0789, Initial Validation Loss: 0.1290, Validation Loss: 0.0870,V Acc: 0.5741, Top 70th Acc: 0.7105, Bottom 30th Acc: 0.2500
Fold [5/5] Epoch [20/100] Initial Loss: 0.1314, Training Loss: 0.0770, Initial Validation Loss: 0.1290, Validation Loss: 0.0862,V Acc: 0.5926, Top 70th Acc: 0.7500, Bottom 30th Acc: 0.2188
Stopping early at Epoch (base 0): 29  Rolling back to Epoch (base 0): 24  Top Validation Acc: 0.7236842105263158
Running train_nn.py with seed 52
CUDA:False
Training samples count:  550
Training on 2 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1308, Training Loss: 0.1308, Initial Validation Loss: 0.1155, Validation Loss: 0.1155,V Acc: 0.3964, Top 70th Acc: 0.5256, Bottom 30th Acc: 0.0909
Fold [1/5] Epoch [10/100] Initial Loss: 0.1308, Training Loss: 0.0825, Initial Validation Loss: 0.1155, Validation Loss: 0.0741,V Acc: 0.6847, Top 70th Acc: 0.7692, Bottom 30th Acc: 0.4848
Fold [1/5] Epoch [20/100] Initial Loss: 0.1308, Training Loss: 0.0805, Initial Validation Loss: 0.1155, Validation Loss: 0.0738,V Acc: 0.6757, Top 70th Acc: 0.7692, Bottom 30th Acc: 0.4545
Stopping early at Epoch (base 0): 29  Rolling back to Epoch (base 0): 24  Top Validation Acc: 0.7564102564102564
Fold [2/5] Epoch [0/100] Initial Loss: 0.1376, Training Loss: 0.1376, Initial Validation Loss: 0.1322, Validation Loss: 0.1322,V Acc: 0.2072, Top 70th Acc: 0.2692, Bottom 30th Acc: 0.0606
Fold [2/5] Epoch [10/100] Initial Loss: 0.1376, Training Loss: 0.0833, Initial Validation Loss: 0.1322, Validation Loss: 0.0802,V Acc: 0.6577, Top 70th Acc: 0.7564, Bottom 30th Acc: 0.4242
Fold [2/5] Epoch [20/100] Initial Loss: 0.1376, Training Loss: 0.0808, Initial Validation Loss: 0.1322, Validation Loss: 0.0768,V Acc: 0.6667, Top 70th Acc: 0.7564, Bottom 30th Acc: 0.4545
Stopping early at Epoch (base 0): 27  Rolling back to Epoch (base 0): 22  Top Validation Acc: 0.7692307692307693
Fold [3/5] Epoch [0/100] Initial Loss: 0.1327, Training Loss: 0.1327, Initial Validation Loss: 0.1206, Validation Loss: 0.1206,V Acc: 0.4000, Top 70th Acc: 0.4286, Bottom 30th Acc: 0.3333
Fold [3/5] Epoch [10/100] Initial Loss: 0.1327, Training Loss: 0.0806, Initial Validation Loss: 0.1206, Validation Loss: 0.0805,V Acc: 0.6091, Top 70th Acc: 0.7532, Bottom 30th Acc: 0.2727
Stopping early at Epoch (base 0): 12  Rolling back to Epoch (base 0): 7  Top Validation Acc: 0.7662337662337663
52 2 [array([0.15240525, 0.37074694, 0.16534771, 0.16930486, 0.14219521],
      dtype=float32)]
Fold [4/5] Epoch [0/100] Initial Loss: 0.1384, Training Loss: 0.1384, Initial Validation Loss: 0.1373, Validation Loss: 0.1373,V Acc: 0.2818, Top 70th Acc: 0.3766, Bottom 30th Acc: 0.0606
Fold [4/5] Epoch [10/100] Initial Loss: 0.1384, Training Loss: 0.0793, Initial Validation Loss: 0.1373, Validation Loss: 0.0889,V Acc: 0.6000, Top 70th Acc: 0.7273, Bottom 30th Acc: 0.3030
Fold [4/5] Epoch [20/100] Initial Loss: 0.1384, Training Loss: 0.0763, Initial Validation Loss: 0.1373, Validation Loss: 0.0873,V Acc: 0.5909, Top 70th Acc: 0.7143, Bottom 30th Acc: 0.3030
Fold [4/5] Epoch [30/100] Initial Loss: 0.1384, Training Loss: 0.0753, Initial Validation Loss: 0.1373, Validation Loss: 0.0868,V Acc: 0.6091, Top 70th Acc: 0.7143, Bottom 30th Acc: 0.3636
Stopping early at Epoch (base 0): 31  Rolling back to Epoch (base 0): 26  Top Validation Acc: 0.7142857142857143
Fold [5/5] Epoch [0/100] Initial Loss: 0.1346, Training Loss: 0.1346, Initial Validation Loss: 0.1218, Validation Loss: 0.1218,V Acc: 0.4537, Top 70th Acc: 0.5263, Bottom 30th Acc: 0.2812
Fold [5/5] Epoch [10/100] Initial Loss: 0.1346, Training Loss: 0.0803, Initial Validation Loss: 0.1218, Validation Loss: 0.0808,V Acc: 0.5741, Top 70th Acc: 0.6579, Bottom 30th Acc: 0.3750
Stopping early at Epoch (base 0): 19  Rolling back to Epoch (base 0): 14  Top Validation Acc: 0.6578947368421053
Running train_nn.py with seed 53
CUDA:False
Training samples count:  550
Training on 2 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1406, Training Loss: 0.1406, Initial Validation Loss: 0.1389, Validation Loss: 0.1389,V Acc: 0.1351, Top 70th Acc: 0.1923, Bottom 30th Acc: 0.0000
Fold [1/5] Epoch [10/100] Initial Loss: 0.1406, Training Loss: 0.0794, Initial Validation Loss: 0.1389, Validation Loss: 0.0891,V Acc: 0.5676, Top 70th Acc: 0.6667, Bottom 30th Acc: 0.3333
Fold [1/5] Epoch [20/100] Initial Loss: 0.1406, Training Loss: 0.0767, Initial Validation Loss: 0.1389, Validation Loss: 0.0875,V Acc: 0.5766, Top 70th Acc: 0.6923, Bottom 30th Acc: 0.3030
Fold [1/5] Epoch [30/100] Initial Loss: 0.1406, Training Loss: 0.0755, Initial Validation Loss: 0.1389, Validation Loss: 0.0887,V Acc: 0.5766, Top 70th Acc: 0.6795, Bottom 30th Acc: 0.3333
Stopping early at Epoch (base 0): 30  Rolling back to Epoch (base 0): 25  Top Validation Acc: 0.6794871794871795
Fold [2/5] Epoch [0/100] Initial Loss: 0.1391, Training Loss: 0.1391, Initial Validation Loss: 0.1287, Validation Loss: 0.1287,V Acc: 0.3514, Top 70th Acc: 0.4615, Bottom 30th Acc: 0.0909
Fold [2/5] Epoch [10/100] Initial Loss: 0.1391, Training Loss: 0.0814, Initial Validation Loss: 0.1287, Validation Loss: 0.0779,V Acc: 0.6486, Top 70th Acc: 0.7179, Bottom 30th Acc: 0.4848
Fold [2/5] Epoch [20/100] Initial Loss: 0.1391, Training Loss: 0.0791, Initial Validation Loss: 0.1287, Validation Loss: 0.0766,V Acc: 0.6306, Top 70th Acc: 0.7308, Bottom 30th Acc: 0.3939
Fold [2/5] Epoch [30/100] Initial Loss: 0.1391, Training Loss: 0.0785, Initial Validation Loss: 0.1287, Validation Loss: 0.0764,V Acc: 0.6486, Top 70th Acc: 0.7436, Bottom 30th Acc: 0.4242
Stopping early at Epoch (base 0): 32  Rolling back to Epoch (base 0): 27  Top Validation Acc: 0.7435897435897436
Fold [3/5] Epoch [0/100] Initial Loss: 0.1380, Training Loss: 0.1380, Initial Validation Loss: 0.1267, Validation Loss: 0.1267,V Acc: 0.3545, Top 70th Acc: 0.4026, Bottom 30th Acc: 0.2424
Fold [3/5] Epoch [10/100] Initial Loss: 0.1380, Training Loss: 0.0819, Initial Validation Loss: 0.1267, Validation Loss: 0.0748,V Acc: 0.6545, Top 70th Acc: 0.7532, Bottom 30th Acc: 0.4242
Fold [3/5] Epoch [20/100] Initial Loss: 0.1380, Training Loss: 0.0799, Initial Validation Loss: 0.1267, Validation Loss: 0.0726,V Acc: 0.6727, Top 70th Acc: 0.7662, Bottom 30th Acc: 0.4545
Fold [3/5] Epoch [30/100] Initial Loss: 0.1380, Training Loss: 0.0793, Initial Validation Loss: 0.1267, Validation Loss: 0.0718,V Acc: 0.6364, Top 70th Acc: 0.7662, Bottom 30th Acc: 0.3333
Stopping early at Epoch (base 0): 35  Rolling back to Epoch (base 0): 30  Top Validation Acc: 0.7662337662337663
Fold [4/5] Epoch [0/100] Initial Loss: 0.1332, Training Loss: 0.1332, Initial Validation Loss: 0.1273, Validation Loss: 0.1273,V Acc: 0.4000, Top 70th Acc: 0.5065, Bottom 30th Acc: 0.1515
Fold [4/5] Epoch [10/100] Initial Loss: 0.1332, Training Loss: 0.0820, Initial Validation Loss: 0.1273, Validation Loss: 0.0779,V Acc: 0.6273, Top 70th Acc: 0.7662, Bottom 30th Acc: 0.3030
Fold [4/5] Epoch [20/100] Initial Loss: 0.1332, Training Loss: 0.0793, Initial Validation Loss: 0.1273, Validation Loss: 0.0761,V Acc: 0.6273, Top 70th Acc: 0.7532, Bottom 30th Acc: 0.3333
Fold [2/5] Epoch [20/100] Initial Loss: 0.1336, Training Loss: 0.0229, Initial Validation Loss: 0.1313, Validation Loss: 0.0343,V Acc: 0.8288, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 21  Rolling back to Epoch (base 0): 16  Top Validation Acc: 0.9487179487179487
Fold [3/5] Epoch [0/100] Initial Loss: 0.1422, Training Loss: 0.1422, Initial Validation Loss: 0.1290, Validation Loss: 0.1290,V Acc: 0.3182, Top 70th Acc: 0.3636, Bottom 30th Acc: 0.2121
Fold [3/5] Epoch [10/100] Initial Loss: 0.1422, Training Loss: 0.0381, Initial Validation Loss: 0.1290, Validation Loss: 0.0468,V Acc: 0.7636, Top 70th Acc: 0.8571, Bottom 30th Acc: 0.5455
Fold [3/5] Epoch [20/100] Initial Loss: 0.1422, Training Loss: 0.0230, Initial Validation Loss: 0.1290, Validation Loss: 0.0378,V Acc: 0.8000, Top 70th Acc: 0.8961, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 27  Rolling back to Epoch (base 0): 22  Top Validation Acc: 0.8701298701298701
55 2 [array([0.21567118, 0.14282879, 0.1633918 , 0.2491211 , 0.22898708],
      dtype=float32)]
Fold [4/5] Epoch [0/100] Initial Loss: 0.1357, Training Loss: 0.1357, Initial Validation Loss: 0.1325, Validation Loss: 0.1325,V Acc: 0.3273, Top 70th Acc: 0.3896, Bottom 30th Acc: 0.1818
Fold [4/5] Epoch [10/100] Initial Loss: 0.1357, Training Loss: 0.0386, Initial Validation Loss: 0.1325, Validation Loss: 0.0317,V Acc: 0.8727, Top 70th Acc: 0.9870, Bottom 30th Acc: 0.6061
Fold [4/5] Epoch [20/100] Initial Loss: 0.1357, Training Loss: 0.0259, Initial Validation Loss: 0.1325, Validation Loss: 0.0259,V Acc: 0.8727, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 29  Rolling back to Epoch (base 0): 24  Top Validation Acc: 0.948051948051948
Fold [5/5] Epoch [0/100] Initial Loss: 0.1395, Training Loss: 0.1395, Initial Validation Loss: 0.1328, Validation Loss: 0.1328,V Acc: 0.3611, Top 70th Acc: 0.4079, Bottom 30th Acc: 0.2500
Fold [5/5] Epoch [10/100] Initial Loss: 0.1395, Training Loss: 0.0332, Initial Validation Loss: 0.1328, Validation Loss: 0.0451,V Acc: 0.8148, Top 70th Acc: 0.8553, Bottom 30th Acc: 0.7188
Fold [5/5] Epoch [20/100] Initial Loss: 0.1395, Training Loss: 0.0235, Initial Validation Loss: 0.1328, Validation Loss: 0.0366,V Acc: 0.8148, Top 70th Acc: 0.8947, Bottom 30th Acc: 0.6250
Fold [5/5] Epoch [30/100] Initial Loss: 0.1395, Training Loss: 0.0209, Initial Validation Loss: 0.1328, Validation Loss: 0.0353,V Acc: 0.8333, Top 70th Acc: 0.9079, Bottom 30th Acc: 0.6562
Stopping early at Epoch (base 0): 33  Rolling back to Epoch (base 0): 28  Top Validation Acc: 0.881578947368421
Running train_nn.py with seed 56
CUDA:False
Training samples count:  550
Training on 20 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1373, Training Loss: 0.1373, Initial Validation Loss: 0.1350, Validation Loss: 0.1350,V Acc: 0.2973, Top 70th Acc: 0.3590, Bottom 30th Acc: 0.1515
Fold [1/5] Epoch [10/100] Initial Loss: 0.1373, Training Loss: 0.0322, Initial Validation Loss: 0.1350, Validation Loss: 0.0401,V Acc: 0.8559, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.7273
Fold [1/5] Epoch [20/100] Initial Loss: 0.1373, Training Loss: 0.0227, Initial Validation Loss: 0.1350, Validation Loss: 0.0360,V Acc: 0.8198, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.9230769230769231
Fold [2/5] Epoch [0/100] Initial Loss: 0.1420, Training Loss: 0.1420, Initial Validation Loss: 0.1400, Validation Loss: 0.1400,V Acc: 0.2072, Top 70th Acc: 0.1282, Bottom 30th Acc: 0.3939
Fold [2/5] Epoch [10/100] Initial Loss: 0.1420, Training Loss: 0.0497, Initial Validation Loss: 0.1400, Validation Loss: 0.0480,V Acc: 0.8018, Top 70th Acc: 0.8974, Bottom 30th Acc: 0.5758
Fold [2/5] Epoch [20/100] Initial Loss: 0.1420, Training Loss: 0.0257, Initial Validation Loss: 0.1400, Validation Loss: 0.0304,V Acc: 0.8739, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.7273
Stopping early at Epoch (base 0): 28  Rolling back to Epoch (base 0): 23  Top Validation Acc: 0.9487179487179487
Fold [3/5] Epoch [0/100] Initial Loss: 0.1387, Training Loss: 0.1387, Initial Validation Loss: 0.1343, Validation Loss: 0.1343,V Acc: 0.2545, Top 70th Acc: 0.3117, Bottom 30th Acc: 0.1212
Fold [3/5] Epoch [10/100] Initial Loss: 0.1387, Training Loss: 0.0347, Initial Validation Loss: 0.1343, Validation Loss: 0.0422,V Acc: 0.8091, Top 70th Acc: 0.8831, Bottom 30th Acc: 0.6364
Fold [3/5] Epoch [20/100] Initial Loss: 0.1387, Training Loss: 0.0225, Initial Validation Loss: 0.1343, Validation Loss: 0.0402,V Acc: 0.8455, Top 70th Acc: 0.8831, Bottom 30th Acc: 0.7576
Stopping early at Epoch (base 0): 22  Rolling back to Epoch (base 0): 17  Top Validation Acc: 0.8961038961038961
Fold [4/5] Epoch [0/100] Initial Loss: 0.1397, Training Loss: 0.1397, Initial Validation Loss: 0.1337, Validation Loss: 0.1337,V Acc: 0.2455, Top 70th Acc: 0.2727, Bottom 30th Acc: 0.1818
Fold [4/5] Epoch [10/100] Initial Loss: 0.1397, Training Loss: 0.0432, Initial Validation Loss: 0.1337, Validation Loss: 0.0478,V Acc: 0.7909, Top 70th Acc: 0.8701, Bottom 30th Acc: 0.6061
Fold [4/5] Epoch [20/100] Initial Loss: 0.1397, Training Loss: 0.0237, Initial Validation Loss: 0.1337, Validation Loss: 0.0371,V Acc: 0.8182, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.5758
Fold [4/5] Epoch [30/100] Initial Loss: 0.1397, Training Loss: 0.0213, Initial Validation Loss: 0.1337, Validation Loss: 0.0365,V Acc: 0.8182, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 33  Rolling back to Epoch (base 0): 28  Top Validation Acc: 0.922077922077922
56 3 [array([0.24959376, 0.09458625, 0.07536832, 0.3833696 , 0.19708213],
      dtype=float32)]
Fold [5/5] Epoch [0/100] Initial Loss: 0.1383, Training Loss: 0.1383, Initial Validation Loss: 0.1300, Validation Loss: 0.1300,V Acc: 0.4074, Top 70th Acc: 0.4474, Bottom 30th Acc: 0.3125
Fold [5/5] Epoch [10/100] Initial Loss: 0.1383, Training Loss: 0.0379, Initial Validation Loss: 0.1300, Validation Loss: 0.0362,V Acc: 0.8333, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.5625
Fold [5/5] Epoch [20/100] Initial Loss: 0.1383, Training Loss: 0.0257, Initial Validation Loss: 0.1300, Validation Loss: 0.0278,V Acc: 0.8426, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.5938
Fold [5/5] Epoch [30/100] Initial Loss: 0.1383, Training Loss: 0.0236, Initial Validation Loss: 0.1300, Validation Loss: 0.0289,V Acc: 0.8519, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.6250
Stopping early at Epoch (base 0): 30  Rolling back to Epoch (base 0): 25  Top Validation Acc: 0.9473684210526315
Running train_nn.py with seed 57
CUDA:False
Training samples count:  550
Training on 20 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1398, Training Loss: 0.1398, Initial Validation Loss: 0.1312, Validation Loss: 0.1312,V Acc: 0.3514, Top 70th Acc: 0.4487, Bottom 30th Acc: 0.1212
Fold [1/5] Epoch [10/100] Initial Loss: 0.1398, Training Loss: 0.0398, Initial Validation Loss: 0.1312, Validation Loss: 0.0454,V Acc: 0.7838, Top 70th Acc: 0.8718, Bottom 30th Acc: 0.5758
Fold [1/5] Epoch [20/100] Initial Loss: 0.1398, Training Loss: 0.0238, Initial Validation Loss: 0.1312, Validation Loss: 0.0402,V Acc: 0.7838, Top 70th Acc: 0.8846, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.8974358974358975
57 0 [array([0.29801998, 0.11877942, 0.11523163, 0.23890385, 0.22906515],
      dtype=float32)]
Fold [2/5] Epoch [0/100] Initial Loss: 0.1361, Training Loss: 0.1361, Initial Validation Loss: 0.1347, Validation Loss: 0.1347,V Acc: 0.2973, Top 70th Acc: 0.3333, Bottom 30th Acc: 0.2121
Fold [2/5] Epoch [10/100] Initial Loss: 0.1361, Training Loss: 0.0405, Initial Validation Loss: 0.1347, Validation Loss: 0.0485,V Acc: 0.8018, Top 70th Acc: 0.8718, Bottom 30th Acc: 0.6364
Fold [2/5] Epoch [20/100] Initial Loss: 0.1361, Training Loss: 0.0247, Initial Validation Loss: 0.1347, Validation Loss: 0.0356,V Acc: 0.8559, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.9102564102564102
Fold [3/5] Epoch [0/100] Initial Loss: 0.1431, Training Loss: 0.1431, Initial Validation Loss: 0.1369, Validation Loss: 0.1369,V Acc: 0.2545, Top 70th Acc: 0.2857, Bottom 30th Acc: 0.1818
Fold [1/5] Epoch [20/100] Initial Loss: 0.1275, Training Loss: 0.0183, Initial Validation Loss: 0.1107, Validation Loss: 0.0293,V Acc: 0.8468, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 22  Rolling back to Epoch (base 0): 17  Top Validation Acc: 0.9358974358974359
Fold [2/5] Epoch [0/100] Initial Loss: 0.1315, Training Loss: 0.1315, Initial Validation Loss: 0.1257, Validation Loss: 0.1257,V Acc: 0.3874, Top 70th Acc: 0.4744, Bottom 30th Acc: 0.1818
Fold [2/5] Epoch [10/100] Initial Loss: 0.1315, Training Loss: 0.0244, Initial Validation Loss: 0.1257, Validation Loss: 0.0301,V Acc: 0.8378, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.5455
Fold [2/5] Epoch [20/100] Initial Loss: 0.1315, Training Loss: 0.0193, Initial Validation Loss: 0.1257, Validation Loss: 0.0280,V Acc: 0.8739, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.9615384615384616
Fold [3/5] Epoch [0/100] Initial Loss: 0.1391, Training Loss: 0.1391, Initial Validation Loss: 0.1311, Validation Loss: 0.1311,V Acc: 0.3182, Top 70th Acc: 0.4026, Bottom 30th Acc: 0.1212
Fold [3/5] Epoch [10/100] Initial Loss: 0.1391, Training Loss: 0.0276, Initial Validation Loss: 0.1311, Validation Loss: 0.0337,V Acc: 0.8091, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.4848
Fold [3/5] Epoch [20/100] Initial Loss: 0.1391, Training Loss: 0.0174, Initial Validation Loss: 0.1311, Validation Loss: 0.0364,V Acc: 0.8000, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.5152
Stopping early at Epoch (base 0): 21  Rolling back to Epoch (base 0): 16  Top Validation Acc: 0.948051948051948
Fold [4/5] Epoch [0/100] Initial Loss: 0.1331, Training Loss: 0.1331, Initial Validation Loss: 0.1195, Validation Loss: 0.1195,V Acc: 0.4364, Top 70th Acc: 0.5325, Bottom 30th Acc: 0.2121
Fold [4/5] Epoch [10/100] Initial Loss: 0.1331, Training Loss: 0.0311, Initial Validation Loss: 0.1195, Validation Loss: 0.0385,V Acc: 0.8091, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.5758
Fold [4/5] Epoch [20/100] Initial Loss: 0.1331, Training Loss: 0.0187, Initial Validation Loss: 0.1195, Validation Loss: 0.0265,V Acc: 0.8727, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 29  Rolling back to Epoch (base 0): 24  Top Validation Acc: 0.948051948051948
Fold [5/5] Epoch [0/100] Initial Loss: 0.1291, Training Loss: 0.1291, Initial Validation Loss: 0.1110, Validation Loss: 0.1110,V Acc: 0.5093, Top 70th Acc: 0.6711, Bottom 30th Acc: 0.1250
Fold [5/5] Epoch [10/100] Initial Loss: 0.1291, Training Loss: 0.0255, Initial Validation Loss: 0.1110, Validation Loss: 0.0286,V Acc: 0.8611, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.6250
Fold [5/5] Epoch [20/100] Initial Loss: 0.1291, Training Loss: 0.0197, Initial Validation Loss: 0.1110, Validation Loss: 0.0270,V Acc: 0.8519, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.6250
Fold [5/5] Epoch [30/100] Initial Loss: 0.1291, Training Loss: 0.0170, Initial Validation Loss: 0.1110, Validation Loss: 0.0274,V Acc: 0.8519, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.5938
Stopping early at Epoch (base 0): 30  Rolling back to Epoch (base 0): 25  Top Validation Acc: 0.9605263157894737
79 4 [array([0.7573152 , 0.0202772 , 0.03637817, 0.07419321, 0.11183617],
      dtype=float32)]
Running train_nn.py with seed 80
CUDA:False
Training samples count:  550
Training on 21 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1312, Training Loss: 0.1312, Initial Validation Loss: 0.1250, Validation Loss: 0.1250,V Acc: 0.3964, Top 70th Acc: 0.5256, Bottom 30th Acc: 0.0909
Fold [1/5] Epoch [10/100] Initial Loss: 0.1312, Training Loss: 0.0248, Initial Validation Loss: 0.1250, Validation Loss: 0.0266,V Acc: 0.9009, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.7273
Stopping early at Epoch (base 0): 17  Rolling back to Epoch (base 0): 12  Top Validation Acc: 0.9487179487179487
Fold [2/5] Epoch [0/100] Initial Loss: 0.1286, Training Loss: 0.1286, Initial Validation Loss: 0.1197, Validation Loss: 0.1197,V Acc: 0.4685, Top 70th Acc: 0.5897, Bottom 30th Acc: 0.1818
Fold [2/5] Epoch [10/100] Initial Loss: 0.1286, Training Loss: 0.0203, Initial Validation Loss: 0.1197, Validation Loss: 0.0366,V Acc: 0.8559, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 17  Rolling back to Epoch (base 0): 12  Top Validation Acc: 0.9230769230769231
Fold [3/5] Epoch [0/100] Initial Loss: 0.1380, Training Loss: 0.1380, Initial Validation Loss: 0.1259, Validation Loss: 0.1259,V Acc: 0.5000, Top 70th Acc: 0.4935, Bottom 30th Acc: 0.5152
Fold [3/5] Epoch [10/100] Initial Loss: 0.1380, Training Loss: 0.0281, Initial Validation Loss: 0.1259, Validation Loss: 0.0249,V Acc: 0.8545, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 17  Rolling back to Epoch (base 0): 12  Top Validation Acc: 0.961038961038961
Fold [4/5] Epoch [0/100] Initial Loss: 0.1399, Training Loss: 0.1399, Initial Validation Loss: 0.1342, Validation Loss: 0.1342,V Acc: 0.2545, Top 70th Acc: 0.3117, Bottom 30th Acc: 0.1212
Fold [4/5] Epoch [10/100] Initial Loss: 0.1399, Training Loss: 0.0284, Initial Validation Loss: 0.1342, Validation Loss: 0.0337,V Acc: 0.8364, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.6667
Fold [4/5] Epoch [20/100] Initial Loss: 0.1399, Training Loss: 0.0181, Initial Validation Loss: 0.1342, Validation Loss: 0.0276,V Acc: 0.8455, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 29  Rolling back to Epoch (base 0): 24  Top Validation Acc: 0.935064935064935
Fold [5/5] Epoch [0/100] Initial Loss: 0.1345, Training Loss: 0.1345, Initial Validation Loss: 0.1253, Validation Loss: 0.1253,V Acc: 0.5463, Top 70th Acc: 0.6842, Bottom 30th Acc: 0.2188
Fold [5/5] Epoch [10/100] Initial Loss: 0.1345, Training Loss: 0.0330, Initial Validation Loss: 0.1253, Validation Loss: 0.0405,V Acc: 0.8241, Top 70th Acc: 0.9079, Bottom 30th Acc: 0.6250
Fold [5/5] Epoch [20/100] Initial Loss: 0.1345, Training Loss: 0.0196, Initial Validation Loss: 0.1253, Validation Loss: 0.0301,V Acc: 0.8519, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.5938
Fold [5/5] Epoch [30/100] Initial Loss: 0.1345, Training Loss: 0.0184, Initial Validation Loss: 0.1253, Validation Loss: 0.0285,V Acc: 0.8519, Top 70th Acc: 0.9868, Bottom 30th Acc: 0.5312
Stopping early at Epoch (base 0): 31  Rolling back to Epoch (base 0): 26  Top Validation Acc: 0.9605263157894737
80 4 [array([0.74567616, 0.01639779, 0.03077384, 0.09343293, 0.11371925],
      dtype=float32)]
Running train_nn.py with seed 81
CUDA:False
Training samples count:  550
Training on 21 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1401, Training Loss: 0.1401, Initial Validation Loss: 0.1323, Validation Loss: 0.1323,V Acc: 0.4865, Top 70th Acc: 0.5385, Bottom 30th Acc: 0.3636
Fold [1/5] Epoch [10/100] Initial Loss: 0.1401, Training Loss: 0.0269, Initial Validation Loss: 0.1323, Validation Loss: 0.0297,V Acc: 0.8288, Top 70th Acc: 0.9872, Bottom 30th Acc: 0.4545
Fold [1/5] Epoch [20/100] Initial Loss: 0.1401, Training Loss: 0.0183, Initial Validation Loss: 0.1323, Validation Loss: 0.0289,V Acc: 0.8649, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.9743589743589743
Fold [2/5] Epoch [0/100] Initial Loss: 0.1357, Training Loss: 0.1357, Initial Validation Loss: 0.1254, Validation Loss: 0.1254,V Acc: 0.3153, Top 70th Acc: 0.3718, Bottom 30th Acc: 0.1818
Fold [2/5] Epoch [10/100] Initial Loss: 0.1357, Training Loss: 0.0257, Initial Validation Loss: 0.1254, Validation Loss: 0.0381,V Acc: 0.8018, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.5152
Stopping early at Epoch (base 0): 18  Rolling back to Epoch (base 0): 13  Top Validation Acc: 0.9230769230769231
Fold [3/5] Epoch [0/100] Initial Loss: 0.1320, Training Loss: 0.1320, Initial Validation Loss: 0.1225, Validation Loss: 0.1225,V Acc: 0.6000, Top 70th Acc: 0.7143, Bottom 30th Acc: 0.3333
Fold [3/5] Epoch [10/100] Initial Loss: 0.1320, Training Loss: 0.0236, Initial Validation Loss: 0.1225, Validation Loss: 0.0259,V Acc: 0.8636, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.6061
Fold [3/5] Epoch [20/100] Initial Loss: 0.1320, Training Loss: 0.0168, Initial Validation Loss: 0.1225, Validation Loss: 0.0204,V Acc: 0.9091, Top 70th Acc: 0.9870, Bottom 30th Acc: 0.7273
Fold [4/5] Epoch [30/100] Initial Loss: 0.1400, Training Loss: 0.0130, Initial Validation Loss: 0.1355, Validation Loss: 0.0234,V Acc: 0.8727, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 35  Rolling back to Epoch (base 0): 30  Top Validation Acc: 0.961038961038961
Fold [5/5] Epoch [0/100] Initial Loss: 0.1373, Training Loss: 0.1373, Initial Validation Loss: 0.1301, Validation Loss: 0.1301,V Acc: 0.3889, Top 70th Acc: 0.4342, Bottom 30th Acc: 0.2812
Fold [5/5] Epoch [10/100] Initial Loss: 0.1373, Training Loss: 0.0218, Initial Validation Loss: 0.1301, Validation Loss: 0.0364,V Acc: 0.8056, Top 70th Acc: 0.9211, Bottom 30th Acc: 0.5312
Fold [5/5] Epoch [20/100] Initial Loss: 0.1373, Training Loss: 0.0130, Initial Validation Loss: 0.1301, Validation Loss: 0.0355,V Acc: 0.8241, Top 70th Acc: 0.9211, Bottom 30th Acc: 0.5938
Stopping early at Epoch (base 0): 21  Rolling back to Epoch (base 0): 16  Top Validation Acc: 0.9210526315789473
Running train_nn.py with seed 56
CUDA:False
Training samples count:  550
Training on 40 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1418, Training Loss: 0.1418, Initial Validation Loss: 0.1364, Validation Loss: 0.1364,V Acc: 0.2703, Top 70th Acc: 0.3205, Bottom 30th Acc: 0.1515
Fold [1/5] Epoch [10/100] Initial Loss: 0.1418, Training Loss: 0.0420, Initial Validation Loss: 0.1364, Validation Loss: 0.0572,V Acc: 0.7387, Top 70th Acc: 0.8462, Bottom 30th Acc: 0.4848
Fold [1/5] Epoch [20/100] Initial Loss: 0.1418, Training Loss: 0.0174, Initial Validation Loss: 0.1364, Validation Loss: 0.0381,V Acc: 0.7928, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.4545
Fold [1/5] Epoch [30/100] Initial Loss: 0.1418, Training Loss: 0.0116, Initial Validation Loss: 0.1364, Validation Loss: 0.0331,V Acc: 0.7928, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.3939
Fold [1/5] Epoch [40/100] Initial Loss: 0.1418, Training Loss: 0.0103, Initial Validation Loss: 0.1364, Validation Loss: 0.0315,V Acc: 0.8468, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 46  Rolling back to Epoch (base 0): 41  Top Validation Acc: 0.9615384615384616
Fold [2/5] Epoch [0/100] Initial Loss: 0.1366, Training Loss: 0.1366, Initial Validation Loss: 0.1354, Validation Loss: 0.1354,V Acc: 0.4144, Top 70th Acc: 0.4231, Bottom 30th Acc: 0.3939
Fold [2/5] Epoch [10/100] Initial Loss: 0.1366, Training Loss: 0.0349, Initial Validation Loss: 0.1354, Validation Loss: 0.0374,V Acc: 0.8288, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.6364
Fold [2/5] Epoch [20/100] Initial Loss: 0.1366, Training Loss: 0.0220, Initial Validation Loss: 0.1354, Validation Loss: 0.0286,V Acc: 0.8468, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.5758
Fold [2/5] Epoch [30/100] Initial Loss: 0.1366, Training Loss: 0.0154, Initial Validation Loss: 0.1354, Validation Loss: 0.0214,V Acc: 0.8829, Top 70th Acc: 0.9872, Bottom 30th Acc: 0.6364
Fold [2/5] Epoch [40/100] Initial Loss: 0.1366, Training Loss: 0.0117, Initial Validation Loss: 0.1354, Validation Loss: 0.0184,V Acc: 0.9189, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.7879
Stopping early at Epoch (base 0): 46  Rolling back to Epoch (base 0): 41  Top Validation Acc: 0.9743589743589743
Fold [3/5] Epoch [0/100] Initial Loss: 0.1383, Training Loss: 0.1383, Initial Validation Loss: 0.1353, Validation Loss: 0.1353,V Acc: 0.3182, Top 70th Acc: 0.3377, Bottom 30th Acc: 0.2727
Fold [3/5] Epoch [10/100] Initial Loss: 0.1383, Training Loss: 0.0284, Initial Validation Loss: 0.1353, Validation Loss: 0.0400,V Acc: 0.8091, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.5758
Fold [3/5] Epoch [20/100] Initial Loss: 0.1383, Training Loss: 0.0160, Initial Validation Loss: 0.1353, Validation Loss: 0.0310,V Acc: 0.8364, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.5455
Fold [3/5] Epoch [30/100] Initial Loss: 0.1383, Training Loss: 0.0133, Initial Validation Loss: 0.1353, Validation Loss: 0.0295,V Acc: 0.8364, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 36  Rolling back to Epoch (base 0): 31  Top Validation Acc: 0.974025974025974
Fold [4/5] Epoch [0/100] Initial Loss: 0.1396, Training Loss: 0.1396, Initial Validation Loss: 0.1320, Validation Loss: 0.1320,V Acc: 0.3909, Top 70th Acc: 0.4545, Bottom 30th Acc: 0.2424
Fold [4/5] Epoch [10/100] Initial Loss: 0.1396, Training Loss: 0.0252, Initial Validation Loss: 0.1320, Validation Loss: 0.0354,V Acc: 0.8455, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.5758
Fold [4/5] Epoch [20/100] Initial Loss: 0.1396, Training Loss: 0.0136, Initial Validation Loss: 0.1320, Validation Loss: 0.0309,V Acc: 0.8545, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 29  Rolling back to Epoch (base 0): 24  Top Validation Acc: 0.961038961038961
56 3 [array([0.45657468, 0.04059986, 0.07323175, 0.24411902, 0.18547475],
      dtype=float32)]
Fold [5/5] Epoch [0/100] Initial Loss: 0.1383, Training Loss: 0.1383, Initial Validation Loss: 0.1321, Validation Loss: 0.1321,V Acc: 0.3796, Top 70th Acc: 0.4474, Bottom 30th Acc: 0.2188
Fold [5/5] Epoch [10/100] Initial Loss: 0.1383, Training Loss: 0.0262, Initial Validation Loss: 0.1321, Validation Loss: 0.0346,V Acc: 0.8241, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.5625
Stopping early at Epoch (base 0): 19  Rolling back to Epoch (base 0): 14  Top Validation Acc: 0.9473684210526315
Running train_nn.py with seed 57
CUDA:False
Training samples count:  550
Training on 40 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1402, Training Loss: 0.1402, Initial Validation Loss: 0.1327, Validation Loss: 0.1327,V Acc: 0.3243, Top 70th Acc: 0.3205, Bottom 30th Acc: 0.3333
Fold [1/5] Epoch [10/100] Initial Loss: 0.1402, Training Loss: 0.0355, Initial Validation Loss: 0.1327, Validation Loss: 0.0419,V Acc: 0.8018, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.5455
Fold [1/5] Epoch [20/100] Initial Loss: 0.1402, Training Loss: 0.0133, Initial Validation Loss: 0.1327, Validation Loss: 0.0342,V Acc: 0.8198, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.9358974358974359
57 0 [array([0.4592252 , 0.06053201, 0.05097237, 0.09383164, 0.33543873],
      dtype=float32)]
Fold [2/5] Epoch [0/100] Initial Loss: 0.1412, Training Loss: 0.1412, Initial Validation Loss: 0.1378, Validation Loss: 0.1378,V Acc: 0.2973, Top 70th Acc: 0.3462, Bottom 30th Acc: 0.1818
Fold [2/5] Epoch [10/100] Initial Loss: 0.1412, Training Loss: 0.0262, Initial Validation Loss: 0.1378, Validation Loss: 0.0373,V Acc: 0.8649, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.7576
Fold [2/5] Epoch [20/100] Initial Loss: 0.1412, Training Loss: 0.0139, Initial Validation Loss: 0.1378, Validation Loss: 0.0312,V Acc: 0.8739, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.7576
Stopping early at Epoch (base 0): 27  Rolling back to Epoch (base 0): 22  Top Validation Acc: 0.9358974358974359
Fold [3/5] Epoch [0/100] Initial Loss: 0.1407, Training Loss: 0.1407, Initial Validation Loss: 0.1344, Validation Loss: 0.1344,V Acc: 0.3000, Top 70th Acc: 0.3636, Bottom 30th Acc: 0.1515
Fold [3/5] Epoch [10/100] Initial Loss: 0.1407, Training Loss: 0.0287, Initial Validation Loss: 0.1344, Validation Loss: 0.0429,V Acc: 0.8000, Top 70th Acc: 0.8831, Bottom 30th Acc: 0.6061
Fold [3/5] Epoch [20/100] Initial Loss: 0.1407, Training Loss: 0.0130, Initial Validation Loss: 0.1344, Validation Loss: 0.0359,V Acc: 0.8182, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.6061
Fold [3/5] Epoch [30/100] Initial Loss: 0.1407, Training Loss: 0.0105, Initial Validation Loss: 0.1344, Validation Loss: 0.0368,V Acc: 0.8091, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.5152
Stopping early at Epoch (base 0): 30  Rolling back to Epoch (base 0): 25  Top Validation Acc: 0.935064935064935
Fold [4/5] Epoch [0/100] Initial Loss: 0.1354, Training Loss: 0.1354, Initial Validation Loss: 0.1343, Validation Loss: 0.1343,V Acc: 0.3091, Top 70th Acc: 0.3377, Bottom 30th Acc: 0.2424
Fold [4/5] Epoch [10/100] Initial Loss: 0.1354, Training Loss: 0.0276, Initial Validation Loss: 0.1343, Validation Loss: 0.0326,V Acc: 0.8636, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.6061
Fold [4/5] Epoch [20/100] Initial Loss: 0.1354, Training Loss: 0.0151, Initial Validation Loss: 0.1343, Validation Loss: 0.0246,V Acc: 0.8818, Top 70th Acc: 0.9870, Bottom 30th Acc: 0.6364
Fold [1/5] Epoch [50/100] Initial Loss: 0.1399, Training Loss: 0.0037, Initial Validation Loss: 0.1321, Validation Loss: 0.0334,V Acc: 0.8288, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.6061
Fold [1/5] Epoch [60/100] Initial Loss: 0.1399, Training Loss: 0.0036, Initial Validation Loss: 0.1321, Validation Loss: 0.0328,V Acc: 0.8378, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.6364
Fold [1/5] Epoch [70/100] Initial Loss: 0.1399, Training Loss: 0.0035, Initial Validation Loss: 0.1321, Validation Loss: 0.0325,V Acc: 0.8559, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 71  Rolling back to Epoch (base 0): 66  Top Validation Acc: 0.9358974358974359
Fold [2/5] Epoch [0/100] Initial Loss: 0.1405, Training Loss: 0.1405, Initial Validation Loss: 0.1305, Validation Loss: 0.1305,V Acc: 0.3153, Top 70th Acc: 0.3974, Bottom 30th Acc: 0.1212
Fold [2/5] Epoch [10/100] Initial Loss: 0.1405, Training Loss: 0.0139, Initial Validation Loss: 0.1305, Validation Loss: 0.0391,V Acc: 0.7748, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.3939
Fold [2/5] Epoch [20/100] Initial Loss: 0.1405, Training Loss: 0.0050, Initial Validation Loss: 0.1305, Validation Loss: 0.0354,V Acc: 0.7838, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.3939
Fold [2/5] Epoch [30/100] Initial Loss: 0.1405, Training Loss: 0.0039, Initial Validation Loss: 0.1305, Validation Loss: 0.0345,V Acc: 0.7928, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.4242
Stopping early at Epoch (base 0): 31  Rolling back to Epoch (base 0): 26  Top Validation Acc: 0.9487179487179487
Fold [3/5] Epoch [0/100] Initial Loss: 0.1368, Training Loss: 0.1368, Initial Validation Loss: 0.1368, Validation Loss: 0.1368,V Acc: 0.4273, Top 70th Acc: 0.5325, Bottom 30th Acc: 0.1818
Fold [3/5] Epoch [10/100] Initial Loss: 0.1368, Training Loss: 0.0178, Initial Validation Loss: 0.1368, Validation Loss: 0.0308,V Acc: 0.8636, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.6061
Fold [3/5] Epoch [20/100] Initial Loss: 0.1368, Training Loss: 0.0051, Initial Validation Loss: 0.1368, Validation Loss: 0.0249,V Acc: 0.8818, Top 70th Acc: 0.9870, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.987012987012987
43 2 [array([0.11172561, 0.02607741, 0.04737652, 0.15885283, 0.65596765],
      dtype=float32)]
Fold [4/5] Epoch [0/100] Initial Loss: 0.1376, Training Loss: 0.1376, Initial Validation Loss: 0.1336, Validation Loss: 0.1336,V Acc: 0.4273, Top 70th Acc: 0.5455, Bottom 30th Acc: 0.1515
Fold [4/5] Epoch [10/100] Initial Loss: 0.1376, Training Loss: 0.0100, Initial Validation Loss: 0.1336, Validation Loss: 0.0364,V Acc: 0.8273, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 17  Rolling back to Epoch (base 0): 12  Top Validation Acc: 0.935064935064935
Fold [5/5] Epoch [0/100] Initial Loss: 0.1414, Training Loss: 0.1414, Initial Validation Loss: 0.1354, Validation Loss: 0.1354,V Acc: 0.2685, Top 70th Acc: 0.3553, Bottom 30th Acc: 0.0625
Fold [5/5] Epoch [10/100] Initial Loss: 0.1414, Training Loss: 0.0241, Initial Validation Loss: 0.1354, Validation Loss: 0.0369,V Acc: 0.8056, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.5000
Fold [5/5] Epoch [20/100] Initial Loss: 0.1414, Training Loss: 0.0051, Initial Validation Loss: 0.1354, Validation Loss: 0.0228,V Acc: 0.8889, Top 70th Acc: 0.9737, Bottom 30th Acc: 0.6875
Fold [5/5] Epoch [30/100] Initial Loss: 0.1414, Training Loss: 0.0040, Initial Validation Loss: 0.1354, Validation Loss: 0.0219,V Acc: 0.8981, Top 70th Acc: 0.9868, Bottom 30th Acc: 0.6875
Stopping early at Epoch (base 0): 35  Rolling back to Epoch (base 0): 30  Top Validation Acc: 0.9868421052631579
Running train_nn.py with seed 44
CUDA:False
Training samples count:  550
Training on 163 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1365, Training Loss: 0.1365, Initial Validation Loss: 0.1305, Validation Loss: 0.1305,V Acc: 0.3423, Top 70th Acc: 0.4231, Bottom 30th Acc: 0.1515
Fold [1/5] Epoch [10/100] Initial Loss: 0.1365, Training Loss: 0.0155, Initial Validation Loss: 0.1305, Validation Loss: 0.0350,V Acc: 0.8198, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.5455
Fold [1/5] Epoch [20/100] Initial Loss: 0.1365, Training Loss: 0.0046, Initial Validation Loss: 0.1305, Validation Loss: 0.0307,V Acc: 0.8288, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.5152
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.9487179487179487
Fold [2/5] Epoch [0/100] Initial Loss: 0.1359, Training Loss: 0.1359, Initial Validation Loss: 0.1313, Validation Loss: 0.1313,V Acc: 0.4234, Top 70th Acc: 0.4872, Bottom 30th Acc: 0.2727
Fold [2/5] Epoch [10/100] Initial Loss: 0.1359, Training Loss: 0.0166, Initial Validation Loss: 0.1313, Validation Loss: 0.0371,V Acc: 0.8198, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.5455
Fold [2/5] Epoch [20/100] Initial Loss: 0.1359, Training Loss: 0.0052, Initial Validation Loss: 0.1313, Validation Loss: 0.0318,V Acc: 0.8288, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 27  Rolling back to Epoch (base 0): 22  Top Validation Acc: 0.9358974358974359
Fold [3/5] Epoch [0/100] Initial Loss: 0.1398, Training Loss: 0.1398, Initial Validation Loss: 0.1366, Validation Loss: 0.1366,V Acc: 0.3273, Top 70th Acc: 0.3636, Bottom 30th Acc: 0.2424
Fold [3/5] Epoch [10/100] Initial Loss: 0.1398, Training Loss: 0.0259, Initial Validation Loss: 0.1366, Validation Loss: 0.0470,V Acc: 0.7909, Top 70th Acc: 0.8961, Bottom 30th Acc: 0.5455
Fold [3/5] Epoch [20/100] Initial Loss: 0.1398, Training Loss: 0.0049, Initial Validation Loss: 0.1366, Validation Loss: 0.0335,V Acc: 0.8455, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6061
Fold [3/5] Epoch [30/100] Initial Loss: 0.1398, Training Loss: 0.0037, Initial Validation Loss: 0.1366, Validation Loss: 0.0330,V Acc: 0.8273, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.5152
Fold [3/5] Epoch [40/100] Initial Loss: 0.1398, Training Loss: 0.0035, Initial Validation Loss: 0.1366, Validation Loss: 0.0324,V Acc: 0.8455, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 46  Rolling back to Epoch (base 0): 41  Top Validation Acc: 0.961038961038961
44 2 [array([0.12669352, 0.04646897, 0.06758329, 0.23009038, 0.52916384],
      dtype=float32)]
Fold [4/5] Epoch [0/100] Initial Loss: 0.1413, Training Loss: 0.1413, Initial Validation Loss: 0.1322, Validation Loss: 0.1322,V Acc: 0.3455, Top 70th Acc: 0.3896, Bottom 30th Acc: 0.2424
Fold [4/5] Epoch [10/100] Initial Loss: 0.1413, Training Loss: 0.0118, Initial Validation Loss: 0.1322, Validation Loss: 0.0256,V Acc: 0.8727, Top 70th Acc: 0.9870, Bottom 30th Acc: 0.6061
Fold [4/5] Epoch [20/100] Initial Loss: 0.1413, Training Loss: 0.0044, Initial Validation Loss: 0.1322, Validation Loss: 0.0232,V Acc: 0.8818, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.961038961038961
Fold [5/5] Epoch [0/100] Initial Loss: 0.1384, Training Loss: 0.1384, Initial Validation Loss: 0.1344, Validation Loss: 0.1344,V Acc: 0.3056, Top 70th Acc: 0.3421, Bottom 30th Acc: 0.2188
Fold [5/5] Epoch [10/100] Initial Loss: 0.1384, Training Loss: 0.0178, Initial Validation Loss: 0.1344, Validation Loss: 0.0360,V Acc: 0.8519, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.6562
Fold [5/5] Epoch [20/100] Initial Loss: 0.1384, Training Loss: 0.0055, Initial Validation Loss: 0.1344, Validation Loss: 0.0290,V Acc: 0.8611, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.6875
Fold [5/5] Epoch [30/100] Initial Loss: 0.1384, Training Loss: 0.0042, Initial Validation Loss: 0.1344, Validation Loss: 0.0270,V Acc: 0.8796, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.6875
Fold [5/5] Epoch [40/100] Initial Loss: 0.1384, Training Loss: 0.0039, Initial Validation Loss: 0.1344, Validation Loss: 0.0264,V Acc: 0.8889, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.7188
Stopping early at Epoch (base 0): 43  Rolling back to Epoch (base 0): 38  Top Validation Acc: 0.9605263157894737
Running train_nn.py with seed 45
CUDA:False
Training samples count:  550
Training on 163 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1385, Training Loss: 0.1385, Initial Validation Loss: 0.1302, Validation Loss: 0.1302,V Acc: 0.2883, Top 70th Acc: 0.3590, Bottom 30th Acc: 0.1212
Stopping early at Epoch (base 0): 29  Rolling back to Epoch (base 0): 24  Top Validation Acc: 0.9230769230769231
Fold [3/5] Epoch [0/100] Initial Loss: 0.1360, Training Loss: 0.1360, Initial Validation Loss: 0.1318, Validation Loss: 0.1318,V Acc: 0.3455, Top 70th Acc: 0.4286, Bottom 30th Acc: 0.1515
Fold [3/5] Epoch [10/100] Initial Loss: 0.1360, Training Loss: 0.0314, Initial Validation Loss: 0.1318, Validation Loss: 0.0449,V Acc: 0.7909, Top 70th Acc: 0.8701, Bottom 30th Acc: 0.6061
Fold [3/5] Epoch [20/100] Initial Loss: 0.1360, Training Loss: 0.0168, Initial Validation Loss: 0.1318, Validation Loss: 0.0400,V Acc: 0.7909, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.5152
Stopping early at Epoch (base 0): 28  Rolling back to Epoch (base 0): 23  Top Validation Acc: 0.922077922077922
Fold [4/5] Epoch [0/100] Initial Loss: 0.1381, Training Loss: 0.1381, Initial Validation Loss: 0.1363, Validation Loss: 0.1363,V Acc: 0.3273, Top 70th Acc: 0.3506, Bottom 30th Acc: 0.2727
Fold [4/5] Epoch [10/100] Initial Loss: 0.1381, Training Loss: 0.0333, Initial Validation Loss: 0.1363, Validation Loss: 0.0329,V Acc: 0.8818, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.6667
Fold [4/5] Epoch [20/100] Initial Loss: 0.1381, Training Loss: 0.0192, Initial Validation Loss: 0.1363, Validation Loss: 0.0250,V Acc: 0.8727, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.948051948051948
Fold [5/5] Epoch [0/100] Initial Loss: 0.1370, Training Loss: 0.1370, Initial Validation Loss: 0.1289, Validation Loss: 0.1289,V Acc: 0.3611, Top 70th Acc: 0.4079, Bottom 30th Acc: 0.2500
Fold [5/5] Epoch [10/100] Initial Loss: 0.1370, Training Loss: 0.0446, Initial Validation Loss: 0.1289, Validation Loss: 0.0525,V Acc: 0.7593, Top 70th Acc: 0.8553, Bottom 30th Acc: 0.5312
Fold [5/5] Epoch [20/100] Initial Loss: 0.1370, Training Loss: 0.0195, Initial Validation Loss: 0.1289, Validation Loss: 0.0368,V Acc: 0.8056, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.5000
Fold [5/5] Epoch [30/100] Initial Loss: 0.1370, Training Loss: 0.0160, Initial Validation Loss: 0.1289, Validation Loss: 0.0355,V Acc: 0.7963, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.4688
Stopping early at Epoch (base 0): 32  Rolling back to Epoch (base 0): 27  Top Validation Acc: 0.9210526315789473
Running train_nn.py with seed 58
CUDA:False
Training samples count:  550
Training on 30 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1364, Training Loss: 0.1364, Initial Validation Loss: 0.1354, Validation Loss: 0.1354,V Acc: 0.3243, Top 70th Acc: 0.3846, Bottom 30th Acc: 0.1818
Fold [1/5] Epoch [10/100] Initial Loss: 0.1364, Training Loss: 0.0307, Initial Validation Loss: 0.1354, Validation Loss: 0.0402,V Acc: 0.8378, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.6061
Fold [1/5] Epoch [20/100] Initial Loss: 0.1364, Training Loss: 0.0185, Initial Validation Loss: 0.1354, Validation Loss: 0.0334,V Acc: 0.8468, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 22  Rolling back to Epoch (base 0): 17  Top Validation Acc: 0.9487179487179487
Fold [2/5] Epoch [0/100] Initial Loss: 0.1389, Training Loss: 0.1389, Initial Validation Loss: 0.1345, Validation Loss: 0.1345,V Acc: 0.2523, Top 70th Acc: 0.3462, Bottom 30th Acc: 0.0303
Fold [2/5] Epoch [10/100] Initial Loss: 0.1389, Training Loss: 0.0372, Initial Validation Loss: 0.1345, Validation Loss: 0.0364,V Acc: 0.8468, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.6667
Fold [2/5] Epoch [20/100] Initial Loss: 0.1389, Training Loss: 0.0201, Initial Validation Loss: 0.1345, Validation Loss: 0.0272,V Acc: 0.8829, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.7273
Stopping early at Epoch (base 0): 28  Rolling back to Epoch (base 0): 23  Top Validation Acc: 0.9358974358974359
58 1 [array([0.59318566, 0.11929941, 0.09749577, 0.10552458, 0.08449452],
      dtype=float32)]
Fold [3/5] Epoch [0/100] Initial Loss: 0.1390, Training Loss: 0.1390, Initial Validation Loss: 0.1348, Validation Loss: 0.1348,V Acc: 0.3091, Top 70th Acc: 0.3766, Bottom 30th Acc: 0.1515
Fold [3/5] Epoch [10/100] Initial Loss: 0.1390, Training Loss: 0.0308, Initial Validation Loss: 0.1348, Validation Loss: 0.0457,V Acc: 0.7727, Top 70th Acc: 0.8442, Bottom 30th Acc: 0.6061
Fold [3/5] Epoch [20/100] Initial Loss: 0.1390, Training Loss: 0.0177, Initial Validation Loss: 0.1348, Validation Loss: 0.0399,V Acc: 0.7727, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.4545
Fold [3/5] Epoch [30/100] Initial Loss: 0.1390, Training Loss: 0.0154, Initial Validation Loss: 0.1348, Validation Loss: 0.0394,V Acc: 0.7909, Top 70th Acc: 0.8961, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 30  Rolling back to Epoch (base 0): 25  Top Validation Acc: 0.8961038961038961
Fold [4/5] Epoch [0/100] Initial Loss: 0.1387, Training Loss: 0.1387, Initial Validation Loss: 0.1340, Validation Loss: 0.1340,V Acc: 0.3727, Top 70th Acc: 0.4156, Bottom 30th Acc: 0.2727
Fold [4/5] Epoch [10/100] Initial Loss: 0.1387, Training Loss: 0.0350, Initial Validation Loss: 0.1340, Validation Loss: 0.0303,V Acc: 0.8636, Top 70th Acc: 0.9870, Bottom 30th Acc: 0.5758
Fold [4/5] Epoch [20/100] Initial Loss: 0.1387, Training Loss: 0.0197, Initial Validation Loss: 0.1340, Validation Loss: 0.0244,V Acc: 0.8727, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.6364
Fold [4/5] Epoch [30/100] Initial Loss: 0.1387, Training Loss: 0.0173, Initial Validation Loss: 0.1340, Validation Loss: 0.0253,V Acc: 0.8727, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 30  Rolling back to Epoch (base 0): 25  Top Validation Acc: 0.961038961038961
Fold [5/5] Epoch [0/100] Initial Loss: 0.1376, Training Loss: 0.1376, Initial Validation Loss: 0.1292, Validation Loss: 0.1292,V Acc: 0.2963, Top 70th Acc: 0.3816, Bottom 30th Acc: 0.0938
Fold [5/5] Epoch [10/100] Initial Loss: 0.1376, Training Loss: 0.0291, Initial Validation Loss: 0.1292, Validation Loss: 0.0460,V Acc: 0.7500, Top 70th Acc: 0.8421, Bottom 30th Acc: 0.5312
Fold [5/5] Epoch [20/100] Initial Loss: 0.1376, Training Loss: 0.0187, Initial Validation Loss: 0.1292, Validation Loss: 0.0368,V Acc: 0.7778, Top 70th Acc: 0.9079, Bottom 30th Acc: 0.4688
Fold [5/5] Epoch [30/100] Initial Loss: 0.1376, Training Loss: 0.0162, Initial Validation Loss: 0.1292, Validation Loss: 0.0344,V Acc: 0.8241, Top 70th Acc: 0.9211, Bottom 30th Acc: 0.5938
Stopping early at Epoch (base 0): 33  Rolling back to Epoch (base 0): 28  Top Validation Acc: 0.9210526315789473
Running train_nn.py with seed 59
CUDA:False
Training samples count:  550
Training on 30 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1363, Training Loss: 0.1363, Initial Validation Loss: 0.1338, Validation Loss: 0.1338,V Acc: 0.3333, Top 70th Acc: 0.3718, Bottom 30th Acc: 0.2424
Fold [1/5] Epoch [10/100] Initial Loss: 0.1363, Training Loss: 0.0291, Initial Validation Loss: 0.1338, Validation Loss: 0.0315,V Acc: 0.8559, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.6061
Fold [1/5] Epoch [20/100] Initial Loss: 0.1363, Training Loss: 0.0180, Initial Validation Loss: 0.1338, Validation Loss: 0.0251,V Acc: 0.8468, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 28  Rolling back to Epoch (base 0): 23  Top Validation Acc: 0.9615384615384616
Fold [2/5] Epoch [0/100] Initial Loss: 0.1371, Training Loss: 0.1371, Initial Validation Loss: 0.1328, Validation Loss: 0.1328,V Acc: 0.3243, Top 70th Acc: 0.4359, Bottom 30th Acc: 0.0606
Fold [2/5] Epoch [10/100] Initial Loss: 0.1371, Training Loss: 0.0329, Initial Validation Loss: 0.1328, Validation Loss: 0.0387,V Acc: 0.8198, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.6061
Fold [2/5] Epoch [20/100] Initial Loss: 0.1371, Training Loss: 0.0229, Initial Validation Loss: 0.1328, Validation Loss: 0.0332,V Acc: 0.8378, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.6061
Fold [2/5] Epoch [30/100] Initial Loss: 0.1371, Training Loss: 0.0190, Initial Validation Loss: 0.1328, Validation Loss: 0.0303,V Acc: 0.8378, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.6061
Fold [2/5] Epoch [40/100] Initial Loss: 0.1371, Training Loss: 0.0163, Initial Validation Loss: 0.1328, Validation Loss: 0.0290,V Acc: 0.8559, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.6667
Fold [4/5] Epoch [30/100] Initial Loss: 0.1332, Training Loss: 0.0791, Initial Validation Loss: 0.1273, Validation Loss: 0.0747,V Acc: 0.6636, Top 70th Acc: 0.7662, Bottom 30th Acc: 0.4242
Stopping early at Epoch (base 0): 37  Rolling back to Epoch (base 0): 32  Top Validation Acc: 0.7662337662337663
53 3 [array([0.13384639, 0.34005824, 0.15552822, 0.24112912, 0.12943812],
      dtype=float32)]
Fold [5/5] Epoch [0/100] Initial Loss: 0.1333, Training Loss: 0.1333, Initial Validation Loss: 0.1243, Validation Loss: 0.1243,V Acc: 0.4537, Top 70th Acc: 0.5526, Bottom 30th Acc: 0.2188
Fold [5/5] Epoch [10/100] Initial Loss: 0.1333, Training Loss: 0.0811, Initial Validation Loss: 0.1243, Validation Loss: 0.0835,V Acc: 0.5926, Top 70th Acc: 0.7237, Bottom 30th Acc: 0.2812
Fold [5/5] Epoch [20/100] Initial Loss: 0.1333, Training Loss: 0.0784, Initial Validation Loss: 0.1243, Validation Loss: 0.0805,V Acc: 0.6019, Top 70th Acc: 0.7500, Bottom 30th Acc: 0.2500
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.7631578947368421
Running train_nn.py with seed 54
CUDA:False
Training samples count:  550
Training on 2 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1332, Training Loss: 0.1332, Initial Validation Loss: 0.1270, Validation Loss: 0.1270,V Acc: 0.4414, Top 70th Acc: 0.5256, Bottom 30th Acc: 0.2424
Fold [1/5] Epoch [10/100] Initial Loss: 0.1332, Training Loss: 0.0811, Initial Validation Loss: 0.1270, Validation Loss: 0.0800,V Acc: 0.6577, Top 70th Acc: 0.7436, Bottom 30th Acc: 0.4545
Fold [1/5] Epoch [20/100] Initial Loss: 0.1332, Training Loss: 0.0794, Initial Validation Loss: 0.1270, Validation Loss: 0.0783,V Acc: 0.6757, Top 70th Acc: 0.7436, Bottom 30th Acc: 0.5152
Fold [1/5] Epoch [30/100] Initial Loss: 0.1332, Training Loss: 0.0788, Initial Validation Loss: 0.1270, Validation Loss: 0.0785,V Acc: 0.6757, Top 70th Acc: 0.7564, Bottom 30th Acc: 0.4848
Stopping early at Epoch (base 0): 37  Rolling back to Epoch (base 0): 32  Top Validation Acc: 0.7435897435897436
Fold [2/5] Epoch [0/100] Initial Loss: 0.1282, Training Loss: 0.1282, Initial Validation Loss: 0.1177, Validation Loss: 0.1177,V Acc: 0.4955, Top 70th Acc: 0.6282, Bottom 30th Acc: 0.1818
Fold [2/5] Epoch [10/100] Initial Loss: 0.1282, Training Loss: 0.0828, Initial Validation Loss: 0.1177, Validation Loss: 0.0758,V Acc: 0.6847, Top 70th Acc: 0.7692, Bottom 30th Acc: 0.4848
Fold [2/5] Epoch [20/100] Initial Loss: 0.1282, Training Loss: 0.0810, Initial Validation Loss: 0.1177, Validation Loss: 0.0736,V Acc: 0.6757, Top 70th Acc: 0.7692, Bottom 30th Acc: 0.4545
Fold [2/5] Epoch [30/100] Initial Loss: 0.1282, Training Loss: 0.0801, Initial Validation Loss: 0.1177, Validation Loss: 0.0729,V Acc: 0.6667, Top 70th Acc: 0.7692, Bottom 30th Acc: 0.4242
Stopping early at Epoch (base 0): 38  Rolling back to Epoch (base 0): 33  Top Validation Acc: 0.7435897435897436
Fold [3/5] Epoch [0/100] Initial Loss: 0.1343, Training Loss: 0.1343, Initial Validation Loss: 0.1222, Validation Loss: 0.1222,V Acc: 0.4091, Top 70th Acc: 0.5195, Bottom 30th Acc: 0.1515
Fold [3/5] Epoch [10/100] Initial Loss: 0.1343, Training Loss: 0.0779, Initial Validation Loss: 0.1222, Validation Loss: 0.0886,V Acc: 0.5273, Top 70th Acc: 0.6494, Bottom 30th Acc: 0.2424
Fold [3/5] Epoch [20/100] Initial Loss: 0.1343, Training Loss: 0.0758, Initial Validation Loss: 0.1222, Validation Loss: 0.0889,V Acc: 0.5455, Top 70th Acc: 0.6494, Bottom 30th Acc: 0.3030
Stopping early at Epoch (base 0): 28  Rolling back to Epoch (base 0): 23  Top Validation Acc: 0.6493506493506493
Fold [4/5] Epoch [0/100] Initial Loss: 0.1351, Training Loss: 0.1351, Initial Validation Loss: 0.1242, Validation Loss: 0.1242,V Acc: 0.4000, Top 70th Acc: 0.5065, Bottom 30th Acc: 0.1515
Fold [4/5] Epoch [10/100] Initial Loss: 0.1351, Training Loss: 0.0789, Initial Validation Loss: 0.1242, Validation Loss: 0.0841,V Acc: 0.6182, Top 70th Acc: 0.7013, Bottom 30th Acc: 0.4242
Fold [4/5] Epoch [20/100] Initial Loss: 0.1351, Training Loss: 0.0772, Initial Validation Loss: 0.1242, Validation Loss: 0.0841,V Acc: 0.6091, Top 70th Acc: 0.7013, Bottom 30th Acc: 0.3939
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.7142857142857143
54 3 [array([0.1524008 , 0.34520778, 0.13444197, 0.22799918, 0.13995022],
      dtype=float32)]
Fold [5/5] Epoch [0/100] Initial Loss: 0.1358, Training Loss: 0.1358, Initial Validation Loss: 0.1210, Validation Loss: 0.1210,V Acc: 0.4630, Top 70th Acc: 0.5395, Bottom 30th Acc: 0.2812
Fold [5/5] Epoch [10/100] Initial Loss: 0.1358, Training Loss: 0.0825, Initial Validation Loss: 0.1210, Validation Loss: 0.0730,V Acc: 0.6667, Top 70th Acc: 0.8158, Bottom 30th Acc: 0.3125
Fold [5/5] Epoch [20/100] Initial Loss: 0.1358, Training Loss: 0.0803, Initial Validation Loss: 0.1210, Validation Loss: 0.0706,V Acc: 0.6759, Top 70th Acc: 0.8026, Bottom 30th Acc: 0.3750
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.8157894736842105
Running train_nn.py with seed 55
CUDA:False
Training samples count:  550
Training on 2 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1371, Training Loss: 0.1371, Initial Validation Loss: 0.1316, Validation Loss: 0.1316,V Acc: 0.3964, Top 70th Acc: 0.4744, Bottom 30th Acc: 0.2121
Fold [1/5] Epoch [10/100] Initial Loss: 0.1371, Training Loss: 0.0812, Initial Validation Loss: 0.1316, Validation Loss: 0.0801,V Acc: 0.6486, Top 70th Acc: 0.7051, Bottom 30th Acc: 0.5152
Fold [1/5] Epoch [20/100] Initial Loss: 0.1371, Training Loss: 0.0789, Initial Validation Loss: 0.1316, Validation Loss: 0.0790,V Acc: 0.6577, Top 70th Acc: 0.7179, Bottom 30th Acc: 0.5152
Fold [1/5] Epoch [30/100] Initial Loss: 0.1371, Training Loss: 0.0780, Initial Validation Loss: 0.1316, Validation Loss: 0.0780,V Acc: 0.6667, Top 70th Acc: 0.7308, Bottom 30th Acc: 0.5152
Stopping early at Epoch (base 0): 34  Rolling back to Epoch (base 0): 29  Top Validation Acc: 0.717948717948718
Fold [2/5] Epoch [0/100] Initial Loss: 0.1337, Training Loss: 0.1337, Initial Validation Loss: 0.1325, Validation Loss: 0.1325,V Acc: 0.3874, Top 70th Acc: 0.5385, Bottom 30th Acc: 0.0303
Fold [2/5] Epoch [10/100] Initial Loss: 0.1337, Training Loss: 0.0813, Initial Validation Loss: 0.1325, Validation Loss: 0.0838,V Acc: 0.6577, Top 70th Acc: 0.7308, Bottom 30th Acc: 0.4848
Fold [2/5] Epoch [20/100] Initial Loss: 0.1337, Training Loss: 0.0793, Initial Validation Loss: 0.1325, Validation Loss: 0.0812,V Acc: 0.6937, Top 70th Acc: 0.7436, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 29  Rolling back to Epoch (base 0): 24  Top Validation Acc: 0.7051282051282052
Fold [3/5] Epoch [0/100] Initial Loss: 0.1338, Training Loss: 0.1338, Initial Validation Loss: 0.1150, Validation Loss: 0.1150,V Acc: 0.4727, Top 70th Acc: 0.6104, Bottom 30th Acc: 0.1515
Fold [3/5] Epoch [10/100] Initial Loss: 0.1338, Training Loss: 0.0796, Initial Validation Loss: 0.1150, Validation Loss: 0.0849,V Acc: 0.5636, Top 70th Acc: 0.6623, Bottom 30th Acc: 0.3333
Fold [3/5] Epoch [20/100] Initial Loss: 0.1338, Training Loss: 0.0784, Initial Validation Loss: 0.1150, Validation Loss: 0.0828,V Acc: 0.5636, Top 70th Acc: 0.6883, Bottom 30th Acc: 0.2727
Stopping early at Epoch (base 0): 21  Rolling back to Epoch (base 0): 16  Top Validation Acc: 0.6493506493506493
55 2 [array([0.1196385 , 0.41850466, 0.1288686 , 0.19306295, 0.13992527],
      dtype=float32)]
Fold [4/5] Epoch [0/100] Initial Loss: 0.1457, Training Loss: 0.1457, Initial Validation Loss: 0.1388, Validation Loss: 0.1388,V Acc: 0.0818, Top 70th Acc: 0.1169, Bottom 30th Acc: 0.0000
Fold [4/5] Epoch [10/100] Initial Loss: 0.1457, Training Loss: 0.0849, Initial Validation Loss: 0.1388, Validation Loss: 0.0692,V Acc: 0.7182, Top 70th Acc: 0.8701, Bottom 30th Acc: 0.3636
Fold [4/5] Epoch [20/100] Initial Loss: 0.1457, Training Loss: 0.0828, Initial Validation Loss: 0.1388, Validation Loss: 0.0664,V Acc: 0.7091, Top 70th Acc: 0.8571, Bottom 30th Acc: 0.3636
Fold [4/5] Epoch [30/100] Initial Loss: 0.1457, Training Loss: 0.0821, Initial Validation Loss: 0.1388, Validation Loss: 0.0651,V Acc: 0.7000, Top 70th Acc: 0.8571, Bottom 30th Acc: 0.3333
Fold [3/5] Epoch [10/100] Initial Loss: 0.1431, Training Loss: 0.0343, Initial Validation Loss: 0.1369, Validation Loss: 0.0416,V Acc: 0.8091, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.5758
Fold [3/5] Epoch [20/100] Initial Loss: 0.1431, Training Loss: 0.0234, Initial Validation Loss: 0.1369, Validation Loss: 0.0365,V Acc: 0.8000, Top 70th Acc: 0.8961, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.9090909090909091
Fold [4/5] Epoch [0/100] Initial Loss: 0.1396, Training Loss: 0.1396, Initial Validation Loss: 0.1374, Validation Loss: 0.1374,V Acc: 0.2545, Top 70th Acc: 0.3117, Bottom 30th Acc: 0.1212
Fold [4/5] Epoch [10/100] Initial Loss: 0.1396, Training Loss: 0.0348, Initial Validation Loss: 0.1374, Validation Loss: 0.0366,V Acc: 0.8273, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.5758
Fold [4/5] Epoch [20/100] Initial Loss: 0.1396, Training Loss: 0.0244, Initial Validation Loss: 0.1374, Validation Loss: 0.0314,V Acc: 0.8545, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 29  Rolling back to Epoch (base 0): 24  Top Validation Acc: 0.961038961038961
Fold [5/5] Epoch [0/100] Initial Loss: 0.1377, Training Loss: 0.1377, Initial Validation Loss: 0.1267, Validation Loss: 0.1267,V Acc: 0.3889, Top 70th Acc: 0.3947, Bottom 30th Acc: 0.3750
Fold [5/5] Epoch [10/100] Initial Loss: 0.1377, Training Loss: 0.0434, Initial Validation Loss: 0.1267, Validation Loss: 0.0479,V Acc: 0.7778, Top 70th Acc: 0.8684, Bottom 30th Acc: 0.5625
Fold [5/5] Epoch [20/100] Initial Loss: 0.1377, Training Loss: 0.0237, Initial Validation Loss: 0.1267, Validation Loss: 0.0383,V Acc: 0.8241, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.5625
Stopping early at Epoch (base 0): 20  Rolling back to Epoch (base 0): 15  Top Validation Acc: 0.9342105263157895
Running train_nn.py with seed 58
CUDA:False
Training samples count:  550
Training on 20 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1367, Training Loss: 0.1367, Initial Validation Loss: 0.1334, Validation Loss: 0.1334,V Acc: 0.4324, Top 70th Acc: 0.4615, Bottom 30th Acc: 0.3636
Fold [1/5] Epoch [10/100] Initial Loss: 0.1367, Training Loss: 0.0373, Initial Validation Loss: 0.1334, Validation Loss: 0.0467,V Acc: 0.8288, Top 70th Acc: 0.8846, Bottom 30th Acc: 0.6970
Fold [1/5] Epoch [20/100] Initial Loss: 0.1367, Training Loss: 0.0255, Initial Validation Loss: 0.1334, Validation Loss: 0.0411,V Acc: 0.8018, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.5152
Stopping early at Epoch (base 0): 22  Rolling back to Epoch (base 0): 17  Top Validation Acc: 0.9230769230769231
Fold [2/5] Epoch [0/100] Initial Loss: 0.1400, Training Loss: 0.1400, Initial Validation Loss: 0.1330, Validation Loss: 0.1330,V Acc: 0.3514, Top 70th Acc: 0.4103, Bottom 30th Acc: 0.2121
Fold [2/5] Epoch [10/100] Initial Loss: 0.1400, Training Loss: 0.0390, Initial Validation Loss: 0.1330, Validation Loss: 0.0379,V Acc: 0.8468, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.6970
Fold [2/5] Epoch [20/100] Initial Loss: 0.1400, Training Loss: 0.0245, Initial Validation Loss: 0.1330, Validation Loss: 0.0339,V Acc: 0.8378, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.9102564102564102
58 1 [array([0.38466018, 0.09481677, 0.13485667, 0.16886564, 0.21680078],
      dtype=float32)]
Fold [3/5] Epoch [0/100] Initial Loss: 0.1418, Training Loss: 0.1418, Initial Validation Loss: 0.1363, Validation Loss: 0.1363,V Acc: 0.3455, Top 70th Acc: 0.3117, Bottom 30th Acc: 0.4242
Fold [3/5] Epoch [10/100] Initial Loss: 0.1418, Training Loss: 0.0378, Initial Validation Loss: 0.1363, Validation Loss: 0.0487,V Acc: 0.7636, Top 70th Acc: 0.8571, Bottom 30th Acc: 0.5455
Fold [3/5] Epoch [20/100] Initial Loss: 0.1418, Training Loss: 0.0231, Initial Validation Loss: 0.1363, Validation Loss: 0.0390,V Acc: 0.7909, Top 70th Acc: 0.8831, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 29  Rolling back to Epoch (base 0): 24  Top Validation Acc: 0.8961038961038961
Fold [4/5] Epoch [0/100] Initial Loss: 0.1398, Training Loss: 0.1398, Initial Validation Loss: 0.1333, Validation Loss: 0.1333,V Acc: 0.3818, Top 70th Acc: 0.4805, Bottom 30th Acc: 0.1515
Fold [4/5] Epoch [10/100] Initial Loss: 0.1398, Training Loss: 0.0349, Initial Validation Loss: 0.1333, Validation Loss: 0.0271,V Acc: 0.8727, Top 70th Acc: 0.9870, Bottom 30th Acc: 0.6061
Fold [4/5] Epoch [20/100] Initial Loss: 0.1398, Training Loss: 0.0257, Initial Validation Loss: 0.1333, Validation Loss: 0.0220,V Acc: 0.9000, Top 70th Acc: 0.9870, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 27  Rolling back to Epoch (base 0): 22  Top Validation Acc: 0.974025974025974
Fold [5/5] Epoch [0/100] Initial Loss: 0.1389, Training Loss: 0.1389, Initial Validation Loss: 0.1309, Validation Loss: 0.1309,V Acc: 0.2500, Top 70th Acc: 0.3553, Bottom 30th Acc: 0.0000
Fold [5/5] Epoch [10/100] Initial Loss: 0.1389, Training Loss: 0.0365, Initial Validation Loss: 0.1309, Validation Loss: 0.0403,V Acc: 0.7870, Top 70th Acc: 0.8684, Bottom 30th Acc: 0.5938
Fold [5/5] Epoch [20/100] Initial Loss: 0.1389, Training Loss: 0.0235, Initial Validation Loss: 0.1309, Validation Loss: 0.0324,V Acc: 0.8426, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.6250
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.9473684210526315
Running train_nn.py with seed 59
CUDA:False
Training samples count:  550
Training on 20 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1381, Training Loss: 0.1381, Initial Validation Loss: 0.1362, Validation Loss: 0.1362,V Acc: 0.2793, Top 70th Acc: 0.3205, Bottom 30th Acc: 0.1818
Fold [1/5] Epoch [10/100] Initial Loss: 0.1381, Training Loss: 0.0383, Initial Validation Loss: 0.1362, Validation Loss: 0.0355,V Acc: 0.8288, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.4848
Fold [1/5] Epoch [20/100] Initial Loss: 0.1381, Training Loss: 0.0241, Initial Validation Loss: 0.1362, Validation Loss: 0.0248,V Acc: 0.8739, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.9743589743589743
Fold [2/5] Epoch [0/100] Initial Loss: 0.1382, Training Loss: 0.1382, Initial Validation Loss: 0.1329, Validation Loss: 0.1329,V Acc: 0.2703, Top 70th Acc: 0.3077, Bottom 30th Acc: 0.1818
Fold [2/5] Epoch [10/100] Initial Loss: 0.1382, Training Loss: 0.0346, Initial Validation Loss: 0.1329, Validation Loss: 0.0354,V Acc: 0.8198, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.5758
Fold [2/5] Epoch [20/100] Initial Loss: 0.1382, Training Loss: 0.0234, Initial Validation Loss: 0.1329, Validation Loss: 0.0290,V Acc: 0.8739, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.6970
Fold [2/5] Epoch [30/100] Initial Loss: 0.1382, Training Loss: 0.0212, Initial Validation Loss: 0.1329, Validation Loss: 0.0302,V Acc: 0.8649, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.7273
Stopping early at Epoch (base 0): 33  Rolling back to Epoch (base 0): 28  Top Validation Acc: 0.9358974358974359
Fold [3/5] Epoch [0/100] Initial Loss: 0.1366, Training Loss: 0.1366, Initial Validation Loss: 0.1291, Validation Loss: 0.1291,V Acc: 0.3545, Top 70th Acc: 0.4805, Bottom 30th Acc: 0.0606
Fold [3/5] Epoch [10/100] Initial Loss: 0.1366, Training Loss: 0.0314, Initial Validation Loss: 0.1291, Validation Loss: 0.0441,V Acc: 0.8000, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 18  Rolling back to Epoch (base 0): 13  Top Validation Acc: 0.8961038961038961
Fold [4/5] Epoch [0/100] Initial Loss: 0.1370, Training Loss: 0.1370, Initial Validation Loss: 0.1326, Validation Loss: 0.1326,V Acc: 0.3636, Top 70th Acc: 0.3636, Bottom 30th Acc: 0.3636
Fold [4/5] Epoch [10/100] Initial Loss: 0.1370, Training Loss: 0.0302, Initial Validation Loss: 0.1326, Validation Loss: 0.0360,V Acc: 0.8636, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6667
Fold [4/5] Epoch [20/100] Initial Loss: 0.1370, Training Loss: 0.0222, Initial Validation Loss: 0.1326, Validation Loss: 0.0331,V Acc: 0.8273, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.5455
Fold [4/5] Epoch [30/100] Initial Loss: 0.1370, Training Loss: 0.0205, Initial Validation Loss: 0.1326, Validation Loss: 0.0343,V Acc: 0.8182, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.5152
Stopping early at Epoch (base 0): 28  Rolling back to Epoch (base 0): 23  Top Validation Acc: 0.961038961038961
Fold [4/5] Epoch [0/100] Initial Loss: 0.1312, Training Loss: 0.1312, Initial Validation Loss: 0.1167, Validation Loss: 0.1167,V Acc: 0.5727, Top 70th Acc: 0.7013, Bottom 30th Acc: 0.2727
Fold [4/5] Epoch [10/100] Initial Loss: 0.1312, Training Loss: 0.0232, Initial Validation Loss: 0.1167, Validation Loss: 0.0316,V Acc: 0.8364, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 12  Rolling back to Epoch (base 0): 7  Top Validation Acc: 0.961038961038961
81 3 [array([0.70043314, 0.0215299 , 0.05947745, 0.14271198, 0.07584742],
      dtype=float32)]
Fold [5/5] Epoch [0/100] Initial Loss: 0.1372, Training Loss: 0.1372, Initial Validation Loss: 0.1268, Validation Loss: 0.1268,V Acc: 0.4444, Top 70th Acc: 0.5658, Bottom 30th Acc: 0.1562
Fold [5/5] Epoch [10/100] Initial Loss: 0.1372, Training Loss: 0.0225, Initial Validation Loss: 0.1268, Validation Loss: 0.0371,V Acc: 0.8611, Top 70th Acc: 0.9211, Bottom 30th Acc: 0.7188
Stopping early at Epoch (base 0): 17  Rolling back to Epoch (base 0): 12  Top Validation Acc: 0.9342105263157895
Running train_nn.py with seed 82
CUDA:False
Training samples count:  550
Training on 21 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1342, Training Loss: 0.1342, Initial Validation Loss: 0.1190, Validation Loss: 0.1190,V Acc: 0.2973, Top 70th Acc: 0.3718, Bottom 30th Acc: 0.1212
Fold [1/5] Epoch [10/100] Initial Loss: 0.1342, Training Loss: 0.0208, Initial Validation Loss: 0.1190, Validation Loss: 0.0329,V Acc: 0.8378, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.6364
Fold [1/5] Epoch [20/100] Initial Loss: 0.1342, Training Loss: 0.0162, Initial Validation Loss: 0.1190, Validation Loss: 0.0237,V Acc: 0.8919, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.7576
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.9487179487179487
82 0 [array([0.74023414, 0.02487396, 0.02803233, 0.12314013, 0.08371936],
      dtype=float32)]
Fold [2/5] Epoch [0/100] Initial Loss: 0.1397, Training Loss: 0.1397, Initial Validation Loss: 0.1392, Validation Loss: 0.1392,V Acc: 0.3604, Top 70th Acc: 0.4103, Bottom 30th Acc: 0.2424
Fold [2/5] Epoch [10/100] Initial Loss: 0.1397, Training Loss: 0.0239, Initial Validation Loss: 0.1392, Validation Loss: 0.0391,V Acc: 0.8288, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.6364
Fold [2/5] Epoch [20/100] Initial Loss: 0.1397, Training Loss: 0.0164, Initial Validation Loss: 0.1392, Validation Loss: 0.0345,V Acc: 0.8649, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 28  Rolling back to Epoch (base 0): 23  Top Validation Acc: 0.9487179487179487
Fold [3/5] Epoch [0/100] Initial Loss: 0.1372, Training Loss: 0.1372, Initial Validation Loss: 0.1260, Validation Loss: 0.1260,V Acc: 0.4727, Top 70th Acc: 0.5195, Bottom 30th Acc: 0.3636
Fold [3/5] Epoch [10/100] Initial Loss: 0.1372, Training Loss: 0.0310, Initial Validation Loss: 0.1260, Validation Loss: 0.0345,V Acc: 0.8182, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.4848
Stopping early at Epoch (base 0): 17  Rolling back to Epoch (base 0): 12  Top Validation Acc: 0.8961038961038961
Fold [4/5] Epoch [0/100] Initial Loss: 0.1354, Training Loss: 0.1354, Initial Validation Loss: 0.1282, Validation Loss: 0.1282,V Acc: 0.4909, Top 70th Acc: 0.5455, Bottom 30th Acc: 0.3636
Fold [4/5] Epoch [10/100] Initial Loss: 0.1354, Training Loss: 0.0218, Initial Validation Loss: 0.1282, Validation Loss: 0.0306,V Acc: 0.8545, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 14  Rolling back to Epoch (base 0): 9  Top Validation Acc: 0.961038961038961
Fold [5/5] Epoch [0/100] Initial Loss: 0.1352, Training Loss: 0.1352, Initial Validation Loss: 0.1271, Validation Loss: 0.1271,V Acc: 0.4444, Top 70th Acc: 0.5526, Bottom 30th Acc: 0.1875
Fold [5/5] Epoch [10/100] Initial Loss: 0.1352, Training Loss: 0.0298, Initial Validation Loss: 0.1271, Validation Loss: 0.0259,V Acc: 0.8889, Top 70th Acc: 1.0000, Bottom 30th Acc: 0.6250
Fold [5/5] Epoch [20/100] Initial Loss: 0.1352, Training Loss: 0.0202, Initial Validation Loss: 0.1271, Validation Loss: 0.0192,V Acc: 0.8981, Top 70th Acc: 1.0000, Bottom 30th Acc: 0.6562
Stopping early at Epoch (base 0): 20  Rolling back to Epoch (base 0): 15  Top Validation Acc: 1.0
Running train_nn.py with seed 83
CUDA:False
Training samples count:  550
Training on 21 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1329, Training Loss: 0.1329, Initial Validation Loss: 0.1196, Validation Loss: 0.1196,V Acc: 0.4955, Top 70th Acc: 0.6282, Bottom 30th Acc: 0.1818
Fold [1/5] Epoch [10/100] Initial Loss: 0.1329, Training Loss: 0.0264, Initial Validation Loss: 0.1196, Validation Loss: 0.0327,V Acc: 0.8378, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.6061
Fold [1/5] Epoch [20/100] Initial Loss: 0.1329, Training Loss: 0.0183, Initial Validation Loss: 0.1196, Validation Loss: 0.0241,V Acc: 0.8919, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.7576
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.9487179487179487
Fold [2/5] Epoch [0/100] Initial Loss: 0.1323, Training Loss: 0.1323, Initial Validation Loss: 0.1268, Validation Loss: 0.1268,V Acc: 0.5315, Top 70th Acc: 0.6026, Bottom 30th Acc: 0.3636
Fold [2/5] Epoch [10/100] Initial Loss: 0.1323, Training Loss: 0.0255, Initial Validation Loss: 0.1268, Validation Loss: 0.0249,V Acc: 0.8919, Top 70th Acc: 0.9872, Bottom 30th Acc: 0.6667
Fold [2/5] Epoch [20/100] Initial Loss: 0.1323, Training Loss: 0.0195, Initial Validation Loss: 0.1268, Validation Loss: 0.0222,V Acc: 0.9189, Top 70th Acc: 0.9872, Bottom 30th Acc: 0.7576
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.9871794871794872
Fold [3/5] Epoch [0/100] Initial Loss: 0.1384, Training Loss: 0.1384, Initial Validation Loss: 0.1191, Validation Loss: 0.1191,V Acc: 0.5455, Top 70th Acc: 0.6234, Bottom 30th Acc: 0.3636
Fold [3/5] Epoch [10/100] Initial Loss: 0.1384, Training Loss: 0.0222, Initial Validation Loss: 0.1191, Validation Loss: 0.0301,V Acc: 0.8727, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6970
Fold [3/5] Epoch [20/100] Initial Loss: 0.1384, Training Loss: 0.0156, Initial Validation Loss: 0.1191, Validation Loss: 0.0277,V Acc: 0.8727, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.961038961038961
Fold [4/5] Epoch [0/100] Initial Loss: 0.1326, Training Loss: 0.1326, Initial Validation Loss: 0.1255, Validation Loss: 0.1255,V Acc: 0.4000, Top 70th Acc: 0.4935, Bottom 30th Acc: 0.1818
Fold [4/5] Epoch [10/100] Initial Loss: 0.1326, Training Loss: 0.0237, Initial Validation Loss: 0.1255, Validation Loss: 0.0354,V Acc: 0.8364, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.6364
Fold [4/5] Epoch [20/100] Initial Loss: 0.1326, Training Loss: 0.0163, Initial Validation Loss: 0.1255, Validation Loss: 0.0284,V Acc: 0.8636, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6667
Fold [4/5] Epoch [30/100] Initial Loss: 0.1326, Training Loss: 0.0144, Initial Validation Loss: 0.1255, Validation Loss: 0.0298,V Acc: 0.8545, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.6667
Fold [4/5] Epoch [40/100] Initial Loss: 0.1326, Training Loss: 0.0129, Initial Validation Loss: 0.1255, Validation Loss: 0.0265,V Acc: 0.8727, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 47  Rolling back to Epoch (base 0): 42  Top Validation Acc: 0.961038961038961
Fold [5/5] Epoch [0/100] Initial Loss: 0.1286, Training Loss: 0.1286, Initial Validation Loss: 0.1127, Validation Loss: 0.1127,V Acc: 0.4074, Top 70th Acc: 0.5132, Bottom 30th Acc: 0.1562
Fold [5/5] Epoch [10/100] Initial Loss: 0.1286, Training Loss: 0.0264, Initial Validation Loss: 0.1127, Validation Loss: 0.0419,V Acc: 0.7778, Top 70th Acc: 0.8947, Bottom 30th Acc: 0.5000
Fold [5/5] Epoch [20/100] Initial Loss: 0.1286, Training Loss: 0.0180, Initial Validation Loss: 0.1127, Validation Loss: 0.0371,V Acc: 0.7870, Top 70th Acc: 0.9079, Bottom 30th Acc: 0.5000
Fold [5/5] Epoch [30/100] Initial Loss: 0.1286, Training Loss: 0.0145, Initial Validation Loss: 0.1127, Validation Loss: 0.0321,V Acc: 0.8241, Top 70th Acc: 0.9079, Bottom 30th Acc: 0.6250
Stopping early at Epoch (base 0): 28  Rolling back to Epoch (base 0): 23  Top Validation Acc: 0.961038961038961
Fold [5/5] Epoch [0/100] Initial Loss: 0.1362, Training Loss: 0.1362, Initial Validation Loss: 0.1284, Validation Loss: 0.1284,V Acc: 0.3519, Top 70th Acc: 0.3684, Bottom 30th Acc: 0.3125
Fold [5/5] Epoch [10/100] Initial Loss: 0.1362, Training Loss: 0.0201, Initial Validation Loss: 0.1284, Validation Loss: 0.0342,V Acc: 0.8241, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.5312
Fold [5/5] Epoch [20/100] Initial Loss: 0.1362, Training Loss: 0.0129, Initial Validation Loss: 0.1284, Validation Loss: 0.0334,V Acc: 0.8056, Top 70th Acc: 0.9211, Bottom 30th Acc: 0.5312
Stopping early at Epoch (base 0): 20  Rolling back to Epoch (base 0): 15  Top Validation Acc: 0.9210526315789473
Running train_nn.py with seed 58
CUDA:False
Training samples count:  550
Training on 40 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1384, Training Loss: 0.1384, Initial Validation Loss: 0.1357, Validation Loss: 0.1357,V Acc: 0.3604, Top 70th Acc: 0.3462, Bottom 30th Acc: 0.3939
Fold [1/5] Epoch [10/100] Initial Loss: 0.1384, Training Loss: 0.0248, Initial Validation Loss: 0.1357, Validation Loss: 0.0362,V Acc: 0.8468, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.6061
Fold [1/5] Epoch [20/100] Initial Loss: 0.1384, Training Loss: 0.0130, Initial Validation Loss: 0.1357, Validation Loss: 0.0297,V Acc: 0.8649, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.9871794871794872
Fold [2/5] Epoch [0/100] Initial Loss: 0.1393, Training Loss: 0.1393, Initial Validation Loss: 0.1327, Validation Loss: 0.1327,V Acc: 0.3243, Top 70th Acc: 0.3333, Bottom 30th Acc: 0.3030
Fold [2/5] Epoch [10/100] Initial Loss: 0.1393, Training Loss: 0.0328, Initial Validation Loss: 0.1327, Validation Loss: 0.0333,V Acc: 0.8559, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.7273
Fold [2/5] Epoch [20/100] Initial Loss: 0.1393, Training Loss: 0.0143, Initial Validation Loss: 0.1327, Validation Loss: 0.0244,V Acc: 0.8829, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.7273
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.9358974358974359
58 1 [array([0.60497326, 0.06476463, 0.07744719, 0.10066929, 0.1521456 ],
      dtype=float32)]
Fold [3/5] Epoch [0/100] Initial Loss: 0.1454, Training Loss: 0.1454, Initial Validation Loss: 0.1358, Validation Loss: 0.1358,V Acc: 0.3000, Top 70th Acc: 0.3766, Bottom 30th Acc: 0.1212
Fold [3/5] Epoch [10/100] Initial Loss: 0.1454, Training Loss: 0.0266, Initial Validation Loss: 0.1358, Validation Loss: 0.0402,V Acc: 0.8000, Top 70th Acc: 0.8961, Bottom 30th Acc: 0.5758
Fold [3/5] Epoch [20/100] Initial Loss: 0.1454, Training Loss: 0.0136, Initial Validation Loss: 0.1358, Validation Loss: 0.0327,V Acc: 0.8273, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.935064935064935
Fold [4/5] Epoch [0/100] Initial Loss: 0.1399, Training Loss: 0.1399, Initial Validation Loss: 0.1348, Validation Loss: 0.1348,V Acc: 0.2818, Top 70th Acc: 0.3506, Bottom 30th Acc: 0.1212
Fold [4/5] Epoch [10/100] Initial Loss: 0.1399, Training Loss: 0.0305, Initial Validation Loss: 0.1348, Validation Loss: 0.0305,V Acc: 0.8727, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.6364
Fold [4/5] Epoch [20/100] Initial Loss: 0.1399, Training Loss: 0.0149, Initial Validation Loss: 0.1348, Validation Loss: 0.0247,V Acc: 0.8727, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.961038961038961
Fold [5/5] Epoch [0/100] Initial Loss: 0.1425, Training Loss: 0.1425, Initial Validation Loss: 0.1331, Validation Loss: 0.1331,V Acc: 0.2685, Top 70th Acc: 0.2632, Bottom 30th Acc: 0.2812
Fold [5/5] Epoch [10/100] Initial Loss: 0.1425, Training Loss: 0.0254, Initial Validation Loss: 0.1331, Validation Loss: 0.0362,V Acc: 0.7870, Top 70th Acc: 0.9079, Bottom 30th Acc: 0.5000
Fold [5/5] Epoch [20/100] Initial Loss: 0.1425, Training Loss: 0.0134, Initial Validation Loss: 0.1331, Validation Loss: 0.0318,V Acc: 0.8148, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.5312
Stopping early at Epoch (base 0): 28  Rolling back to Epoch (base 0): 23  Top Validation Acc: 0.9210526315789473
Running train_nn.py with seed 59
CUDA:False
Training samples count:  550
Training on 40 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1390, Training Loss: 0.1390, Initial Validation Loss: 0.1374, Validation Loss: 0.1374,V Acc: 0.3063, Top 70th Acc: 0.3718, Bottom 30th Acc: 0.1515
Fold [1/5] Epoch [10/100] Initial Loss: 0.1390, Training Loss: 0.0494, Initial Validation Loss: 0.1374, Validation Loss: 0.0496,V Acc: 0.7838, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.4848
Fold [1/5] Epoch [20/100] Initial Loss: 0.1390, Training Loss: 0.0207, Initial Validation Loss: 0.1374, Validation Loss: 0.0288,V Acc: 0.8649, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.6667
Fold [1/5] Epoch [30/100] Initial Loss: 0.1390, Training Loss: 0.0133, Initial Validation Loss: 0.1374, Validation Loss: 0.0257,V Acc: 0.8559, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 37  Rolling back to Epoch (base 0): 32  Top Validation Acc: 0.9615384615384616
Fold [2/5] Epoch [0/100] Initial Loss: 0.1375, Training Loss: 0.1375, Initial Validation Loss: 0.1324, Validation Loss: 0.1324,V Acc: 0.3604, Top 70th Acc: 0.4231, Bottom 30th Acc: 0.2121
Fold [2/5] Epoch [10/100] Initial Loss: 0.1375, Training Loss: 0.0224, Initial Validation Loss: 0.1324, Validation Loss: 0.0315,V Acc: 0.8378, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.5152
Fold [2/5] Epoch [20/100] Initial Loss: 0.1375, Training Loss: 0.0133, Initial Validation Loss: 0.1324, Validation Loss: 0.0284,V Acc: 0.8378, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.9487179487179487
Fold [3/5] Epoch [0/100] Initial Loss: 0.1399, Training Loss: 0.1399, Initial Validation Loss: 0.1347, Validation Loss: 0.1347,V Acc: 0.2545, Top 70th Acc: 0.2987, Bottom 30th Acc: 0.1515
Fold [3/5] Epoch [10/100] Initial Loss: 0.1399, Training Loss: 0.0400, Initial Validation Loss: 0.1347, Validation Loss: 0.0487,V Acc: 0.8091, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.5455
Fold [3/5] Epoch [20/100] Initial Loss: 0.1399, Training Loss: 0.0168, Initial Validation Loss: 0.1347, Validation Loss: 0.0303,V Acc: 0.8636, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.6970
Fold [3/5] Epoch [30/100] Initial Loss: 0.1399, Training Loss: 0.0131, Initial Validation Loss: 0.1347, Validation Loss: 0.0315,V Acc: 0.8545, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 30  Rolling back to Epoch (base 0): 25  Top Validation Acc: 0.922077922077922
Fold [4/5] Epoch [0/100] Initial Loss: 0.1423, Training Loss: 0.1423, Initial Validation Loss: 0.1376, Validation Loss: 0.1376,V Acc: 0.2636, Top 70th Acc: 0.3117, Bottom 30th Acc: 0.1515
Fold [4/5] Epoch [10/100] Initial Loss: 0.1423, Training Loss: 0.0430, Initial Validation Loss: 0.1376, Validation Loss: 0.0518,V Acc: 0.7455, Top 70th Acc: 0.8961, Bottom 30th Acc: 0.3939
Fold [4/5] Epoch [20/100] Initial Loss: 0.1423, Training Loss: 0.0196, Initial Validation Loss: 0.1376, Validation Loss: 0.0324,V Acc: 0.8273, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.5455
Fold [4/5] Epoch [30/100] Initial Loss: 0.1423, Training Loss: 0.0132, Initial Validation Loss: 0.1376, Validation Loss: 0.0276,V Acc: 0.8636, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.6364
Fold [4/5] Epoch [40/100] Initial Loss: 0.1423, Training Loss: 0.0113, Initial Validation Loss: 0.1376, Validation Loss: 0.0268,V Acc: 0.8545, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 48  Rolling back to Epoch (base 0): 43  Top Validation Acc: 0.961038961038961
Fold [5/5] Epoch [0/100] Initial Loss: 0.1397, Training Loss: 0.1397, Initial Validation Loss: 0.1326, Validation Loss: 0.1326,V Acc: 0.3241, Top 70th Acc: 0.3553, Bottom 30th Acc: 0.2500
Fold [5/5] Epoch [10/100] Initial Loss: 0.1397, Training Loss: 0.0238, Initial Validation Loss: 0.1326, Validation Loss: 0.0370,V Acc: 0.8519, Top 70th Acc: 0.9079, Bottom 30th Acc: 0.7188
Fold [1/5] Epoch [10/100] Initial Loss: 0.1385, Training Loss: 0.0119, Initial Validation Loss: 0.1302, Validation Loss: 0.0411,V Acc: 0.7658, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.4242
Fold [1/5] Epoch [20/100] Initial Loss: 0.1385, Training Loss: 0.0045, Initial Validation Loss: 0.1302, Validation Loss: 0.0383,V Acc: 0.7928, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.4545
Stopping early at Epoch (base 0): 21  Rolling back to Epoch (base 0): 16  Top Validation Acc: 0.9358974358974359
45 0 [array([0.15553334, 0.17382215, 0.03613251, 0.11451633, 0.5199956 ],
      dtype=float32)]
Fold [2/5] Epoch [0/100] Initial Loss: 0.1384, Training Loss: 0.1384, Initial Validation Loss: 0.1381, Validation Loss: 0.1381,V Acc: 0.2523, Top 70th Acc: 0.3205, Bottom 30th Acc: 0.0909
Fold [2/5] Epoch [10/100] Initial Loss: 0.1384, Training Loss: 0.0263, Initial Validation Loss: 0.1381, Validation Loss: 0.0500,V Acc: 0.7748, Top 70th Acc: 0.8718, Bottom 30th Acc: 0.5455
Fold [2/5] Epoch [20/100] Initial Loss: 0.1384, Training Loss: 0.0081, Initial Validation Loss: 0.1381, Validation Loss: 0.0447,V Acc: 0.7658, Top 70th Acc: 0.8974, Bottom 30th Acc: 0.4545
Fold [2/5] Epoch [30/100] Initial Loss: 0.1384, Training Loss: 0.0052, Initial Validation Loss: 0.1381, Validation Loss: 0.0421,V Acc: 0.7748, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.3939
Fold [2/5] Epoch [40/100] Initial Loss: 0.1384, Training Loss: 0.0044, Initial Validation Loss: 0.1381, Validation Loss: 0.0402,V Acc: 0.7928, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.4545
Stopping early at Epoch (base 0): 46  Rolling back to Epoch (base 0): 41  Top Validation Acc: 0.9615384615384616
Fold [3/5] Epoch [0/100] Initial Loss: 0.1383, Training Loss: 0.1383, Initial Validation Loss: 0.1306, Validation Loss: 0.1306,V Acc: 0.2636, Top 70th Acc: 0.3636, Bottom 30th Acc: 0.0303
Fold [3/5] Epoch [10/100] Initial Loss: 0.1383, Training Loss: 0.0140, Initial Validation Loss: 0.1306, Validation Loss: 0.0386,V Acc: 0.7636, Top 70th Acc: 0.8701, Bottom 30th Acc: 0.5152
Stopping early at Epoch (base 0): 17  Rolling back to Epoch (base 0): 12  Top Validation Acc: 0.8831168831168831
Fold [4/5] Epoch [0/100] Initial Loss: 0.1381, Training Loss: 0.1381, Initial Validation Loss: 0.1339, Validation Loss: 0.1339,V Acc: 0.2818, Top 70th Acc: 0.3636, Bottom 30th Acc: 0.0909
Fold [4/5] Epoch [10/100] Initial Loss: 0.1381, Training Loss: 0.0264, Initial Validation Loss: 0.1339, Validation Loss: 0.0401,V Acc: 0.8182, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.5758
Fold [4/5] Epoch [20/100] Initial Loss: 0.1381, Training Loss: 0.0058, Initial Validation Loss: 0.1339, Validation Loss: 0.0324,V Acc: 0.8273, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.5758
Fold [4/5] Epoch [30/100] Initial Loss: 0.1381, Training Loss: 0.0042, Initial Validation Loss: 0.1339, Validation Loss: 0.0309,V Acc: 0.8364, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.5455
Fold [4/5] Epoch [40/100] Initial Loss: 0.1381, Training Loss: 0.0038, Initial Validation Loss: 0.1339, Validation Loss: 0.0300,V Acc: 0.8545, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 48  Rolling back to Epoch (base 0): 43  Top Validation Acc: 0.948051948051948
Fold [5/5] Epoch [0/100] Initial Loss: 0.1363, Training Loss: 0.1363, Initial Validation Loss: 0.1328, Validation Loss: 0.1328,V Acc: 0.3704, Top 70th Acc: 0.4342, Bottom 30th Acc: 0.2188
Fold [5/5] Epoch [10/100] Initial Loss: 0.1363, Training Loss: 0.0110, Initial Validation Loss: 0.1328, Validation Loss: 0.0239,V Acc: 0.9167, Top 70th Acc: 0.9737, Bottom 30th Acc: 0.7812
Fold [5/5] Epoch [20/100] Initial Loss: 0.1363, Training Loss: 0.0047, Initial Validation Loss: 0.1328, Validation Loss: 0.0200,V Acc: 0.9074, Top 70th Acc: 0.9737, Bottom 30th Acc: 0.7500
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.9736842105263158
Running train_nn.py with seed 46
CUDA:False
Training samples count:  550
Training on 163 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1383, Training Loss: 0.1383, Initial Validation Loss: 0.1347, Validation Loss: 0.1347,V Acc: 0.2703, Top 70th Acc: 0.3590, Bottom 30th Acc: 0.0606
Fold [1/5] Epoch [10/100] Initial Loss: 0.1383, Training Loss: 0.0228, Initial Validation Loss: 0.1347, Validation Loss: 0.0432,V Acc: 0.7838, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.4848
Fold [1/5] Epoch [20/100] Initial Loss: 0.1383, Training Loss: 0.0051, Initial Validation Loss: 0.1347, Validation Loss: 0.0342,V Acc: 0.7838, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.4545
Fold [1/5] Epoch [30/100] Initial Loss: 0.1383, Training Loss: 0.0038, Initial Validation Loss: 0.1347, Validation Loss: 0.0324,V Acc: 0.7838, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.4242
Stopping early at Epoch (base 0): 35  Rolling back to Epoch (base 0): 30  Top Validation Acc: 0.9358974358974359
46 0 [array([0.31463456, 0.08819126, 0.06167952, 0.35468042, 0.18081427],
      dtype=float32)]
Fold [2/5] Epoch [0/100] Initial Loss: 0.1404, Training Loss: 0.1404, Initial Validation Loss: 0.1299, Validation Loss: 0.1299,V Acc: 0.3784, Top 70th Acc: 0.4487, Bottom 30th Acc: 0.2121
Fold [2/5] Epoch [10/100] Initial Loss: 0.1404, Training Loss: 0.0145, Initial Validation Loss: 0.1299, Validation Loss: 0.0346,V Acc: 0.8108, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.4545
Fold [2/5] Epoch [20/100] Initial Loss: 0.1404, Training Loss: 0.0049, Initial Validation Loss: 0.1299, Validation Loss: 0.0310,V Acc: 0.8559, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.6364
Fold [2/5] Epoch [30/100] Initial Loss: 0.1404, Training Loss: 0.0037, Initial Validation Loss: 0.1299, Validation Loss: 0.0282,V Acc: 0.8378, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.5152
Fold [2/5] Epoch [40/100] Initial Loss: 0.1404, Training Loss: 0.0034, Initial Validation Loss: 0.1299, Validation Loss: 0.0274,V Acc: 0.8468, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.5455
Fold [2/5] Epoch [50/100] Initial Loss: 0.1404, Training Loss: 0.0032, Initial Validation Loss: 0.1299, Validation Loss: 0.0249,V Acc: 0.8649, Top 70th Acc: 1.0000, Bottom 30th Acc: 0.5455
Fold [2/5] Epoch [60/100] Initial Loss: 0.1404, Training Loss: 0.0031, Initial Validation Loss: 0.1299, Validation Loss: 0.0244,V Acc: 0.8739, Top 70th Acc: 0.9872, Bottom 30th Acc: 0.6061
Fold [2/5] Epoch [70/100] Initial Loss: 0.1404, Training Loss: 0.0031, Initial Validation Loss: 0.1299, Validation Loss: 0.0237,V Acc: 0.8739, Top 70th Acc: 0.9872, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 70  Rolling back to Epoch (base 0): 65  Top Validation Acc: 0.9871794871794872
Fold [3/5] Epoch [0/100] Initial Loss: 0.1357, Training Loss: 0.1357, Initial Validation Loss: 0.1340, Validation Loss: 0.1340,V Acc: 0.2636, Top 70th Acc: 0.3247, Bottom 30th Acc: 0.1212
Fold [3/5] Epoch [10/100] Initial Loss: 0.1357, Training Loss: 0.0119, Initial Validation Loss: 0.1340, Validation Loss: 0.0297,V Acc: 0.8636, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6667
Fold [3/5] Epoch [20/100] Initial Loss: 0.1357, Training Loss: 0.0050, Initial Validation Loss: 0.1340, Validation Loss: 0.0265,V Acc: 0.8636, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.6364
Fold [3/5] Epoch [30/100] Initial Loss: 0.1357, Training Loss: 0.0041, Initial Validation Loss: 0.1340, Validation Loss: 0.0258,V Acc: 0.8636, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 33  Rolling back to Epoch (base 0): 28  Top Validation Acc: 0.948051948051948
Fold [4/5] Epoch [0/100] Initial Loss: 0.1401, Training Loss: 0.1401, Initial Validation Loss: 0.1327, Validation Loss: 0.1327,V Acc: 0.3364, Top 70th Acc: 0.3896, Bottom 30th Acc: 0.2121
Fold [4/5] Epoch [10/100] Initial Loss: 0.1401, Training Loss: 0.0308, Initial Validation Loss: 0.1327, Validation Loss: 0.0467,V Acc: 0.7727, Top 70th Acc: 0.8312, Bottom 30th Acc: 0.6364
Fold [4/5] Epoch [20/100] Initial Loss: 0.1401, Training Loss: 0.0086, Initial Validation Loss: 0.1327, Validation Loss: 0.0403,V Acc: 0.8091, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.5758
Fold [4/5] Epoch [30/100] Initial Loss: 0.1401, Training Loss: 0.0052, Initial Validation Loss: 0.1327, Validation Loss: 0.0375,V Acc: 0.8182, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.5758
Fold [4/5] Epoch [40/100] Initial Loss: 0.1401, Training Loss: 0.0045, Initial Validation Loss: 0.1327, Validation Loss: 0.0356,V Acc: 0.8455, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.6667
Training on 40 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 46
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 40 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 47
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 40 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 48
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 40 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 49
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 40 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 50
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 40 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 51
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 40 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 52
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 40 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 53
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 40 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 54
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 40 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 55
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 40 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 56
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 40 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 57
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 40 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 58
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 40 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 59
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 40 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 60
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 40 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 61
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 40 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 62
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 39 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 63
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 40 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 64
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 40 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 65
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 40 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 66
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 40 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 67
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 40 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 68
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 40 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 69
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 40 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 70
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 40 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 71
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 40 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 72
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 40 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 73
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 40 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 74
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 40 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 75
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 40 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 76
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 40 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 77
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 40 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 78
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 40 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 79
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 40 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 80
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 40 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 81
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 40 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 82
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 40 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 83
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 40 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 84
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 40 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 85
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 40 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 86
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 40 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 87
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 40 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 88
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 40 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 89
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 40 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 90
Training size: 439
Stopping early at Epoch (base 0): 31  Rolling back to Epoch (base 0): 26  Top Validation Acc: 0.8441558441558441
Fold [5/5] Epoch [0/100] Initial Loss: 0.1378, Training Loss: 0.1378, Initial Validation Loss: 0.1287, Validation Loss: 0.1287,V Acc: 0.4815, Top 70th Acc: 0.5526, Bottom 30th Acc: 0.3125
Fold [5/5] Epoch [10/100] Initial Loss: 0.1378, Training Loss: 0.0773, Initial Validation Loss: 0.1287, Validation Loss: 0.0868,V Acc: 0.5556, Top 70th Acc: 0.6974, Bottom 30th Acc: 0.2188
Stopping early at Epoch (base 0): 19  Rolling back to Epoch (base 0): 14  Top Validation Acc: 0.7105263157894737
Running train_nn.py with seed 56
CUDA:False
Training samples count:  550
Training on 2 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1354, Training Loss: 0.1354, Initial Validation Loss: 0.1318, Validation Loss: 0.1318,V Acc: 0.2613, Top 70th Acc: 0.3462, Bottom 30th Acc: 0.0606
Fold [1/5] Epoch [10/100] Initial Loss: 0.1354, Training Loss: 0.0801, Initial Validation Loss: 0.1318, Validation Loss: 0.0852,V Acc: 0.6306, Top 70th Acc: 0.7564, Bottom 30th Acc: 0.3333
Fold [1/5] Epoch [20/100] Initial Loss: 0.1354, Training Loss: 0.0783, Initial Validation Loss: 0.1318, Validation Loss: 0.0835,V Acc: 0.6486, Top 70th Acc: 0.7564, Bottom 30th Acc: 0.3939
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.7564102564102564
Fold [2/5] Epoch [0/100] Initial Loss: 0.1298, Training Loss: 0.1298, Initial Validation Loss: 0.1193, Validation Loss: 0.1193,V Acc: 0.3784, Top 70th Acc: 0.4231, Bottom 30th Acc: 0.2727
Fold [2/5] Epoch [10/100] Initial Loss: 0.1298, Training Loss: 0.0829, Initial Validation Loss: 0.1193, Validation Loss: 0.0705,V Acc: 0.6847, Top 70th Acc: 0.7821, Bottom 30th Acc: 0.4545
Fold [2/5] Epoch [20/100] Initial Loss: 0.1298, Training Loss: 0.0815, Initial Validation Loss: 0.1193, Validation Loss: 0.0690,V Acc: 0.6757, Top 70th Acc: 0.7821, Bottom 30th Acc: 0.4242
Fold [2/5] Epoch [30/100] Initial Loss: 0.1298, Training Loss: 0.0808, Initial Validation Loss: 0.1193, Validation Loss: 0.0678,V Acc: 0.6847, Top 70th Acc: 0.7821, Bottom 30th Acc: 0.4545
Stopping early at Epoch (base 0): 36  Rolling back to Epoch (base 0): 31  Top Validation Acc: 0.782051282051282
Fold [3/5] Epoch [0/100] Initial Loss: 0.1372, Training Loss: 0.1372, Initial Validation Loss: 0.1262, Validation Loss: 0.1262,V Acc: 0.3909, Top 70th Acc: 0.5455, Bottom 30th Acc: 0.0303
Fold [3/5] Epoch [10/100] Initial Loss: 0.1372, Training Loss: 0.0775, Initial Validation Loss: 0.1262, Validation Loss: 0.0901,V Acc: 0.5455, Top 70th Acc: 0.6753, Bottom 30th Acc: 0.2424
Stopping early at Epoch (base 0): 11  Rolling back to Epoch (base 0): 6  Top Validation Acc: 0.6883116883116883
Fold [4/5] Epoch [0/100] Initial Loss: 0.1373, Training Loss: 0.1373, Initial Validation Loss: 0.1293, Validation Loss: 0.1293,V Acc: 0.4909, Top 70th Acc: 0.6234, Bottom 30th Acc: 0.1818
Fold [4/5] Epoch [10/100] Initial Loss: 0.1373, Training Loss: 0.0801, Initial Validation Loss: 0.1293, Validation Loss: 0.0823,V Acc: 0.5727, Top 70th Acc: 0.7273, Bottom 30th Acc: 0.2121
Fold [4/5] Epoch [20/100] Initial Loss: 0.1373, Training Loss: 0.0790, Initial Validation Loss: 0.1293, Validation Loss: 0.0798,V Acc: 0.5727, Top 70th Acc: 0.7273, Bottom 30th Acc: 0.2121
Fold [4/5] Epoch [30/100] Initial Loss: 0.1373, Training Loss: 0.0787, Initial Validation Loss: 0.1293, Validation Loss: 0.0793,V Acc: 0.5818, Top 70th Acc: 0.7273, Bottom 30th Acc: 0.2424
Fold [4/5] Epoch [40/100] Initial Loss: 0.1373, Training Loss: 0.0786, Initial Validation Loss: 0.1293, Validation Loss: 0.0787,V Acc: 0.6091, Top 70th Acc: 0.7273, Bottom 30th Acc: 0.3333
Stopping early at Epoch (base 0): 45  Rolling back to Epoch (base 0): 40  Top Validation Acc: 0.7272727272727273
56 3 [array([0.1455864 , 0.35496578, 0.14497359, 0.22583985, 0.1286344 ],
      dtype=float32)]
Fold [5/5] Epoch [0/100] Initial Loss: 0.1348, Training Loss: 0.1348, Initial Validation Loss: 0.1239, Validation Loss: 0.1239,V Acc: 0.4352, Top 70th Acc: 0.3947, Bottom 30th Acc: 0.5312
Fold [5/5] Epoch [10/100] Initial Loss: 0.1348, Training Loss: 0.0824, Initial Validation Loss: 0.1239, Validation Loss: 0.0759,V Acc: 0.6852, Top 70th Acc: 0.7500, Bottom 30th Acc: 0.5312
Fold [5/5] Epoch [20/100] Initial Loss: 0.1348, Training Loss: 0.0801, Initial Validation Loss: 0.1239, Validation Loss: 0.0744,V Acc: 0.6759, Top 70th Acc: 0.7237, Bottom 30th Acc: 0.5625
Fold [5/5] Epoch [30/100] Initial Loss: 0.1348, Training Loss: 0.0791, Initial Validation Loss: 0.1239, Validation Loss: 0.0740,V Acc: 0.6574, Top 70th Acc: 0.7500, Bottom 30th Acc: 0.4375
Stopping early at Epoch (base 0): 32  Rolling back to Epoch (base 0): 27  Top Validation Acc: 0.75
Running train_nn.py with seed 57
CUDA:False
Training samples count:  550
Training on 2 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1305, Training Loss: 0.1305, Initial Validation Loss: 0.1159, Validation Loss: 0.1159,V Acc: 0.5315, Top 70th Acc: 0.6154, Bottom 30th Acc: 0.3333
Fold [1/5] Epoch [10/100] Initial Loss: 0.1305, Training Loss: 0.0794, Initial Validation Loss: 0.1159, Validation Loss: 0.0814,V Acc: 0.5676, Top 70th Acc: 0.6923, Bottom 30th Acc: 0.2727
Stopping early at Epoch (base 0): 17  Rolling back to Epoch (base 0): 12  Top Validation Acc: 0.6923076923076923
57 0 [array([0.13179335, 0.3713432 , 0.12806284, 0.20486754, 0.16393305],
      dtype=float32)]
Fold [2/5] Epoch [0/100] Initial Loss: 0.1370, Training Loss: 0.1370, Initial Validation Loss: 0.1335, Validation Loss: 0.1335,V Acc: 0.2523, Top 70th Acc: 0.3590, Bottom 30th Acc: 0.0000
Fold [2/5] Epoch [10/100] Initial Loss: 0.1370, Training Loss: 0.0836, Initial Validation Loss: 0.1335, Validation Loss: 0.0747,V Acc: 0.6937, Top 70th Acc: 0.7692, Bottom 30th Acc: 0.5152
Fold [2/5] Epoch [20/100] Initial Loss: 0.1370, Training Loss: 0.0816, Initial Validation Loss: 0.1335, Validation Loss: 0.0720,V Acc: 0.7117, Top 70th Acc: 0.7564, Bottom 30th Acc: 0.6061
Fold [2/5] Epoch [30/100] Initial Loss: 0.1370, Training Loss: 0.0808, Initial Validation Loss: 0.1335, Validation Loss: 0.0716,V Acc: 0.7027, Top 70th Acc: 0.7821, Bottom 30th Acc: 0.5152
Stopping early at Epoch (base 0): 34  Rolling back to Epoch (base 0): 29  Top Validation Acc: 0.7564102564102564
Fold [3/5] Epoch [0/100] Initial Loss: 0.1377, Training Loss: 0.1377, Initial Validation Loss: 0.1326, Validation Loss: 0.1326,V Acc: 0.2909, Top 70th Acc: 0.3636, Bottom 30th Acc: 0.1212
Fold [3/5] Epoch [10/100] Initial Loss: 0.1377, Training Loss: 0.0824, Initial Validation Loss: 0.1326, Validation Loss: 0.0781,V Acc: 0.6727, Top 70th Acc: 0.7922, Bottom 30th Acc: 0.3939
Fold [3/5] Epoch [20/100] Initial Loss: 0.1377, Training Loss: 0.0802, Initial Validation Loss: 0.1326, Validation Loss: 0.0756,V Acc: 0.6909, Top 70th Acc: 0.7922, Bottom 30th Acc: 0.4545
Fold [3/5] Epoch [30/100] Initial Loss: 0.1377, Training Loss: 0.0796, Initial Validation Loss: 0.1326, Validation Loss: 0.0750,V Acc: 0.6636, Top 70th Acc: 0.7922, Bottom 30th Acc: 0.3636
Stopping early at Epoch (base 0): 30  Rolling back to Epoch (base 0): 25  Top Validation Acc: 0.7922077922077922
Fold [4/5] Epoch [0/100] Initial Loss: 0.1431, Training Loss: 0.1431, Initial Validation Loss: 0.1372, Validation Loss: 0.1372,V Acc: 0.2818, Top 70th Acc: 0.3766, Bottom 30th Acc: 0.0606
Fold [4/5] Epoch [10/100] Initial Loss: 0.1431, Training Loss: 0.0809, Initial Validation Loss: 0.1372, Validation Loss: 0.0831,V Acc: 0.6091, Top 70th Acc: 0.7143, Bottom 30th Acc: 0.3636
Fold [4/5] Epoch [20/100] Initial Loss: 0.1431, Training Loss: 0.0787, Initial Validation Loss: 0.1372, Validation Loss: 0.0832,V Acc: 0.6091, Top 70th Acc: 0.7013, Bottom 30th Acc: 0.3939
Stopping early at Epoch (base 0): 20  Rolling back to Epoch (base 0): 15  Top Validation Acc: 0.7012987012987013
Fold [5/5] Epoch [0/100] Initial Loss: 0.1386, Training Loss: 0.1386, Initial Validation Loss: 0.1287, Validation Loss: 0.1287,V Acc: 0.3333, Top 70th Acc: 0.3947, Bottom 30th Acc: 0.1875
Fold [5/5] Epoch [10/100] Initial Loss: 0.1386, Training Loss: 0.0782, Initial Validation Loss: 0.1287, Validation Loss: 0.0851,V Acc: 0.5741, Top 70th Acc: 0.7105, Bottom 30th Acc: 0.2500
Stopping early at Epoch (base 0): 30  Rolling back to Epoch (base 0): 25  Top Validation Acc: 0.948051948051948
Fold [5/5] Epoch [0/100] Initial Loss: 0.1384, Training Loss: 0.1384, Initial Validation Loss: 0.1316, Validation Loss: 0.1316,V Acc: 0.2778, Top 70th Acc: 0.3684, Bottom 30th Acc: 0.0625
Fold [5/5] Epoch [10/100] Initial Loss: 0.1384, Training Loss: 0.0345, Initial Validation Loss: 0.1316, Validation Loss: 0.0402,V Acc: 0.7963, Top 70th Acc: 0.8947, Bottom 30th Acc: 0.5625
Fold [5/5] Epoch [20/100] Initial Loss: 0.1384, Training Loss: 0.0214, Initial Validation Loss: 0.1316, Validation Loss: 0.0338,V Acc: 0.8519, Top 70th Acc: 0.9211, Bottom 30th Acc: 0.6875
Stopping early at Epoch (base 0): 22  Rolling back to Epoch (base 0): 17  Top Validation Acc: 0.9342105263157895
59 4 [array([0.38969466, 0.08689639, 0.09415435, 0.25757626, 0.1716783 ],
      dtype=float32)]
Running train_nn.py with seed 60
CUDA:False
Training samples count:  550
Training on 20 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1397, Training Loss: 0.1397, Initial Validation Loss: 0.1367, Validation Loss: 0.1367,V Acc: 0.2523, Top 70th Acc: 0.3205, Bottom 30th Acc: 0.0909
Fold [1/5] Epoch [10/100] Initial Loss: 0.1397, Training Loss: 0.0390, Initial Validation Loss: 0.1367, Validation Loss: 0.0413,V Acc: 0.8378, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.6364
Fold [1/5] Epoch [20/100] Initial Loss: 0.1397, Training Loss: 0.0234, Initial Validation Loss: 0.1367, Validation Loss: 0.0326,V Acc: 0.8649, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 27  Rolling back to Epoch (base 0): 22  Top Validation Acc: 0.9358974358974359
Fold [2/5] Epoch [0/100] Initial Loss: 0.1394, Training Loss: 0.1394, Initial Validation Loss: 0.1397, Validation Loss: 0.1397,V Acc: 0.2613, Top 70th Acc: 0.2179, Bottom 30th Acc: 0.3636
Fold [2/5] Epoch [10/100] Initial Loss: 0.1394, Training Loss: 0.0361, Initial Validation Loss: 0.1397, Validation Loss: 0.0453,V Acc: 0.8108, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.5758
Fold [2/5] Epoch [20/100] Initial Loss: 0.1394, Training Loss: 0.0227, Initial Validation Loss: 0.1397, Validation Loss: 0.0388,V Acc: 0.8378, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.9102564102564102
Fold [3/5] Epoch [0/100] Initial Loss: 0.1368, Training Loss: 0.1368, Initial Validation Loss: 0.1308, Validation Loss: 0.1308,V Acc: 0.4818, Top 70th Acc: 0.5584, Bottom 30th Acc: 0.3030
Fold [3/5] Epoch [10/100] Initial Loss: 0.1368, Training Loss: 0.0399, Initial Validation Loss: 0.1308, Validation Loss: 0.0423,V Acc: 0.8364, Top 70th Acc: 0.8961, Bottom 30th Acc: 0.6970
Fold [3/5] Epoch [20/100] Initial Loss: 0.1368, Training Loss: 0.0231, Initial Validation Loss: 0.1308, Validation Loss: 0.0353,V Acc: 0.8364, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.935064935064935
60 2 [array([0.5030312 , 0.07245556, 0.13121326, 0.10966583, 0.18363415],
      dtype=float32)]
Fold [4/5] Epoch [0/100] Initial Loss: 0.1422, Training Loss: 0.1422, Initial Validation Loss: 0.1339, Validation Loss: 0.1339,V Acc: 0.4818, Top 70th Acc: 0.5065, Bottom 30th Acc: 0.4242
Fold [4/5] Epoch [10/100] Initial Loss: 0.1422, Training Loss: 0.0336, Initial Validation Loss: 0.1339, Validation Loss: 0.0431,V Acc: 0.7909, Top 70th Acc: 0.8831, Bottom 30th Acc: 0.5758
Fold [4/5] Epoch [20/100] Initial Loss: 0.1422, Training Loss: 0.0219, Initial Validation Loss: 0.1339, Validation Loss: 0.0379,V Acc: 0.8182, Top 70th Acc: 0.8961, Bottom 30th Acc: 0.6364
Fold [4/5] Epoch [30/100] Initial Loss: 0.1422, Training Loss: 0.0202, Initial Validation Loss: 0.1339, Validation Loss: 0.0370,V Acc: 0.8091, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 30  Rolling back to Epoch (base 0): 25  Top Validation Acc: 0.9090909090909091
Fold [5/5] Epoch [0/100] Initial Loss: 0.1382, Training Loss: 0.1382, Initial Validation Loss: 0.1298, Validation Loss: 0.1298,V Acc: 0.3796, Top 70th Acc: 0.3553, Bottom 30th Acc: 0.4375
Fold [5/5] Epoch [10/100] Initial Loss: 0.1382, Training Loss: 0.0406, Initial Validation Loss: 0.1298, Validation Loss: 0.0380,V Acc: 0.8056, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.5000
Fold [5/5] Epoch [20/100] Initial Loss: 0.1382, Training Loss: 0.0250, Initial Validation Loss: 0.1298, Validation Loss: 0.0307,V Acc: 0.8333, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.5625
Fold [5/5] Epoch [30/100] Initial Loss: 0.1382, Training Loss: 0.0208, Initial Validation Loss: 0.1298, Validation Loss: 0.0305,V Acc: 0.8333, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.5625
Fold [5/5] Epoch [40/100] Initial Loss: 0.1382, Training Loss: 0.0195, Initial Validation Loss: 0.1298, Validation Loss: 0.0293,V Acc: 0.8241, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.5000
Stopping early at Epoch (base 0): 47  Rolling back to Epoch (base 0): 42  Top Validation Acc: 0.9473684210526315
Running train_nn.py with seed 61
CUDA:False
Training samples count:  550
Training on 20 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1411, Training Loss: 0.1411, Initial Validation Loss: 0.1329, Validation Loss: 0.1329,V Acc: 0.2883, Top 70th Acc: 0.3205, Bottom 30th Acc: 0.2121
Fold [1/5] Epoch [10/100] Initial Loss: 0.1411, Training Loss: 0.0436, Initial Validation Loss: 0.1329, Validation Loss: 0.0464,V Acc: 0.8198, Top 70th Acc: 0.8846, Bottom 30th Acc: 0.6667
Fold [1/5] Epoch [20/100] Initial Loss: 0.1411, Training Loss: 0.0235, Initial Validation Loss: 0.1329, Validation Loss: 0.0304,V Acc: 0.8378, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.5758
Fold [1/5] Epoch [30/100] Initial Loss: 0.1411, Training Loss: 0.0207, Initial Validation Loss: 0.1329, Validation Loss: 0.0299,V Acc: 0.8198, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.4848
Stopping early at Epoch (base 0): 30  Rolling back to Epoch (base 0): 25  Top Validation Acc: 0.9615384615384616
Fold [2/5] Epoch [0/100] Initial Loss: 0.1353, Training Loss: 0.1353, Initial Validation Loss: 0.1312, Validation Loss: 0.1312,V Acc: 0.5045, Top 70th Acc: 0.6026, Bottom 30th Acc: 0.2727
Fold [2/5] Epoch [10/100] Initial Loss: 0.1353, Training Loss: 0.0365, Initial Validation Loss: 0.1312, Validation Loss: 0.0412,V Acc: 0.8108, Top 70th Acc: 0.8974, Bottom 30th Acc: 0.6061
Fold [2/5] Epoch [20/100] Initial Loss: 0.1353, Training Loss: 0.0224, Initial Validation Loss: 0.1312, Validation Loss: 0.0299,V Acc: 0.8559, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.6970
Fold [2/5] Epoch [30/100] Initial Loss: 0.1353, Training Loss: 0.0202, Initial Validation Loss: 0.1312, Validation Loss: 0.0293,V Acc: 0.8649, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 30  Rolling back to Epoch (base 0): 25  Top Validation Acc: 0.9487179487179487
Fold [3/5] Epoch [0/100] Initial Loss: 0.1382, Training Loss: 0.1382, Initial Validation Loss: 0.1353, Validation Loss: 0.1353,V Acc: 0.3364, Top 70th Acc: 0.4026, Bottom 30th Acc: 0.1818
Fold [3/5] Epoch [10/100] Initial Loss: 0.1382, Training Loss: 0.0309, Initial Validation Loss: 0.1353, Validation Loss: 0.0384,V Acc: 0.8182, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.5455
Fold [3/5] Epoch [20/100] Initial Loss: 0.1382, Training Loss: 0.0217, Initial Validation Loss: 0.1353, Validation Loss: 0.0357,V Acc: 0.8273, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.948051948051948
Fold [4/5] Epoch [0/100] Initial Loss: 0.1389, Training Loss: 0.1389, Initial Validation Loss: 0.1387, Validation Loss: 0.1387,V Acc: 0.2636, Top 70th Acc: 0.2468, Bottom 30th Acc: 0.3030
Fold [4/5] Epoch [10/100] Initial Loss: 0.1389, Training Loss: 0.0447, Initial Validation Loss: 0.1387, Validation Loss: 0.0434,V Acc: 0.8091, Top 70th Acc: 0.8961, Bottom 30th Acc: 0.6061
Fold [4/5] Epoch [20/100] Initial Loss: 0.1389, Training Loss: 0.0254, Initial Validation Loss: 0.1387, Validation Loss: 0.0289,V Acc: 0.8727, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc:
Fold [2/5] Epoch [50/100] Initial Loss: 0.1371, Training Loss: 0.0151, Initial Validation Loss: 0.1328, Validation Loss: 0.0281,V Acc: 0.8649, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.7273
Stopping early at Epoch (base 0): 56  Rolling back to Epoch (base 0): 51  Top Validation Acc: 0.9358974358974359
Fold [3/5] Epoch [0/100] Initial Loss: 0.1407, Training Loss: 0.1407, Initial Validation Loss: 0.1339, Validation Loss: 0.1339,V Acc: 0.2636, Top 70th Acc: 0.2857, Bottom 30th Acc: 0.2121
Fold [3/5] Epoch [10/100] Initial Loss: 0.1407, Training Loss: 0.0244, Initial Validation Loss: 0.1339, Validation Loss: 0.0419,V Acc: 0.7818, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.4848
Stopping early at Epoch (base 0): 19  Rolling back to Epoch (base 0): 14  Top Validation Acc: 0.9090909090909091
Fold [4/5] Epoch [0/100] Initial Loss: 0.1387, Training Loss: 0.1387, Initial Validation Loss: 0.1365, Validation Loss: 0.1365,V Acc: 0.2182, Top 70th Acc: 0.2597, Bottom 30th Acc: 0.1212
Fold [4/5] Epoch [10/100] Initial Loss: 0.1387, Training Loss: 0.0287, Initial Validation Loss: 0.1365, Validation Loss: 0.0345,V Acc: 0.8636, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.6970
Fold [4/5] Epoch [20/100] Initial Loss: 0.1387, Training Loss: 0.0176, Initial Validation Loss: 0.1365, Validation Loss: 0.0272,V Acc: 0.8727, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.6667
Fold [4/5] Epoch [30/100] Initial Loss: 0.1387, Training Loss: 0.0155, Initial Validation Loss: 0.1365, Validation Loss: 0.0273,V Acc: 0.8727, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 32  Rolling back to Epoch (base 0): 27  Top Validation Acc: 0.961038961038961
Fold [5/5] Epoch [0/100] Initial Loss: 0.1380, Training Loss: 0.1380, Initial Validation Loss: 0.1316, Validation Loss: 0.1316,V Acc: 0.2500, Top 70th Acc: 0.3158, Bottom 30th Acc: 0.0938
Fold [5/5] Epoch [10/100] Initial Loss: 0.1380, Training Loss: 0.0277, Initial Validation Loss: 0.1316, Validation Loss: 0.0350,V Acc: 0.8519, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.6562
Fold [5/5] Epoch [20/100] Initial Loss: 0.1380, Training Loss: 0.0165, Initial Validation Loss: 0.1316, Validation Loss: 0.0311,V Acc: 0.8426, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.5938
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.9605263157894737
59 4 [array([0.6539186 , 0.06144851, 0.04557053, 0.0901686 , 0.14889371],
      dtype=float32)]
Running train_nn.py with seed 60
CUDA:False
Training samples count:  550
Training on 30 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1444, Training Loss: 0.1444, Initial Validation Loss: 0.1381, Validation Loss: 0.1381,V Acc: 0.3423, Top 70th Acc: 0.3590, Bottom 30th Acc: 0.3030
Fold [1/5] Epoch [10/100] Initial Loss: 0.1444, Training Loss: 0.0331, Initial Validation Loss: 0.1381, Validation Loss: 0.0417,V Acc: 0.8288, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.6364
Fold [1/5] Epoch [20/100] Initial Loss: 0.1444, Training Loss: 0.0201, Initial Validation Loss: 0.1381, Validation Loss: 0.0357,V Acc: 0.8468, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 29  Rolling back to Epoch (base 0): 24  Top Validation Acc: 0.9230769230769231
Fold [2/5] Epoch [0/100] Initial Loss: 0.1390, Training Loss: 0.1390, Initial Validation Loss: 0.1359, Validation Loss: 0.1359,V Acc: 0.2703, Top 70th Acc: 0.3462, Bottom 30th Acc: 0.0909
Fold [2/5] Epoch [10/100] Initial Loss: 0.1390, Training Loss: 0.0328, Initial Validation Loss: 0.1359, Validation Loss: 0.0448,V Acc: 0.8018, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.5455
Fold [2/5] Epoch [20/100] Initial Loss: 0.1390, Training Loss: 0.0189, Initial Validation Loss: 0.1359, Validation Loss: 0.0364,V Acc: 0.8559, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 27  Rolling back to Epoch (base 0): 22  Top Validation Acc: 0.9230769230769231
Fold [3/5] Epoch [0/100] Initial Loss: 0.1387, Training Loss: 0.1387, Initial Validation Loss: 0.1343, Validation Loss: 0.1343,V Acc: 0.2545, Top 70th Acc: 0.2727, Bottom 30th Acc: 0.2121
Fold [3/5] Epoch [10/100] Initial Loss: 0.1387, Training Loss: 0.0310, Initial Validation Loss: 0.1343, Validation Loss: 0.0428,V Acc: 0.7818, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.4848
Fold [3/5] Epoch [20/100] Initial Loss: 0.1387, Training Loss: 0.0175, Initial Validation Loss: 0.1343, Validation Loss: 0.0352,V Acc: 0.8091, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.4545
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.961038961038961
60 2 [array([0.629019  , 0.06011445, 0.04702824, 0.05868945, 0.20514889],
      dtype=float32)]
Fold [4/5] Epoch [0/100] Initial Loss: 0.1390, Training Loss: 0.1390, Initial Validation Loss: 0.1336, Validation Loss: 0.1336,V Acc: 0.2909, Top 70th Acc: 0.3766, Bottom 30th Acc: 0.0909
Fold [4/5] Epoch [10/100] Initial Loss: 0.1390, Training Loss: 0.0267, Initial Validation Loss: 0.1336, Validation Loss: 0.0339,V Acc: 0.8273, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.6364
Fold [4/5] Epoch [20/100] Initial Loss: 0.1390, Training Loss: 0.0179, Initial Validation Loss: 0.1336, Validation Loss: 0.0301,V Acc: 0.8636, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.7273
Fold [4/5] Epoch [30/100] Initial Loss: 0.1390, Training Loss: 0.0158, Initial Validation Loss: 0.1336, Validation Loss: 0.0294,V Acc: 0.8727, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.7576
Stopping early at Epoch (base 0): 32  Rolling back to Epoch (base 0): 27  Top Validation Acc: 0.9090909090909091
Fold [5/5] Epoch [0/100] Initial Loss: 0.1387, Training Loss: 0.1387, Initial Validation Loss: 0.1312, Validation Loss: 0.1312,V Acc: 0.3796, Top 70th Acc: 0.4605, Bottom 30th Acc: 0.1875
Fold [5/5] Epoch [10/100] Initial Loss: 0.1387, Training Loss: 0.0328, Initial Validation Loss: 0.1312, Validation Loss: 0.0340,V Acc: 0.8148, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.5000
Fold [5/5] Epoch [20/100] Initial Loss: 0.1387, Training Loss: 0.0204, Initial Validation Loss: 0.1312, Validation Loss: 0.0294,V Acc: 0.8519, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.5938
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.9473684210526315
Running train_nn.py with seed 61
CUDA:False
Training samples count:  550
Training on 30 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1377, Training Loss: 0.1377, Initial Validation Loss: 0.1308, Validation Loss: 0.1308,V Acc: 0.3874, Top 70th Acc: 0.3974, Bottom 30th Acc: 0.3636
Fold [1/5] Epoch [10/100] Initial Loss: 0.1377, Training Loss: 0.0246, Initial Validation Loss: 0.1308, Validation Loss: 0.0355,V Acc: 0.8108, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.4848
Fold [1/5] Epoch [20/100] Initial Loss: 0.1377, Training Loss: 0.0168, Initial Validation Loss: 0.1308, Validation Loss: 0.0329,V Acc: 0.8018, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.4242
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.9487179487179487
Fold [2/5] Epoch [0/100] Initial Loss: 0.1365, Training Loss: 0.1365, Initial Validation Loss: 0.1339, Validation Loss: 0.1339,V Acc: 0.4144, Top 70th Acc: 0.4744, Bottom 30th Acc: 0.2727
Fold [2/5] Epoch [10/100] Initial Loss: 0.1365, Training Loss: 0.0343, Initial Validation Loss: 0.1339, Validation Loss: 0.0425,V Acc: 0.7928, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.5152
Fold [2/5] Epoch [20/100] Initial Loss: 0.1365, Training Loss: 0.0181, Initial Validation Loss: 0.1339, Validation Loss: 0.0353,V Acc: 0.8288, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 22  Rolling back to Epoch (base 0): 17  Top Validation Acc: 0.9358974358974359
Fold [3/5] Epoch [0/100] Initial Loss: 0.1401, Training Loss: 0.1401, Initial Validation Loss: 0.1340, Validation Loss: 0.1340,V Acc: 0.3727, Top 70th Acc: 0.4156, Bottom 30th Acc: 0.2727
Fold [3/5] Epoch [10/100] Initial Loss: 0.1401, Training Loss: 0.0269, Initial Validation Loss: 0.1340, Validation Loss: 0.0399,V Acc: 0.8091, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.5758
Fold [3/5] Epoch [20/100] Initial Loss: 0.1401, Training Loss: 0.0158, Initial Validation Loss: 0.1340, Validation Loss: 0.0381,V Acc: 0.8091, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.5455/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)

Stopping early at Epoch (base 0): 35  Rolling back to Epoch (base 0): 30  Top Validation Acc: 0.9078947368421053
83 4 [array([0.70776504, 0.03572628, 0.01796683, 0.1097938 , 0.12874809],
      dtype=float32)]
Running train_nn.py with seed 84
CUDA:False
Training samples count:  550
Training on 21 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1314, Training Loss: 0.1314, Initial Validation Loss: 0.1174, Validation Loss: 0.1174,V Acc: 0.4685, Top 70th Acc: 0.5513, Bottom 30th Acc: 0.2727
Fold [1/5] Epoch [10/100] Initial Loss: 0.1314, Training Loss: 0.0210, Initial Validation Loss: 0.1174, Validation Loss: 0.0370,V Acc: 0.8018, Top 70th Acc: 0.8974, Bottom 30th Acc: 0.5758
Fold [1/5] Epoch [20/100] Initial Loss: 0.1314, Training Loss: 0.0149, Initial Validation Loss: 0.1174, Validation Loss: 0.0337,V Acc: 0.8198, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 27  Rolling back to Epoch (base 0): 22  Top Validation Acc: 0.9230769230769231
84 0 [array([0.8452171 , 0.02896418, 0.02325614, 0.04794174, 0.05462087],
      dtype=float32)]
Fold [2/5] Epoch [0/100] Initial Loss: 0.1368, Training Loss: 0.1368, Initial Validation Loss: 0.1328, Validation Loss: 0.1328,V Acc: 0.2793, Top 70th Acc: 0.3590, Bottom 30th Acc: 0.0909
Fold [2/5] Epoch [10/100] Initial Loss: 0.1368, Training Loss: 0.0237, Initial Validation Loss: 0.1328, Validation Loss: 0.0289,V Acc: 0.8649, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.6364
Fold [2/5] Epoch [20/100] Initial Loss: 0.1368, Training Loss: 0.0175, Initial Validation Loss: 0.1328, Validation Loss: 0.0288,V Acc: 0.8649, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.9743589743589743
Fold [3/5] Epoch [0/100] Initial Loss: 0.1324, Training Loss: 0.1324, Initial Validation Loss: 0.1181, Validation Loss: 0.1181,V Acc: 0.4636, Top 70th Acc: 0.5455, Bottom 30th Acc: 0.2727
Fold [3/5] Epoch [10/100] Initial Loss: 0.1324, Training Loss: 0.0235, Initial Validation Loss: 0.1181, Validation Loss: 0.0355,V Acc: 0.8636, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 13  Rolling back to Epoch (base 0): 8  Top Validation Acc: 0.974025974025974
Fold [4/5] Epoch [0/100] Initial Loss: 0.1337, Training Loss: 0.1337, Initial Validation Loss: 0.1171, Validation Loss: 0.1171,V Acc: 0.4455, Top 70th Acc: 0.5455, Bottom 30th Acc: 0.2121
Fold [4/5] Epoch [10/100] Initial Loss: 0.1337, Training Loss: 0.0269, Initial Validation Loss: 0.1171, Validation Loss: 0.0276,V Acc: 0.8455, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.5758
Fold [4/5] Epoch [20/100] Initial Loss: 0.1337, Training Loss: 0.0182, Initial Validation Loss: 0.1171, Validation Loss: 0.0221,V Acc: 0.8636, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.961038961038961
Fold [5/5] Epoch [0/100] Initial Loss: 0.1340, Training Loss: 0.1340, Initial Validation Loss: 0.1259, Validation Loss: 0.1259,V Acc: 0.4259, Top 70th Acc: 0.5132, Bottom 30th Acc: 0.2188
Fold [5/5] Epoch [10/100] Initial Loss: 0.1340, Training Loss: 0.0219, Initial Validation Loss: 0.1259, Validation Loss: 0.0291,V Acc: 0.8611, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.6562
Stopping early at Epoch (base 0): 17  Rolling back to Epoch (base 0): 12  Top Validation Acc: 0.9210526315789473
Running train_nn.py with seed 85
CUDA:False
Training samples count:  550
Training on 21 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1298, Training Loss: 0.1298, Initial Validation Loss: 0.1168, Validation Loss: 0.1168,V Acc: 0.4955, Top 70th Acc: 0.5769, Bottom 30th Acc: 0.3030
Fold [1/5] Epoch [10/100] Initial Loss: 0.1298, Training Loss: 0.0254, Initial Validation Loss: 0.1168, Validation Loss: 0.0366,V Acc: 0.8198, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 19  Rolling back to Epoch (base 0): 14  Top Validation Acc: 0.9615384615384616
Fold [2/5] Epoch [0/100] Initial Loss: 0.1334, Training Loss: 0.1334, Initial Validation Loss: 0.1220, Validation Loss: 0.1220,V Acc: 0.5135, Top 70th Acc: 0.6667, Bottom 30th Acc: 0.1515
Fold [2/5] Epoch [10/100] Initial Loss: 0.1334, Training Loss: 0.0243, Initial Validation Loss: 0.1220, Validation Loss: 0.0290,V Acc: 0.8739, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 12  Rolling back to Epoch (base 0): 7  Top Validation Acc: 0.9615384615384616
85 1 [array([0.51175547, 0.03951838, 0.09760001, 0.196778  , 0.15434809],
      dtype=float32)]
Fold [3/5] Epoch [0/100] Initial Loss: 0.1288, Training Loss: 0.1288, Initial Validation Loss: 0.1122, Validation Loss: 0.1122,V Acc: 0.6000, Top 70th Acc: 0.7143, Bottom 30th Acc: 0.3333
Fold [3/5] Epoch [10/100] Initial Loss: 0.1288, Training Loss: 0.0232, Initial Validation Loss: 0.1122, Validation Loss: 0.0197,V Acc: 0.9273, Top 70th Acc: 0.9870, Bottom 30th Acc: 0.7879
Stopping early at Epoch (base 0): 15  Rolling back to Epoch (base 0): 10  Top Validation Acc: 0.987012987012987
Fold [4/5] Epoch [0/100] Initial Loss: 0.1341, Training Loss: 0.1341, Initial Validation Loss: 0.1251, Validation Loss: 0.1251,V Acc: 0.5273, Top 70th Acc: 0.5714, Bottom 30th Acc: 0.4242
Fold [4/5] Epoch [10/100] Initial Loss: 0.1341, Training Loss: 0.0216, Initial Validation Loss: 0.1251, Validation Loss: 0.0335,V Acc: 0.8364, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.6061
Fold [4/5] Epoch [20/100] Initial Loss: 0.1341, Training Loss: 0.0160, Initial Validation Loss: 0.1251, Validation Loss: 0.0301,V Acc: 0.8636, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 21  Rolling back to Epoch (base 0): 16  Top Validation Acc: 0.948051948051948
Fold [5/5] Epoch [0/100] Initial Loss: 0.1324, Training Loss: 0.1324, Initial Validation Loss: 0.1128, Validation Loss: 0.1128,V Acc: 0.4444, Top 70th Acc: 0.5658, Bottom 30th Acc: 0.1562
Fold [5/5] Epoch [10/100] Initial Loss: 0.1324, Training Loss: 0.0225, Initial Validation Loss: 0.1128, Validation Loss: 0.0258,V Acc: 0.8519, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.6562
Fold [5/5] Epoch [20/100] Initial Loss: 0.1324, Training Loss: 0.0163, Initial Validation Loss: 0.1128, Validation Loss: 0.0275,V Acc: 0.8611, Top 70th Acc: 0.9079, Bottom 30th Acc: 0.7500
Stopping early at Epoch (base 0): 20  Rolling back to Epoch (base 0): 15  Top Validation Acc: 0.9078947368421053
Running train_nn.py with seed 86
CUDA:False
Training samples count:  550
Training on 21 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1360, Training Loss: 0.1360, Initial Validation Loss: 0.1255, Validation Loss: 0.1255,V Acc: 0.5225, Top 70th Acc: 0.6026, Bottom 30th Acc: 0.3333
Fold [1/5] Epoch [10/100] Initial Loss: 0.1360, Training Loss: 0.0278, Initial Validation Loss: 0.1255, Validation Loss: 0.0282,V Acc: 0.8739, Top 70th Acc: 1.0000, Bottom 30th Acc: 0.5758
Fold [1/5] Epoch [20/100] Initial Loss: 0.1360, Training Loss: 0.0184, Initial Validation Loss: 0.1255, Validation Loss: 0.0293,V Acc: 0.8829, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 22  Rolling back to Epoch (base 0): 17  Top Validation Acc: 0.9871794871794872
Fold [2/5] Epoch [0/100] Initial Loss: 0.1339, Training Loss: 0.1339, Initial Validation Loss: 0.1205, Validation Loss: 0.1205,V Acc: 0.4595, Top 70th Acc: 0.5256, Bottom 30th Acc: 0.3030
Fold [2/5] Epoch [10/100] Initial Loss: 0.1339, Training Loss: 0.0230, Initial Validation Loss: 0.1205, Validation Loss: 0.0298,V Acc: 0.8559, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 16  Rolling back to Epoch (base 0): 11  Top Validation Acc: 0.9487179487179487
Fold [3/5] Epoch [0/100] Initial Loss: 0.1362, Training Loss: 0.1362, Initial Validation Loss: 0.1231, Validation Loss: 0.1231,V Acc: 0.4273, Top 70th Acc: 0.4675, Bottom 30th Acc: 0.3333
Fold [3/5] Epoch [10/100] Initial Loss: 0.1362, Training Loss: 0.0213, Initial Validation Loss: 0.1231, Validation Loss: 0.0308,V Acc: 0.8545, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.6970
Fold [3/5] Epoch [20/100] Initial Loss: 0.1362, Training Loss: 0.0156, Initial Validation Loss: 0.1231, Validation Loss: 0.0284,V Acc: 0.8636, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6667/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)

Fold [5/5] Epoch [20/100] Initial Loss: 0.1397, Training Loss: 0.0125, Initial Validation Loss: 0.1326, Validation Loss: 0.0335,V Acc: 0.8333, Top 70th Acc: 0.9211, Bottom 30th Acc: 0.6250
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.9342105263157895
59 4 [array([0.52344984, 0.05872237, 0.05460455, 0.07408885, 0.2891344 ],
      dtype=float32)]
Running train_nn.py with seed 60
CUDA:False
Training samples count:  550
Training on 40 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1372, Training Loss: 0.1372, Initial Validation Loss: 0.1306, Validation Loss: 0.1306,V Acc: 0.2973, Top 70th Acc: 0.3718, Bottom 30th Acc: 0.1212
Fold [1/5] Epoch [10/100] Initial Loss: 0.1372, Training Loss: 0.0361, Initial Validation Loss: 0.1306, Validation Loss: 0.0463,V Acc: 0.8108, Top 70th Acc: 0.8718, Bottom 30th Acc: 0.6667
Fold [1/5] Epoch [20/100] Initial Loss: 0.1372, Training Loss: 0.0156, Initial Validation Loss: 0.1306, Validation Loss: 0.0304,V Acc: 0.8468, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.5758
Fold [1/5] Epoch [30/100] Initial Loss: 0.1372, Training Loss: 0.0120, Initial Validation Loss: 0.1306, Validation Loss: 0.0277,V Acc: 0.8559, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.5758
Fold [1/5] Epoch [40/100] Initial Loss: 0.1372, Training Loss: 0.0110, Initial Validation Loss: 0.1306, Validation Loss: 0.0265,V Acc: 0.8739, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 44  Rolling back to Epoch (base 0): 39  Top Validation Acc: 0.9615384615384616
Fold [2/5] Epoch [0/100] Initial Loss: 0.1355, Training Loss: 0.1355, Initial Validation Loss: 0.1339, Validation Loss: 0.1339,V Acc: 0.3784, Top 70th Acc: 0.4103, Bottom 30th Acc: 0.3030
Fold [2/5] Epoch [10/100] Initial Loss: 0.1355, Training Loss: 0.0294, Initial Validation Loss: 0.1339, Validation Loss: 0.0436,V Acc: 0.7748, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.4545
Fold [2/5] Epoch [20/100] Initial Loss: 0.1355, Training Loss: 0.0137, Initial Validation Loss: 0.1339, Validation Loss: 0.0320,V Acc: 0.8108, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.4242
Fold [2/5] Epoch [30/100] Initial Loss: 0.1355, Training Loss: 0.0114, Initial Validation Loss: 0.1339, Validation Loss: 0.0302,V Acc: 0.8468, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 31  Rolling back to Epoch (base 0): 26  Top Validation Acc: 0.9615384615384616
Fold [3/5] Epoch [0/100] Initial Loss: 0.1444, Training Loss: 0.1444, Initial Validation Loss: 0.1351, Validation Loss: 0.1351,V Acc: 0.2818, Top 70th Acc: 0.3377, Bottom 30th Acc: 0.1515
Fold [3/5] Epoch [10/100] Initial Loss: 0.1444, Training Loss: 0.0273, Initial Validation Loss: 0.1351, Validation Loss: 0.0425,V Acc: 0.7727, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.4242
Fold [3/5] Epoch [20/100] Initial Loss: 0.1444, Training Loss: 0.0138, Initial Validation Loss: 0.1351, Validation Loss: 0.0359,V Acc: 0.7727, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.3030
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.974025974025974
60 2 [array([0.34879163, 0.03774824, 0.07303988, 0.08557966, 0.4548406 ],
      dtype=float32)]
Fold [4/5] Epoch [0/100] Initial Loss: 0.1389, Training Loss: 0.1389, Initial Validation Loss: 0.1342, Validation Loss: 0.1342,V Acc: 0.3000, Top 70th Acc: 0.3636, Bottom 30th Acc: 0.1515
Fold [4/5] Epoch [10/100] Initial Loss: 0.1389, Training Loss: 0.0306, Initial Validation Loss: 0.1342, Validation Loss: 0.0381,V Acc: 0.8273, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.5758
Fold [4/5] Epoch [20/100] Initial Loss: 0.1389, Training Loss: 0.0146, Initial Validation Loss: 0.1342, Validation Loss: 0.0285,V Acc: 0.8727, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.6667
Fold [4/5] Epoch [30/100] Initial Loss: 0.1389, Training Loss: 0.0121, Initial Validation Loss: 0.1342, Validation Loss: 0.0266,V Acc: 0.8545, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.6061
Fold [4/5] Epoch [40/100] Initial Loss: 0.1389, Training Loss: 0.0110, Initial Validation Loss: 0.1342, Validation Loss: 0.0266,V Acc: 0.8727, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 43  Rolling back to Epoch (base 0): 38  Top Validation Acc: 0.948051948051948
Fold [5/5] Epoch [0/100] Initial Loss: 0.1422, Training Loss: 0.1422, Initial Validation Loss: 0.1314, Validation Loss: 0.1314,V Acc: 0.3148, Top 70th Acc: 0.2632, Bottom 30th Acc: 0.4375
Fold [5/5] Epoch [10/100] Initial Loss: 0.1422, Training Loss: 0.0372, Initial Validation Loss: 0.1314, Validation Loss: 0.0460,V Acc: 0.7870, Top 70th Acc: 0.8553, Bottom 30th Acc: 0.6250
Fold [5/5] Epoch [20/100] Initial Loss: 0.1422, Training Loss: 0.0157, Initial Validation Loss: 0.1314, Validation Loss: 0.0281,V Acc: 0.8611, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.6562
Fold [5/5] Epoch [30/100] Initial Loss: 0.1422, Training Loss: 0.0125, Initial Validation Loss: 0.1314, Validation Loss: 0.0279,V Acc: 0.8704, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.6875
Stopping early at Epoch (base 0): 30  Rolling back to Epoch (base 0): 25  Top Validation Acc: 0.9473684210526315
Running train_nn.py with seed 61
CUDA:False
Training samples count:  550
Training on 40 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1372, Training Loss: 0.1372, Initial Validation Loss: 0.1323, Validation Loss: 0.1323,V Acc: 0.2613, Top 70th Acc: 0.3462, Bottom 30th Acc: 0.0606
Fold [1/5] Epoch [10/100] Initial Loss: 0.1372, Training Loss: 0.0211, Initial Validation Loss: 0.1323, Validation Loss: 0.0331,V Acc: 0.8468, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 18  Rolling back to Epoch (base 0): 13  Top Validation Acc: 0.9358974358974359
Fold [2/5] Epoch [0/100] Initial Loss: 0.1377, Training Loss: 0.1377, Initial Validation Loss: 0.1330, Validation Loss: 0.1330,V Acc: 0.4144, Top 70th Acc: 0.4744, Bottom 30th Acc: 0.2727
Fold [2/5] Epoch [10/100] Initial Loss: 0.1377, Training Loss: 0.0322, Initial Validation Loss: 0.1330, Validation Loss: 0.0426,V Acc: 0.8378, Top 70th Acc: 0.8846, Bottom 30th Acc: 0.7273
Fold [2/5] Epoch [20/100] Initial Loss: 0.1377, Training Loss: 0.0148, Initial Validation Loss: 0.1330, Validation Loss: 0.0356,V Acc: 0.8468, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 27  Rolling back to Epoch (base 0): 22  Top Validation Acc: 0.9230769230769231
Fold [3/5] Epoch [0/100] Initial Loss: 0.1370, Training Loss: 0.1370, Initial Validation Loss: 0.1340, Validation Loss: 0.1340,V Acc: 0.3091, Top 70th Acc: 0.3117, Bottom 30th Acc: 0.3030
Fold [3/5] Epoch [10/100] Initial Loss: 0.1370, Training Loss: 0.0281, Initial Validation Loss: 0.1340, Validation Loss: 0.0395,V Acc: 0.8091, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.5455
Fold [3/5] Epoch [20/100] Initial Loss: 0.1370, Training Loss: 0.0128, Initial Validation Loss: 0.1340, Validation Loss: 0.0347,V Acc: 0.8273, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.948051948051948
Fold [4/5] Epoch [0/100] Initial Loss: 0.1402, Training Loss: 0.1402, Initial Validation Loss: 0.1378, Validation Loss: 0.1378,V Acc: 0.2909, Top 70th Acc: 0.3506, Bottom 30th Acc: 0.1515
Fold [4/5] Epoch [10/100] Initial Loss: 0.1402, Training Loss: 0.0443, Initial Validation Loss: 0.1378, Validation Loss: 0.0458,V Acc: 0.8000, Top 70th Acc: 0.8961, Bottom 30th Acc: 0.5758
Fold [4/5] Epoch [20/100] Initial Loss: 0.1402, Training Loss: 0.0176, Initial Validation Loss: 0.1378, Validation Loss: 0.0257,V Acc: 0.8818, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.974025974025974
Fold [5/5] Epoch [0/100] Initial Loss: 0.1404, Training Loss: 0.1404, Initial Validation Loss: 0.1298, Validation Loss: 0.1298,V Acc: 0.3148, Top 70th Acc: 0.3158, Bottom 30th Acc: 0.3125
Fold [5/5] Epoch [10/100] Initial Loss: 0.1404, Training Loss: 0.0241, Initial Validation Loss: 0.1298, Validation Loss: 0.0356,V Acc: 0.8056, Top 70th Acc: 0.9079, Bottom 30th Acc: 0.5625
Stopping early at Epoch (base 0): 17  Rolling back to Epoch (base 0): 12  Top Validation Acc:/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
 0.961038961038961
Fold [5/5] Epoch [0/100] Initial Loss: 0.1386, Training Loss: 0.1386, Initial Validation Loss: 0.1271, Validation Loss: 0.1271,V Acc: 0.3981, Top 70th Acc: 0.4079, Bottom 30th Acc: 0.3750
Fold [5/5] Epoch [10/100] Initial Loss: 0.1386, Training Loss: 0.0392, Initial Validation Loss: 0.1271, Validation Loss: 0.0476,V Acc: 0.7407, Top 70th Acc: 0.8553, Bottom 30th Acc: 0.4688
Fold [5/5] Epoch [20/100] Initial Loss: 0.1386, Training Loss: 0.0240, Initial Validation Loss: 0.1271, Validation Loss: 0.0371,V Acc: 0.7963, Top 70th Acc: 0.9079, Bottom 30th Acc: 0.5312
Fold [5/5] Epoch [30/100] Initial Loss: 0.1386, Training Loss: 0.0208, Initial Validation Loss: 0.1271, Validation Loss: 0.0361,V Acc: 0.7870, Top 70th Acc: 0.8947, Bottom 30th Acc: 0.5312
Stopping early at Epoch (base 0): 31  Rolling back to Epoch (base 0): 26  Top Validation Acc: 0.9078947368421053
61 4 [array([0.18470305, 0.09849927, 0.173159  , 0.23889922, 0.3047395 ],
      dtype=float32)]
Running train_nn.py with seed 62
CUDA:False
Training samples count:  550
Training on 20 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1369, Training Loss: 0.1369, Initial Validation Loss: 0.1341, Validation Loss: 0.1341,V Acc: 0.3604, Top 70th Acc: 0.3590, Bottom 30th Acc: 0.3636
Fold [1/5] Epoch [10/100] Initial Loss: 0.1369, Training Loss: 0.0427, Initial Validation Loss: 0.1341, Validation Loss: 0.0535,V Acc: 0.8018, Top 70th Acc: 0.8205, Bottom 30th Acc: 0.7576
Fold [1/5] Epoch [20/100] Initial Loss: 0.1369, Training Loss: 0.0236, Initial Validation Loss: 0.1341, Validation Loss: 0.0383,V Acc: 0.8468, Top 70th Acc: 0.8846, Bottom 30th Acc: 0.7576
Fold [1/5] Epoch [30/100] Initial Loss: 0.1369, Training Loss: 0.0212, Initial Validation Loss: 0.1341, Validation Loss: 0.0376,V Acc: 0.8378, Top 70th Acc: 0.8974, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 30  Rolling back to Epoch (base 0): 25  Top Validation Acc: 0.8974358974358975
Fold [2/5] Epoch [0/100] Initial Loss: 0.1381, Training Loss: 0.1381, Initial Validation Loss: 0.1304, Validation Loss: 0.1304,V Acc: 0.2613, Top 70th Acc: 0.3333, Bottom 30th Acc: 0.0909
Fold [2/5] Epoch [10/100] Initial Loss: 0.1381, Training Loss: 0.0360, Initial Validation Loss: 0.1304, Validation Loss: 0.0386,V Acc: 0.7748, Top 70th Acc: 0.8974, Bottom 30th Acc: 0.4848
Fold [2/5] Epoch [20/100] Initial Loss: 0.1381, Training Loss: 0.0225, Initial Validation Loss: 0.1304, Validation Loss: 0.0337,V Acc: 0.7838, Top 70th Acc: 0.8974, Bottom 30th Acc: 0.5152
Fold [2/5] Epoch [30/100] Initial Loss: 0.1381, Training Loss: 0.0202, Initial Validation Loss: 0.1304, Validation Loss: 0.0316,V Acc: 0.8018, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.5152
Stopping early at Epoch (base 0): 32  Rolling back to Epoch (base 0): 27  Top Validation Acc: 0.8974358974358975
62 1 [array([0.37424847, 0.10731073, 0.21979485, 0.2080426 , 0.09060334],
      dtype=float32)]
Fold [3/5] Epoch [0/100] Initial Loss: 0.1345, Training Loss: 0.1345, Initial Validation Loss: 0.1329, Validation Loss: 0.1329,V Acc: 0.3364, Top 70th Acc: 0.4156, Bottom 30th Acc: 0.1515
Fold [3/5] Epoch [10/100] Initial Loss: 0.1345, Training Loss: 0.0375, Initial Validation Loss: 0.1329, Validation Loss: 0.0462,V Acc: 0.7727, Top 70th Acc: 0.8961, Bottom 30th Acc: 0.4848
Fold [3/5] Epoch [20/100] Initial Loss: 0.1345, Training Loss: 0.0273, Initial Validation Loss: 0.1329, Validation Loss: 0.0373,V Acc: 0.8273, Top 70th Acc: 0.8961, Bottom 30th Acc: 0.6667
Fold [3/5] Epoch [30/100] Initial Loss: 0.1345, Training Loss: 0.0234, Initial Validation Loss: 0.1329, Validation Loss: 0.0313,V Acc: 0.8636, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 36  Rolling back to Epoch (base 0): 31  Top Validation Acc: 0.922077922077922
Fold [4/5] Epoch [0/100] Initial Loss: 0.1338, Training Loss: 0.1338, Initial Validation Loss: 0.1236, Validation Loss: 0.1236,V Acc: 0.4818, Top 70th Acc: 0.5844, Bottom 30th Acc: 0.2424
Fold [4/5] Epoch [10/100] Initial Loss: 0.1338, Training Loss: 0.0331, Initial Validation Loss: 0.1236, Validation Loss: 0.0424,V Acc: 0.8000, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.5455
Fold [4/5] Epoch [20/100] Initial Loss: 0.1338, Training Loss: 0.0217, Initial Validation Loss: 0.1236, Validation Loss: 0.0397,V Acc: 0.8091, Top 70th Acc: 0.8961, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 21  Rolling back to Epoch (base 0): 16  Top Validation Acc: 0.9090909090909091
Fold [5/5] Epoch [0/100] Initial Loss: 0.1369, Training Loss: 0.1369, Initial Validation Loss: 0.1352, Validation Loss: 0.1352,V Acc: 0.2500, Top 70th Acc: 0.3421, Bottom 30th Acc: 0.0312
Fold [5/5] Epoch [10/100] Initial Loss: 0.1369, Training Loss: 0.0395, Initial Validation Loss: 0.1352, Validation Loss: 0.0331,V Acc: 0.8611, Top 70th Acc: 0.9737, Bottom 30th Acc: 0.5938
Fold [5/5] Epoch [20/100] Initial Loss: 0.1369, Training Loss: 0.0247, Initial Validation Loss: 0.1352, Validation Loss: 0.0259,V Acc: 0.9074, Top 70th Acc: 0.9737, Bottom 30th Acc: 0.7500
Fold [5/5] Epoch [30/100] Initial Loss: 0.1369, Training Loss: 0.0222, Initial Validation Loss: 0.1352, Validation Loss: 0.0255,V Acc: 0.9074, Top 70th Acc: 0.9868, Bottom 30th Acc: 0.7188
Stopping early at Epoch (base 0): 30  Rolling back to Epoch (base 0): 25  Top Validation Acc: 0.9868421052631579
Running train_nn.py with seed 63
CUDA:False
Training samples count:  550
Training on 20 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1352, Training Loss: 0.1352, Initial Validation Loss: 0.1348, Validation Loss: 0.1348,V Acc: 0.3964, Top 70th Acc: 0.4487, Bottom 30th Acc: 0.2727
Fold [1/5] Epoch [10/100] Initial Loss: 0.1352, Training Loss: 0.0329, Initial Validation Loss: 0.1348, Validation Loss: 0.0338,V Acc: 0.8829, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.6970
Fold [1/5] Epoch [20/100] Initial Loss: 0.1352, Training Loss: 0.0249, Initial Validation Loss: 0.1348, Validation Loss: 0.0283,V Acc: 0.8829, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 27  Rolling back to Epoch (base 0): 22  Top Validation Acc: 0.9615384615384616
Fold [2/5] Epoch [0/100] Initial Loss: 0.1399, Training Loss: 0.1399, Initial Validation Loss: 0.1296, Validation Loss: 0.1296,V Acc: 0.2883, Top 70th Acc: 0.3590, Bottom 30th Acc: 0.1212
Fold [2/5] Epoch [10/100] Initial Loss: 0.1399, Training Loss: 0.0380, Initial Validation Loss: 0.1296, Validation Loss: 0.0343,V Acc: 0.8288, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.6061
Fold [2/5] Epoch [20/100] Initial Loss: 0.1399, Training Loss: 0.0246, Initial Validation Loss: 0.1296, Validation Loss: 0.0273,V Acc: 0.8288, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.9358974358974359
Fold [3/5] Epoch [0/100] Initial Loss: 0.1368, Training Loss: 0.1368, Initial Validation Loss: 0.1322, Validation Loss: 0.1322,V Acc: 0.3364, Top 70th Acc: 0.4156, Bottom 30th Acc: 0.1515
Fold [3/5] Epoch [10/100] Initial Loss: 0.1368, Training Loss: 0.0396, Initial Validation Loss: 0.1322, Validation Loss: 0.0431,V Acc: 0.8091, Top 70th Acc: 0.8831, Bottom 30th Acc: 0.6364
Fold [3/5] Epoch [20/100] Initial Loss: 0.1368, Training Loss: 0.0239, Initial Validation Loss: 0.1322, Validation Loss: 0.0336,V Acc: 0.8364, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.9090909090909091
63 2 [array([0.5090526 , 0.09050132, 0.16563639, 0.13244873, 0.10236099],
      dtype=float32)]
Fold [4/5] Epoch [0/100] Initial Loss: 0.1423, Training Loss: 0.1423, Initial Validation Loss: 0.1373, Validation Loss: 0.1373,V Acc: 0.2364, Top 70th Acc: 0.2338, Bottom 30th Acc: 0.2424
Fold [4/5] Epoch [10/100] Initial Loss: 0.1423, Training Loss: 0.0366, Initial Validation Loss: 0.1373, Validation Loss: 0.0492,V Acc: 0.7727, Top 70th Acc: 0.8571, Bottom 30th Acc: 0.5758
Fold [4/5] Epoch [20/100] Initial Loss: 0.1423, Training Loss: 0.0215, Initial Validation Loss: 0.1373, Validation Loss: 0.0446,V Acc: 0.7727, Top 70th Acc: 0.8961, Bottom 30th Acc: 0.4848
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18
Stopping early at Epoch (base 0): 18  Rolling back to Epoch (base 0): 13  Top Validation Acc: 0.6973684210526315
Running train_nn.py with seed 58
CUDA:False
Training samples count:  550
Training on 2 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1401, Training Loss: 0.1401, Initial Validation Loss: 0.1332, Validation Loss: 0.1332,V Acc: 0.3604, Top 70th Acc: 0.4744, Bottom 30th Acc: 0.0909
Fold [1/5] Epoch [10/100] Initial Loss: 0.1401, Training Loss: 0.0776, Initial Validation Loss: 0.1332, Validation Loss: 0.0881,V Acc: 0.5856, Top 70th Acc: 0.7564, Bottom 30th Acc: 0.1818
Stopping early at Epoch (base 0): 15  Rolling back to Epoch (base 0): 10  Top Validation Acc: 0.7307692307692307
Fold [2/5] Epoch [0/100] Initial Loss: 0.1347, Training Loss: 0.1347, Initial Validation Loss: 0.1249, Validation Loss: 0.1249,V Acc: 0.4054, Top 70th Acc: 0.4872, Bottom 30th Acc: 0.2121
Fold [2/5] Epoch [10/100] Initial Loss: 0.1347, Training Loss: 0.0797, Initial Validation Loss: 0.1249, Validation Loss: 0.0810,V Acc: 0.6036, Top 70th Acc: 0.7308, Bottom 30th Acc: 0.3030
Stopping early at Epoch (base 0): 18  Rolling back to Epoch (base 0): 13  Top Validation Acc: 0.717948717948718
58 1 [array([0.15179364, 0.34925714, 0.15124476, 0.20726451, 0.14043988],
      dtype=float32)]
Fold [3/5] Epoch [0/100] Initial Loss: 0.1358, Training Loss: 0.1358, Initial Validation Loss: 0.1279, Validation Loss: 0.1279,V Acc: 0.4000, Top 70th Acc: 0.4286, Bottom 30th Acc: 0.3333
Fold [3/5] Epoch [10/100] Initial Loss: 0.1358, Training Loss: 0.0795, Initial Validation Loss: 0.1279, Validation Loss: 0.0854,V Acc: 0.5909, Top 70th Acc: 0.6623, Bottom 30th Acc: 0.4242
Stopping early at Epoch (base 0): 19  Rolling back to Epoch (base 0): 14  Top Validation Acc: 0.6753246753246753
Fold [4/5] Epoch [0/100] Initial Loss: 0.1356, Training Loss: 0.1356, Initial Validation Loss: 0.1296, Validation Loss: 0.1296,V Acc: 0.3273, Top 70th Acc: 0.4416, Bottom 30th Acc: 0.0606
Fold [4/5] Epoch [10/100] Initial Loss: 0.1356, Training Loss: 0.0836, Initial Validation Loss: 0.1296, Validation Loss: 0.0702,V Acc: 0.6818, Top 70th Acc: 0.8052, Bottom 30th Acc: 0.3939
Fold [4/5] Epoch [20/100] Initial Loss: 0.1356, Training Loss: 0.0823, Initial Validation Loss: 0.1296, Validation Loss: 0.0689,V Acc: 0.7091, Top 70th Acc: 0.7922, Bottom 30th Acc: 0.5152
Fold [4/5] Epoch [30/100] Initial Loss: 0.1356, Training Loss: 0.0819, Initial Validation Loss: 0.1296, Validation Loss: 0.0670,V Acc: 0.6909, Top 70th Acc: 0.8182, Bottom 30th Acc: 0.3939
Fold [4/5] Epoch [40/100] Initial Loss: 0.1356, Training Loss: 0.0815, Initial Validation Loss: 0.1296, Validation Loss: 0.0666,V Acc: 0.7000, Top 70th Acc: 0.8052, Bottom 30th Acc: 0.4545
Stopping early at Epoch (base 0): 45  Rolling back to Epoch (base 0): 40  Top Validation Acc: 0.8051948051948052
Fold [5/5] Epoch [0/100] Initial Loss: 0.1380, Training Loss: 0.1380, Initial Validation Loss: 0.1267, Validation Loss: 0.1267,V Acc: 0.3889, Top 70th Acc: 0.5263, Bottom 30th Acc: 0.0625
Fold [5/5] Epoch [10/100] Initial Loss: 0.1380, Training Loss: 0.0837, Initial Validation Loss: 0.1267, Validation Loss: 0.0769,V Acc: 0.6204, Top 70th Acc: 0.7368, Bottom 30th Acc: 0.3438
Fold [5/5] Epoch [20/100] Initial Loss: 0.1380, Training Loss: 0.0803, Initial Validation Loss: 0.1267, Validation Loss: 0.0727,V Acc: 0.6481, Top 70th Acc: 0.7632, Bottom 30th Acc: 0.3750
Fold [5/5] Epoch [30/100] Initial Loss: 0.1380, Training Loss: 0.0792, Initial Validation Loss: 0.1267, Validation Loss: 0.0719,V Acc: 0.6667, Top 70th Acc: 0.7632, Bottom 30th Acc: 0.4375
Fold [5/5] Epoch [40/100] Initial Loss: 0.1380, Training Loss: 0.0786, Initial Validation Loss: 0.1267, Validation Loss: 0.0710,V Acc: 0.6759, Top 70th Acc: 0.7632, Bottom 30th Acc: 0.4688
Fold [5/5] Epoch [50/100] Initial Loss: 0.1380, Training Loss: 0.0781, Initial Validation Loss: 0.1267, Validation Loss: 0.0711,V Acc: 0.6667, Top 70th Acc: 0.7500, Bottom 30th Acc: 0.4688
Fold [5/5] Epoch [60/100] Initial Loss: 0.1380, Training Loss: 0.0775, Initial Validation Loss: 0.1267, Validation Loss: 0.0706,V Acc: 0.6759, Top 70th Acc: 0.7632, Bottom 30th Acc: 0.4688
Fold [5/5] Epoch [70/100] Initial Loss: 0.1380, Training Loss: 0.0770, Initial Validation Loss: 0.1267, Validation Loss: 0.0715,V Acc: 0.6481, Top 70th Acc: 0.7763, Bottom 30th Acc: 0.3438
Stopping early at Epoch (base 0): 74  Rolling back to Epoch (base 0): 69  Top Validation Acc: 0.75
Running train_nn.py with seed 59
CUDA:False
Training samples count:  550
Training on 2 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1371, Training Loss: 0.1371, Initial Validation Loss: 0.1313, Validation Loss: 0.1313,V Acc: 0.4054, Top 70th Acc: 0.5128, Bottom 30th Acc: 0.1515
Fold [1/5] Epoch [10/100] Initial Loss: 0.1371, Training Loss: 0.0826, Initial Validation Loss: 0.1313, Validation Loss: 0.0750,V Acc: 0.6847, Top 70th Acc: 0.7949, Bottom 30th Acc: 0.4242
Fold [1/5] Epoch [20/100] Initial Loss: 0.1371, Training Loss: 0.0807, Initial Validation Loss: 0.1313, Validation Loss: 0.0729,V Acc: 0.6847, Top 70th Acc: 0.7949, Bottom 30th Acc: 0.4242
Fold [1/5] Epoch [30/100] Initial Loss: 0.1371, Training Loss: 0.0800, Initial Validation Loss: 0.1313, Validation Loss: 0.0723,V Acc: 0.7027, Top 70th Acc: 0.7821, Bottom 30th Acc: 0.5152
Fold [1/5] Epoch [40/100] Initial Loss: 0.1371, Training Loss: 0.0797, Initial Validation Loss: 0.1313, Validation Loss: 0.0718,V Acc: 0.6847, Top 70th Acc: 0.7949, Bottom 30th Acc: 0.4242
Stopping early at Epoch (base 0): 42  Rolling back to Epoch (base 0): 37  Top Validation Acc: 0.782051282051282
Fold [2/5] Epoch [0/100] Initial Loss: 0.1335, Training Loss: 0.1335, Initial Validation Loss: 0.1251, Validation Loss: 0.1251,V Acc: 0.4865, Top 70th Acc: 0.5256, Bottom 30th Acc: 0.3939
Fold [2/5] Epoch [10/100] Initial Loss: 0.1335, Training Loss: 0.0813, Initial Validation Loss: 0.1251, Validation Loss: 0.0785,V Acc: 0.6396, Top 70th Acc: 0.7179, Bottom 30th Acc: 0.4545
Fold [2/5] Epoch [20/100] Initial Loss: 0.1335, Training Loss: 0.0789, Initial Validation Loss: 0.1251, Validation Loss: 0.0777,V Acc: 0.6396, Top 70th Acc: 0.7179, Bottom 30th Acc: 0.4545
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.6923076923076923
Fold [3/5] Epoch [0/100] Initial Loss: 0.1310, Training Loss: 0.1310, Initial Validation Loss: 0.1191, Validation Loss: 0.1191,V Acc: 0.4818, Top 70th Acc: 0.5974, Bottom 30th Acc: 0.2121
Fold [3/5] Epoch [10/100] Initial Loss: 0.1310, Training Loss: 0.0791, Initial Validation Loss: 0.1191, Validation Loss: 0.0846,V Acc: 0.5818, Top 70th Acc: 0.6753, Bottom 30th Acc: 0.3636
Fold [3/5] Epoch [20/100] Initial Loss: 0.1310, Training Loss: 0.0767, Initial Validation Loss: 0.1191, Validation Loss: 0.0839,V Acc: 0.5909, Top 70th Acc: 0.6753, Bottom 30th Acc: 0.3939
Fold [3/5] Epoch [30/100] Initial Loss: 0.1310, Training Loss: 0.0756, Initial Validation Loss: 0.1191, Validation Loss: 0.0845,V Acc: 0.5818, Top 70th Acc: 0.6883, Bottom 30th Acc: 0.3333
Stopping early at Epoch (base 0): 30  Rolling back to Epoch (base 0): 25  Top Validation Acc: 0.6883116883116883
Fold [4/5] Epoch [0/100] Initial Loss: 0.1349, Training Loss: 0.1349, Initial Validation Loss: 0.1310, Validation Loss: 0.1310,V Acc: 0.2636, Top 70th Acc: 0.3377, Bottom 30th Acc: 0.0909
Fold [4/5] Epoch [10/100] Initial Loss: 0.1349, Training Loss: 0.0819, Initial Validation Loss: 0.1310, Validation Loss: 0.0816,V Acc: 0.6182, Top 70th Acc: 0.7532, Bottom 30th Acc: 0.3030
Fold [4/5] Epoch [20/100] Initial Loss: 0.1349, Training Loss: 0.0793, Initial Validation Loss: 0.1310, Validation Loss: 0.0777,V Acc: 0.6364, Top 70th Acc: 0.7792, Bottom 30th Acc: 0.3030
Fold [4/5] Epoch [30/100] Initial Loss: 0.1349, Training Loss: 0.0784, Initial Validation Loss: 0.1310, Validation Loss: 0.0776,V Acc: 0.6455, Top 70th Acc: 0.7922, Bottom 30th Acc: 0.3030
Fold [4/5] Epoch [40/100] Initial Loss: 0.1349, Training Loss: 0.0780, Initial Validation Loss: 0.1310, Validation Loss: 0.0769,V Acc: 0.6273, Top 70th Acc: 0.7922, Bottom 30th Acc: 0.2424
Stopping early at Epoch (base 0): 42  Rolling back to Epoch (base 0): 37  Top Validation Acc: 0.7662337662337663
Fold [4/5] Epoch [50/100] Initial Loss: 0.1401, Training Loss: 0.0041, Initial Validation Loss: 0.1327, Validation Loss: 0.0346,V Acc: 0.8182, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.5455
Fold [4/5] Epoch [60/100] Initial Loss: 0.1401, Training Loss: 0.0040, Initial Validation Loss: 0.1327, Validation Loss: 0.0332,V Acc: 0.8273, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.5455
Fold [4/5] Epoch [70/100] Initial Loss: 0.1401, Training Loss: 0.0038, Initial Validation Loss: 0.1327, Validation Loss: 0.0322,V Acc: 0.8364, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.5758
Fold [4/5] Epoch [80/100] Initial Loss: 0.1401, Training Loss: 0.0038, Initial Validation Loss: 0.1327, Validation Loss: 0.0310,V Acc: 0.8364, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.5455
Fold [4/5] Epoch [90/100] Initial Loss: 0.1401, Training Loss: 0.0037, Initial Validation Loss: 0.1327, Validation Loss: 0.0304,V Acc: 0.8364, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 93  Rolling back to Epoch (base 0): 88  Top Validation Acc: 0.961038961038961
Fold [5/5] Epoch [0/100] Initial Loss: 0.1380, Training Loss: 0.1380, Initial Validation Loss: 0.1348, Validation Loss: 0.1348,V Acc: 0.3704, Top 70th Acc: 0.3947, Bottom 30th Acc: 0.3125
Fold [5/5] Epoch [10/100] Initial Loss: 0.1380, Training Loss: 0.0245, Initial Validation Loss: 0.1348, Validation Loss: 0.0426,V Acc: 0.8241, Top 70th Acc: 0.9211, Bottom 30th Acc: 0.5938
Fold [5/5] Epoch [20/100] Initial Loss: 0.1380, Training Loss: 0.0052, Initial Validation Loss: 0.1348, Validation Loss: 0.0282,V Acc: 0.8519, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.6250
Stopping early at Epoch (base 0): 29  Rolling back to Epoch (base 0): 24  Top Validation Acc: 0.9605263157894737
Running train_nn.py with seed 47
CUDA:False
Training samples count:  550
Training on 163 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1396, Training Loss: 0.1396, Initial Validation Loss: 0.1321, Validation Loss: 0.1321,V Acc: 0.3243, Top 70th Acc: 0.3974, Bottom 30th Acc: 0.1515
Fold [1/5] Epoch [10/100] Initial Loss: 0.1396, Training Loss: 0.0131, Initial Validation Loss: 0.1321, Validation Loss: 0.0321,V Acc: 0.8468, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.6667
Fold [1/5] Epoch [20/100] Initial Loss: 0.1396, Training Loss: 0.0049, Initial Validation Loss: 0.1321, Validation Loss: 0.0290,V Acc: 0.8468, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.9358974358974359
Fold [2/5] Epoch [0/100] Initial Loss: 0.1360, Training Loss: 0.1360, Initial Validation Loss: 0.1387, Validation Loss: 0.1387,V Acc: 0.3243, Top 70th Acc: 0.4103, Bottom 30th Acc: 0.1212
Fold [2/5] Epoch [10/100] Initial Loss: 0.1360, Training Loss: 0.0132, Initial Validation Loss: 0.1387, Validation Loss: 0.0308,V Acc: 0.8829, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.6970
Fold [2/5] Epoch [20/100] Initial Loss: 0.1360, Training Loss: 0.0050, Initial Validation Loss: 0.1387, Validation Loss: 0.0262,V Acc: 0.9009, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.7273
Stopping early at Epoch (base 0): 28  Rolling back to Epoch (base 0): 23  Top Validation Acc: 0.9743589743589743
Fold [3/5] Epoch [0/100] Initial Loss: 0.1341, Training Loss: 0.1341, Initial Validation Loss: 0.1343, Validation Loss: 0.1343,V Acc: 0.3636, Top 70th Acc: 0.3766, Bottom 30th Acc: 0.3333
Fold [3/5] Epoch [10/100] Initial Loss: 0.1341, Training Loss: 0.0110, Initial Validation Loss: 0.1343, Validation Loss: 0.0300,V Acc: 0.8727, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.6364
Fold [3/5] Epoch [20/100] Initial Loss: 0.1341, Training Loss: 0.0042, Initial Validation Loss: 0.1343, Validation Loss: 0.0278,V Acc: 0.8636, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 28  Rolling back to Epoch (base 0): 23  Top Validation Acc: 0.974025974025974
Fold [4/5] Epoch [0/100] Initial Loss: 0.1382, Training Loss: 0.1382, Initial Validation Loss: 0.1307, Validation Loss: 0.1307,V Acc: 0.3636, Top 70th Acc: 0.4545, Bottom 30th Acc: 0.1515
Fold [4/5] Epoch [10/100] Initial Loss: 0.1382, Training Loss: 0.0135, Initial Validation Loss: 0.1307, Validation Loss: 0.0330,V Acc: 0.8455, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.6970
Fold [4/5] Epoch [20/100] Initial Loss: 0.1382, Training Loss: 0.0048, Initial Validation Loss: 0.1307, Validation Loss: 0.0314,V Acc: 0.8455, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.922077922077922
47 3 [array([0.17931697, 0.176954  , 0.10213175, 0.22952162, 0.31207576],
      dtype=float32)]
Fold [5/5] Epoch [0/100] Initial Loss: 0.1412, Training Loss: 0.1412, Initial Validation Loss: 0.1293, Validation Loss: 0.1293,V Acc: 0.3148, Top 70th Acc: 0.3684, Bottom 30th Acc: 0.1875
Fold [5/5] Epoch [10/100] Initial Loss: 0.1412, Training Loss: 0.0136, Initial Validation Loss: 0.1293, Validation Loss: 0.0372,V Acc: 0.8056, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.5000
Stopping early at Epoch (base 0): 16  Rolling back to Epoch (base 0): 11  Top Validation Acc: 0.9210526315789473
Running train_nn.py with seed 48
CUDA:False
Training samples count:  550
Training on 163 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1351, Training Loss: 0.1351, Initial Validation Loss: 0.1258, Validation Loss: 0.1258,V Acc: 0.4414, Top 70th Acc: 0.4872, Bottom 30th Acc: 0.3333
Fold [1/5] Epoch [10/100] Initial Loss: 0.1351, Training Loss: 0.0203, Initial Validation Loss: 0.1258, Validation Loss: 0.0380,V Acc: 0.7838, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.4545
Fold [1/5] Epoch [20/100] Initial Loss: 0.1351, Training Loss: 0.0058, Initial Validation Loss: 0.1258, Validation Loss: 0.0307,V Acc: 0.8108, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.4848
Fold [1/5] Epoch [30/100] Initial Loss: 0.1351, Training Loss: 0.0043, Initial Validation Loss: 0.1258, Validation Loss: 0.0293,V Acc: 0.8108, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.5152
Fold [1/5] Epoch [40/100] Initial Loss: 0.1351, Training Loss: 0.0040, Initial Validation Loss: 0.1258, Validation Loss: 0.0278,V Acc: 0.8198, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.5152
Fold [1/5] Epoch [50/100] Initial Loss: 0.1351, Training Loss: 0.0038, Initial Validation Loss: 0.1258, Validation Loss: 0.0264,V Acc: 0.8378, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.5758
Fold [1/5] Epoch [60/100] Initial Loss: 0.1351, Training Loss: 0.0036, Initial Validation Loss: 0.1258, Validation Loss: 0.0254,V Acc: 0.8378, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.5455
Fold [1/5] Epoch [70/100] Initial Loss: 0.1351, Training Loss: 0.0035, Initial Validation Loss: 0.1258, Validation Loss: 0.0242,V Acc: 0.8559, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.6364
Fold [1/5] Epoch [80/100] Initial Loss: 0.1351, Training Loss: 0.0034, Initial Validation Loss: 0.1258, Validation Loss: 0.0238,V Acc: 0.8559, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 86  Rolling back to Epoch (base 0): 81  Top Validation Acc: 0.9615384615384616
Fold [2/5] Epoch [0/100] Initial Loss: 0.1389, Training Loss: 0.1389, Initial Validation Loss: 0.1388, Validation Loss: 0.1388,V Acc: 0.3153, Top 70th Acc: 0.3718, Bottom 30th Acc: 0.1818
Fold [2/5] Epoch [10/100] Initial Loss: 0.1389, Training Loss: 0.0196, Initial Validation Loss: 0.1388, Validation Loss: 0.0298,V Acc: 0.9099, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.7576
Fold [2/5] Epoch [20/100] Initial Loss: 0.1389, Training Loss: 0.0054, Initial Validation Loss: 0.1388, Validation Loss: 0.0190,V Acc: 0.9459, Top 70th Acc: 0.9872, Bottom 30th Acc: 0.8485
Stopping early at Epoch (base 0): 27  Rolling back to Epoch (base 0): 22  Top Validation Acc: 0.9743589743589743
48 1 [array([0.33420113, 0.02616894, 0.06129832, 0.23956643, 0.3387652 ],
      dtype=float32)]
Fold [3/5] Epoch [0/100] Initial Loss: 0.1373, Training Loss: 0.1373, Initial Validation Loss: 0.1334, Validation Loss: 0.1334,V Acc: 0.2545, Top 70th Acc: 0.3377, Bottom 30th Acc: 0.0606
Fold [3/5] Epoch [10/100] Initial Loss: 0.1373, Training Loss: 0.0129, Initial Validation Loss: 0.1334, Validation Loss: 0.0333,V Acc: 0.8727, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.7273
Stopping early at Epoch (base 0): 20  Rolling back to Epoch (base 0): 15  Top Validation Acc: 0.948051948051948
Fold [4/5] Epoch [0/100] Initial Loss: 0.1326, Training Loss: 0.1326, Initial Validation Loss: 0.1222, Validation Loss: 0.1222,V Acc: 0.4636, Top 70th Acc: 0.5195, Bottom 30th Acc: 0.3333
Fold [4/5] Epoch [10/100] Initial Loss: 0.1326, Training Loss: 0.0260, Initial Validation Loss: 0.1222, Validation Loss: 0.0355,V Acc: 0.8182, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.5152
Stopping early at Epoch (base 0): 17  Rolling back to Epoch (base 0): 12  Top Validation Acc: 0.922077922077922
Fold [5/5] Epoch [0/100] Initial Loss: 0.1344, Training Loss: 0.1344, Initial Validation Loss: 0.1249, Validation Loss: 0.1249,V Acc: 0.4352, Top 70th Acc: 0.5132, Bottom 30th Acc: 0.2500
Fold [5/5] Epoch [10/100] Initial Loss: 0.1344, Training Loss: 0.0269, Initial Validation Loss: 0.1249, Validation Loss: 0.0293,V Acc: 0.8426, Top 70th Acc: 0.9737, Bottom 30th Acc: 0.5312
Fold [5/5] Epoch [20/100] Initial Loss: 0.1344, Training Loss: 0.0179, Initial Validation Loss: 0.1249, Validation Loss: 0.0237,V Acc: 0.8704, Top 70th Acc: 0.9737, Bottom 30th Acc: 0.6250
Stopping early at Epoch (base 0): 22  Rolling back to Epoch (base 0): 17  Top Validation Acc: 0.9605263157894737
86 4 [array([0.7098108 , 0.01392341, 0.04387993, 0.10910696, 0.12327886],
      dtype=float32)]
Running train_nn.py with seed 87
CUDA:False
Training samples count:  550
Training on 21 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1365, Training Loss: 0.1365, Initial Validation Loss: 0.1315, Validation Loss: 0.1315,V Acc: 0.3784, Top 70th Acc: 0.4872, Bottom 30th Acc: 0.1212
Fold [1/5] Epoch [10/100] Initial Loss: 0.1365, Training Loss: 0.0232, Initial Validation Loss: 0.1315, Validation Loss: 0.0369,V Acc: 0.8378, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.5758
Fold [1/5] Epoch [20/100] Initial Loss: 0.1365, Training Loss: 0.0162, Initial Validation Loss: 0.1315, Validation Loss: 0.0305,V Acc: 0.8378, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.5152
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.9615384615384616
Fold [2/5] Epoch [0/100] Initial Loss: 0.1316, Training Loss: 0.1316, Initial Validation Loss: 0.1179, Validation Loss: 0.1179,V Acc: 0.5405, Top 70th Acc: 0.6410, Bottom 30th Acc: 0.3030
Fold [2/5] Epoch [10/100] Initial Loss: 0.1316, Training Loss: 0.0211, Initial Validation Loss: 0.1179, Validation Loss: 0.0355,V Acc: 0.8559, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.6667
Fold [2/5] Epoch [20/100] Initial Loss: 0.1316, Training Loss: 0.0158, Initial Validation Loss: 0.1179, Validation Loss: 0.0363,V Acc: 0.8198, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.9102564102564102
Fold [3/5] Epoch [0/100] Initial Loss: 0.1340, Training Loss: 0.1340, Initial Validation Loss: 0.1226, Validation Loss: 0.1226,V Acc: 0.5727, Top 70th Acc: 0.6753, Bottom 30th Acc: 0.3333
Fold [3/5] Epoch [10/100] Initial Loss: 0.1340, Training Loss: 0.0323, Initial Validation Loss: 0.1226, Validation Loss: 0.0380,V Acc: 0.8182, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.5455
Fold [3/5] Epoch [20/100] Initial Loss: 0.1340, Training Loss: 0.0193, Initial Validation Loss: 0.1226, Validation Loss: 0.0280,V Acc: 0.8455, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 29  Rolling back to Epoch (base 0): 24  Top Validation Acc: 0.974025974025974
Fold [4/5] Epoch [0/100] Initial Loss: 0.1334, Training Loss: 0.1334, Initial Validation Loss: 0.1189, Validation Loss: 0.1189,V Acc: 0.5000, Top 70th Acc: 0.6364, Bottom 30th Acc: 0.1818
Fold [4/5] Epoch [10/100] Initial Loss: 0.1334, Training Loss: 0.0257, Initial Validation Loss: 0.1189, Validation Loss: 0.0213,V Acc: 0.9273, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.8182
Fold [4/5] Epoch [20/100] Initial Loss: 0.1334, Training Loss: 0.0186, Initial Validation Loss: 0.1189, Validation Loss: 0.0204,V Acc: 0.8818, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.987012987012987
Fold [5/5] Epoch [0/100] Initial Loss: 0.1356, Training Loss: 0.1356, Initial Validation Loss: 0.1186, Validation Loss: 0.1186,V Acc: 0.5741, Top 70th Acc: 0.6711, Bottom 30th Acc: 0.3438
Fold [5/5] Epoch [10/100] Initial Loss: 0.1356, Training Loss: 0.0233, Initial Validation Loss: 0.1186, Validation Loss: 0.0212,V Acc: 0.9167, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.8125
Stopping early at Epoch (base 0): 19  Rolling back to Epoch (base 0): 14  Top Validation Acc: 0.9605263157894737
87 4 [array([0.74100643, 0.02934172, 0.02241757, 0.09027495, 0.11695934],
      dtype=float32)]
Running train_nn.py with seed 88
CUDA:False
Training samples count:  550
Training on 21 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1289, Training Loss: 0.1289, Initial Validation Loss: 0.1108, Validation Loss: 0.1108,V Acc: 0.6216, Top 70th Acc: 0.7821, Bottom 30th Acc: 0.2424
Fold [1/5] Epoch [10/100] Initial Loss: 0.1289, Training Loss: 0.0256, Initial Validation Loss: 0.1108, Validation Loss: 0.0302,V Acc: 0.8739, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.6970
Fold [1/5] Epoch [20/100] Initial Loss: 0.1289, Training Loss: 0.0186, Initial Validation Loss: 0.1108, Validation Loss: 0.0339,V Acc: 0.8559, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 22  Rolling back to Epoch (base 0): 17  Top Validation Acc: 0.9358974358974359
Fold [2/5] Epoch [0/100] Initial Loss: 0.1386, Training Loss: 0.1386, Initial Validation Loss: 0.1320, Validation Loss: 0.1320,V Acc: 0.3784, Top 70th Acc: 0.4487, Bottom 30th Acc: 0.2121
Fold [2/5] Epoch [10/100] Initial Loss: 0.1386, Training Loss: 0.0321, Initial Validation Loss: 0.1320, Validation Loss: 0.0367,V Acc: 0.8378, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.6061
Fold [2/5] Epoch [20/100] Initial Loss: 0.1386, Training Loss: 0.0204, Initial Validation Loss: 0.1320, Validation Loss: 0.0343,V Acc: 0.8559, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 22  Rolling back to Epoch (base 0): 17  Top Validation Acc: 0.9615384615384616
Fold [3/5] Epoch [0/100] Initial Loss: 0.1382, Training Loss: 0.1382, Initial Validation Loss: 0.1291, Validation Loss: 0.1291,V Acc: 0.3636, Top 70th Acc: 0.4545, Bottom 30th Acc: 0.1515
Fold [3/5] Epoch [10/100] Initial Loss: 0.1382, Training Loss: 0.0237, Initial Validation Loss: 0.1291, Validation Loss: 0.0369,V Acc: 0.8182, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 19  Rolling back to Epoch (base 0): 14  Top Validation Acc: 0.961038961038961
88 2 [array([0.6609918 , 0.01671946, 0.03386563, 0.12177369, 0.16664936],
      dtype=float32)]
Fold [4/5] Epoch [0/100] Initial Loss: 0.1334, Training Loss: 0.1334, Initial Validation Loss: 0.1186, Validation Loss: 0.1186,V Acc: 0.5273, Top 70th Acc: 0.6104, Bottom 30th Acc: 0.3333
Fold [4/5] Epoch [10/100] Initial Loss: 0.1334, Training Loss: 0.0263, Initial Validation Loss: 0.1186, Validation Loss: 0.0287,V Acc: 0.8091, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.4242
Fold [4/5] Epoch [20/100] Initial Loss: 0.1334, Training Loss: 0.0184, Initial Validation Loss: 0.1186, Validation Loss: 0.0243,V Acc: 0.8455, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.5455
Fold [4/5] Epoch [30/100] Initial Loss: 0.1334, Training Loss: 0.0163, Initial Validation Loss: 0.1186, Validation Loss: 0.0244,V Acc: 0.8545, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 30  Rolling back to Epoch (base 0): 25  Top Validation Acc: 0.961038961038961
Fold [5/5] Epoch [0/100] Initial Loss: 0.1321, Training Loss: 0.1321, Initial Validation Loss: 0.1192, Validation Loss: 0.1192,V Acc: 0.4537, Top 70th Acc: 0.5526, Bottom 30th Acc: 0.2188
Fold [5/5] Epoch [10/100] Initial Loss: 0.1321, Training Loss: 0.0264, Initial Validation Loss: 0.1192, Validation Loss: 0.0340,V Acc: 0.8796, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.7188
Stopping early at Epoch (base 0): 18  Rolling back to Epoch (base 0): 13  Top Validation Acc: 0.9605263157894737
Running train_nn.py with seed 89
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.922077922077922
Fold [4/5] Epoch [0/100] Initial Loss: 0.1360, Training Loss: 0.1360, Initial Validation Loss: 0.1342, Validation Loss: 0.1342,V Acc: 0.2909, Top 70th Acc: 0.3636, Bottom 30th Acc: 0.1212
Fold [4/5] Epoch [10/100] Initial Loss: 0.1360, Training Loss: 0.0429, Initial Validation Loss: 0.1342, Validation Loss: 0.0407,V Acc: 0.8091, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.5152
Fold [4/5] Epoch [20/100] Initial Loss: 0.1360, Training Loss: 0.0206, Initial Validation Loss: 0.1342, Validation Loss: 0.0243,V Acc: 0.9091, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.7576
Fold [4/5] Epoch [30/100] Initial Loss: 0.1360, Training Loss: 0.0173, Initial Validation Loss: 0.1342, Validation Loss: 0.0233,V Acc: 0.8818, Top 70th Acc: 0.9870, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 34  Rolling back to Epoch (base 0): 29  Top Validation Acc: 0.974025974025974
Fold [5/5] Epoch [0/100] Initial Loss: 0.1390, Training Loss: 0.1390, Initial Validation Loss: 0.1302, Validation Loss: 0.1302,V Acc: 0.2963, Top 70th Acc: 0.3289, Bottom 30th Acc: 0.2188
Fold [5/5] Epoch [10/100] Initial Loss: 0.1390, Training Loss: 0.0266, Initial Validation Loss: 0.1302, Validation Loss: 0.0371,V Acc: 0.8056, Top 70th Acc: 0.9211, Bottom 30th Acc: 0.5312
Fold [5/5] Epoch [20/100] Initial Loss: 0.1390, Training Loss: 0.0169, Initial Validation Loss: 0.1302, Validation Loss: 0.0357,V Acc: 0.7870, Top 70th Acc: 0.9211, Bottom 30th Acc: 0.4688
Stopping early at Epoch (base 0): 20  Rolling back to Epoch (base 0): 15  Top Validation Acc: 0.9210526315789473
61 4 [array([0.5711194 , 0.09520633, 0.06642023, 0.05346825, 0.2137857 ],
      dtype=float32)]
Running train_nn.py with seed 62
CUDA:False
Training samples count:  550
Training on 30 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1361, Training Loss: 0.1361, Initial Validation Loss: 0.1324, Validation Loss: 0.1324,V Acc: 0.3153, Top 70th Acc: 0.3718, Bottom 30th Acc: 0.1818
Fold [1/5] Epoch [10/100] Initial Loss: 0.1361, Training Loss: 0.0313, Initial Validation Loss: 0.1324, Validation Loss: 0.0448,V Acc: 0.7658, Top 70th Acc: 0.8846, Bottom 30th Acc: 0.4848
Fold [1/5] Epoch [20/100] Initial Loss: 0.1361, Training Loss: 0.0181, Initial Validation Loss: 0.1324, Validation Loss: 0.0381,V Acc: 0.7928, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.4545
Stopping early at Epoch (base 0): 29  Rolling back to Epoch (base 0): 24  Top Validation Acc: 0.9230769230769231
Fold [2/5] Epoch [0/100] Initial Loss: 0.1370, Training Loss: 0.1370, Initial Validation Loss: 0.1307, Validation Loss: 0.1307,V Acc: 0.4324, Top 70th Acc: 0.5000, Bottom 30th Acc: 0.2727
Fold [2/5] Epoch [10/100] Initial Loss: 0.1370, Training Loss: 0.0430, Initial Validation Loss: 0.1307, Validation Loss: 0.0418,V Acc: 0.7748, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.4545
Fold [2/5] Epoch [20/100] Initial Loss: 0.1370, Training Loss: 0.0194, Initial Validation Loss: 0.1307, Validation Loss: 0.0297,V Acc: 0.8378, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.9487179487179487
62 1 [array([0.76133174, 0.03698768, 0.04343704, 0.09340908, 0.06483436],
      dtype=float32)]
Fold [3/5] Epoch [0/100] Initial Loss: 0.1360, Training Loss: 0.1360, Initial Validation Loss: 0.1341, Validation Loss: 0.1341,V Acc: 0.2727, Top 70th Acc: 0.3377, Bottom 30th Acc: 0.1212
Fold [3/5] Epoch [10/100] Initial Loss: 0.1360, Training Loss: 0.0354, Initial Validation Loss: 0.1341, Validation Loss: 0.0476,V Acc: 0.7545, Top 70th Acc: 0.8831, Bottom 30th Acc: 0.4545
Fold [3/5] Epoch [20/100] Initial Loss: 0.1360, Training Loss: 0.0189, Initial Validation Loss: 0.1341, Validation Loss: 0.0350,V Acc: 0.8364, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.5758
Fold [3/5] Epoch [30/100] Initial Loss: 0.1360, Training Loss: 0.0166, Initial Validation Loss: 0.1341, Validation Loss: 0.0333,V Acc: 0.8455, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 35  Rolling back to Epoch (base 0): 30  Top Validation Acc: 0.935064935064935
Fold [4/5] Epoch [0/100] Initial Loss: 0.1371, Training Loss: 0.1371, Initial Validation Loss: 0.1285, Validation Loss: 0.1285,V Acc: 0.3727, Top 70th Acc: 0.4545, Bottom 30th Acc: 0.1818
Fold [4/5] Epoch [10/100] Initial Loss: 0.1371, Training Loss: 0.0354, Initial Validation Loss: 0.1285, Validation Loss: 0.0496,V Acc: 0.7273, Top 70th Acc: 0.8571, Bottom 30th Acc: 0.4242
Fold [4/5] Epoch [20/100] Initial Loss: 0.1371, Training Loss: 0.0224, Initial Validation Loss: 0.1285, Validation Loss: 0.0452,V Acc: 0.7545, Top 70th Acc: 0.8701, Bottom 30th Acc: 0.4848
Fold [4/5] Epoch [30/100] Initial Loss: 0.1371, Training Loss: 0.0173, Initial Validation Loss: 0.1285, Validation Loss: 0.0416,V Acc: 0.7727, Top 70th Acc: 0.8961, Bottom 30th Acc: 0.4848
Fold [4/5] Epoch [40/100] Initial Loss: 0.1371, Training Loss: 0.0149, Initial Validation Loss: 0.1285, Validation Loss: 0.0387,V Acc: 0.7818, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.4545
Stopping early at Epoch (base 0): 44  Rolling back to Epoch (base 0): 39  Top Validation Acc: 0.922077922077922
Fold [5/5] Epoch [0/100] Initial Loss: 0.1382, Training Loss: 0.1382, Initial Validation Loss: 0.1350, Validation Loss: 0.1350,V Acc: 0.2963, Top 70th Acc: 0.3026, Bottom 30th Acc: 0.2812
Fold [5/5] Epoch [10/100] Initial Loss: 0.1382, Training Loss: 0.0297, Initial Validation Loss: 0.1350, Validation Loss: 0.0294,V Acc: 0.8796, Top 70th Acc: 0.9868, Bottom 30th Acc: 0.6250
Fold [5/5] Epoch [20/100] Initial Loss: 0.1382, Training Loss: 0.0195, Initial Validation Loss: 0.1350, Validation Loss: 0.0237,V Acc: 0.8889, Top 70th Acc: 1.0000, Bottom 30th Acc: 0.6250
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.9868421052631579
Running train_nn.py with seed 63
CUDA:False
Training samples count:  550
Training on 30 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1374, Training Loss: 0.1374, Initial Validation Loss: 0.1368, Validation Loss: 0.1368,V Acc: 0.2793, Top 70th Acc: 0.3333, Bottom 30th Acc: 0.1515
Fold [1/5] Epoch [10/100] Initial Loss: 0.1374, Training Loss: 0.0372, Initial Validation Loss: 0.1368, Validation Loss: 0.0405,V Acc: 0.8378, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.5758
Fold [1/5] Epoch [20/100] Initial Loss: 0.1374, Training Loss: 0.0218, Initial Validation Loss: 0.1368, Validation Loss: 0.0251,V Acc: 0.9099, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.7576
Fold [1/5] Epoch [30/100] Initial Loss: 0.1374, Training Loss: 0.0187, Initial Validation Loss: 0.1368, Validation Loss: 0.0229,V Acc: 0.9189, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.7879
Stopping early at Epoch (base 0): 34  Rolling back to Epoch (base 0): 29  Top Validation Acc: 0.9743589743589743
Fold [2/5] Epoch [0/100] Initial Loss: 0.1414, Training Loss: 0.1414, Initial Validation Loss: 0.1316, Validation Loss: 0.1316,V Acc: 0.2523, Top 70th Acc: 0.2949, Bottom 30th Acc: 0.1515
Fold [2/5] Epoch [10/100] Initial Loss: 0.1414, Training Loss: 0.0401, Initial Validation Loss: 0.1316, Validation Loss: 0.0426,V Acc: 0.7838, Top 70th Acc: 0.8974, Bottom 30th Acc: 0.5152
Fold [2/5] Epoch [20/100] Initial Loss: 0.1414, Training Loss: 0.0206, Initial Validation Loss: 0.1316, Validation Loss: 0.0355,V Acc: 0.8108, Top 70th Acc: 0.8974, Bottom 30th Acc: 0.6061
Fold [2/5] Epoch [30/100] Initial Loss: 0.1414, Training Loss: 0.0168, Initial Validation Loss: 0.1316, Validation Loss: 0.0346,V Acc: 0.7928, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.5152
Stopping early at Epoch (base 0): 37  Rolling back to Epoch (base 0): 32  Top Validation Acc: 0.8974358974358975
Fold [3/5] Epoch [0/100] Initial Loss: 0.1399, Training Loss: 0.1399, Initial Validation Loss: 0.1330, Validation Loss: 0.1330,V Acc: 0.2636, Top 70th Acc: 0.3247, Bottom 30th Acc: 0.1212
Fold [3/5] Epoch [10/100] Initial Loss: 0.1399, Training Loss: 0.0352, Initial Validation Loss: 0.1330, Validation Loss: 0.0429,V Acc: 0.8091, Top 70th Acc: 0.8701, Bottom 30th Acc: 0.6667
Fold [3/5] Epoch [20/100] Initial Loss: 0.1399, Training Loss: 0.0208, Initial Validation Loss: 0.1330, Validation Loss: 0.0385,V Acc: 0.7909, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.4848 0.9078947368421053
61 4 [array([0.39429605, 0.09482446, 0.09232458, 0.08408387, 0.3344711 ],
      dtype=float32)]
Running train_nn.py with seed 62
CUDA:False
Training samples count:  550
Training on 39 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1439, Training Loss: 0.1439, Initial Validation Loss: 0.1375, Validation Loss: 0.1375,V Acc: 0.2252, Top 70th Acc: 0.2692, Bottom 30th Acc: 0.1212
Fold [1/5] Epoch [10/100] Initial Loss: 0.1439, Training Loss: 0.0588, Initial Validation Loss: 0.1375, Validation Loss: 0.0691,V Acc: 0.7207, Top 70th Acc: 0.7821, Bottom 30th Acc: 0.5758
Fold [1/5] Epoch [20/100] Initial Loss: 0.1439, Training Loss: 0.0351, Initial Validation Loss: 0.1375, Validation Loss: 0.0657,V Acc: 0.7207, Top 70th Acc: 0.7692, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 22  Rolling back to Epoch (base 0): 17  Top Validation Acc: 0.782051282051282
Fold [2/5] Epoch [0/100] Initial Loss: 0.1386, Training Loss: 0.1386, Initial Validation Loss: 0.1321, Validation Loss: 0.1321,V Acc: 0.3694, Top 70th Acc: 0.4615, Bottom 30th Acc: 0.1515
Fold [2/5] Epoch [10/100] Initial Loss: 0.1386, Training Loss: 0.0643, Initial Validation Loss: 0.1321, Validation Loss: 0.0662,V Acc: 0.7117, Top 70th Acc: 0.8205, Bottom 30th Acc: 0.4545
Fold [2/5] Epoch [20/100] Initial Loss: 0.1386, Training Loss: 0.0424, Initial Validation Loss: 0.1321, Validation Loss: 0.0536,V Acc: 0.7027, Top 70th Acc: 0.8590, Bottom 30th Acc: 0.3333
Fold [2/5] Epoch [30/100] Initial Loss: 0.1386, Training Loss: 0.0345, Initial Validation Loss: 0.1321, Validation Loss: 0.0486,V Acc: 0.7207, Top 70th Acc: 0.8590, Bottom 30th Acc: 0.3939
Stopping early at Epoch (base 0): 36  Rolling back to Epoch (base 0): 31  Top Validation Acc: 0.8589743589743589
62 1 [array([0.22782311, 0.03825911, 0.11756562, 0.10977121, 0.5065809 ],
      dtype=float32)]
Fold [3/5] Epoch [0/100] Initial Loss: 0.1388, Training Loss: 0.1388, Initial Validation Loss: 0.1383, Validation Loss: 0.1383,V Acc: 0.2545, Top 70th Acc: 0.2208, Bottom 30th Acc: 0.3333
Fold [3/5] Epoch [10/100] Initial Loss: 0.1388, Training Loss: 0.0545, Initial Validation Loss: 0.1383, Validation Loss: 0.0700,V Acc: 0.7182, Top 70th Acc: 0.7922, Bottom 30th Acc: 0.5455
Fold [3/5] Epoch [20/100] Initial Loss: 0.1388, Training Loss: 0.0337, Initial Validation Loss: 0.1383, Validation Loss: 0.0590,V Acc: 0.7636, Top 70th Acc: 0.8442, Bottom 30th Acc: 0.5758
Fold [3/5] Epoch [30/100] Initial Loss: 0.1388, Training Loss: 0.0251, Initial Validation Loss: 0.1383, Validation Loss: 0.0570,V Acc: 0.7455, Top 70th Acc: 0.8701, Bottom 30th Acc: 0.4545
Stopping early at Epoch (base 0): 38  Rolling back to Epoch (base 0): 33  Top Validation Acc: 0.8961038961038961
Fold [4/5] Epoch [0/100] Initial Loss: 0.1363, Training Loss: 0.1363, Initial Validation Loss: 0.1280, Validation Loss: 0.1280,V Acc: 0.3727, Top 70th Acc: 0.4156, Bottom 30th Acc: 0.2727
Fold [4/5] Epoch [10/100] Initial Loss: 0.1363, Training Loss: 0.0512, Initial Validation Loss: 0.1280, Validation Loss: 0.0650,V Acc: 0.6545, Top 70th Acc: 0.8052, Bottom 30th Acc: 0.3030
Stopping early at Epoch (base 0): 19  Rolling back to Epoch (base 0): 14  Top Validation Acc: 0.8051948051948052
Fold [5/5] Epoch [0/100] Initial Loss: 0.1383, Training Loss: 0.1383, Initial Validation Loss: 0.1376, Validation Loss: 0.1376,V Acc: 0.2222, Top 70th Acc: 0.1974, Bottom 30th Acc: 0.2812
Fold [5/5] Epoch [10/100] Initial Loss: 0.1383, Training Loss: 0.0606, Initial Validation Loss: 0.1376, Validation Loss: 0.0550,V Acc: 0.8241, Top 70th Acc: 0.8816, Bottom 30th Acc: 0.6875
Fold [5/5] Epoch [20/100] Initial Loss: 0.1383, Training Loss: 0.0370, Initial Validation Loss: 0.1376, Validation Loss: 0.0417,V Acc: 0.8519, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.6562
Stopping early at Epoch (base 0): 29  Rolling back to Epoch (base 0): 24  Top Validation Acc: 0.9342105263157895
Running train_nn.py with seed 63
CUDA:False
Training samples count:  550
Training on 40 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1385, Training Loss: 0.1385, Initial Validation Loss: 0.1389, Validation Loss: 0.1389,V Acc: 0.2613, Top 70th Acc: 0.2179, Bottom 30th Acc: 0.3636
Fold [1/5] Epoch [10/100] Initial Loss: 0.1385, Training Loss: 0.0332, Initial Validation Loss: 0.1389, Validation Loss: 0.0410,V Acc: 0.8108, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.5455
Fold [1/5] Epoch [20/100] Initial Loss: 0.1385, Training Loss: 0.0157, Initial Validation Loss: 0.1389, Validation Loss: 0.0250,V Acc: 0.8829, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.6970
Fold [1/5] Epoch [30/100] Initial Loss: 0.1385, Training Loss: 0.0132, Initial Validation Loss: 0.1389, Validation Loss: 0.0235,V Acc: 0.9189, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.7879
Stopping early at Epoch (base 0): 38  Rolling back to Epoch (base 0): 33  Top Validation Acc: 0.9615384615384616
Fold [2/5] Epoch [0/100] Initial Loss: 0.1388, Training Loss: 0.1388, Initial Validation Loss: 0.1295, Validation Loss: 0.1295,V Acc: 0.2613, Top 70th Acc: 0.3205, Bottom 30th Acc: 0.1212
Fold [2/5] Epoch [10/100] Initial Loss: 0.1388, Training Loss: 0.0259, Initial Validation Loss: 0.1295, Validation Loss: 0.0339,V Acc: 0.8198, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.4848
Fold [2/5] Epoch [20/100] Initial Loss: 0.1388, Training Loss: 0.0150, Initial Validation Loss: 0.1295, Validation Loss: 0.0278,V Acc: 0.8559, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.6061
Fold [2/5] Epoch [30/100] Initial Loss: 0.1388, Training Loss: 0.0122, Initial Validation Loss: 0.1295, Validation Loss: 0.0269,V Acc: 0.8559, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 35  Rolling back to Epoch (base 0): 30  Top Validation Acc: 0.9615384615384616
Fold [3/5] Epoch [0/100] Initial Loss: 0.1361, Training Loss: 0.1361, Initial Validation Loss: 0.1311, Validation Loss: 0.1311,V Acc: 0.4091, Top 70th Acc: 0.4545, Bottom 30th Acc: 0.3030
Fold [3/5] Epoch [10/100] Initial Loss: 0.1361, Training Loss: 0.0395, Initial Validation Loss: 0.1311, Validation Loss: 0.0460,V Acc: 0.7727, Top 70th Acc: 0.8831, Bottom 30th Acc: 0.5152
Fold [3/5] Epoch [20/100] Initial Loss: 0.1361, Training Loss: 0.0146, Initial Validation Loss: 0.1311, Validation Loss: 0.0322,V Acc: 0.8364, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 29  Rolling back to Epoch (base 0): 24  Top Validation Acc: 0.948051948051948
63 2 [array([0.5324545 , 0.07805602, 0.05026376, 0.15324533, 0.18598035],
      dtype=float32)]
Fold [4/5] Epoch [0/100] Initial Loss: 0.1427, Training Loss: 0.1427, Initial Validation Loss: 0.1362, Validation Loss: 0.1362,V Acc: 0.3909, Top 70th Acc: 0.4416, Bottom 30th Acc: 0.2727
Fold [4/5] Epoch [10/100] Initial Loss: 0.1427, Training Loss: 0.0363, Initial Validation Loss: 0.1362, Validation Loss: 0.0506,V Acc: 0.7455, Top 70th Acc: 0.8701, Bottom 30th Acc: 0.4545
Fold [4/5] Epoch [20/100] Initial Loss: 0.1427, Training Loss: 0.0151, Initial Validation Loss: 0.1362, Validation Loss: 0.0415,V Acc: 0.7818, Top 70th Acc: 0.8961, Bottom 30th Acc: 0.5152
Stopping early at Epoch (base 0): 27  Rolling back to Epoch (base 0): 22  Top Validation Acc: 0.9090909090909091
Fold [5/5] Epoch [0/100] Initial Loss: 0.1373, Training Loss: 0.1373, Initial Validation Loss: 0.1341, Validation Loss: 0.1341,V Acc: 0.3056, Top 70th Acc: 0.3816, Bottom 30th Acc: 0.1250
Fold [5/5] Epoch [10/100] Initial Loss: 0.1373, Training Loss: 0.0268, Initial Validation Loss: 0.1341, Validation Loss: 0.0345,V Acc: 0.8519, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.6250
Fold [5/5] Epoch [20/100] Initial Loss: 0.1373, Training Loss: 0.0123, Initial Validation Loss: 0.1341, Validation Loss: 0.0295,V Acc: 0.8241, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.5000
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.9605263157894737
Running train_nn.py with seed 64
CUDA:False
Training samples count:  550
Training on 40 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1412, Training Loss: 0.1412, Initial Validation Loss: 0.1360, Validation Loss: 0.1360,V Acc: 0.2883, Top 70th Acc: 0.3333, Bottom 30th Acc: 0.1818
Fold [1/5] Epoch [10/100] Initial Loss: 0.1412, Training Loss: 0.0360, Initial Validation Loss: 0.1360, Validation Loss: 0.0480,V Acc: 0.8108, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.5758  Top Validation Acc: 0.8831168831168831
Fold [5/5] Epoch [0/100] Initial Loss: 0.1393, Training Loss: 0.1393, Initial Validation Loss: 0.1331, Validation Loss: 0.1331,V Acc: 0.3241, Top 70th Acc: 0.3684, Bottom 30th Acc: 0.2188
Fold [5/5] Epoch [10/100] Initial Loss: 0.1393, Training Loss: 0.0463, Initial Validation Loss: 0.1331, Validation Loss: 0.0507,V Acc: 0.7037, Top 70th Acc: 0.8816, Bottom 30th Acc: 0.2812
Fold [5/5] Epoch [20/100] Initial Loss: 0.1393, Training Loss: 0.0241, Initial Validation Loss: 0.1331, Validation Loss: 0.0318,V Acc: 0.8333, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.5312
Fold [5/5] Epoch [30/100] Initial Loss: 0.1393, Training Loss: 0.0206, Initial Validation Loss: 0.1331, Validation Loss: 0.0303,V Acc: 0.8426, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.5938
Stopping early at Epoch (base 0): 32  Rolling back to Epoch (base 0): 27  Top Validation Acc: 0.9473684210526315
Running train_nn.py with seed 64
CUDA:False
Training samples count:  550
Training on 20 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1412, Training Loss: 0.1412, Initial Validation Loss: 0.1369, Validation Loss: 0.1369,V Acc: 0.2883, Top 70th Acc: 0.3333, Bottom 30th Acc: 0.1818
Fold [1/5] Epoch [10/100] Initial Loss: 0.1412, Training Loss: 0.0459, Initial Validation Loss: 0.1369, Validation Loss: 0.0573,V Acc: 0.7387, Top 70th Acc: 0.8462, Bottom 30th Acc: 0.4848
Fold [1/5] Epoch [20/100] Initial Loss: 0.1412, Training Loss: 0.0252, Initial Validation Loss: 0.1369, Validation Loss: 0.0352,V Acc: 0.8198, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.9487179487179487
Fold [2/5] Epoch [0/100] Initial Loss: 0.1383, Training Loss: 0.1383, Initial Validation Loss: 0.1324, Validation Loss: 0.1324,V Acc: 0.2523, Top 70th Acc: 0.3462, Bottom 30th Acc: 0.0303
Fold [2/5] Epoch [10/100] Initial Loss: 0.1383, Training Loss: 0.0309, Initial Validation Loss: 0.1324, Validation Loss: 0.0353,V Acc: 0.8468, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 18  Rolling back to Epoch (base 0): 13  Top Validation Acc: 0.9230769230769231
Fold [3/5] Epoch [0/100] Initial Loss: 0.1383, Training Loss: 0.1383, Initial Validation Loss: 0.1345, Validation Loss: 0.1345,V Acc: 0.2273, Top 70th Acc: 0.2468, Bottom 30th Acc: 0.1818
Fold [3/5] Epoch [10/100] Initial Loss: 0.1383, Training Loss: 0.0338, Initial Validation Loss: 0.1345, Validation Loss: 0.0273,V Acc: 0.8727, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.6667
Fold [3/5] Epoch [20/100] Initial Loss: 0.1383, Training Loss: 0.0238, Initial Validation Loss: 0.1345, Validation Loss: 0.0250,V Acc: 0.8818, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.6667
Fold [3/5] Epoch [30/100] Initial Loss: 0.1383, Training Loss: 0.0221, Initial Validation Loss: 0.1345, Validation Loss: 0.0245,V Acc: 0.8727, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 31  Rolling back to Epoch (base 0): 26  Top Validation Acc: 0.961038961038961
Fold [4/5] Epoch [0/100] Initial Loss: 0.1387, Training Loss: 0.1387, Initial Validation Loss: 0.1350, Validation Loss: 0.1350,V Acc: 0.2727, Top 70th Acc: 0.2597, Bottom 30th Acc: 0.3030
Fold [4/5] Epoch [10/100] Initial Loss: 0.1387, Training Loss: 0.0419, Initial Validation Loss: 0.1350, Validation Loss: 0.0413,V Acc: 0.8273, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.6061
Fold [4/5] Epoch [20/100] Initial Loss: 0.1387, Training Loss: 0.0241, Initial Validation Loss: 0.1350, Validation Loss: 0.0300,V Acc: 0.8818, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.6970
Fold [4/5] Epoch [30/100] Initial Loss: 0.1387, Training Loss: 0.0211, Initial Validation Loss: 0.1350, Validation Loss: 0.0278,V Acc: 0.8727, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 34  Rolling back to Epoch (base 0): 29  Top Validation Acc: 0.948051948051948
64 3 [array([0.31926778, 0.07728174, 0.22965427, 0.24069121, 0.13310489],
      dtype=float32)]
Fold [5/5] Epoch [0/100] Initial Loss: 0.1386, Training Loss: 0.1386, Initial Validation Loss: 0.1303, Validation Loss: 0.1303,V Acc: 0.3981, Top 70th Acc: 0.4868, Bottom 30th Acc: 0.1875
Fold [5/5] Epoch [10/100] Initial Loss: 0.1386, Training Loss: 0.0371, Initial Validation Loss: 0.1303, Validation Loss: 0.0506,V Acc: 0.7500, Top 70th Acc: 0.8421, Bottom 30th Acc: 0.5312
Fold [5/5] Epoch [20/100] Initial Loss: 0.1386, Training Loss: 0.0204, Initial Validation Loss: 0.1303, Validation Loss: 0.0412,V Acc: 0.8056, Top 70th Acc: 0.8816, Bottom 30th Acc: 0.6250
Fold [5/5] Epoch [30/100] Initial Loss: 0.1386, Training Loss: 0.0177, Initial Validation Loss: 0.1303, Validation Loss: 0.0405,V Acc: 0.7778, Top 70th Acc: 0.8816, Bottom 30th Acc: 0.5312
Stopping early at Epoch (base 0): 32  Rolling back to Epoch (base 0): 27  Top Validation Acc: 0.868421052631579
Running train_nn.py with seed 65
CUDA:False
Training samples count:  550
Training on 20 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1391, Training Loss: 0.1391, Initial Validation Loss: 0.1370, Validation Loss: 0.1370,V Acc: 0.3333, Top 70th Acc: 0.3333, Bottom 30th Acc: 0.3333
Fold [1/5] Epoch [10/100] Initial Loss: 0.1391, Training Loss: 0.0484, Initial Validation Loss: 0.1370, Validation Loss: 0.0570,V Acc: 0.7568, Top 70th Acc: 0.8333, Bottom 30th Acc: 0.5758
Fold [1/5] Epoch [20/100] Initial Loss: 0.1391, Training Loss: 0.0236, Initial Validation Loss: 0.1370, Validation Loss: 0.0430,V Acc: 0.7928, Top 70th Acc: 0.8846, Bottom 30th Acc: 0.5758
Fold [1/5] Epoch [30/100] Initial Loss: 0.1391, Training Loss: 0.0208, Initial Validation Loss: 0.1370, Validation Loss: 0.0420,V Acc: 0.8108, Top 70th Acc: 0.8846, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 32  Rolling back to Epoch (base 0): 27  Top Validation Acc: 0.9102564102564102
65 0 [array([0.26095232, 0.045596  , 0.16737814, 0.3073358 , 0.21873778],
      dtype=float32)]
Fold [2/5] Epoch [0/100] Initial Loss: 0.1435, Training Loss: 0.1435, Initial Validation Loss: 0.1378, Validation Loss: 0.1378,V Acc: 0.2973, Top 70th Acc: 0.3333, Bottom 30th Acc: 0.2121
Fold [2/5] Epoch [10/100] Initial Loss: 0.1435, Training Loss: 0.0450, Initial Validation Loss: 0.1378, Validation Loss: 0.0547,V Acc: 0.7568, Top 70th Acc: 0.8590, Bottom 30th Acc: 0.5152
Fold [2/5] Epoch [20/100] Initial Loss: 0.1435, Training Loss: 0.0308, Initial Validation Loss: 0.1378, Validation Loss: 0.0456,V Acc: 0.7838, Top 70th Acc: 0.8974, Bottom 30th Acc: 0.5152
Fold [2/5] Epoch [30/100] Initial Loss: 0.1435, Training Loss: 0.0226, Initial Validation Loss: 0.1378, Validation Loss: 0.0418,V Acc: 0.7928, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.5152
Fold [2/5] Epoch [40/100] Initial Loss: 0.1435, Training Loss: 0.0198, Initial Validation Loss: 0.1378, Validation Loss: 0.0414,V Acc: 0.8018, Top 70th Acc: 0.8846, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 40  Rolling back to Epoch (base 0): 35  Top Validation Acc: 0.8846153846153846
Fold [3/5] Epoch [0/100] Initial Loss: 0.1389, Training Loss: 0.1389, Initial Validation Loss: 0.1311, Validation Loss: 0.1311,V Acc: 0.2818, Top 70th Acc: 0.3377, Bottom 30th Acc: 0.1515
Fold [3/5] Epoch [10/100] Initial Loss: 0.1389, Training Loss: 0.0302, Initial Validation Loss: 0.1311, Validation Loss: 0.0301,V Acc: 0.8273, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.5152
Fold [3/5] Epoch [20/100] Initial Loss: 0.1389, Training Loss: 0.0230, Initial Validation Loss: 0.1311, Validation Loss: 0.0284,V Acc: 0.8364, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.5152
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.974025974025974
Fold [4/5] Epoch [0/100] Initial Loss: 0.1388, Training Loss: 0.1388, Initial Validation Loss: 0.1342, Validation Loss: 0.1342,V Acc: 0.2909, Top 70th Acc: 0.3636, Bottom 30th Acc: 0.1212
Fold [4/5] Epoch [10/100] Initial Loss: 0.1388, Training Loss: 0.0311, Initial Validation Loss: 0.1342, Validation Loss: 0.0382,V Acc: 0.8364, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.6364
Fold [4/5] Epoch [20/100] Initial Loss: 0.1388, Training Loss: 0.0231, Initial Validation Loss: 0.1342, Validation Loss: 0.0360,V Acc: 0.8364, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.5758
CUDA:False
Training samples count:  550
Training on 21 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1304, Training Loss: 0.1304, Initial Validation Loss: 0.1198, Validation Loss: 0.1198,V Acc: 0.4775, Top 70th Acc: 0.5897, Bottom 30th Acc: 0.2121
Fold [1/5] Epoch [10/100] Initial Loss: 0.1304, Training Loss: 0.0247, Initial Validation Loss: 0.1198, Validation Loss: 0.0385,V Acc: 0.8108, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.5758
Fold [1/5] Epoch [20/100] Initial Loss: 0.1304, Training Loss: 0.0177, Initial Validation Loss: 0.1198, Validation Loss: 0.0269,V Acc: 0.8649, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 20  Rolling back to Epoch (base 0): 15  Top Validation Acc: 0.9487179487179487
Fold [2/5] Epoch [0/100] Initial Loss: 0.1390, Training Loss: 0.1390, Initial Validation Loss: 0.1297, Validation Loss: 0.1297,V Acc: 0.5405, Top 70th Acc: 0.5897, Bottom 30th Acc: 0.4242
Fold [2/5] Epoch [10/100] Initial Loss: 0.1390, Training Loss: 0.0282, Initial Validation Loss: 0.1297, Validation Loss: 0.0414,V Acc: 0.8018, Top 70th Acc: 0.8974, Bottom 30th Acc: 0.5758
Fold [2/5] Epoch [20/100] Initial Loss: 0.1390, Training Loss: 0.0175, Initial Validation Loss: 0.1297, Validation Loss: 0.0400,V Acc: 0.8108, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 21  Rolling back to Epoch (base 0): 16  Top Validation Acc: 0.9615384615384616
Fold [3/5] Epoch [0/100] Initial Loss: 0.1379, Training Loss: 0.1379, Initial Validation Loss: 0.1311, Validation Loss: 0.1311,V Acc: 0.4182, Top 70th Acc: 0.5195, Bottom 30th Acc: 0.1818
Fold [3/5] Epoch [10/100] Initial Loss: 0.1379, Training Loss: 0.0259, Initial Validation Loss: 0.1311, Validation Loss: 0.0293,V Acc: 0.8364, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 16  Rolling back to Epoch (base 0): 11  Top Validation Acc: 0.948051948051948
89 2 [array([0.68335956, 0.02829108, 0.04676665, 0.08283155, 0.15875113],
      dtype=float32)]
Fold [4/5] Epoch [0/100] Initial Loss: 0.1328, Training Loss: 0.1328, Initial Validation Loss: 0.1233, Validation Loss: 0.1233,V Acc: 0.4091, Top 70th Acc: 0.4935, Bottom 30th Acc: 0.2121
Fold [4/5] Epoch [10/100] Initial Loss: 0.1328, Training Loss: 0.0235, Initial Validation Loss: 0.1233, Validation Loss: 0.0328,V Acc: 0.8364, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.5455
Fold [4/5] Epoch [20/100] Initial Loss: 0.1328, Training Loss: 0.0183, Initial Validation Loss: 0.1233, Validation Loss: 0.0276,V Acc: 0.8727, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.948051948051948
Fold [5/5] Epoch [0/100] Initial Loss: 0.1277, Training Loss: 0.1277, Initial Validation Loss: 0.1170, Validation Loss: 0.1170,V Acc: 0.5926, Top 70th Acc: 0.6579, Bottom 30th Acc: 0.4375
Fold [5/5] Epoch [10/100] Initial Loss: 0.1277, Training Loss: 0.0221, Initial Validation Loss: 0.1170, Validation Loss: 0.0337,V Acc: 0.8426, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.6250
Stopping early at Epoch (base 0): 17  Rolling back to Epoch (base 0): 12  Top Validation Acc: 0.9736842105263158
Running train_nn.py with seed 90
CUDA:False
Training samples count:  550
Training on 21 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1264, Training Loss: 0.1264, Initial Validation Loss: 0.1155, Validation Loss: 0.1155,V Acc: 0.5135, Top 70th Acc: 0.6282, Bottom 30th Acc: 0.2424
Fold [1/5] Epoch [10/100] Initial Loss: 0.1264, Training Loss: 0.0248, Initial Validation Loss: 0.1155, Validation Loss: 0.0489,V Acc: 0.7748, Top 70th Acc: 0.8974, Bottom 30th Acc: 0.4848
Fold [1/5] Epoch [20/100] Initial Loss: 0.1264, Training Loss: 0.0154, Initial Validation Loss: 0.1155, Validation Loss: 0.0412,V Acc: 0.7928, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.4848
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.9102564102564102
Fold [2/5] Epoch [0/100] Initial Loss: 0.1314, Training Loss: 0.1314, Initial Validation Loss: 0.1196, Validation Loss: 0.1196,V Acc: 0.5045, Top 70th Acc: 0.6154, Bottom 30th Acc: 0.2424
Fold [2/5] Epoch [10/100] Initial Loss: 0.1314, Training Loss: 0.0310, Initial Validation Loss: 0.1196, Validation Loss: 0.0335,V Acc: 0.8468, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.6364
Fold [2/5] Epoch [20/100] Initial Loss: 0.1314, Training Loss: 0.0201, Initial Validation Loss: 0.1196, Validation Loss: 0.0264,V Acc: 0.8649, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 21  Rolling back to Epoch (base 0): 16  Top Validation Acc: 0.9743589743589743
Fold [3/5] Epoch [0/100] Initial Loss: 0.1319, Training Loss: 0.1319, Initial Validation Loss: 0.1173, Validation Loss: 0.1173,V Acc: 0.4545, Top 70th Acc: 0.5584, Bottom 30th Acc: 0.2121
Fold [3/5] Epoch [10/100] Initial Loss: 0.1319, Training Loss: 0.0224, Initial Validation Loss: 0.1173, Validation Loss: 0.0287,V Acc: 0.8364, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 18  Rolling back to Epoch (base 0): 13  Top Validation Acc: 0.961038961038961
Fold [4/5] Epoch [0/100] Initial Loss: 0.1355, Training Loss: 0.1355, Initial Validation Loss: 0.1312, Validation Loss: 0.1312,V Acc: 0.2909, Top 70th Acc: 0.3636, Bottom 30th Acc: 0.1212
Fold [4/5] Epoch [10/100] Initial Loss: 0.1355, Training Loss: 0.0251, Initial Validation Loss: 0.1312, Validation Loss: 0.0287,V Acc: 0.8909, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.7879
Stopping early at Epoch (base 0): 18  Rolling back to Epoch (base 0): 13  Top Validation Acc: 0.961038961038961
90 3 [array([0.69265467, 0.05115638, 0.02073541, 0.15832384, 0.07712959],
      dtype=float32)]
Fold [5/5] Epoch [0/100] Initial Loss: 0.1292, Training Loss: 0.1292, Initial Validation Loss: 0.1138, Validation Loss: 0.1138,V Acc: 0.4907, Top 70th Acc: 0.5921, Bottom 30th Acc: 0.2500
Fold [5/5] Epoch [10/100] Initial Loss: 0.1292, Training Loss: 0.0254, Initial Validation Loss: 0.1138, Validation Loss: 0.0349,V Acc: 0.8241, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.5625
Stopping early at Epoch (base 0): 18  Rolling back to Epoch (base 0): 13  Top Validation Acc: 0.9078947368421053
Running train_nn.py with seed 91
CUDA:False
Training samples count:  550
Training on 21 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1324, Training Loss: 0.1324, Initial Validation Loss: 0.1259, Validation Loss: 0.1259,V Acc: 0.5045, Top 70th Acc: 0.5769, Bottom 30th Acc: 0.3333
Fold [1/5] Epoch [10/100] Initial Loss: 0.1324, Training Loss: 0.0245, Initial Validation Loss: 0.1259, Validation Loss: 0.0410,V Acc: 0.8288, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 14  Rolling back to Epoch (base 0): 9  Top Validation Acc: 0.9358974358974359
Fold [2/5] Epoch [0/100] Initial Loss: 0.1368, Training Loss: 0.1368, Initial Validation Loss: 0.1208, Validation Loss: 0.1208,V Acc: 0.4324, Top 70th Acc: 0.5769, Bottom 30th Acc: 0.0909
Fold [2/5] Epoch [10/100] Initial Loss: 0.1368, Training Loss: 0.0218, Initial Validation Loss: 0.1208, Validation Loss: 0.0356,V Acc: 0.8108, Top 70th Acc: 0.8974, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 16  Rolling back to Epoch (base 0): 11  Top Validation Acc: 0.9102564102564102
Fold [3/5] Epoch [0/100] Initial Loss: 0.1234, Training Loss: 0.1234, Initial Validation Loss: 0.1125, Validation Loss: 0.1125,V Acc: 0.5273, Top 70th Acc: 0.6104, Bottom 30th Acc: 0.3333
Fold [3/5] Epoch [10/100] Initial Loss: 0.1234, Training Loss: 0.0262, Initial Validation Loss: 0.1125, Validation Loss: 0.0368,V Acc: 0.8273, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 16  Rolling back to Epoch (base 0): 11  Top Validation Acc: 0.961038961038961
Fold [4/5] Epoch [0/100] Initial Loss: 0.1363, Training Loss: 0.1363, Initial Validation Loss: 0.1317, Validation Loss: 0.1317,V Acc: 0.4545, Top 70th Acc: 0.6234, Bottom 30th Acc: 0.0606
Fold [4/5] Epoch [10/100] Initial Loss: 0.1363, Training Loss: 0.0293, Initial Validation Loss: 0.1317, Validation Loss: 0.0258,V Acc: 0.9091, Top 70th Acc: 0.9870, Bottom 30th Acc: 0.7273
Stopping early at Epoch (base 0): 17  Rolling back to Epoch (base 0):
Fold [5/5] Epoch [0/100] Initial Loss: 0.1395, Training Loss: 0.1395, Initial Validation Loss: 0.1315, Validation Loss: 0.1315,V Acc: 0.2963, Top 70th Acc: 0.3553, Bottom 30th Acc: 0.1562
Fold [5/5] Epoch [10/100] Initial Loss: 0.1395, Training Loss: 0.0795, Initial Validation Loss: 0.1315, Validation Loss: 0.0822,V Acc: 0.6019, Top 70th Acc: 0.7500, Bottom 30th Acc: 0.2500
Fold [5/5] Epoch [20/100] Initial Loss: 0.1395, Training Loss: 0.0774, Initial Validation Loss: 0.1315, Validation Loss: 0.0805,V Acc: 0.5833, Top 70th Acc: 0.7237, Bottom 30th Acc: 0.2500
Fold [5/5] Epoch [30/100] Initial Loss: 0.1395, Training Loss: 0.0769, Initial Validation Loss: 0.1315, Validation Loss: 0.0798,V Acc: 0.6111, Top 70th Acc: 0.7368, Bottom 30th Acc: 0.3125
Fold [5/5] Epoch [40/100] Initial Loss: 0.1395, Training Loss: 0.0762, Initial Validation Loss: 0.1315, Validation Loss: 0.0800,V Acc: 0.6204, Top 70th Acc: 0.7368, Bottom 30th Acc: 0.3438
Stopping early at Epoch (base 0): 40  Rolling back to Epoch (base 0): 35  Top Validation Acc: 0.7368421052631579
59 4 [array([0.144571  , 0.31481445, 0.14751668, 0.24707432, 0.14602359],
      dtype=float32)]
Running train_nn.py with seed 60
CUDA:False
Training samples count:  550
Training on 2 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1315, Training Loss: 0.1315, Initial Validation Loss: 0.1220, Validation Loss: 0.1220,V Acc: 0.4685, Top 70th Acc: 0.5256, Bottom 30th Acc: 0.3333
Fold [1/5] Epoch [10/100] Initial Loss: 0.1315, Training Loss: 0.0800, Initial Validation Loss: 0.1220, Validation Loss: 0.0819,V Acc: 0.6396, Top 70th Acc: 0.7051, Bottom 30th Acc: 0.4848
Stopping early at Epoch (base 0): 19  Rolling back to Epoch (base 0): 14  Top Validation Acc: 0.717948717948718
Fold [2/5] Epoch [0/100] Initial Loss: 0.1316, Training Loss: 0.1316, Initial Validation Loss: 0.1270, Validation Loss: 0.1270,V Acc: 0.4505, Top 70th Acc: 0.6026, Bottom 30th Acc: 0.0909
Fold [2/5] Epoch [10/100] Initial Loss: 0.1316, Training Loss: 0.0792, Initial Validation Loss: 0.1270, Validation Loss: 0.0909,V Acc: 0.5856, Top 70th Acc: 0.7051, Bottom 30th Acc: 0.3030
Fold [2/5] Epoch [20/100] Initial Loss: 0.1316, Training Loss: 0.0765, Initial Validation Loss: 0.1270, Validation Loss: 0.0889,V Acc: 0.5856, Top 70th Acc: 0.7051, Bottom 30th Acc: 0.3030
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.7051282051282052
Fold [3/5] Epoch [0/100] Initial Loss: 0.1357, Training Loss: 0.1357, Initial Validation Loss: 0.1240, Validation Loss: 0.1240,V Acc: 0.5000, Top 70th Acc: 0.6494, Bottom 30th Acc: 0.1515
Fold [3/5] Epoch [10/100] Initial Loss: 0.1357, Training Loss: 0.0823, Initial Validation Loss: 0.1240, Validation Loss: 0.0787,V Acc: 0.6273, Top 70th Acc: 0.7143, Bottom 30th Acc: 0.4242
Fold [3/5] Epoch [20/100] Initial Loss: 0.1357, Training Loss: 0.0805, Initial Validation Loss: 0.1240, Validation Loss: 0.0765,V Acc: 0.6364, Top 70th Acc: 0.7273, Bottom 30th Acc: 0.4242
Fold [3/5] Epoch [30/100] Initial Loss: 0.1357, Training Loss: 0.0801, Initial Validation Loss: 0.1240, Validation Loss: 0.0748,V Acc: 0.6273, Top 70th Acc: 0.7403, Bottom 30th Acc: 0.3636
Stopping early at Epoch (base 0): 39  Rolling back to Epoch (base 0): 34  Top Validation Acc: 0.7272727272727273
60 2 [array([0.13151486, 0.35433716, 0.14928688, 0.22059965, 0.14426148],
      dtype=float32)]
Fold [4/5] Epoch [0/100] Initial Loss: 0.1373, Training Loss: 0.1373, Initial Validation Loss: 0.1316, Validation Loss: 0.1316,V Acc: 0.4091, Top 70th Acc: 0.5455, Bottom 30th Acc: 0.0909
Fold [4/5] Epoch [10/100] Initial Loss: 0.1373, Training Loss: 0.0843, Initial Validation Loss: 0.1316, Validation Loss: 0.0728,V Acc: 0.6455, Top 70th Acc: 0.7792, Bottom 30th Acc: 0.3333
Fold [4/5] Epoch [20/100] Initial Loss: 0.1373, Training Loss: 0.0820, Initial Validation Loss: 0.1316, Validation Loss: 0.0692,V Acc: 0.6636, Top 70th Acc: 0.7792, Bottom 30th Acc: 0.3939
Fold [4/5] Epoch [30/100] Initial Loss: 0.1373, Training Loss: 0.0812, Initial Validation Loss: 0.1316, Validation Loss: 0.0681,V Acc: 0.6636, Top 70th Acc: 0.8052, Bottom 30th Acc: 0.3333
Fold [4/5] Epoch [40/100] Initial Loss: 0.1373, Training Loss: 0.0807, Initial Validation Loss: 0.1316, Validation Loss: 0.0677,V Acc: 0.7000, Top 70th Acc: 0.7922, Bottom 30th Acc: 0.4848
Fold [4/5] Epoch [50/100] Initial Loss: 0.1373, Training Loss: 0.0805, Initial Validation Loss: 0.1316, Validation Loss: 0.0675,V Acc: 0.7000, Top 70th Acc: 0.8182, Bottom 30th Acc: 0.4242
Fold [4/5] Epoch [60/100] Initial Loss: 0.1373, Training Loss: 0.0800, Initial Validation Loss: 0.1316, Validation Loss: 0.0669,V Acc: 0.7000, Top 70th Acc: 0.8312, Bottom 30th Acc: 0.3939
Stopping early at Epoch (base 0): 69  Rolling back to Epoch (base 0): 64  Top Validation Acc: 0.8181818181818182
Fold [5/5] Epoch [0/100] Initial Loss: 0.1369, Training Loss: 0.1369, Initial Validation Loss: 0.1260, Validation Loss: 0.1260,V Acc: 0.5278, Top 70th Acc: 0.6447, Bottom 30th Acc: 0.2500
Fold [5/5] Epoch [10/100] Initial Loss: 0.1369, Training Loss: 0.0796, Initial Validation Loss: 0.1260, Validation Loss: 0.0808,V Acc: 0.5833, Top 70th Acc: 0.7105, Bottom 30th Acc: 0.2812
Fold [5/5] Epoch [20/100] Initial Loss: 0.1369, Training Loss: 0.0773, Initial Validation Loss: 0.1260, Validation Loss: 0.0796,V Acc: 0.6204, Top 70th Acc: 0.7237, Bottom 30th Acc: 0.3750
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.7105263157894737
Running train_nn.py with seed 61
CUDA:False
Training samples count:  550
Training on 2 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1355, Training Loss: 0.1355, Initial Validation Loss: 0.1256, Validation Loss: 0.1256,V Acc: 0.4144, Top 70th Acc: 0.5385, Bottom 30th Acc: 0.1212
Fold [1/5] Epoch [10/100] Initial Loss: 0.1355, Training Loss: 0.0816, Initial Validation Loss: 0.1256, Validation Loss: 0.0796,V Acc: 0.6306, Top 70th Acc: 0.7308, Bottom 30th Acc: 0.3939
Fold [1/5] Epoch [20/100] Initial Loss: 0.1355, Training Loss: 0.0793, Initial Validation Loss: 0.1256, Validation Loss: 0.0776,V Acc: 0.6396, Top 70th Acc: 0.7436, Bottom 30th Acc: 0.3939
Fold [1/5] Epoch [30/100] Initial Loss: 0.1355, Training Loss: 0.0786, Initial Validation Loss: 0.1256, Validation Loss: 0.0772,V Acc: 0.6216, Top 70th Acc: 0.7308, Bottom 30th Acc: 0.3636
Stopping early at Epoch (base 0): 33  Rolling back to Epoch (base 0): 28  Top Validation Acc: 0.717948717948718
Fold [2/5] Epoch [0/100] Initial Loss: 0.1318, Training Loss: 0.1318, Initial Validation Loss: 0.1201, Validation Loss: 0.1201,V Acc: 0.4685, Top 70th Acc: 0.5385, Bottom 30th Acc: 0.3030
Fold [2/5] Epoch [10/100] Initial Loss: 0.1318, Training Loss: 0.0811, Initial Validation Loss: 0.1201, Validation Loss: 0.0781,V Acc: 0.6577, Top 70th Acc: 0.7564, Bottom 30th Acc: 0.4242
Fold [2/5] Epoch [20/100] Initial Loss: 0.1318, Training Loss: 0.0793, Initial Validation Loss: 0.1201, Validation Loss: 0.0766,V Acc: 0.6667, Top 70th Acc: 0.7308, Bottom 30th Acc: 0.5152
Fold [2/5] Epoch [30/100] Initial Loss: 0.1318, Training Loss: 0.0784, Initial Validation Loss: 0.1201, Validation Loss: 0.0768,V Acc: 0.6757, Top 70th Acc: 0.7436, Bottom 30th Acc: 0.5152
Stopping early at Epoch (base 0): 34  Rolling back to Epoch (base 0): 29  Top Validation Acc: 0.7307692307692307
Fold [3/5] Epoch [0/100] Initial Loss: 0.1364, Training Loss: 0.1364, Initial Validation Loss: 0.1288, Validation Loss: 0.1288,V Acc: 0.5091, Top 70th Acc: 0.6364, Bottom 30th Acc: 0.2121
Fold [3/5] Epoch [10/100] Initial Loss: 0.1364, Training Loss: 0.0800, Initial Validation Loss: 0.1288, Validation Loss: 0.0825,V Acc: 0.6182, Top 70th Acc: 0.7792, Bottom 30th Acc: 0.2424
Fold [3/5] Epoch [20/100] Initial Loss: 0.1364, Training Loss: 0.0778, Initial Validation Loss: 0.1288, Validation Loss: 0.0810,V Acc: 0.6182, Top 70th Acc: 0.7792, Bottom 30th Acc: 0.2424
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.7792207792207793
Fold [4/5] Epoch [0/100] Initial Loss: 0.1347, Training Loss: 0.1347, Initial Validation Loss: 0.1300, Validation Loss: 0.1300,V Acc: 0.4727, Top 70th Acc: 0.5974, Bottom 30th Acc: 0.1818
Stopping early at Epoch (base 0): 28  Rolling back to Epoch (base 0): 23  Top Validation Acc: 0.922077922077922
63 2 [array([0.39658767, 0.06774103, 0.17548409, 0.14150071, 0.21868646],
      dtype=float32)]
Fold [4/5] Epoch [0/100] Initial Loss: 0.1383, Training Loss: 0.1383, Initial Validation Loss: 0.1354, Validation Loss: 0.1354,V Acc: 0.3273, Top 70th Acc: 0.3636, Bottom 30th Acc: 0.2424
Fold [4/5] Epoch [10/100] Initial Loss: 0.1383, Training Loss: 0.0295, Initial Validation Loss: 0.1354, Validation Loss: 0.0434,V Acc: 0.7818, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.4848
Fold [4/5] Epoch [20/100] Initial Loss: 0.1383, Training Loss: 0.0164, Initial Validation Loss: 0.1354, Validation Loss: 0.0411,V Acc: 0.7909, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.4848
Stopping early at Epoch (base 0): 21  Rolling back to Epoch (base 0): 16  Top Validation Acc: 0.922077922077922
Fold [5/5] Epoch [0/100] Initial Loss: 0.1396, Training Loss: 0.1396, Initial Validation Loss: 0.1365, Validation Loss: 0.1365,V Acc: 0.2222, Top 70th Acc: 0.2237, Bottom 30th Acc: 0.2188
Fold [5/5] Epoch [10/100] Initial Loss: 0.1396, Training Loss: 0.0365, Initial Validation Loss: 0.1365, Validation Loss: 0.0390,V Acc: 0.8148, Top 70th Acc: 0.9211, Bottom 30th Acc: 0.5625
Fold [5/5] Epoch [20/100] Initial Loss: 0.1396, Training Loss: 0.0184, Initial Validation Loss: 0.1365, Validation Loss: 0.0293,V Acc: 0.8519, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.5938
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.9605263157894737
Running train_nn.py with seed 64
CUDA:False
Training samples count:  550
Training on 30 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1371, Training Loss: 0.1371, Initial Validation Loss: 0.1362, Validation Loss: 0.1362,V Acc: 0.2703, Top 70th Acc: 0.3205, Bottom 30th Acc: 0.1515
Fold [1/5] Epoch [10/100] Initial Loss: 0.1371, Training Loss: 0.0294, Initial Validation Loss: 0.1362, Validation Loss: 0.0397,V Acc: 0.7928, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.5152
Fold [1/5] Epoch [20/100] Initial Loss: 0.1371, Training Loss: 0.0176, Initial Validation Loss: 0.1362, Validation Loss: 0.0290,V Acc: 0.8739, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.9487179487179487
Fold [2/5] Epoch [0/100] Initial Loss: 0.1410, Training Loss: 0.1410, Initial Validation Loss: 0.1345, Validation Loss: 0.1345,V Acc: 0.2703, Top 70th Acc: 0.3205, Bottom 30th Acc: 0.1515
Fold [2/5] Epoch [10/100] Initial Loss: 0.1410, Training Loss: 0.0348, Initial Validation Loss: 0.1345, Validation Loss: 0.0453,V Acc: 0.7297, Top 70th Acc: 0.8590, Bottom 30th Acc: 0.4242
Fold [2/5] Epoch [20/100] Initial Loss: 0.1410, Training Loss: 0.0247, Initial Validation Loss: 0.1345, Validation Loss: 0.0456,V Acc: 0.7568, Top 70th Acc: 0.8846, Bottom 30th Acc: 0.4545
Fold [2/5] Epoch [30/100] Initial Loss: 0.1410, Training Loss: 0.0159, Initial Validation Loss: 0.1345, Validation Loss: 0.0371,V Acc: 0.8018, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.4848
Stopping early at Epoch (base 0): 37  Rolling back to Epoch (base 0): 32  Top Validation Acc: 0.9487179487179487
Fold [3/5] Epoch [0/100] Initial Loss: 0.1388, Training Loss: 0.1388, Initial Validation Loss: 0.1327, Validation Loss: 0.1327,V Acc: 0.2727, Top 70th Acc: 0.3636, Bottom 30th Acc: 0.0606
Fold [3/5] Epoch [10/100] Initial Loss: 0.1388, Training Loss: 0.0415, Initial Validation Loss: 0.1327, Validation Loss: 0.0365,V Acc: 0.8273, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.5758
Fold [3/5] Epoch [20/100] Initial Loss: 0.1388, Training Loss: 0.0225, Initial Validation Loss: 0.1327, Validation Loss: 0.0214,V Acc: 0.8909, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 27  Rolling back to Epoch (base 0): 22  Top Validation Acc: 0.974025974025974
Fold [4/5] Epoch [0/100] Initial Loss: 0.1383, Training Loss: 0.1383, Initial Validation Loss: 0.1330, Validation Loss: 0.1330,V Acc: 0.3545, Top 70th Acc: 0.4286, Bottom 30th Acc: 0.1818
Fold [4/5] Epoch [10/100] Initial Loss: 0.1383, Training Loss: 0.0332, Initial Validation Loss: 0.1330, Validation Loss: 0.0363,V Acc: 0.8636, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.7273
Fold [4/5] Epoch [20/100] Initial Loss: 0.1383, Training Loss: 0.0174, Initial Validation Loss: 0.1330, Validation Loss: 0.0291,V Acc: 0.8455, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.5758
Fold [4/5] Epoch [30/100] Initial Loss: 0.1383, Training Loss: 0.0148, Initial Validation Loss: 0.1330, Validation Loss: 0.0290,V Acc: 0.8455, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 33  Rolling back to Epoch (base 0): 28  Top Validation Acc: 0.961038961038961
64 3 [array([0.71088547, 0.02047656, 0.0450229 , 0.07854311, 0.14507201],
      dtype=float32)]
Fold [5/5] Epoch [0/100] Initial Loss: 0.1419, Training Loss: 0.1419, Initial Validation Loss: 0.1341, Validation Loss: 0.1341,V Acc: 0.2593, Top 70th Acc: 0.2500, Bottom 30th Acc: 0.2812
Fold [5/5] Epoch [10/100] Initial Loss: 0.1419, Training Loss: 0.0367, Initial Validation Loss: 0.1341, Validation Loss: 0.0571,V Acc: 0.7037, Top 70th Acc: 0.7895, Bottom 30th Acc: 0.5000
Fold [5/5] Epoch [20/100] Initial Loss: 0.1419, Training Loss: 0.0176, Initial Validation Loss: 0.1341, Validation Loss: 0.0468,V Acc: 0.7407, Top 70th Acc: 0.8553, Bottom 30th Acc: 0.4688
Fold [5/5] Epoch [30/100] Initial Loss: 0.1419, Training Loss: 0.0146, Initial Validation Loss: 0.1341, Validation Loss: 0.0436,V Acc: 0.7500, Top 70th Acc: 0.8553, Bottom 30th Acc: 0.5000
Stopping early at Epoch (base 0): 32  Rolling back to Epoch (base 0): 27  Top Validation Acc: 0.8552631578947368
Running train_nn.py with seed 65
CUDA:False
Training samples count:  550
Training on 30 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1404, Training Loss: 0.1404, Initial Validation Loss: 0.1363, Validation Loss: 0.1363,V Acc: 0.3694, Top 70th Acc: 0.4231, Bottom 30th Acc: 0.2424
Fold [1/5] Epoch [10/100] Initial Loss: 0.1404, Training Loss: 0.0341, Initial Validation Loss: 0.1363, Validation Loss: 0.0408,V Acc: 0.8288, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.5758
Fold [1/5] Epoch [20/100] Initial Loss: 0.1404, Training Loss: 0.0188, Initial Validation Loss: 0.1363, Validation Loss: 0.0312,V Acc: 0.8468, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 28  Rolling back to Epoch (base 0): 23  Top Validation Acc: 0.9358974358974359
65 0 [array([0.49816   , 0.06916113, 0.04096389, 0.07258213, 0.31913292],
      dtype=float32)]
Fold [2/5] Epoch [0/100] Initial Loss: 0.1355, Training Loss: 0.1355, Initial Validation Loss: 0.1332, Validation Loss: 0.1332,V Acc: 0.3874, Top 70th Acc: 0.4231, Bottom 30th Acc: 0.3030
Fold [2/5] Epoch [10/100] Initial Loss: 0.1355, Training Loss: 0.0377, Initial Validation Loss: 0.1332, Validation Loss: 0.0443,V Acc: 0.7748, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.4545
Fold [2/5] Epoch [20/100] Initial Loss: 0.1355, Training Loss: 0.0187, Initial Validation Loss: 0.1332, Validation Loss: 0.0311,V Acc: 0.8559, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 28  Rolling back to Epoch (base 0): 23  Top Validation Acc: 0.9487179487179487
Fold [3/5] Epoch [0/100] Initial Loss: 0.1378, Training Loss: 0.1378, Initial Validation Loss: 0.1309, Validation Loss: 0.1309,V Acc: 0.3636, Top 70th Acc: 0.3896, Bottom 30th Acc: 0.3030
Fold [3/5] Epoch [10/100] Initial Loss: 0.1378, Training Loss: 0.0434, Initial Validation Loss: 0.1309, Validation Loss: 0.0444,V Acc: 0.7727, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.4545
Fold [3/5] Epoch [20/100] Initial Loss: 0.1378, Training Loss: 0.0187, Initial Validation Loss: 0.1309, Validation Loss: 0.0316,V Acc: 0.8182, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.4848
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.974025974025974
Fold [4/5] Epoch [0/100] Initial Loss: 0.1433, Training Loss: 0.1433, Initial Validation Loss: 0.1355, Validation Loss: 0.1355,V Acc: 0.2636, Top 70th Acc: 0.2338, Bottom 30th Acc: 0.3333
Fold [4/5] Epoch [10/100] Initial Loss: 0.1433, Training Loss: 0.0342, Initial Validation Loss: 0.1355, Validation Loss: 0.0477,V Acc: 0.7455, Top 70th Acc: 0.8701, Bottom 30th Acc: 0.4545/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)

Fold [3/5] Epoch [20/100] Initial Loss: 0.1373, Training Loss: 0.0042, Initial Validation Loss: 0.1334, Validation Loss: 0.0294,V Acc: 0.8636, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.948051948051948
Fold [4/5] Epoch [0/100] Initial Loss: 0.1406, Training Loss: 0.1406, Initial Validation Loss: 0.1324, Validation Loss: 0.1324,V Acc: 0.4091, Top 70th Acc: 0.4675, Bottom 30th Acc: 0.2727
Fold [4/5] Epoch [10/100] Initial Loss: 0.1406, Training Loss: 0.0168, Initial Validation Loss: 0.1324, Validation Loss: 0.0367,V Acc: 0.8636, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.7273
Fold [4/5] Epoch [20/100] Initial Loss: 0.1406, Training Loss: 0.0052, Initial Validation Loss: 0.1324, Validation Loss: 0.0313,V Acc: 0.8182, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 29  Rolling back to Epoch (base 0): 24  Top Validation Acc: 0.948051948051948
Fold [5/5] Epoch [0/100] Initial Loss: 0.1386, Training Loss: 0.1386, Initial Validation Loss: 0.1359, Validation Loss: 0.1359,V Acc: 0.2685, Top 70th Acc: 0.3158, Bottom 30th Acc: 0.1562
Fold [5/5] Epoch [10/100] Initial Loss: 0.1386, Training Loss: 0.0158, Initial Validation Loss: 0.1359, Validation Loss: 0.0381,V Acc: 0.8056, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.5000
Fold [5/5] Epoch [20/100] Initial Loss: 0.1386, Training Loss: 0.0051, Initial Validation Loss: 0.1359, Validation Loss: 0.0332,V Acc: 0.7963, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.4062
Stopping early at Epoch (base 0): 29  Rolling back to Epoch (base 0): 24  Top Validation Acc: 0.9473684210526315
Running train_nn.py with seed 49
CUDA:False
Training samples count:  550
Training on 163 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1390, Training Loss: 0.1390, Initial Validation Loss: 0.1338, Validation Loss: 0.1338,V Acc: 0.2523, Top 70th Acc: 0.3077, Bottom 30th Acc: 0.1212
Fold [1/5] Epoch [10/100] Initial Loss: 0.1390, Training Loss: 0.0142, Initial Validation Loss: 0.1338, Validation Loss: 0.0279,V Acc: 0.8649, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.6364
Fold [1/5] Epoch [20/100] Initial Loss: 0.1390, Training Loss: 0.0048, Initial Validation Loss: 0.1338, Validation Loss: 0.0241,V Acc: 0.8739, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.9487179487179487
Fold [2/5] Epoch [0/100] Initial Loss: 0.1366, Training Loss: 0.1366, Initial Validation Loss: 0.1371, Validation Loss: 0.1371,V Acc: 0.3063, Top 70th Acc: 0.3846, Bottom 30th Acc: 0.1212
Fold [2/5] Epoch [10/100] Initial Loss: 0.1366, Training Loss: 0.0253, Initial Validation Loss: 0.1371, Validation Loss: 0.0380,V Acc: 0.8198, Top 70th Acc: 0.9872, Bottom 30th Acc: 0.4242
Fold [2/5] Epoch [20/100] Initial Loss: 0.1366, Training Loss: 0.0069, Initial Validation Loss: 0.1371, Validation Loss: 0.0293,V Acc: 0.8378, Top 70th Acc: 0.9872, Bottom 30th Acc: 0.4848
Fold [2/5] Epoch [30/100] Initial Loss: 0.1366, Training Loss: 0.0046, Initial Validation Loss: 0.1371, Validation Loss: 0.0281,V Acc: 0.8108, Top 70th Acc: 1.0000, Bottom 30th Acc: 0.3636
Fold [2/5] Epoch [40/100] Initial Loss: 0.1366, Training Loss: 0.0040, Initial Validation Loss: 0.1371, Validation Loss: 0.0274,V Acc: 0.8378, Top 70th Acc: 1.0000, Bottom 30th Acc: 0.4545
Fold [2/5] Epoch [50/100] Initial Loss: 0.1366, Training Loss: 0.0036, Initial Validation Loss: 0.1371, Validation Loss: 0.0258,V Acc: 0.8559, Top 70th Acc: 1.0000, Bottom 30th Acc: 0.5152
Fold [2/5] Epoch [60/100] Initial Loss: 0.1366, Training Loss: 0.0035, Initial Validation Loss: 0.1371, Validation Loss: 0.0245,V Acc: 0.8649, Top 70th Acc: 1.0000, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 66  Rolling back to Epoch (base 0): 61  Top Validation Acc: 1.0
Fold [3/5] Epoch [0/100] Initial Loss: 0.1378, Training Loss: 0.1378, Initial Validation Loss: 0.1335, Validation Loss: 0.1335,V Acc: 0.2636, Top 70th Acc: 0.3247, Bottom 30th Acc: 0.1212
Fold [3/5] Epoch [10/100] Initial Loss: 0.1378, Training Loss: 0.0202, Initial Validation Loss: 0.1335, Validation Loss: 0.0471,V Acc: 0.7273, Top 70th Acc: 0.8961, Bottom 30th Acc: 0.3333
Fold [3/5] Epoch [20/100] Initial Loss: 0.1378, Training Loss: 0.0048, Initial Validation Loss: 0.1335, Validation Loss: 0.0412,V Acc: 0.7364, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.3030
Stopping early at Epoch (base 0): 28  Rolling back to Epoch (base 0): 23  Top Validation Acc: 0.922077922077922
Fold [4/5] Epoch [0/100] Initial Loss: 0.1380, Training Loss: 0.1380, Initial Validation Loss: 0.1344, Validation Loss: 0.1344,V Acc: 0.2545, Top 70th Acc: 0.2987, Bottom 30th Acc: 0.1515
Fold [4/5] Epoch [10/100] Initial Loss: 0.1380, Training Loss: 0.0148, Initial Validation Loss: 0.1344, Validation Loss: 0.0346,V Acc: 0.8091, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.5455
Fold [4/5] Epoch [20/100] Initial Loss: 0.1380, Training Loss: 0.0054, Initial Validation Loss: 0.1344, Validation Loss: 0.0289,V Acc: 0.8455, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.987012987012987
Fold [5/5] Epoch [0/100] Initial Loss: 0.1383, Training Loss: 0.1383, Initial Validation Loss: 0.1304, Validation Loss: 0.1304,V Acc: 0.2593, Top 70th Acc: 0.3553, Bottom 30th Acc: 0.0312
Fold [5/5] Epoch [10/100] Initial Loss: 0.1383, Training Loss: 0.0215, Initial Validation Loss: 0.1304, Validation Loss: 0.0411,V Acc: 0.7963, Top 70th Acc: 0.9211, Bottom 30th Acc: 0.5000
Fold [5/5] Epoch [20/100] Initial Loss: 0.1383, Training Loss: 0.0048, Initial Validation Loss: 0.1304, Validation Loss: 0.0336,V Acc: 0.8333, Top 70th Acc: 0.9211, Bottom 30th Acc: 0.6250
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.9210526315789473
49 4 [array([0.1781531 , 0.04436856, 0.0402486 , 0.12063164, 0.6165981 ],
      dtype=float32)]
Running train_nn.py with seed 50
CUDA:False
Training samples count:  550
Training on 163 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1354, Training Loss: 0.1354, Initial Validation Loss: 0.1351, Validation Loss: 0.1351,V Acc: 0.4414, Top 70th Acc: 0.5641, Bottom 30th Acc: 0.1515
Fold [1/5] Epoch [10/100] Initial Loss: 0.1354, Training Loss: 0.0127, Initial Validation Loss: 0.1351, Validation Loss: 0.0305,V Acc: 0.8468, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.5758
Fold [1/5] Epoch [20/100] Initial Loss: 0.1354, Training Loss: 0.0047, Initial Validation Loss: 0.1351, Validation Loss: 0.0248,V Acc: 0.8919, Top 70th Acc: 0.9872, Bottom 30th Acc: 0.6667
Fold [1/5] Epoch [30/100] Initial Loss: 0.1354, Training Loss: 0.0038, Initial Validation Loss: 0.1351, Validation Loss: 0.0247,V Acc: 0.9009, Top 70th Acc: 0.9872, Bottom 30th Acc: 0.6970
Fold [1/5] Epoch [40/100] Initial Loss: 0.1354, Training Loss: 0.0036, Initial Validation Loss: 0.1351, Validation Loss: 0.0244,V Acc: 0.8919, Top 70th Acc: 0.9872, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 45  Rolling back to Epoch (base 0): 40  Top Validation Acc: 0.9743589743589743
Fold [2/5] Epoch [0/100] Initial Loss: 0.1388, Training Loss: 0.1388, Initial Validation Loss: 0.1348, Validation Loss: 0.1348,V Acc: 0.2523, Top 70th Acc: 0.3333, Bottom 30th Acc: 0.0606
Fold [2/5] Epoch [10/100] Initial Loss: 0.1388, Training Loss: 0.0176, Initial Validation Loss: 0.1348, Validation Loss: 0.0363,V Acc: 0.8108, Top 70th Acc: 0.8974, Bottom 30th Acc: 0.6061
Fold [2/5] Epoch [20/100] Initial Loss: 0.1388, Training Loss: 0.0047, Initial Validation Loss: 0.1348, Validation Loss: 0.0283,V Acc: 0.8288, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.5152
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.9615384615384616
Fold [3/5] Epoch [0/100] Initial Loss: 0.1387, Training Loss: 0.1387, Initial Validation Loss: 0.1360, Validation Loss: 0.1360,V Acc: 0.2545, Top 70th Acc: 0.3377, Bottom 30th Acc: 0.0606
Fold [3/5] Epoch [10/100] Initial Loss: 0.1387, Training Loss: 0.0205, Initial Validation Loss: 0.1360, Validation Loss: 0.0365,V Acc: 0.8273, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.5152
Fold [1/5] Epoch [20/100] Initial Loss: 0.1412, Training Loss: 0.0168, Initial Validation Loss: 0.1360, Validation Loss: 0.0337,V Acc: 0.8649, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.6667
Fold [1/5] Epoch [30/100] Initial Loss: 0.1412, Training Loss: 0.0135, Initial Validation Loss: 0.1360, Validation Loss: 0.0318,V Acc: 0.8649, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.6364
Fold [1/5] Epoch [40/100] Initial Loss: 0.1412, Training Loss: 0.0120, Initial Validation Loss: 0.1360, Validation Loss: 0.0317,V Acc: 0.8559, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 40  Rolling back to Epoch (base 0): 35  Top Validation Acc: 0.9743589743589743
Fold [2/5] Epoch [0/100] Initial Loss: 0.1399, Training Loss: 0.1399, Initial Validation Loss: 0.1348, Validation Loss: 0.1348,V Acc: 0.2342, Top 70th Acc: 0.2949, Bottom 30th Acc: 0.0909
Fold [2/5] Epoch [10/100] Initial Loss: 0.1399, Training Loss: 0.0294, Initial Validation Loss: 0.1348, Validation Loss: 0.0390,V Acc: 0.8108, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.5455
Fold [2/5] Epoch [20/100] Initial Loss: 0.1399, Training Loss: 0.0131, Initial Validation Loss: 0.1348, Validation Loss: 0.0339,V Acc: 0.8378, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 20  Rolling back to Epoch (base 0): 15  Top Validation Acc: 0.9102564102564102
Fold [3/5] Epoch [0/100] Initial Loss: 0.1371, Training Loss: 0.1371, Initial Validation Loss: 0.1328, Validation Loss: 0.1328,V Acc: 0.3455, Top 70th Acc: 0.4416, Bottom 30th Acc: 0.1212
Fold [3/5] Epoch [10/100] Initial Loss: 0.1371, Training Loss: 0.0315, Initial Validation Loss: 0.1328, Validation Loss: 0.0311,V Acc: 0.8909, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.7879
Fold [3/5] Epoch [20/100] Initial Loss: 0.1371, Training Loss: 0.0156, Initial Validation Loss: 0.1328, Validation Loss: 0.0259,V Acc: 0.8909, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.7576
Stopping early at Epoch (base 0): 28  Rolling back to Epoch (base 0): 23  Top Validation Acc: 0.961038961038961
Fold [4/5] Epoch [0/100] Initial Loss: 0.1387, Training Loss: 0.1387, Initial Validation Loss: 0.1348, Validation Loss: 0.1348,V Acc: 0.3455, Top 70th Acc: 0.3896, Bottom 30th Acc: 0.2424
Fold [4/5] Epoch [10/100] Initial Loss: 0.1387, Training Loss: 0.0264, Initial Validation Loss: 0.1348, Validation Loss: 0.0338,V Acc: 0.8545, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.6061
Fold [4/5] Epoch [20/100] Initial Loss: 0.1387, Training Loss: 0.0140, Initial Validation Loss: 0.1348, Validation Loss: 0.0282,V Acc: 0.8636, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6667
Fold [4/5] Epoch [30/100] Initial Loss: 0.1387, Training Loss: 0.0113, Initial Validation Loss: 0.1348, Validation Loss: 0.0277,V Acc: 0.8727, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 35  Rolling back to Epoch (base 0): 30  Top Validation Acc: 0.961038961038961
64 3 [array([0.6897006 , 0.01853866, 0.06645216, 0.06426512, 0.16104345],
      dtype=float32)]
Fold [5/5] Epoch [0/100] Initial Loss: 0.1400, Training Loss: 0.1400, Initial Validation Loss: 0.1325, Validation Loss: 0.1325,V Acc: 0.2963, Top 70th Acc: 0.3026, Bottom 30th Acc: 0.2812
Fold [5/5] Epoch [10/100] Initial Loss: 0.1400, Training Loss: 0.0276, Initial Validation Loss: 0.1325, Validation Loss: 0.0462,V Acc: 0.7593, Top 70th Acc: 0.8947, Bottom 30th Acc: 0.4375
Fold [5/5] Epoch [20/100] Initial Loss: 0.1400, Training Loss: 0.0137, Initial Validation Loss: 0.1325, Validation Loss: 0.0394,V Acc: 0.7963, Top 70th Acc: 0.9079, Bottom 30th Acc: 0.5312
Fold [5/5] Epoch [30/100] Initial Loss: 0.1400, Training Loss: 0.0110, Initial Validation Loss: 0.1325, Validation Loss: 0.0384,V Acc: 0.8148, Top 70th Acc: 0.8947, Bottom 30th Acc: 0.6250
Stopping early at Epoch (base 0): 32  Rolling back to Epoch (base 0): 27  Top Validation Acc: 0.9078947368421053
Running train_nn.py with seed 65
CUDA:False
Training samples count:  550
Training on 40 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1395, Training Loss: 0.1395, Initial Validation Loss: 0.1356, Validation Loss: 0.1356,V Acc: 0.3063, Top 70th Acc: 0.3974, Bottom 30th Acc: 0.0909
Fold [1/5] Epoch [10/100] Initial Loss: 0.1395, Training Loss: 0.0321, Initial Validation Loss: 0.1356, Validation Loss: 0.0405,V Acc: 0.8468, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.6364
Fold [1/5] Epoch [20/100] Initial Loss: 0.1395, Training Loss: 0.0153, Initial Validation Loss: 0.1356, Validation Loss: 0.0340,V Acc: 0.8378, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.5758
Fold [1/5] Epoch [30/100] Initial Loss: 0.1395, Training Loss: 0.0129, Initial Validation Loss: 0.1356, Validation Loss: 0.0334,V Acc: 0.8288, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 32  Rolling back to Epoch (base 0): 27  Top Validation Acc: 0.9487179487179487
65 0 [array([0.439803  , 0.05692584, 0.13403615, 0.06927232, 0.2999627 ],
      dtype=float32)]
Fold [2/5] Epoch [0/100] Initial Loss: 0.1424, Training Loss: 0.1424, Initial Validation Loss: 0.1393, Validation Loss: 0.1393,V Acc: 0.2523, Top 70th Acc: 0.2692, Bottom 30th Acc: 0.2121
Fold [2/5] Epoch [10/100] Initial Loss: 0.1424, Training Loss: 0.0406, Initial Validation Loss: 0.1393, Validation Loss: 0.0495,V Acc: 0.7748, Top 70th Acc: 0.8846, Bottom 30th Acc: 0.5152
Fold [2/5] Epoch [20/100] Initial Loss: 0.1424, Training Loss: 0.0210, Initial Validation Loss: 0.1393, Validation Loss: 0.0356,V Acc: 0.8378, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.6061
Fold [2/5] Epoch [30/100] Initial Loss: 0.1424, Training Loss: 0.0150, Initial Validation Loss: 0.1393, Validation Loss: 0.0316,V Acc: 0.8468, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.6061
Fold [2/5] Epoch [40/100] Initial Loss: 0.1424, Training Loss: 0.0128, Initial Validation Loss: 0.1393, Validation Loss: 0.0303,V Acc: 0.8468, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 43  Rolling back to Epoch (base 0): 38  Top Validation Acc: 0.9358974358974359
Fold [3/5] Epoch [0/100] Initial Loss: 0.1389, Training Loss: 0.1389, Initial Validation Loss: 0.1332, Validation Loss: 0.1332,V Acc: 0.3091, Top 70th Acc: 0.3377, Bottom 30th Acc: 0.2424
Fold [3/5] Epoch [10/100] Initial Loss: 0.1389, Training Loss: 0.0347, Initial Validation Loss: 0.1332, Validation Loss: 0.0387,V Acc: 0.7909, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.4848
Fold [3/5] Epoch [20/100] Initial Loss: 0.1389, Training Loss: 0.0153, Initial Validation Loss: 0.1332, Validation Loss: 0.0293,V Acc: 0.8455, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.5758
Fold [3/5] Epoch [30/100] Initial Loss: 0.1389, Training Loss: 0.0124, Initial Validation Loss: 0.1332, Validation Loss: 0.0280,V Acc: 0.8545, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 39  Rolling back to Epoch (base 0): 34  Top Validation Acc: 0.961038961038961
Fold [4/5] Epoch [0/100] Initial Loss: 0.1415, Training Loss: 0.1415, Initial Validation Loss: 0.1350, Validation Loss: 0.1350,V Acc: 0.2545, Top 70th Acc: 0.2987, Bottom 30th Acc: 0.1515
Fold [4/5] Epoch [10/100] Initial Loss: 0.1415, Training Loss: 0.0274, Initial Validation Loss: 0.1350, Validation Loss: 0.0401,V Acc: 0.8000, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.4545
Fold [4/5] Epoch [20/100] Initial Loss: 0.1415, Training Loss: 0.0126, Initial Validation Loss: 0.1350, Validation Loss: 0.0362,V Acc: 0.8273, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.922077922077922
Fold [5/5] Epoch [0/100] Initial Loss: 0.1378, Training Loss: 0.1378, Initial Validation Loss: 0.1311, Validation Loss: 0.1311,V Acc: 0.2685, Top 70th Acc: 0.3421, Bottom 30th Acc: 0.0938
Fold [5/5] Epoch [10/100] Initial Loss: 0.1378, Training Loss: 0.0346, Initial Validation Loss: 0.1311, Validation Loss: 0.0426,V Acc: 0.7778, Top 70th Acc: 0.8816, Bottom 30th Acc: 0.5312
Fold [5/5] Epoch [20/100] Initial Loss: 0.1378, Training Loss: 0.0159, Initial Validation Loss: 0.1311, Validation Loss: 0.0304,V Acc: 0.8519, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.6250
Fold [5/5] Epoch [30/100] Initial Loss: 0.1378, Training Loss: 0.0122, Initial Validation Loss: 0.1311, Validation Loss: 0.0288,V Acc: 0.8426, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.5938
Stopping early at Epoch (base 0): 21  Rolling back to Epoch (base 0): 16  Top Validation Acc: 0.948051948051948
Fold [5/5] Epoch [0/100] Initial Loss: 0.1397, Training Loss: 0.1397, Initial Validation Loss: 0.1349, Validation Loss: 0.1349,V Acc: 0.2500, Top 70th Acc: 0.2895, Bottom 30th Acc: 0.1562
Fold [5/5] Epoch [10/100] Initial Loss: 0.1397, Training Loss: 0.0547, Initial Validation Loss: 0.1349, Validation Loss: 0.0510,V Acc: 0.7500, Top 70th Acc: 0.9079, Bottom 30th Acc: 0.3750
Fold [5/5] Epoch [20/100] Initial Loss: 0.1397, Training Loss: 0.0251, Initial Validation Loss: 0.1349, Validation Loss: 0.0311,V Acc: 0.8148, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.5312
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.9210526315789473
Running train_nn.py with seed 66
CUDA:False
Training samples count:  550
Training on 20 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1360, Training Loss: 0.1360, Initial Validation Loss: 0.1373, Validation Loss: 0.1373,V Acc: 0.3063, Top 70th Acc: 0.3205, Bottom 30th Acc: 0.2727
Fold [1/5] Epoch [10/100] Initial Loss: 0.1360, Training Loss: 0.0353, Initial Validation Loss: 0.1373, Validation Loss: 0.0467,V Acc: 0.8018, Top 70th Acc: 0.8846, Bottom 30th Acc: 0.6061
Fold [1/5] Epoch [20/100] Initial Loss: 0.1360, Training Loss: 0.0240, Initial Validation Loss: 0.1373, Validation Loss: 0.0345,V Acc: 0.8378, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.6061
Fold [1/5] Epoch [30/100] Initial Loss: 0.1360, Training Loss: 0.0215, Initial Validation Loss: 0.1373, Validation Loss: 0.0320,V Acc: 0.8649, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 33  Rolling back to Epoch (base 0): 28  Top Validation Acc: 0.9358974358974359
Fold [2/5] Epoch [0/100] Initial Loss: 0.1373, Training Loss: 0.1373, Initial Validation Loss: 0.1331, Validation Loss: 0.1331,V Acc: 0.3333, Top 70th Acc: 0.4231, Bottom 30th Acc: 0.1212
Fold [2/5] Epoch [10/100] Initial Loss: 0.1373, Training Loss: 0.0409, Initial Validation Loss: 0.1331, Validation Loss: 0.0494,V Acc: 0.7748, Top 70th Acc: 0.8718, Bottom 30th Acc: 0.5455
Fold [2/5] Epoch [20/100] Initial Loss: 0.1373, Training Loss: 0.0216, Initial Validation Loss: 0.1331, Validation Loss: 0.0373,V Acc: 0.8108, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.5152
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.9230769230769231
Fold [3/5] Epoch [0/100] Initial Loss: 0.1392, Training Loss: 0.1392, Initial Validation Loss: 0.1294, Validation Loss: 0.1294,V Acc: 0.3364, Top 70th Acc: 0.3896, Bottom 30th Acc: 0.2121
Fold [3/5] Epoch [10/100] Initial Loss: 0.1392, Training Loss: 0.0324, Initial Validation Loss: 0.1294, Validation Loss: 0.0388,V Acc: 0.7909, Top 70th Acc: 0.8831, Bottom 30th Acc: 0.5758
Fold [3/5] Epoch [20/100] Initial Loss: 0.1392, Training Loss: 0.0231, Initial Validation Loss: 0.1294, Validation Loss: 0.0319,V Acc: 0.8000, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.5152
Stopping early at Epoch (base 0): 28  Rolling back to Epoch (base 0): 23  Top Validation Acc: 0.935064935064935
Fold [4/5] Epoch [0/100] Initial Loss: 0.1351, Training Loss: 0.1351, Initial Validation Loss: 0.1334, Validation Loss: 0.1334,V Acc: 0.2636, Top 70th Acc: 0.3636, Bottom 30th Acc: 0.0303
Fold [4/5] Epoch [10/100] Initial Loss: 0.1351, Training Loss: 0.0323, Initial Validation Loss: 0.1334, Validation Loss: 0.0328,V Acc: 0.8545, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6364
Fold [4/5] Epoch [20/100] Initial Loss: 0.1351, Training Loss: 0.0237, Initial Validation Loss: 0.1334, Validation Loss: 0.0306,V Acc: 0.8364, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.961038961038961
66 3 [array([0.18806818, 0.13237803, 0.11332126, 0.32988653, 0.23634599],
      dtype=float32)]
Fold [5/5] Epoch [0/100] Initial Loss: 0.1394, Training Loss: 0.1394, Initial Validation Loss: 0.1297, Validation Loss: 0.1297,V Acc: 0.2778, Top 70th Acc: 0.2895, Bottom 30th Acc: 0.2500
Fold [5/5] Epoch [10/100] Initial Loss: 0.1394, Training Loss: 0.0308, Initial Validation Loss: 0.1297, Validation Loss: 0.0401,V Acc: 0.8056, Top 70th Acc: 0.9079, Bottom 30th Acc: 0.5625
Fold [5/5] Epoch [20/100] Initial Loss: 0.1394, Training Loss: 0.0213, Initial Validation Loss: 0.1297, Validation Loss: 0.0388,V Acc: 0.8148, Top 70th Acc: 0.8947, Bottom 30th Acc: 0.6250
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.9078947368421053
Running train_nn.py with seed 67
CUDA:False
Training samples count:  550
Training on 20 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1365, Training Loss: 0.1365, Initial Validation Loss: 0.1316, Validation Loss: 0.1316,V Acc: 0.3243, Top 70th Acc: 0.3974, Bottom 30th Acc: 0.1515
Fold [1/5] Epoch [10/100] Initial Loss: 0.1365, Training Loss: 0.0310, Initial Validation Loss: 0.1316, Validation Loss: 0.0365,V Acc: 0.8108, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.5455
Fold [1/5] Epoch [20/100] Initial Loss: 0.1365, Training Loss: 0.0214, Initial Validation Loss: 0.1316, Validation Loss: 0.0366,V Acc: 0.8018, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.5152
Stopping early at Epoch (base 0): 22  Rolling back to Epoch (base 0): 17  Top Validation Acc: 0.9102564102564102
67 0 [array([0.5370831 , 0.06952125, 0.04553116, 0.17717989, 0.17068465],
      dtype=float32)]
Fold [2/5] Epoch [0/100] Initial Loss: 0.1405, Training Loss: 0.1405, Initial Validation Loss: 0.1332, Validation Loss: 0.1332,V Acc: 0.2523, Top 70th Acc: 0.3590, Bottom 30th Acc: 0.0000
Fold [2/5] Epoch [10/100] Initial Loss: 0.1405, Training Loss: 0.0497, Initial Validation Loss: 0.1332, Validation Loss: 0.0506,V Acc: 0.7748, Top 70th Acc: 0.8846, Bottom 30th Acc: 0.5152
Fold [2/5] Epoch [20/100] Initial Loss: 0.1405, Training Loss: 0.0264, Initial Validation Loss: 0.1332, Validation Loss: 0.0315,V Acc: 0.8559, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.6970
Fold [2/5] Epoch [30/100] Initial Loss: 0.1405, Training Loss: 0.0210, Initial Validation Loss: 0.1332, Validation Loss: 0.0315,V Acc: 0.8288, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 37  Rolling back to Epoch (base 0): 32  Top Validation Acc: 0.9358974358974359
Fold [3/5] Epoch [0/100] Initial Loss: 0.1411, Training Loss: 0.1411, Initial Validation Loss: 0.1341, Validation Loss: 0.1341,V Acc: 0.3636, Top 70th Acc: 0.4286, Bottom 30th Acc: 0.2121
Fold [3/5] Epoch [10/100] Initial Loss: 0.1411, Training Loss: 0.0424, Initial Validation Loss: 0.1341, Validation Loss: 0.0492,V Acc: 0.7909, Top 70th Acc: 0.8701, Bottom 30th Acc: 0.6061
Fold [3/5] Epoch [20/100] Initial Loss: 0.1411, Training Loss: 0.0269, Initial Validation Loss: 0.1341, Validation Loss: 0.0371,V Acc: 0.8455, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.6667
Fold [3/5] Epoch [30/100] Initial Loss: 0.1411, Training Loss: 0.0210, Initial Validation Loss: 0.1341, Validation Loss: 0.0322,V Acc: 0.8545, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 38  Rolling back to Epoch (base 0): 33  Top Validation Acc: 0.948051948051948
Fold [4/5] Epoch [0/100] Initial Loss: 0.1414, Training Loss: 0.1414, Initial Validation Loss: 0.1348, Validation Loss: 0.1348,V Acc: 0.2545, Top 70th Acc: 0.2208, Bottom 30th Acc: 0.3333
Fold [4/5] Epoch [10/100] Initial Loss: 0.1414, Training Loss: 0.0340, Initial Validation Loss: 0.1348, Validation Loss: 0.0421,V Acc: 0.8091, Top 70th Acc: 0.8701, Bottom 30th Acc: 0.6667
Fold [4/5] Epoch [20/100] Initial Loss: 0.1414, Training Loss: 0.0205, Initial Validation Loss: 0.1348, Validation Loss: 0.0361,V Acc: 0.8000, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 27  Rolling back to Epoch (base 0): 22  Top Validation Acc: 0.8701298701298701
Fold [5/5] Epoch [0/100] Initial Loss: 0.1403, Training Loss: 0.1403, Initial Validation Loss: 0.1308, Validation Loss: 0.1308,V Acc: 0.3981, Top 70th Acc: 0.5000, Bottom 30th Acc: 0.1562
Fold [5/5] Epoch [10/100] Initial Loss: 0.1403, Training Loss: 0.0324, Initial Validation Loss: 0.1308, Validation Loss: 0.0374,V Acc: 0.8426, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.6250 12  Top Validation Acc: 1.0
Fold [5/5] Epoch [0/100] Initial Loss: 0.1295, Training Loss: 0.1295, Initial Validation Loss: 0.1117, Validation Loss: 0.1117,V Acc: 0.4444, Top 70th Acc: 0.5132, Bottom 30th Acc: 0.2812
Fold [5/5] Epoch [10/100] Initial Loss: 0.1295, Training Loss: 0.0239, Initial Validation Loss: 0.1117, Validation Loss: 0.0297,V Acc: 0.8519, Top 70th Acc: 0.9737, Bottom 30th Acc: 0.5625
Fold [5/5] Epoch [20/100] Initial Loss: 0.1295, Training Loss: 0.0165, Initial Validation Loss: 0.1117, Validation Loss: 0.0236,V Acc: 0.8889, Top 70th Acc: 0.9737, Bottom 30th Acc: 0.6875
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.9605263157894737
91 4 [array([0.78571236, 0.02569006, 0.03876181, 0.04766928, 0.10216644],
      dtype=float32)]
Running train_nn.py with seed 92
CUDA:False
Training samples count:  550
Training on 21 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1378, Training Loss: 0.1378, Initial Validation Loss: 0.1252, Validation Loss: 0.1252,V Acc: 0.2973, Top 70th Acc: 0.3974, Bottom 30th Acc: 0.0606
Fold [1/5] Epoch [10/100] Initial Loss: 0.1378, Training Loss: 0.0266, Initial Validation Loss: 0.1252, Validation Loss: 0.0289,V Acc: 0.8378, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.5758
Fold [1/5] Epoch [20/100] Initial Loss: 0.1378, Training Loss: 0.0182, Initial Validation Loss: 0.1252, Validation Loss: 0.0249,V Acc: 0.8739, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.9487179487179487
92 0 [array([0.7150581 , 0.0127572 , 0.040833  , 0.15563825, 0.07571355],
      dtype=float32)]
Fold [2/5] Epoch [0/100] Initial Loss: 0.1371, Training Loss: 0.1371, Initial Validation Loss: 0.1260, Validation Loss: 0.1260,V Acc: 0.5315, Top 70th Acc: 0.6410, Bottom 30th Acc: 0.2727
Fold [2/5] Epoch [10/100] Initial Loss: 0.1371, Training Loss: 0.0231, Initial Validation Loss: 0.1260, Validation Loss: 0.0283,V Acc: 0.8288, Top 70th Acc: 1.0000, Bottom 30th Acc: 0.4242
Stopping early at Epoch (base 0): 18  Rolling back to Epoch (base 0): 13  Top Validation Acc: 0.9871794871794872
Fold [3/5] Epoch [0/100] Initial Loss: 0.1310, Training Loss: 0.1310, Initial Validation Loss: 0.1154, Validation Loss: 0.1154,V Acc: 0.4909, Top 70th Acc: 0.6104, Bottom 30th Acc: 0.2121
Fold [3/5] Epoch [10/100] Initial Loss: 0.1310, Training Loss: 0.0270, Initial Validation Loss: 0.1154, Validation Loss: 0.0302,V Acc: 0.8455, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 17  Rolling back to Epoch (base 0): 12  Top Validation Acc: 0.961038961038961
Fold [4/5] Epoch [0/100] Initial Loss: 0.1311, Training Loss: 0.1311, Initial Validation Loss: 0.1238, Validation Loss: 0.1238,V Acc: 0.4000, Top 70th Acc: 0.5065, Bottom 30th Acc: 0.1515
Fold [4/5] Epoch [10/100] Initial Loss: 0.1311, Training Loss: 0.0235, Initial Validation Loss: 0.1238, Validation Loss: 0.0398,V Acc: 0.8091, Top 70th Acc: 0.8961, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 19  Rolling back to Epoch (base 0): 14  Top Validation Acc: 0.935064935064935
Fold [5/5] Epoch [0/100] Initial Loss: 0.1336, Training Loss: 0.1336, Initial Validation Loss: 0.1255, Validation Loss: 0.1255,V Acc: 0.4630, Top 70th Acc: 0.5658, Bottom 30th Acc: 0.2188
Fold [5/5] Epoch [10/100] Initial Loss: 0.1336, Training Loss: 0.0235, Initial Validation Loss: 0.1255, Validation Loss: 0.0299,V Acc: 0.8889, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.7188
Stopping early at Epoch (base 0): 16  Rolling back to Epoch (base 0): 11  Top Validation Acc: 0.9605263157894737
Running train_nn.py with seed 93
CUDA:False
Training samples count:  550
Training on 21 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1413, Training Loss: 0.1413, Initial Validation Loss: 0.1271, Validation Loss: 0.1271,V Acc: 0.5676, Top 70th Acc: 0.6282, Bottom 30th Acc: 0.4242
Fold [1/5] Epoch [10/100] Initial Loss: 0.1413, Training Loss: 0.0272, Initial Validation Loss: 0.1271, Validation Loss: 0.0355,V Acc: 0.8468, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.6970
Fold [1/5] Epoch [20/100] Initial Loss: 0.1413, Training Loss: 0.0162, Initial Validation Loss: 0.1271, Validation Loss: 0.0298,V Acc: 0.8378, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 22  Rolling back to Epoch (base 0): 17  Top Validation Acc: 0.9102564102564102
Fold [2/5] Epoch [0/100] Initial Loss: 0.1396, Training Loss: 0.1396, Initial Validation Loss: 0.1360, Validation Loss: 0.1360,V Acc: 0.3514, Top 70th Acc: 0.4103, Bottom 30th Acc: 0.2121
Fold [2/5] Epoch [10/100] Initial Loss: 0.1396, Training Loss: 0.0279, Initial Validation Loss: 0.1360, Validation Loss: 0.0343,V Acc: 0.8468, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.6061
Fold [2/5] Epoch [20/100] Initial Loss: 0.1396, Training Loss: 0.0184, Initial Validation Loss: 0.1360, Validation Loss: 0.0273,V Acc: 0.8559, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 28  Rolling back to Epoch (base 0): 23  Top Validation Acc: 0.9615384615384616
Fold [3/5] Epoch [0/100] Initial Loss: 0.1367, Training Loss: 0.1367, Initial Validation Loss: 0.1276, Validation Loss: 0.1276,V Acc: 0.3818, Top 70th Acc: 0.4286, Bottom 30th Acc: 0.2727
Fold [3/5] Epoch [10/100] Initial Loss: 0.1367, Training Loss: 0.0244, Initial Validation Loss: 0.1276, Validation Loss: 0.0296,V Acc: 0.8364, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.5152
Fold [3/5] Epoch [20/100] Initial Loss: 0.1367, Training Loss: 0.0178, Initial Validation Loss: 0.1276, Validation Loss: 0.0247,V Acc: 0.8818, Top 70th Acc: 1.0000, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 29  Rolling back to Epoch (base 0): 24  Top Validation Acc: 0.987012987012987
Fold [4/5] Epoch [0/100] Initial Loss: 0.1276, Training Loss: 0.1276, Initial Validation Loss: 0.1172, Validation Loss: 0.1172,V Acc: 0.5636, Top 70th Acc: 0.7143, Bottom 30th Acc: 0.2121
Fold [4/5] Epoch [10/100] Initial Loss: 0.1276, Training Loss: 0.0235, Initial Validation Loss: 0.1172, Validation Loss: 0.0371,V Acc: 0.8273, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.5758
Fold [4/5] Epoch [20/100] Initial Loss: 0.1276, Training Loss: 0.0160, Initial Validation Loss: 0.1172, Validation Loss: 0.0276,V Acc: 0.8909, Top 70th Acc: 0.9870, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.961038961038961
Fold [5/5] Epoch [0/100] Initial Loss: 0.1348, Training Loss: 0.1348, Initial Validation Loss: 0.1160, Validation Loss: 0.1160,V Acc: 0.4167, Top 70th Acc: 0.5132, Bottom 30th Acc: 0.1875
Fold [5/5] Epoch [10/100] Initial Loss: 0.1348, Training Loss: 0.0279, Initial Validation Loss: 0.1160, Validation Loss: 0.0314,V Acc: 0.8333, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.5938
Fold [5/5] Epoch [20/100] Initial Loss: 0.1348, Training Loss: 0.0195, Initial Validation Loss: 0.1160, Validation Loss: 0.0229,V Acc: 0.8704, Top 70th Acc: 0.9737, Bottom 30th Acc: 0.6250
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.9736842105263158
93 4 [array([0.7826561 , 0.02282999, 0.02044187, 0.07494923, 0.09912279],
      dtype=float32)]
Running train_nn.py with seed 94
CUDA:False
Training samples count:  550
Training on 21 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1316, Training Loss: 0.1316, Initial Validation Loss: 0.1221, Validation Loss: 0.1221,V Acc: 0.4234, Top 70th Acc: 0.5000, Bottom 30th Acc: 0.2424
Fold [1/5] Epoch [10/100] Initial Loss: 0.1316, Training Loss: 0.0230, Initial Validation Loss: 0.1221, Validation Loss: 0.0374,V Acc: 0.8018, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.4545
Stopping early at Epoch (base 0): 17  Rolling back to Epoch (base 0): 12  Top Validation Acc: 0.9230769230769231
Fold [2/5] Epoch [0/100] Initial Loss: 0.1336, Training Loss: 0.1336, Initial Validation Loss: 0.1211, Validation Loss: 0.1211,V Acc: 0.5405, Top 70th Acc: 0.6154, Bottom 30th Acc: 0.3636
Fold [2/5] Epoch [10/100] Initial Loss: 0.1336, Training Loss: 0.0258, Initial Validation Loss: 0.1211, Validation Loss: 0.0239,V Acc: 0.9099, Top 70th Acc: 0.9872, Bottom 30th Acc: 0.7273
Fold [2/5] Epoch [20/100] Initial Loss: 0.1336, Training Loss: 0.0184, Initial Validation Loss: 0.1211, Validation Loss: 0.0194,V Acc: 0.9099, Top 70th Acc: 0.9872, Bottom 30th Acc: 0.7273
Fold [4/5] Epoch [10/100] Initial Loss: 0.1347, Training Loss: 0.0807, Initial Validation Loss: 0.1300, Validation Loss: 0.0779,V Acc: 0.6273, Top 70th Acc: 0.7273, Bottom 30th Acc: 0.3939
Fold [4/5] Epoch [20/100] Initial Loss: 0.1347, Training Loss: 0.0788, Initial Validation Loss: 0.1300, Validation Loss: 0.0771,V Acc: 0.6455, Top 70th Acc: 0.7143, Bottom 30th Acc: 0.4848
Stopping early at Epoch (base 0): 21  Rolling back to Epoch (base 0): 16  Top Validation Acc: 0.7012987012987013
Fold [5/5] Epoch [0/100] Initial Loss: 0.1328, Training Loss: 0.1328, Initial Validation Loss: 0.1184, Validation Loss: 0.1184,V Acc: 0.4259, Top 70th Acc: 0.5000, Bottom 30th Acc: 0.2500
Fold [5/5] Epoch [10/100] Initial Loss: 0.1328, Training Loss: 0.0796, Initial Validation Loss: 0.1184, Validation Loss: 0.0827,V Acc: 0.5648, Top 70th Acc: 0.6974, Bottom 30th Acc: 0.2500
Fold [5/5] Epoch [20/100] Initial Loss: 0.1328, Training Loss: 0.0779, Initial Validation Loss: 0.1184, Validation Loss: 0.0815,V Acc: 0.5648, Top 70th Acc: 0.6974, Bottom 30th Acc: 0.2500
Fold [5/5] Epoch [30/100] Initial Loss: 0.1328, Training Loss: 0.0772, Initial Validation Loss: 0.1184, Validation Loss: 0.0810,V Acc: 0.5741, Top 70th Acc: 0.7105, Bottom 30th Acc: 0.2500
Stopping early at Epoch (base 0): 30  Rolling back to Epoch (base 0): 25  Top Validation Acc: 0.7105263157894737
61 4 [array([0.1478756 , 0.37027347, 0.10578931, 0.24272366, 0.13333786],
      dtype=float32)]
Running train_nn.py with seed 62
CUDA:False
Training samples count:  550
Training on 2 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1370, Training Loss: 0.1370, Initial Validation Loss: 0.1325, Validation Loss: 0.1325,V Acc: 0.2523, Top 70th Acc: 0.3590, Bottom 30th Acc: 0.0000
Fold [1/5] Epoch [10/100] Initial Loss: 0.1370, Training Loss: 0.0794, Initial Validation Loss: 0.1325, Validation Loss: 0.0855,V Acc: 0.6036, Top 70th Acc: 0.6923, Bottom 30th Acc: 0.3939
Fold [1/5] Epoch [20/100] Initial Loss: 0.1370, Training Loss: 0.0771, Initial Validation Loss: 0.1325, Validation Loss: 0.0844,V Acc: 0.6126, Top 70th Acc: 0.7051, Bottom 30th Acc: 0.3939
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.717948717948718
Fold [2/5] Epoch [0/100] Initial Loss: 0.1336, Training Loss: 0.1336, Initial Validation Loss: 0.1190, Validation Loss: 0.1190,V Acc: 0.4685, Top 70th Acc: 0.5641, Bottom 30th Acc: 0.2424
Fold [2/5] Epoch [10/100] Initial Loss: 0.1336, Training Loss: 0.0802, Initial Validation Loss: 0.1190, Validation Loss: 0.0821,V Acc: 0.5946, Top 70th Acc: 0.6795, Bottom 30th Acc: 0.3939
Fold [2/5] Epoch [20/100] Initial Loss: 0.1336, Training Loss: 0.0782, Initial Validation Loss: 0.1190, Validation Loss: 0.0797,V Acc: 0.6036, Top 70th Acc: 0.7179, Bottom 30th Acc: 0.3333
Fold [2/5] Epoch [30/100] Initial Loss: 0.1336, Training Loss: 0.0774, Initial Validation Loss: 0.1190, Validation Loss: 0.0796,V Acc: 0.6036, Top 70th Acc: 0.7051, Bottom 30th Acc: 0.3636
Stopping early at Epoch (base 0): 31  Rolling back to Epoch (base 0): 26  Top Validation Acc: 0.717948717948718
62 1 [array([0.13419458, 0.33621803, 0.14051309, 0.25346863, 0.1356057 ],
      dtype=float32)]
Fold [3/5] Epoch [0/100] Initial Loss: 0.1392, Training Loss: 0.1392, Initial Validation Loss: 0.1295, Validation Loss: 0.1295,V Acc: 0.2727, Top 70th Acc: 0.3636, Bottom 30th Acc: 0.0606
Fold [3/5] Epoch [10/100] Initial Loss: 0.1392, Training Loss: 0.0799, Initial Validation Loss: 0.1295, Validation Loss: 0.0852,V Acc: 0.6000, Top 70th Acc: 0.7662, Bottom 30th Acc: 0.2121
Fold [3/5] Epoch [20/100] Initial Loss: 0.1392, Training Loss: 0.0776, Initial Validation Loss: 0.1295, Validation Loss: 0.0832,V Acc: 0.6545, Top 70th Acc: 0.7792, Bottom 30th Acc: 0.3636
Fold [3/5] Epoch [30/100] Initial Loss: 0.1392, Training Loss: 0.0769, Initial Validation Loss: 0.1295, Validation Loss: 0.0825,V Acc: 0.6364, Top 70th Acc: 0.7792, Bottom 30th Acc: 0.3030
Fold [3/5] Epoch [40/100] Initial Loss: 0.1392, Training Loss: 0.0762, Initial Validation Loss: 0.1295, Validation Loss: 0.0816,V Acc: 0.6545, Top 70th Acc: 0.7922, Bottom 30th Acc: 0.3333
Stopping early at Epoch (base 0): 45  Rolling back to Epoch (base 0): 40  Top Validation Acc: 0.7792207792207793
Fold [4/5] Epoch [0/100] Initial Loss: 0.1397, Training Loss: 0.1397, Initial Validation Loss: 0.1294, Validation Loss: 0.1294,V Acc: 0.3000, Top 70th Acc: 0.3636, Bottom 30th Acc: 0.1515
Fold [4/5] Epoch [10/100] Initial Loss: 0.1397, Training Loss: 0.0833, Initial Validation Loss: 0.1294, Validation Loss: 0.0752,V Acc: 0.6364, Top 70th Acc: 0.7273, Bottom 30th Acc: 0.4242
Fold [4/5] Epoch [20/100] Initial Loss: 0.1397, Training Loss: 0.0806, Initial Validation Loss: 0.1294, Validation Loss: 0.0739,V Acc: 0.6273, Top 70th Acc: 0.7273, Bottom 30th Acc: 0.3939
Fold [4/5] Epoch [30/100] Initial Loss: 0.1397, Training Loss: 0.0801, Initial Validation Loss: 0.1294, Validation Loss: 0.0725,V Acc: 0.6545, Top 70th Acc: 0.7403, Bottom 30th Acc: 0.4545
Stopping early at Epoch (base 0): 34  Rolling back to Epoch (base 0): 29  Top Validation Acc: 0.7402597402597403
Fold [5/5] Epoch [0/100] Initial Loss: 0.1395, Training Loss: 0.1395, Initial Validation Loss: 0.1350, Validation Loss: 0.1350,V Acc: 0.4907, Top 70th Acc: 0.5263, Bottom 30th Acc: 0.4062
Fold [5/5] Epoch [10/100] Initial Loss: 0.1395, Training Loss: 0.0828, Initial Validation Loss: 0.1350, Validation Loss: 0.0763,V Acc: 0.6296, Top 70th Acc: 0.7632, Bottom 30th Acc: 0.3125
Fold [5/5] Epoch [20/100] Initial Loss: 0.1395, Training Loss: 0.0798, Initial Validation Loss: 0.1350, Validation Loss: 0.0723,V Acc: 0.6759, Top 70th Acc: 0.8026, Bottom 30th Acc: 0.3750
Fold [5/5] Epoch [30/100] Initial Loss: 0.1395, Training Loss: 0.0793, Initial Validation Loss: 0.1350, Validation Loss: 0.0720,V Acc: 0.6759, Top 70th Acc: 0.7632, Bottom 30th Acc: 0.4688
Stopping early at Epoch (base 0): 33  Rolling back to Epoch (base 0): 28  Top Validation Acc: 0.7763157894736842
Running train_nn.py with seed 63
CUDA:False
Training samples count:  550
Training on 2 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1347, Training Loss: 0.1347, Initial Validation Loss: 0.1319, Validation Loss: 0.1319,V Acc: 0.3874, Top 70th Acc: 0.3590, Bottom 30th Acc: 0.4545
Fold [1/5] Epoch [10/100] Initial Loss: 0.1347, Training Loss: 0.0814, Initial Validation Loss: 0.1319, Validation Loss: 0.0768,V Acc: 0.6667, Top 70th Acc: 0.7564, Bottom 30th Acc: 0.4545
Fold [1/5] Epoch [20/100] Initial Loss: 0.1347, Training Loss: 0.0787, Initial Validation Loss: 0.1319, Validation Loss: 0.0747,V Acc: 0.6847, Top 70th Acc: 0.7821, Bottom 30th Acc: 0.4545
Stopping early at Epoch (base 0): 27  Rolling back to Epoch (base 0): 22  Top Validation Acc: 0.7564102564102564
Fold [2/5] Epoch [0/100] Initial Loss: 0.1316, Training Loss: 0.1316, Initial Validation Loss: 0.1190, Validation Loss: 0.1190,V Acc: 0.5405, Top 70th Acc: 0.6410, Bottom 30th Acc: 0.3030
Fold [2/5] Epoch [10/100] Initial Loss: 0.1316, Training Loss: 0.0800, Initial Validation Loss: 0.1190, Validation Loss: 0.0798,V Acc: 0.5946, Top 70th Acc: 0.7436, Bottom 30th Acc: 0.2424
Fold [2/5] Epoch [20/100] Initial Loss: 0.1316, Training Loss: 0.0786, Initial Validation Loss: 0.1190, Validation Loss: 0.0785,V Acc: 0.5856, Top 70th Acc: 0.7179, Bottom 30th Acc: 0.2727
Fold [2/5] Epoch [30/100] Initial Loss: 0.1316, Training Loss: 0.0780, Initial Validation Loss: 0.1190, Validation Loss: 0.0782,V Acc: 0.5946, Top 70th Acc: 0.7436, Bottom 30th Acc: 0.2424
Fold [2/5] Epoch [40/100] Initial Loss: 0.1316, Training Loss: 0.0774, Initial Validation Loss: 0.1190, Validation Loss: 0.0779,V Acc: 0.5856, Top 70th Acc: 0.7436, Bottom 30th Acc: 0.2121
Stopping early at Epoch (base 0): 42  Rolling back to Epoch (base 0): 37  Top Validation Acc: 0.7051282051282052
Fold [3/5] Epoch [0/100] Initial Loss: 0.1394, Training Loss: 0.1394, Initial Validation Loss: 0.1298, Validation Loss: 0.1298,V Acc: 0.3091, Top 70th Acc: 0.3247, Bottom 30th Acc: 0.2727
Fold [3/5] Epoch [10/100] Initial Loss: 0.1394, Training Loss: 0.0815, Initial Validation Loss: 0.1298, Validation Loss: 0.0801,V Acc: 0.6091, Top 70th Acc: 0.7143, Bottom 30th Acc: 0.3636
Fold [4/5] Epoch [20/100] Initial Loss: 0.1433, Training Loss: 0.0234, Initial Validation Loss: 0.1355, Validation Loss: 0.0456,V Acc: 0.7545, Top 70th Acc: 0.8831, Bottom 30th Acc: 0.4545
Stopping early at Epoch (base 0): 22  Rolling back to Epoch (base 0): 17  Top Validation Acc: 0.8831168831168831
Fold [5/5] Epoch [0/100] Initial Loss: 0.1406, Training Loss: 0.1406, Initial Validation Loss: 0.1333, Validation Loss: 0.1333,V Acc: 0.2500, Top 70th Acc: 0.3421, Bottom 30th Acc: 0.0312
Fold [5/5] Epoch [10/100] Initial Loss: 0.1406, Training Loss: 0.0345, Initial Validation Loss: 0.1333, Validation Loss: 0.0372,V Acc: 0.8148, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.5312
Fold [5/5] Epoch [20/100] Initial Loss: 0.1406, Training Loss: 0.0186, Initial Validation Loss: 0.1333, Validation Loss: 0.0293,V Acc: 0.8519, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.6562
Stopping early at Epoch (base 0): 28  Rolling back to Epoch (base 0): 23  Top Validation Acc: 0.9342105263157895
Running train_nn.py with seed 66
CUDA:False
Training samples count:  550
Training on 30 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1412, Training Loss: 0.1412, Initial Validation Loss: 0.1376, Validation Loss: 0.1376,V Acc: 0.3423, Top 70th Acc: 0.3974, Bottom 30th Acc: 0.2121
Fold [1/5] Epoch [10/100] Initial Loss: 0.1412, Training Loss: 0.0279, Initial Validation Loss: 0.1376, Validation Loss: 0.0386,V Acc: 0.8288, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.5455
Fold [1/5] Epoch [20/100] Initial Loss: 0.1412, Training Loss: 0.0187, Initial Validation Loss: 0.1376, Validation Loss: 0.0335,V Acc: 0.8559, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.9487179487179487
Fold [2/5] Epoch [0/100] Initial Loss: 0.1366, Training Loss: 0.1366, Initial Validation Loss: 0.1342, Validation Loss: 0.1342,V Acc: 0.2703, Top 70th Acc: 0.3590, Bottom 30th Acc: 0.0606
Fold [2/5] Epoch [10/100] Initial Loss: 0.1366, Training Loss: 0.0309, Initial Validation Loss: 0.1342, Validation Loss: 0.0446,V Acc: 0.7928, Top 70th Acc: 0.8974, Bottom 30th Acc: 0.5455
Fold [2/5] Epoch [20/100] Initial Loss: 0.1366, Training Loss: 0.0173, Initial Validation Loss: 0.1342, Validation Loss: 0.0360,V Acc: 0.8378, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.9102564102564102
Fold [3/5] Epoch [0/100] Initial Loss: 0.1358, Training Loss: 0.1358, Initial Validation Loss: 0.1233, Validation Loss: 0.1233,V Acc: 0.4091, Top 70th Acc: 0.5325, Bottom 30th Acc: 0.1212
Fold [3/5] Epoch [10/100] Initial Loss: 0.1358, Training Loss: 0.0292, Initial Validation Loss: 0.1233, Validation Loss: 0.0343,V Acc: 0.8182, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 18  Rolling back to Epoch (base 0): 13  Top Validation Acc: 0.9090909090909091
Fold [4/5] Epoch [0/100] Initial Loss: 0.1365, Training Loss: 0.1365, Initial Validation Loss: 0.1363, Validation Loss: 0.1363,V Acc: 0.3545, Top 70th Acc: 0.4156, Bottom 30th Acc: 0.2121
Fold [4/5] Epoch [10/100] Initial Loss: 0.1365, Training Loss: 0.0406, Initial Validation Loss: 0.1363, Validation Loss: 0.0399,V Acc: 0.8273, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.5758
Fold [4/5] Epoch [20/100] Initial Loss: 0.1365, Training Loss: 0.0193, Initial Validation Loss: 0.1363, Validation Loss: 0.0279,V Acc: 0.8818, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.961038961038961
66 3 [array([0.53976566, 0.16440333, 0.04197121, 0.12643175, 0.12742804],
      dtype=float32)]
Fold [5/5] Epoch [0/100] Initial Loss: 0.1378, Training Loss: 0.1378, Initial Validation Loss: 0.1288, Validation Loss: 0.1288,V Acc: 0.3056, Top 70th Acc: 0.3816, Bottom 30th Acc: 0.1250
Fold [5/5] Epoch [10/100] Initial Loss: 0.1378, Training Loss: 0.0428, Initial Validation Loss: 0.1288, Validation Loss: 0.0550,V Acc: 0.7500, Top 70th Acc: 0.8553, Bottom 30th Acc: 0.5000
Fold [5/5] Epoch [20/100] Initial Loss: 0.1378, Training Loss: 0.0183, Initial Validation Loss: 0.1288, Validation Loss: 0.0365,V Acc: 0.8333, Top 70th Acc: 0.9211, Bottom 30th Acc: 0.6250
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.9210526315789473
Running train_nn.py with seed 67
CUDA:False
Training samples count:  550
Training on 30 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1371, Training Loss: 0.1371, Initial Validation Loss: 0.1296, Validation Loss: 0.1296,V Acc: 0.3423, Top 70th Acc: 0.4231, Bottom 30th Acc: 0.1515
Fold [1/5] Epoch [10/100] Initial Loss: 0.1371, Training Loss: 0.0353, Initial Validation Loss: 0.1296, Validation Loss: 0.0414,V Acc: 0.8018, Top 70th Acc: 0.8974, Bottom 30th Acc: 0.5758
Fold [1/5] Epoch [20/100] Initial Loss: 0.1371, Training Loss: 0.0168, Initial Validation Loss: 0.1296, Validation Loss: 0.0359,V Acc: 0.8198, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 22  Rolling back to Epoch (base 0): 17  Top Validation Acc: 0.9358974358974359
67 0 [array([0.6610477 , 0.10887051, 0.02225143, 0.04692322, 0.16090707],
      dtype=float32)]
Fold [2/5] Epoch [0/100] Initial Loss: 0.1387, Training Loss: 0.1387, Initial Validation Loss: 0.1331, Validation Loss: 0.1331,V Acc: 0.2523, Top 70th Acc: 0.3205, Bottom 30th Acc: 0.0909
Fold [2/5] Epoch [10/100] Initial Loss: 0.1387, Training Loss: 0.0328, Initial Validation Loss: 0.1331, Validation Loss: 0.0378,V Acc: 0.7928, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.4545
Fold [2/5] Epoch [20/100] Initial Loss: 0.1387, Training Loss: 0.0176, Initial Validation Loss: 0.1331, Validation Loss: 0.0248,V Acc: 0.8649, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.9487179487179487
Fold [3/5] Epoch [0/100] Initial Loss: 0.1390, Training Loss: 0.1390, Initial Validation Loss: 0.1350, Validation Loss: 0.1350,V Acc: 0.2545, Top 70th Acc: 0.3377, Bottom 30th Acc: 0.0606
Fold [3/5] Epoch [10/100] Initial Loss: 0.1390, Training Loss: 0.0360, Initial Validation Loss: 0.1350, Validation Loss: 0.0425,V Acc: 0.8273, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.6061
Fold [3/5] Epoch [20/100] Initial Loss: 0.1390, Training Loss: 0.0218, Initial Validation Loss: 0.1350, Validation Loss: 0.0292,V Acc: 0.8818, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.6667
Fold [3/5] Epoch [30/100] Initial Loss: 0.1390, Training Loss: 0.0162, Initial Validation Loss: 0.1350, Validation Loss: 0.0249,V Acc: 0.8818, Top 70th Acc: 0.9870, Bottom 30th Acc: 0.6364
Fold [3/5] Epoch [40/100] Initial Loss: 0.1390, Training Loss: 0.0143, Initial Validation Loss: 0.1350, Validation Loss: 0.0250,V Acc: 0.8818, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 42  Rolling back to Epoch (base 0): 37  Top Validation Acc: 0.987012987012987
Fold [4/5] Epoch [0/100] Initial Loss: 0.1406, Training Loss: 0.1406, Initial Validation Loss: 0.1320, Validation Loss: 0.1320,V Acc: 0.4091, Top 70th Acc: 0.4545, Bottom 30th Acc: 0.3030
Fold [4/5] Epoch [10/100] Initial Loss: 0.1406, Training Loss: 0.0374, Initial Validation Loss: 0.1320, Validation Loss: 0.0464,V Acc: 0.7636, Top 70th Acc: 0.8571, Bottom 30th Acc: 0.5455
Fold [4/5] Epoch [20/100] Initial Loss: 0.1406, Training Loss: 0.0159, Initial Validation Loss: 0.1320, Validation Loss: 0.0359,V Acc: 0.7909, Top 70th Acc: 0.8961, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.8961038961038961
Fold [5/5] Epoch [0/100] Initial Loss: 0.1377, Training Loss: 0.1377, Initial Validation Loss: 0.1343, Validation Loss: 0.1343,V Acc: 0.3981, Top 70th Acc: 0.5000, Bottom 30th Acc: 0.1562
Fold [5/5] Epoch [10/100] Initial Loss: 0.1377, Training Loss: 0.0410, Initial Validation Loss: 0.1343, Validation Loss: 0.0422,V Acc: 0.8056, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.5000
Fold [5/5] Epoch [20/100] Initial Loss: 0.1377, Training Loss: 0.0185, Initial Validation Loss: 0.1343, Validation Loss: 0.0252,V Acc: 0.8704, Top 70th Acc: 0.9868, Bottom 30th Acc: 0.5938
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 40 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 91
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 40 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 92
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 40 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 93
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 40 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 94
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 40 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 95
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 40 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 96
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 40 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 97
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 40 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 98
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 40 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 99
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 40 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5
training rf with seed 100
Training size: 439
Training size: 439
Training size: 440
Training size: 440
Training size: 442
Training on 40 features
Fold: 1
Fold: 2
Fold: 3
Fold: 4
Fold: 5

Fold [3/5] Epoch [20/100] Initial Loss: 0.1387, Training Loss: 0.0051, Initial Validation Loss: 0.1360, Validation Loss: 0.0305,V Acc: 0.8455, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.974025974025974
Fold [4/5] Epoch [0/100] Initial Loss: 0.1382, Training Loss: 0.1382, Initial Validation Loss: 0.1250, Validation Loss: 0.1250,V Acc: 0.5455, Top 70th Acc: 0.6364, Bottom 30th Acc: 0.3333
Fold [4/5] Epoch [10/100] Initial Loss: 0.1382, Training Loss: 0.0177, Initial Validation Loss: 0.1250, Validation Loss: 0.0315,V Acc: 0.8455, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6061
Fold [4/5] Epoch [20/100] Initial Loss: 0.1382, Training Loss: 0.0044, Initial Validation Loss: 0.1250, Validation Loss: 0.0228,V Acc: 0.8727, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.974025974025974
Fold [5/5] Epoch [0/100] Initial Loss: 0.1393, Training Loss: 0.1393, Initial Validation Loss: 0.1296, Validation Loss: 0.1296,V Acc: 0.2870, Top 70th Acc: 0.3289, Bottom 30th Acc: 0.1875
Fold [5/5] Epoch [10/100] Initial Loss: 0.1393, Training Loss: 0.0198, Initial Validation Loss: 0.1296, Validation Loss: 0.0332,V Acc: 0.8981, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.7812
Fold [5/5] Epoch [20/100] Initial Loss: 0.1393, Training Loss: 0.0047, Initial Validation Loss: 0.1296, Validation Loss: 0.0267,V Acc: 0.8704, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.6875
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.9473684210526315
50 4 [array([0.21784289, 0.06123544, 0.06081738, 0.31092638, 0.34917787],
      dtype=float32)]
Running train_nn.py with seed 51
CUDA:False
Training samples count:  550
Training on 163 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1374, Training Loss: 0.1374, Initial Validation Loss: 0.1322, Validation Loss: 0.1322,V Acc: 0.2793, Top 70th Acc: 0.3590, Bottom 30th Acc: 0.0909
Fold [1/5] Epoch [10/100] Initial Loss: 0.1374, Training Loss: 0.0136, Initial Validation Loss: 0.1322, Validation Loss: 0.0346,V Acc: 0.8559, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.6667
Fold [1/5] Epoch [20/100] Initial Loss: 0.1374, Training Loss: 0.0047, Initial Validation Loss: 0.1322, Validation Loss: 0.0294,V Acc: 0.8919, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.7576
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.9487179487179487
51 0 [array([0.23798622, 0.08120961, 0.04687067, 0.14295651, 0.49097705],
      dtype=float32)]
Fold [2/5] Epoch [0/100] Initial Loss: 0.1400, Training Loss: 0.1400, Initial Validation Loss: 0.1325, Validation Loss: 0.1325,V Acc: 0.3423, Top 70th Acc: 0.4103, Bottom 30th Acc: 0.1818
Fold [2/5] Epoch [10/100] Initial Loss: 0.1400, Training Loss: 0.0241, Initial Validation Loss: 0.1325, Validation Loss: 0.0357,V Acc: 0.8739, Top 70th Acc: 0.8974, Bottom 30th Acc: 0.8182
Fold [2/5] Epoch [20/100] Initial Loss: 0.1400, Training Loss: 0.0057, Initial Validation Loss: 0.1325, Validation Loss: 0.0297,V Acc: 0.8378, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.9358974358974359
Fold [3/5] Epoch [0/100] Initial Loss: 0.1376, Training Loss: 0.1376, Initial Validation Loss: 0.1354, Validation Loss: 0.1354,V Acc: 0.2545, Top 70th Acc: 0.3377, Bottom 30th Acc: 0.0606
Fold [3/5] Epoch [10/100] Initial Loss: 0.1376, Training Loss: 0.0160, Initial Validation Loss: 0.1354, Validation Loss: 0.0322,V Acc: 0.8273, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.4848
Fold [3/5] Epoch [20/100] Initial Loss: 0.1376, Training Loss: 0.0053, Initial Validation Loss: 0.1354, Validation Loss: 0.0257,V Acc: 0.8636, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 29  Rolling back to Epoch (base 0): 24  Top Validation Acc: 0.987012987012987
Fold [4/5] Epoch [0/100] Initial Loss: 0.1404, Training Loss: 0.1404, Initial Validation Loss: 0.1330, Validation Loss: 0.1330,V Acc: 0.2727, Top 70th Acc: 0.3377, Bottom 30th Acc: 0.1212
Fold [4/5] Epoch [10/100] Initial Loss: 0.1404, Training Loss: 0.0143, Initial Validation Loss: 0.1330, Validation Loss: 0.0342,V Acc: 0.8545, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.6667
Fold [4/5] Epoch [20/100] Initial Loss: 0.1404, Training Loss: 0.0047, Initial Validation Loss: 0.1330, Validation Loss: 0.0297,V Acc: 0.8636, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.935064935064935
Fold [5/5] Epoch [0/100] Initial Loss: 0.1372, Training Loss: 0.1372, Initial Validation Loss: 0.1364, Validation Loss: 0.1364,V Acc: 0.2500, Top 70th Acc: 0.3421, Bottom 30th Acc: 0.0312
Fold [5/5] Epoch [10/100] Initial Loss: 0.1372, Training Loss: 0.0118, Initial Validation Loss: 0.1364, Validation Loss: 0.0292,V Acc: 0.8981, Top 70th Acc: 0.9737, Bottom 30th Acc: 0.7188
Fold [5/5] Epoch [20/100] Initial Loss: 0.1372, Training Loss: 0.0050, Initial Validation Loss: 0.1364, Validation Loss: 0.0265,V Acc: 0.8981, Top 70th Acc: 0.9868, Bottom 30th Acc: 0.6875
Stopping early at Epoch (base 0): 22  Rolling back to Epoch (base 0): 17  Top Validation Acc: 0.9868421052631579
Running train_nn.py with seed 52
CUDA:False
Training samples count:  550
Training on 163 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1395, Training Loss: 0.1395, Initial Validation Loss: 0.1341, Validation Loss: 0.1341,V Acc: 0.2613, Top 70th Acc: 0.2564, Bottom 30th Acc: 0.2727
Fold [1/5] Epoch [10/100] Initial Loss: 0.1395, Training Loss: 0.0200, Initial Validation Loss: 0.1341, Validation Loss: 0.0347,V Acc: 0.8288, Top 70th Acc: 0.8974, Bottom 30th Acc: 0.6667
Fold [1/5] Epoch [20/100] Initial Loss: 0.1395, Training Loss: 0.0052, Initial Validation Loss: 0.1341, Validation Loss: 0.0261,V Acc: 0.8649, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.6970
Fold [1/5] Epoch [30/100] Initial Loss: 0.1395, Training Loss: 0.0040, Initial Validation Loss: 0.1341, Validation Loss: 0.0252,V Acc: 0.8739, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.6364
Fold [1/5] Epoch [40/100] Initial Loss: 0.1395, Training Loss: 0.0037, Initial Validation Loss: 0.1341, Validation Loss: 0.0251,V Acc: 0.8559, Top 70th Acc: 0.9872, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 46  Rolling back to Epoch (base 0): 41  Top Validation Acc: 0.9871794871794872
Fold [2/5] Epoch [0/100] Initial Loss: 0.1392, Training Loss: 0.1392, Initial Validation Loss: 0.1347, Validation Loss: 0.1347,V Acc: 0.2523, Top 70th Acc: 0.3333, Bottom 30th Acc: 0.0606
Fold [2/5] Epoch [10/100] Initial Loss: 0.1392, Training Loss: 0.0305, Initial Validation Loss: 0.1347, Validation Loss: 0.0508,V Acc: 0.7477, Top 70th Acc: 0.8718, Bottom 30th Acc: 0.4545
Fold [2/5] Epoch [20/100] Initial Loss: 0.1392, Training Loss: 0.0056, Initial Validation Loss: 0.1347, Validation Loss: 0.0349,V Acc: 0.7928, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.3939
Fold [2/5] Epoch [30/100] Initial Loss: 0.1392, Training Loss: 0.0038, Initial Validation Loss: 0.1347, Validation Loss: 0.0342,V Acc: 0.8018, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.4242
Stopping early at Epoch (base 0): 34  Rolling back to Epoch (base 0): 29  Top Validation Acc: 0.9615384615384616
Fold [3/5] Epoch [0/100] Initial Loss: 0.1388, Training Loss: 0.1388, Initial Validation Loss: 0.1370, Validation Loss: 0.1370,V Acc: 0.2909, Top 70th Acc: 0.2987, Bottom 30th Acc: 0.2727
Fold [3/5] Epoch [10/100] Initial Loss: 0.1388, Training Loss: 0.0311, Initial Validation Loss: 0.1370, Validation Loss: 0.0440,V Acc: 0.8182, Top 70th Acc: 0.8831, Bottom 30th Acc: 0.6667
Fold [3/5] Epoch [20/100] Initial Loss: 0.1388, Training Loss: 0.0055, Initial Validation Loss: 0.1370, Validation Loss: 0.0267,V Acc: 0.8909, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.7879
Fold [3/5] Epoch [30/100] Initial Loss: 0.1388, Training Loss: 0.0038, Initial Validation Loss: 0.1370, Validation Loss: 0.0267,V Acc: 0.8818, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.7576
Stopping early at Epoch (base 0): 31  Rolling back to Epoch (base 0): 26 
Stopping early at Epoch (base 0): 35  Rolling back to Epoch (base 0): 30  Top Validation Acc: 0.9605263157894737
Running train_nn.py with seed 66
CUDA:False
Training samples count:  550
Training on 40 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1370, Training Loss: 0.1370, Initial Validation Loss: 0.1380, Validation Loss: 0.1380,V Acc: 0.3514, Top 70th Acc: 0.4231, Bottom 30th Acc: 0.1818
Fold [1/5] Epoch [10/100] Initial Loss: 0.1370, Training Loss: 0.0383, Initial Validation Loss: 0.1380, Validation Loss: 0.0452,V Acc: 0.8198, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.6061
Fold [1/5] Epoch [20/100] Initial Loss: 0.1370, Training Loss: 0.0156, Initial Validation Loss: 0.1380, Validation Loss: 0.0295,V Acc: 0.8829, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.6667
Fold [1/5] Epoch [30/100] Initial Loss: 0.1370, Training Loss: 0.0125, Initial Validation Loss: 0.1380, Validation Loss: 0.0282,V Acc: 0.8649, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 33  Rolling back to Epoch (base 0): 28  Top Validation Acc: 0.9743589743589743
Fold [2/5] Epoch [0/100] Initial Loss: 0.1386, Training Loss: 0.1386, Initial Validation Loss: 0.1351, Validation Loss: 0.1351,V Acc: 0.3153, Top 70th Acc: 0.3718, Bottom 30th Acc: 0.1818
Fold [2/5] Epoch [10/100] Initial Loss: 0.1386, Training Loss: 0.0212, Initial Validation Loss: 0.1351, Validation Loss: 0.0369,V Acc: 0.8198, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.5758
Fold [2/5] Epoch [20/100] Initial Loss: 0.1386, Training Loss: 0.0128, Initial Validation Loss: 0.1351, Validation Loss: 0.0373,V Acc: 0.8198, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 20  Rolling back to Epoch (base 0): 15  Top Validation Acc: 0.9230769230769231
Fold [3/5] Epoch [0/100] Initial Loss: 0.1412, Training Loss: 0.1412, Initial Validation Loss: 0.1290, Validation Loss: 0.1290,V Acc: 0.2818, Top 70th Acc: 0.3117, Bottom 30th Acc: 0.2121
Fold [3/5] Epoch [10/100] Initial Loss: 0.1412, Training Loss: 0.0265, Initial Validation Loss: 0.1290, Validation Loss: 0.0345,V Acc: 0.7818, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.3939
Fold [3/5] Epoch [20/100] Initial Loss: 0.1412, Training Loss: 0.0141, Initial Validation Loss: 0.1290, Validation Loss: 0.0291,V Acc: 0.8273, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 29  Rolling back to Epoch (base 0): 24  Top Validation Acc: 0.9090909090909091
Fold [4/5] Epoch [0/100] Initial Loss: 0.1385, Training Loss: 0.1385, Initial Validation Loss: 0.1369, Validation Loss: 0.1369,V Acc: 0.2364, Top 70th Acc: 0.2987, Bottom 30th Acc: 0.0909
Fold [4/5] Epoch [10/100] Initial Loss: 0.1385, Training Loss: 0.0310, Initial Validation Loss: 0.1369, Validation Loss: 0.0334,V Acc: 0.8545, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.6667
Fold [4/5] Epoch [20/100] Initial Loss: 0.1385, Training Loss: 0.0148, Initial Validation Loss: 0.1369, Validation Loss: 0.0278,V Acc: 0.8545, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.5758
Fold [4/5] Epoch [30/100] Initial Loss: 0.1385, Training Loss: 0.0121, Initial Validation Loss: 0.1369, Validation Loss: 0.0271,V Acc: 0.8727, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 30  Rolling back to Epoch (base 0): 25  Top Validation Acc: 0.961038961038961
66 3 [array([0.64491135, 0.06077835, 0.04168672, 0.08251414, 0.17010947],
      dtype=float32)]
Fold [5/5] Epoch [0/100] Initial Loss: 0.1393, Training Loss: 0.1393, Initial Validation Loss: 0.1304, Validation Loss: 0.1304,V Acc: 0.3426, Top 70th Acc: 0.4079, Bottom 30th Acc: 0.1875
Fold [5/5] Epoch [10/100] Initial Loss: 0.1393, Training Loss: 0.0306, Initial Validation Loss: 0.1304, Validation Loss: 0.0420,V Acc: 0.8056, Top 70th Acc: 0.8816, Bottom 30th Acc: 0.6250
Fold [5/5] Epoch [20/100] Initial Loss: 0.1393, Training Loss: 0.0145, Initial Validation Loss: 0.1304, Validation Loss: 0.0373,V Acc: 0.7870, Top 70th Acc: 0.9079, Bottom 30th Acc: 0.5000
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.9078947368421053
Running train_nn.py with seed 67
CUDA:False
Training samples count:  550
Training on 40 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1381, Training Loss: 0.1381, Initial Validation Loss: 0.1346, Validation Loss: 0.1346,V Acc: 0.2793, Top 70th Acc: 0.3590, Bottom 30th Acc: 0.0909
Fold [1/5] Epoch [10/100] Initial Loss: 0.1381, Training Loss: 0.0289, Initial Validation Loss: 0.1346, Validation Loss: 0.0366,V Acc: 0.8559, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.6667
Fold [1/5] Epoch [20/100] Initial Loss: 0.1381, Training Loss: 0.0142, Initial Validation Loss: 0.1346, Validation Loss: 0.0321,V Acc: 0.8559, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 22  Rolling back to Epoch (base 0): 17  Top Validation Acc: 0.9615384615384616
67 0 [array([0.638862  , 0.10117028, 0.03539096, 0.08994686, 0.13462977],
      dtype=float32)]
Fold [2/5] Epoch [0/100] Initial Loss: 0.1389, Training Loss: 0.1389, Initial Validation Loss: 0.1316, Validation Loss: 0.1316,V Acc: 0.2703, Top 70th Acc: 0.3333, Bottom 30th Acc: 0.1212
Fold [2/5] Epoch [10/100] Initial Loss: 0.1389, Training Loss: 0.0413, Initial Validation Loss: 0.1316, Validation Loss: 0.0469,V Acc: 0.7838, Top 70th Acc: 0.8718, Bottom 30th Acc: 0.5758
Fold [2/5] Epoch [20/100] Initial Loss: 0.1389, Training Loss: 0.0187, Initial Validation Loss: 0.1316, Validation Loss: 0.0278,V Acc: 0.8559, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.6364
Fold [2/5] Epoch [30/100] Initial Loss: 0.1389, Training Loss: 0.0126, Initial Validation Loss: 0.1316, Validation Loss: 0.0259,V Acc: 0.8559, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 32  Rolling back to Epoch (base 0): 27  Top Validation Acc: 0.9615384615384616
Fold [3/5] Epoch [0/100] Initial Loss: 0.1427, Training Loss: 0.1427, Initial Validation Loss: 0.1340, Validation Loss: 0.1340,V Acc: 0.4091, Top 70th Acc: 0.4675, Bottom 30th Acc: 0.2727
Fold [3/5] Epoch [10/100] Initial Loss: 0.1427, Training Loss: 0.0328, Initial Validation Loss: 0.1340, Validation Loss: 0.0407,V Acc: 0.8273, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.5758
Fold [3/5] Epoch [20/100] Initial Loss: 0.1427, Training Loss: 0.0166, Initial Validation Loss: 0.1340, Validation Loss: 0.0255,V Acc: 0.9000, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.7273
Fold [3/5] Epoch [30/100] Initial Loss: 0.1427, Training Loss: 0.0136, Initial Validation Loss: 0.1340, Validation Loss: 0.0244,V Acc: 0.9091, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.7576
Stopping early at Epoch (base 0): 38  Rolling back to Epoch (base 0): 33  Top Validation Acc: 0.987012987012987
Fold [4/5] Epoch [0/100] Initial Loss: 0.1388, Training Loss: 0.1388, Initial Validation Loss: 0.1333, Validation Loss: 0.1333,V Acc: 0.4000, Top 70th Acc: 0.4416, Bottom 30th Acc: 0.3030
Fold [4/5] Epoch [10/100] Initial Loss: 0.1388, Training Loss: 0.0244, Initial Validation Loss: 0.1333, Validation Loss: 0.0425,V Acc: 0.7909, Top 70th Acc: 0.8831, Bottom 30th Acc: 0.5758
Fold [4/5] Epoch [20/100] Initial Loss: 0.1388, Training Loss: 0.0125, Initial Validation Loss: 0.1333, Validation Loss: 0.0401,V Acc: 0.7727, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.4545
Fold [4/5] Epoch [30/100] Initial Loss: 0.1388, Training Loss: 0.0102, Initial Validation Loss: 0.1333, Validation Loss: 0.0390,V Acc: 0.7727, Top 70th Acc: 0.8961, Bottom 30th Acc: 0.4848
Stopping early at Epoch (base 0): 35  Rolling back to Epoch (base 0): 30  Top Validation Acc: 0.8961038961038961
Fold [5/5] Epoch [0/100] Initial Loss: 0.1372, Training Loss: 0.1372, Initial Validation Loss: 0.1354, Validation Loss: 0.1354,V Acc: 0.2500, Top 70th Acc: 0.2895, Bottom 30th Acc: 0.1562
Fold [5/5] Epoch [10/100] Initial Loss: 0.1372, Training Loss: 0.0363, Initial Validation Loss: 0.1354, Validation Loss: 0.0365,V Acc: 0.8611, Top 70th Acc: 0.9737, Bottom 30th Acc: 0.5938
Fold [5/5] Epoch [20/100] Initial Loss: 0.1372, Training Loss: 0.0179, Initial Validation Loss: 0.1354, Validation Loss: 0.0285,V Acc: 0.8704, Top 70th Acc: 0.9868, Bottom 30th Acc: 0.5938
Fold [5/5] Epoch [30/100] Initial Loss: 0.1372, Training Loss: 0.0132, Initial Validation Loss: 0.1354, Validation Loss: 0.0265,V Acc: 0.8611, Top 70th Acc: 1.0000, Bottom 30th Acc: 0.5312
Stopping early at Epoch (base 0): 22  Rolling back to Epoch (base 0): 17  Top Validation Acc: 0.9871794871794872
Fold [3/5] Epoch [0/100] Initial Loss: 0.1350, Training Loss: 0.1350, Initial Validation Loss: 0.1249, Validation Loss: 0.1249,V Acc: 0.4364, Top 70th Acc: 0.5195, Bottom 30th Acc: 0.2424
Fold [3/5] Epoch [10/100] Initial Loss: 0.1350, Training Loss: 0.0252, Initial Validation Loss: 0.1249, Validation Loss: 0.0334,V Acc: 0.8636, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.6970
Fold [3/5] Epoch [20/100] Initial Loss: 0.1350, Training Loss: 0.0174, Initial Validation Loss: 0.1249, Validation Loss: 0.0343,V Acc: 0.8182, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.5152
Stopping early at Epoch (base 0): 20  Rolling back to Epoch (base 0): 15  Top Validation Acc: 0.948051948051948
94 2 [array([0.81117177, 0.01743794, 0.01494392, 0.09795679, 0.05848958],
      dtype=float32)]
Fold [4/5] Epoch [0/100] Initial Loss: 0.1363, Training Loss: 0.1363, Initial Validation Loss: 0.1244, Validation Loss: 0.1244,V Acc: 0.4000, Top 70th Acc: 0.3636, Bottom 30th Acc: 0.4848
Fold [4/5] Epoch [10/100] Initial Loss: 0.1363, Training Loss: 0.0274, Initial Validation Loss: 0.1244, Validation Loss: 0.0325,V Acc: 0.8636, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.7576
Fold [4/5] Epoch [20/100] Initial Loss: 0.1363, Training Loss: 0.0181, Initial Validation Loss: 0.1244, Validation Loss: 0.0282,V Acc: 0.8636, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 20  Rolling back to Epoch (base 0): 15  Top Validation Acc: 0.935064935064935
Fold [5/5] Epoch [0/100] Initial Loss: 0.1361, Training Loss: 0.1361, Initial Validation Loss: 0.1235, Validation Loss: 0.1235,V Acc: 0.4630, Top 70th Acc: 0.4737, Bottom 30th Acc: 0.4375
Fold [5/5] Epoch [10/100] Initial Loss: 0.1361, Training Loss: 0.0254, Initial Validation Loss: 0.1235, Validation Loss: 0.0324,V Acc: 0.8519, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.5938
Fold [5/5] Epoch [20/100] Initial Loss: 0.1361, Training Loss: 0.0175, Initial Validation Loss: 0.1235, Validation Loss: 0.0251,V Acc: 0.9074, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.8125
Fold [5/5] Epoch [30/100] Initial Loss: 0.1361, Training Loss: 0.0160, Initial Validation Loss: 0.1235, Validation Loss: 0.0273,V Acc: 0.8426, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.5938
Stopping early at Epoch (base 0): 31  Rolling back to Epoch (base 0): 26  Top Validation Acc: 0.9605263157894737
Running train_nn.py with seed 95
CUDA:False
Training samples count:  550
Training on 21 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1359, Training Loss: 0.1359, Initial Validation Loss: 0.1303, Validation Loss: 0.1303,V Acc: 0.4775, Top 70th Acc: 0.5769, Bottom 30th Acc: 0.2424
Fold [1/5] Epoch [10/100] Initial Loss: 0.1359, Training Loss: 0.0253, Initial Validation Loss: 0.1303, Validation Loss: 0.0310,V Acc: 0.8739, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.6364
Fold [1/5] Epoch [20/100] Initial Loss: 0.1359, Training Loss: 0.0174, Initial Validation Loss: 0.1303, Validation Loss: 0.0238,V Acc: 0.9189, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.7879
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.9743589743589743
Fold [2/5] Epoch [0/100] Initial Loss: 0.1333, Training Loss: 0.1333, Initial Validation Loss: 0.1203, Validation Loss: 0.1203,V Acc: 0.4414, Top 70th Acc: 0.5000, Bottom 30th Acc: 0.3030
Fold [2/5] Epoch [10/100] Initial Loss: 0.1333, Training Loss: 0.0250, Initial Validation Loss: 0.1203, Validation Loss: 0.0314,V Acc: 0.8378, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 18  Rolling back to Epoch (base 0): 13  Top Validation Acc: 0.9615384615384616
Fold [3/5] Epoch [0/100] Initial Loss: 0.1332, Training Loss: 0.1332, Initial Validation Loss: 0.1178, Validation Loss: 0.1178,V Acc: 0.5091, Top 70th Acc: 0.6104, Bottom 30th Acc: 0.2727
Fold [3/5] Epoch [10/100] Initial Loss: 0.1332, Training Loss: 0.0224, Initial Validation Loss: 0.1178, Validation Loss: 0.0272,V Acc: 0.8636, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.6061
Fold [3/5] Epoch [20/100] Initial Loss: 0.1332, Training Loss: 0.0182, Initial Validation Loss: 0.1178, Validation Loss: 0.0240,V Acc: 0.8727, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 29  Rolling back to Epoch (base 0): 24  Top Validation Acc: 0.987012987012987
Fold [4/5] Epoch [0/100] Initial Loss: 0.1364, Training Loss: 0.1364, Initial Validation Loss: 0.1232, Validation Loss: 0.1232,V Acc: 0.4182, Top 70th Acc: 0.4675, Bottom 30th Acc: 0.3030
Fold [4/5] Epoch [10/100] Initial Loss: 0.1364, Training Loss: 0.0240, Initial Validation Loss: 0.1232, Validation Loss: 0.0377,V Acc: 0.8364, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 17  Rolling back to Epoch (base 0): 12  Top Validation Acc: 0.8831168831168831
Fold [5/5] Epoch [0/100] Initial Loss: 0.1411, Training Loss: 0.1411, Initial Validation Loss: 0.1311, Validation Loss: 0.1311,V Acc: 0.2500, Top 70th Acc: 0.3553, Bottom 30th Acc: 0.0000
Fold [5/5] Epoch [10/100] Initial Loss: 0.1411, Training Loss: 0.0327, Initial Validation Loss: 0.1311, Validation Loss: 0.0408,V Acc: 0.7685, Top 70th Acc: 0.9079, Bottom 30th Acc: 0.4375
Fold [5/5] Epoch [20/100] Initial Loss: 0.1411, Training Loss: 0.0210, Initial Validation Loss: 0.1311, Validation Loss: 0.0256,V Acc: 0.8981, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.7500
Fold [5/5] Epoch [30/100] Initial Loss: 0.1411, Training Loss: 0.0166, Initial Validation Loss: 0.1311, Validation Loss: 0.0229,V Acc: 0.8889, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.7188
Stopping early at Epoch (base 0): 33  Rolling back to Epoch (base 0): 28  Top Validation Acc: 0.9473684210526315
95 4 [array([0.75208896, 0.01716433, 0.0234126 , 0.08875549, 0.11857857],
      dtype=float32)]
Running train_nn.py with seed 96
CUDA:False
Training samples count:  550
Training on 21 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1309, Training Loss: 0.1309, Initial Validation Loss: 0.1214, Validation Loss: 0.1214,V Acc: 0.4505, Top 70th Acc: 0.5385, Bottom 30th Acc: 0.2424
Fold [1/5] Epoch [10/100] Initial Loss: 0.1309, Training Loss: 0.0218, Initial Validation Loss: 0.1214, Validation Loss: 0.0346,V Acc: 0.8288, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 12  Rolling back to Epoch (base 0): 7  Top Validation Acc: 0.9615384615384616
Fold [2/5] Epoch [0/100] Initial Loss: 0.1338, Training Loss: 0.1338, Initial Validation Loss: 0.1204, Validation Loss: 0.1204,V Acc: 0.5586, Top 70th Acc: 0.6795, Bottom 30th Acc: 0.2727
Fold [2/5] Epoch [10/100] Initial Loss: 0.1338, Training Loss: 0.0243, Initial Validation Loss: 0.1204, Validation Loss: 0.0284,V Acc: 0.8829, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.7576
Stopping early at Epoch (base 0): 17  Rolling back to Epoch (base 0): 12  Top Validation Acc: 0.9743589743589743
Fold [3/5] Epoch [0/100] Initial Loss: 0.1279, Training Loss: 0.1279, Initial Validation Loss: 0.1136, Validation Loss: 0.1136,V Acc: 0.4727, Top 70th Acc: 0.6364, Bottom 30th Acc: 0.0909
Fold [3/5] Epoch [10/100] Initial Loss: 0.1279, Training Loss: 0.0279, Initial Validation Loss: 0.1136, Validation Loss: 0.0331,V Acc: 0.8273, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.5455
Fold [3/5] Epoch [20/100] Initial Loss: 0.1279, Training Loss: 0.0196, Initial Validation Loss: 0.1136, Validation Loss: 0.0223,V Acc: 0.9000, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.7879
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.961038961038961
Fold [4/5] Epoch [0/100] Initial Loss: 0.1360, Training Loss: 0.1360, Initial Validation Loss: 0.1227, Validation Loss: 0.1227,V Acc: 0.4909, Top 70th Acc: 0.6234, Bottom 30th Acc: 0.1818
Fold [4/5] Epoch [10/100] Initial Loss: 0.1360, Training Loss: 0.0215, Initial Validation Loss: 0.1227, Validation Loss: 0.0322,V Acc: 0.8545, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 18  Rolling back to Epoch (base 0): 13  Top Validation Acc: 0.948051948051948
Fold [5/5] Epoch [0/100] Initial Loss: 0.1296, Training Loss: 0.1296, Initial Validation Loss: 0.1121, Validation Loss: 0.1121,V Acc: 0.5278, Top 70th Acc: 0.6447, Bottom 30th Acc: 0.2500
Fold [5/5] Epoch [20/100] Initial Loss: 0.1403, Training Loss: 0.0234, Initial Validation Loss: 0.1308, Validation Loss: 0.0295,V Acc: 0.8611, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.6250
Fold [5/5] Epoch [30/100] Initial Loss: 0.1403, Training Loss: 0.0214, Initial Validation Loss: 0.1308, Validation Loss: 0.0293,V Acc: 0.8796, Top 70th Acc: 0.9737, Bottom 30th Acc: 0.6562
Stopping early at Epoch (base 0): 34  Rolling back to Epoch (base 0): 29  Top Validation Acc: 0.9605263157894737
Running train_nn.py with seed 68
CUDA:False
Training samples count:  550
Training on 20 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1368, Training Loss: 0.1368, Initial Validation Loss: 0.1350, Validation Loss: 0.1350,V Acc: 0.4505, Top 70th Acc: 0.5128, Bottom 30th Acc: 0.3030
Fold [1/5] Epoch [10/100] Initial Loss: 0.1368, Training Loss: 0.0385, Initial Validation Loss: 0.1350, Validation Loss: 0.0476,V Acc: 0.8108, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.5758
Fold [1/5] Epoch [20/100] Initial Loss: 0.1368, Training Loss: 0.0234, Initial Validation Loss: 0.1350, Validation Loss: 0.0356,V Acc: 0.8198, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.5455
Fold [1/5] Epoch [30/100] Initial Loss: 0.1368, Training Loss: 0.0210, Initial Validation Loss: 0.1350, Validation Loss: 0.0323,V Acc: 0.8468, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 35  Rolling back to Epoch (base 0): 30  Top Validation Acc: 0.9358974358974359
Fold [2/5] Epoch [0/100] Initial Loss: 0.1379, Training Loss: 0.1379, Initial Validation Loss: 0.1349, Validation Loss: 0.1349,V Acc: 0.2613, Top 70th Acc: 0.3462, Bottom 30th Acc: 0.0606
Fold [2/5] Epoch [10/100] Initial Loss: 0.1379, Training Loss: 0.0328, Initial Validation Loss: 0.1349, Validation Loss: 0.0381,V Acc: 0.8468, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.6061
Fold [2/5] Epoch [20/100] Initial Loss: 0.1379, Training Loss: 0.0221, Initial Validation Loss: 0.1349, Validation Loss: 0.0325,V Acc: 0.8468, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.9743589743589743
Fold [3/5] Epoch [0/100] Initial Loss: 0.1405, Training Loss: 0.1405, Initial Validation Loss: 0.1301, Validation Loss: 0.1301,V Acc: 0.3273, Top 70th Acc: 0.3766, Bottom 30th Acc: 0.2121
Fold [3/5] Epoch [10/100] Initial Loss: 0.1405, Training Loss: 0.0361, Initial Validation Loss: 0.1301, Validation Loss: 0.0447,V Acc: 0.7364, Top 70th Acc: 0.8701, Bottom 30th Acc: 0.4242
Fold [3/5] Epoch [20/100] Initial Loss: 0.1405, Training Loss: 0.0218, Initial Validation Loss: 0.1301, Validation Loss: 0.0402,V Acc: 0.7727, Top 70th Acc: 0.8571, Bottom 30th Acc: 0.5758
Fold [3/5] Epoch [30/100] Initial Loss: 0.1405, Training Loss: 0.0197, Initial Validation Loss: 0.1301, Validation Loss: 0.0386,V Acc: 0.7818, Top 70th Acc: 0.8831, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 38  Rolling back to Epoch (base 0): 33  Top Validation Acc: 0.8961038961038961
Fold [4/5] Epoch [0/100] Initial Loss: 0.1346, Training Loss: 0.1346, Initial Validation Loss: 0.1332, Validation Loss: 0.1332,V Acc: 0.4455, Top 70th Acc: 0.5065, Bottom 30th Acc: 0.3030
Fold [4/5] Epoch [10/100] Initial Loss: 0.1346, Training Loss: 0.0356, Initial Validation Loss: 0.1332, Validation Loss: 0.0269,V Acc: 0.9000, Top 70th Acc: 0.9870, Bottom 30th Acc: 0.6970
Fold [4/5] Epoch [20/100] Initial Loss: 0.1346, Training Loss: 0.0260, Initial Validation Loss: 0.1332, Validation Loss: 0.0209,V Acc: 0.9091, Top 70th Acc: 0.9870, Bottom 30th Acc: 0.7273
Fold [4/5] Epoch [30/100] Initial Loss: 0.1346, Training Loss: 0.0238, Initial Validation Loss: 0.1332, Validation Loss: 0.0207,V Acc: 0.9000, Top 70th Acc: 0.9870, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 35  Rolling back to Epoch (base 0): 30  Top Validation Acc: 0.987012987012987
Fold [5/5] Epoch [0/100] Initial Loss: 0.1389, Training Loss: 0.1389, Initial Validation Loss: 0.1284, Validation Loss: 0.1284,V Acc: 0.2870, Top 70th Acc: 0.3553, Bottom 30th Acc: 0.1250
Fold [5/5] Epoch [10/100] Initial Loss: 0.1389, Training Loss: 0.0317, Initial Validation Loss: 0.1284, Validation Loss: 0.0374,V Acc: 0.8426, Top 70th Acc: 0.8816, Bottom 30th Acc: 0.7500
Fold [5/5] Epoch [20/100] Initial Loss: 0.1389, Training Loss: 0.0225, Initial Validation Loss: 0.1284, Validation Loss: 0.0323,V Acc: 0.8426, Top 70th Acc: 0.9211, Bottom 30th Acc: 0.6562
Stopping early at Epoch (base 0): 27  Rolling back to Epoch (base 0): 22  Top Validation Acc: 0.9210526315789473
68 4 [array([0.46631414, 0.05718331, 0.13058847, 0.1669546 , 0.17895946],
      dtype=float32)]
Running train_nn.py with seed 69
CUDA:False
Training samples count:  550
Training on 20 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1396, Training Loss: 0.1396, Initial Validation Loss: 0.1363, Validation Loss: 0.1363,V Acc: 0.2793, Top 70th Acc: 0.3333, Bottom 30th Acc: 0.1515
Fold [1/5] Epoch [10/100] Initial Loss: 0.1396, Training Loss: 0.0327, Initial Validation Loss: 0.1363, Validation Loss: 0.0431,V Acc: 0.7748, Top 70th Acc: 0.8974, Bottom 30th Acc: 0.4848
Fold [1/5] Epoch [20/100] Initial Loss: 0.1396, Training Loss: 0.0232, Initial Validation Loss: 0.1363, Validation Loss: 0.0379,V Acc: 0.8108, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.5455
Fold [1/5] Epoch [30/100] Initial Loss: 0.1396, Training Loss: 0.0206, Initial Validation Loss: 0.1363, Validation Loss: 0.0367,V Acc: 0.8198, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.6061
Fold [1/5] Epoch [40/100] Initial Loss: 0.1396, Training Loss: 0.0196, Initial Validation Loss: 0.1363, Validation Loss: 0.0347,V Acc: 0.8198, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 45  Rolling back to Epoch (base 0): 40  Top Validation Acc: 0.9230769230769231
69 0 [array([0.34481218, 0.02636671, 0.17367074, 0.16141123, 0.2937391 ],
      dtype=float32)]
Fold [2/5] Epoch [0/100] Initial Loss: 0.1371, Training Loss: 0.1371, Initial Validation Loss: 0.1342, Validation Loss: 0.1342,V Acc: 0.3514, Top 70th Acc: 0.3846, Bottom 30th Acc: 0.2727
Fold [2/5] Epoch [10/100] Initial Loss: 0.1371, Training Loss: 0.0346, Initial Validation Loss: 0.1342, Validation Loss: 0.0410,V Acc: 0.8468, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.6667
Fold [2/5] Epoch [20/100] Initial Loss: 0.1371, Training Loss: 0.0220, Initial Validation Loss: 0.1342, Validation Loss: 0.0360,V Acc: 0.8559, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.9358974358974359
Fold [3/5] Epoch [0/100] Initial Loss: 0.1413, Training Loss: 0.1413, Initial Validation Loss: 0.1345, Validation Loss: 0.1345,V Acc: 0.2182, Top 70th Acc: 0.2338, Bottom 30th Acc: 0.1818
Fold [3/5] Epoch [10/100] Initial Loss: 0.1413, Training Loss: 0.0354, Initial Validation Loss: 0.1345, Validation Loss: 0.0328,V Acc: 0.8909, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.7576
Fold [3/5] Epoch [20/100] Initial Loss: 0.1413, Training Loss: 0.0236, Initial Validation Loss: 0.1345, Validation Loss: 0.0266,V Acc: 0.9000, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.7576
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.974025974025974
Fold [4/5] Epoch [0/100] Initial Loss: 0.1362, Training Loss: 0.1362, Initial Validation Loss: 0.1326, Validation Loss: 0.1326,V Acc: 0.3000, Top 70th Acc: 0.3506, Bottom 30th Acc: 0.1818
Fold [4/5] Epoch [10/100] Initial Loss: 0.1362, Training Loss: 0.0374, Initial Validation Loss: 0.1326, Validation Loss: 0.0431,V Acc: 0.8091, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.5758
Fold [4/5] Epoch [20/100] Initial Loss: 0.1362, Training Loss: 0.0248, Initial Validation Loss: 0.1326, Validation Loss: 0.0320,V Acc: 0.8455, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6061
Fold [4/5] Epoch [30/100] Initial Loss: 0.1362, Training Loss: 0.0218, Initial Validation Loss: 0.1326, Validation Loss: 0.0305,V Acc: 0.8545, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 38  Rolling back to Epoch (base 0): 33  Top Validation Acc: 0.935064935064935
Fold [5/5] Epoch [0/100] Initial Loss: 0.1418, Training Loss: 0.1418, Initial Validation Loss: 0.1328, Validation Loss: 0.1328,V Acc: 0.2500, Top 70th Acc: 0.2763, Bottom 30th Acc: 0.1875
Stopping early at Epoch (base 0): 17  Rolling back to Epoch (base 0): 12  Top Validation Acc: 0.7142857142857143
63 2 [array([0.1451324 , 0.33367473, 0.15968128, 0.18696529, 0.17454633],
      dtype=float32)]
Fold [4/5] Epoch [0/100] Initial Loss: 0.1287, Training Loss: 0.1287, Initial Validation Loss: 0.1185, Validation Loss: 0.1185,V Acc: 0.4273, Top 70th Acc: 0.5584, Bottom 30th Acc: 0.1212
Fold [4/5] Epoch [10/100] Initial Loss: 0.1287, Training Loss: 0.0804, Initial Validation Loss: 0.1185, Validation Loss: 0.0841,V Acc: 0.6091, Top 70th Acc: 0.7273, Bottom 30th Acc: 0.3333
Fold [4/5] Epoch [20/100] Initial Loss: 0.1287, Training Loss: 0.0779, Initial Validation Loss: 0.1185, Validation Loss: 0.0821,V Acc: 0.6273, Top 70th Acc: 0.7273, Bottom 30th Acc: 0.3939
Fold [4/5] Epoch [30/100] Initial Loss: 0.1287, Training Loss: 0.0771, Initial Validation Loss: 0.1185, Validation Loss: 0.0827,V Acc: 0.5909, Top 70th Acc: 0.7143, Bottom 30th Acc: 0.3030
Stopping early at Epoch (base 0): 37  Rolling back to Epoch (base 0): 32  Top Validation Acc: 0.7272727272727273
Fold [5/5] Epoch [0/100] Initial Loss: 0.1361, Training Loss: 0.1361, Initial Validation Loss: 0.1250, Validation Loss: 0.1250,V Acc: 0.6019, Top 70th Acc: 0.7368, Bottom 30th Acc: 0.2812
Fold [5/5] Epoch [10/100] Initial Loss: 0.1361, Training Loss: 0.0807, Initial Validation Loss: 0.1250, Validation Loss: 0.0820,V Acc: 0.6389, Top 70th Acc: 0.7368, Bottom 30th Acc: 0.4062
Fold [5/5] Epoch [20/100] Initial Loss: 0.1361, Training Loss: 0.0785, Initial Validation Loss: 0.1250, Validation Loss: 0.0800,V Acc: 0.6296, Top 70th Acc: 0.7368, Bottom 30th Acc: 0.3750
Stopping early at Epoch (base 0): 27  Rolling back to Epoch (base 0): 22  Top Validation Acc: 0.7368421052631579
Running train_nn.py with seed 64
CUDA:False
Training samples count:  550
Training on 2 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1346, Training Loss: 0.1346, Initial Validation Loss: 0.1265, Validation Loss: 0.1265,V Acc: 0.4144, Top 70th Acc: 0.5000, Bottom 30th Acc: 0.2121
Fold [1/5] Epoch [10/100] Initial Loss: 0.1346, Training Loss: 0.0776, Initial Validation Loss: 0.1265, Validation Loss: 0.0896,V Acc: 0.5946, Top 70th Acc: 0.6795, Bottom 30th Acc: 0.3939
Fold [1/5] Epoch [20/100] Initial Loss: 0.1346, Training Loss: 0.0753, Initial Validation Loss: 0.1265, Validation Loss: 0.0886,V Acc: 0.5856, Top 70th Acc: 0.6923, Bottom 30th Acc: 0.3333
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.6923076923076923
Fold [2/5] Epoch [0/100] Initial Loss: 0.1398, Training Loss: 0.1398, Initial Validation Loss: 0.1264, Validation Loss: 0.1264,V Acc: 0.4144, Top 70th Acc: 0.4231, Bottom 30th Acc: 0.3939
Fold [2/5] Epoch [10/100] Initial Loss: 0.1398, Training Loss: 0.0821, Initial Validation Loss: 0.1264, Validation Loss: 0.0756,V Acc: 0.6396, Top 70th Acc: 0.7436, Bottom 30th Acc: 0.3939
Fold [2/5] Epoch [20/100] Initial Loss: 0.1398, Training Loss: 0.0803, Initial Validation Loss: 0.1264, Validation Loss: 0.0737,V Acc: 0.6216, Top 70th Acc: 0.7436, Bottom 30th Acc: 0.3333
Fold [2/5] Epoch [30/100] Initial Loss: 0.1398, Training Loss: 0.0797, Initial Validation Loss: 0.1264, Validation Loss: 0.0733,V Acc: 0.6306, Top 70th Acc: 0.7436, Bottom 30th Acc: 0.3636
Fold [2/5] Epoch [40/100] Initial Loss: 0.1398, Training Loss: 0.0793, Initial Validation Loss: 0.1264, Validation Loss: 0.0730,V Acc: 0.6306, Top 70th Acc: 0.7308, Bottom 30th Acc: 0.3939
Stopping early at Epoch (base 0): 41  Rolling back to Epoch (base 0): 36  Top Validation Acc: 0.7564102564102564
Fold [3/5] Epoch [0/100] Initial Loss: 0.1355, Training Loss: 0.1355, Initial Validation Loss: 0.1267, Validation Loss: 0.1267,V Acc: 0.3727, Top 70th Acc: 0.4935, Bottom 30th Acc: 0.0909
Fold [3/5] Epoch [10/100] Initial Loss: 0.1355, Training Loss: 0.0819, Initial Validation Loss: 0.1267, Validation Loss: 0.0752,V Acc: 0.6455, Top 70th Acc: 0.7792, Bottom 30th Acc: 0.3333
Fold [3/5] Epoch [20/100] Initial Loss: 0.1355, Training Loss: 0.0801, Initial Validation Loss: 0.1267, Validation Loss: 0.0737,V Acc: 0.6545, Top 70th Acc: 0.8052, Bottom 30th Acc: 0.3030
Fold [3/5] Epoch [30/100] Initial Loss: 0.1355, Training Loss: 0.0794, Initial Validation Loss: 0.1267, Validation Loss: 0.0733,V Acc: 0.6364, Top 70th Acc: 0.7662, Bottom 30th Acc: 0.3333
Stopping early at Epoch (base 0): 38  Rolling back to Epoch (base 0): 33  Top Validation Acc: 0.7792207792207793
Fold [4/5] Epoch [0/100] Initial Loss: 0.1381, Training Loss: 0.1381, Initial Validation Loss: 0.1336, Validation Loss: 0.1336,V Acc: 0.2545, Top 70th Acc: 0.3506, Bottom 30th Acc: 0.0303
Fold [4/5] Epoch [10/100] Initial Loss: 0.1381, Training Loss: 0.0823, Initial Validation Loss: 0.1336, Validation Loss: 0.0802,V Acc: 0.6364, Top 70th Acc: 0.7532, Bottom 30th Acc: 0.3636
Fold [4/5] Epoch [20/100] Initial Loss: 0.1381, Training Loss: 0.0794, Initial Validation Loss: 0.1336, Validation Loss: 0.0776,V Acc: 0.6364, Top 70th Acc: 0.7532, Bottom 30th Acc: 0.3636
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.7532467532467533
64 3 [array([0.1327859 , 0.3198335 , 0.17634048, 0.23625153, 0.1347886 ],
      dtype=float32)]
Fold [5/5] Epoch [0/100] Initial Loss: 0.1398, Training Loss: 0.1398, Initial Validation Loss: 0.1294, Validation Loss: 0.1294,V Acc: 0.2593, Top 70th Acc: 0.3289, Bottom 30th Acc: 0.0938
Fold [5/5] Epoch [10/100] Initial Loss: 0.1398, Training Loss: 0.0810, Initial Validation Loss: 0.1294, Validation Loss: 0.0793,V Acc: 0.6481, Top 70th Acc: 0.7763, Bottom 30th Acc: 0.3438
Fold [5/5] Epoch [20/100] Initial Loss: 0.1398, Training Loss: 0.0787, Initial Validation Loss: 0.1294, Validation Loss: 0.0783,V Acc: 0.6481, Top 70th Acc: 0.7500, Bottom 30th Acc: 0.4062
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.75
Running train_nn.py with seed 65
CUDA:False
Training samples count:  550
Training on 2 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1340, Training Loss: 0.1340, Initial Validation Loss: 0.1242, Validation Loss: 0.1242,V Acc: 0.4414, Top 70th Acc: 0.4872, Bottom 30th Acc: 0.3333
Fold [1/5] Epoch [10/100] Initial Loss: 0.1340, Training Loss: 0.0803, Initial Validation Loss: 0.1242, Validation Loss: 0.0807,V Acc: 0.5946, Top 70th Acc: 0.6923, Bottom 30th Acc: 0.3636
Fold [1/5] Epoch [20/100] Initial Loss: 0.1340, Training Loss: 0.0783, Initial Validation Loss: 0.1242, Validation Loss: 0.0796,V Acc: 0.6126, Top 70th Acc: 0.7308, Bottom 30th Acc: 0.3333
Stopping early at Epoch (base 0): 28  Rolling back to Epoch (base 0): 23  Top Validation Acc: 0.717948717948718
65 0 [array([0.13150358, 0.3553807 , 0.12613143, 0.2353745 , 0.15160976],
      dtype=float32)]
Fold [2/5] Epoch [0/100] Initial Loss: 0.1367, Training Loss: 0.1367, Initial Validation Loss: 0.1315, Validation Loss: 0.1315,V Acc: 0.3423, Top 70th Acc: 0.3590, Bottom 30th Acc: 0.3030
Fold [2/5] Epoch [10/100] Initial Loss: 0.1367, Training Loss: 0.0806, Initial Validation Loss: 0.1315, Validation Loss: 0.0828,V Acc: 0.6036, Top 70th Acc: 0.7179, Bottom 30th Acc: 0.3333
Fold [2/5] Epoch [20/100] Initial Loss: 0.1367, Training Loss: 0.0785, Initial Validation Loss: 0.1315, Validation Loss: 0.0821,V Acc: 0.6216, Top 70th Acc: 0.7308, Bottom 30th Acc: 0.3636
Fold [2/5] Epoch [30/100] Initial Loss: 0.1367, Training Loss: 0.0777, Initial Validation Loss: 0.1315, Validation Loss: 0.0811,V Acc: 0.6126, Top 70th Acc: 0.7436, Bottom 30th Acc: 0.3030
Stopping early at Epoch (base 0): 39  Rolling back to Epoch (base 0): 34  Top Validation Acc: 0.7307692307692307
Fold [3/5] Epoch [0/100] Initial Loss: 0.1394, Training Loss: 0.1394, Initial Validation Loss: 0.1289, Validation Loss: 0.1289,V Acc: 0.4364, Top 70th Acc: 0.5065, Bottom 30th Acc: 0.2727
Fold [3/5] Epoch [10/100] Initial Loss: 0.1394, Training Loss: 0.0823, Initial Validation Loss: 0.1289, Validation Loss: 0.0750,V Acc: 0.6455, Top 70th Acc: 0.7662, Bottom 30th Acc: 0.3636
Fold [3/5] Epoch [20/100] Initial Loss: 0.1394, Training Loss: 0.0800, Initial Validation Loss: 0.1289, Validation Loss: 0.0742,V Acc: 0.6455, Top 70th Acc: 0.7532, Bottom 30th Acc: 0.3939
Fold [5/5] Epoch [30/100] Initial Loss: 0.1377, Training Loss: 0.0151, Initial Validation Loss: 0.1343, Validation Loss: 0.0248,V Acc: 0.8796, Top 70th Acc: 0.9737, Bottom 30th Acc: 0.6562
Stopping early at Epoch (base 0): 33  Rolling back to Epoch (base 0): 28  Top Validation Acc: 0.9736842105263158
Running train_nn.py with seed 68
CUDA:False
Training samples count:  550
Training on 29 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1380, Training Loss: 0.1380, Initial Validation Loss: 0.1389, Validation Loss: 0.1389,V Acc: 0.2523, Top 70th Acc: 0.3333, Bottom 30th Acc: 0.0606
Fold [1/5] Epoch [10/100] Initial Loss: 0.1380, Training Loss: 0.0475, Initial Validation Loss: 0.1389, Validation Loss: 0.0588,V Acc: 0.7387, Top 70th Acc: 0.8462, Bottom 30th Acc: 0.4848
Fold [1/5] Epoch [20/100] Initial Loss: 0.1380, Training Loss: 0.0245, Initial Validation Loss: 0.1389, Validation Loss: 0.0434,V Acc: 0.7928, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.5152
Fold [1/5] Epoch [30/100] Initial Loss: 0.1380, Training Loss: 0.0212, Initial Validation Loss: 0.1389, Validation Loss: 0.0425,V Acc: 0.7748, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.4545
Stopping early at Epoch (base 0): 31  Rolling back to Epoch (base 0): 26  Top Validation Acc: 0.9102564102564102
Fold [2/5] Epoch [0/100] Initial Loss: 0.1387, Training Loss: 0.1387, Initial Validation Loss: 0.1357, Validation Loss: 0.1357,V Acc: 0.4414, Top 70th Acc: 0.4872, Bottom 30th Acc: 0.3333
Fold [2/5] Epoch [10/100] Initial Loss: 0.1387, Training Loss: 0.0448, Initial Validation Loss: 0.1357, Validation Loss: 0.0506,V Acc: 0.7838, Top 70th Acc: 0.8846, Bottom 30th Acc: 0.5455
Fold [2/5] Epoch [20/100] Initial Loss: 0.1387, Training Loss: 0.0272, Initial Validation Loss: 0.1357, Validation Loss: 0.0386,V Acc: 0.8018, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.4545
Stopping early at Epoch (base 0): 28  Rolling back to Epoch (base 0): 23  Top Validation Acc: 0.9487179487179487
Fold [3/5] Epoch [0/100] Initial Loss: 0.1413, Training Loss: 0.1413, Initial Validation Loss: 0.1298, Validation Loss: 0.1298,V Acc: 0.2727, Top 70th Acc: 0.3506, Bottom 30th Acc: 0.0909
Fold [3/5] Epoch [10/100] Initial Loss: 0.1413, Training Loss: 0.0346, Initial Validation Loss: 0.1298, Validation Loss: 0.0478,V Acc: 0.7636, Top 70th Acc: 0.8442, Bottom 30th Acc: 0.5758
Fold [3/5] Epoch [20/100] Initial Loss: 0.1413, Training Loss: 0.0225, Initial Validation Loss: 0.1298, Validation Loss: 0.0425,V Acc: 0.7818, Top 70th Acc: 0.8701, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 22  Rolling back to Epoch (base 0): 17  Top Validation Acc: 0.8831168831168831
Fold [4/5] Epoch [0/100] Initial Loss: 0.1375, Training Loss: 0.1375, Initial Validation Loss: 0.1387, Validation Loss: 0.1387,V Acc: 0.2545, Top 70th Acc: 0.3506, Bottom 30th Acc: 0.0303
Fold [4/5] Epoch [10/100] Initial Loss: 0.1375, Training Loss: 0.0401, Initial Validation Loss: 0.1387, Validation Loss: 0.0373,V Acc: 0.8727, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 18  Rolling back to Epoch (base 0): 13  Top Validation Acc: 0.948051948051948
Fold [5/5] Epoch [0/100] Initial Loss: 0.1369, Training Loss: 0.1369, Initial Validation Loss: 0.1257, Validation Loss: 0.1257,V Acc: 0.2963, Top 70th Acc: 0.3289, Bottom 30th Acc: 0.2188
Fold [5/5] Epoch [10/100] Initial Loss: 0.1369, Training Loss: 0.0401, Initial Validation Loss: 0.1257, Validation Loss: 0.0498,V Acc: 0.7315, Top 70th Acc: 0.8289, Bottom 30th Acc: 0.5000
Fold [5/5] Epoch [20/100] Initial Loss: 0.1369, Training Loss: 0.0256, Initial Validation Loss: 0.1257, Validation Loss: 0.0417,V Acc: 0.7407, Top 70th Acc: 0.8947, Bottom 30th Acc: 0.3750
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.881578947368421
68 4 [array([0.613055  , 0.01843203, 0.13283406, 0.11196441, 0.12371448],
      dtype=float32)]
Running train_nn.py with seed 69
CUDA:False
Training samples count:  550
Training on 30 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1388, Training Loss: 0.1388, Initial Validation Loss: 0.1342, Validation Loss: 0.1342,V Acc: 0.2703, Top 70th Acc: 0.3333, Bottom 30th Acc: 0.1212
Fold [1/5] Epoch [10/100] Initial Loss: 0.1388, Training Loss: 0.0294, Initial Validation Loss: 0.1342, Validation Loss: 0.0414,V Acc: 0.8108, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.5152
Fold [1/5] Epoch [20/100] Initial Loss: 0.1388, Training Loss: 0.0183, Initial Validation Loss: 0.1342, Validation Loss: 0.0370,V Acc: 0.8198, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.6061
Fold [1/5] Epoch [30/100] Initial Loss: 0.1388, Training Loss: 0.0165, Initial Validation Loss: 0.1342, Validation Loss: 0.0352,V Acc: 0.8198, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 30  Rolling back to Epoch (base 0): 25  Top Validation Acc: 0.9230769230769231
69 0 [array([0.5523086 , 0.1103661 , 0.06961752, 0.10604735, 0.16166043],
      dtype=float32)]
Fold [2/5] Epoch [0/100] Initial Loss: 0.1409, Training Loss: 0.1409, Initial Validation Loss: 0.1345, Validation Loss: 0.1345,V Acc: 0.3153, Top 70th Acc: 0.3974, Bottom 30th Acc: 0.1212
Fold [2/5] Epoch [10/100] Initial Loss: 0.1409, Training Loss: 0.0362, Initial Validation Loss: 0.1345, Validation Loss: 0.0499,V Acc: 0.7387, Top 70th Acc: 0.8846, Bottom 30th Acc: 0.3939
Fold [2/5] Epoch [20/100] Initial Loss: 0.1409, Training Loss: 0.0229, Initial Validation Loss: 0.1345, Validation Loss: 0.0448,V Acc: 0.7658, Top 70th Acc: 0.8974, Bottom 30th Acc: 0.4545
Fold [2/5] Epoch [30/100] Initial Loss: 0.1409, Training Loss: 0.0171, Initial Validation Loss: 0.1345, Validation Loss: 0.0413,V Acc: 0.7838, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.4848
Stopping early at Epoch (base 0): 37  Rolling back to Epoch (base 0): 32  Top Validation Acc: 0.9230769230769231
Fold [3/5] Epoch [0/100] Initial Loss: 0.1397, Training Loss: 0.1397, Initial Validation Loss: 0.1340, Validation Loss: 0.1340,V Acc: 0.2545, Top 70th Acc: 0.3117, Bottom 30th Acc: 0.1212
Fold [3/5] Epoch [10/100] Initial Loss: 0.1397, Training Loss: 0.0370, Initial Validation Loss: 0.1340, Validation Loss: 0.0421,V Acc: 0.8455, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.6970
Fold [3/5] Epoch [20/100] Initial Loss: 0.1397, Training Loss: 0.0194, Initial Validation Loss: 0.1340, Validation Loss: 0.0314,V Acc: 0.8636, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.6970
Fold [3/5] Epoch [30/100] Initial Loss: 0.1397, Training Loss: 0.0166, Initial Validation Loss: 0.1340, Validation Loss: 0.0326,V Acc: 0.8636, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 30  Rolling back to Epoch (base 0): 25  Top Validation Acc: 0.935064935064935
Fold [4/5] Epoch [0/100] Initial Loss: 0.1373, Training Loss: 0.1373, Initial Validation Loss: 0.1347, Validation Loss: 0.1347,V Acc: 0.3727, Top 70th Acc: 0.4156, Bottom 30th Acc: 0.2727
Fold [4/5] Epoch [10/100] Initial Loss: 0.1373, Training Loss: 0.0344, Initial Validation Loss: 0.1347, Validation Loss: 0.0373,V Acc: 0.8273, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.6061
Fold [4/5] Epoch [20/100] Initial Loss: 0.1373, Training Loss: 0.0198, Initial Validation Loss: 0.1347, Validation Loss: 0.0289,V Acc: 0.8636, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 21  Rolling back to Epoch (base 0): 16  Top Validation Acc: 0.948051948051948
Fold [5/5] Epoch [0/100] Initial Loss: 0.1382, Training Loss: 0.1382, Initial Validation Loss: 0.1308, Validation Loss: 0.1308,V Acc: 0.3426, Top 70th Acc: 0.4079, Bottom 30th Acc: 0.1875
Fold [5/5] Epoch [10/100] Initial Loss: 0.1382, Training Loss: 0.0392, Initial Validation Loss: 0.1308, Validation Loss: 0.0462,V Acc: 0.7778, Top 70th Acc: 0.8684, Bottom 30th Acc: 0.5625
Fold [5/5] Epoch [20/100] Initial Loss: 0.1382, Training Loss: 0.0195, Initial Validation Loss: 0.1308, Validation Loss: 0.0323,V Acc: 0.8426, Top 70th Acc: 0.9211, Bottom 30th Acc: 0.6562
Fold [5/5] Epoch [30/100] Initial Loss: 0.1382, Training Loss: 0.0162, Initial Validation Loss: 0.1308, Validation Loss: 0.0328,V Acc: 0.8056, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.5000
Stopping early at Epoch (base 0): 32  Rolling back to Epoch (base 0): 27  Top Validation Acc:
Stopping early at Epoch (base 0): 30  Rolling back to Epoch (base 0): 25  Top Validation Acc: 1.0
Running train_nn.py with seed 68
CUDA:False
Training samples count:  550
Training on 40 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1376, Training Loss: 0.1376, Initial Validation Loss: 0.1372, Validation Loss: 0.1372,V Acc: 0.3604, Top 70th Acc: 0.4231, Bottom 30th Acc: 0.2121
Fold [1/5] Epoch [10/100] Initial Loss: 0.1376, Training Loss: 0.0390, Initial Validation Loss: 0.1372, Validation Loss: 0.0519,V Acc: 0.7658, Top 70th Acc: 0.8974, Bottom 30th Acc: 0.4545
Fold [1/5] Epoch [20/100] Initial Loss: 0.1376, Training Loss: 0.0149, Initial Validation Loss: 0.1372, Validation Loss: 0.0326,V Acc: 0.8108, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.4242
Fold [1/5] Epoch [30/100] Initial Loss: 0.1376, Training Loss: 0.0117, Initial Validation Loss: 0.1372, Validation Loss: 0.0303,V Acc: 0.8559, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 31  Rolling back to Epoch (base 0): 26  Top Validation Acc: 0.9743589743589743
Fold [2/5] Epoch [0/100] Initial Loss: 0.1380, Training Loss: 0.1380, Initial Validation Loss: 0.1373, Validation Loss: 0.1373,V Acc: 0.2793, Top 70th Acc: 0.3462, Bottom 30th Acc: 0.1212
Fold [2/5] Epoch [10/100] Initial Loss: 0.1380, Training Loss: 0.0258, Initial Validation Loss: 0.1373, Validation Loss: 0.0338,V Acc: 0.8468, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.5455
Fold [2/5] Epoch [20/100] Initial Loss: 0.1380, Training Loss: 0.0137, Initial Validation Loss: 0.1373, Validation Loss: 0.0275,V Acc: 0.8649, Top 70th Acc: 1.0000, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 28  Rolling back to Epoch (base 0): 23  Top Validation Acc: 0.9871794871794872
Fold [3/5] Epoch [0/100] Initial Loss: 0.1407, Training Loss: 0.1407, Initial Validation Loss: 0.1313, Validation Loss: 0.1313,V Acc: 0.2273, Top 70th Acc: 0.2727, Bottom 30th Acc: 0.1212
Fold [3/5] Epoch [10/100] Initial Loss: 0.1407, Training Loss: 0.0343, Initial Validation Loss: 0.1313, Validation Loss: 0.0458,V Acc: 0.7455, Top 70th Acc: 0.8701, Bottom 30th Acc: 0.4545
Fold [3/5] Epoch [20/100] Initial Loss: 0.1407, Training Loss: 0.0141, Initial Validation Loss: 0.1313, Validation Loss: 0.0386,V Acc: 0.8273, Top 70th Acc: 0.8701, Bottom 30th Acc: 0.7273
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.8571428571428571
Fold [4/5] Epoch [0/100] Initial Loss: 0.1399, Training Loss: 0.1399, Initial Validation Loss: 0.1380, Validation Loss: 0.1380,V Acc: 0.3273, Top 70th Acc: 0.3377, Bottom 30th Acc: 0.3030
Fold [4/5] Epoch [10/100] Initial Loss: 0.1399, Training Loss: 0.0398, Initial Validation Loss: 0.1380, Validation Loss: 0.0421,V Acc: 0.8000, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.4848
Fold [4/5] Epoch [20/100] Initial Loss: 0.1399, Training Loss: 0.0182, Initial Validation Loss: 0.1380, Validation Loss: 0.0281,V Acc: 0.8818, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.6667
Fold [4/5] Epoch [30/100] Initial Loss: 0.1399, Training Loss: 0.0136, Initial Validation Loss: 0.1380, Validation Loss: 0.0238,V Acc: 0.8909, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.6970
Fold [4/5] Epoch [40/100] Initial Loss: 0.1399, Training Loss: 0.0118, Initial Validation Loss: 0.1380, Validation Loss: 0.0233,V Acc: 0.9000, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.7576
Stopping early at Epoch (base 0): 43  Rolling back to Epoch (base 0): 38  Top Validation Acc: 0.961038961038961
Fold [5/5] Epoch [0/100] Initial Loss: 0.1383, Training Loss: 0.1383, Initial Validation Loss: 0.1292, Validation Loss: 0.1292,V Acc: 0.3333, Top 70th Acc: 0.4211, Bottom 30th Acc: 0.1250
Fold [5/5] Epoch [10/100] Initial Loss: 0.1383, Training Loss: 0.0275, Initial Validation Loss: 0.1292, Validation Loss: 0.0336,V Acc: 0.8796, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.7188
Fold [5/5] Epoch [20/100] Initial Loss: 0.1383, Training Loss: 0.0141, Initial Validation Loss: 0.1292, Validation Loss: 0.0309,V Acc: 0.8426, Top 70th Acc: 0.9211, Bottom 30th Acc: 0.6562
Stopping early at Epoch (base 0): 21  Rolling back to Epoch (base 0): 16  Top Validation Acc: 0.9078947368421053
68 4 [array([0.4658227 , 0.15804759, 0.10909032, 0.09430526, 0.17273408],
      dtype=float32)]
Running train_nn.py with seed 69
CUDA:False
Training samples count:  550
Training on 40 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1396, Training Loss: 0.1396, Initial Validation Loss: 0.1353, Validation Loss: 0.1353,V Acc: 0.3243, Top 70th Acc: 0.3077, Bottom 30th Acc: 0.3636
Fold [1/5] Epoch [10/100] Initial Loss: 0.1396, Training Loss: 0.0343, Initial Validation Loss: 0.1353, Validation Loss: 0.0461,V Acc: 0.7838, Top 70th Acc: 0.8846, Bottom 30th Acc: 0.5455
Fold [1/5] Epoch [20/100] Initial Loss: 0.1396, Training Loss: 0.0149, Initial Validation Loss: 0.1353, Validation Loss: 0.0367,V Acc: 0.8288, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.6364
Fold [1/5] Epoch [30/100] Initial Loss: 0.1396, Training Loss: 0.0114, Initial Validation Loss: 0.1353, Validation Loss: 0.0347,V Acc: 0.8198, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.6061
Fold [1/5] Epoch [40/100] Initial Loss: 0.1396, Training Loss: 0.0101, Initial Validation Loss: 0.1353, Validation Loss: 0.0335,V Acc: 0.8288, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 44  Rolling back to Epoch (base 0): 39  Top Validation Acc: 0.9102564102564102
69 0 [array([0.6436441 , 0.02076014, 0.12933296, 0.10819563, 0.09806724],
      dtype=float32)]
Fold [2/5] Epoch [0/100] Initial Loss: 0.1371, Training Loss: 0.1371, Initial Validation Loss: 0.1371, Validation Loss: 0.1371,V Acc: 0.3694, Top 70th Acc: 0.3590, Bottom 30th Acc: 0.3939
Fold [2/5] Epoch [10/100] Initial Loss: 0.1371, Training Loss: 0.0323, Initial Validation Loss: 0.1371, Validation Loss: 0.0387,V Acc: 0.8378, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.6061
Fold [2/5] Epoch [20/100] Initial Loss: 0.1371, Training Loss: 0.0145, Initial Validation Loss: 0.1371, Validation Loss: 0.0330,V Acc: 0.8378, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.9358974358974359
Fold [3/5] Epoch [0/100] Initial Loss: 0.1404, Training Loss: 0.1404, Initial Validation Loss: 0.1351, Validation Loss: 0.1351,V Acc: 0.2545, Top 70th Acc: 0.1948, Bottom 30th Acc: 0.3939
Fold [3/5] Epoch [10/100] Initial Loss: 0.1404, Training Loss: 0.0411, Initial Validation Loss: 0.1351, Validation Loss: 0.0424,V Acc: 0.8364, Top 70th Acc: 0.8961, Bottom 30th Acc: 0.6970
Fold [3/5] Epoch [20/100] Initial Loss: 0.1404, Training Loss: 0.0155, Initial Validation Loss: 0.1351, Validation Loss: 0.0275,V Acc: 0.8545, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.961038961038961
Fold [4/5] Epoch [0/100] Initial Loss: 0.1390, Training Loss: 0.1390, Initial Validation Loss: 0.1355, Validation Loss: 0.1355,V Acc: 0.2727, Top 70th Acc: 0.3506, Bottom 30th Acc: 0.0909
Fold [4/5] Epoch [10/100] Initial Loss: 0.1390, Training Loss: 0.0416, Initial Validation Loss: 0.1355, Validation Loss: 0.0460,V Acc: 0.8091, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.5455
Fold [4/5] Epoch [20/100] Initial Loss: 0.1390, Training Loss: 0.0162, Initial Validation Loss: 0.1355, Validation Loss: 0.0256,V Acc: 0.8636, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.6061
Fold [4/5] Epoch [30/100] Initial Loss: 0.1390, Training Loss: 0.0131, Initial Validation Loss: 0.1355, Validation Loss: 0.0240,V Acc: 0.8636, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 34  Rolling back to Epoch (base 0): 29  Top Validation Acc: 0.974025974025974
Fold [5/5] Epoch [0/100] Initial Loss: 0.1360, Training Loss: 0.1360, Initial Validation Loss: 0.1287, Validation Loss: 0.1287,V Acc: 0.2407, Top 70th Acc: 0.3289, Bottom 30th Acc: 0.0312
Fold [5/5] Epoch [10/100] Initial Loss: 0.1360, Training Loss: 0.0245, Initial Validation Loss: 0.1287, Validation Loss: 0.0315,V Acc: 0.8704, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.6875
Fold [5/5] Epoch [20/100] Initial Loss: 0.1360, Training Loss: 0.0139, Initial Validation Loss: 0.1287, Validation Loss: 0.0296,V Acc: 0.8426, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.5938
Fold [5/5] Epoch [10/100] Initial Loss: 0.1296, Training Loss: 0.0199, Initial Validation Loss: 0.1121, Validation Loss: 0.0322,V Acc: 0.8426, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.5625
Fold [5/5] Epoch [20/100] Initial Loss: 0.1296, Training Loss: 0.0165, Initial Validation Loss: 0.1121, Validation Loss: 0.0299,V Acc: 0.8519, Top 70th Acc: 0.9737, Bottom 30th Acc: 0.5625
Stopping early at Epoch (base 0): 20  Rolling back to Epoch (base 0): 15  Top Validation Acc: 0.9736842105263158
96 4 [array([0.86117744, 0.03794447, 0.0259386 , 0.03065705, 0.04428245],
      dtype=float32)]
Running train_nn.py with seed 97
CUDA:False
Training samples count:  550
Training on 21 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1383, Training Loss: 0.1383, Initial Validation Loss: 0.1303, Validation Loss: 0.1303,V Acc: 0.4234, Top 70th Acc: 0.5128, Bottom 30th Acc: 0.2121
Fold [1/5] Epoch [10/100] Initial Loss: 0.1383, Training Loss: 0.0273, Initial Validation Loss: 0.1303, Validation Loss: 0.0235,V Acc: 0.9009, Top 70th Acc: 1.0000, Bottom 30th Acc: 0.6667
Fold [1/5] Epoch [20/100] Initial Loss: 0.1383, Training Loss: 0.0191, Initial Validation Loss: 0.1303, Validation Loss: 0.0227,V Acc: 0.8739, Top 70th Acc: 1.0000, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 1.0
Fold [2/5] Epoch [0/100] Initial Loss: 0.1330, Training Loss: 0.1330, Initial Validation Loss: 0.1218, Validation Loss: 0.1218,V Acc: 0.4414, Top 70th Acc: 0.5897, Bottom 30th Acc: 0.0909
Fold [2/5] Epoch [10/100] Initial Loss: 0.1330, Training Loss: 0.0270, Initial Validation Loss: 0.1218, Validation Loss: 0.0358,V Acc: 0.8468, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.6667
Fold [2/5] Epoch [20/100] Initial Loss: 0.1330, Training Loss: 0.0175, Initial Validation Loss: 0.1218, Validation Loss: 0.0345,V Acc: 0.8649, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.7273
Fold [2/5] Epoch [30/100] Initial Loss: 0.1330, Training Loss: 0.0141, Initial Validation Loss: 0.1218, Validation Loss: 0.0270,V Acc: 0.8829, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.7879
Stopping early at Epoch (base 0): 31  Rolling back to Epoch (base 0): 26  Top Validation Acc: 0.9358974358974359
97 1 [array([0.7965576 , 0.01083483, 0.03400972, 0.09808589, 0.06051199],
      dtype=float32)]
Fold [3/5] Epoch [0/100] Initial Loss: 0.1370, Training Loss: 0.1370, Initial Validation Loss: 0.1232, Validation Loss: 0.1232,V Acc: 0.5000, Top 70th Acc: 0.5584, Bottom 30th Acc: 0.3636
Fold [3/5] Epoch [10/100] Initial Loss: 0.1370, Training Loss: 0.0264, Initial Validation Loss: 0.1232, Validation Loss: 0.0246,V Acc: 0.8818, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 15  Rolling back to Epoch (base 0): 10  Top Validation Acc: 0.961038961038961
Fold [4/5] Epoch [0/100] Initial Loss: 0.1351, Training Loss: 0.1351, Initial Validation Loss: 0.1279, Validation Loss: 0.1279,V Acc: 0.4364, Top 70th Acc: 0.4545, Bottom 30th Acc: 0.3939
Fold [4/5] Epoch [10/100] Initial Loss: 0.1351, Training Loss: 0.0237, Initial Validation Loss: 0.1279, Validation Loss: 0.0334,V Acc: 0.8636, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.6970
Fold [4/5] Epoch [20/100] Initial Loss: 0.1351, Training Loss: 0.0185, Initial Validation Loss: 0.1279, Validation Loss: 0.0265,V Acc: 0.8818, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 22  Rolling back to Epoch (base 0): 17  Top Validation Acc: 0.961038961038961
Fold [5/5] Epoch [0/100] Initial Loss: 0.1330, Training Loss: 0.1330, Initial Validation Loss: 0.1148, Validation Loss: 0.1148,V Acc: 0.4815, Top 70th Acc: 0.5526, Bottom 30th Acc: 0.3125
Fold [5/5] Epoch [10/100] Initial Loss: 0.1330, Training Loss: 0.0219, Initial Validation Loss: 0.1148, Validation Loss: 0.0356,V Acc: 0.8056, Top 70th Acc: 0.8947, Bottom 30th Acc: 0.5938
Fold [5/5] Epoch [20/100] Initial Loss: 0.1330, Training Loss: 0.0158, Initial Validation Loss: 0.1148, Validation Loss: 0.0348,V Acc: 0.7963, Top 70th Acc: 0.9211, Bottom 30th Acc: 0.5000
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.8947368421052632
Running train_nn.py with seed 98
CUDA:False
Training samples count:  550
Training on 21 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1382, Training Loss: 0.1382, Initial Validation Loss: 0.1296, Validation Loss: 0.1296,V Acc: 0.4775, Top 70th Acc: 0.5641, Bottom 30th Acc: 0.2727
Fold [1/5] Epoch [10/100] Initial Loss: 0.1382, Training Loss: 0.0250, Initial Validation Loss: 0.1296, Validation Loss: 0.0344,V Acc: 0.8649, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.6667
Fold [1/5] Epoch [20/100] Initial Loss: 0.1382, Training Loss: 0.0177, Initial Validation Loss: 0.1296, Validation Loss: 0.0300,V Acc: 0.8829, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 20  Rolling back to Epoch (base 0): 15  Top Validation Acc: 0.9743589743589743
98 0 [array([0.8221914 , 0.02263704, 0.02366141, 0.07523562, 0.05627444],
      dtype=float32)]
Fold [2/5] Epoch [0/100] Initial Loss: 0.1282, Training Loss: 0.1282, Initial Validation Loss: 0.1073, Validation Loss: 0.1073,V Acc: 0.5586, Top 70th Acc: 0.6667, Bottom 30th Acc: 0.3030
Fold [2/5] Epoch [10/100] Initial Loss: 0.1282, Training Loss: 0.0271, Initial Validation Loss: 0.1073, Validation Loss: 0.0406,V Acc: 0.8288, Top 70th Acc: 0.8846, Bottom 30th Acc: 0.6970
Fold [2/5] Epoch [20/100] Initial Loss: 0.1282, Training Loss: 0.0185, Initial Validation Loss: 0.1073, Validation Loss: 0.0363,V Acc: 0.7928, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.5152
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.9230769230769231
Fold [3/5] Epoch [0/100] Initial Loss: 0.1284, Training Loss: 0.1284, Initial Validation Loss: 0.1175, Validation Loss: 0.1175,V Acc: 0.6000, Top 70th Acc: 0.7143, Bottom 30th Acc: 0.3333
Fold [3/5] Epoch [10/100] Initial Loss: 0.1284, Training Loss: 0.0221, Initial Validation Loss: 0.1175, Validation Loss: 0.0334,V Acc: 0.8545, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.6061
Fold [3/5] Epoch [20/100] Initial Loss: 0.1284, Training Loss: 0.0155, Initial Validation Loss: 0.1175, Validation Loss: 0.0278,V Acc: 0.8727, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 20  Rolling back to Epoch (base 0): 15  Top Validation Acc: 0.961038961038961
Fold [4/5] Epoch [0/100] Initial Loss: 0.1311, Training Loss: 0.1311, Initial Validation Loss: 0.1151, Validation Loss: 0.1151,V Acc: 0.4636, Top 70th Acc: 0.5455, Bottom 30th Acc: 0.2727
Fold [4/5] Epoch [10/100] Initial Loss: 0.1311, Training Loss: 0.0260, Initial Validation Loss: 0.1151, Validation Loss: 0.0312,V Acc: 0.8182, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.5455
Fold [4/5] Epoch [20/100] Initial Loss: 0.1311, Training Loss: 0.0169, Initial Validation Loss: 0.1151, Validation Loss: 0.0285,V Acc: 0.8455, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.935064935064935
Fold [5/5] Epoch [0/100] Initial Loss: 0.1315, Training Loss: 0.1315, Initial Validation Loss: 0.1227, Validation Loss: 0.1227,V Acc: 0.5370, Top 70th Acc: 0.6447, Bottom 30th Acc: 0.2812
Fold [5/5] Epoch [10/100] Initial Loss: 0.1315, Training Loss: 0.0239, Initial Validation Loss: 0.1227, Validation Loss: 0.0261,V Acc: 0.8611, Top 70th Acc: 0.9737, Bottom 30th Acc: 0.5938
Fold [5/5] Epoch [20/100] Initial Loss: 0.1315, Training Loss: 0.0180, Initial Validation Loss: 0.1227, Validation Loss: 0.0198,V Acc: 0.9259, Top 70th Acc: 0.9868, Bottom 30th Acc: 0.7812
Stopping early at Epoch (base 0): 27  Rolling back to Epoch (base 0): 22  Top Validation Acc: 0.9868421052631579
Running train_nn.py with seed 99
CUDA:False
Training samples count:  550
Training on 21 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1325, Training Loss: 0.1325, Initial Validation Loss: 0.1152, Validation Loss: 0.1152,V Acc: 0.4775, Top 70th Acc: 0.5641, Bottom 30th Acc: 0.2727
Fold [1/5] Epoch [10/100] Initial Loss: 0.1325, Training Loss: 0.0231, Initial Validation Loss: 0.1152, Validation Loss: 0.0237,V Acc: 0.9009, Top 70th Acc: 0.9872, Bottom 30th Acc: 0.6970 Top Validation Acc: 0.935064935064935
52 2 [array([0.12114787, 0.03249694, 0.02302116, 0.22274157, 0.60059243],
      dtype=float32)]
Fold [4/5] Epoch [0/100] Initial Loss: 0.1366, Training Loss: 0.1366, Initial Validation Loss: 0.1377, Validation Loss: 0.1377,V Acc: 0.4364, Top 70th Acc: 0.4545, Bottom 30th Acc: 0.3939
Fold [4/5] Epoch [10/100] Initial Loss: 0.1366, Training Loss: 0.0150, Initial Validation Loss: 0.1377, Validation Loss: 0.0390,V Acc: 0.8182, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.5152
Fold [4/5] Epoch [20/100] Initial Loss: 0.1366, Training Loss: 0.0047, Initial Validation Loss: 0.1377, Validation Loss: 0.0311,V Acc: 0.8455, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.5455
Fold [4/5] Epoch [30/100] Initial Loss: 0.1366, Training Loss: 0.0038, Initial Validation Loss: 0.1377, Validation Loss: 0.0306,V Acc: 0.8455, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.5455
Fold [4/5] Epoch [40/100] Initial Loss: 0.1366, Training Loss: 0.0035, Initial Validation Loss: 0.1377, Validation Loss: 0.0306,V Acc: 0.8364, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.5152
Stopping early at Epoch (base 0): 42  Rolling back to Epoch (base 0): 37  Top Validation Acc: 0.974025974025974
Fold [5/5] Epoch [0/100] Initial Loss: 0.1400, Training Loss: 0.1400, Initial Validation Loss: 0.1301, Validation Loss: 0.1301,V Acc: 0.2685, Top 70th Acc: 0.3026, Bottom 30th Acc: 0.1875
Fold [5/5] Epoch [10/100] Initial Loss: 0.1400, Training Loss: 0.0188, Initial Validation Loss: 0.1301, Validation Loss: 0.0339,V Acc: 0.8056, Top 70th Acc: 0.9211, Bottom 30th Acc: 0.5312
Stopping early at Epoch (base 0): 19  Rolling back to Epoch (base 0): 14  Top Validation Acc: 0.9473684210526315
Running train_nn.py with seed 53
CUDA:False
Training samples count:  550
Training on 163 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1389, Training Loss: 0.1389, Initial Validation Loss: 0.1371, Validation Loss: 0.1371,V Acc: 0.2973, Top 70th Acc: 0.3462, Bottom 30th Acc: 0.1818
Fold [1/5] Epoch [10/100] Initial Loss: 0.1389, Training Loss: 0.0189, Initial Validation Loss: 0.1371, Validation Loss: 0.0352,V Acc: 0.8649, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.6364
Fold [1/5] Epoch [20/100] Initial Loss: 0.1389, Training Loss: 0.0047, Initial Validation Loss: 0.1371, Validation Loss: 0.0288,V Acc: 0.9009, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.7576
Stopping early at Epoch (base 0): 29  Rolling back to Epoch (base 0): 24  Top Validation Acc: 0.9615384615384616
Fold [2/5] Epoch [0/100] Initial Loss: 0.1380, Training Loss: 0.1380, Initial Validation Loss: 0.1311, Validation Loss: 0.1311,V Acc: 0.2523, Top 70th Acc: 0.3590, Bottom 30th Acc: 0.0000
Fold [2/5] Epoch [10/100] Initial Loss: 0.1380, Training Loss: 0.0105, Initial Validation Loss: 0.1311, Validation Loss: 0.0309,V Acc: 0.8378, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 15  Rolling back to Epoch (base 0): 10  Top Validation Acc: 0.9615384615384616
Fold [3/5] Epoch [0/100] Initial Loss: 0.1377, Training Loss: 0.1377, Initial Validation Loss: 0.1307, Validation Loss: 0.1307,V Acc: 0.2909, Top 70th Acc: 0.3506, Bottom 30th Acc: 0.1515
Fold [3/5] Epoch [10/100] Initial Loss: 0.1377, Training Loss: 0.0140, Initial Validation Loss: 0.1307, Validation Loss: 0.0307,V Acc: 0.8455, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.5758
Fold [3/5] Epoch [20/100] Initial Loss: 0.1377, Training Loss: 0.0051, Initial Validation Loss: 0.1307, Validation Loss: 0.0290,V Acc: 0.8455, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 22  Rolling back to Epoch (base 0): 17  Top Validation Acc: 0.948051948051948
Fold [4/5] Epoch [0/100] Initial Loss: 0.1407, Training Loss: 0.1407, Initial Validation Loss: 0.1380, Validation Loss: 0.1380,V Acc: 0.2273, Top 70th Acc: 0.2727, Bottom 30th Acc: 0.1212
Fold [4/5] Epoch [10/100] Initial Loss: 0.1407, Training Loss: 0.0207, Initial Validation Loss: 0.1380, Validation Loss: 0.0353,V Acc: 0.8545, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.6667
Fold [4/5] Epoch [20/100] Initial Loss: 0.1407, Training Loss: 0.0054, Initial Validation Loss: 0.1380, Validation Loss: 0.0226,V Acc: 0.9273, Top 70th Acc: 0.9870, Bottom 30th Acc: 0.7879
Fold [4/5] Epoch [30/100] Initial Loss: 0.1407, Training Loss: 0.0042, Initial Validation Loss: 0.1380, Validation Loss: 0.0225,V Acc: 0.9091, Top 70th Acc: 0.9870, Bottom 30th Acc: 0.7273
Stopping early at Epoch (base 0): 33  Rolling back to Epoch (base 0): 28  Top Validation Acc: 0.987012987012987
53 3 [array([0.322602  , 0.03376099, 0.06134878, 0.30587685, 0.27641144],
      dtype=float32)]
Fold [5/5] Epoch [0/100] Initial Loss: 0.1397, Training Loss: 0.1397, Initial Validation Loss: 0.1325, Validation Loss: 0.1325,V Acc: 0.5093, Top 70th Acc: 0.5395, Bottom 30th Acc: 0.4375
Fold [5/5] Epoch [10/100] Initial Loss: 0.1397, Training Loss: 0.0160, Initial Validation Loss: 0.1325, Validation Loss: 0.0381,V Acc: 0.7963, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.4688
Fold [5/5] Epoch [20/100] Initial Loss: 0.1397, Training Loss: 0.0059, Initial Validation Loss: 0.1325, Validation Loss: 0.0357,V Acc: 0.8056, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.5000
Fold [5/5] Epoch [30/100] Initial Loss: 0.1397, Training Loss: 0.0045, Initial Validation Loss: 0.1325, Validation Loss: 0.0331,V Acc: 0.8333, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.5625
Fold [5/5] Epoch [40/100] Initial Loss: 0.1397, Training Loss: 0.0042, Initial Validation Loss: 0.1325, Validation Loss: 0.0323,V Acc: 0.8426, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.6250
Fold [5/5] Epoch [50/100] Initial Loss: 0.1397, Training Loss: 0.0040, Initial Validation Loss: 0.1325, Validation Loss: 0.0311,V Acc: 0.8611, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.6250
Stopping early at Epoch (base 0): 52  Rolling back to Epoch (base 0): 47  Top Validation Acc: 0.9473684210526315
Running train_nn.py with seed 54
CUDA:False
Training samples count:  550
Training on 163 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1366, Training Loss: 0.1366, Initial Validation Loss: 0.1395, Validation Loss: 0.1395,V Acc: 0.3153, Top 70th Acc: 0.3205, Bottom 30th Acc: 0.3030
Fold [1/5] Epoch [10/100] Initial Loss: 0.1366, Training Loss: 0.0149, Initial Validation Loss: 0.1395, Validation Loss: 0.0318,V Acc: 0.8739, Top 70th Acc: 0.9872, Bottom 30th Acc: 0.6061
Fold [1/5] Epoch [20/100] Initial Loss: 0.1366, Training Loss: 0.0043, Initial Validation Loss: 0.1395, Validation Loss: 0.0268,V Acc: 0.8829, Top 70th Acc: 0.9872, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.9871794871794872
Fold [2/5] Epoch [0/100] Initial Loss: 0.1384, Training Loss: 0.1384, Initial Validation Loss: 0.1349, Validation Loss: 0.1349,V Acc: 0.2703, Top 70th Acc: 0.3462, Bottom 30th Acc: 0.0909
Fold [2/5] Epoch [10/100] Initial Loss: 0.1384, Training Loss: 0.0154, Initial Validation Loss: 0.1349, Validation Loss: 0.0286,V Acc: 0.8468, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.5758
Fold [2/5] Epoch [20/100] Initial Loss: 0.1384, Training Loss: 0.0048, Initial Validation Loss: 0.1349, Validation Loss: 0.0259,V Acc: 0.8649, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 20  Rolling back to Epoch (base 0): 15  Top Validation Acc: 0.9487179487179487
Fold [3/5] Epoch [0/100] Initial Loss: 0.1389, Training Loss: 0.1389, Initial Validation Loss: 0.1329, Validation Loss: 0.1329,V Acc: 0.2727, Top 70th Acc: 0.2727, Bottom 30th Acc: 0.2727
Fold [3/5] Epoch [10/100] Initial Loss: 0.1389, Training Loss: 0.0256, Initial Validation Loss: 0.1329, Validation Loss: 0.0495,V Acc: 0.7727, Top 70th Acc: 0.8701, Bottom 30th Acc: 0.5455
Fold [3/5] Epoch [20/100] Initial Loss: 0.1389, Training Loss: 0.0066, Initial Validation Loss: 0.1329, Validation Loss: 0.0372,V Acc: 0.8091, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.5152
Fold [3/5] Epoch [30/100] Initial Loss: 0.1389, Training Loss: 0.0047, Initial Validation Loss: 0.1329, Validation Loss: 0.0362,V Acc: 0.8364, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 33  Rolling back to Epoch (base 0): 28  Top Validation Acc: 0.922077922077922
Fold [4/5] Epoch [0/100] Initial Loss: 0.1388, Training Loss: 0.1388, Initial Validation Loss: 0.1296, Validation Loss: 0.1296,V Acc: 0.3818, Top 70th Acc: 0.4416, Bottom 30th Acc: 0.2424
Fold [5/5] Epoch [10/100] Initial Loss: 0.1418, Training Loss: 0.0380, Initial Validation Loss: 0.1328, Validation Loss: 0.0430,V Acc: 0.7778, Top 70th Acc: 0.8684, Bottom 30th Acc: 0.5625
Fold [5/5] Epoch [20/100] Initial Loss: 0.1418, Training Loss: 0.0231, Initial Validation Loss: 0.1328, Validation Loss: 0.0320,V Acc: 0.8241, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.5000
Stopping early at Epoch (base 0): 29  Rolling back to Epoch (base 0): 24  Top Validation Acc: 0.9342105263157895
Running train_nn.py with seed 70
CUDA:False
Training samples count:  550
Training on 20 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1349, Training Loss: 0.1349, Initial Validation Loss: 0.1317, Validation Loss: 0.1317,V Acc: 0.4054, Top 70th Acc: 0.5385, Bottom 30th Acc: 0.0909
Fold [1/5] Epoch [10/100] Initial Loss: 0.1349, Training Loss: 0.0313, Initial Validation Loss: 0.1317, Validation Loss: 0.0432,V Acc: 0.7748, Top 70th Acc: 0.8718, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 19  Rolling back to Epoch (base 0): 14  Top Validation Acc: 0.8974358974358975
Fold [2/5] Epoch [0/100] Initial Loss: 0.1380, Training Loss: 0.1380, Initial Validation Loss: 0.1314, Validation Loss: 0.1314,V Acc: 0.3153, Top 70th Acc: 0.3333, Bottom 30th Acc: 0.2727
Fold [2/5] Epoch [10/100] Initial Loss: 0.1380, Training Loss: 0.0299, Initial Validation Loss: 0.1314, Validation Loss: 0.0394,V Acc: 0.8378, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.6061
Fold [2/5] Epoch [20/100] Initial Loss: 0.1380, Training Loss: 0.0208, Initial Validation Loss: 0.1314, Validation Loss: 0.0351,V Acc: 0.8649, Top 70th Acc: 0.8974, Bottom 30th Acc: 0.7879
Fold [2/5] Epoch [30/100] Initial Loss: 0.1380, Training Loss: 0.0185, Initial Validation Loss: 0.1314, Validation Loss: 0.0329,V Acc: 0.8378, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 35  Rolling back to Epoch (base 0): 30  Top Validation Acc: 0.9102564102564102
70 1 [array([0.2917783 , 0.17184415, 0.0948288 , 0.32813007, 0.11341864],
      dtype=float32)]
Fold [3/5] Epoch [0/100] Initial Loss: 0.1377, Training Loss: 0.1377, Initial Validation Loss: 0.1324, Validation Loss: 0.1324,V Acc: 0.3545, Top 70th Acc: 0.3636, Bottom 30th Acc: 0.3333
Fold [3/5] Epoch [10/100] Initial Loss: 0.1377, Training Loss: 0.0350, Initial Validation Loss: 0.1324, Validation Loss: 0.0329,V Acc: 0.8818, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.6667
Fold [3/5] Epoch [20/100] Initial Loss: 0.1377, Training Loss: 0.0241, Initial Validation Loss: 0.1324, Validation Loss: 0.0239,V Acc: 0.9000, Top 70th Acc: 0.9870, Bottom 30th Acc: 0.6970
Fold [3/5] Epoch [30/100] Initial Loss: 0.1377, Training Loss: 0.0212, Initial Validation Loss: 0.1324, Validation Loss: 0.0233,V Acc: 0.9091, Top 70th Acc: 1.0000, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 36  Rolling back to Epoch (base 0): 31  Top Validation Acc: 0.987012987012987
Fold [4/5] Epoch [0/100] Initial Loss: 0.1337, Training Loss: 0.1337, Initial Validation Loss: 0.1334, Validation Loss: 0.1334,V Acc: 0.3455, Top 70th Acc: 0.3636, Bottom 30th Acc: 0.3030
Fold [4/5] Epoch [10/100] Initial Loss: 0.1337, Training Loss: 0.0335, Initial Validation Loss: 0.1334, Validation Loss: 0.0366,V Acc: 0.9000, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.7576
Fold [4/5] Epoch [20/100] Initial Loss: 0.1337, Training Loss: 0.0228, Initial Validation Loss: 0.1334, Validation Loss: 0.0319,V Acc: 0.8727, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.6364
Fold [4/5] Epoch [30/100] Initial Loss: 0.1337, Training Loss: 0.0209, Initial Validation Loss: 0.1334, Validation Loss: 0.0315,V Acc: 0.8818, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 34  Rolling back to Epoch (base 0): 29  Top Validation Acc: 0.961038961038961
Fold [5/5] Epoch [0/100] Initial Loss: 0.1374, Training Loss: 0.1374, Initial Validation Loss: 0.1238, Validation Loss: 0.1238,V Acc: 0.3611, Top 70th Acc: 0.4737, Bottom 30th Acc: 0.0938
Fold [5/5] Epoch [10/100] Initial Loss: 0.1374, Training Loss: 0.0341, Initial Validation Loss: 0.1238, Validation Loss: 0.0337,V Acc: 0.7963, Top 70th Acc: 0.9211, Bottom 30th Acc: 0.5000
Fold [5/5] Epoch [20/100] Initial Loss: 0.1374, Training Loss: 0.0232, Initial Validation Loss: 0.1238, Validation Loss: 0.0294,V Acc: 0.8148, Top 70th Acc: 0.9079, Bottom 30th Acc: 0.5938
Stopping early at Epoch (base 0): 29  Rolling back to Epoch (base 0): 24  Top Validation Acc: 0.9210526315789473
Running train_nn.py with seed 71
CUDA:False
Training samples count:  550
Training on 20 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1395, Training Loss: 0.1395, Initial Validation Loss: 0.1379, Validation Loss: 0.1379,V Acc: 0.2523, Top 70th Acc: 0.3205, Bottom 30th Acc: 0.0909
Fold [1/5] Epoch [10/100] Initial Loss: 0.1395, Training Loss: 0.0407, Initial Validation Loss: 0.1379, Validation Loss: 0.0442,V Acc: 0.8018, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.5152
Fold [1/5] Epoch [20/100] Initial Loss: 0.1395, Training Loss: 0.0259, Initial Validation Loss: 0.1379, Validation Loss: 0.0312,V Acc: 0.8559, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.6061
Fold [1/5] Epoch [30/100] Initial Loss: 0.1395, Training Loss: 0.0227, Initial Validation Loss: 0.1379, Validation Loss: 0.0301,V Acc: 0.8739, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 36  Rolling back to Epoch (base 0): 31  Top Validation Acc: 0.9487179487179487
Fold [2/5] Epoch [0/100] Initial Loss: 0.1371, Training Loss: 0.1371, Initial Validation Loss: 0.1321, Validation Loss: 0.1321,V Acc: 0.2703, Top 70th Acc: 0.3077, Bottom 30th Acc: 0.1818
Fold [2/5] Epoch [10/100] Initial Loss: 0.1371, Training Loss: 0.0317, Initial Validation Loss: 0.1321, Validation Loss: 0.0384,V Acc: 0.8378, Top 70th Acc: 0.8974, Bottom 30th Acc: 0.6970
Fold [2/5] Epoch [20/100] Initial Loss: 0.1371, Training Loss: 0.0235, Initial Validation Loss: 0.1321, Validation Loss: 0.0327,V Acc: 0.8559, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.6970
Fold [2/5] Epoch [30/100] Initial Loss: 0.1371, Training Loss: 0.0212, Initial Validation Loss: 0.1321, Validation Loss: 0.0323,V Acc: 0.8559, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.7273
Stopping early at Epoch (base 0): 30  Rolling back to Epoch (base 0): 25  Top Validation Acc: 0.9102564102564102
Fold [3/5] Epoch [0/100] Initial Loss: 0.1396, Training Loss: 0.1396, Initial Validation Loss: 0.1301, Validation Loss: 0.1301,V Acc: 0.2545, Top 70th Acc: 0.3247, Bottom 30th Acc: 0.0909
Fold [3/5] Epoch [10/100] Initial Loss: 0.1396, Training Loss: 0.0384, Initial Validation Loss: 0.1301, Validation Loss: 0.0459,V Acc: 0.7727, Top 70th Acc: 0.8701, Bottom 30th Acc: 0.5455
Fold [3/5] Epoch [20/100] Initial Loss: 0.1396, Training Loss: 0.0234, Initial Validation Loss: 0.1301, Validation Loss: 0.0365,V Acc: 0.8000, Top 70th Acc: 0.8961, Bottom 30th Acc: 0.5758
Fold [3/5] Epoch [30/100] Initial Loss: 0.1396, Training Loss: 0.0211, Initial Validation Loss: 0.1301, Validation Loss: 0.0370,V Acc: 0.7909, Top 70th Acc: 0.8961, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 30  Rolling back to Epoch (base 0): 25  Top Validation Acc: 0.8961038961038961
Fold [4/5] Epoch [0/100] Initial Loss: 0.1361, Training Loss: 0.1361, Initial Validation Loss: 0.1331, Validation Loss: 0.1331,V Acc: 0.2727, Top 70th Acc: 0.3247, Bottom 30th Acc: 0.1515
Fold [4/5] Epoch [10/100] Initial Loss: 0.1361, Training Loss: 0.0321, Initial Validation Loss: 0.1331, Validation Loss: 0.0331,V Acc: 0.8909, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.6970
Fold [4/5] Epoch [20/100] Initial Loss: 0.1361, Training Loss: 0.0235, Initial Validation Loss: 0.1331, Validation Loss: 0.0321,V Acc: 0.8636, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 20  Rolling back to Epoch (base 0): 15  Top Validation Acc: 0.961038961038961
71 3 [array([0.44890726, 0.07152273, 0.19624603, 0.09943829, 0.18388571],
      dtype=float32)]
Fold [5/5] Epoch [0/100] Initial Loss: 0.1393, Training Loss: 0.1393, Initial Validation Loss: 0.1361, Validation Loss: 0.1361,V Acc: 0.3519, Top 70th Acc: 0.4079, Bottom 30th Acc: 0.2188
Fold [5/5] Epoch [10/100] Initial Loss: 0.1393, Training Loss: 0.0383, Initial Validation Loss: 0.1361, Validation Loss: 0.0445,V Acc: 0.7963, Top 70th Acc: 0.9211, Bottom 30th Acc: 0.5000
Stopping early at Epoch (base 0): 27  Rolling back to Epoch (base 0): 22  Top Validation Acc: 0.7662337662337663
Fold [4/5] Epoch [0/100] Initial Loss: 0.1356, Training Loss: 0.1356, Initial Validation Loss: 0.1228, Validation Loss: 0.1228,V Acc: 0.4091, Top 70th Acc: 0.5065, Bottom 30th Acc: 0.1818
Fold [4/5] Epoch [10/100] Initial Loss: 0.1356, Training Loss: 0.0798, Initial Validation Loss: 0.1228, Validation Loss: 0.0823,V Acc: 0.6091, Top 70th Acc: 0.7273, Bottom 30th Acc: 0.3333
Fold [4/5] Epoch [20/100] Initial Loss: 0.1356, Training Loss: 0.0781, Initial Validation Loss: 0.1228, Validation Loss: 0.0804,V Acc: 0.6000, Top 70th Acc: 0.7273, Bottom 30th Acc: 0.3030
Fold [4/5] Epoch [30/100] Initial Loss: 0.1356, Training Loss: 0.0777, Initial Validation Loss: 0.1228, Validation Loss: 0.0808,V Acc: 0.6000, Top 70th Acc: 0.7143, Bottom 30th Acc: 0.3333
Stopping early at Epoch (base 0): 37  Rolling back to Epoch (base 0): 32  Top Validation Acc: 0.7272727272727273
Fold [5/5] Epoch [0/100] Initial Loss: 0.1332, Training Loss: 0.1332, Initial Validation Loss: 0.1203, Validation Loss: 0.1203,V Acc: 0.5370, Top 70th Acc: 0.5921, Bottom 30th Acc: 0.4062
Fold [5/5] Epoch [10/100] Initial Loss: 0.1332, Training Loss: 0.0795, Initial Validation Loss: 0.1203, Validation Loss: 0.0794,V Acc: 0.6667, Top 70th Acc: 0.6974, Bottom 30th Acc: 0.5938
Fold [5/5] Epoch [20/100] Initial Loss: 0.1332, Training Loss: 0.0781, Initial Validation Loss: 0.1203, Validation Loss: 0.0780,V Acc: 0.6667, Top 70th Acc: 0.6974, Bottom 30th Acc: 0.5938
Fold [5/5] Epoch [30/100] Initial Loss: 0.1332, Training Loss: 0.0777, Initial Validation Loss: 0.1203, Validation Loss: 0.0774,V Acc: 0.6667, Top 70th Acc: 0.7105, Bottom 30th Acc: 0.5625
Fold [5/5] Epoch [40/100] Initial Loss: 0.1332, Training Loss: 0.0771, Initial Validation Loss: 0.1203, Validation Loss: 0.0775,V Acc: 0.6667, Top 70th Acc: 0.6974, Bottom 30th Acc: 0.5938
Stopping early at Epoch (base 0): 44  Rolling back to Epoch (base 0): 39  Top Validation Acc: 0.6842105263157895
Running train_nn.py with seed 66
CUDA:False
Training samples count:  550
Training on 2 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1327, Training Loss: 0.1327, Initial Validation Loss: 0.1263, Validation Loss: 0.1263,V Acc: 0.4955, Top 70th Acc: 0.5641, Bottom 30th Acc: 0.3333
Fold [1/5] Epoch [10/100] Initial Loss: 0.1327, Training Loss: 0.0786, Initial Validation Loss: 0.1263, Validation Loss: 0.0853,V Acc: 0.6306, Top 70th Acc: 0.6923, Bottom 30th Acc: 0.4848
Stopping early at Epoch (base 0): 17  Rolling back to Epoch (base 0): 12  Top Validation Acc: 0.6923076923076923
Fold [2/5] Epoch [0/100] Initial Loss: 0.1330, Training Loss: 0.1330, Initial Validation Loss: 0.1242, Validation Loss: 0.1242,V Acc: 0.4775, Top 70th Acc: 0.5256, Bottom 30th Acc: 0.3636
Fold [2/5] Epoch [10/100] Initial Loss: 0.1330, Training Loss: 0.0796, Initial Validation Loss: 0.1242, Validation Loss: 0.0868,V Acc: 0.5946, Top 70th Acc: 0.7436, Bottom 30th Acc: 0.2424
Fold [2/5] Epoch [20/100] Initial Loss: 0.1330, Training Loss: 0.0777, Initial Validation Loss: 0.1242, Validation Loss: 0.0850,V Acc: 0.6036, Top 70th Acc: 0.7308, Bottom 30th Acc: 0.3030
Fold [2/5] Epoch [30/100] Initial Loss: 0.1330, Training Loss: 0.0769, Initial Validation Loss: 0.1242, Validation Loss: 0.0839,V Acc: 0.6306, Top 70th Acc: 0.7308, Bottom 30th Acc: 0.3939
Fold [2/5] Epoch [40/100] Initial Loss: 0.1330, Training Loss: 0.0767, Initial Validation Loss: 0.1242, Validation Loss: 0.0837,V Acc: 0.6396, Top 70th Acc: 0.7564, Bottom 30th Acc: 0.3636
Fold [2/5] Epoch [50/100] Initial Loss: 0.1330, Training Loss: 0.0763, Initial Validation Loss: 0.1242, Validation Loss: 0.0832,V Acc: 0.6216, Top 70th Acc: 0.7564, Bottom 30th Acc: 0.3030
Stopping early at Epoch (base 0): 54  Rolling back to Epoch (base 0): 49  Top Validation Acc: 0.7435897435897436
Fold [3/5] Epoch [0/100] Initial Loss: 0.1344, Training Loss: 0.1344, Initial Validation Loss: 0.1175, Validation Loss: 0.1175,V Acc: 0.4636, Top 70th Acc: 0.5844, Bottom 30th Acc: 0.1818
Fold [3/5] Epoch [10/100] Initial Loss: 0.1344, Training Loss: 0.0831, Initial Validation Loss: 0.1175, Validation Loss: 0.0700,V Acc: 0.6636, Top 70th Acc: 0.7662, Bottom 30th Acc: 0.4242
Fold [3/5] Epoch [20/100] Initial Loss: 0.1344, Training Loss: 0.0816, Initial Validation Loss: 0.1175, Validation Loss: 0.0681,V Acc: 0.6818, Top 70th Acc: 0.7922, Bottom 30th Acc: 0.4242
Fold [3/5] Epoch [30/100] Initial Loss: 0.1344, Training Loss: 0.0808, Initial Validation Loss: 0.1175, Validation Loss: 0.0675,V Acc: 0.6727, Top 70th Acc: 0.8052, Bottom 30th Acc: 0.3636
Fold [3/5] Epoch [40/100] Initial Loss: 0.1344, Training Loss: 0.0804, Initial Validation Loss: 0.1175, Validation Loss: 0.0671,V Acc: 0.6545, Top 70th Acc: 0.8052, Bottom 30th Acc: 0.3030
Stopping early at Epoch (base 0): 47  Rolling back to Epoch (base 0): 42  Top Validation Acc: 0.8181818181818182
Fold [4/5] Epoch [0/100] Initial Loss: 0.1393, Training Loss: 0.1393, Initial Validation Loss: 0.1323, Validation Loss: 0.1323,V Acc: 0.4364, Top 70th Acc: 0.4935, Bottom 30th Acc: 0.3030
Fold [4/5] Epoch [10/100] Initial Loss: 0.1393, Training Loss: 0.0829, Initial Validation Loss: 0.1323, Validation Loss: 0.0768,V Acc: 0.6727, Top 70th Acc: 0.7662, Bottom 30th Acc: 0.4545
Fold [4/5] Epoch [20/100] Initial Loss: 0.1393, Training Loss: 0.0808, Initial Validation Loss: 0.1323, Validation Loss: 0.0742,V Acc: 0.6727, Top 70th Acc: 0.7662, Bottom 30th Acc: 0.4545
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.7532467532467533
66 3 [array([0.15018706, 0.31682193, 0.15978609, 0.21676907, 0.15643583],
      dtype=float32)]
Fold [5/5] Epoch [0/100] Initial Loss: 0.1346, Training Loss: 0.1346, Initial Validation Loss: 0.1214, Validation Loss: 0.1214,V Acc: 0.4352, Top 70th Acc: 0.5263, Bottom 30th Acc: 0.2188
Fold [5/5] Epoch [10/100] Initial Loss: 0.1346, Training Loss: 0.0782, Initial Validation Loss: 0.1214, Validation Loss: 0.0838,V Acc: 0.5741, Top 70th Acc: 0.6711, Bottom 30th Acc: 0.3438
Fold [5/5] Epoch [20/100] Initial Loss: 0.1346, Training Loss: 0.0763, Initial Validation Loss: 0.1214, Validation Loss: 0.0839,V Acc: 0.5741, Top 70th Acc: 0.6711, Bottom 30th Acc: 0.3438
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.6842105263157895
Running train_nn.py with seed 67
CUDA:False
Training samples count:  550
Training on 2 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1327, Training Loss: 0.1327, Initial Validation Loss: 0.1236, Validation Loss: 0.1236,V Acc: 0.4054, Top 70th Acc: 0.4872, Bottom 30th Acc: 0.2121
Fold [1/5] Epoch [10/100] Initial Loss: 0.1327, Training Loss: 0.0812, Initial Validation Loss: 0.1236, Validation Loss: 0.0775,V Acc: 0.6306, Top 70th Acc: 0.7436, Bottom 30th Acc: 0.3636
Fold [1/5] Epoch [20/100] Initial Loss: 0.1327, Training Loss: 0.0794, Initial Validation Loss: 0.1236, Validation Loss: 0.0749,V Acc: 0.6757, Top 70th Acc: 0.7436, Bottom 30th Acc: 0.5152
Stopping early at Epoch (base 0): 28  Rolling back to Epoch (base 0): 23  Top Validation Acc: 0.7435897435897436
67 0 [array([0.14598759, 0.37542373, 0.1255891 , 0.21846816, 0.1345315 ],
      dtype=float32)]
Fold [2/5] Epoch [0/100] Initial Loss: 0.1434, Training Loss: 0.1434, Initial Validation Loss: 0.1359, Validation Loss: 0.1359,V Acc: 0.2883, Top 70th Acc: 0.3077, Bottom 30th Acc: 0.2424
Fold [2/5] Epoch [10/100] Initial Loss: 0.1434, Training Loss: 0.0838, Initial Validation Loss: 0.1359, Validation Loss: 0.0735,V Acc: 0.6757, Top 70th Acc: 0.7564, Bottom 30th Acc: 0.4848
Fold [2/5] Epoch [20/100] Initial Loss: 0.1434, Training Loss: 0.0808, Initial Validation Loss: 0.1359, Validation Loss: 0.0719,V Acc: 0.6757, Top 70th Acc: 0.7564, Bottom 30th Acc: 0.4848
Fold [2/5] Epoch [30/100] Initial Loss: 0.1434, Training Loss: 0.0802, Initial Validation Loss: 0.1359, Validation Loss: 0.0715,V Acc: 0.6667, Top 70th Acc: 0.7564, Bottom 30th Acc: 0.4545
Stopping early at Epoch (base 0): 33  Rolling back to Epoch (base 0): 28  Top Validation Acc: 0.782051282051282
Fold [3/5] Epoch [0/100] Initial Loss: 0.1313, Training Loss: 0.1313, Initial Validation Loss: 0.1208, Validation Loss: 0.1208,V Acc: 0.4273, Top 70th Acc: 0.4675, Bottom 30th Acc: 0.3333 0.9342105263157895
Running train_nn.py with seed 70
CUDA:False
Training samples count:  550
Training on 30 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1393, Training Loss: 0.1393, Initial Validation Loss: 0.1369, Validation Loss: 0.1369,V Acc: 0.3063, Top 70th Acc: 0.3590, Bottom 30th Acc: 0.1818
Fold [1/5] Epoch [10/100] Initial Loss: 0.1393, Training Loss: 0.0346, Initial Validation Loss: 0.1369, Validation Loss: 0.0456,V Acc: 0.7748, Top 70th Acc: 0.8590, Bottom 30th Acc: 0.5758
Fold [1/5] Epoch [20/100] Initial Loss: 0.1393, Training Loss: 0.0188, Initial Validation Loss: 0.1369, Validation Loss: 0.0358,V Acc: 0.8018, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.4848
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.9230769230769231
Fold [2/5] Epoch [0/100] Initial Loss: 0.1399, Training Loss: 0.1399, Initial Validation Loss: 0.1334, Validation Loss: 0.1334,V Acc: 0.3694, Top 70th Acc: 0.3974, Bottom 30th Acc: 0.3030
Fold [2/5] Epoch [10/100] Initial Loss: 0.1399, Training Loss: 0.0422, Initial Validation Loss: 0.1334, Validation Loss: 0.0537,V Acc: 0.7748, Top 70th Acc: 0.8846, Bottom 30th Acc: 0.5152
Fold [2/5] Epoch [20/100] Initial Loss: 0.1399, Training Loss: 0.0205, Initial Validation Loss: 0.1334, Validation Loss: 0.0319,V Acc: 0.8649, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 28  Rolling back to Epoch (base 0): 23  Top Validation Acc: 0.9615384615384616
70 1 [array([0.64677453, 0.14467712, 0.05005516, 0.09556959, 0.06292366],
      dtype=float32)]
Fold [3/5] Epoch [0/100] Initial Loss: 0.1411, Training Loss: 0.1411, Initial Validation Loss: 0.1346, Validation Loss: 0.1346,V Acc: 0.2727, Top 70th Acc: 0.2597, Bottom 30th Acc: 0.3030
Fold [3/5] Epoch [10/100] Initial Loss: 0.1411, Training Loss: 0.0374, Initial Validation Loss: 0.1346, Validation Loss: 0.0407,V Acc: 0.8000, Top 70th Acc: 0.8961, Bottom 30th Acc: 0.5758
Fold [3/5] Epoch [20/100] Initial Loss: 0.1411, Training Loss: 0.0258, Initial Validation Loss: 0.1346, Validation Loss: 0.0326,V Acc: 0.8364, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.5455
Fold [3/5] Epoch [30/100] Initial Loss: 0.1411, Training Loss: 0.0197, Initial Validation Loss: 0.1346, Validation Loss: 0.0304,V Acc: 0.8091, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.4242
Fold [3/5] Epoch [40/100] Initial Loss: 0.1411, Training Loss: 0.0164, Initial Validation Loss: 0.1346, Validation Loss: 0.0284,V Acc: 0.8182, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.4545
Stopping early at Epoch (base 0): 44  Rolling back to Epoch (base 0): 39  Top Validation Acc: 0.961038961038961
Fold [4/5] Epoch [0/100] Initial Loss: 0.1386, Training Loss: 0.1386, Initial Validation Loss: 0.1380, Validation Loss: 0.1380,V Acc: 0.4636, Top 70th Acc: 0.5455, Bottom 30th Acc: 0.2727
Fold [4/5] Epoch [10/100] Initial Loss: 0.1386, Training Loss: 0.0393, Initial Validation Loss: 0.1380, Validation Loss: 0.0431,V Acc: 0.8091, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.5152
Fold [4/5] Epoch [20/100] Initial Loss: 0.1386, Training Loss: 0.0189, Initial Validation Loss: 0.1380, Validation Loss: 0.0330,V Acc: 0.8273, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.5152
Stopping early at Epoch (base 0): 21  Rolling back to Epoch (base 0): 16  Top Validation Acc: 0.961038961038961
Fold [5/5] Epoch [0/100] Initial Loss: 0.1352, Training Loss: 0.1352, Initial Validation Loss: 0.1223, Validation Loss: 0.1223,V Acc: 0.4907, Top 70th Acc: 0.6184, Bottom 30th Acc: 0.1875
Fold [5/5] Epoch [10/100] Initial Loss: 0.1352, Training Loss: 0.0280, Initial Validation Loss: 0.1223, Validation Loss: 0.0304,V Acc: 0.8148, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.5312
Fold [5/5] Epoch [20/100] Initial Loss: 0.1352, Training Loss: 0.0184, Initial Validation Loss: 0.1223, Validation Loss: 0.0254,V Acc: 0.8519, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.6250
Fold [5/5] Epoch [30/100] Initial Loss: 0.1352, Training Loss: 0.0166, Initial Validation Loss: 0.1223, Validation Loss: 0.0253,V Acc: 0.8519, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.6562
Stopping early at Epoch (base 0): 31  Rolling back to Epoch (base 0): 26  Top Validation Acc: 0.9473684210526315
Running train_nn.py with seed 71
CUDA:False
Training samples count:  550
Training on 30 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1342, Training Loss: 0.1342, Initial Validation Loss: 0.1312, Validation Loss: 0.1312,V Acc: 0.4865, Top 70th Acc: 0.5897, Bottom 30th Acc: 0.2424
Fold [1/5] Epoch [10/100] Initial Loss: 0.1342, Training Loss: 0.0273, Initial Validation Loss: 0.1312, Validation Loss: 0.0345,V Acc: 0.8649, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.6364
Fold [1/5] Epoch [20/100] Initial Loss: 0.1342, Training Loss: 0.0190, Initial Validation Loss: 0.1312, Validation Loss: 0.0321,V Acc: 0.8829, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.7273
Stopping early at Epoch (base 0): 20  Rolling back to Epoch (base 0): 15  Top Validation Acc: 0.9487179487179487
Fold [2/5] Epoch [0/100] Initial Loss: 0.1402, Training Loss: 0.1402, Initial Validation Loss: 0.1324, Validation Loss: 0.1324,V Acc: 0.3423, Top 70th Acc: 0.4359, Bottom 30th Acc: 0.1212
Fold [2/5] Epoch [10/100] Initial Loss: 0.1402, Training Loss: 0.0462, Initial Validation Loss: 0.1324, Validation Loss: 0.0485,V Acc: 0.7748, Top 70th Acc: 0.8462, Bottom 30th Acc: 0.6061
Fold [2/5] Epoch [20/100] Initial Loss: 0.1402, Training Loss: 0.0267, Initial Validation Loss: 0.1324, Validation Loss: 0.0392,V Acc: 0.8108, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.5455
Fold [2/5] Epoch [30/100] Initial Loss: 0.1402, Training Loss: 0.0180, Initial Validation Loss: 0.1324, Validation Loss: 0.0346,V Acc: 0.8468, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.6970
Fold [2/5] Epoch [40/100] Initial Loss: 0.1402, Training Loss: 0.0155, Initial Validation Loss: 0.1324, Validation Loss: 0.0337,V Acc: 0.8468, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 41  Rolling back to Epoch (base 0): 36  Top Validation Acc: 0.9102564102564102
Fold [3/5] Epoch [0/100] Initial Loss: 0.1402, Training Loss: 0.1402, Initial Validation Loss: 0.1285, Validation Loss: 0.1285,V Acc: 0.3455, Top 70th Acc: 0.3766, Bottom 30th Acc: 0.2727
Fold [3/5] Epoch [10/100] Initial Loss: 0.1402, Training Loss: 0.0398, Initial Validation Loss: 0.1285, Validation Loss: 0.0518,V Acc: 0.7273, Top 70th Acc: 0.8442, Bottom 30th Acc: 0.4545
Fold [3/5] Epoch [20/100] Initial Loss: 0.1402, Training Loss: 0.0220, Initial Validation Loss: 0.1285, Validation Loss: 0.0436,V Acc: 0.7545, Top 70th Acc: 0.8831, Bottom 30th Acc: 0.4545
Fold [3/5] Epoch [30/100] Initial Loss: 0.1402, Training Loss: 0.0166, Initial Validation Loss: 0.1285, Validation Loss: 0.0400,V Acc: 0.7727, Top 70th Acc: 0.8831, Bottom 30th Acc: 0.5152
Stopping early at Epoch (base 0): 37  Rolling back to Epoch (base 0): 32  Top Validation Acc: 0.9090909090909091
Fold [4/5] Epoch [0/100] Initial Loss: 0.1397, Training Loss: 0.1397, Initial Validation Loss: 0.1351, Validation Loss: 0.1351,V Acc: 0.3545, Top 70th Acc: 0.4026, Bottom 30th Acc: 0.2424
Fold [4/5] Epoch [10/100] Initial Loss: 0.1397, Training Loss: 0.0291, Initial Validation Loss: 0.1351, Validation Loss: 0.0367,V Acc: 0.8545, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6364
Fold [4/5] Epoch [20/100] Initial Loss: 0.1397, Training Loss: 0.0191, Initial Validation Loss: 0.1351, Validation Loss: 0.0335,V Acc: 0.8182, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 20  Rolling back to Epoch (base 0): 15  Top Validation Acc: 0.935064935064935
71 3 [array([0.5827104 , 0.13501969, 0.0656683 , 0.08807625, 0.12852538],
      dtype=float32)]
Fold [5/5] Epoch [0/100] Initial Loss: 0.1371, Training Loss: 0.1371, Initial Validation Loss: 0.1360, Validation Loss: 0.1360,V Acc: 0.2870, Top 70th Acc: 0.1974, Bottom 30th Acc: 0.5000
Fold [5/5] Epoch [10/100] Initial Loss: 0.1371, Training Loss: 0.0358, Initial Validation Loss: 0.1360, Validation Loss: 0.0416,V Acc: 0.7870, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.4062
Fold [5/5] Epoch [20/100] Initial Loss: 0.1371, Training Loss: 0.0204, Initial Validation Loss: 0.1360, Validation Loss: 0.0305,V Acc: 0.8426, Top 70th Acc: 0.9737, Bottom 30th Acc: 0.5312/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)

Stopping early at Epoch (base 0): 15  Rolling back to Epoch (base 0): 10  Top Validation Acc: 0.9743589743589743
Fold [2/5] Epoch [0/100] Initial Loss: 0.1282, Training Loss: 0.1282, Initial Validation Loss: 0.1164, Validation Loss: 0.1164,V Acc: 0.5135, Top 70th Acc: 0.6538, Bottom 30th Acc: 0.1818
Fold [2/5] Epoch [10/100] Initial Loss: 0.1282, Training Loss: 0.0235, Initial Validation Loss: 0.1164, Validation Loss: 0.0382,V Acc: 0.8018, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.5455
Fold [2/5] Epoch [20/100] Initial Loss: 0.1282, Training Loss: 0.0173, Initial Validation Loss: 0.1164, Validation Loss: 0.0431,V Acc: 0.7748, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.4242
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.9487179487179487
Fold [3/5] Epoch [0/100] Initial Loss: 0.1388, Training Loss: 0.1388, Initial Validation Loss: 0.1307, Validation Loss: 0.1307,V Acc: 0.3727, Top 70th Acc: 0.4156, Bottom 30th Acc: 0.2727
Fold [3/5] Epoch [10/100] Initial Loss: 0.1388, Training Loss: 0.0215, Initial Validation Loss: 0.1307, Validation Loss: 0.0281,V Acc: 0.8455, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 17  Rolling back to Epoch (base 0): 12  Top Validation Acc: 0.948051948051948
Fold [4/5] Epoch [0/100] Initial Loss: 0.1347, Training Loss: 0.1347, Initial Validation Loss: 0.1249, Validation Loss: 0.1249,V Acc: 0.4364, Top 70th Acc: 0.5325, Bottom 30th Acc: 0.2121
Fold [4/5] Epoch [10/100] Initial Loss: 0.1347, Training Loss: 0.0271, Initial Validation Loss: 0.1249, Validation Loss: 0.0370,V Acc: 0.8091, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.5152
Fold [4/5] Epoch [20/100] Initial Loss: 0.1347, Training Loss: 0.0193, Initial Validation Loss: 0.1249, Validation Loss: 0.0286,V Acc: 0.8545, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 21  Rolling back to Epoch (base 0): 16  Top Validation Acc: 0.961038961038961
Fold [5/5] Epoch [0/100] Initial Loss: 0.1366, Training Loss: 0.1366, Initial Validation Loss: 0.1318, Validation Loss: 0.1318,V Acc: 0.4074, Top 70th Acc: 0.5526, Bottom 30th Acc: 0.0625
Fold [5/5] Epoch [10/100] Initial Loss: 0.1366, Training Loss: 0.0266, Initial Validation Loss: 0.1318, Validation Loss: 0.0343,V Acc: 0.8333, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.5625
Fold [5/5] Epoch [20/100] Initial Loss: 0.1366, Training Loss: 0.0175, Initial Validation Loss: 0.1318, Validation Loss: 0.0305,V Acc: 0.8519, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.5938
Stopping early at Epoch (base 0): 20  Rolling back to Epoch (base 0): 15  Top Validation Acc: 0.9605263157894737
99 4 [array([0.7217968 , 0.01665464, 0.02104584, 0.12652811, 0.11397453],
      dtype=float32)]
Running train_nn.py with seed 100
CUDA:False
Training samples count:  550
Training on 21 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1282, Training Loss: 0.1282, Initial Validation Loss: 0.1171, Validation Loss: 0.1171,V Acc: 0.4775, Top 70th Acc: 0.6410, Bottom 30th Acc: 0.0909
Fold [1/5] Epoch [10/100] Initial Loss: 0.1282, Training Loss: 0.0280, Initial Validation Loss: 0.1171, Validation Loss: 0.0340,V Acc: 0.8829, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.7273
Fold [1/5] Epoch [20/100] Initial Loss: 0.1282, Training Loss: 0.0191, Initial Validation Loss: 0.1171, Validation Loss: 0.0296,V Acc: 0.8739, Top 70th Acc: 0.9872, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 22  Rolling back to Epoch (base 0): 17  Top Validation Acc: 1.0
Fold [2/5] Epoch [0/100] Initial Loss: 0.1366, Training Loss: 0.1366, Initial Validation Loss: 0.1257, Validation Loss: 0.1257,V Acc: 0.4144, Top 70th Acc: 0.4615, Bottom 30th Acc: 0.3030
Fold [2/5] Epoch [10/100] Initial Loss: 0.1366, Training Loss: 0.0303, Initial Validation Loss: 0.1257, Validation Loss: 0.0286,V Acc: 0.8739, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.6970
Fold [2/5] Epoch [20/100] Initial Loss: 0.1366, Training Loss: 0.0191, Initial Validation Loss: 0.1257, Validation Loss: 0.0244,V Acc: 0.9009, Top 70th Acc: 0.9872, Bottom 30th Acc: 0.6970
Fold [2/5] Epoch [30/100] Initial Loss: 0.1366, Training Loss: 0.0149, Initial Validation Loss: 0.1257, Validation Loss: 0.0213,V Acc: 0.8919, Top 70th Acc: 0.9872, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 32  Rolling back to Epoch (base 0): 27  Top Validation Acc: 0.9871794871794872
Fold [3/5] Epoch [0/100] Initial Loss: 0.1299, Training Loss: 0.1299, Initial Validation Loss: 0.1106, Validation Loss: 0.1106,V Acc: 0.5091, Top 70th Acc: 0.6104, Bottom 30th Acc: 0.2727
Fold [3/5] Epoch [10/100] Initial Loss: 0.1299, Training Loss: 0.0282, Initial Validation Loss: 0.1106, Validation Loss: 0.0343,V Acc: 0.7727, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.4242
Fold [3/5] Epoch [20/100] Initial Loss: 0.1299, Training Loss: 0.0168, Initial Validation Loss: 0.1106, Validation Loss: 0.0362,V Acc: 0.7909, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.4848
Stopping early at Epoch (base 0): 21  Rolling back to Epoch (base 0): 16  Top Validation Acc: 0.922077922077922
100 2 [array([0.6601467 , 0.02187016, 0.03737324, 0.20569126, 0.07491861],
      dtype=float32)]
Fold [4/5] Epoch [0/100] Initial Loss: 0.1242, Training Loss: 0.1242, Initial Validation Loss: 0.1088, Validation Loss: 0.1088,V Acc: 0.5727, Top 70th Acc: 0.7403, Bottom 30th Acc: 0.1818
Fold [4/5] Epoch [10/100] Initial Loss: 0.1242, Training Loss: 0.0285, Initial Validation Loss: 0.1088, Validation Loss: 0.0420,V Acc: 0.8091, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.5455
Fold [4/5] Epoch [20/100] Initial Loss: 0.1242, Training Loss: 0.0181, Initial Validation Loss: 0.1088, Validation Loss: 0.0334,V Acc: 0.8545, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.948051948051948
Fold [5/5] Epoch [0/100] Initial Loss: 0.1427, Training Loss: 0.1427, Initial Validation Loss: 0.1307, Validation Loss: 0.1307,V Acc: 0.3796, Top 70th Acc: 0.4079, Bottom 30th Acc: 0.3125
Fold [5/5] Epoch [10/100] Initial Loss: 0.1427, Training Loss: 0.0265, Initial Validation Loss: 0.1307, Validation Loss: 0.0319,V Acc: 0.8426, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.6250
Stopping early at Epoch (base 0): 15  Rolling back to Epoch (base 0): 10  Top Validation Acc: 0.9078947368421053

Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.9473684210526315
Running train_nn.py with seed 70
CUDA:False
Training samples count:  550
Training on 40 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1382, Training Loss: 0.1382, Initial Validation Loss: 0.1369, Validation Loss: 0.1369,V Acc: 0.2613, Top 70th Acc: 0.3333, Bottom 30th Acc: 0.0909
Fold [1/5] Epoch [10/100] Initial Loss: 0.1382, Training Loss: 0.0293, Initial Validation Loss: 0.1369, Validation Loss: 0.0411,V Acc: 0.7928, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.4848
Fold [1/5] Epoch [20/100] Initial Loss: 0.1382, Training Loss: 0.0142, Initial Validation Loss: 0.1369, Validation Loss: 0.0310,V Acc: 0.8468, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.6364
Fold [1/5] Epoch [30/100] Initial Loss: 0.1382, Training Loss: 0.0108, Initial Validation Loss: 0.1369, Validation Loss: 0.0308,V Acc: 0.8108, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.4848
Stopping early at Epoch (base 0): 30  Rolling back to Epoch (base 0): 25  Top Validation Acc: 0.9487179487179487
Fold [2/5] Epoch [0/100] Initial Loss: 0.1422, Training Loss: 0.1422, Initial Validation Loss: 0.1351, Validation Loss: 0.1351,V Acc: 0.2523, Top 70th Acc: 0.3077, Bottom 30th Acc: 0.1212
Fold [2/5] Epoch [10/100] Initial Loss: 0.1422, Training Loss: 0.0335, Initial Validation Loss: 0.1351, Validation Loss: 0.0409,V Acc: 0.8559, Top 70th Acc: 0.9872, Bottom 30th Acc: 0.5455
Fold [2/5] Epoch [20/100] Initial Loss: 0.1422, Training Loss: 0.0145, Initial Validation Loss: 0.1351, Validation Loss: 0.0265,V Acc: 0.8468, Top 70th Acc: 1.0000, Bottom 30th Acc: 0.4848
Fold [2/5] Epoch [30/100] Initial Loss: 0.1422, Training Loss: 0.0115, Initial Validation Loss: 0.1351, Validation Loss: 0.0245,V Acc: 0.8829, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 32  Rolling back to Epoch (base 0): 27  Top Validation Acc: 0.9743589743589743
70 1 [array([0.3452515 , 0.21030737, 0.11519001, 0.08427881, 0.24497232],
      dtype=float32)]
Fold [3/5] Epoch [0/100] Initial Loss: 0.1376, Training Loss: 0.1376, Initial Validation Loss: 0.1340, Validation Loss: 0.1340,V Acc: 0.4182, Top 70th Acc: 0.5325, Bottom 30th Acc: 0.1515
Fold [3/5] Epoch [10/100] Initial Loss: 0.1376, Training Loss: 0.0283, Initial Validation Loss: 0.1340, Validation Loss: 0.0346,V Acc: 0.8182, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.5152
Fold [3/5] Epoch [20/100] Initial Loss: 0.1376, Training Loss: 0.0133, Initial Validation Loss: 0.1340, Validation Loss: 0.0271,V Acc: 0.8545, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.974025974025974
Fold [4/5] Epoch [0/100] Initial Loss: 0.1378, Training Loss: 0.1378, Initial Validation Loss: 0.1374, Validation Loss: 0.1374,V Acc: 0.3545, Top 70th Acc: 0.4026, Bottom 30th Acc: 0.2424
Fold [4/5] Epoch [10/100] Initial Loss: 0.1378, Training Loss: 0.0275, Initial Validation Loss: 0.1374, Validation Loss: 0.0321,V Acc: 0.8727, Top 70th Acc: 0.9870, Bottom 30th Acc: 0.6061
Fold [4/5] Epoch [20/100] Initial Loss: 0.1378, Training Loss: 0.0131, Initial Validation Loss: 0.1374, Validation Loss: 0.0274,V Acc: 0.8818, Top 70th Acc: 0.9870, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.987012987012987
Fold [5/5] Epoch [0/100] Initial Loss: 0.1383, Training Loss: 0.1383, Initial Validation Loss: 0.1275, Validation Loss: 0.1275,V Acc: 0.2778, Top 70th Acc: 0.3553, Bottom 30th Acc: 0.0938
Fold [5/5] Epoch [10/100] Initial Loss: 0.1383, Training Loss: 0.0428, Initial Validation Loss: 0.1275, Validation Loss: 0.0400,V Acc: 0.8056, Top 70th Acc: 0.8816, Bottom 30th Acc: 0.6250
Fold [5/5] Epoch [20/100] Initial Loss: 0.1383, Training Loss: 0.0257, Initial Validation Loss: 0.1275, Validation Loss: 0.0298,V Acc: 0.8148, Top 70th Acc: 0.9079, Bottom 30th Acc: 0.5938
Fold [5/5] Epoch [30/100] Initial Loss: 0.1383, Training Loss: 0.0171, Initial Validation Loss: 0.1275, Validation Loss: 0.0233,V Acc: 0.8519, Top 70th Acc: 0.9079, Bottom 30th Acc: 0.7188
Fold [5/5] Epoch [40/100] Initial Loss: 0.1383, Training Loss: 0.0126, Initial Validation Loss: 0.1275, Validation Loss: 0.0217,V Acc: 0.8519, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.6250
Stopping early at Epoch (base 0): 41  Rolling back to Epoch (base 0): 36  Top Validation Acc: 0.9473684210526315
Running train_nn.py with seed 71
CUDA:False
Training samples count:  550
Training on 40 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1408, Training Loss: 0.1408, Initial Validation Loss: 0.1386, Validation Loss: 0.1386,V Acc: 0.2613, Top 70th Acc: 0.3077, Bottom 30th Acc: 0.1515
Fold [1/5] Epoch [10/100] Initial Loss: 0.1408, Training Loss: 0.0312, Initial Validation Loss: 0.1386, Validation Loss: 0.0363,V Acc: 0.8919, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.7273
Fold [1/5] Epoch [20/100] Initial Loss: 0.1408, Training Loss: 0.0151, Initial Validation Loss: 0.1386, Validation Loss: 0.0266,V Acc: 0.8919, Top 70th Acc: 0.9872, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.9743589743589743
Fold [2/5] Epoch [0/100] Initial Loss: 0.1388, Training Loss: 0.1388, Initial Validation Loss: 0.1332, Validation Loss: 0.1332,V Acc: 0.2883, Top 70th Acc: 0.2949, Bottom 30th Acc: 0.2727
Fold [2/5] Epoch [10/100] Initial Loss: 0.1388, Training Loss: 0.0359, Initial Validation Loss: 0.1332, Validation Loss: 0.0405,V Acc: 0.8108, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.5758
Fold [2/5] Epoch [20/100] Initial Loss: 0.1388, Training Loss: 0.0161, Initial Validation Loss: 0.1332, Validation Loss: 0.0286,V Acc: 0.8739, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.7273
Fold [2/5] Epoch [30/100] Initial Loss: 0.1388, Training Loss: 0.0117, Initial Validation Loss: 0.1332, Validation Loss: 0.0264,V Acc: 0.8649, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.6667
Fold [2/5] Epoch [40/100] Initial Loss: 0.1388, Training Loss: 0.0100, Initial Validation Loss: 0.1332, Validation Loss: 0.0258,V Acc: 0.8649, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.6667
Fold [2/5] Epoch [50/100] Initial Loss: 0.1388, Training Loss: 0.0095, Initial Validation Loss: 0.1332, Validation Loss: 0.0251,V Acc: 0.8829, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.7273
Stopping early at Epoch (base 0): 57  Rolling back to Epoch (base 0): 52  Top Validation Acc: 0.9358974358974359
Fold [3/5] Epoch [0/100] Initial Loss: 0.1417, Training Loss: 0.1417, Initial Validation Loss: 0.1302, Validation Loss: 0.1302,V Acc: 0.3273, Top 70th Acc: 0.3766, Bottom 30th Acc: 0.2121
Fold [3/5] Epoch [10/100] Initial Loss: 0.1417, Training Loss: 0.0314, Initial Validation Loss: 0.1302, Validation Loss: 0.0420,V Acc: 0.7727, Top 70th Acc: 0.8831, Bottom 30th Acc: 0.5152
Stopping early at Epoch (base 0): 19  Rolling back to Epoch (base 0): 14  Top Validation Acc: 0.9090909090909091
Fold [4/5] Epoch [0/100] Initial Loss: 0.1411, Training Loss: 0.1411, Initial Validation Loss: 0.1380, Validation Loss: 0.1380,V Acc: 0.2091, Top 70th Acc: 0.1948, Bottom 30th Acc: 0.2424
Fold [4/5] Epoch [10/100] Initial Loss: 0.1411, Training Loss: 0.0362, Initial Validation Loss: 0.1380, Validation Loss: 0.0395,V Acc: 0.8636, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6667
Fold [4/5] Epoch [20/100] Initial Loss: 0.1411, Training Loss: 0.0144, Initial Validation Loss: 0.1380, Validation Loss: 0.0313,V Acc: 0.8727, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.7273
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.935064935064935
71 3 [array([0.2071835 , 0.10132864, 0.11453427, 0.08761095, 0.4893427 ],
      dtype=float32)]
Fold [5/5] Epoch [0/100] Initial Loss: 0.1360, Training Loss: 0.1360, Initial Validation Loss: 0.1339, Validation Loss: 0.1339,V Acc: 0.3519, Top 70th Acc: 0.4342, Bottom 30th Acc: 0.1562
Fold [5/5] Epoch [10/100] Initial Loss: 0.1360, Training Loss: 0.0250, Initial Validation Loss: 0.1339, Validation Loss: 0.0335,V Acc: 0.8426, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.5938
Fold [5/5] Epoch [20/100] Initial Loss: 0.1360, Training Loss: 0.0132, Initial Validation Loss: 0.1339, Validation Loss: 0.0293,V Acc: 0.8519, Top 70th Acc: 0.9868, Bottom 30th Acc: 0.5312
Fold [4/5] Epoch [10/100] Initial Loss: 0.1388, Training Loss: 0.0163, Initial Validation Loss: 0.1296, Validation Loss: 0.0365,V Acc: 0.8000, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.5152
Fold [4/5] Epoch [20/100] Initial Loss: 0.1388, Training Loss: 0.0056, Initial Validation Loss: 0.1296, Validation Loss: 0.0318,V Acc: 0.8273, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.5758
Fold [4/5] Epoch [30/100] Initial Loss: 0.1388, Training Loss: 0.0043, Initial Validation Loss: 0.1296, Validation Loss: 0.0308,V Acc: 0.8364, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 36  Rolling back to Epoch (base 0): 31  Top Validation Acc: 0.935064935064935
54 3 [array([0.28360382, 0.04707715, 0.09499857, 0.21242124, 0.3618993 ],
      dtype=float32)]
Fold [5/5] Epoch [0/100] Initial Loss: 0.1382, Training Loss: 0.1382, Initial Validation Loss: 0.1327, Validation Loss: 0.1327,V Acc: 0.2685, Top 70th Acc: 0.3158, Bottom 30th Acc: 0.1562
Fold [5/5] Epoch [10/100] Initial Loss: 0.1382, Training Loss: 0.0281, Initial Validation Loss: 0.1327, Validation Loss: 0.0505,V Acc: 0.7407, Top 70th Acc: 0.8421, Bottom 30th Acc: 0.5000
Fold [5/5] Epoch [20/100] Initial Loss: 0.1382, Training Loss: 0.0071, Initial Validation Loss: 0.1327, Validation Loss: 0.0475,V Acc: 0.7500, Top 70th Acc: 0.8816, Bottom 30th Acc: 0.4375
Stopping early at Epoch (base 0): 22  Rolling back to Epoch (base 0): 17  Top Validation Acc: 0.9078947368421053
Running train_nn.py with seed 55
CUDA:False
Training samples count:  550
Training on 163 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1373, Training Loss: 0.1373, Initial Validation Loss: 0.1355, Validation Loss: 0.1355,V Acc: 0.3243, Top 70th Acc: 0.4231, Bottom 30th Acc: 0.0909
Fold [1/5] Epoch [10/100] Initial Loss: 0.1373, Training Loss: 0.0137, Initial Validation Loss: 0.1355, Validation Loss: 0.0312,V Acc: 0.8829, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.6970
Fold [1/5] Epoch [20/100] Initial Loss: 0.1373, Training Loss: 0.0049, Initial Validation Loss: 0.1355, Validation Loss: 0.0247,V Acc: 0.8829, Top 70th Acc: 0.9872, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 22  Rolling back to Epoch (base 0): 17  Top Validation Acc: 0.9871794871794872
Fold [2/5] Epoch [0/100] Initial Loss: 0.1388, Training Loss: 0.1388, Initial Validation Loss: 0.1403, Validation Loss: 0.1403,V Acc: 0.2973, Top 70th Acc: 0.3590, Bottom 30th Acc: 0.1515
Fold [2/5] Epoch [10/100] Initial Loss: 0.1388, Training Loss: 0.0226, Initial Validation Loss: 0.1403, Validation Loss: 0.0345,V Acc: 0.8378, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.5455
Fold [2/5] Epoch [20/100] Initial Loss: 0.1388, Training Loss: 0.0051, Initial Validation Loss: 0.1403, Validation Loss: 0.0259,V Acc: 0.8468, Top 70th Acc: 0.9872, Bottom 30th Acc: 0.5152
Stopping early at Epoch (base 0): 28  Rolling back to Epoch (base 0): 23  Top Validation Acc: 0.9871794871794872
Fold [3/5] Epoch [0/100] Initial Loss: 0.1403, Training Loss: 0.1403, Initial Validation Loss: 0.1275, Validation Loss: 0.1275,V Acc: 0.2636, Top 70th Acc: 0.3506, Bottom 30th Acc: 0.0606
Fold [3/5] Epoch [10/100] Initial Loss: 0.1403, Training Loss: 0.0128, Initial Validation Loss: 0.1275, Validation Loss: 0.0474,V Acc: 0.7455, Top 70th Acc: 0.8312, Bottom 30th Acc: 0.5455
Fold [3/5] Epoch [20/100] Initial Loss: 0.1403, Training Loss: 0.0048, Initial Validation Loss: 0.1275, Validation Loss: 0.0434,V Acc: 0.7364, Top 70th Acc: 0.8571, Bottom 30th Acc: 0.4545
Stopping early at Epoch (base 0): 21  Rolling back to Epoch (base 0): 16  Top Validation Acc: 0.8571428571428571
55 2 [array([0.32869768, 0.04828195, 0.04250015, 0.16991583, 0.41060445],
      dtype=float32)]
Fold [4/5] Epoch [0/100] Initial Loss: 0.1395, Training Loss: 0.1395, Initial Validation Loss: 0.1369, Validation Loss: 0.1369,V Acc: 0.2545, Top 70th Acc: 0.3636, Bottom 30th Acc: 0.0000
Fold [4/5] Epoch [10/100] Initial Loss: 0.1395, Training Loss: 0.0395, Initial Validation Loss: 0.1369, Validation Loss: 0.0494,V Acc: 0.7727, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.3939
Fold [4/5] Epoch [20/100] Initial Loss: 0.1395, Training Loss: 0.0064, Initial Validation Loss: 0.1369, Validation Loss: 0.0217,V Acc: 0.9091, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.7576
Fold [4/5] Epoch [30/100] Initial Loss: 0.1395, Training Loss: 0.0044, Initial Validation Loss: 0.1369, Validation Loss: 0.0214,V Acc: 0.8909, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 31  Rolling back to Epoch (base 0): 26  Top Validation Acc: 0.974025974025974
Fold [5/5] Epoch [0/100] Initial Loss: 0.1426, Training Loss: 0.1426, Initial Validation Loss: 0.1334, Validation Loss: 0.1334,V Acc: 0.3056, Top 70th Acc: 0.3421, Bottom 30th Acc: 0.2188
Fold [5/5] Epoch [10/100] Initial Loss: 0.1426, Training Loss: 0.0136, Initial Validation Loss: 0.1334, Validation Loss: 0.0361,V Acc: 0.8333, Top 70th Acc: 0.9079, Bottom 30th Acc: 0.6562
Fold [5/5] Epoch [20/100] Initial Loss: 0.1426, Training Loss: 0.0051, Initial Validation Loss: 0.1334, Validation Loss: 0.0305,V Acc: 0.8519, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.6562
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.9210526315789473
Running train_nn.py with seed 56
CUDA:False
Training samples count:  550
Training on 163 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1387, Training Loss: 0.1387, Initial Validation Loss: 0.1355, Validation Loss: 0.1355,V Acc: 0.2703, Top 70th Acc: 0.3333, Bottom 30th Acc: 0.1212
Fold [1/5] Epoch [10/100] Initial Loss: 0.1387, Training Loss: 0.0207, Initial Validation Loss: 0.1355, Validation Loss: 0.0487,V Acc: 0.7838, Top 70th Acc: 0.8462, Bottom 30th Acc: 0.6364
Fold [1/5] Epoch [20/100] Initial Loss: 0.1387, Training Loss: 0.0058, Initial Validation Loss: 0.1355, Validation Loss: 0.0462,V Acc: 0.7658, Top 70th Acc: 0.8718, Bottom 30th Acc: 0.5152
Stopping early at Epoch (base 0): 20  Rolling back to Epoch (base 0): 15  Top Validation Acc: 0.8717948717948718
Fold [2/5] Epoch [0/100] Initial Loss: 0.1429, Training Loss: 0.1429, Initial Validation Loss: 0.1347, Validation Loss: 0.1347,V Acc: 0.3063, Top 70th Acc: 0.3590, Bottom 30th Acc: 0.1818
Fold [2/5] Epoch [10/100] Initial Loss: 0.1429, Training Loss: 0.0172, Initial Validation Loss: 0.1347, Validation Loss: 0.0252,V Acc: 0.9009, Top 70th Acc: 0.9872, Bottom 30th Acc: 0.6970
Fold [2/5] Epoch [20/100] Initial Loss: 0.1429, Training Loss: 0.0050, Initial Validation Loss: 0.1347, Validation Loss: 0.0210,V Acc: 0.9009, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.7273
Stopping early at Epoch (base 0): 20  Rolling back to Epoch (base 0): 15  Top Validation Acc: 0.9743589743589743
Fold [3/5] Epoch [0/100] Initial Loss: 0.1399, Training Loss: 0.1399, Initial Validation Loss: 0.1350, Validation Loss: 0.1350,V Acc: 0.2273, Top 70th Acc: 0.2727, Bottom 30th Acc: 0.1212
Fold [3/5] Epoch [10/100] Initial Loss: 0.1399, Training Loss: 0.0201, Initial Validation Loss: 0.1350, Validation Loss: 0.0377,V Acc: 0.8000, Top 70th Acc: 0.8961, Bottom 30th Acc: 0.5758
Fold [3/5] Epoch [20/100] Initial Loss: 0.1399, Training Loss: 0.0065, Initial Validation Loss: 0.1350, Validation Loss: 0.0321,V Acc: 0.8091, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.5152
Fold [3/5] Epoch [30/100] Initial Loss: 0.1399, Training Loss: 0.0047, Initial Validation Loss: 0.1350, Validation Loss: 0.0305,V Acc: 0.8182, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.4848
Fold [3/5] Epoch [40/100] Initial Loss: 0.1399, Training Loss: 0.0042, Initial Validation Loss: 0.1350, Validation Loss: 0.0296,V Acc: 0.8182, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.5152
Fold [3/5] Epoch [50/100] Initial Loss: 0.1399, Training Loss: 0.0040, Initial Validation Loss: 0.1350, Validation Loss: 0.0291,V Acc: 0.8273, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.5455
Fold [3/5] Epoch [60/100] Initial Loss: 0.1399, Training Loss: 0.0039, Initial Validation Loss: 0.1350, Validation Loss: 0.0287,V Acc: 0.8091, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.4848
Fold [3/5] Epoch [70/100] Initial Loss: 0.1399, Training Loss: 0.0038, Initial Validation Loss: 0.1350, Validation Loss: 0.0283,V Acc: 0.8273, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.5152
Fold [5/5] Epoch [20/100] Initial Loss: 0.1393, Training Loss: 0.0245, Initial Validation Loss: 0.1361, Validation Loss: 0.0332,V Acc: 0.8333, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.5312
Fold [5/5] Epoch [30/100] Initial Loss: 0.1393, Training Loss: 0.0221, Initial Validation Loss: 0.1361, Validation Loss: 0.0317,V Acc: 0.8241, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.5000
Fold [5/5] Epoch [40/100] Initial Loss: 0.1393, Training Loss: 0.0210, Initial Validation Loss: 0.1361, Validation Loss: 0.0314,V Acc: 0.8241, Top 70th Acc: 0.9737, Bottom 30th Acc: 0.4688
Fold [5/5] Epoch [50/100] Initial Loss: 0.1393, Training Loss: 0.0200, Initial Validation Loss: 0.1361, Validation Loss: 0.0306,V Acc: 0.8333, Top 70th Acc: 0.9737, Bottom 30th Acc: 0.5000
Stopping early at Epoch (base 0): 56  Rolling back to Epoch (base 0): 51  Top Validation Acc: 0.9868421052631579
Running train_nn.py with seed 72
CUDA:False
Training samples count:  550
Training on 20 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1372, Training Loss: 0.1372, Initial Validation Loss: 0.1354, Validation Loss: 0.1354,V Acc: 0.3333, Top 70th Acc: 0.3077, Bottom 30th Acc: 0.3939
Fold [1/5] Epoch [10/100] Initial Loss: 0.1372, Training Loss: 0.0305, Initial Validation Loss: 0.1354, Validation Loss: 0.0376,V Acc: 0.8288, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.5455
Fold [1/5] Epoch [20/100] Initial Loss: 0.1372, Training Loss: 0.0229, Initial Validation Loss: 0.1354, Validation Loss: 0.0333,V Acc: 0.8198, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.4848
Stopping early at Epoch (base 0): 22  Rolling back to Epoch (base 0): 17  Top Validation Acc: 0.9487179487179487
Fold [2/5] Epoch [0/100] Initial Loss: 0.1351, Training Loss: 0.1351, Initial Validation Loss: 0.1297, Validation Loss: 0.1297,V Acc: 0.4144, Top 70th Acc: 0.3974, Bottom 30th Acc: 0.4545
Fold [2/5] Epoch [10/100] Initial Loss: 0.1351, Training Loss: 0.0372, Initial Validation Loss: 0.1297, Validation Loss: 0.0350,V Acc: 0.8468, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.6667
Fold [2/5] Epoch [20/100] Initial Loss: 0.1351, Training Loss: 0.0247, Initial Validation Loss: 0.1297, Validation Loss: 0.0266,V Acc: 0.8739, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.7576
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.9230769230769231
Fold [3/5] Epoch [0/100] Initial Loss: 0.1353, Training Loss: 0.1353, Initial Validation Loss: 0.1287, Validation Loss: 0.1287,V Acc: 0.4727, Top 70th Acc: 0.5714, Bottom 30th Acc: 0.2424
Fold [3/5] Epoch [10/100] Initial Loss: 0.1353, Training Loss: 0.0332, Initial Validation Loss: 0.1287, Validation Loss: 0.0414,V Acc: 0.7909, Top 70th Acc: 0.8831, Bottom 30th Acc: 0.5758
Fold [3/5] Epoch [20/100] Initial Loss: 0.1353, Training Loss: 0.0222, Initial Validation Loss: 0.1287, Validation Loss: 0.0370,V Acc: 0.7909, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.4848
Fold [3/5] Epoch [30/100] Initial Loss: 0.1353, Training Loss: 0.0198, Initial Validation Loss: 0.1287, Validation Loss: 0.0364,V Acc: 0.8182, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 30  Rolling back to Epoch (base 0): 25  Top Validation Acc: 0.922077922077922
Fold [4/5] Epoch [0/100] Initial Loss: 0.1411, Training Loss: 0.1411, Initial Validation Loss: 0.1376, Validation Loss: 0.1376,V Acc: 0.2545, Top 70th Acc: 0.2857, Bottom 30th Acc: 0.1818
Fold [4/5] Epoch [10/100] Initial Loss: 0.1411, Training Loss: 0.0439, Initial Validation Loss: 0.1376, Validation Loss: 0.0454,V Acc: 0.8182, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.6061
Fold [4/5] Epoch [20/100] Initial Loss: 0.1411, Training Loss: 0.0332, Initial Validation Loss: 0.1376, Validation Loss: 0.0371,V Acc: 0.8273, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.5758
Fold [4/5] Epoch [30/100] Initial Loss: 0.1411, Training Loss: 0.0266, Initial Validation Loss: 0.1376, Validation Loss: 0.0304,V Acc: 0.8545, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6364
Fold [4/5] Epoch [40/100] Initial Loss: 0.1411, Training Loss: 0.0217, Initial Validation Loss: 0.1376, Validation Loss: 0.0277,V Acc: 0.8727, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 44  Rolling back to Epoch (base 0): 39  Top Validation Acc: 0.948051948051948
72 3 [array([0.352615  , 0.09836285, 0.1962137 , 0.24959053, 0.10321795],
      dtype=float32)]
Fold [5/5] Epoch [0/100] Initial Loss: 0.1363, Training Loss: 0.1363, Initial Validation Loss: 0.1290, Validation Loss: 0.1290,V Acc: 0.4444, Top 70th Acc: 0.4868, Bottom 30th Acc: 0.3438
Fold [5/5] Epoch [10/100] Initial Loss: 0.1363, Training Loss: 0.0329, Initial Validation Loss: 0.1290, Validation Loss: 0.0443,V Acc: 0.8241, Top 70th Acc: 0.8947, Bottom 30th Acc: 0.6562
Fold [5/5] Epoch [20/100] Initial Loss: 0.1363, Training Loss: 0.0218, Initial Validation Loss: 0.1290, Validation Loss: 0.0378,V Acc: 0.8056, Top 70th Acc: 0.9211, Bottom 30th Acc: 0.5312
Fold [5/5] Epoch [30/100] Initial Loss: 0.1363, Training Loss: 0.0199, Initial Validation Loss: 0.1290, Validation Loss: 0.0366,V Acc: 0.8056, Top 70th Acc: 0.9211, Bottom 30th Acc: 0.5312
Fold [5/5] Epoch [40/100] Initial Loss: 0.1363, Training Loss: 0.0190, Initial Validation Loss: 0.1290, Validation Loss: 0.0367,V Acc: 0.8056, Top 70th Acc: 0.9079, Bottom 30th Acc: 0.5625
Stopping early at Epoch (base 0): 47  Rolling back to Epoch (base 0): 42  Top Validation Acc: 0.9473684210526315
Running train_nn.py with seed 73
CUDA:False
Training samples count:  550
Training on 20 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1359, Training Loss: 0.1359, Initial Validation Loss: 0.1330, Validation Loss: 0.1330,V Acc: 0.3874, Top 70th Acc: 0.4487, Bottom 30th Acc: 0.2424
Fold [1/5] Epoch [10/100] Initial Loss: 0.1359, Training Loss: 0.0439, Initial Validation Loss: 0.1330, Validation Loss: 0.0552,V Acc: 0.7568, Top 70th Acc: 0.8462, Bottom 30th Acc: 0.5455
Fold [1/5] Epoch [20/100] Initial Loss: 0.1359, Training Loss: 0.0237, Initial Validation Loss: 0.1330, Validation Loss: 0.0409,V Acc: 0.8018, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.5152
Stopping early at Epoch (base 0): 29  Rolling back to Epoch (base 0): 24  Top Validation Acc: 0.9230769230769231
73 0 [array([0.2748392 , 0.09291513, 0.3858731 , 0.17030399, 0.07606858],
      dtype=float32)]
Fold [2/5] Epoch [0/100] Initial Loss: 0.1381, Training Loss: 0.1381, Initial Validation Loss: 0.1306, Validation Loss: 0.1306,V Acc: 0.3333, Top 70th Acc: 0.4231, Bottom 30th Acc: 0.1212
Fold [2/5] Epoch [10/100] Initial Loss: 0.1381, Training Loss: 0.0391, Initial Validation Loss: 0.1306, Validation Loss: 0.0447,V Acc: 0.7477, Top 70th Acc: 0.8590, Bottom 30th Acc: 0.4848
Fold [2/5] Epoch [20/100] Initial Loss: 0.1381, Training Loss: 0.0249, Initial Validation Loss: 0.1306, Validation Loss: 0.0345,V Acc: 0.7928, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.5152
Fold [2/5] Epoch [30/100] Initial Loss: 0.1381, Training Loss: 0.0211, Initial Validation Loss: 0.1306, Validation Loss: 0.0338,V Acc: 0.8198, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 31  Rolling back to Epoch (base 0): 26  Top Validation Acc: 0.8974358974358975
Fold [3/5] Epoch [0/100] Initial Loss: 0.1376, Training Loss: 0.1376, Initial Validation Loss: 0.1269, Validation Loss: 0.1269,V Acc: 0.3818, Top 70th Acc: 0.5065, Bottom 30th Acc: 0.0909
Fold [3/5] Epoch [10/100] Initial Loss: 0.1376, Training Loss: 0.0315, Initial Validation Loss: 0.1269, Validation Loss: 0.0322,V Acc: 0.8545, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 18  Rolling back to Epoch (base 0): 13  Top Validation Acc: 0.935064935064935
Fold [4/5] Epoch [0/100] Initial Loss: 0.1405, Training Loss: 0.1405, Initial Validation Loss: 0.1376, Validation Loss: 0.1376,V Acc: 0.2636, Top 70th Acc: 0.3247, Bottom 30th Acc: 0.1212
Fold [4/5] Epoch [10/100] Initial Loss: 0.1405, Training Loss: 0.0458, Initial Validation Loss: 0.1376, Validation Loss: 0.0513,V Acc: 0.7727, Top 70th Acc: 0.8701, Bottom 30th Acc: 0.5455
Fold [4/5] Epoch [20/100] Initial Loss: 0.1405, Training Loss: 0.0246, Initial Validation Loss: 0.1376, Validation Loss: 0.0396,V Acc: 0.8455, Top 70th Acc: 0.8961, Bottom 30th Acc: 0.7273
Fold [3/5] Epoch [10/100] Initial Loss: 0.1313, Training Loss: 0.0780, Initial Validation Loss: 0.1208, Validation Loss: 0.0876,V Acc: 0.5727, Top 70th Acc: 0.7013, Bottom 30th Acc: 0.2727
Fold [3/5] Epoch [20/100] Initial Loss: 0.1313, Training Loss: 0.0756, Initial Validation Loss: 0.1208, Validation Loss: 0.0845,V Acc: 0.6000, Top 70th Acc: 0.7143, Bottom 30th Acc: 0.3333
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.7142857142857143
Fold [4/5] Epoch [0/100] Initial Loss: 0.1303, Training Loss: 0.1303, Initial Validation Loss: 0.1171, Validation Loss: 0.1171,V Acc: 0.4000, Top 70th Acc: 0.4416, Bottom 30th Acc: 0.3030
Fold [4/5] Epoch [10/100] Initial Loss: 0.1303, Training Loss: 0.0805, Initial Validation Loss: 0.1171, Validation Loss: 0.0815,V Acc: 0.6091, Top 70th Acc: 0.7403, Bottom 30th Acc: 0.3030
Fold [4/5] Epoch [20/100] Initial Loss: 0.1303, Training Loss: 0.0784, Initial Validation Loss: 0.1171, Validation Loss: 0.0795,V Acc: 0.6091, Top 70th Acc: 0.7532, Bottom 30th Acc: 0.2727
Fold [4/5] Epoch [30/100] Initial Loss: 0.1303, Training Loss: 0.0776, Initial Validation Loss: 0.1171, Validation Loss: 0.0785,V Acc: 0.6091, Top 70th Acc: 0.7403, Bottom 30th Acc: 0.3030
Stopping early at Epoch (base 0): 35  Rolling back to Epoch (base 0): 30  Top Validation Acc: 0.7532467532467533
Fold [5/5] Epoch [0/100] Initial Loss: 0.1415, Training Loss: 0.1415, Initial Validation Loss: 0.1337, Validation Loss: 0.1337,V Acc: 0.3241, Top 70th Acc: 0.4211, Bottom 30th Acc: 0.0938
Fold [5/5] Epoch [10/100] Initial Loss: 0.1415, Training Loss: 0.0812, Initial Validation Loss: 0.1337, Validation Loss: 0.0835,V Acc: 0.6019, Top 70th Acc: 0.7237, Bottom 30th Acc: 0.3125
Fold [5/5] Epoch [20/100] Initial Loss: 0.1415, Training Loss: 0.0784, Initial Validation Loss: 0.1337, Validation Loss: 0.0814,V Acc: 0.5926, Top 70th Acc: 0.7368, Bottom 30th Acc: 0.2500
Fold [5/5] Epoch [30/100] Initial Loss: 0.1415, Training Loss: 0.0776, Initial Validation Loss: 0.1337, Validation Loss: 0.0801,V Acc: 0.6111, Top 70th Acc: 0.7237, Bottom 30th Acc: 0.3438
Stopping early at Epoch (base 0): 37  Rolling back to Epoch (base 0): 32  Top Validation Acc: 0.7368421052631579
Running train_nn.py with seed 68
CUDA:False
Training samples count:  550
Training on 2 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1329, Training Loss: 0.1329, Initial Validation Loss: 0.1331, Validation Loss: 0.1331,V Acc: 0.3874, Top 70th Acc: 0.4487, Bottom 30th Acc: 0.2424
Fold [1/5] Epoch [10/100] Initial Loss: 0.1329, Training Loss: 0.0784, Initial Validation Loss: 0.1331, Validation Loss: 0.0873,V Acc: 0.6216, Top 70th Acc: 0.7436, Bottom 30th Acc: 0.3333
Fold [1/5] Epoch [20/100] Initial Loss: 0.1329, Training Loss: 0.0768, Initial Validation Loss: 0.1331, Validation Loss: 0.0852,V Acc: 0.6216, Top 70th Acc: 0.7564, Bottom 30th Acc: 0.3030
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.7564102564102564
Fold [2/5] Epoch [0/100] Initial Loss: 0.1322, Training Loss: 0.1322, Initial Validation Loss: 0.1225, Validation Loss: 0.1225,V Acc: 0.4595, Top 70th Acc: 0.5769, Bottom 30th Acc: 0.1818
Fold [2/5] Epoch [10/100] Initial Loss: 0.1322, Training Loss: 0.0809, Initial Validation Loss: 0.1225, Validation Loss: 0.0772,V Acc: 0.6577, Top 70th Acc: 0.7692, Bottom 30th Acc: 0.3939
Fold [2/5] Epoch [20/100] Initial Loss: 0.1322, Training Loss: 0.0789, Initial Validation Loss: 0.1225, Validation Loss: 0.0765,V Acc: 0.6396, Top 70th Acc: 0.7436, Bottom 30th Acc: 0.3939
Fold [2/5] Epoch [30/100] Initial Loss: 0.1322, Training Loss: 0.0783, Initial Validation Loss: 0.1225, Validation Loss: 0.0757,V Acc: 0.6486, Top 70th Acc: 0.7436, Bottom 30th Acc: 0.4242
Fold [2/5] Epoch [40/100] Initial Loss: 0.1322, Training Loss: 0.0773, Initial Validation Loss: 0.1225, Validation Loss: 0.0758,V Acc: 0.6577, Top 70th Acc: 0.7436, Bottom 30th Acc: 0.4545
Stopping early at Epoch (base 0): 43  Rolling back to Epoch (base 0): 38  Top Validation Acc: 0.7435897435897436
Fold [3/5] Epoch [0/100] Initial Loss: 0.1347, Training Loss: 0.1347, Initial Validation Loss: 0.1207, Validation Loss: 0.1207,V Acc: 0.3182, Top 70th Acc: 0.3766, Bottom 30th Acc: 0.1818
Fold [3/5] Epoch [10/100] Initial Loss: 0.1347, Training Loss: 0.0799, Initial Validation Loss: 0.1207, Validation Loss: 0.0800,V Acc: 0.5727, Top 70th Acc: 0.7013, Bottom 30th Acc: 0.2727
Fold [3/5] Epoch [20/100] Initial Loss: 0.1347, Training Loss: 0.0783, Initial Validation Loss: 0.1207, Validation Loss: 0.0788,V Acc: 0.5636, Top 70th Acc: 0.7013, Bottom 30th Acc: 0.2424
Stopping early at Epoch (base 0): 28  Rolling back to Epoch (base 0): 23  Top Validation Acc: 0.7012987012987013
Fold [4/5] Epoch [0/100] Initial Loss: 0.1331, Training Loss: 0.1331, Initial Validation Loss: 0.1283, Validation Loss: 0.1283,V Acc: 0.4000, Top 70th Acc: 0.4675, Bottom 30th Acc: 0.2424
Fold [4/5] Epoch [10/100] Initial Loss: 0.1331, Training Loss: 0.0808, Initial Validation Loss: 0.1283, Validation Loss: 0.0808,V Acc: 0.6455, Top 70th Acc: 0.7273, Bottom 30th Acc: 0.4545
Fold [4/5] Epoch [20/100] Initial Loss: 0.1331, Training Loss: 0.0786, Initial Validation Loss: 0.1283, Validation Loss: 0.0794,V Acc: 0.6455, Top 70th Acc: 0.7273, Bottom 30th Acc: 0.4545
Fold [4/5] Epoch [30/100] Initial Loss: 0.1331, Training Loss: 0.0773, Initial Validation Loss: 0.1283, Validation Loss: 0.0783,V Acc: 0.6636, Top 70th Acc: 0.7662, Bottom 30th Acc: 0.4242
Fold [4/5] Epoch [40/100] Initial Loss: 0.1331, Training Loss: 0.0775, Initial Validation Loss: 0.1283, Validation Loss: 0.0777,V Acc: 0.6818, Top 70th Acc: 0.7403, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 47  Rolling back to Epoch (base 0): 42  Top Validation Acc: 0.7402597402597403
Fold [5/5] Epoch [0/100] Initial Loss: 0.1370, Training Loss: 0.1370, Initial Validation Loss: 0.1176, Validation Loss: 0.1176,V Acc: 0.5556, Top 70th Acc: 0.6316, Bottom 30th Acc: 0.3750
Fold [5/5] Epoch [10/100] Initial Loss: 0.1370, Training Loss: 0.0821, Initial Validation Loss: 0.1176, Validation Loss: 0.0740,V Acc: 0.6574, Top 70th Acc: 0.7500, Bottom 30th Acc: 0.4375
Fold [5/5] Epoch [20/100] Initial Loss: 0.1370, Training Loss: 0.0804, Initial Validation Loss: 0.1176, Validation Loss: 0.0719,V Acc: 0.6574, Top 70th Acc: 0.7500, Bottom 30th Acc: 0.4375
Stopping early at Epoch (base 0): 27  Rolling back to Epoch (base 0): 22  Top Validation Acc: 0.7631578947368421
68 4 [array([0.12198306, 0.37358582, 0.14754625, 0.21471968, 0.14216515],
      dtype=float32)]
Running train_nn.py with seed 69
CUDA:False
Training samples count:  550
Training on 2 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1419, Training Loss: 0.1419, Initial Validation Loss: 0.1277, Validation Loss: 0.1277,V Acc: 0.4505, Top 70th Acc: 0.5256, Bottom 30th Acc: 0.2727
Fold [1/5] Epoch [10/100] Initial Loss: 0.1419, Training Loss: 0.0820, Initial Validation Loss: 0.1277, Validation Loss: 0.0815,V Acc: 0.6306, Top 70th Acc: 0.7308, Bottom 30th Acc: 0.3939
Fold [1/5] Epoch [20/100] Initial Loss: 0.1419, Training Loss: 0.0797, Initial Validation Loss: 0.1277, Validation Loss: 0.0791,V Acc: 0.6577, Top 70th Acc: 0.7436, Bottom 30th Acc: 0.4545
Fold [1/5] Epoch [30/100] Initial Loss: 0.1419, Training Loss: 0.0788, Initial Validation Loss: 0.1277, Validation Loss: 0.0784,V Acc: 0.6577, Top 70th Acc: 0.7692, Bottom 30th Acc: 0.3939
Stopping early at Epoch (base 0): 39  Rolling back to Epoch (base 0): 34  Top Validation Acc: 0.7435897435897436
69 0 [array([0.16889991, 0.3483771 , 0.1189111 , 0.22785649, 0.13595536],
      dtype=float32)]
Fold [2/5] Epoch [0/100] Initial Loss: 0.1386, Training Loss: 0.1386, Initial Validation Loss: 0.1330, Validation Loss: 0.1330,V Acc: 0.4054, Top 70th Acc: 0.4487, Bottom 30th Acc: 0.3030
Fold [2/5] Epoch [10/100] Initial Loss: 0.1386, Training Loss: 0.0813, Initial Validation Loss: 0.1330, Validation Loss: 0.0804,V Acc: 0.6486, Top 70th Acc: 0.7692, Bottom 30th Acc: 0.3636
Fold [2/5] Epoch [20/100] Initial Loss: 0.1386, Training Loss: 0.0785, Initial Validation Loss: 0.1330, Validation Loss: 0.0787,V Acc: 0.6396, Top 70th Acc: 0.7436, Bottom 30th Acc: 0.3939
Fold [5/5] Epoch [30/100] Initial Loss: 0.1371, Training Loss: 0.0171, Initial Validation Loss: 0.1360, Validation Loss: 0.0300,V Acc: 0.8241, Top 70th Acc: 0.9737, Bottom 30th Acc: 0.4688
Stopping early at Epoch (base 0): 31  Rolling back to Epoch (base 0): 26  Top Validation Acc: 0.9605263157894737
Running train_nn.py with seed 72
CUDA:False
Training samples count:  550
Training on 30 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1379, Training Loss: 0.1379, Initial Validation Loss: 0.1364, Validation Loss: 0.1364,V Acc: 0.2793, Top 70th Acc: 0.3333, Bottom 30th Acc: 0.1515
Fold [1/5] Epoch [10/100] Initial Loss: 0.1379, Training Loss: 0.0362, Initial Validation Loss: 0.1364, Validation Loss: 0.0496,V Acc: 0.7387, Top 70th Acc: 0.8974, Bottom 30th Acc: 0.3636
Fold [1/5] Epoch [20/100] Initial Loss: 0.1379, Training Loss: 0.0251, Initial Validation Loss: 0.1364, Validation Loss: 0.0492,V Acc: 0.7568, Top 70th Acc: 0.8718, Bottom 30th Acc: 0.4848
Stopping early at Epoch (base 0): 21  Rolling back to Epoch (base 0): 16  Top Validation Acc: 0.8846153846153846
Fold [2/5] Epoch [0/100] Initial Loss: 0.1401, Training Loss: 0.1401, Initial Validation Loss: 0.1360, Validation Loss: 0.1360,V Acc: 0.2613, Top 70th Acc: 0.2564, Bottom 30th Acc: 0.2727
Fold [2/5] Epoch [10/100] Initial Loss: 0.1401, Training Loss: 0.0368, Initial Validation Loss: 0.1360, Validation Loss: 0.0397,V Acc: 0.7928, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.4848
Fold [2/5] Epoch [20/100] Initial Loss: 0.1401, Training Loss: 0.0205, Initial Validation Loss: 0.1360, Validation Loss: 0.0328,V Acc: 0.8108, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.5455
Fold [2/5] Epoch [30/100] Initial Loss: 0.1401, Training Loss: 0.0170, Initial Validation Loss: 0.1360, Validation Loss: 0.0322,V Acc: 0.8468, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 30  Rolling back to Epoch (base 0): 25  Top Validation Acc: 0.9102564102564102
Fold [3/5] Epoch [0/100] Initial Loss: 0.1396, Training Loss: 0.1396, Initial Validation Loss: 0.1346, Validation Loss: 0.1346,V Acc: 0.3636, Top 70th Acc: 0.3636, Bottom 30th Acc: 0.3636
Fold [3/5] Epoch [10/100] Initial Loss: 0.1396, Training Loss: 0.0432, Initial Validation Loss: 0.1346, Validation Loss: 0.0469,V Acc: 0.8000, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.5455
Fold [3/5] Epoch [20/100] Initial Loss: 0.1396, Training Loss: 0.0189, Initial Validation Loss: 0.1346, Validation Loss: 0.0297,V Acc: 0.8636, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6667
Fold [3/5] Epoch [30/100] Initial Loss: 0.1396, Training Loss: 0.0153, Initial Validation Loss: 0.1346, Validation Loss: 0.0301,V Acc: 0.8636, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 31  Rolling back to Epoch (base 0): 26  Top Validation Acc: 0.961038961038961
Fold [4/5] Epoch [0/100] Initial Loss: 0.1363, Training Loss: 0.1363, Initial Validation Loss: 0.1348, Validation Loss: 0.1348,V Acc: 0.3727, Top 70th Acc: 0.4675, Bottom 30th Acc: 0.1515
Fold [4/5] Epoch [10/100] Initial Loss: 0.1363, Training Loss: 0.0331, Initial Validation Loss: 0.1348, Validation Loss: 0.0386,V Acc: 0.8545, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.6667
Fold [4/5] Epoch [20/100] Initial Loss: 0.1363, Training Loss: 0.0188, Initial Validation Loss: 0.1348, Validation Loss: 0.0302,V Acc: 0.8636, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 29  Rolling back to Epoch (base 0): 24  Top Validation Acc: 0.948051948051948
72 3 [array([0.66003954, 0.04472493, 0.05695373, 0.11951756, 0.11876428],
      dtype=float32)]
Fold [5/5] Epoch [0/100] Initial Loss: 0.1417, Training Loss: 0.1417, Initial Validation Loss: 0.1337, Validation Loss: 0.1337,V Acc: 0.2130, Top 70th Acc: 0.2105, Bottom 30th Acc: 0.2188
Fold [5/5] Epoch [10/100] Initial Loss: 0.1417, Training Loss: 0.0381, Initial Validation Loss: 0.1337, Validation Loss: 0.0507,V Acc: 0.7315, Top 70th Acc: 0.8684, Bottom 30th Acc: 0.4062
Fold [5/5] Epoch [20/100] Initial Loss: 0.1417, Training Loss: 0.0186, Initial Validation Loss: 0.1337, Validation Loss: 0.0378,V Acc: 0.8056, Top 70th Acc: 0.9079, Bottom 30th Acc: 0.5625
Fold [5/5] Epoch [30/100] Initial Loss: 0.1417, Training Loss: 0.0157, Initial Validation Loss: 0.1337, Validation Loss: 0.0378,V Acc: 0.7685, Top 70th Acc: 0.9079, Bottom 30th Acc: 0.4375
Stopping early at Epoch (base 0): 30  Rolling back to Epoch (base 0): 25  Top Validation Acc: 0.9078947368421053
Running train_nn.py with seed 73
CUDA:False
Training samples count:  550
Training on 30 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1377, Training Loss: 0.1377, Initial Validation Loss: 0.1331, Validation Loss: 0.1331,V Acc: 0.3153, Top 70th Acc: 0.3718, Bottom 30th Acc: 0.1818
Fold [1/5] Epoch [10/100] Initial Loss: 0.1377, Training Loss: 0.0327, Initial Validation Loss: 0.1331, Validation Loss: 0.0445,V Acc: 0.7928, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.4242
Fold [1/5] Epoch [20/100] Initial Loss: 0.1377, Training Loss: 0.0177, Initial Validation Loss: 0.1331, Validation Loss: 0.0338,V Acc: 0.8288, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.5152
Fold [1/5] Epoch [30/100] Initial Loss: 0.1377, Training Loss: 0.0156, Initial Validation Loss: 0.1331, Validation Loss: 0.0325,V Acc: 0.8468, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 32  Rolling back to Epoch (base 0): 27  Top Validation Acc: 0.9487179487179487
73 0 [array([0.60528594, 0.0225245 , 0.07453458, 0.12593594, 0.17171906],
      dtype=float32)]
Fold [2/5] Epoch [0/100] Initial Loss: 0.1418, Training Loss: 0.1418, Initial Validation Loss: 0.1318, Validation Loss: 0.1318,V Acc: 0.2523, Top 70th Acc: 0.3462, Bottom 30th Acc: 0.0303
Fold [2/5] Epoch [10/100] Initial Loss: 0.1418, Training Loss: 0.0289, Initial Validation Loss: 0.1318, Validation Loss: 0.0393,V Acc: 0.7928, Top 70th Acc: 0.8974, Bottom 30th Acc: 0.5455
Fold [2/5] Epoch [20/100] Initial Loss: 0.1418, Training Loss: 0.0161, Initial Validation Loss: 0.1318, Validation Loss: 0.0349,V Acc: 0.7748, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.4545
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.8974358974358975
Fold [3/5] Epoch [0/100] Initial Loss: 0.1415, Training Loss: 0.1415, Initial Validation Loss: 0.1346, Validation Loss: 0.1346,V Acc: 0.2909, Top 70th Acc: 0.3247, Bottom 30th Acc: 0.2121
Fold [3/5] Epoch [10/100] Initial Loss: 0.1415, Training Loss: 0.0242, Initial Validation Loss: 0.1346, Validation Loss: 0.0287,V Acc: 0.8727, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 17  Rolling back to Epoch (base 0): 12  Top Validation Acc: 0.961038961038961
Fold [4/5] Epoch [0/100] Initial Loss: 0.1382, Training Loss: 0.1382, Initial Validation Loss: 0.1383, Validation Loss: 0.1383,V Acc: 0.2727, Top 70th Acc: 0.3636, Bottom 30th Acc: 0.0606
Fold [4/5] Epoch [10/100] Initial Loss: 0.1382, Training Loss: 0.0292, Initial Validation Loss: 0.1383, Validation Loss: 0.0380,V Acc: 0.8455, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.5758
Fold [4/5] Epoch [20/100] Initial Loss: 0.1382, Training Loss: 0.0166, Initial Validation Loss: 0.1383, Validation Loss: 0.0346,V Acc: 0.8273, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 22  Rolling back to Epoch (base 0): 17  Top Validation Acc: 0.935064935064935
Fold [5/5] Epoch [0/100] Initial Loss: 0.1410, Training Loss: 0.1410, Initial Validation Loss: 0.1370, Validation Loss: 0.1370,V Acc: 0.2500, Top 70th Acc: 0.2763, Bottom 30th Acc: 0.1875
Fold [5/5] Epoch [10/100] Initial Loss: 0.1410, Training Loss: 0.0308, Initial Validation Loss: 0.1370, Validation Loss: 0.0365,V Acc: 0.8241, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.5312
Fold [5/5] Epoch [20/100] Initial Loss: 0.1410, Training Loss: 0.0181, Initial Validation Loss: 0.1370, Validation Loss: 0.0309,V Acc: 0.8333, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.5312
Stopping early at Epoch (base 0): 28  Rolling back to Epoch (base 0): 23  Top Validation Acc: 0.9342105263157895
Running train_nn.py with seed 74
CUDA:False
Training samples count:  550
Training on 30 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1421, Training Loss: 0.1421, Initial Validation Loss: 0.1358, Validation Loss: 0.1358,V Acc: 0.3153, Top 70th Acc: 0.4103, Bottom 30th Acc: 0.0909
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.9736842105263158
Running train_nn.py with seed 72
CUDA:False
Training samples count:  550
Training on 40 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1385, Training Loss: 0.1385, Initial Validation Loss: 0.1355, Validation Loss: 0.1355,V Acc: 0.3874, Top 70th Acc: 0.3974, Bottom 30th Acc: 0.3636
Fold [1/5] Epoch [10/100] Initial Loss: 0.1385, Training Loss: 0.0342, Initial Validation Loss: 0.1355, Validation Loss: 0.0403,V Acc: 0.8559, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.6970
Fold [1/5] Epoch [20/100] Initial Loss: 0.1385, Training Loss: 0.0145, Initial Validation Loss: 0.1355, Validation Loss: 0.0298,V Acc: 0.8468, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 22  Rolling back to Epoch (base 0): 17  Top Validation Acc: 0.9743589743589743
Fold [2/5] Epoch [0/100] Initial Loss: 0.1384, Training Loss: 0.1384, Initial Validation Loss: 0.1349, Validation Loss: 0.1349,V Acc: 0.2342, Top 70th Acc: 0.3077, Bottom 30th Acc: 0.0606
Fold [2/5] Epoch [10/100] Initial Loss: 0.1384, Training Loss: 0.0298, Initial Validation Loss: 0.1349, Validation Loss: 0.0317,V Acc: 0.8198, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.5758
Fold [2/5] Epoch [20/100] Initial Loss: 0.1384, Training Loss: 0.0145, Initial Validation Loss: 0.1349, Validation Loss: 0.0246,V Acc: 0.8559, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.6364
Fold [2/5] Epoch [30/100] Initial Loss: 0.1384, Training Loss: 0.0123, Initial Validation Loss: 0.1349, Validation Loss: 0.0239,V Acc: 0.8378, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 35  Rolling back to Epoch (base 0): 30  Top Validation Acc: 0.9487179487179487
Fold [3/5] Epoch [0/100] Initial Loss: 0.1390, Training Loss: 0.1390, Initial Validation Loss: 0.1339, Validation Loss: 0.1339,V Acc: 0.2636, Top 70th Acc: 0.3117, Bottom 30th Acc: 0.1515
Fold [3/5] Epoch [10/100] Initial Loss: 0.1390, Training Loss: 0.0412, Initial Validation Loss: 0.1339, Validation Loss: 0.0442,V Acc: 0.8091, Top 70th Acc: 0.8961, Bottom 30th Acc: 0.6061
Fold [3/5] Epoch [20/100] Initial Loss: 0.1390, Training Loss: 0.0218, Initial Validation Loss: 0.1339, Validation Loss: 0.0370,V Acc: 0.8000, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.4545
Fold [3/5] Epoch [30/100] Initial Loss: 0.1390, Training Loss: 0.0168, Initial Validation Loss: 0.1339, Validation Loss: 0.0355,V Acc: 0.8091, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.4545
Stopping early at Epoch (base 0): 32  Rolling back to Epoch (base 0): 27  Top Validation Acc: 0.961038961038961
Fold [4/5] Epoch [0/100] Initial Loss: 0.1380, Training Loss: 0.1380, Initial Validation Loss: 0.1352, Validation Loss: 0.1352,V Acc: 0.3545, Top 70th Acc: 0.4416, Bottom 30th Acc: 0.1515
Fold [4/5] Epoch [10/100] Initial Loss: 0.1380, Training Loss: 0.0262, Initial Validation Loss: 0.1352, Validation Loss: 0.0389,V Acc: 0.8182, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.5758
Fold [4/5] Epoch [20/100] Initial Loss: 0.1380, Training Loss: 0.0145, Initial Validation Loss: 0.1352, Validation Loss: 0.0291,V Acc: 0.8636, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.6364
Fold [4/5] Epoch [30/100] Initial Loss: 0.1380, Training Loss: 0.0123, Initial Validation Loss: 0.1352, Validation Loss: 0.0278,V Acc: 0.8636, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.6061
Fold [4/5] Epoch [40/100] Initial Loss: 0.1380, Training Loss: 0.0112, Initial Validation Loss: 0.1352, Validation Loss: 0.0272,V Acc: 0.8545, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 46  Rolling back to Epoch (base 0): 41  Top Validation Acc: 0.974025974025974
72 3 [array([0.3845086 , 0.05323997, 0.10328056, 0.05060996, 0.40836096],
      dtype=float32)]
Fold [5/5] Epoch [0/100] Initial Loss: 0.1381, Training Loss: 0.1381, Initial Validation Loss: 0.1307, Validation Loss: 0.1307,V Acc: 0.2685, Top 70th Acc: 0.3553, Bottom 30th Acc: 0.0625
Fold [5/5] Epoch [10/100] Initial Loss: 0.1381, Training Loss: 0.0278, Initial Validation Loss: 0.1307, Validation Loss: 0.0374,V Acc: 0.7963, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.4688
Fold [5/5] Epoch [20/100] Initial Loss: 0.1381, Training Loss: 0.0133, Initial Validation Loss: 0.1307, Validation Loss: 0.0324,V Acc: 0.8056, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.4375
Stopping early at Epoch (base 0): 21  Rolling back to Epoch (base 0): 16  Top Validation Acc: 0.9605263157894737
Running train_nn.py with seed 73
CUDA:False
Training samples count:  550
Training on 40 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1376, Training Loss: 0.1376, Initial Validation Loss: 0.1330, Validation Loss: 0.1330,V Acc: 0.2793, Top 70th Acc: 0.3462, Bottom 30th Acc: 0.1212
Fold [1/5] Epoch [10/100] Initial Loss: 0.1376, Training Loss: 0.0239, Initial Validation Loss: 0.1330, Validation Loss: 0.0390,V Acc: 0.8108, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.5152
Fold [1/5] Epoch [20/100] Initial Loss: 0.1376, Training Loss: 0.0135, Initial Validation Loss: 0.1330, Validation Loss: 0.0318,V Acc: 0.8559, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.6061
Fold [1/5] Epoch [30/100] Initial Loss: 0.1376, Training Loss: 0.0115, Initial Validation Loss: 0.1330, Validation Loss: 0.0299,V Acc: 0.8559, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 35  Rolling back to Epoch (base 0): 30  Top Validation Acc: 0.9615384615384616
73 0 [array([0.65655863, 0.02724067, 0.07880794, 0.12743998, 0.10995275],
      dtype=float32)]
Fold [2/5] Epoch [0/100] Initial Loss: 0.1398, Training Loss: 0.1398, Initial Validation Loss: 0.1313, Validation Loss: 0.1313,V Acc: 0.2613, Top 70th Acc: 0.2821, Bottom 30th Acc: 0.2121
Fold [2/5] Epoch [10/100] Initial Loss: 0.1398, Training Loss: 0.0247, Initial Validation Loss: 0.1313, Validation Loss: 0.0423,V Acc: 0.7838, Top 70th Acc: 0.8590, Bottom 30th Acc: 0.6061
Fold [2/5] Epoch [20/100] Initial Loss: 0.1398, Training Loss: 0.0123, Initial Validation Loss: 0.1313, Validation Loss: 0.0398,V Acc: 0.7928, Top 70th Acc: 0.8718, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 29  Rolling back to Epoch (base 0): 24  Top Validation Acc: 0.8717948717948718
Fold [3/5] Epoch [0/100] Initial Loss: 0.1392, Training Loss: 0.1392, Initial Validation Loss: 0.1340, Validation Loss: 0.1340,V Acc: 0.3545, Top 70th Acc: 0.3247, Bottom 30th Acc: 0.4242
Fold [3/5] Epoch [10/100] Initial Loss: 0.1392, Training Loss: 0.0320, Initial Validation Loss: 0.1340, Validation Loss: 0.0366,V Acc: 0.8273, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.6364
Fold [3/5] Epoch [20/100] Initial Loss: 0.1392, Training Loss: 0.0160, Initial Validation Loss: 0.1340, Validation Loss: 0.0266,V Acc: 0.8818, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.6667
Fold [3/5] Epoch [30/100] Initial Loss: 0.1392, Training Loss: 0.0133, Initial Validation Loss: 0.1340, Validation Loss: 0.0257,V Acc: 0.9000, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.7273
Stopping early at Epoch (base 0): 39  Rolling back to Epoch (base 0): 34  Top Validation Acc: 0.935064935064935
Fold [4/5] Epoch [0/100] Initial Loss: 0.1370, Training Loss: 0.1370, Initial Validation Loss: 0.1362, Validation Loss: 0.1362,V Acc: 0.3818, Top 70th Acc: 0.4156, Bottom 30th Acc: 0.3030
Fold [4/5] Epoch [10/100] Initial Loss: 0.1370, Training Loss: 0.0331, Initial Validation Loss: 0.1362, Validation Loss: 0.0411,V Acc: 0.7909, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.5152
Fold [4/5] Epoch [20/100] Initial Loss: 0.1370, Training Loss: 0.0200, Initial Validation Loss: 0.1362, Validation Loss: 0.0385,V Acc: 0.8182, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.5152
Stopping early at Epoch (base 0): 22  Rolling back to Epoch (base 0): 17  Top Validation Acc: 0.935064935064935
Fold [5/5] Epoch [0/100] Initial Loss: 0.1369, Training Loss: 0.1369, Initial Validation Loss: 0.1346, Validation Loss: 0.1346,V Acc: 0.3056, Top 70th Acc: 0.3289, Bottom 30th Acc: 0.2500
Fold [5/5] Epoch [10/100] Initial Loss: 0.1369, Training Loss: 0.0343, Initial Validation Loss: 0.1346, Validation Loss: 0.0420,V Acc: 0.7963, Top 70th Acc: 0.9079, Bottom 30th Acc: 0.5312
Fold [5/5] Epoch [20/100] Initial Loss: 0.1369, Training Loss: 0.0196, Initial Validation Loss: 0.1346, Validation Loss: 0.0353,V Acc: 0.8519, Top 70th Acc: 0.9211, Bottom 30th Acc: 0.6875
Fold [4/5] Epoch [30/100] Initial Loss: 0.1405, Training Loss: 0.0218, Initial Validation Loss: 0.1376, Validation Loss: 0.0356,V Acc: 0.8545, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.6970
Fold [4/5] Epoch [40/100] Initial Loss: 0.1405, Training Loss: 0.0206, Initial Validation Loss: 0.1376, Validation Loss: 0.0372,V Acc: 0.8545, Top 70th Acc: 0.8831, Bottom 30th Acc: 0.7879
Stopping early at Epoch (base 0): 40  Rolling back to Epoch (base 0): 35  Top Validation Acc: 0.8831168831168831
Fold [5/5] Epoch [0/100] Initial Loss: 0.1398, Training Loss: 0.1398, Initial Validation Loss: 0.1354, Validation Loss: 0.1354,V Acc: 0.2500, Top 70th Acc: 0.2763, Bottom 30th Acc: 0.1875
Fold [5/5] Epoch [10/100] Initial Loss: 0.1398, Training Loss: 0.0355, Initial Validation Loss: 0.1354, Validation Loss: 0.0406,V Acc: 0.8333, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.5938
Fold [5/5] Epoch [20/100] Initial Loss: 0.1398, Training Loss: 0.0243, Initial Validation Loss: 0.1354, Validation Loss: 0.0337,V Acc: 0.8426, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.5625
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.9605263157894737
Running train_nn.py with seed 74
CUDA:False
Training samples count:  550
Training on 20 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1406, Training Loss: 0.1406, Initial Validation Loss: 0.1351, Validation Loss: 0.1351,V Acc: 0.3063, Top 70th Acc: 0.2949, Bottom 30th Acc: 0.3333
Fold [1/5] Epoch [10/100] Initial Loss: 0.1406, Training Loss: 0.0376, Initial Validation Loss: 0.1351, Validation Loss: 0.0397,V Acc: 0.8468, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.6970
Fold [1/5] Epoch [20/100] Initial Loss: 0.1406, Training Loss: 0.0259, Initial Validation Loss: 0.1351, Validation Loss: 0.0294,V Acc: 0.8829, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.9615384615384616
Fold [2/5] Epoch [0/100] Initial Loss: 0.1383, Training Loss: 0.1383, Initial Validation Loss: 0.1354, Validation Loss: 0.1354,V Acc: 0.3514, Top 70th Acc: 0.3974, Bottom 30th Acc: 0.2424
Fold [2/5] Epoch [10/100] Initial Loss: 0.1383, Training Loss: 0.0502, Initial Validation Loss: 0.1354, Validation Loss: 0.0460,V Acc: 0.8198, Top 70th Acc: 0.8974, Bottom 30th Acc: 0.6364
Fold [2/5] Epoch [20/100] Initial Loss: 0.1383, Training Loss: 0.0268, Initial Validation Loss: 0.1354, Validation Loss: 0.0286,V Acc: 0.8829, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 29  Rolling back to Epoch (base 0): 24  Top Validation Acc: 0.9487179487179487
Fold [3/5] Epoch [0/100] Initial Loss: 0.1390, Training Loss: 0.1390, Initial Validation Loss: 0.1331, Validation Loss: 0.1331,V Acc: 0.3636, Top 70th Acc: 0.3377, Bottom 30th Acc: 0.4242
Fold [3/5] Epoch [10/100] Initial Loss: 0.1390, Training Loss: 0.0314, Initial Validation Loss: 0.1331, Validation Loss: 0.0391,V Acc: 0.8545, Top 70th Acc: 0.8961, Bottom 30th Acc: 0.7576
Stopping early at Epoch (base 0): 18  Rolling back to Epoch (base 0): 13  Top Validation Acc: 0.9090909090909091
74 2 [array([0.46754557, 0.06959383, 0.09905604, 0.24938142, 0.11442321],
      dtype=float32)]
Fold [4/5] Epoch [0/100] Initial Loss: 0.1379, Training Loss: 0.1379, Initial Validation Loss: 0.1295, Validation Loss: 0.1295,V Acc: 0.3545, Top 70th Acc: 0.3896, Bottom 30th Acc: 0.2727
Fold [4/5] Epoch [10/100] Initial Loss: 0.1379, Training Loss: 0.0351, Initial Validation Loss: 0.1295, Validation Loss: 0.0396,V Acc: 0.8273, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.6061
Fold [4/5] Epoch [20/100] Initial Loss: 0.1379, Training Loss: 0.0231, Initial Validation Loss: 0.1295, Validation Loss: 0.0362,V Acc: 0.8273, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 27  Rolling back to Epoch (base 0): 22  Top Validation Acc: 0.922077922077922
Fold [5/5] Epoch [0/100] Initial Loss: 0.1381, Training Loss: 0.1381, Initial Validation Loss: 0.1290, Validation Loss: 0.1290,V Acc: 0.3148, Top 70th Acc: 0.4079, Bottom 30th Acc: 0.0938
Fold [5/5] Epoch [10/100] Initial Loss: 0.1381, Training Loss: 0.0349, Initial Validation Loss: 0.1290, Validation Loss: 0.0456,V Acc: 0.7778, Top 70th Acc: 0.8816, Bottom 30th Acc: 0.5312
Fold [5/5] Epoch [20/100] Initial Loss: 0.1381, Training Loss: 0.0243, Initial Validation Loss: 0.1290, Validation Loss: 0.0374,V Acc: 0.7963, Top 70th Acc: 0.8947, Bottom 30th Acc: 0.5625
Stopping early at Epoch (base 0): 28  Rolling back to Epoch (base 0): 23  Top Validation Acc: 0.9078947368421053
Running train_nn.py with seed 75
CUDA:False
Training samples count:  550
Training on 20 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1380, Training Loss: 0.1380, Initial Validation Loss: 0.1346, Validation Loss: 0.1346,V Acc: 0.3784, Top 70th Acc: 0.4487, Bottom 30th Acc: 0.2121
Fold [1/5] Epoch [10/100] Initial Loss: 0.1380, Training Loss: 0.0301, Initial Validation Loss: 0.1346, Validation Loss: 0.0418,V Acc: 0.8198, Top 70th Acc: 0.8846, Bottom 30th Acc: 0.6667
Fold [1/5] Epoch [20/100] Initial Loss: 0.1380, Training Loss: 0.0217, Initial Validation Loss: 0.1346, Validation Loss: 0.0347,V Acc: 0.8288, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.8974358974358975
Fold [2/5] Epoch [0/100] Initial Loss: 0.1403, Training Loss: 0.1403, Initial Validation Loss: 0.1398, Validation Loss: 0.1398,V Acc: 0.2432, Top 70th Acc: 0.2692, Bottom 30th Acc: 0.1818
Fold [2/5] Epoch [10/100] Initial Loss: 0.1403, Training Loss: 0.0451, Initial Validation Loss: 0.1398, Validation Loss: 0.0400,V Acc: 0.8468, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.6364
Fold [2/5] Epoch [20/100] Initial Loss: 0.1403, Training Loss: 0.0261, Initial Validation Loss: 0.1398, Validation Loss: 0.0251,V Acc: 0.8919, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.6970
Fold [2/5] Epoch [30/100] Initial Loss: 0.1403, Training Loss: 0.0240, Initial Validation Loss: 0.1398, Validation Loss: 0.0250,V Acc: 0.8829, Top 70th Acc: 0.9872, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 33  Rolling back to Epoch (base 0): 28  Top Validation Acc: 0.9871794871794872
Fold [3/5] Epoch [0/100] Initial Loss: 0.1356, Training Loss: 0.1356, Initial Validation Loss: 0.1288, Validation Loss: 0.1288,V Acc: 0.3455, Top 70th Acc: 0.4416, Bottom 30th Acc: 0.1212
Fold [3/5] Epoch [10/100] Initial Loss: 0.1356, Training Loss: 0.0356, Initial Validation Loss: 0.1288, Validation Loss: 0.0388,V Acc: 0.8364, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.6667
Fold [3/5] Epoch [20/100] Initial Loss: 0.1356, Training Loss: 0.0253, Initial Validation Loss: 0.1288, Validation Loss: 0.0314,V Acc: 0.8545, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6364
Fold [3/5] Epoch [30/100] Initial Loss: 0.1356, Training Loss: 0.0230, Initial Validation Loss: 0.1288, Validation Loss: 0.0316,V Acc: 0.8455, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 30  Rolling back to Epoch (base 0): 25  Top Validation Acc: 0.948051948051948
Fold [4/5] Epoch [0/100] Initial Loss: 0.1404, Training Loss: 0.1404, Initial Validation Loss: 0.1309, Validation Loss: 0.1309,V Acc: 0.2909, Top 70th Acc: 0.3506, Bottom 30th Acc: 0.1515
Fold [4/5] Epoch [10/100] Initial Loss: 0.1404, Training Loss: 0.0330, Initial Validation Loss: 0.1309, Validation Loss: 0.0420,V Acc: 0.7818, Top 70th Acc: 0.8701, Bottom 30th Acc: 0.5758
Fold [4/5] Epoch [20/100] Initial Loss: 0.1404, Training Loss: 0.0224, Initial Validation Loss: 0.1309, Validation Loss: 0.0379,V Acc: 0.7636, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.4242
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.9090909090909091
Fold [5/5] Epoch [0/100] Initial Loss: 0.1363, Training Loss: 0.1363, Initial Validation Loss: 0.1345, Validation Loss: 0.1345,V Acc: 0.2500, Top 70th Acc: 0.3026, Bottom 30th Acc: 0.1250
Fold [5/5] Epoch [10/100] Initial Loss: 0.1363, Training Loss: 0.0366, Initial Validation Loss: 0.1345, Validation Loss: 0.0379,V Acc: 0.8519, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.6562
Fold [5/5] Epoch [20/100] Initial Loss: 0.1363, Training Loss: 0.0250, Initial Validation Loss: 0.1345, Validation Loss: 0.0313,V Acc: 0.8704, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.6875
Fold [3/5] Epoch [80/100] Initial Loss: 0.1399, Training Loss: 0.0038, Initial Validation Loss: 0.1350, Validation Loss: 0.0278,V Acc: 0.8273, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.5152
Stopping early at Epoch (base 0): 85  Rolling back to Epoch (base 0): 80  Top Validation Acc: 0.961038961038961
Fold [4/5] Epoch [0/100] Initial Loss: 0.1386, Training Loss: 0.1386, Initial Validation Loss: 0.1334, Validation Loss: 0.1334,V Acc: 0.2545, Top 70th Acc: 0.3506, Bottom 30th Acc: 0.0303
Fold [4/5] Epoch [10/100] Initial Loss: 0.1386, Training Loss: 0.0173, Initial Validation Loss: 0.1334, Validation Loss: 0.0363,V Acc: 0.8455, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.5455
Fold [4/5] Epoch [20/100] Initial Loss: 0.1386, Training Loss: 0.0046, Initial Validation Loss: 0.1334, Validation Loss: 0.0301,V Acc: 0.8545, Top 70th Acc: 0.9870, Bottom 30th Acc: 0.5455
Fold [4/5] Epoch [30/100] Initial Loss: 0.1386, Training Loss: 0.0036, Initial Validation Loss: 0.1334, Validation Loss: 0.0295,V Acc: 0.8545, Top 70th Acc: 0.9870, Bottom 30th Acc: 0.5455
Fold [4/5] Epoch [40/100] Initial Loss: 0.1386, Training Loss: 0.0034, Initial Validation Loss: 0.1334, Validation Loss: 0.0292,V Acc: 0.8545, Top 70th Acc: 0.9870, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 44  Rolling back to Epoch (base 0): 39  Top Validation Acc: 0.987012987012987
56 3 [array([0.22557545, 0.04576465, 0.07940276, 0.30463615, 0.344621  ],
      dtype=float32)]
Fold [5/5] Epoch [0/100] Initial Loss: 0.1392, Training Loss: 0.1392, Initial Validation Loss: 0.1307, Validation Loss: 0.1307,V Acc: 0.2593, Top 70th Acc: 0.3553, Bottom 30th Acc: 0.0312
Fold [5/5] Epoch [10/100] Initial Loss: 0.1392, Training Loss: 0.0153, Initial Validation Loss: 0.1307, Validation Loss: 0.0339,V Acc: 0.8426, Top 70th Acc: 0.9211, Bottom 30th Acc: 0.6562
Fold [5/5] Epoch [20/100] Initial Loss: 0.1392, Training Loss: 0.0053, Initial Validation Loss: 0.1307, Validation Loss: 0.0301,V Acc: 0.8426, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.6250
Fold [5/5] Epoch [30/100] Initial Loss: 0.1392, Training Loss: 0.0043, Initial Validation Loss: 0.1307, Validation Loss: 0.0290,V Acc: 0.8519, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.6562
Stopping early at Epoch (base 0): 31  Rolling back to Epoch (base 0): 26  Top Validation Acc: 0.9342105263157895
Running train_nn.py with seed 57
CUDA:False
Training samples count:  550
Training on 163 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1393, Training Loss: 0.1393, Initial Validation Loss: 0.1324, Validation Loss: 0.1324,V Acc: 0.2793, Top 70th Acc: 0.3333, Bottom 30th Acc: 0.1515
Fold [1/5] Epoch [10/100] Initial Loss: 0.1393, Training Loss: 0.0156, Initial Validation Loss: 0.1324, Validation Loss: 0.0361,V Acc: 0.7928, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.4545
Fold [1/5] Epoch [20/100] Initial Loss: 0.1393, Training Loss: 0.0046, Initial Validation Loss: 0.1324, Validation Loss: 0.0328,V Acc: 0.8018, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.4242
Fold [1/5] Epoch [30/100] Initial Loss: 0.1393, Training Loss: 0.0039, Initial Validation Loss: 0.1324, Validation Loss: 0.0315,V Acc: 0.8108, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.4848
Stopping early at Epoch (base 0): 32  Rolling back to Epoch (base 0): 27  Top Validation Acc: 0.9487179487179487
57 0 [array([0.17680661, 0.07717393, 0.0537572 , 0.22427107, 0.46799123],
      dtype=float32)]
Fold [2/5] Epoch [0/100] Initial Loss: 0.1374, Training Loss: 0.1374, Initial Validation Loss: 0.1368, Validation Loss: 0.1368,V Acc: 0.3694, Top 70th Acc: 0.4744, Bottom 30th Acc: 0.1212
Fold [2/5] Epoch [10/100] Initial Loss: 0.1374, Training Loss: 0.0122, Initial Validation Loss: 0.1368, Validation Loss: 0.0285,V Acc: 0.8649, Top 70th Acc: 0.9872, Bottom 30th Acc: 0.5758
Fold [2/5] Epoch [20/100] Initial Loss: 0.1374, Training Loss: 0.0046, Initial Validation Loss: 0.1368, Validation Loss: 0.0255,V Acc: 0.9099, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.7576
Fold [2/5] Epoch [30/100] Initial Loss: 0.1374, Training Loss: 0.0037, Initial Validation Loss: 0.1368, Validation Loss: 0.0256,V Acc: 0.9099, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.7576
Stopping early at Epoch (base 0): 31  Rolling back to Epoch (base 0): 26  Top Validation Acc: 0.9743589743589743
Fold [3/5] Epoch [0/100] Initial Loss: 0.1391, Training Loss: 0.1391, Initial Validation Loss: 0.1345, Validation Loss: 0.1345,V Acc: 0.2909, Top 70th Acc: 0.3636, Bottom 30th Acc: 0.1212
Fold [3/5] Epoch [10/100] Initial Loss: 0.1391, Training Loss: 0.0191, Initial Validation Loss: 0.1345, Validation Loss: 0.0420,V Acc: 0.7727, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.4242
Stopping early at Epoch (base 0): 16  Rolling back to Epoch (base 0): 11  Top Validation Acc: 0.935064935064935
Fold [4/5] Epoch [0/100] Initial Loss: 0.1363, Training Loss: 0.1363, Initial Validation Loss: 0.1325, Validation Loss: 0.1325,V Acc: 0.4000, Top 70th Acc: 0.4545, Bottom 30th Acc: 0.2727
Fold [4/5] Epoch [10/100] Initial Loss: 0.1363, Training Loss: 0.0228, Initial Validation Loss: 0.1325, Validation Loss: 0.0434,V Acc: 0.8182, Top 70th Acc: 0.8831, Bottom 30th Acc: 0.6667
Fold [4/5] Epoch [20/100] Initial Loss: 0.1363, Training Loss: 0.0066, Initial Validation Loss: 0.1325, Validation Loss: 0.0361,V Acc: 0.8364, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.5758
Fold [4/5] Epoch [30/100] Initial Loss: 0.1363, Training Loss: 0.0047, Initial Validation Loss: 0.1325, Validation Loss: 0.0327,V Acc: 0.8273, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.5152
Fold [4/5] Epoch [40/100] Initial Loss: 0.1363, Training Loss: 0.0041, Initial Validation Loss: 0.1325, Validation Loss: 0.0310,V Acc: 0.8545, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 46  Rolling back to Epoch (base 0): 41  Top Validation Acc: 0.961038961038961
Fold [5/5] Epoch [0/100] Initial Loss: 0.1400, Training Loss: 0.1400, Initial Validation Loss: 0.1291, Validation Loss: 0.1291,V Acc: 0.3981, Top 70th Acc: 0.4342, Bottom 30th Acc: 0.3125
Fold [5/5] Epoch [10/100] Initial Loss: 0.1400, Training Loss: 0.0188, Initial Validation Loss: 0.1291, Validation Loss: 0.0392,V Acc: 0.8056, Top 70th Acc: 0.9079, Bottom 30th Acc: 0.5625
Fold [5/5] Epoch [20/100] Initial Loss: 0.1400, Training Loss: 0.0048, Initial Validation Loss: 0.1291, Validation Loss: 0.0338,V Acc: 0.8333, Top 70th Acc: 0.9211, Bottom 30th Acc: 0.6250
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.9210526315789473
Running train_nn.py with seed 58
CUDA:False
Training samples count:  550
Training on 163 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1410, Training Loss: 0.1410, Initial Validation Loss: 0.1386, Validation Loss: 0.1386,V Acc: 0.2523, Top 70th Acc: 0.2949, Bottom 30th Acc: 0.1515
Fold [1/5] Epoch [10/100] Initial Loss: 0.1410, Training Loss: 0.0207, Initial Validation Loss: 0.1386, Validation Loss: 0.0410,V Acc: 0.8378, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.5758
Fold [1/5] Epoch [20/100] Initial Loss: 0.1410, Training Loss: 0.0049, Initial Validation Loss: 0.1386, Validation Loss: 0.0349,V Acc: 0.8198, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.5152
Fold [1/5] Epoch [30/100] Initial Loss: 0.1410, Training Loss: 0.0037, Initial Validation Loss: 0.1386, Validation Loss: 0.0326,V Acc: 0.8468, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.5455
Fold [1/5] Epoch [40/100] Initial Loss: 0.1410, Training Loss: 0.0034, Initial Validation Loss: 0.1386, Validation Loss: 0.0321,V Acc: 0.8468, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.5455
Fold [1/5] Epoch [50/100] Initial Loss: 0.1410, Training Loss: 0.0033, Initial Validation Loss: 0.1386, Validation Loss: 0.0313,V Acc: 0.8378, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.5455
Fold [1/5] Epoch [60/100] Initial Loss: 0.1410, Training Loss: 0.0032, Initial Validation Loss: 0.1386, Validation Loss: 0.0309,V Acc: 0.8468, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.5758
Fold [1/5] Epoch [70/100] Initial Loss: 0.1410, Training Loss: 0.0032, Initial Validation Loss: 0.1386, Validation Loss: 0.0306,V Acc: 0.8378, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.5152
Stopping early at Epoch (base 0): 72  Rolling back to Epoch (base 0): 67  Top Validation Acc: 0.9743589743589743
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.7564102564102564
Fold [3/5] Epoch [0/100] Initial Loss: 0.1379, Training Loss: 0.1379, Initial Validation Loss: 0.1279, Validation Loss: 0.1279,V Acc: 0.3727, Top 70th Acc: 0.4935, Bottom 30th Acc: 0.0909
Fold [3/5] Epoch [10/100] Initial Loss: 0.1379, Training Loss: 0.0818, Initial Validation Loss: 0.1279, Validation Loss: 0.0772,V Acc: 0.6273, Top 70th Acc: 0.7273, Bottom 30th Acc: 0.3939
Fold [3/5] Epoch [20/100] Initial Loss: 0.1379, Training Loss: 0.0794, Initial Validation Loss: 0.1279, Validation Loss: 0.0761,V Acc: 0.6364, Top 70th Acc: 0.7273, Bottom 30th Acc: 0.4242
Stopping early at Epoch (base 0): 29  Rolling back to Epoch (base 0): 24  Top Validation Acc: 0.7532467532467533
Fold [4/5] Epoch [0/100] Initial Loss: 0.1279, Training Loss: 0.1279, Initial Validation Loss: 0.1167, Validation Loss: 0.1167,V Acc: 0.4455, Top 70th Acc: 0.4805, Bottom 30th Acc: 0.3636
Fold [4/5] Epoch [10/100] Initial Loss: 0.1279, Training Loss: 0.0789, Initial Validation Loss: 0.1167, Validation Loss: 0.0825,V Acc: 0.5909, Top 70th Acc: 0.7143, Bottom 30th Acc: 0.3030
Fold [4/5] Epoch [20/100] Initial Loss: 0.1279, Training Loss: 0.0775, Initial Validation Loss: 0.1167, Validation Loss: 0.0819,V Acc: 0.5818, Top 70th Acc: 0.7013, Bottom 30th Acc: 0.3030
Fold [4/5] Epoch [30/100] Initial Loss: 0.1279, Training Loss: 0.0768, Initial Validation Loss: 0.1167, Validation Loss: 0.0814,V Acc: 0.5818, Top 70th Acc: 0.7273, Bottom 30th Acc: 0.2424
Fold [4/5] Epoch [40/100] Initial Loss: 0.1279, Training Loss: 0.0765, Initial Validation Loss: 0.1167, Validation Loss: 0.0812,V Acc: 0.5727, Top 70th Acc: 0.7143, Bottom 30th Acc: 0.2424
Stopping early at Epoch (base 0): 43  Rolling back to Epoch (base 0): 38  Top Validation Acc: 0.7142857142857143
Fold [5/5] Epoch [0/100] Initial Loss: 0.1363, Training Loss: 0.1363, Initial Validation Loss: 0.1232, Validation Loss: 0.1232,V Acc: 0.2963, Top 70th Acc: 0.3421, Bottom 30th Acc: 0.1875
Fold [5/5] Epoch [10/100] Initial Loss: 0.1363, Training Loss: 0.0799, Initial Validation Loss: 0.1232, Validation Loss: 0.0809,V Acc: 0.6296, Top 70th Acc: 0.7368, Bottom 30th Acc: 0.3750
Stopping early at Epoch (base 0): 18  Rolling back to Epoch (base 0): 13  Top Validation Acc: 0.7368421052631579
Running train_nn.py with seed 70
CUDA:False
Training samples count:  550
Training on 2 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1353, Training Loss: 0.1353, Initial Validation Loss: 0.1314, Validation Loss: 0.1314,V Acc: 0.3333, Top 70th Acc: 0.3590, Bottom 30th Acc: 0.2727
Fold [1/5] Epoch [10/100] Initial Loss: 0.1353, Training Loss: 0.0786, Initial Validation Loss: 0.1314, Validation Loss: 0.0893,V Acc: 0.5676, Top 70th Acc: 0.6667, Bottom 30th Acc: 0.3333
Fold [1/5] Epoch [20/100] Initial Loss: 0.1353, Training Loss: 0.0766, Initial Validation Loss: 0.1314, Validation Loss: 0.0882,V Acc: 0.5586, Top 70th Acc: 0.6667, Bottom 30th Acc: 0.3030
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.6923076923076923
Fold [2/5] Epoch [0/100] Initial Loss: 0.1373, Training Loss: 0.1373, Initial Validation Loss: 0.1294, Validation Loss: 0.1294,V Acc: 0.5135, Top 70th Acc: 0.5641, Bottom 30th Acc: 0.3939
Fold [2/5] Epoch [10/100] Initial Loss: 0.1373, Training Loss: 0.0803, Initial Validation Loss: 0.1294, Validation Loss: 0.0830,V Acc: 0.6396, Top 70th Acc: 0.7436, Bottom 30th Acc: 0.3939
Fold [2/5] Epoch [20/100] Initial Loss: 0.1373, Training Loss: 0.0777, Initial Validation Loss: 0.1294, Validation Loss: 0.0817,V Acc: 0.6396, Top 70th Acc: 0.7436, Bottom 30th Acc: 0.3939
Stopping early at Epoch (base 0): 27  Rolling back to Epoch (base 0): 22  Top Validation Acc: 0.7435897435897436
70 1 [array([0.15296738, 0.3160016 , 0.13493629, 0.24579844, 0.15029635],
      dtype=float32)]
Fold [3/5] Epoch [0/100] Initial Loss: 0.1351, Training Loss: 0.1351, Initial Validation Loss: 0.1262, Validation Loss: 0.1262,V Acc: 0.4818, Top 70th Acc: 0.5714, Bottom 30th Acc: 0.2727
Fold [3/5] Epoch [10/100] Initial Loss: 0.1351, Training Loss: 0.0801, Initial Validation Loss: 0.1262, Validation Loss: 0.0791,V Acc: 0.6273, Top 70th Acc: 0.7662, Bottom 30th Acc: 0.3030
Fold [3/5] Epoch [20/100] Initial Loss: 0.1351, Training Loss: 0.0781, Initial Validation Loss: 0.1262, Validation Loss: 0.0780,V Acc: 0.6364, Top 70th Acc: 0.7532, Bottom 30th Acc: 0.3636
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.7532467532467533
Fold [4/5] Epoch [0/100] Initial Loss: 0.1359, Training Loss: 0.1359, Initial Validation Loss: 0.1282, Validation Loss: 0.1282,V Acc: 0.4091, Top 70th Acc: 0.5714, Bottom 30th Acc: 0.0303
Fold [4/5] Epoch [10/100] Initial Loss: 0.1359, Training Loss: 0.0809, Initial Validation Loss: 0.1282, Validation Loss: 0.0824,V Acc: 0.6545, Top 70th Acc: 0.7273, Bottom 30th Acc: 0.4848
Fold [4/5] Epoch [20/100] Initial Loss: 0.1359, Training Loss: 0.0788, Initial Validation Loss: 0.1282, Validation Loss: 0.0813,V Acc: 0.6182, Top 70th Acc: 0.7403, Bottom 30th Acc: 0.3333
Fold [4/5] Epoch [30/100] Initial Loss: 0.1359, Training Loss: 0.0784, Initial Validation Loss: 0.1282, Validation Loss: 0.0798,V Acc: 0.6545, Top 70th Acc: 0.7662, Bottom 30th Acc: 0.3939
Stopping early at Epoch (base 0): 31  Rolling back to Epoch (base 0): 26  Top Validation Acc: 0.7662337662337663
Fold [5/5] Epoch [0/100] Initial Loss: 0.1402, Training Loss: 0.1402, Initial Validation Loss: 0.1226, Validation Loss: 0.1226,V Acc: 0.3981, Top 70th Acc: 0.3947, Bottom 30th Acc: 0.4062
Fold [5/5] Epoch [10/100] Initial Loss: 0.1402, Training Loss: 0.0834, Initial Validation Loss: 0.1226, Validation Loss: 0.0680,V Acc: 0.6667, Top 70th Acc: 0.7763, Bottom 30th Acc: 0.4062
Fold [5/5] Epoch [20/100] Initial Loss: 0.1402, Training Loss: 0.0815, Initial Validation Loss: 0.1226, Validation Loss: 0.0649,V Acc: 0.6667, Top 70th Acc: 0.7368, Bottom 30th Acc: 0.5000
Fold [5/5] Epoch [30/100] Initial Loss: 0.1402, Training Loss: 0.0807, Initial Validation Loss: 0.1226, Validation Loss: 0.0634,V Acc: 0.6759, Top 70th Acc: 0.7632, Bottom 30th Acc: 0.4688
Stopping early at Epoch (base 0): 35  Rolling back to Epoch (base 0): 30  Top Validation Acc: 0.7894736842105263
Running train_nn.py with seed 71
CUDA:False
Training samples count:  550
Training on 2 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1313, Training Loss: 0.1313, Initial Validation Loss: 0.1263, Validation Loss: 0.1263,V Acc: 0.4595, Top 70th Acc: 0.5385, Bottom 30th Acc: 0.2727
Fold [1/5] Epoch [10/100] Initial Loss: 0.1313, Training Loss: 0.0816, Initial Validation Loss: 0.1263, Validation Loss: 0.0793,V Acc: 0.6667, Top 70th Acc: 0.7564, Bottom 30th Acc: 0.4545
Fold [1/5] Epoch [20/100] Initial Loss: 0.1313, Training Loss: 0.0799, Initial Validation Loss: 0.1263, Validation Loss: 0.0775,V Acc: 0.6757, Top 70th Acc: 0.8077, Bottom 30th Acc: 0.3636
Stopping early at Epoch (base 0): 29  Rolling back to Epoch (base 0): 24  Top Validation Acc: 0.7435897435897436
Fold [2/5] Epoch [0/100] Initial Loss: 0.1359, Training Loss: 0.1359, Initial Validation Loss: 0.1239, Validation Loss: 0.1239,V Acc: 0.3694, Top 70th Acc: 0.4615, Bottom 30th Acc: 0.1515
Fold [2/5] Epoch [10/100] Initial Loss: 0.1359, Training Loss: 0.0809, Initial Validation Loss: 0.1239, Validation Loss: 0.0809,V Acc: 0.5766, Top 70th Acc: 0.7051, Bottom 30th Acc: 0.2727
Fold [2/5] Epoch [20/100] Initial Loss: 0.1359, Training Loss: 0.0778, Initial Validation Loss: 0.1239, Validation Loss: 0.0806,V Acc: 0.5766, Top 70th Acc: 0.6923, Bottom 30th Acc: 0.3030
Stopping early at Epoch (base 0): 27  Rolling back to Epoch (base 0): 22  Top Validation Acc: 0.717948717948718
Fold [3/5] Epoch [0/100] Initial Loss: 0.1402, Training Loss: 0.1402, Initial Validation Loss: 0.1293, Validation Loss: 0.1293,V Acc: 0.2727, Top 70th Acc: 0.3636, Bottom 30th Acc: 0.0606
Fold [3/5] Epoch [10/100] Initial Loss: 0.1402, Training Loss: 0.0806, Initial Validation Loss: 0.1293, Validation Loss: 0.0816,V Acc: 0.5909, Top 70th Acc: 0.7403, Bottom 30th Acc: 0.2424
Fold [3/5] Epoch [20/100] Initial Loss: 0.1402, Training Loss: 0.0782, Initial Validation Loss: 0.1293, Validation Loss: 0.0794,V Acc: 0.6000, Top 70th Acc: 0.7143, Bottom 30th Acc: 0.3333
Fold [1/5] Epoch [10/100] Initial Loss: 0.1421, Training Loss: 0.0401, Initial Validation Loss: 0.1358, Validation Loss: 0.0421,V Acc: 0.7928, Top 70th Acc: 0.8718, Bottom 30th Acc: 0.6061
Fold [1/5] Epoch [20/100] Initial Loss: 0.1421, Training Loss: 0.0208, Initial Validation Loss: 0.1358, Validation Loss: 0.0295,V Acc: 0.8108, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.4545
Fold [1/5] Epoch [30/100] Initial Loss: 0.1421, Training Loss: 0.0179, Initial Validation Loss: 0.1358, Validation Loss: 0.0287,V Acc: 0.8468, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 33  Rolling back to Epoch (base 0): 28  Top Validation Acc: 0.9615384615384616
Fold [2/5] Epoch [0/100] Initial Loss: 0.1380, Training Loss: 0.1380, Initial Validation Loss: 0.1370, Validation Loss: 0.1370,V Acc: 0.3153, Top 70th Acc: 0.3462, Bottom 30th Acc: 0.2424
Fold [2/5] Epoch [10/100] Initial Loss: 0.1380, Training Loss: 0.0320, Initial Validation Loss: 0.1370, Validation Loss: 0.0328,V Acc: 0.8468, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.5455
Fold [2/5] Epoch [20/100] Initial Loss: 0.1380, Training Loss: 0.0196, Initial Validation Loss: 0.1370, Validation Loss: 0.0263,V Acc: 0.8829, Top 70th Acc: 0.9872, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.9871794871794872
Fold [3/5] Epoch [0/100] Initial Loss: 0.1389, Training Loss: 0.1389, Initial Validation Loss: 0.1331, Validation Loss: 0.1331,V Acc: 0.3182, Top 70th Acc: 0.3896, Bottom 30th Acc: 0.1515
Fold [3/5] Epoch [10/100] Initial Loss: 0.1389, Training Loss: 0.0349, Initial Validation Loss: 0.1331, Validation Loss: 0.0437,V Acc: 0.8364, Top 70th Acc: 0.8701, Bottom 30th Acc: 0.7576
Fold [3/5] Epoch [20/100] Initial Loss: 0.1389, Training Loss: 0.0186, Initial Validation Loss: 0.1331, Validation Loss: 0.0399,V Acc: 0.8000, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.5152
Stopping early at Epoch (base 0): 22  Rolling back to Epoch (base 0): 17  Top Validation Acc: 0.922077922077922
74 2 [array([0.7078415 , 0.04358829, 0.07371774, 0.10264695, 0.07220549],
      dtype=float32)]
Fold [4/5] Epoch [0/100] Initial Loss: 0.1409, Training Loss: 0.1409, Initial Validation Loss: 0.1370, Validation Loss: 0.1370,V Acc: 0.3000, Top 70th Acc: 0.2468, Bottom 30th Acc: 0.4242
Fold [4/5] Epoch [10/100] Initial Loss: 0.1409, Training Loss: 0.0466, Initial Validation Loss: 0.1370, Validation Loss: 0.0513,V Acc: 0.7545, Top 70th Acc: 0.8961, Bottom 30th Acc: 0.4242
Fold [4/5] Epoch [20/100] Initial Loss: 0.1409, Training Loss: 0.0205, Initial Validation Loss: 0.1370, Validation Loss: 0.0327,V Acc: 0.8455, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6061
Fold [4/5] Epoch [30/100] Initial Loss: 0.1409, Training Loss: 0.0172, Initial Validation Loss: 0.1370, Validation Loss: 0.0311,V Acc: 0.8273, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 34  Rolling back to Epoch (base 0): 29  Top Validation Acc: 0.948051948051948
Fold [5/5] Epoch [0/100] Initial Loss: 0.1406, Training Loss: 0.1406, Initial Validation Loss: 0.1294, Validation Loss: 0.1294,V Acc: 0.3056, Top 70th Acc: 0.3816, Bottom 30th Acc: 0.1250
Fold [5/5] Epoch [10/100] Initial Loss: 0.1406, Training Loss: 0.0299, Initial Validation Loss: 0.1294, Validation Loss: 0.0435,V Acc: 0.7593, Top 70th Acc: 0.8553, Bottom 30th Acc: 0.5312
Fold [5/5] Epoch [20/100] Initial Loss: 0.1406, Training Loss: 0.0193, Initial Validation Loss: 0.1294, Validation Loss: 0.0402,V Acc: 0.7870, Top 70th Acc: 0.8421, Bottom 30th Acc: 0.6562
Fold [5/5] Epoch [30/100] Initial Loss: 0.1406, Training Loss: 0.0167, Initial Validation Loss: 0.1294, Validation Loss: 0.0361,V Acc: 0.8056, Top 70th Acc: 0.8947, Bottom 30th Acc: 0.5938
Fold [5/5] Epoch [40/100] Initial Loss: 0.1406, Training Loss: 0.0155, Initial Validation Loss: 0.1294, Validation Loss: 0.0356,V Acc: 0.8241, Top 70th Acc: 0.8816, Bottom 30th Acc: 0.6875
Stopping early at Epoch (base 0): 48  Rolling back to Epoch (base 0): 43  Top Validation Acc: 0.881578947368421
Running train_nn.py with seed 75
CUDA:False
Training samples count:  550
Training on 30 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1395, Training Loss: 0.1395, Initial Validation Loss: 0.1354, Validation Loss: 0.1354,V Acc: 0.3333, Top 70th Acc: 0.3462, Bottom 30th Acc: 0.3030
Fold [1/5] Epoch [10/100] Initial Loss: 0.1395, Training Loss: 0.0327, Initial Validation Loss: 0.1354, Validation Loss: 0.0473,V Acc: 0.7838, Top 70th Acc: 0.8718, Bottom 30th Acc: 0.5758
Fold [1/5] Epoch [20/100] Initial Loss: 0.1395, Training Loss: 0.0165, Initial Validation Loss: 0.1354, Validation Loss: 0.0374,V Acc: 0.8288, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.9230769230769231
Fold [2/5] Epoch [0/100] Initial Loss: 0.1350, Training Loss: 0.1350, Initial Validation Loss: 0.1320, Validation Loss: 0.1320,V Acc: 0.3874, Top 70th Acc: 0.4744, Bottom 30th Acc: 0.1818
Fold [2/5] Epoch [10/100] Initial Loss: 0.1350, Training Loss: 0.0337, Initial Validation Loss: 0.1320, Validation Loss: 0.0340,V Acc: 0.8829, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.6970
Fold [2/5] Epoch [20/100] Initial Loss: 0.1350, Training Loss: 0.0212, Initial Validation Loss: 0.1320, Validation Loss: 0.0267,V Acc: 0.9009, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.7576
Fold [2/5] Epoch [30/100] Initial Loss: 0.1350, Training Loss: 0.0176, Initial Validation Loss: 0.1320, Validation Loss: 0.0257,V Acc: 0.8829, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.6970
Fold [2/5] Epoch [40/100] Initial Loss: 0.1350, Training Loss: 0.0158, Initial Validation Loss: 0.1320, Validation Loss: 0.0265,V Acc: 0.8739, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 48  Rolling back to Epoch (base 0): 43  Top Validation Acc: 0.9615384615384616
Fold [3/5] Epoch [0/100] Initial Loss: 0.1367, Training Loss: 0.1367, Initial Validation Loss: 0.1284, Validation Loss: 0.1284,V Acc: 0.2909, Top 70th Acc: 0.3636, Bottom 30th Acc: 0.1212
Fold [3/5] Epoch [10/100] Initial Loss: 0.1367, Training Loss: 0.0293, Initial Validation Loss: 0.1284, Validation Loss: 0.0307,V Acc: 0.8455, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.5455
Fold [3/5] Epoch [20/100] Initial Loss: 0.1367, Training Loss: 0.0189, Initial Validation Loss: 0.1284, Validation Loss: 0.0241,V Acc: 0.8636, Top 70th Acc: 0.9870, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.987012987012987
Fold [4/5] Epoch [0/100] Initial Loss: 0.1400, Training Loss: 0.1400, Initial Validation Loss: 0.1314, Validation Loss: 0.1314,V Acc: 0.2545, Top 70th Acc: 0.3377, Bottom 30th Acc: 0.0606
Fold [4/5] Epoch [10/100] Initial Loss: 0.1400, Training Loss: 0.0340, Initial Validation Loss: 0.1314, Validation Loss: 0.0388,V Acc: 0.7909, Top 70th Acc: 0.8831, Bottom 30th Acc: 0.5758
Fold [4/5] Epoch [20/100] Initial Loss: 0.1400, Training Loss: 0.0185, Initial Validation Loss: 0.1314, Validation Loss: 0.0336,V Acc: 0.7909, Top 70th Acc: 0.8831, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.8961038961038961
Fold [5/5] Epoch [0/100] Initial Loss: 0.1392, Training Loss: 0.1392, Initial Validation Loss: 0.1363, Validation Loss: 0.1363,V Acc: 0.3333, Top 70th Acc: 0.3684, Bottom 30th Acc: 0.2500
Fold [5/5] Epoch [10/100] Initial Loss: 0.1392, Training Loss: 0.0321, Initial Validation Loss: 0.1363, Validation Loss: 0.0317,V Acc: 0.9167, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.8125
Fold [5/5] Epoch [20/100] Initial Loss: 0.1392, Training Loss: 0.0190, Initial Validation Loss: 0.1363, Validation Loss: 0.0244,V Acc: 0.9259, Top 70th Acc: 0.9868, Bottom 30th Acc: 0.7812
Fold [5/5] Epoch [30/100] Initial Loss: 0.1392, Training Loss: 0.0171, Initial Validation Loss: 0.1363, Validation Loss: 0.0255,V Acc: 0.9167, Top 70th Acc: 0.9737, Bottom 30th Acc: 0.7812
Stopping early at Epoch (base 0): 30  Rolling back to Epoch (base 0): 25  Top Validation Acc: 0.9736842105263158
75 4 [array([0.6300915 , 0.12595168, 0.01757499, 0.05566205, 0.17071979],
      dtype=float32)]
Stopping early at Epoch (base 0): 22  Rolling back to Epoch (base 0): 17  Top Validation Acc: 0.9210526315789473
Running train_nn.py with seed 74
CUDA:False
Training samples count:  550
Training on 40 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1388, Training Loss: 0.1388, Initial Validation Loss: 0.1364, Validation Loss: 0.1364,V Acc: 0.2793, Top 70th Acc: 0.2949, Bottom 30th Acc: 0.2424
Fold [1/5] Epoch [10/100] Initial Loss: 0.1388, Training Loss: 0.0385, Initial Validation Loss: 0.1364, Validation Loss: 0.0434,V Acc: 0.7838, Top 70th Acc: 0.8974, Bottom 30th Acc: 0.5152
Fold [1/5] Epoch [20/100] Initial Loss: 0.1388, Training Loss: 0.0161, Initial Validation Loss: 0.1364, Validation Loss: 0.0296,V Acc: 0.8468, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.9615384615384616
Fold [2/5] Epoch [0/100] Initial Loss: 0.1423, Training Loss: 0.1423, Initial Validation Loss: 0.1329, Validation Loss: 0.1329,V Acc: 0.3964, Top 70th Acc: 0.4231, Bottom 30th Acc: 0.3333
Fold [2/5] Epoch [10/100] Initial Loss: 0.1423, Training Loss: 0.0250, Initial Validation Loss: 0.1329, Validation Loss: 0.0284,V Acc: 0.8649, Top 70th Acc: 1.0000, Bottom 30th Acc: 0.5455
Fold [2/5] Epoch [20/100] Initial Loss: 0.1423, Training Loss: 0.0141, Initial Validation Loss: 0.1329, Validation Loss: 0.0251,V Acc: 0.8649, Top 70th Acc: 0.9872, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.9871794871794872
Fold [3/5] Epoch [0/100] Initial Loss: 0.1427, Training Loss: 0.1427, Initial Validation Loss: 0.1360, Validation Loss: 0.1360,V Acc: 0.2727, Top 70th Acc: 0.3506, Bottom 30th Acc: 0.0909
Fold [3/5] Epoch [10/100] Initial Loss: 0.1427, Training Loss: 0.0384, Initial Validation Loss: 0.1360, Validation Loss: 0.0484,V Acc: 0.7909, Top 70th Acc: 0.8701, Bottom 30th Acc: 0.6061
Fold [3/5] Epoch [20/100] Initial Loss: 0.1427, Training Loss: 0.0147, Initial Validation Loss: 0.1360, Validation Loss: 0.0405,V Acc: 0.8000, Top 70th Acc: 0.8961, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.9090909090909091
74 2 [array([0.63579595, 0.03669264, 0.04748198, 0.12072671, 0.15930276],
      dtype=float32)]
Fold [4/5] Epoch [0/100] Initial Loss: 0.1360, Training Loss: 0.1360, Initial Validation Loss: 0.1319, Validation Loss: 0.1319,V Acc: 0.4000, Top 70th Acc: 0.5065, Bottom 30th Acc: 0.1515
Fold [4/5] Epoch [10/100] Initial Loss: 0.1360, Training Loss: 0.0223, Initial Validation Loss: 0.1319, Validation Loss: 0.0333,V Acc: 0.8182, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.4545
Fold [4/5] Epoch [20/100] Initial Loss: 0.1360, Training Loss: 0.0143, Initial Validation Loss: 0.1319, Validation Loss: 0.0312,V Acc: 0.8273, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.5152
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.961038961038961
Fold [5/5] Epoch [0/100] Initial Loss: 0.1392, Training Loss: 0.1392, Initial Validation Loss: 0.1311, Validation Loss: 0.1311,V Acc: 0.2315, Top 70th Acc: 0.2368, Bottom 30th Acc: 0.2188
Fold [5/5] Epoch [10/100] Initial Loss: 0.1392, Training Loss: 0.0295, Initial Validation Loss: 0.1311, Validation Loss: 0.0418,V Acc: 0.8148, Top 70th Acc: 0.8553, Bottom 30th Acc: 0.7188
Fold [5/5] Epoch [20/100] Initial Loss: 0.1392, Training Loss: 0.0148, Initial Validation Loss: 0.1311, Validation Loss: 0.0322,V Acc: 0.8148, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.5312
Fold [5/5] Epoch [30/100] Initial Loss: 0.1392, Training Loss: 0.0127, Initial Validation Loss: 0.1311, Validation Loss: 0.0314,V Acc: 0.8333, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.5938
Stopping early at Epoch (base 0): 31  Rolling back to Epoch (base 0): 26  Top Validation Acc: 0.9210526315789473
Running train_nn.py with seed 75
CUDA:False
Training samples count:  550
Training on 40 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1419, Training Loss: 0.1419, Initial Validation Loss: 0.1362, Validation Loss: 0.1362,V Acc: 0.3243, Top 70th Acc: 0.3718, Bottom 30th Acc: 0.2121
Fold [1/5] Epoch [10/100] Initial Loss: 0.1419, Training Loss: 0.0281, Initial Validation Loss: 0.1362, Validation Loss: 0.0428,V Acc: 0.7658, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.4242
Fold [1/5] Epoch [20/100] Initial Loss: 0.1419, Training Loss: 0.0120, Initial Validation Loss: 0.1362, Validation Loss: 0.0374,V Acc: 0.8198, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.8974358974358975
Fold [2/5] Epoch [0/100] Initial Loss: 0.1372, Training Loss: 0.1372, Initial Validation Loss: 0.1377, Validation Loss: 0.1377,V Acc: 0.3333, Top 70th Acc: 0.3846, Bottom 30th Acc: 0.2121
Fold [2/5] Epoch [10/100] Initial Loss: 0.1372, Training Loss: 0.0369, Initial Validation Loss: 0.1377, Validation Loss: 0.0404,V Acc: 0.8468, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.6061
Fold [2/5] Epoch [20/100] Initial Loss: 0.1372, Training Loss: 0.0191, Initial Validation Loss: 0.1377, Validation Loss: 0.0335,V Acc: 0.8468, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.5758
Fold [2/5] Epoch [30/100] Initial Loss: 0.1372, Training Loss: 0.0130, Initial Validation Loss: 0.1377, Validation Loss: 0.0281,V Acc: 0.8649, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.6061
Fold [2/5] Epoch [40/100] Initial Loss: 0.1372, Training Loss: 0.0112, Initial Validation Loss: 0.1377, Validation Loss: 0.0263,V Acc: 0.9009, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.7273
Stopping early at Epoch (base 0): 47  Rolling back to Epoch (base 0): 42  Top Validation Acc: 0.9743589743589743
Fold [3/5] Epoch [0/100] Initial Loss: 0.1421, Training Loss: 0.1421, Initial Validation Loss: 0.1329, Validation Loss: 0.1329,V Acc: 0.2455, Top 70th Acc: 0.3247, Bottom 30th Acc: 0.0606
Fold [3/5] Epoch [10/100] Initial Loss: 0.1421, Training Loss: 0.0244, Initial Validation Loss: 0.1329, Validation Loss: 0.0244,V Acc: 0.8909, Top 70th Acc: 0.9870, Bottom 30th Acc: 0.6667
Fold [3/5] Epoch [20/100] Initial Loss: 0.1421, Training Loss: 0.0138, Initial Validation Loss: 0.1329, Validation Loss: 0.0206,V Acc: 0.9273, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.8182
Stopping early at Epoch (base 0): 21  Rolling back to Epoch (base 0): 16  Top Validation Acc: 0.987012987012987
Fold [4/5] Epoch [0/100] Initial Loss: 0.1438, Training Loss: 0.1438, Initial Validation Loss: 0.1316, Validation Loss: 0.1316,V Acc: 0.3182, Top 70th Acc: 0.3377, Bottom 30th Acc: 0.2727
Fold [4/5] Epoch [10/100] Initial Loss: 0.1438, Training Loss: 0.0327, Initial Validation Loss: 0.1316, Validation Loss: 0.0371,V Acc: 0.7727, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.4545
Fold [4/5] Epoch [20/100] Initial Loss: 0.1438, Training Loss: 0.0153, Initial Validation Loss: 0.1316, Validation Loss: 0.0299,V Acc: 0.8182, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.5758
Fold [4/5] Epoch [30/100] Initial Loss: 0.1438, Training Loss: 0.0121, Initial Validation Loss: 0.1316, Validation Loss: 0.0287,V Acc: 0.8364, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 38  Rolling back to Epoch (base 0): 33  Top Validation Acc: 0.948051948051948
Fold [5/5] Epoch [0/100] Initial Loss: 0.1393, Training Loss: 0.1393, Initial Validation Loss: 0.1355, Validation Loss: 0.1355,V Acc: 0.2778, Top 70th Acc: 0.3289, Bottom 30th Acc: 0.1562
Fold [5/5] Epoch [10/100] Initial Loss: 0.1393, Training Loss: 0.0240, Initial Validation Loss: 0.1355, Validation Loss: 0.0285,V Acc: 0.8796, Top 70th Acc: 0.9737, Bottom 30th Acc: 0.6562
Fold [5/5] Epoch [20/100] Initial Loss: 0.1393, Training Loss: 0.0143, Initial Validation Loss: 0.1355, Validation Loss: 0.0223,V Acc: 0.9352, Top 70th Acc: 1.0000, Bottom 30th Acc: 0.7812
Stopping early at Epoch (base 0): 29  Rolling back to Epoch (base 0): 24  Top Validation Acc: 1.0
75 4 [array([0.56978667, 0.04792926, 0.11898627, 0.07653151, 0.18676628],
      dtype=float32)]
Running train_nn.py with seed 76
CUDA:False
Training samples count:  550
Training on 40 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1376, Training Loss: 0.1376, Initial Validation Loss: 0.1372, Validation Loss: 0.1372,V Acc: 0.3333, Top 70th Acc: 0.3974, Bottom 30th Acc: 0.1818
Stopping early at Epoch (base 0): 28  Rolling back to Epoch (base 0): 23  Top Validation Acc: 0.9605263157894737
75 4 [array([0.49940965, 0.1463055 , 0.08239485, 0.1621446 , 0.10974536],
      dtype=float32)]
Running train_nn.py with seed 76
CUDA:False
Training samples count:  550
Training on 20 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1382, Training Loss: 0.1382, Initial Validation Loss: 0.1376, Validation Loss: 0.1376,V Acc: 0.4144, Top 70th Acc: 0.4231, Bottom 30th Acc: 0.3939
Fold [1/5] Epoch [10/100] Initial Loss: 0.1382, Training Loss: 0.0323, Initial Validation Loss: 0.1376, Validation Loss: 0.0298,V Acc: 0.8739, Top 70th Acc: 0.9872, Bottom 30th Acc: 0.6061
Fold [1/5] Epoch [20/100] Initial Loss: 0.1382, Training Loss: 0.0248, Initial Validation Loss: 0.1376, Validation Loss: 0.0264,V Acc: 0.8649, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 21  Rolling back to Epoch (base 0): 16  Top Validation Acc: 0.9743589743589743
Fold [2/5] Epoch [0/100] Initial Loss: 0.1401, Training Loss: 0.1401, Initial Validation Loss: 0.1329, Validation Loss: 0.1329,V Acc: 0.3694, Top 70th Acc: 0.4103, Bottom 30th Acc: 0.2727
Fold [2/5] Epoch [10/100] Initial Loss: 0.1401, Training Loss: 0.0392, Initial Validation Loss: 0.1329, Validation Loss: 0.0406,V Acc: 0.8108, Top 70th Acc: 0.8846, Bottom 30th Acc: 0.6364
Fold [2/5] Epoch [20/100] Initial Loss: 0.1401, Training Loss: 0.0237, Initial Validation Loss: 0.1329, Validation Loss: 0.0321,V Acc: 0.8378, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.9230769230769231
Fold [3/5] Epoch [0/100] Initial Loss: 0.1414, Training Loss: 0.1414, Initial Validation Loss: 0.1361, Validation Loss: 0.1361,V Acc: 0.2364, Top 70th Acc: 0.3247, Bottom 30th Acc: 0.0303
Fold [3/5] Epoch [10/100] Initial Loss: 0.1414, Training Loss: 0.0284, Initial Validation Loss: 0.1361, Validation Loss: 0.0347,V Acc: 0.8091, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.4848
Fold [3/5] Epoch [20/100] Initial Loss: 0.1414, Training Loss: 0.0216, Initial Validation Loss: 0.1361, Validation Loss: 0.0318,V Acc: 0.8273, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 28  Rolling back to Epoch (base 0): 23  Top Validation Acc: 0.961038961038961
Fold [4/5] Epoch [0/100] Initial Loss: 0.1371, Training Loss: 0.1371, Initial Validation Loss: 0.1344, Validation Loss: 0.1344,V Acc: 0.2545, Top 70th Acc: 0.3506, Bottom 30th Acc: 0.0303
Fold [4/5] Epoch [10/100] Initial Loss: 0.1371, Training Loss: 0.0403, Initial Validation Loss: 0.1344, Validation Loss: 0.0429,V Acc: 0.8091, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.5455
Fold [4/5] Epoch [20/100] Initial Loss: 0.1371, Training Loss: 0.0307, Initial Validation Loss: 0.1344, Validation Loss: 0.0391,V Acc: 0.8182, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.5455
Fold [4/5] Epoch [30/100] Initial Loss: 0.1371, Training Loss: 0.0248, Initial Validation Loss: 0.1344, Validation Loss: 0.0345,V Acc: 0.8455, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6061
Fold [4/5] Epoch [40/100] Initial Loss: 0.1371, Training Loss: 0.0222, Initial Validation Loss: 0.1344, Validation Loss: 0.0309,V Acc: 0.8455, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6061
Fold [4/5] Epoch [50/100] Initial Loss: 0.1371, Training Loss: 0.0209, Initial Validation Loss: 0.1344, Validation Loss: 0.0303,V Acc: 0.8545, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 52  Rolling back to Epoch (base 0): 47  Top Validation Acc: 0.961038961038961
76 3 [array([0.33958322, 0.10425401, 0.2542985 , 0.22655396, 0.07531032],
      dtype=float32)]
Fold [5/5] Epoch [0/100] Initial Loss: 0.1414, Training Loss: 0.1414, Initial Validation Loss: 0.1299, Validation Loss: 0.1299,V Acc: 0.2593, Top 70th Acc: 0.3158, Bottom 30th Acc: 0.1250
Fold [5/5] Epoch [10/100] Initial Loss: 0.1414, Training Loss: 0.0447, Initial Validation Loss: 0.1299, Validation Loss: 0.0600,V Acc: 0.7222, Top 70th Acc: 0.7895, Bottom 30th Acc: 0.5625
Fold [5/5] Epoch [20/100] Initial Loss: 0.1414, Training Loss: 0.0236, Initial Validation Loss: 0.1299, Validation Loss: 0.0415,V Acc: 0.8241, Top 70th Acc: 0.8684, Bottom 30th Acc: 0.7188
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.8552631578947368
Running train_nn.py with seed 77
CUDA:False
Training samples count:  550
Training on 20 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1398, Training Loss: 0.1398, Initial Validation Loss: 0.1375, Validation Loss: 0.1375,V Acc: 0.2613, Top 70th Acc: 0.3333, Bottom 30th Acc: 0.0909
Fold [1/5] Epoch [10/100] Initial Loss: 0.1398, Training Loss: 0.0385, Initial Validation Loss: 0.1375, Validation Loss: 0.0396,V Acc: 0.8198, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.5455
Fold [1/5] Epoch [20/100] Initial Loss: 0.1398, Training Loss: 0.0255, Initial Validation Loss: 0.1375, Validation Loss: 0.0310,V Acc: 0.8559, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.6364
Fold [1/5] Epoch [30/100] Initial Loss: 0.1398, Training Loss: 0.0230, Initial Validation Loss: 0.1375, Validation Loss: 0.0320,V Acc: 0.8559, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 32  Rolling back to Epoch (base 0): 27  Top Validation Acc: 0.9230769230769231
Fold [2/5] Epoch [0/100] Initial Loss: 0.1396, Training Loss: 0.1396, Initial Validation Loss: 0.1290, Validation Loss: 0.1290,V Acc: 0.3333, Top 70th Acc: 0.3718, Bottom 30th Acc: 0.2424
Fold [2/5] Epoch [10/100] Initial Loss: 0.1396, Training Loss: 0.0369, Initial Validation Loss: 0.1290, Validation Loss: 0.0448,V Acc: 0.7748, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.4545
Fold [2/5] Epoch [20/100] Initial Loss: 0.1396, Training Loss: 0.0222, Initial Validation Loss: 0.1290, Validation Loss: 0.0400,V Acc: 0.7838, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.4848
Fold [2/5] Epoch [30/100] Initial Loss: 0.1396, Training Loss: 0.0201, Initial Validation Loss: 0.1290, Validation Loss: 0.0399,V Acc: 0.7748, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.4242
Stopping early at Epoch (base 0): 30  Rolling back to Epoch (base 0): 25  Top Validation Acc: 0.9230769230769231
Fold [3/5] Epoch [0/100] Initial Loss: 0.1389, Training Loss: 0.1389, Initial Validation Loss: 0.1294, Validation Loss: 0.1294,V Acc: 0.3364, Top 70th Acc: 0.4026, Bottom 30th Acc: 0.1818
Fold [3/5] Epoch [10/100] Initial Loss: 0.1389, Training Loss: 0.0327, Initial Validation Loss: 0.1294, Validation Loss: 0.0363,V Acc: 0.8182, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.5758
Fold [3/5] Epoch [20/100] Initial Loss: 0.1389, Training Loss: 0.0233, Initial Validation Loss: 0.1294, Validation Loss: 0.0327,V Acc: 0.8364, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.9090909090909091
Fold [4/5] Epoch [0/100] Initial Loss: 0.1379, Training Loss: 0.1379, Initial Validation Loss: 0.1338, Validation Loss: 0.1338,V Acc: 0.3909, Top 70th Acc: 0.5325, Bottom 30th Acc: 0.0606
Fold [4/5] Epoch [10/100] Initial Loss: 0.1379, Training Loss: 0.0335, Initial Validation Loss: 0.1338, Validation Loss: 0.0304,V Acc: 0.9091, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.7879
Fold [4/5] Epoch [20/100] Initial Loss: 0.1379, Training Loss: 0.0251, Initial Validation Loss: 0.1338, Validation Loss: 0.0259,V Acc: 0.9182, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.7879
Stopping early at Epoch (base 0): 28  Rolling back to Epoch (base 0): 23  Top Validation Acc: 0.974025974025974
Fold [5/5] Epoch [0/100] Initial Loss: 0.1355, Training Loss: 0.1355, Initial Validation Loss: 0.1289, Validation Loss: 0.1289,V Acc: 0.3796, Top 70th Acc: 0.4079, Bottom 30th Acc: 0.3125
Fold [5/5] Epoch [10/100] Initial Loss: 0.1355, Training Loss: 0.0317, Initial Validation Loss: 0.1289, Validation Loss: 0.0381,V Acc: 0.8056, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.5000
Fold [5/5] Epoch [20/100] Initial Loss: 0.1355, Training Loss: 0.0224, Initial Validation Loss: 0.1289, Validation Loss: 0.0346,V Acc: 0.8333, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.5938
Stopping early at Epoch (base 0): 22  Rolling back to Epoch (base 0): 17  Top Validation Acc:/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)

Fold [3/5] Epoch [30/100] Initial Loss: 0.1402, Training Loss: 0.0777, Initial Validation Loss: 0.1293, Validation Loss: 0.0786,V Acc: 0.5909, Top 70th Acc: 0.7532, Bottom 30th Acc: 0.2121
Fold [3/5] Epoch [40/100] Initial Loss: 0.1402, Training Loss: 0.0770, Initial Validation Loss: 0.1293, Validation Loss: 0.0781,V Acc: 0.5909, Top 70th Acc: 0.7403, Bottom 30th Acc: 0.2424
Stopping early at Epoch (base 0): 40  Rolling back to Epoch (base 0): 35  Top Validation Acc: 0.7402597402597403
Fold [4/5] Epoch [0/100] Initial Loss: 0.1385, Training Loss: 0.1385, Initial Validation Loss: 0.1303, Validation Loss: 0.1303,V Acc: 0.3727, Top 70th Acc: 0.4805, Bottom 30th Acc: 0.1212
Fold [4/5] Epoch [10/100] Initial Loss: 0.1385, Training Loss: 0.0822, Initial Validation Loss: 0.1303, Validation Loss: 0.0809,V Acc: 0.6455, Top 70th Acc: 0.7403, Bottom 30th Acc: 0.4242
Fold [4/5] Epoch [20/100] Initial Loss: 0.1385, Training Loss: 0.0796, Initial Validation Loss: 0.1303, Validation Loss: 0.0789,V Acc: 0.6364, Top 70th Acc: 0.7532, Bottom 30th Acc: 0.3636
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.7662337662337663
71 3 [array([0.1426736 , 0.33069962, 0.15423611, 0.22526172, 0.14712901],
      dtype=float32)]
Fold [5/5] Epoch [0/100] Initial Loss: 0.1309, Training Loss: 0.1309, Initial Validation Loss: 0.1223, Validation Loss: 0.1223,V Acc: 0.4630, Top 70th Acc: 0.4474, Bottom 30th Acc: 0.5000
Fold [5/5] Epoch [10/100] Initial Loss: 0.1309, Training Loss: 0.0811, Initial Validation Loss: 0.1223, Validation Loss: 0.0810,V Acc: 0.6481, Top 70th Acc: 0.7237, Bottom 30th Acc: 0.4688
Fold [5/5] Epoch [20/100] Initial Loss: 0.1309, Training Loss: 0.0787, Initial Validation Loss: 0.1223, Validation Loss: 0.0793,V Acc: 0.6296, Top 70th Acc: 0.7237, Bottom 30th Acc: 0.4062
Fold [5/5] Epoch [30/100] Initial Loss: 0.1309, Training Loss: 0.0778, Initial Validation Loss: 0.1223, Validation Loss: 0.0790,V Acc: 0.6389, Top 70th Acc: 0.7237, Bottom 30th Acc: 0.4375
Fold [5/5] Epoch [40/100] Initial Loss: 0.1309, Training Loss: 0.0778, Initial Validation Loss: 0.1223, Validation Loss: 0.0786,V Acc: 0.6481, Top 70th Acc: 0.7237, Bottom 30th Acc: 0.4688
Stopping early at Epoch (base 0): 41  Rolling back to Epoch (base 0): 36  Top Validation Acc: 0.75
Running train_nn.py with seed 72
CUDA:False
Training samples count:  550
Training on 2 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1320, Training Loss: 0.1320, Initial Validation Loss: 0.1254, Validation Loss: 0.1254,V Acc: 0.3694, Top 70th Acc: 0.4359, Bottom 30th Acc: 0.2121
Fold [1/5] Epoch [10/100] Initial Loss: 0.1320, Training Loss: 0.0792, Initial Validation Loss: 0.1254, Validation Loss: 0.0857,V Acc: 0.6126, Top 70th Acc: 0.7179, Bottom 30th Acc: 0.3636
Fold [1/5] Epoch [20/100] Initial Loss: 0.1320, Training Loss: 0.0775, Initial Validation Loss: 0.1254, Validation Loss: 0.0840,V Acc: 0.6126, Top 70th Acc: 0.7308, Bottom 30th Acc: 0.3333
Fold [1/5] Epoch [30/100] Initial Loss: 0.1320, Training Loss: 0.0767, Initial Validation Loss: 0.1254, Validation Loss: 0.0819,V Acc: 0.6216, Top 70th Acc: 0.7436, Bottom 30th Acc: 0.3333
Stopping early at Epoch (base 0): 35  Rolling back to Epoch (base 0): 30  Top Validation Acc: 0.7307692307692307
Fold [2/5] Epoch [0/100] Initial Loss: 0.1419, Training Loss: 0.1419, Initial Validation Loss: 0.1358, Validation Loss: 0.1358,V Acc: 0.2523, Top 70th Acc: 0.3462, Bottom 30th Acc: 0.0303
Fold [2/5] Epoch [10/100] Initial Loss: 0.1419, Training Loss: 0.0861, Initial Validation Loss: 0.1358, Validation Loss: 0.0729,V Acc: 0.7117, Top 70th Acc: 0.7692, Bottom 30th Acc: 0.5758
Fold [2/5] Epoch [20/100] Initial Loss: 0.1419, Training Loss: 0.0828, Initial Validation Loss: 0.1358, Validation Loss: 0.0690,V Acc: 0.6937, Top 70th Acc: 0.7821, Bottom 30th Acc: 0.4848
Fold [2/5] Epoch [30/100] Initial Loss: 0.1419, Training Loss: 0.0821, Initial Validation Loss: 0.1358, Validation Loss: 0.0681,V Acc: 0.6937, Top 70th Acc: 0.7692, Bottom 30th Acc: 0.5152
Stopping early at Epoch (base 0): 39  Rolling back to Epoch (base 0): 34  Top Validation Acc: 0.782051282051282
Fold [3/5] Epoch [0/100] Initial Loss: 0.1372, Training Loss: 0.1372, Initial Validation Loss: 0.1279, Validation Loss: 0.1279,V Acc: 0.3909, Top 70th Acc: 0.4026, Bottom 30th Acc: 0.3636
Fold [3/5] Epoch [10/100] Initial Loss: 0.1372, Training Loss: 0.0835, Initial Validation Loss: 0.1279, Validation Loss: 0.0753,V Acc: 0.6636, Top 70th Acc: 0.7792, Bottom 30th Acc: 0.3939
Fold [3/5] Epoch [20/100] Initial Loss: 0.1372, Training Loss: 0.0808, Initial Validation Loss: 0.1279, Validation Loss: 0.0732,V Acc: 0.6727, Top 70th Acc: 0.8182, Bottom 30th Acc: 0.3333
Stopping early at Epoch (base 0): 28  Rolling back to Epoch (base 0): 23  Top Validation Acc: 0.8051948051948052
Fold [4/5] Epoch [0/100] Initial Loss: 0.1305, Training Loss: 0.1305, Initial Validation Loss: 0.1214, Validation Loss: 0.1214,V Acc: 0.4455, Top 70th Acc: 0.5714, Bottom 30th Acc: 0.1515
Fold [4/5] Epoch [10/100] Initial Loss: 0.1305, Training Loss: 0.0779, Initial Validation Loss: 0.1214, Validation Loss: 0.0875,V Acc: 0.5818, Top 70th Acc: 0.7013, Bottom 30th Acc: 0.3030
Fold [4/5] Epoch [20/100] Initial Loss: 0.1305, Training Loss: 0.0761, Initial Validation Loss: 0.1214, Validation Loss: 0.0867,V Acc: 0.5818, Top 70th Acc: 0.7013, Bottom 30th Acc: 0.3030
Stopping early at Epoch (base 0): 21  Rolling back to Epoch (base 0): 16  Top Validation Acc: 0.7012987012987013
72 3 [array([0.14263156, 0.3740078 , 0.13699582, 0.20116025, 0.14520462],
      dtype=float32)]
Fold [5/5] Epoch [0/100] Initial Loss: 0.1372, Training Loss: 0.1372, Initial Validation Loss: 0.1263, Validation Loss: 0.1263,V Acc: 0.4074, Top 70th Acc: 0.4342, Bottom 30th Acc: 0.3438
Fold [5/5] Epoch [10/100] Initial Loss: 0.1372, Training Loss: 0.0786, Initial Validation Loss: 0.1263, Validation Loss: 0.0851,V Acc: 0.5648, Top 70th Acc: 0.6974, Bottom 30th Acc: 0.2500
Fold [5/5] Epoch [20/100] Initial Loss: 0.1372, Training Loss: 0.0768, Initial Validation Loss: 0.1263, Validation Loss: 0.0848,V Acc: 0.5648, Top 70th Acc: 0.6974, Bottom 30th Acc: 0.2500
Fold [5/5] Epoch [30/100] Initial Loss: 0.1372, Training Loss: 0.0764, Initial Validation Loss: 0.1263, Validation Loss: 0.0831,V Acc: 0.5741, Top 70th Acc: 0.7105, Bottom 30th Acc: 0.2500
Stopping early at Epoch (base 0): 38  Rolling back to Epoch (base 0): 33  Top Validation Acc: 0.7236842105263158
Running train_nn.py with seed 73
CUDA:False
Training samples count:  550
Training on 2 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1288, Training Loss: 0.1288, Initial Validation Loss: 0.1131, Validation Loss: 0.1131,V Acc: 0.5495, Top 70th Acc: 0.5897, Bottom 30th Acc: 0.4545
Fold [1/5] Epoch [10/100] Initial Loss: 0.1288, Training Loss: 0.0811, Initial Validation Loss: 0.1131, Validation Loss: 0.0802,V Acc: 0.6036, Top 70th Acc: 0.7308, Bottom 30th Acc: 0.3030
Fold [1/5] Epoch [20/100] Initial Loss: 0.1288, Training Loss: 0.0792, Initial Validation Loss: 0.1131, Validation Loss: 0.0796,V Acc: 0.5946, Top 70th Acc: 0.7692, Bottom 30th Acc: 0.1818
Fold [1/5] Epoch [30/100] Initial Loss: 0.1288, Training Loss: 0.0786, Initial Validation Loss: 0.1131, Validation Loss: 0.0785,V Acc: 0.6036, Top 70th Acc: 0.7692, Bottom 30th Acc: 0.2121
Stopping early at Epoch (base 0): 34  Rolling back to Epoch (base 0): 29  Top Validation Acc: 0.7692307692307693
73 0 [array([0.14571251, 0.31958398, 0.16120194, 0.23602237, 0.1374792 ],
      dtype=float32)]
Fold [2/5] Epoch [0/100] Initial Loss: 0.1333, Training Loss: 0.1333, Initial Validation Loss: 0.1197, Validation Loss: 0.1197,V Acc: 0.4505, Top 70th Acc: 0.5256, Bottom 30th Acc: 0.2727
Fold [2/5] Epoch [10/100] Initial Loss: 0.1333, Training Loss: 0.0808, Initial Validation Loss: 0.1197, Validation Loss: 0.0815,V Acc: 0.6126, Top 70th Acc: 0.7308, Bottom 30th Acc: 0.3333
Fold [2/5] Epoch [20/100] Initial Loss: 0.1333, Training Loss: 0.0784, Initial Validation Loss: 0.1197, Validation Loss: 0.0795,V Acc: 0.6036, Top 70th Acc: 0.7179, Bottom 30th Acc: 0.3333
Fold [2/5] Epoch [30/100] Initial Loss: 0.1333, Training Loss: 0.0781, Initial Validation Loss: 0.1197, Validation Loss: 0.0801,V Acc: 0.6036, Top 70th Acc: 0.7179, Bottom 30th Acc: 0.3333
Fold [2/5] Epoch [0/100] Initial Loss: 0.1381, Training Loss: 0.1381, Initial Validation Loss: 0.1349, Validation Loss: 0.1349,V Acc: 0.2703, Top 70th Acc: 0.3333, Bottom 30th Acc: 0.1212
Fold [2/5] Epoch [10/100] Initial Loss: 0.1381, Training Loss: 0.0175, Initial Validation Loss: 0.1349, Validation Loss: 0.0339,V Acc: 0.8649, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.6667
Fold [2/5] Epoch [20/100] Initial Loss: 0.1381, Training Loss: 0.0052, Initial Validation Loss: 0.1349, Validation Loss: 0.0284,V Acc: 0.8649, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.6667
Fold [2/5] Epoch [30/100] Initial Loss: 0.1381, Training Loss: 0.0041, Initial Validation Loss: 0.1349, Validation Loss: 0.0273,V Acc: 0.8739, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.6970
Fold [2/5] Epoch [40/100] Initial Loss: 0.1381, Training Loss: 0.0039, Initial Validation Loss: 0.1349, Validation Loss: 0.0279,V Acc: 0.8559, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 40  Rolling back to Epoch (base 0): 35  Top Validation Acc: 0.9487179487179487
58 1 [array([0.2171    , 0.09163009, 0.15960732, 0.25676462, 0.274898  ],
      dtype=float32)]
Fold [3/5] Epoch [0/100] Initial Loss: 0.1395, Training Loss: 0.1395, Initial Validation Loss: 0.1343, Validation Loss: 0.1343,V Acc: 0.3909, Top 70th Acc: 0.4675, Bottom 30th Acc: 0.2121
Fold [3/5] Epoch [10/100] Initial Loss: 0.1395, Training Loss: 0.0172, Initial Validation Loss: 0.1343, Validation Loss: 0.0435,V Acc: 0.7818, Top 70th Acc: 0.8961, Bottom 30th Acc: 0.5152
Fold [3/5] Epoch [20/100] Initial Loss: 0.1395, Training Loss: 0.0055, Initial Validation Loss: 0.1343, Validation Loss: 0.0356,V Acc: 0.8091, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.5152
Fold [3/5] Epoch [30/100] Initial Loss: 0.1395, Training Loss: 0.0042, Initial Validation Loss: 0.1343, Validation Loss: 0.0342,V Acc: 0.8273, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.5758
Fold [3/5] Epoch [40/100] Initial Loss: 0.1395, Training Loss: 0.0039, Initial Validation Loss: 0.1343, Validation Loss: 0.0330,V Acc: 0.8364, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.6061
Fold [3/5] Epoch [50/100] Initial Loss: 0.1395, Training Loss: 0.0038, Initial Validation Loss: 0.1343, Validation Loss: 0.0326,V Acc: 0.8455, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.6364
Fold [3/5] Epoch [60/100] Initial Loss: 0.1395, Training Loss: 0.0037, Initial Validation Loss: 0.1343, Validation Loss: 0.0320,V Acc: 0.8636, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6667
Fold [3/5] Epoch [70/100] Initial Loss: 0.1395, Training Loss: 0.0036, Initial Validation Loss: 0.1343, Validation Loss: 0.0319,V Acc: 0.8636, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 76  Rolling back to Epoch (base 0): 71  Top Validation Acc: 0.948051948051948
Fold [4/5] Epoch [0/100] Initial Loss: 0.1370, Training Loss: 0.1370, Initial Validation Loss: 0.1316, Validation Loss: 0.1316,V Acc: 0.4727, Top 70th Acc: 0.5325, Bottom 30th Acc: 0.3333
Fold [4/5] Epoch [10/100] Initial Loss: 0.1370, Training Loss: 0.0239, Initial Validation Loss: 0.1316, Validation Loss: 0.0337,V Acc: 0.8636, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.7273
Fold [4/5] Epoch [20/100] Initial Loss: 0.1370, Training Loss: 0.0052, Initial Validation Loss: 0.1316, Validation Loss: 0.0196,V Acc: 0.9091, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.7576
Fold [4/5] Epoch [30/100] Initial Loss: 0.1370, Training Loss: 0.0041, Initial Validation Loss: 0.1316, Validation Loss: 0.0183,V Acc: 0.9364, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.8788
Stopping early at Epoch (base 0): 32  Rolling back to Epoch (base 0): 27  Top Validation Acc: 0.974025974025974
Fold [5/5] Epoch [0/100] Initial Loss: 0.1392, Training Loss: 0.1392, Initial Validation Loss: 0.1305, Validation Loss: 0.1305,V Acc: 0.2593, Top 70th Acc: 0.3421, Bottom 30th Acc: 0.0625
Fold [5/5] Epoch [10/100] Initial Loss: 0.1392, Training Loss: 0.0174, Initial Validation Loss: 0.1305, Validation Loss: 0.0376,V Acc: 0.7778, Top 70th Acc: 0.9211, Bottom 30th Acc: 0.4375
Fold [5/5] Epoch [20/100] Initial Loss: 0.1392, Training Loss: 0.0045, Initial Validation Loss: 0.1305, Validation Loss: 0.0306,V Acc: 0.7963, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.4688
Fold [5/5] Epoch [30/100] Initial Loss: 0.1392, Training Loss: 0.0037, Initial Validation Loss: 0.1305, Validation Loss: 0.0300,V Acc: 0.8148, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.5312
Stopping early at Epoch (base 0): 33  Rolling back to Epoch (base 0): 28  Top Validation Acc: 0.9342105263157895
Running train_nn.py with seed 59
CUDA:False
Training samples count:  550
Training on 163 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1389, Training Loss: 0.1389, Initial Validation Loss: 0.1379, Validation Loss: 0.1379,V Acc: 0.3063, Top 70th Acc: 0.3462, Bottom 30th Acc: 0.2121
Fold [1/5] Epoch [10/100] Initial Loss: 0.1389, Training Loss: 0.0369, Initial Validation Loss: 0.1379, Validation Loss: 0.0453,V Acc: 0.7838, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.4545
Fold [1/5] Epoch [20/100] Initial Loss: 0.1389, Training Loss: 0.0062, Initial Validation Loss: 0.1379, Validation Loss: 0.0234,V Acc: 0.8919, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.6970
Fold [1/5] Epoch [30/100] Initial Loss: 0.1389, Training Loss: 0.0043, Initial Validation Loss: 0.1379, Validation Loss: 0.0234,V Acc: 0.9009, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.7273
Stopping early at Epoch (base 0): 33  Rolling back to Epoch (base 0): 28  Top Validation Acc: 0.9743589743589743
Fold [2/5] Epoch [0/100] Initial Loss: 0.1386, Training Loss: 0.1386, Initial Validation Loss: 0.1357, Validation Loss: 0.1357,V Acc: 0.2432, Top 70th Acc: 0.2051, Bottom 30th Acc: 0.3333
Fold [2/5] Epoch [10/100] Initial Loss: 0.1386, Training Loss: 0.0116, Initial Validation Loss: 0.1357, Validation Loss: 0.0343,V Acc: 0.8198, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.5758
Fold [2/5] Epoch [20/100] Initial Loss: 0.1386, Training Loss: 0.0044, Initial Validation Loss: 0.1357, Validation Loss: 0.0314,V Acc: 0.8378, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.9358974358974359
Fold [3/5] Epoch [0/100] Initial Loss: 0.1383, Training Loss: 0.1383, Initial Validation Loss: 0.1316, Validation Loss: 0.1316,V Acc: 0.4000, Top 70th Acc: 0.5065, Bottom 30th Acc: 0.1515
Fold [3/5] Epoch [10/100] Initial Loss: 0.1383, Training Loss: 0.0198, Initial Validation Loss: 0.1316, Validation Loss: 0.0474,V Acc: 0.7818, Top 70th Acc: 0.8831, Bottom 30th Acc: 0.5455
Fold [3/5] Epoch [20/100] Initial Loss: 0.1383, Training Loss: 0.0048, Initial Validation Loss: 0.1316, Validation Loss: 0.0391,V Acc: 0.8091, Top 70th Acc: 0.8961, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.8831168831168831
Fold [4/5] Epoch [0/100] Initial Loss: 0.1387, Training Loss: 0.1387, Initial Validation Loss: 0.1352, Validation Loss: 0.1352,V Acc: 0.4636, Top 70th Acc: 0.5195, Bottom 30th Acc: 0.3333
Fold [4/5] Epoch [10/100] Initial Loss: 0.1387, Training Loss: 0.0286, Initial Validation Loss: 0.1352, Validation Loss: 0.0462,V Acc: 0.7727, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.4545
Fold [4/5] Epoch [20/100] Initial Loss: 0.1387, Training Loss: 0.0058, Initial Validation Loss: 0.1352, Validation Loss: 0.0245,V Acc: 0.8818, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.6667
Fold [4/5] Epoch [30/100] Initial Loss: 0.1387, Training Loss: 0.0044, Initial Validation Loss: 0.1352, Validation Loss: 0.0229,V Acc: 0.8727, Top 70th Acc: 1.0000, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 37  Rolling back to Epoch (base 0): 32  Top Validation Acc: 1.0
Fold [5/5] Epoch [0/100] Initial Loss: 0.1412, Training Loss: 0.1412, Initial Validation Loss: 0.1318, Validation Loss: 0.1318,V Acc: 0.3333, Top 70th Acc: 0.3421, Bottom 30th Acc: 0.3125
Fold [5/5] Epoch [10/100] Initial Loss: 0.1412, Training Loss: 0.0198, Initial Validation Loss: 0.1318, Validation Loss: 0.0398,V Acc: 0.8148, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.5312
Fold [5/5] Epoch [20/100] Initial Loss: 0.1412, Training Loss: 0.0051, Initial Validation Loss: 0.1318, Validation Loss: 0.0323,V Acc: 0.8519, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.6250/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)

Running train_nn.py with seed 76
CUDA:False
Training samples count:  550
Training on 30 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1322, Training Loss: 0.1322, Initial Validation Loss: 0.1262, Validation Loss: 0.1262,V Acc: 0.5405, Top 70th Acc: 0.6667, Bottom 30th Acc: 0.2424
Fold [1/5] Epoch [10/100] Initial Loss: 0.1322, Training Loss: 0.0303, Initial Validation Loss: 0.1262, Validation Loss: 0.0335,V Acc: 0.8468, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.6061
Fold [1/5] Epoch [20/100] Initial Loss: 0.1322, Training Loss: 0.0188, Initial Validation Loss: 0.1262, Validation Loss: 0.0272,V Acc: 0.8559, Top 70th Acc: 1.0000, Bottom 30th Acc: 0.5152
Stopping early at Epoch (base 0): 21  Rolling back to Epoch (base 0): 16  Top Validation Acc: 1.0
Fold [2/5] Epoch [0/100] Initial Loss: 0.1370, Training Loss: 0.1370, Initial Validation Loss: 0.1288, Validation Loss: 0.1288,V Acc: 0.3423, Top 70th Acc: 0.3718, Bottom 30th Acc: 0.2727
Fold [2/5] Epoch [10/100] Initial Loss: 0.1370, Training Loss: 0.0395, Initial Validation Loss: 0.1288, Validation Loss: 0.0438,V Acc: 0.7748, Top 70th Acc: 0.8718, Bottom 30th Acc: 0.5455
Fold [2/5] Epoch [20/100] Initial Loss: 0.1370, Training Loss: 0.0215, Initial Validation Loss: 0.1288, Validation Loss: 0.0303,V Acc: 0.8198, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.4848
Fold [2/5] Epoch [30/100] Initial Loss: 0.1370, Training Loss: 0.0170, Initial Validation Loss: 0.1288, Validation Loss: 0.0293,V Acc: 0.8288, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.5152
Stopping early at Epoch (base 0): 33  Rolling back to Epoch (base 0): 28  Top Validation Acc: 0.9615384615384616
Fold [3/5] Epoch [0/100] Initial Loss: 0.1383, Training Loss: 0.1383, Initial Validation Loss: 0.1363, Validation Loss: 0.1363,V Acc: 0.3273, Top 70th Acc: 0.3506, Bottom 30th Acc: 0.2727
Fold [3/5] Epoch [10/100] Initial Loss: 0.1383, Training Loss: 0.0280, Initial Validation Loss: 0.1363, Validation Loss: 0.0380,V Acc: 0.7727, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.3939
Fold [3/5] Epoch [20/100] Initial Loss: 0.1383, Training Loss: 0.0157, Initial Validation Loss: 0.1363, Validation Loss: 0.0340,V Acc: 0.7909, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.3939
Fold [3/5] Epoch [30/100] Initial Loss: 0.1383, Training Loss: 0.0138, Initial Validation Loss: 0.1363, Validation Loss: 0.0329,V Acc: 0.8091, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 33  Rolling back to Epoch (base 0): 28  Top Validation Acc: 0.935064935064935
Fold [4/5] Epoch [0/100] Initial Loss: 0.1362, Training Loss: 0.1362, Initial Validation Loss: 0.1329, Validation Loss: 0.1329,V Acc: 0.3909, Top 70th Acc: 0.3896, Bottom 30th Acc: 0.3939
Fold [4/5] Epoch [10/100] Initial Loss: 0.1362, Training Loss: 0.0308, Initial Validation Loss: 0.1329, Validation Loss: 0.0349,V Acc: 0.8727, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.6364
Fold [4/5] Epoch [20/100] Initial Loss: 0.1362, Training Loss: 0.0171, Initial Validation Loss: 0.1329, Validation Loss: 0.0269,V Acc: 0.8909, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.7273
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.961038961038961
76 3 [array([0.71061975, 0.0674015 , 0.0558359 , 0.05312011, 0.11302279],
      dtype=float32)]
Fold [5/5] Epoch [0/100] Initial Loss: 0.1385, Training Loss: 0.1385, Initial Validation Loss: 0.1297, Validation Loss: 0.1297,V Acc: 0.2593, Top 70th Acc: 0.3026, Bottom 30th Acc: 0.1562
Fold [5/5] Epoch [10/100] Initial Loss: 0.1385, Training Loss: 0.0248, Initial Validation Loss: 0.1297, Validation Loss: 0.0351,V Acc: 0.8333, Top 70th Acc: 0.9079, Bottom 30th Acc: 0.6562
Fold [5/5] Epoch [20/100] Initial Loss: 0.1385, Training Loss: 0.0167, Initial Validation Loss: 0.1297, Validation Loss: 0.0319,V Acc: 0.8796, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.7188
Stopping early at Epoch (base 0): 22  Rolling back to Epoch (base 0): 17  Top Validation Acc: 0.9210526315789473
Running train_nn.py with seed 77
CUDA:False
Training samples count:  550
Training on 30 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1418, Training Loss: 0.1418, Initial Validation Loss: 0.1400, Validation Loss: 0.1400,V Acc: 0.2793, Top 70th Acc: 0.2308, Bottom 30th Acc: 0.3939
Fold [1/5] Epoch [10/100] Initial Loss: 0.1418, Training Loss: 0.0446, Initial Validation Loss: 0.1400, Validation Loss: 0.0460,V Acc: 0.7658, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.3939
Fold [1/5] Epoch [20/100] Initial Loss: 0.1418, Training Loss: 0.0200, Initial Validation Loss: 0.1400, Validation Loss: 0.0354,V Acc: 0.8198, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.9487179487179487
Fold [2/5] Epoch [0/100] Initial Loss: 0.1396, Training Loss: 0.1396, Initial Validation Loss: 0.1322, Validation Loss: 0.1322,V Acc: 0.3604, Top 70th Acc: 0.3846, Bottom 30th Acc: 0.3030
Fold [2/5] Epoch [10/100] Initial Loss: 0.1396, Training Loss: 0.0405, Initial Validation Loss: 0.1322, Validation Loss: 0.0504,V Acc: 0.7477, Top 70th Acc: 0.8462, Bottom 30th Acc: 0.5152
Fold [2/5] Epoch [20/100] Initial Loss: 0.1396, Training Loss: 0.0186, Initial Validation Loss: 0.1322, Validation Loss: 0.0370,V Acc: 0.7928, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.5152
Stopping early at Epoch (base 0): 28  Rolling back to Epoch (base 0): 23  Top Validation Acc: 0.8974358974358975
Fold [3/5] Epoch [0/100] Initial Loss: 0.1390, Training Loss: 0.1390, Initial Validation Loss: 0.1317, Validation Loss: 0.1317,V Acc: 0.2545, Top 70th Acc: 0.3377, Bottom 30th Acc: 0.0606
Fold [3/5] Epoch [10/100] Initial Loss: 0.1390, Training Loss: 0.0346, Initial Validation Loss: 0.1317, Validation Loss: 0.0390,V Acc: 0.8273, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.6364
Fold [3/5] Epoch [20/100] Initial Loss: 0.1390, Training Loss: 0.0175, Initial Validation Loss: 0.1317, Validation Loss: 0.0325,V Acc: 0.8364, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 20  Rolling back to Epoch (base 0): 15  Top Validation Acc: 0.935064935064935
Fold [4/5] Epoch [0/100] Initial Loss: 0.1389, Training Loss: 0.1389, Initial Validation Loss: 0.1375, Validation Loss: 0.1375,V Acc: 0.2727, Top 70th Acc: 0.2987, Bottom 30th Acc: 0.2121
Fold [4/5] Epoch [10/100] Initial Loss: 0.1389, Training Loss: 0.0408, Initial Validation Loss: 0.1375, Validation Loss: 0.0369,V Acc: 0.8727, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.7273
Fold [4/5] Epoch [20/100] Initial Loss: 0.1389, Training Loss: 0.0248, Initial Validation Loss: 0.1375, Validation Loss: 0.0275,V Acc: 0.8818, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.7273
Fold [4/5] Epoch [30/100] Initial Loss: 0.1389, Training Loss: 0.0185, Initial Validation Loss: 0.1375, Validation Loss: 0.0268,V Acc: 0.8727, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 36  Rolling back to Epoch (base 0): 31  Top Validation Acc: 0.961038961038961
Fold [5/5] Epoch [0/100] Initial Loss: 0.1383, Training Loss: 0.1383, Initial Validation Loss: 0.1322, Validation Loss: 0.1322,V Acc: 0.3796, Top 70th Acc: 0.4211, Bottom 30th Acc: 0.2812
Fold [5/5] Epoch [10/100] Initial Loss: 0.1383, Training Loss: 0.0269, Initial Validation Loss: 0.1322, Validation Loss: 0.0327,V Acc: 0.8519, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.6562
Stopping early at Epoch (base 0): 19  Rolling back to Epoch (base 0): 14  Top Validation Acc: 0.9473684210526315
77 4 [array([0.61406416, 0.07389674, 0.06335663, 0.07541731, 0.17326516],
      dtype=float32)]
Running train_nn.py with seed 78
CUDA:False
Training samples count:  550
Training on 30 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1473, Training Loss: 0.1473, Initial Validation Loss: 0.1405, Validation Loss: 0.1405,V Acc: 0.3694, Top 70th Acc: 0.3718, Bottom 30th Acc: 0.3636
Fold [1/5] Epoch [10/100] Initial Loss: 0.1473, Training Loss: 0.0345, Initial Validation Loss: 0.1405, Validation Loss: 0.0397,V Acc: 0.8378, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.6061
Fold [1/5] Epoch [20/100] Initial Loss: 0.1473, Training Loss: 0.0193, Initial Validation Loss: 0.1405, Validation Loss: 0.0324,V Acc: 0.8739, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.6667 0.9342105263157895
77 4 [array([0.45386398, 0.14276059, 0.09799699, 0.21186313, 0.09351527],
      dtype=float32)]
Running train_nn.py with seed 78
CUDA:False
Training samples count:  550
Training on 20 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1368, Training Loss: 0.1368, Initial Validation Loss: 0.1369, Validation Loss: 0.1369,V Acc: 0.2973, Top 70th Acc: 0.3590, Bottom 30th Acc: 0.1515
Fold [1/5] Epoch [10/100] Initial Loss: 0.1368, Training Loss: 0.0374, Initial Validation Loss: 0.1369, Validation Loss: 0.0407,V Acc: 0.8378, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.6364
Fold [1/5] Epoch [20/100] Initial Loss: 0.1368, Training Loss: 0.0237, Initial Validation Loss: 0.1369, Validation Loss: 0.0341,V Acc: 0.8559, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.6667
Fold [1/5] Epoch [30/100] Initial Loss: 0.1368, Training Loss: 0.0218, Initial Validation Loss: 0.1369, Validation Loss: 0.0341,V Acc: 0.8649, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 30  Rolling back to Epoch (base 0): 25  Top Validation Acc: 0.9358974358974359
Fold [2/5] Epoch [0/100] Initial Loss: 0.1375, Training Loss: 0.1375, Initial Validation Loss: 0.1331, Validation Loss: 0.1331,V Acc: 0.3964, Top 70th Acc: 0.4359, Bottom 30th Acc: 0.3030
Fold [2/5] Epoch [10/100] Initial Loss: 0.1375, Training Loss: 0.0392, Initial Validation Loss: 0.1331, Validation Loss: 0.0437,V Acc: 0.7838, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.4848
Fold [2/5] Epoch [20/100] Initial Loss: 0.1375, Training Loss: 0.0225, Initial Validation Loss: 0.1331, Validation Loss: 0.0365,V Acc: 0.8468, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 28  Rolling back to Epoch (base 0): 23  Top Validation Acc: 0.9230769230769231
Fold [3/5] Epoch [0/100] Initial Loss: 0.1388, Training Loss: 0.1388, Initial Validation Loss: 0.1368, Validation Loss: 0.1368,V Acc: 0.2273, Top 70th Acc: 0.2208, Bottom 30th Acc: 0.2424
Fold [3/5] Epoch [10/100] Initial Loss: 0.1388, Training Loss: 0.0306, Initial Validation Loss: 0.1368, Validation Loss: 0.0422,V Acc: 0.8182, Top 70th Acc: 0.8961, Bottom 30th Acc: 0.6364
Fold [3/5] Epoch [20/100] Initial Loss: 0.1388, Training Loss: 0.0218, Initial Validation Loss: 0.1368, Validation Loss: 0.0371,V Acc: 0.8636, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.7273
Stopping early at Epoch (base 0): 21  Rolling back to Epoch (base 0): 16  Top Validation Acc: 0.9090909090909091
Fold [4/5] Epoch [0/100] Initial Loss: 0.1400, Training Loss: 0.1400, Initial Validation Loss: 0.1323, Validation Loss: 0.1323,V Acc: 0.2727, Top 70th Acc: 0.2987, Bottom 30th Acc: 0.2121
Fold [4/5] Epoch [10/100] Initial Loss: 0.1400, Training Loss: 0.0365, Initial Validation Loss: 0.1323, Validation Loss: 0.0420,V Acc: 0.7636, Top 70th Acc: 0.8831, Bottom 30th Acc: 0.4848
Fold [4/5] Epoch [20/100] Initial Loss: 0.1400, Training Loss: 0.0213, Initial Validation Loss: 0.1323, Validation Loss: 0.0386,V Acc: 0.7545, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.3939
Stopping early at Epoch (base 0): 21  Rolling back to Epoch (base 0): 16  Top Validation Acc: 0.8831168831168831
78 3 [array([0.41452166, 0.09566199, 0.09379301, 0.22547647, 0.17054689],
      dtype=float32)]
Fold [5/5] Epoch [0/100] Initial Loss: 0.1425, Training Loss: 0.1425, Initial Validation Loss: 0.1325, Validation Loss: 0.1325,V Acc: 0.2500, Top 70th Acc: 0.3026, Bottom 30th Acc: 0.1250
Fold [5/5] Epoch [10/100] Initial Loss: 0.1425, Training Loss: 0.0399, Initial Validation Loss: 0.1325, Validation Loss: 0.0452,V Acc: 0.7685, Top 70th Acc: 0.8816, Bottom 30th Acc: 0.5000
Fold [5/5] Epoch [20/100] Initial Loss: 0.1425, Training Loss: 0.0234, Initial Validation Loss: 0.1325, Validation Loss: 0.0340,V Acc: 0.8241, Top 70th Acc: 0.8947, Bottom 30th Acc: 0.6562
Fold [5/5] Epoch [30/100] Initial Loss: 0.1425, Training Loss: 0.0210, Initial Validation Loss: 0.1325, Validation Loss: 0.0327,V Acc: 0.7963, Top 70th Acc: 0.8947, Bottom 30th Acc: 0.5625
Stopping early at Epoch (base 0): 35  Rolling back to Epoch (base 0): 30  Top Validation Acc: 0.8947368421052632
Running train_nn.py with seed 79
CUDA:False
Training samples count:  550
Training on 20 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1325, Training Loss: 0.1325, Initial Validation Loss: 0.1271, Validation Loss: 0.1271,V Acc: 0.3874, Top 70th Acc: 0.4872, Bottom 30th Acc: 0.1515
Fold [1/5] Epoch [10/100] Initial Loss: 0.1325, Training Loss: 0.0301, Initial Validation Loss: 0.1271, Validation Loss: 0.0422,V Acc: 0.7748, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.4242
Fold [1/5] Epoch [20/100] Initial Loss: 0.1325, Training Loss: 0.0218, Initial Validation Loss: 0.1271, Validation Loss: 0.0393,V Acc: 0.8018, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.5152
Stopping early at Epoch (base 0): 27  Rolling back to Epoch (base 0): 22  Top Validation Acc: 0.9230769230769231
Fold [2/5] Epoch [0/100] Initial Loss: 0.1369, Training Loss: 0.1369, Initial Validation Loss: 0.1353, Validation Loss: 0.1353,V Acc: 0.3063, Top 70th Acc: 0.3846, Bottom 30th Acc: 0.1212
Fold [2/5] Epoch [10/100] Initial Loss: 0.1369, Training Loss: 0.0321, Initial Validation Loss: 0.1353, Validation Loss: 0.0360,V Acc: 0.8468, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.6667
Fold [2/5] Epoch [20/100] Initial Loss: 0.1369, Training Loss: 0.0238, Initial Validation Loss: 0.1353, Validation Loss: 0.0306,V Acc: 0.9009, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.8182
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.9487179487179487
Fold [3/5] Epoch [0/100] Initial Loss: 0.1374, Training Loss: 0.1374, Initial Validation Loss: 0.1313, Validation Loss: 0.1313,V Acc: 0.4455, Top 70th Acc: 0.4805, Bottom 30th Acc: 0.3636
Fold [3/5] Epoch [10/100] Initial Loss: 0.1374, Training Loss: 0.0398, Initial Validation Loss: 0.1313, Validation Loss: 0.0424,V Acc: 0.8000, Top 70th Acc: 0.8961, Bottom 30th Acc: 0.5758
Fold [3/5] Epoch [20/100] Initial Loss: 0.1374, Training Loss: 0.0242, Initial Validation Loss: 0.1313, Validation Loss: 0.0307,V Acc: 0.8364, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 28  Rolling back to Epoch (base 0): 23  Top Validation Acc: 0.948051948051948
Fold [4/5] Epoch [0/100] Initial Loss: 0.1385, Training Loss: 0.1385, Initial Validation Loss: 0.1337, Validation Loss: 0.1337,V Acc: 0.3636, Top 70th Acc: 0.4805, Bottom 30th Acc: 0.0909
Fold [4/5] Epoch [10/100] Initial Loss: 0.1385, Training Loss: 0.0384, Initial Validation Loss: 0.1337, Validation Loss: 0.0515,V Acc: 0.7636, Top 70th Acc: 0.8701, Bottom 30th Acc: 0.5152
Fold [4/5] Epoch [20/100] Initial Loss: 0.1385, Training Loss: 0.0219, Initial Validation Loss: 0.1337, Validation Loss: 0.0394,V Acc: 0.8000, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.4848
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.9090909090909091
Fold [5/5] Epoch [0/100] Initial Loss: 0.1397, Training Loss: 0.1397, Initial Validation Loss: 0.1329, Validation Loss: 0.1329,V Acc: 0.2500, Top 70th Acc: 0.2237, Bottom 30th Acc: 0.3125
Fold [5/5] Epoch [10/100] Initial Loss: 0.1397, Training Loss: 0.0420, Initial Validation Loss: 0.1329, Validation Loss: 0.0394,V Acc: 0.7963, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.4688
Fold [5/5] Epoch [20/100] Initial Loss: 0.1397, Training Loss: 0.0248, Initial Validation Loss: 0.1329, Validation Loss: 0.0274,V Acc: 0.8796, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.7188
Fold [5/5] Epoch [30/100] Initial Loss: 0.1397, Training Loss: 0.0224, Initial Validation Loss: 0.1329, Validation Loss: 0.0262,V Acc: 0.8519, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.6250
Stopping early at Epoch (base 0): 30  Rolling back to Epoch (base 0): 25  Top Validation Acc: 0.9473684210526315
79 4 [array([0.42578784, 0.09707443, 0.21242893, 0.18430203, 0.0804068 ],
      dtype=float32)]
Running train_nn.py with seed 80
CUDA:False
Training samples count:  550
Training on 20 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1376, Training Loss: 0.1376, Initial Validation Loss: 0.1321, Validation Loss: 0.1321,V Acc: 0.5045, Top 70th Acc: 0.5385, Bottom 30th Acc: 0.4242
Fold [1/5] Epoch [10/100] Initial Loss: 0.1376, Training Loss: 0.0410, Initial Validation Loss: 0.1321, Validation Loss: 0.0441,V Acc: 0.8108, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.5758
Fold [1/5] Epoch [10/100] Initial Loss: 0.1376, Training Loss: 0.0342, Initial Validation Loss: 0.1372, Validation Loss: 0.0355,V Acc: 0.8468, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.5758
Fold [1/5] Epoch [20/100] Initial Loss: 0.1376, Training Loss: 0.0161, Initial Validation Loss: 0.1372, Validation Loss: 0.0213,V Acc: 0.9009, Top 70th Acc: 0.9872, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 29  Rolling back to Epoch (base 0): 24  Top Validation Acc: 0.9871794871794872
Fold [2/5] Epoch [0/100] Initial Loss: 0.1401, Training Loss: 0.1401, Initial Validation Loss: 0.1307, Validation Loss: 0.1307,V Acc: 0.3243, Top 70th Acc: 0.4231, Bottom 30th Acc: 0.0909
Fold [2/5] Epoch [10/100] Initial Loss: 0.1401, Training Loss: 0.0339, Initial Validation Loss: 0.1307, Validation Loss: 0.0426,V Acc: 0.7568, Top 70th Acc: 0.8846, Bottom 30th Acc: 0.4545
Fold [2/5] Epoch [20/100] Initial Loss: 0.1401, Training Loss: 0.0156, Initial Validation Loss: 0.1307, Validation Loss: 0.0280,V Acc: 0.8468, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.5758
Fold [2/5] Epoch [30/100] Initial Loss: 0.1401, Training Loss: 0.0129, Initial Validation Loss: 0.1307, Validation Loss: 0.0266,V Acc: 0.8378, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 39  Rolling back to Epoch (base 0): 34  Top Validation Acc: 0.9615384615384616
Fold [3/5] Epoch [0/100] Initial Loss: 0.1388, Training Loss: 0.1388, Initial Validation Loss: 0.1352, Validation Loss: 0.1352,V Acc: 0.3545, Top 70th Acc: 0.3896, Bottom 30th Acc: 0.2727
Fold [3/5] Epoch [10/100] Initial Loss: 0.1388, Training Loss: 0.0398, Initial Validation Loss: 0.1352, Validation Loss: 0.0463,V Acc: 0.7545, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.3939
Fold [3/5] Epoch [20/100] Initial Loss: 0.1388, Training Loss: 0.0203, Initial Validation Loss: 0.1352, Validation Loss: 0.0361,V Acc: 0.7818, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.4242
Fold [3/5] Epoch [30/100] Initial Loss: 0.1388, Training Loss: 0.0142, Initial Validation Loss: 0.1352, Validation Loss: 0.0306,V Acc: 0.8091, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.4545
Fold [3/5] Epoch [40/100] Initial Loss: 0.1388, Training Loss: 0.0116, Initial Validation Loss: 0.1352, Validation Loss: 0.0283,V Acc: 0.8182, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.4545
Fold [3/5] Epoch [50/100] Initial Loss: 0.1388, Training Loss: 0.0105, Initial Validation Loss: 0.1352, Validation Loss: 0.0271,V Acc: 0.8273, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.4848
Stopping early at Epoch (base 0): 56  Rolling back to Epoch (base 0): 51  Top Validation Acc: 0.974025974025974
Fold [4/5] Epoch [0/100] Initial Loss: 0.1375, Training Loss: 0.1375, Initial Validation Loss: 0.1359, Validation Loss: 0.1359,V Acc: 0.3727, Top 70th Acc: 0.3766, Bottom 30th Acc: 0.3636
Fold [4/5] Epoch [10/100] Initial Loss: 0.1375, Training Loss: 0.0401, Initial Validation Loss: 0.1359, Validation Loss: 0.0513,V Acc: 0.7545, Top 70th Acc: 0.8571, Bottom 30th Acc: 0.5152
Fold [4/5] Epoch [20/100] Initial Loss: 0.1375, Training Loss: 0.0186, Initial Validation Loss: 0.1359, Validation Loss: 0.0359,V Acc: 0.8455, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.6364
Fold [4/5] Epoch [30/100] Initial Loss: 0.1375, Training Loss: 0.0124, Initial Validation Loss: 0.1359, Validation Loss: 0.0317,V Acc: 0.8727, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.7273
Fold [4/5] Epoch [40/100] Initial Loss: 0.1375, Training Loss: 0.0105, Initial Validation Loss: 0.1359, Validation Loss: 0.0317,V Acc: 0.8636, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 42  Rolling back to Epoch (base 0): 37  Top Validation Acc: 0.948051948051948
76 3 [array([0.3706535 , 0.06133424, 0.09640533, 0.08396827, 0.38763863],
      dtype=float32)]
Fold [5/5] Epoch [0/100] Initial Loss: 0.1410, Training Loss: 0.1410, Initial Validation Loss: 0.1300, Validation Loss: 0.1300,V Acc: 0.3426, Top 70th Acc: 0.4342, Bottom 30th Acc: 0.1250
Fold [5/5] Epoch [10/100] Initial Loss: 0.1410, Training Loss: 0.0310, Initial Validation Loss: 0.1300, Validation Loss: 0.0411,V Acc: 0.8148, Top 70th Acc: 0.8816, Bottom 30th Acc: 0.6562
Fold [5/5] Epoch [20/100] Initial Loss: 0.1410, Training Loss: 0.0149, Initial Validation Loss: 0.1300, Validation Loss: 0.0289,V Acc: 0.8611, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.6875
Fold [5/5] Epoch [30/100] Initial Loss: 0.1410, Training Loss: 0.0124, Initial Validation Loss: 0.1300, Validation Loss: 0.0291,V Acc: 0.8426, Top 70th Acc: 0.9211, Bottom 30th Acc: 0.6562
Stopping early at Epoch (base 0): 31  Rolling back to Epoch (base 0): 26  Top Validation Acc: 0.9210526315789473
Running train_nn.py with seed 77
CUDA:False
Training samples count:  550
Training on 40 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1389, Training Loss: 0.1389, Initial Validation Loss: 0.1382, Validation Loss: 0.1382,V Acc: 0.2523, Top 70th Acc: 0.3205, Bottom 30th Acc: 0.0909
Fold [1/5] Epoch [10/100] Initial Loss: 0.1389, Training Loss: 0.0306, Initial Validation Loss: 0.1382, Validation Loss: 0.0378,V Acc: 0.8378, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.6364
Fold [1/5] Epoch [20/100] Initial Loss: 0.1389, Training Loss: 0.0142, Initial Validation Loss: 0.1382, Validation Loss: 0.0290,V Acc: 0.8288, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.4848
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.9871794871794872
Fold [2/5] Epoch [0/100] Initial Loss: 0.1365, Training Loss: 0.1365, Initial Validation Loss: 0.1286, Validation Loss: 0.1286,V Acc: 0.3604, Top 70th Acc: 0.4231, Bottom 30th Acc: 0.2121
Fold [2/5] Epoch [10/100] Initial Loss: 0.1365, Training Loss: 0.0184, Initial Validation Loss: 0.1286, Validation Loss: 0.0400,V Acc: 0.7568, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.3636
Fold [2/5] Epoch [20/100] Initial Loss: 0.1365, Training Loss: 0.0111, Initial Validation Loss: 0.1286, Validation Loss: 0.0365,V Acc: 0.7658, Top 70th Acc: 0.8974, Bottom 30th Acc: 0.4545
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.8846153846153846
Fold [3/5] Epoch [0/100] Initial Loss: 0.1395, Training Loss: 0.1395, Initial Validation Loss: 0.1299, Validation Loss: 0.1299,V Acc: 0.3091, Top 70th Acc: 0.3766, Bottom 30th Acc: 0.1515
Fold [3/5] Epoch [10/100] Initial Loss: 0.1395, Training Loss: 0.0275, Initial Validation Loss: 0.1299, Validation Loss: 0.0289,V Acc: 0.8818, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.6970
Fold [3/5] Epoch [20/100] Initial Loss: 0.1395, Training Loss: 0.0153, Initial Validation Loss: 0.1299, Validation Loss: 0.0265,V Acc: 0.8455, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 29  Rolling back to Epoch (base 0): 24  Top Validation Acc: 0.948051948051948
Fold [4/5] Epoch [0/100] Initial Loss: 0.1364, Training Loss: 0.1364, Initial Validation Loss: 0.1335, Validation Loss: 0.1335,V Acc: 0.3636, Top 70th Acc: 0.4545, Bottom 30th Acc: 0.1515
Fold [4/5] Epoch [10/100] Initial Loss: 0.1364, Training Loss: 0.0349, Initial Validation Loss: 0.1335, Validation Loss: 0.0355,V Acc: 0.8273, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.5758
Fold [4/5] Epoch [20/100] Initial Loss: 0.1364, Training Loss: 0.0171, Initial Validation Loss: 0.1335, Validation Loss: 0.0233,V Acc: 0.8636, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 28  Rolling back to Epoch (base 0): 23  Top Validation Acc: 0.987012987012987
Fold [5/5] Epoch [0/100] Initial Loss: 0.1414, Training Loss: 0.1414, Initial Validation Loss: 0.1337, Validation Loss: 0.1337,V Acc: 0.2500, Top 70th Acc: 0.3421, Bottom 30th Acc: 0.0312
Fold [5/5] Epoch [10/100] Initial Loss: 0.1414, Training Loss: 0.0338, Initial Validation Loss: 0.1337, Validation Loss: 0.0456,V Acc: 0.7593, Top 70th Acc: 0.8816, Bottom 30th Acc: 0.4688
Fold [5/5] Epoch [20/100] Initial Loss: 0.1414, Training Loss: 0.0187, Initial Validation Loss: 0.1337, Validation Loss: 0.0363,V Acc: 0.8148, Top 70th Acc: 0.9211, Bottom 30th Acc: 0.5625
Fold [5/5] Epoch [30/100] Initial Loss: 0.1414, Training Loss: 0.0126, Initial Validation Loss: 0.1337, Validation Loss: 0.0314,V Acc: 0.8333, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.5938
Fold [5/5] Epoch [40/100] Initial Loss: 0.1414, Training Loss: 0.0111, Initial Validation Loss: 0.1337, Validation Loss: 0.0303,V Acc: 0.8426, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.6250/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)

Fold [2/5] Epoch [40/100] Initial Loss: 0.1333, Training Loss: 0.0776, Initial Validation Loss: 0.1197, Validation Loss: 0.0797,V Acc: 0.6036, Top 70th Acc: 0.7308, Bottom 30th Acc: 0.3030
Stopping early at Epoch (base 0): 40  Rolling back to Epoch (base 0): 35  Top Validation Acc: 0.7307692307692307
Fold [3/5] Epoch [0/100] Initial Loss: 0.1253, Training Loss: 0.1253, Initial Validation Loss: 0.1079, Validation Loss: 0.1079,V Acc: 0.5818, Top 70th Acc: 0.7532, Bottom 30th Acc: 0.1818
Fold [3/5] Epoch [10/100] Initial Loss: 0.1253, Training Loss: 0.0818, Initial Validation Loss: 0.1079, Validation Loss: 0.0763,V Acc: 0.6273, Top 70th Acc: 0.7403, Bottom 30th Acc: 0.3636
Fold [3/5] Epoch [20/100] Initial Loss: 0.1253, Training Loss: 0.0802, Initial Validation Loss: 0.1079, Validation Loss: 0.0746,V Acc: 0.6545, Top 70th Acc: 0.7532, Bottom 30th Acc: 0.4242
Fold [3/5] Epoch [30/100] Initial Loss: 0.1253, Training Loss: 0.0796, Initial Validation Loss: 0.1079, Validation Loss: 0.0744,V Acc: 0.6545, Top 70th Acc: 0.7273, Bottom 30th Acc: 0.4848
Stopping early at Epoch (base 0): 33  Rolling back to Epoch (base 0): 28  Top Validation Acc: 0.7532467532467533
Fold [4/5] Epoch [0/100] Initial Loss: 0.1324, Training Loss: 0.1324, Initial Validation Loss: 0.1248, Validation Loss: 0.1248,V Acc: 0.4727, Top 70th Acc: 0.5455, Bottom 30th Acc: 0.3030
Fold [4/5] Epoch [10/100] Initial Loss: 0.1324, Training Loss: 0.0811, Initial Validation Loss: 0.1248, Validation Loss: 0.0775,V Acc: 0.6455, Top 70th Acc: 0.7403, Bottom 30th Acc: 0.4242
Fold [4/5] Epoch [20/100] Initial Loss: 0.1324, Training Loss: 0.0797, Initial Validation Loss: 0.1248, Validation Loss: 0.0758,V Acc: 0.6545, Top 70th Acc: 0.7662, Bottom 30th Acc: 0.3939
Stopping early at Epoch (base 0): 28  Rolling back to Epoch (base 0): 23  Top Validation Acc: 0.7402597402597403
Fold [5/5] Epoch [0/100] Initial Loss: 0.1366, Training Loss: 0.1366, Initial Validation Loss: 0.1324, Validation Loss: 0.1324,V Acc: 0.2870, Top 70th Acc: 0.3289, Bottom 30th Acc: 0.1875
Fold [5/5] Epoch [10/100] Initial Loss: 0.1366, Training Loss: 0.0791, Initial Validation Loss: 0.1324, Validation Loss: 0.0875,V Acc: 0.6111, Top 70th Acc: 0.7237, Bottom 30th Acc: 0.3438
Fold [5/5] Epoch [20/100] Initial Loss: 0.1366, Training Loss: 0.0764, Initial Validation Loss: 0.1324, Validation Loss: 0.0861,V Acc: 0.6111, Top 70th Acc: 0.7105, Bottom 30th Acc: 0.3750
Stopping early at Epoch (base 0): 29  Rolling back to Epoch (base 0): 24  Top Validation Acc: 0.7105263157894737
Running train_nn.py with seed 74
CUDA:False
Training samples count:  550
Training on 2 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1322, Training Loss: 0.1322, Initial Validation Loss: 0.1251, Validation Loss: 0.1251,V Acc: 0.3964, Top 70th Acc: 0.5128, Bottom 30th Acc: 0.1212
Fold [1/5] Epoch [10/100] Initial Loss: 0.1322, Training Loss: 0.0815, Initial Validation Loss: 0.1251, Validation Loss: 0.0790,V Acc: 0.6216, Top 70th Acc: 0.7308, Bottom 30th Acc: 0.3636
Fold [1/5] Epoch [20/100] Initial Loss: 0.1322, Training Loss: 0.0796, Initial Validation Loss: 0.1251, Validation Loss: 0.0767,V Acc: 0.6486, Top 70th Acc: 0.7436, Bottom 30th Acc: 0.4242
Fold [1/5] Epoch [30/100] Initial Loss: 0.1322, Training Loss: 0.0788, Initial Validation Loss: 0.1251, Validation Loss: 0.0764,V Acc: 0.6396, Top 70th Acc: 0.7308, Bottom 30th Acc: 0.4242
Fold [1/5] Epoch [40/100] Initial Loss: 0.1322, Training Loss: 0.0788, Initial Validation Loss: 0.1251, Validation Loss: 0.0759,V Acc: 0.6396, Top 70th Acc: 0.7436, Bottom 30th Acc: 0.3939
Stopping early at Epoch (base 0): 45  Rolling back to Epoch (base 0): 40  Top Validation Acc: 0.7307692307692307
Fold [2/5] Epoch [0/100] Initial Loss: 0.1338, Training Loss: 0.1338, Initial Validation Loss: 0.1235, Validation Loss: 0.1235,V Acc: 0.5135, Top 70th Acc: 0.6282, Bottom 30th Acc: 0.2424
Fold [2/5] Epoch [10/100] Initial Loss: 0.1338, Training Loss: 0.0815, Initial Validation Loss: 0.1235, Validation Loss: 0.0766,V Acc: 0.6486, Top 70th Acc: 0.7949, Bottom 30th Acc: 0.3030
Fold [2/5] Epoch [20/100] Initial Loss: 0.1338, Training Loss: 0.0800, Initial Validation Loss: 0.1235, Validation Loss: 0.0752,V Acc: 0.6486, Top 70th Acc: 0.8205, Bottom 30th Acc: 0.2424
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.7692307692307693
Fold [3/5] Epoch [0/100] Initial Loss: 0.1373, Training Loss: 0.1373, Initial Validation Loss: 0.1279, Validation Loss: 0.1279,V Acc: 0.4091, Top 70th Acc: 0.4416, Bottom 30th Acc: 0.3333
Fold [3/5] Epoch [10/100] Initial Loss: 0.1373, Training Loss: 0.0814, Initial Validation Loss: 0.1279, Validation Loss: 0.0815,V Acc: 0.5909, Top 70th Acc: 0.7013, Bottom 30th Acc: 0.3333
Fold [3/5] Epoch [20/100] Initial Loss: 0.1373, Training Loss: 0.0792, Initial Validation Loss: 0.1279, Validation Loss: 0.0788,V Acc: 0.5909, Top 70th Acc: 0.7143, Bottom 30th Acc: 0.3030
Fold [3/5] Epoch [30/100] Initial Loss: 0.1373, Training Loss: 0.0786, Initial Validation Loss: 0.1279, Validation Loss: 0.0786,V Acc: 0.6000, Top 70th Acc: 0.7013, Bottom 30th Acc: 0.3636
Stopping early at Epoch (base 0): 30  Rolling back to Epoch (base 0): 25  Top Validation Acc: 0.7012987012987013
74 2 [array([0.14524984, 0.34221947, 0.13246234, 0.22427762, 0.15579075],
      dtype=float32)]
Fold [4/5] Epoch [0/100] Initial Loss: 0.1315, Training Loss: 0.1315, Initial Validation Loss: 0.1223, Validation Loss: 0.1223,V Acc: 0.5273, Top 70th Acc: 0.5844, Bottom 30th Acc: 0.3939
Fold [4/5] Epoch [10/100] Initial Loss: 0.1315, Training Loss: 0.0801, Initial Validation Loss: 0.1223, Validation Loss: 0.0810,V Acc: 0.6455, Top 70th Acc: 0.7403, Bottom 30th Acc: 0.4242
Stopping early at Epoch (base 0): 14  Rolling back to Epoch (base 0): 9  Top Validation Acc: 0.7142857142857143
Fold [5/5] Epoch [0/100] Initial Loss: 0.1344, Training Loss: 0.1344, Initial Validation Loss: 0.1219, Validation Loss: 0.1219,V Acc: 0.3796, Top 70th Acc: 0.4605, Bottom 30th Acc: 0.1875
Fold [5/5] Epoch [10/100] Initial Loss: 0.1344, Training Loss: 0.0788, Initial Validation Loss: 0.1219, Validation Loss: 0.0851,V Acc: 0.5926, Top 70th Acc: 0.6974, Bottom 30th Acc: 0.3438
Fold [5/5] Epoch [20/100] Initial Loss: 0.1344, Training Loss: 0.0769, Initial Validation Loss: 0.1219, Validation Loss: 0.0841,V Acc: 0.5833, Top 70th Acc: 0.7105, Bottom 30th Acc: 0.2812
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.7105263157894737
Running train_nn.py with seed 75
CUDA:False
Training samples count:  550
Training on 2 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1377, Training Loss: 0.1377, Initial Validation Loss: 0.1287, Validation Loss: 0.1287,V Acc: 0.5315, Top 70th Acc: 0.6538, Bottom 30th Acc: 0.2424
Fold [1/5] Epoch [10/100] Initial Loss: 0.1377, Training Loss: 0.0770, Initial Validation Loss: 0.1287, Validation Loss: 0.0934,V Acc: 0.5766, Top 70th Acc: 0.6667, Bottom 30th Acc: 0.3636
Stopping early at Epoch (base 0): 13  Rolling back to Epoch (base 0): 8  Top Validation Acc: 0.6666666666666666
Fold [2/5] Epoch [0/100] Initial Loss: 0.1453, Training Loss: 0.1453, Initial Validation Loss: 0.1417, Validation Loss: 0.1417,V Acc: 0.2342, Top 70th Acc: 0.2821, Bottom 30th Acc: 0.1212
Fold [2/5] Epoch [10/100] Initial Loss: 0.1453, Training Loss: 0.0838, Initial Validation Loss: 0.1417, Validation Loss: 0.0799,V Acc: 0.6757, Top 70th Acc: 0.7821, Bottom 30th Acc: 0.4242
Fold [2/5] Epoch [20/100] Initial Loss: 0.1453, Training Loss: 0.0811, Initial Validation Loss: 0.1417, Validation Loss: 0.0753,V Acc: 0.6937, Top 70th Acc: 0.7949, Bottom 30th Acc: 0.4545
Stopping early at Epoch (base 0): 28  Rolling back to Epoch (base 0): 23  Top Validation Acc: 0.782051282051282
Fold [3/5] Epoch [0/100] Initial Loss: 0.1354, Training Loss: 0.1354, Initial Validation Loss: 0.1210, Validation Loss: 0.1210,V Acc: 0.5818, Top 70th Acc: 0.7273, Bottom 30th Acc: 0.2424
Fold [3/5] Epoch [10/100] Initial Loss: 0.1354, Training Loss: 0.0808, Initial Validation Loss: 0.1210, Validation Loss: 0.0759,V Acc: 0.6182, Top 70th Acc: 0.7532, Bottom 30th Acc: 0.3030
Fold [3/5] Epoch [20/100] Initial Loss: 0.1354, Training Loss: 0.0780, Initial Validation Loss: 0.1210, Validation Loss: 0.0756,V Acc: 0.6364, Top 70th Acc: 0.7662, Bottom 30th Acc: 0.3333
Fold [1/5] Epoch [30/100] Initial Loss: 0.1473, Training Loss: 0.0170, Initial Validation Loss: 0.1405, Validation Loss: 0.0317,V Acc: 0.8739, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 30  Rolling back to Epoch (base 0): 25  Top Validation Acc: 0.9615384615384616
Fold [2/5] Epoch [0/100] Initial Loss: 0.1400, Training Loss: 0.1400, Initial Validation Loss: 0.1365, Validation Loss: 0.1365,V Acc: 0.3063, Top 70th Acc: 0.3590, Bottom 30th Acc: 0.1818
Fold [2/5] Epoch [10/100] Initial Loss: 0.1400, Training Loss: 0.0354, Initial Validation Loss: 0.1365, Validation Loss: 0.0436,V Acc: 0.8108, Top 70th Acc: 0.8974, Bottom 30th Acc: 0.6061
Fold [2/5] Epoch [20/100] Initial Loss: 0.1400, Training Loss: 0.0200, Initial Validation Loss: 0.1365, Validation Loss: 0.0380,V Acc: 0.8378, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.6667
Fold [2/5] Epoch [30/100] Initial Loss: 0.1400, Training Loss: 0.0161, Initial Validation Loss: 0.1365, Validation Loss: 0.0386,V Acc: 0.8108, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 32  Rolling back to Epoch (base 0): 27  Top Validation Acc: 0.9230769230769231
Fold [3/5] Epoch [0/100] Initial Loss: 0.1368, Training Loss: 0.1368, Initial Validation Loss: 0.1336, Validation Loss: 0.1336,V Acc: 0.4000, Top 70th Acc: 0.4286, Bottom 30th Acc: 0.3333
Fold [3/5] Epoch [10/100] Initial Loss: 0.1368, Training Loss: 0.0345, Initial Validation Loss: 0.1336, Validation Loss: 0.0468,V Acc: 0.8364, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.6667
Fold [3/5] Epoch [20/100] Initial Loss: 0.1368, Training Loss: 0.0192, Initial Validation Loss: 0.1336, Validation Loss: 0.0337,V Acc: 0.8909, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.8182
Fold [3/5] Epoch [30/100] Initial Loss: 0.1368, Training Loss: 0.0169, Initial Validation Loss: 0.1336, Validation Loss: 0.0328,V Acc: 0.8455, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 32  Rolling back to Epoch (base 0): 27  Top Validation Acc: 0.948051948051948
Fold [4/5] Epoch [0/100] Initial Loss: 0.1391, Training Loss: 0.1391, Initial Validation Loss: 0.1317, Validation Loss: 0.1317,V Acc: 0.3727, Top 70th Acc: 0.4156, Bottom 30th Acc: 0.2727
Fold [4/5] Epoch [10/100] Initial Loss: 0.1391, Training Loss: 0.0299, Initial Validation Loss: 0.1317, Validation Loss: 0.0413,V Acc: 0.8091, Top 70th Acc: 0.8961, Bottom 30th Acc: 0.6061
Fold [4/5] Epoch [20/100] Initial Loss: 0.1391, Training Loss: 0.0182, Initial Validation Loss: 0.1317, Validation Loss: 0.0342,V Acc: 0.7909, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.4848
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.922077922077922
78 3 [array([0.71048594, 0.0820443 , 0.03951583, 0.05006586, 0.11788795],
      dtype=float32)]
Fold [5/5] Epoch [0/100] Initial Loss: 0.1391, Training Loss: 0.1391, Initial Validation Loss: 0.1307, Validation Loss: 0.1307,V Acc: 0.4074, Top 70th Acc: 0.5000, Bottom 30th Acc: 0.1875
Fold [5/5] Epoch [10/100] Initial Loss: 0.1391, Training Loss: 0.0389, Initial Validation Loss: 0.1307, Validation Loss: 0.0423,V Acc: 0.7778, Top 70th Acc: 0.9079, Bottom 30th Acc: 0.4688
Fold [5/5] Epoch [20/100] Initial Loss: 0.1391, Training Loss: 0.0198, Initial Validation Loss: 0.1307, Validation Loss: 0.0324,V Acc: 0.8333, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.5938
Fold [5/5] Epoch [30/100] Initial Loss: 0.1391, Training Loss: 0.0171, Initial Validation Loss: 0.1307, Validation Loss: 0.0330,V Acc: 0.8148, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.5000
Stopping early at Epoch (base 0): 31  Rolling back to Epoch (base 0): 26  Top Validation Acc: 0.9342105263157895
Running train_nn.py with seed 79
CUDA:False
Training samples count:  550
Training on 30 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1356, Training Loss: 0.1356, Initial Validation Loss: 0.1321, Validation Loss: 0.1321,V Acc: 0.2973, Top 70th Acc: 0.3718, Bottom 30th Acc: 0.1212
Fold [1/5] Epoch [10/100] Initial Loss: 0.1356, Training Loss: 0.0389, Initial Validation Loss: 0.1321, Validation Loss: 0.0482,V Acc: 0.7838, Top 70th Acc: 0.8846, Bottom 30th Acc: 0.5455
Fold [1/5] Epoch [20/100] Initial Loss: 0.1356, Training Loss: 0.0196, Initial Validation Loss: 0.1321, Validation Loss: 0.0356,V Acc: 0.8468, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 27  Rolling back to Epoch (base 0): 22  Top Validation Acc: 0.9230769230769231
Fold [2/5] Epoch [0/100] Initial Loss: 0.1356, Training Loss: 0.1356, Initial Validation Loss: 0.1361, Validation Loss: 0.1361,V Acc: 0.2793, Top 70th Acc: 0.3590, Bottom 30th Acc: 0.0909
Fold [2/5] Epoch [10/100] Initial Loss: 0.1356, Training Loss: 0.0399, Initial Validation Loss: 0.1361, Validation Loss: 0.0431,V Acc: 0.8288, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.5758
Fold [2/5] Epoch [20/100] Initial Loss: 0.1356, Training Loss: 0.0193, Initial Validation Loss: 0.1361, Validation Loss: 0.0339,V Acc: 0.8108, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.9102564102564102
Fold [3/5] Epoch [0/100] Initial Loss: 0.1393, Training Loss: 0.1393, Initial Validation Loss: 0.1327, Validation Loss: 0.1327,V Acc: 0.3091, Top 70th Acc: 0.3247, Bottom 30th Acc: 0.2727
Fold [3/5] Epoch [10/100] Initial Loss: 0.1393, Training Loss: 0.0338, Initial Validation Loss: 0.1327, Validation Loss: 0.0350,V Acc: 0.8091, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.5758
Fold [3/5] Epoch [20/100] Initial Loss: 0.1393, Training Loss: 0.0182, Initial Validation Loss: 0.1327, Validation Loss: 0.0265,V Acc: 0.8545, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 27  Rolling back to Epoch (base 0): 22  Top Validation Acc: 0.935064935064935
Fold [4/5] Epoch [0/100] Initial Loss: 0.1456, Training Loss: 0.1456, Initial Validation Loss: 0.1353, Validation Loss: 0.1353,V Acc: 0.2909, Top 70th Acc: 0.3117, Bottom 30th Acc: 0.2424
Fold [4/5] Epoch [10/100] Initial Loss: 0.1456, Training Loss: 0.0417, Initial Validation Loss: 0.1353, Validation Loss: 0.0508,V Acc: 0.7909, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.5152
Fold [4/5] Epoch [20/100] Initial Loss: 0.1456, Training Loss: 0.0181, Initial Validation Loss: 0.1353, Validation Loss: 0.0338,V Acc: 0.8636, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.961038961038961
Fold [5/5] Epoch [0/100] Initial Loss: 0.1431, Training Loss: 0.1431, Initial Validation Loss: 0.1340, Validation Loss: 0.1340,V Acc: 0.2685, Top 70th Acc: 0.3158, Bottom 30th Acc: 0.1562
Fold [5/5] Epoch [10/100] Initial Loss: 0.1431, Training Loss: 0.0450, Initial Validation Loss: 0.1340, Validation Loss: 0.0454,V Acc: 0.7870, Top 70th Acc: 0.8947, Bottom 30th Acc: 0.5312
Fold [5/5] Epoch [20/100] Initial Loss: 0.1431, Training Loss: 0.0220, Initial Validation Loss: 0.1340, Validation Loss: 0.0253,V Acc: 0.8796, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.7188
Fold [5/5] Epoch [30/100] Initial Loss: 0.1431, Training Loss: 0.0179, Initial Validation Loss: 0.1340, Validation Loss: 0.0242,V Acc: 0.8889, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.7188
Stopping early at Epoch (base 0): 32  Rolling back to Epoch (base 0): 27  Top Validation Acc: 0.9736842105263158
79 4 [array([0.5430508 , 0.07696924, 0.05275242, 0.11808412, 0.20914336],
      dtype=float32)]
Running train_nn.py with seed 80
CUDA:False
Training samples count:  550
Training on 30 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1424, Training Loss: 0.1424, Initial Validation Loss: 0.1366, Validation Loss: 0.1366,V Acc: 0.3514, Top 70th Acc: 0.4231, Bottom 30th Acc: 0.1818
Fold [1/5] Epoch [10/100] Initial Loss: 0.1424, Training Loss: 0.0287, Initial Validation Loss: 0.1366, Validation Loss: 0.0341,V Acc: 0.8559, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.5758
Fold [1/5] Epoch [20/100] Initial Loss: 0.1424, Training Loss: 0.0178, Initial Validation Loss: 0.1366, Validation Loss: 0.0300,V Acc: 0.8649, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.6364
Fold [1/5] Epoch [30/100] Initial Loss: 0.1424, Training Loss: 0.0150, Initial Validation Loss: 0.1366, Validation Loss: 0.0305,V Acc: 0.8559, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.6364
Fold [5/5] Epoch [30/100] Initial Loss: 0.1412, Training Loss: 0.0040, Initial Validation Loss: 0.1318, Validation Loss: 0.0314,V Acc: 0.8333, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.5312
Fold [5/5] Epoch [40/100] Initial Loss: 0.1412, Training Loss: 0.0037, Initial Validation Loss: 0.1318, Validation Loss: 0.0312,V Acc: 0.8333, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.5312
Stopping early at Epoch (base 0): 40  Rolling back to Epoch (base 0): 35  Top Validation Acc: 0.9605263157894737
59 4 [array([0.28747022, 0.05514467, 0.05005207, 0.28414705, 0.32318595],
      dtype=float32)]
Running train_nn.py with seed 60
CUDA:False
Training samples count:  550
Training on 163 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1379, Training Loss: 0.1379, Initial Validation Loss: 0.1351, Validation Loss: 0.1351,V Acc: 0.2523, Top 70th Acc: 0.3462, Bottom 30th Acc: 0.0303
Fold [1/5] Epoch [10/100] Initial Loss: 0.1379, Training Loss: 0.0133, Initial Validation Loss: 0.1351, Validation Loss: 0.0303,V Acc: 0.8829, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.6970
Fold [1/5] Epoch [20/100] Initial Loss: 0.1379, Training Loss: 0.0047, Initial Validation Loss: 0.1351, Validation Loss: 0.0281,V Acc: 0.8829, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.9615384615384616
Fold [2/5] Epoch [0/100] Initial Loss: 0.1432, Training Loss: 0.1432, Initial Validation Loss: 0.1390, Validation Loss: 0.1390,V Acc: 0.2523, Top 70th Acc: 0.3205, Bottom 30th Acc: 0.0909
Fold [2/5] Epoch [10/100] Initial Loss: 0.1432, Training Loss: 0.0152, Initial Validation Loss: 0.1390, Validation Loss: 0.0321,V Acc: 0.8559, Top 70th Acc: 0.9872, Bottom 30th Acc: 0.5455
Fold [2/5] Epoch [20/100] Initial Loss: 0.1432, Training Loss: 0.0052, Initial Validation Loss: 0.1390, Validation Loss: 0.0314,V Acc: 0.8378, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.9615384615384616
Fold [3/5] Epoch [0/100] Initial Loss: 0.1397, Training Loss: 0.1397, Initial Validation Loss: 0.1327, Validation Loss: 0.1327,V Acc: 0.4364, Top 70th Acc: 0.5714, Bottom 30th Acc: 0.1212
Fold [3/5] Epoch [10/100] Initial Loss: 0.1397, Training Loss: 0.0137, Initial Validation Loss: 0.1327, Validation Loss: 0.0345,V Acc: 0.8182, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.5152
Fold [3/5] Epoch [20/100] Initial Loss: 0.1397, Training Loss: 0.0052, Initial Validation Loss: 0.1327, Validation Loss: 0.0326,V Acc: 0.8364, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.922077922077922
60 2 [array([0.24716866, 0.07312096, 0.06505756, 0.15773578, 0.45691708],
      dtype=float32)]
Fold [4/5] Epoch [0/100] Initial Loss: 0.1393, Training Loss: 0.1393, Initial Validation Loss: 0.1325, Validation Loss: 0.1325,V Acc: 0.4091, Top 70th Acc: 0.4416, Bottom 30th Acc: 0.3333
Fold [4/5] Epoch [10/100] Initial Loss: 0.1393, Training Loss: 0.0132, Initial Validation Loss: 0.1325, Validation Loss: 0.0351,V Acc: 0.8182, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.5455
Fold [4/5] Epoch [20/100] Initial Loss: 0.1393, Training Loss: 0.0046, Initial Validation Loss: 0.1325, Validation Loss: 0.0327,V Acc: 0.8273, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.5758
Fold [4/5] Epoch [30/100] Initial Loss: 0.1393, Training Loss: 0.0037, Initial Validation Loss: 0.1325, Validation Loss: 0.0318,V Acc: 0.8182, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.5455
Fold [4/5] Epoch [40/100] Initial Loss: 0.1393, Training Loss: 0.0035, Initial Validation Loss: 0.1325, Validation Loss: 0.0311,V Acc: 0.8364, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.6061
Fold [4/5] Epoch [50/100] Initial Loss: 0.1393, Training Loss: 0.0034, Initial Validation Loss: 0.1325, Validation Loss: 0.0312,V Acc: 0.8364, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 50  Rolling back to Epoch (base 0): 45  Top Validation Acc: 0.935064935064935
Fold [5/5] Epoch [0/100] Initial Loss: 0.1418, Training Loss: 0.1418, Initial Validation Loss: 0.1318, Validation Loss: 0.1318,V Acc: 0.2500, Top 70th Acc: 0.3026, Bottom 30th Acc: 0.1250
Fold [5/5] Epoch [10/100] Initial Loss: 0.1418, Training Loss: 0.0206, Initial Validation Loss: 0.1318, Validation Loss: 0.0306,V Acc: 0.8796, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.7188
Fold [5/5] Epoch [20/100] Initial Loss: 0.1418, Training Loss: 0.0056, Initial Validation Loss: 0.1318, Validation Loss: 0.0219,V Acc: 0.8796, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.6875
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.9736842105263158
Running train_nn.py with seed 61
CUDA:False
Training samples count:  550
Training on 163 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1396, Training Loss: 0.1396, Initial Validation Loss: 0.1332, Validation Loss: 0.1332,V Acc: 0.3784, Top 70th Acc: 0.4744, Bottom 30th Acc: 0.1515
Fold [1/5] Epoch [10/100] Initial Loss: 0.1396, Training Loss: 0.0110, Initial Validation Loss: 0.1332, Validation Loss: 0.0331,V Acc: 0.8018, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.4242
Fold [1/5] Epoch [20/100] Initial Loss: 0.1396, Training Loss: 0.0044, Initial Validation Loss: 0.1332, Validation Loss: 0.0301,V Acc: 0.8288, Top 70th Acc: 0.9872, Bottom 30th Acc: 0.4545
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.9871794871794872
Fold [2/5] Epoch [0/100] Initial Loss: 0.1398, Training Loss: 0.1398, Initial Validation Loss: 0.1370, Validation Loss: 0.1370,V Acc: 0.3964, Top 70th Acc: 0.4487, Bottom 30th Acc: 0.2727
Fold [2/5] Epoch [10/100] Initial Loss: 0.1398, Training Loss: 0.0202, Initial Validation Loss: 0.1370, Validation Loss: 0.0370,V Acc: 0.8739, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.7576
Fold [2/5] Epoch [20/100] Initial Loss: 0.1398, Training Loss: 0.0052, Initial Validation Loss: 0.1370, Validation Loss: 0.0321,V Acc: 0.8468, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 22  Rolling back to Epoch (base 0): 17  Top Validation Acc: 0.9230769230769231
Fold [3/5] Epoch [0/100] Initial Loss: 0.1376, Training Loss: 0.1376, Initial Validation Loss: 0.1341, Validation Loss: 0.1341,V Acc: 0.4636, Top 70th Acc: 0.5714, Bottom 30th Acc: 0.2121
Fold [3/5] Epoch [10/100] Initial Loss: 0.1376, Training Loss: 0.0148, Initial Validation Loss: 0.1341, Validation Loss: 0.0358,V Acc: 0.8364, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.5758
Fold [3/5] Epoch [20/100] Initial Loss: 0.1376, Training Loss: 0.0043, Initial Validation Loss: 0.1341, Validation Loss: 0.0299,V Acc: 0.8273, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.5152
Stopping early at Epoch (base 0): 27  Rolling back to Epoch (base 0): 22  Top Validation Acc: 0.961038961038961
Fold [4/5] Epoch [0/100] Initial Loss: 0.1377, Training Loss: 0.1377, Initial Validation Loss: 0.1373, Validation Loss: 0.1373,V Acc: 0.2455, Top 70th Acc: 0.2857, Bottom 30th Acc: 0.1515
Fold [4/5] Epoch [10/100] Initial Loss: 0.1377, Training Loss: 0.0180, Initial Validation Loss: 0.1373, Validation Loss: 0.0389,V Acc: 0.8455, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.6364
Fold [4/5] Epoch [20/100] Initial Loss: 0.1377, Training Loss: 0.0055, Initial Validation Loss: 0.1373, Validation Loss: 0.0336,V Acc: 0.8182, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.4545
Fold [4/5] Epoch [30/100] Initial Loss: 0.1377, Training Loss: 0.0040, Initial Validation Loss: 0.1373, Validation Loss: 0.0318,V Acc: 0.8273, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.4848
Fold [4/5] Epoch [40/100] Initial Loss: 0.1377, Training Loss: 0.0037, Initial Validation Loss: 0.1373, Validation Loss: 0.0294,V Acc: 0.8545, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.5758
Fold [4/5] Epoch [50/100] Initial Loss: 0.1377, Training Loss: 0.0035, Initial Validation Loss: 0.1373, Validation Loss: 0.0279,V Acc: 0.8545, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.5758
Fold [4/5] Epoch [60/100] Initial Loss: 0.1377, Training Loss: 0.0033, Initial Validation Loss: 0.1373, Validation Loss: 0.0269,V Acc: 0.8545, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.5758/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)

Fold [1/5] Epoch [20/100] Initial Loss: 0.1376, Training Loss: 0.0236, Initial Validation Loss: 0.1321, Validation Loss: 0.0298,V Acc: 0.8559, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 27  Rolling back to Epoch (base 0): 22  Top Validation Acc: 0.9615384615384616
Fold [2/5] Epoch [0/100] Initial Loss: 0.1426, Training Loss: 0.1426, Initial Validation Loss: 0.1386, Validation Loss: 0.1386,V Acc: 0.2342, Top 70th Acc: 0.2436, Bottom 30th Acc: 0.2121
Fold [2/5] Epoch [10/100] Initial Loss: 0.1426, Training Loss: 0.0346, Initial Validation Loss: 0.1386, Validation Loss: 0.0418,V Acc: 0.8468, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.6061
Fold [2/5] Epoch [20/100] Initial Loss: 0.1426, Training Loss: 0.0234, Initial Validation Loss: 0.1386, Validation Loss: 0.0351,V Acc: 0.8559, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.6970
Fold [2/5] Epoch [30/100] Initial Loss: 0.1426, Training Loss: 0.0212, Initial Validation Loss: 0.1386, Validation Loss: 0.0344,V Acc: 0.8198, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 30  Rolling back to Epoch (base 0): 25  Top Validation Acc: 0.9358974358974359
Fold [3/5] Epoch [0/100] Initial Loss: 0.1363, Training Loss: 0.1363, Initial Validation Loss: 0.1244, Validation Loss: 0.1244,V Acc: 0.4182, Top 70th Acc: 0.5325, Bottom 30th Acc: 0.1515
Fold [3/5] Epoch [10/100] Initial Loss: 0.1363, Training Loss: 0.0335, Initial Validation Loss: 0.1244, Validation Loss: 0.0367,V Acc: 0.8091, Top 70th Acc: 0.8961, Bottom 30th Acc: 0.6061
Fold [3/5] Epoch [20/100] Initial Loss: 0.1363, Training Loss: 0.0231, Initial Validation Loss: 0.1244, Validation Loss: 0.0298,V Acc: 0.8273, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.935064935064935
Fold [4/5] Epoch [0/100] Initial Loss: 0.1345, Training Loss: 0.1345, Initial Validation Loss: 0.1284, Validation Loss: 0.1284,V Acc: 0.3727, Top 70th Acc: 0.4286, Bottom 30th Acc: 0.2424
Fold [4/5] Epoch [10/100] Initial Loss: 0.1345, Training Loss: 0.0271, Initial Validation Loss: 0.1284, Validation Loss: 0.0478,V Acc: 0.7545, Top 70th Acc: 0.8571, Bottom 30th Acc: 0.5152
Fold [4/5] Epoch [20/100] Initial Loss: 0.1345, Training Loss: 0.0202, Initial Validation Loss: 0.1284, Validation Loss: 0.0467,V Acc: 0.7364, Top 70th Acc: 0.8571, Bottom 30th Acc: 0.4545
Stopping early at Epoch (base 0): 22  Rolling back to Epoch (base 0): 17  Top Validation Acc: 0.8441558441558441
Fold [5/5] Epoch [0/100] Initial Loss: 0.1382, Training Loss: 0.1382, Initial Validation Loss: 0.1313, Validation Loss: 0.1313,V Acc: 0.4722, Top 70th Acc: 0.5395, Bottom 30th Acc: 0.3125
Fold [5/5] Epoch [10/100] Initial Loss: 0.1382, Training Loss: 0.0459, Initial Validation Loss: 0.1313, Validation Loss: 0.0458,V Acc: 0.7963, Top 70th Acc: 0.8947, Bottom 30th Acc: 0.5625
Fold [5/5] Epoch [20/100] Initial Loss: 0.1382, Training Loss: 0.0261, Initial Validation Loss: 0.1313, Validation Loss: 0.0272,V Acc: 0.8889, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.7188
Fold [5/5] Epoch [30/100] Initial Loss: 0.1382, Training Loss: 0.0219, Initial Validation Loss: 0.1313, Validation Loss: 0.0262,V Acc: 0.8889, Top 70th Acc: 0.9737, Bottom 30th Acc: 0.6875
Stopping early at Epoch (base 0): 32  Rolling back to Epoch (base 0): 27  Top Validation Acc: 0.9736842105263158
80 4 [array([0.32478333, 0.04958764, 0.21801375, 0.28063652, 0.12697868],
      dtype=float32)]
Running train_nn.py with seed 81
CUDA:False
Training samples count:  550
Training on 20 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1388, Training Loss: 0.1388, Initial Validation Loss: 0.1330, Validation Loss: 0.1330,V Acc: 0.3784, Top 70th Acc: 0.4487, Bottom 30th Acc: 0.2121
Fold [1/5] Epoch [10/100] Initial Loss: 0.1388, Training Loss: 0.0369, Initial Validation Loss: 0.1330, Validation Loss: 0.0428,V Acc: 0.7928, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.5152
Fold [1/5] Epoch [20/100] Initial Loss: 0.1388, Training Loss: 0.0240, Initial Validation Loss: 0.1330, Validation Loss: 0.0338,V Acc: 0.8468, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.6667
Fold [1/5] Epoch [30/100] Initial Loss: 0.1388, Training Loss: 0.0219, Initial Validation Loss: 0.1330, Validation Loss: 0.0333,V Acc: 0.8468, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 38  Rolling back to Epoch (base 0): 33  Top Validation Acc: 0.9487179487179487
Fold [2/5] Epoch [0/100] Initial Loss: 0.1419, Training Loss: 0.1419, Initial Validation Loss: 0.1334, Validation Loss: 0.1334,V Acc: 0.2703, Top 70th Acc: 0.3333, Bottom 30th Acc: 0.1212
Fold [2/5] Epoch [10/100] Initial Loss: 0.1419, Training Loss: 0.0459, Initial Validation Loss: 0.1334, Validation Loss: 0.0573,V Acc: 0.7117, Top 70th Acc: 0.8205, Bottom 30th Acc: 0.4545
Fold [2/5] Epoch [20/100] Initial Loss: 0.1419, Training Loss: 0.0241, Initial Validation Loss: 0.1334, Validation Loss: 0.0420,V Acc: 0.7928, Top 70th Acc: 0.8846, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.8974358974358975
Fold [3/5] Epoch [0/100] Initial Loss: 0.1418, Training Loss: 0.1418, Initial Validation Loss: 0.1355, Validation Loss: 0.1355,V Acc: 0.3273, Top 70th Acc: 0.3766, Bottom 30th Acc: 0.2121
Fold [3/5] Epoch [10/100] Initial Loss: 0.1418, Training Loss: 0.0435, Initial Validation Loss: 0.1355, Validation Loss: 0.0420,V Acc: 0.8455, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.6364
Fold [3/5] Epoch [20/100] Initial Loss: 0.1418, Training Loss: 0.0251, Initial Validation Loss: 0.1355, Validation Loss: 0.0341,V Acc: 0.8455, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.948051948051948
Fold [4/5] Epoch [0/100] Initial Loss: 0.1445, Training Loss: 0.1445, Initial Validation Loss: 0.1353, Validation Loss: 0.1353,V Acc: 0.2636, Top 70th Acc: 0.2987, Bottom 30th Acc: 0.1818
Fold [4/5] Epoch [10/100] Initial Loss: 0.1445, Training Loss: 0.0441, Initial Validation Loss: 0.1353, Validation Loss: 0.0437,V Acc: 0.8455, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.6970
Fold [4/5] Epoch [20/100] Initial Loss: 0.1445, Training Loss: 0.0260, Initial Validation Loss: 0.1353, Validation Loss: 0.0310,V Acc: 0.8636, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.7273
Fold [4/5] Epoch [30/100] Initial Loss: 0.1445, Training Loss: 0.0235, Initial Validation Loss: 0.1353, Validation Loss: 0.0298,V Acc: 0.8455, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.6970
Fold [4/5] Epoch [40/100] Initial Loss: 0.1445, Training Loss: 0.0221, Initial Validation Loss: 0.1353, Validation Loss: 0.0296,V Acc: 0.8455, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 40  Rolling back to Epoch (base 0): 35  Top Validation Acc: 0.922077922077922
81 3 [array([0.49017558, 0.06359021, 0.07847257, 0.13895117, 0.22881041],
      dtype=float32)]
Fold [5/5] Epoch [0/100] Initial Loss: 0.1391, Training Loss: 0.1391, Initial Validation Loss: 0.1323, Validation Loss: 0.1323,V Acc: 0.3611, Top 70th Acc: 0.4342, Bottom 30th Acc: 0.1875
Fold [5/5] Epoch [10/100] Initial Loss: 0.1391, Training Loss: 0.0365, Initial Validation Loss: 0.1323, Validation Loss: 0.0456,V Acc: 0.8056, Top 70th Acc: 0.9079, Bottom 30th Acc: 0.5625
Fold [5/5] Epoch [20/100] Initial Loss: 0.1391, Training Loss: 0.0256, Initial Validation Loss: 0.1323, Validation Loss: 0.0373,V Acc: 0.8056, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.5000
Stopping early at Epoch (base 0): 28  Rolling back to Epoch (base 0): 23  Top Validation Acc: 0.9473684210526315
Running train_nn.py with seed 82
CUDA:False
Training samples count:  550
Training on 20 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1415, Training Loss: 0.1415, Initial Validation Loss: 0.1321, Validation Loss: 0.1321,V Acc: 0.2523, Top 70th Acc: 0.3077, Bottom 30th Acc: 0.1212
Fold [1/5] Epoch [10/100] Initial Loss: 0.1415, Training Loss: 0.0337, Initial Validation Loss: 0.1321, Validation Loss: 0.0435,V Acc: 0.8108, Top 70th Acc: 0.8846, Bottom 30th Acc: 0.6364
Fold [1/5] Epoch [20/100] Initial Loss: 0.1415, Training Loss: 0.0231, Initial Validation Loss: 0.1321, Validation Loss: 0.0348,V Acc: 0.8378, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 45  Rolling back to Epoch (base 0): 40  Top Validation Acc: 0.9342105263157895
77 4 [array([0.42945096, 0.05694683, 0.05835459, 0.17087315, 0.28437456],
      dtype=float32)]
Running train_nn.py with seed 78
CUDA:False
Training samples count:  550
Training on 40 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1372, Training Loss: 0.1372, Initial Validation Loss: 0.1365, Validation Loss: 0.1365,V Acc: 0.2793, Top 70th Acc: 0.3590, Bottom 30th Acc: 0.0909
Fold [1/5] Epoch [10/100] Initial Loss: 0.1372, Training Loss: 0.0332, Initial Validation Loss: 0.1365, Validation Loss: 0.0450,V Acc: 0.7838, Top 70th Acc: 0.8974, Bottom 30th Acc: 0.5152
Fold [1/5] Epoch [20/100] Initial Loss: 0.1372, Training Loss: 0.0159, Initial Validation Loss: 0.1365, Validation Loss: 0.0327,V Acc: 0.8559, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.9615384615384616
Fold [2/5] Epoch [0/100] Initial Loss: 0.1385, Training Loss: 0.1385, Initial Validation Loss: 0.1361, Validation Loss: 0.1361,V Acc: 0.3423, Top 70th Acc: 0.3846, Bottom 30th Acc: 0.2424
Fold [2/5] Epoch [10/100] Initial Loss: 0.1385, Training Loss: 0.0243, Initial Validation Loss: 0.1361, Validation Loss: 0.0410,V Acc: 0.7748, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.4545
Fold [2/5] Epoch [20/100] Initial Loss: 0.1385, Training Loss: 0.0135, Initial Validation Loss: 0.1361, Validation Loss: 0.0378,V Acc: 0.7838, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.4545
Stopping early at Epoch (base 0): 20  Rolling back to Epoch (base 0): 15  Top Validation Acc: 0.9230769230769231
Fold [3/5] Epoch [0/100] Initial Loss: 0.1396, Training Loss: 0.1396, Initial Validation Loss: 0.1383, Validation Loss: 0.1383,V Acc: 0.2455, Top 70th Acc: 0.1948, Bottom 30th Acc: 0.3636
Fold [3/5] Epoch [10/100] Initial Loss: 0.1396, Training Loss: 0.0279, Initial Validation Loss: 0.1383, Validation Loss: 0.0342,V Acc: 0.8636, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.6364
Fold [3/5] Epoch [20/100] Initial Loss: 0.1396, Training Loss: 0.0148, Initial Validation Loss: 0.1383, Validation Loss: 0.0277,V Acc: 0.9000, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.7576
Stopping early at Epoch (base 0): 27  Rolling back to Epoch (base 0): 22  Top Validation Acc: 0.961038961038961
Fold [4/5] Epoch [0/100] Initial Loss: 0.1380, Training Loss: 0.1380, Initial Validation Loss: 0.1287, Validation Loss: 0.1287,V Acc: 0.4091, Top 70th Acc: 0.4675, Bottom 30th Acc: 0.2727
Fold [4/5] Epoch [10/100] Initial Loss: 0.1380, Training Loss: 0.0293, Initial Validation Loss: 0.1287, Validation Loss: 0.0386,V Acc: 0.8000, Top 70th Acc: 0.8701, Bottom 30th Acc: 0.6364
Fold [4/5] Epoch [20/100] Initial Loss: 0.1380, Training Loss: 0.0136, Initial Validation Loss: 0.1287, Validation Loss: 0.0312,V Acc: 0.8364, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.922077922077922
78 3 [array([0.74942476, 0.08239652, 0.04000913, 0.05891911, 0.0692505 ],
      dtype=float32)]
Fold [5/5] Epoch [0/100] Initial Loss: 0.1379, Training Loss: 0.1379, Initial Validation Loss: 0.1294, Validation Loss: 0.1294,V Acc: 0.3333, Top 70th Acc: 0.4079, Bottom 30th Acc: 0.1562
Fold [5/5] Epoch [10/100] Initial Loss: 0.1379, Training Loss: 0.0288, Initial Validation Loss: 0.1294, Validation Loss: 0.0373,V Acc: 0.8148, Top 70th Acc: 0.8947, Bottom 30th Acc: 0.6250
Fold [5/5] Epoch [20/100] Initial Loss: 0.1379, Training Loss: 0.0146, Initial Validation Loss: 0.1294, Validation Loss: 0.0347,V Acc: 0.7778, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.4062
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.9078947368421053
Running train_nn.py with seed 79
CUDA:False
Training samples count:  550
Training on 40 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1372, Training Loss: 0.1372, Initial Validation Loss: 0.1319, Validation Loss: 0.1319,V Acc: 0.2613, Top 70th Acc: 0.3333, Bottom 30th Acc: 0.0909
Fold [1/5] Epoch [10/100] Initial Loss: 0.1372, Training Loss: 0.0257, Initial Validation Loss: 0.1319, Validation Loss: 0.0373,V Acc: 0.8108, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 15  Rolling back to Epoch (base 0): 10  Top Validation Acc: 0.9230769230769231
Fold [2/5] Epoch [0/100] Initial Loss: 0.1375, Training Loss: 0.1375, Initial Validation Loss: 0.1371, Validation Loss: 0.1371,V Acc: 0.2523, Top 70th Acc: 0.3077, Bottom 30th Acc: 0.1212
Fold [2/5] Epoch [10/100] Initial Loss: 0.1375, Training Loss: 0.0275, Initial Validation Loss: 0.1371, Validation Loss: 0.0354,V Acc: 0.8559, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.6667
Fold [2/5] Epoch [20/100] Initial Loss: 0.1375, Training Loss: 0.0146, Initial Validation Loss: 0.1371, Validation Loss: 0.0313,V Acc: 0.8559, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 21  Rolling back to Epoch (base 0): 16  Top Validation Acc: 0.9102564102564102
Fold [3/5] Epoch [0/100] Initial Loss: 0.1375, Training Loss: 0.1375, Initial Validation Loss: 0.1282, Validation Loss: 0.1282,V Acc: 0.4818, Top 70th Acc: 0.5974, Bottom 30th Acc: 0.2121
Fold [3/5] Epoch [10/100] Initial Loss: 0.1375, Training Loss: 0.0289, Initial Validation Loss: 0.1282, Validation Loss: 0.0354,V Acc: 0.8091, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.4848
Fold [3/5] Epoch [20/100] Initial Loss: 0.1375, Training Loss: 0.0145, Initial Validation Loss: 0.1282, Validation Loss: 0.0297,V Acc: 0.8455, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 27  Rolling back to Epoch (base 0): 22  Top Validation Acc: 0.935064935064935
Fold [4/5] Epoch [0/100] Initial Loss: 0.1381, Training Loss: 0.1381, Initial Validation Loss: 0.1323, Validation Loss: 0.1323,V Acc: 0.2818, Top 70th Acc: 0.3636, Bottom 30th Acc: 0.0909
Fold [4/5] Epoch [10/100] Initial Loss: 0.1381, Training Loss: 0.0248, Initial Validation Loss: 0.1323, Validation Loss: 0.0398,V Acc: 0.8182, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.5152
Fold [4/5] Epoch [20/100] Initial Loss: 0.1381, Training Loss: 0.0138, Initial Validation Loss: 0.1323, Validation Loss: 0.0341,V Acc: 0.8455, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.948051948051948
Fold [5/5] Epoch [0/100] Initial Loss: 0.1408, Training Loss: 0.1408, Initial Validation Loss: 0.1323, Validation Loss: 0.1323,V Acc: 0.2500, Top 70th Acc: 0.3289, Bottom 30th Acc: 0.0625
Fold [5/5] Epoch [10/100] Initial Loss: 0.1408, Training Loss: 0.0339, Initial Validation Loss: 0.1323, Validation Loss: 0.0358,V Acc: 0.8333, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.5938
Fold [5/5] Epoch [20/100] Initial Loss: 0.1408, Training Loss: 0.0160, Initial Validation Loss: 0.1323, Validation Loss: 0.0272,V Acc: 0.8611, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.6562
Fold [5/5] Epoch [30/100] Initial Loss: 0.1408, Training Loss: 0.0122, Initial Validation Loss: 0.1323, Validation Loss: 0.0268,V Acc: 0.8796, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.6875
Stopping early at Epoch (base 0): 31  Rolling back to Epoch (base 0): 26  Top Validation Acc: 0.9605263157894737
79 4 [array([0.5433801 , 0.08888017, 0.0630357 , 0.0715344 , 0.2331696 ],
      dtype=float32)]
Running train_nn.py with seed 80
CUDA:False
Training samples count:  550
Training on 40 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1425, Training Loss: 0.1425, Initial Validation Loss: 0.1379, Validation Loss: 0.1379,V Acc: 0.3153, Top 70th Acc: 0.3077, Bottom 30th Acc: 0.3333
Fold [1/5] Epoch [10/100] Initial Loss: 0.1425, Training Loss: 0.0407, Initial Validation Loss: 0.1379, Validation Loss: 0.0509,V Acc: 0.7387, Top 70th Acc: 0.8718, Bottom 30th Acc: 0.4242
Fold [1/5] Epoch [20/100] Initial Loss: 0.1425, Training Loss: 0.0162, Initial Validation Loss: 0.1379, Validation Loss: 0.0287,V Acc: 0.8649, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.6061
Fold [1/5] Epoch [30/100] Initial Loss: 0.1425, Training Loss: 0.0127, Initial Validation Loss: 0.1379, Validation Loss: 0.0288,V Acc: 0.8559, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 20  Rolling back to Epoch (base 0): 15  Top Validation Acc: 0.7662337662337663
Fold [4/5] Epoch [0/100] Initial Loss: 0.1430, Training Loss: 0.1430, Initial Validation Loss: 0.1241, Validation Loss: 0.1241,V Acc: 0.4182, Top 70th Acc: 0.4416, Bottom 30th Acc: 0.3636
Fold [4/5] Epoch [10/100] Initial Loss: 0.1430, Training Loss: 0.0820, Initial Validation Loss: 0.1241, Validation Loss: 0.0763,V Acc: 0.6727, Top 70th Acc: 0.7013, Bottom 30th Acc: 0.6061
Fold [4/5] Epoch [20/100] Initial Loss: 0.1430, Training Loss: 0.0795, Initial Validation Loss: 0.1241, Validation Loss: 0.0745,V Acc: 0.6636, Top 70th Acc: 0.7273, Bottom 30th Acc: 0.5152
Fold [4/5] Epoch [30/100] Initial Loss: 0.1430, Training Loss: 0.0785, Initial Validation Loss: 0.1241, Validation Loss: 0.0740,V Acc: 0.6364, Top 70th Acc: 0.7143, Bottom 30th Acc: 0.4545
Stopping early at Epoch (base 0): 37  Rolling back to Epoch (base 0): 32  Top Validation Acc: 0.7142857142857143
Fold [5/5] Epoch [0/100] Initial Loss: 0.1370, Training Loss: 0.1370, Initial Validation Loss: 0.1300, Validation Loss: 0.1300,V Acc: 0.3796, Top 70th Acc: 0.5000, Bottom 30th Acc: 0.0938
Fold [5/5] Epoch [10/100] Initial Loss: 0.1370, Training Loss: 0.0802, Initial Validation Loss: 0.1300, Validation Loss: 0.0801,V Acc: 0.6019, Top 70th Acc: 0.7368, Bottom 30th Acc: 0.2812
Fold [5/5] Epoch [20/100] Initial Loss: 0.1370, Training Loss: 0.0783, Initial Validation Loss: 0.1300, Validation Loss: 0.0782,V Acc: 0.5926, Top 70th Acc: 0.7500, Bottom 30th Acc: 0.2188
Fold [5/5] Epoch [30/100] Initial Loss: 0.1370, Training Loss: 0.0776, Initial Validation Loss: 0.1300, Validation Loss: 0.0771,V Acc: 0.6019, Top 70th Acc: 0.7368, Bottom 30th Acc: 0.2812
Stopping early at Epoch (base 0): 34  Rolling back to Epoch (base 0): 29  Top Validation Acc: 0.7368421052631579
75 4 [array([0.13248113, 0.37913382, 0.12077667, 0.23589355, 0.13171487],
      dtype=float32)]
Running train_nn.py with seed 76
CUDA:False
Training samples count:  550
Training on 2 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1390, Training Loss: 0.1390, Initial Validation Loss: 0.1365, Validation Loss: 0.1365,V Acc: 0.4144, Top 70th Acc: 0.5256, Bottom 30th Acc: 0.1515
Fold [1/5] Epoch [10/100] Initial Loss: 0.1390, Training Loss: 0.0824, Initial Validation Loss: 0.1365, Validation Loss: 0.0777,V Acc: 0.6577, Top 70th Acc: 0.7821, Bottom 30th Acc: 0.3636
Fold [1/5] Epoch [20/100] Initial Loss: 0.1390, Training Loss: 0.0802, Initial Validation Loss: 0.1365, Validation Loss: 0.0753,V Acc: 0.6667, Top 70th Acc: 0.7821, Bottom 30th Acc: 0.3939
Fold [1/5] Epoch [30/100] Initial Loss: 0.1390, Training Loss: 0.0796, Initial Validation Loss: 0.1365, Validation Loss: 0.0748,V Acc: 0.6667, Top 70th Acc: 0.7821, Bottom 30th Acc: 0.3939
Stopping early at Epoch (base 0): 34  Rolling back to Epoch (base 0): 29  Top Validation Acc: 0.7692307692307693
Fold [2/5] Epoch [0/100] Initial Loss: 0.1382, Training Loss: 0.1382, Initial Validation Loss: 0.1289, Validation Loss: 0.1289,V Acc: 0.3333, Top 70th Acc: 0.3333, Bottom 30th Acc: 0.3333
Fold [2/5] Epoch [10/100] Initial Loss: 0.1382, Training Loss: 0.0802, Initial Validation Loss: 0.1289, Validation Loss: 0.0851,V Acc: 0.6126, Top 70th Acc: 0.6923, Bottom 30th Acc: 0.4242
Fold [2/5] Epoch [20/100] Initial Loss: 0.1382, Training Loss: 0.0781, Initial Validation Loss: 0.1289, Validation Loss: 0.0830,V Acc: 0.6126, Top 70th Acc: 0.6923, Bottom 30th Acc: 0.4242
Fold [2/5] Epoch [30/100] Initial Loss: 0.1382, Training Loss: 0.0775, Initial Validation Loss: 0.1289, Validation Loss: 0.0824,V Acc: 0.6216, Top 70th Acc: 0.6923, Bottom 30th Acc: 0.4545
Stopping early at Epoch (base 0): 38  Rolling back to Epoch (base 0): 33  Top Validation Acc: 0.7051282051282052
Fold [3/5] Epoch [0/100] Initial Loss: 0.1297, Training Loss: 0.1297, Initial Validation Loss: 0.1232, Validation Loss: 0.1232,V Acc: 0.3727, Top 70th Acc: 0.4805, Bottom 30th Acc: 0.1212
Fold [3/5] Epoch [10/100] Initial Loss: 0.1297, Training Loss: 0.0838, Initial Validation Loss: 0.1232, Validation Loss: 0.0795,V Acc: 0.6545, Top 70th Acc: 0.7273, Bottom 30th Acc: 0.4848
Fold [3/5] Epoch [20/100] Initial Loss: 0.1297, Training Loss: 0.0810, Initial Validation Loss: 0.1232, Validation Loss: 0.0752,V Acc: 0.6636, Top 70th Acc: 0.7403, Bottom 30th Acc: 0.4848
Fold [3/5] Epoch [30/100] Initial Loss: 0.1297, Training Loss: 0.0802, Initial Validation Loss: 0.1232, Validation Loss: 0.0737,V Acc: 0.6727, Top 70th Acc: 0.7532, Bottom 30th Acc: 0.4848
Stopping early at Epoch (base 0): 39  Rolling back to Epoch (base 0): 34  Top Validation Acc: 0.7402597402597403
Fold [4/5] Epoch [0/100] Initial Loss: 0.1376, Training Loss: 0.1376, Initial Validation Loss: 0.1331, Validation Loss: 0.1331,V Acc: 0.2909, Top 70th Acc: 0.3636, Bottom 30th Acc: 0.1212
Fold [4/5] Epoch [10/100] Initial Loss: 0.1376, Training Loss: 0.0814, Initial Validation Loss: 0.1331, Validation Loss: 0.0777,V Acc: 0.6273, Top 70th Acc: 0.7403, Bottom 30th Acc: 0.3636
Stopping early at Epoch (base 0): 17  Rolling back to Epoch (base 0): 12  Top Validation Acc: 0.7272727272727273
76 3 [array([0.17171544, 0.34976172, 0.11567022, 0.19739637, 0.16545635],
      dtype=float32)]
Fold [5/5] Epoch [0/100] Initial Loss: 0.1319, Training Loss: 0.1319, Initial Validation Loss: 0.1188, Validation Loss: 0.1188,V Acc: 0.3796, Top 70th Acc: 0.3553, Bottom 30th Acc: 0.4375
Fold [5/5] Epoch [10/100] Initial Loss: 0.1319, Training Loss: 0.0771, Initial Validation Loss: 0.1188, Validation Loss: 0.0882,V Acc: 0.5370, Top 70th Acc: 0.6842, Bottom 30th Acc: 0.1875
Fold [5/5] Epoch [20/100] Initial Loss: 0.1319, Training Loss: 0.0753, Initial Validation Loss: 0.1188, Validation Loss: 0.0868,V Acc: 0.5741, Top 70th Acc: 0.6711, Bottom 30th Acc: 0.3438
Stopping early at Epoch (base 0): 21  Rolling back to Epoch (base 0): 16  Top Validation Acc: 0.6842105263157895
Running train_nn.py with seed 77
CUDA:False
Training samples count:  550
Training on 2 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1384, Training Loss: 0.1384, Initial Validation Loss: 0.1379, Validation Loss: 0.1379,V Acc: 0.2703, Top 70th Acc: 0.3590, Bottom 30th Acc: 0.0606
Fold [1/5] Epoch [10/100] Initial Loss: 0.1384, Training Loss: 0.0832, Initial Validation Loss: 0.1379, Validation Loss: 0.0765,V Acc: 0.6667, Top 70th Acc: 0.7821, Bottom 30th Acc: 0.3939
Fold [1/5] Epoch [20/100] Initial Loss: 0.1384, Training Loss: 0.0807, Initial Validation Loss: 0.1379, Validation Loss: 0.0730,V Acc: 0.7027, Top 70th Acc: 0.7821, Bottom 30th Acc: 0.5152
Fold [1/5] Epoch [30/100] Initial Loss: 0.1384, Training Loss: 0.0799, Initial Validation Loss: 0.1379, Validation Loss: 0.0722,V Acc: 0.6757, Top 70th Acc: 0.7692, Bottom 30th Acc: 0.4545
Stopping early at Epoch (base 0): 38  Rolling back to Epoch (base 0): 33  Top Validation Acc: 0.782051282051282
Fold [2/5] Epoch [0/100] Initial Loss: 0.1377, Training Loss: 0.1377, Initial Validation Loss: 0.1272, Validation Loss: 0.1272,V Acc: 0.4054, Top 70th Acc: 0.5128, Bottom 30th Acc: 0.1515
Fold [2/5] Epoch [10/100] Initial Loss: 0.1377, Training Loss: 0.0798, Initial Validation Loss: 0.1272, Validation Loss: 0.0827,V Acc: 0.5676, Top 70th Acc: 0.6923, Bottom 30th Acc: 0.2727
Fold [2/5] Epoch [20/100] Initial Loss: 0.1377, Training Loss: 0.0775, Initial Validation Loss: 0.1272, Validation Loss: 0.0821,V Acc: 0.5495, Top 70th Acc: 0.6923, Bottom 30th Acc: 0.2121
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.7051282051282052
Fold [3/5] Epoch [0/100] Initial Loss: 0.1372, Training Loss: 0.1372, Initial Validation Loss: 0.1260, Validation Loss: 0.1260,V Acc: 0.3727, Top 70th Acc: 0.4675, Bottom 30th Acc: 0.1515
Fold [3/5] Epoch [10/100] Initial Loss: 0.1372, Training Loss: 0.0798, Initial Validation Loss: 0.1260, Validation Loss: 0.0838,V Acc: 0.6182, Top 70th Acc: 0.7143, Bottom 30th Acc: 0.3939
Stopping early at Epoch (base 0): 14  Rolling back to Epoch (base 0): 9  Top Validation Acc: 0.7012987012987013
Fold [4/5] Epoch [0/100] Initial Loss: 0.1353, Training Loss: 0.1353, Initial Validation Loss: 0.1274, Validation Loss: 0.1274,V Acc: 0.4091, Top 70th Acc: 0.4935, Bottom 30th Acc: 0.2121/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)

Stopping early at Epoch (base 0): 36  Rolling back to Epoch (base 0): 31  Top Validation Acc: 0.9487179487179487
Fold [2/5] Epoch [0/100] Initial Loss: 0.1381, Training Loss: 0.1381, Initial Validation Loss: 0.1381, Validation Loss: 0.1381,V Acc: 0.3784, Top 70th Acc: 0.4231, Bottom 30th Acc: 0.2727
Fold [2/5] Epoch [10/100] Initial Loss: 0.1381, Training Loss: 0.0356, Initial Validation Loss: 0.1381, Validation Loss: 0.0481,V Acc: 0.7748, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.4242
Fold [2/5] Epoch [20/100] Initial Loss: 0.1381, Training Loss: 0.0177, Initial Validation Loss: 0.1381, Validation Loss: 0.0331,V Acc: 0.8649, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.6364
Fold [2/5] Epoch [30/100] Initial Loss: 0.1381, Training Loss: 0.0148, Initial Validation Loss: 0.1381, Validation Loss: 0.0309,V Acc: 0.8468, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 35  Rolling back to Epoch (base 0): 30  Top Validation Acc: 0.9615384615384616
Fold [3/5] Epoch [0/100] Initial Loss: 0.1406, Training Loss: 0.1406, Initial Validation Loss: 0.1327, Validation Loss: 0.1327,V Acc: 0.2455, Top 70th Acc: 0.2597, Bottom 30th Acc: 0.2121
Fold [3/5] Epoch [10/100] Initial Loss: 0.1406, Training Loss: 0.0409, Initial Validation Loss: 0.1327, Validation Loss: 0.0401,V Acc: 0.7727, Top 70th Acc: 0.8701, Bottom 30th Acc: 0.5455
Fold [3/5] Epoch [20/100] Initial Loss: 0.1406, Training Loss: 0.0207, Initial Validation Loss: 0.1327, Validation Loss: 0.0244,V Acc: 0.8545, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 28  Rolling back to Epoch (base 0): 23  Top Validation Acc: 0.961038961038961
Fold [4/5] Epoch [0/100] Initial Loss: 0.1385, Training Loss: 0.1385, Initial Validation Loss: 0.1308, Validation Loss: 0.1308,V Acc: 0.3545, Top 70th Acc: 0.4416, Bottom 30th Acc: 0.1515
Fold [4/5] Epoch [10/100] Initial Loss: 0.1385, Training Loss: 0.0369, Initial Validation Loss: 0.1308, Validation Loss: 0.0493,V Acc: 0.7455, Top 70th Acc: 0.8442, Bottom 30th Acc: 0.5152
Stopping early at Epoch (base 0): 18  Rolling back to Epoch (base 0): 13  Top Validation Acc: 0.8701298701298701
Fold [5/5] Epoch [0/100] Initial Loss: 0.1360, Training Loss: 0.1360, Initial Validation Loss: 0.1294, Validation Loss: 0.1294,V Acc: 0.4722, Top 70th Acc: 0.5395, Bottom 30th Acc: 0.3125
Fold [5/5] Epoch [10/100] Initial Loss: 0.1360, Training Loss: 0.0376, Initial Validation Loss: 0.1294, Validation Loss: 0.0412,V Acc: 0.8148, Top 70th Acc: 0.8816, Bottom 30th Acc: 0.6562
Fold [5/5] Epoch [20/100] Initial Loss: 0.1360, Training Loss: 0.0216, Initial Validation Loss: 0.1294, Validation Loss: 0.0255,V Acc: 0.8981, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.7500
Fold [5/5] Epoch [30/100] Initial Loss: 0.1360, Training Loss: 0.0168, Initial Validation Loss: 0.1294, Validation Loss: 0.0237,V Acc: 0.8889, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.7188
Fold [5/5] Epoch [40/100] Initial Loss: 0.1360, Training Loss: 0.0152, Initial Validation Loss: 0.1294, Validation Loss: 0.0243,V Acc: 0.8704, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.6562
Stopping early at Epoch (base 0): 40  Rolling back to Epoch (base 0): 35  Top Validation Acc: 0.9605263157894737
80 4 [array([0.71478766, 0.07800143, 0.0282197 , 0.08124028, 0.09775089],
      dtype=float32)]
Running train_nn.py with seed 81
CUDA:False
Training samples count:  550
Training on 30 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1381, Training Loss: 0.1381, Initial Validation Loss: 0.1325, Validation Loss: 0.1325,V Acc: 0.3423, Top 70th Acc: 0.3462, Bottom 30th Acc: 0.3333
Fold [1/5] Epoch [10/100] Initial Loss: 0.1381, Training Loss: 0.0331, Initial Validation Loss: 0.1325, Validation Loss: 0.0396,V Acc: 0.8198, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.5758
Fold [1/5] Epoch [20/100] Initial Loss: 0.1381, Training Loss: 0.0190, Initial Validation Loss: 0.1325, Validation Loss: 0.0323,V Acc: 0.8378, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 21  Rolling back to Epoch (base 0): 16  Top Validation Acc: 0.9487179487179487
Fold [2/5] Epoch [0/100] Initial Loss: 0.1408, Training Loss: 0.1408, Initial Validation Loss: 0.1314, Validation Loss: 0.1314,V Acc: 0.2613, Top 70th Acc: 0.3462, Bottom 30th Acc: 0.0606
Fold [2/5] Epoch [10/100] Initial Loss: 0.1408, Training Loss: 0.0324, Initial Validation Loss: 0.1314, Validation Loss: 0.0463,V Acc: 0.7748, Top 70th Acc: 0.8590, Bottom 30th Acc: 0.5758
Fold [2/5] Epoch [20/100] Initial Loss: 0.1408, Training Loss: 0.0185, Initial Validation Loss: 0.1314, Validation Loss: 0.0393,V Acc: 0.8018, Top 70th Acc: 0.8974, Bottom 30th Acc: 0.5758
Fold [2/5] Epoch [30/100] Initial Loss: 0.1408, Training Loss: 0.0158, Initial Validation Loss: 0.1314, Validation Loss: 0.0387,V Acc: 0.7838, Top 70th Acc: 0.8974, Bottom 30th Acc: 0.5152
Stopping early at Epoch (base 0): 34  Rolling back to Epoch (base 0): 29  Top Validation Acc: 0.9102564102564102
Fold [3/5] Epoch [0/100] Initial Loss: 0.1392, Training Loss: 0.1392, Initial Validation Loss: 0.1375, Validation Loss: 0.1375,V Acc: 0.2636, Top 70th Acc: 0.3117, Bottom 30th Acc: 0.1515
Fold [3/5] Epoch [10/100] Initial Loss: 0.1392, Training Loss: 0.0343, Initial Validation Loss: 0.1375, Validation Loss: 0.0342,V Acc: 0.8909, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.6970
Fold [3/5] Epoch [20/100] Initial Loss: 0.1392, Training Loss: 0.0197, Initial Validation Loss: 0.1375, Validation Loss: 0.0280,V Acc: 0.8727, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 27  Rolling back to Epoch (base 0): 22  Top Validation Acc: 0.961038961038961
Fold [4/5] Epoch [0/100] Initial Loss: 0.1395, Training Loss: 0.1395, Initial Validation Loss: 0.1335, Validation Loss: 0.1335,V Acc: 0.3182, Top 70th Acc: 0.3766, Bottom 30th Acc: 0.1818
Fold [4/5] Epoch [10/100] Initial Loss: 0.1395, Training Loss: 0.0377, Initial Validation Loss: 0.1335, Validation Loss: 0.0355,V Acc: 0.8182, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.4848
Fold [4/5] Epoch [20/100] Initial Loss: 0.1395, Training Loss: 0.0201, Initial Validation Loss: 0.1335, Validation Loss: 0.0270,V Acc: 0.8636, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 29  Rolling back to Epoch (base 0): 24  Top Validation Acc: 0.961038961038961
81 3 [array([0.57659864, 0.06532471, 0.05057466, 0.06671709, 0.24078496],
      dtype=float32)]
Fold [5/5] Epoch [0/100] Initial Loss: 0.1402, Training Loss: 0.1402, Initial Validation Loss: 0.1342, Validation Loss: 0.1342,V Acc: 0.3519, Top 70th Acc: 0.3553, Bottom 30th Acc: 0.3438
Fold [5/5] Epoch [10/100] Initial Loss: 0.1402, Training Loss: 0.0335, Initial Validation Loss: 0.1342, Validation Loss: 0.0395,V Acc: 0.8333, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.5312
Fold [5/5] Epoch [20/100] Initial Loss: 0.1402, Training Loss: 0.0199, Initial Validation Loss: 0.1342, Validation Loss: 0.0332,V Acc: 0.8519, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.5938
Stopping early at Epoch (base 0): 22  Rolling back to Epoch (base 0): 17  Top Validation Acc: 0.9605263157894737
Running train_nn.py with seed 82
CUDA:False
Training samples count:  550
Training on 30 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1403, Training Loss: 0.1403, Initial Validation Loss: 0.1315, Validation Loss: 0.1315,V Acc: 0.2523, Top 70th Acc: 0.3462, Bottom 30th Acc: 0.0303
Fold [1/5] Epoch [10/100] Initial Loss: 0.1403, Training Loss: 0.0348, Initial Validation Loss: 0.1315, Validation Loss: 0.0487,V Acc: 0.7568, Top 70th Acc: 0.8718, Bottom 30th Acc: 0.4848
Fold [1/5] Epoch [20/100] Initial Loss: 0.1403, Training Loss: 0.0183, Initial Validation Loss: 0.1315, Validation Loss: 0.0361,V Acc: 0.8018, Top 70th Acc: 0.8974, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 27  Rolling back to Epoch (base 0): 22  Top Validation Acc: 0.9102564102564102
82 0 [array([0.56620896, 0.09635888, 0.04958297, 0.13017306, 0.15767612],
      dtype=float32)]
Fold [2/5] Epoch [0/100] Initial Loss: 0.1383, Training Loss: 0.1383, Initial Validation Loss: 0.1411, Validation Loss: 0.1411,V Acc: 0.3514, Top 70th Acc: 0.3846, Bottom 30th Acc: 0.2727
Fold [2/5] Epoch [10/100] Initial Loss: 0.1383, Training Loss: 0.0426, Initial Validation Loss: 0.1411, Validation Loss: 0.0558,V Acc: 0.7568, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.3939
Fold [4/5] Epoch [70/100] Initial Loss: 0.1377, Training Loss: 0.0033, Initial Validation Loss: 0.1373, Validation Loss: 0.0261,V Acc: 0.8545, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.5758
Fold [4/5] Epoch [80/100] Initial Loss: 0.1377, Training Loss: 0.0032, Initial Validation Loss: 0.1373, Validation Loss: 0.0258,V Acc: 0.8818, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 83  Rolling back to Epoch (base 0): 78  Top Validation Acc: 0.974025974025974
Fold [5/5] Epoch [0/100] Initial Loss: 0.1385, Training Loss: 0.1385, Initial Validation Loss: 0.1297, Validation Loss: 0.1297,V Acc: 0.3333, Top 70th Acc: 0.4211, Bottom 30th Acc: 0.1250
Fold [5/5] Epoch [10/100] Initial Loss: 0.1385, Training Loss: 0.0310, Initial Validation Loss: 0.1297, Validation Loss: 0.0470,V Acc: 0.7500, Top 70th Acc: 0.8553, Bottom 30th Acc: 0.5000
Fold [5/5] Epoch [20/100] Initial Loss: 0.1385, Training Loss: 0.0057, Initial Validation Loss: 0.1297, Validation Loss: 0.0300,V Acc: 0.8241, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.5000
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.9473684210526315
61 4 [array([0.42973113, 0.04022301, 0.05955343, 0.16380514, 0.30668736],
      dtype=float32)]
Running train_nn.py with seed 62
CUDA:False
Training samples count:  550
Training on 163 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1399, Training Loss: 0.1399, Initial Validation Loss: 0.1373, Validation Loss: 0.1373,V Acc: 0.2883, Top 70th Acc: 0.3077, Bottom 30th Acc: 0.2424
Fold [1/5] Epoch [10/100] Initial Loss: 0.1399, Training Loss: 0.0145, Initial Validation Loss: 0.1373, Validation Loss: 0.0364,V Acc: 0.8559, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.6970
Fold [1/5] Epoch [20/100] Initial Loss: 0.1399, Training Loss: 0.0051, Initial Validation Loss: 0.1373, Validation Loss: 0.0317,V Acc: 0.8559, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 29  Rolling back to Epoch (base 0): 24  Top Validation Acc: 0.9615384615384616
Fold [2/5] Epoch [0/100] Initial Loss: 0.1385, Training Loss: 0.1385, Initial Validation Loss: 0.1312, Validation Loss: 0.1312,V Acc: 0.3243, Top 70th Acc: 0.3846, Bottom 30th Acc: 0.1818
Fold [2/5] Epoch [10/100] Initial Loss: 0.1385, Training Loss: 0.0252, Initial Validation Loss: 0.1312, Validation Loss: 0.0412,V Acc: 0.8108, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.4848
Fold [2/5] Epoch [20/100] Initial Loss: 0.1385, Training Loss: 0.0053, Initial Validation Loss: 0.1312, Validation Loss: 0.0294,V Acc: 0.8649, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.6061
Fold [2/5] Epoch [30/100] Initial Loss: 0.1385, Training Loss: 0.0040, Initial Validation Loss: 0.1312, Validation Loss: 0.0277,V Acc: 0.8829, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.6667
Fold [2/5] Epoch [40/100] Initial Loss: 0.1385, Training Loss: 0.0038, Initial Validation Loss: 0.1312, Validation Loss: 0.0272,V Acc: 0.8829, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 48  Rolling back to Epoch (base 0): 43  Top Validation Acc: 0.9487179487179487
62 1 [array([0.32732895, 0.05024244, 0.06503355, 0.23146534, 0.32592976],
      dtype=float32)]
Fold [3/5] Epoch [0/100] Initial Loss: 0.1394, Training Loss: 0.1394, Initial Validation Loss: 0.1374, Validation Loss: 0.1374,V Acc: 0.2545, Top 70th Acc: 0.3247, Bottom 30th Acc: 0.0909
Fold [3/5] Epoch [10/100] Initial Loss: 0.1394, Training Loss: 0.0213, Initial Validation Loss: 0.1374, Validation Loss: 0.0426,V Acc: 0.7727, Top 70th Acc: 0.8961, Bottom 30th Acc: 0.4848
Fold [3/5] Epoch [20/100] Initial Loss: 0.1394, Training Loss: 0.0048, Initial Validation Loss: 0.1374, Validation Loss: 0.0294,V Acc: 0.8727, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.935064935064935
Fold [4/5] Epoch [0/100] Initial Loss: 0.1391, Training Loss: 0.1391, Initial Validation Loss: 0.1309, Validation Loss: 0.1309,V Acc: 0.3364, Top 70th Acc: 0.3377, Bottom 30th Acc: 0.3333
Fold [4/5] Epoch [10/100] Initial Loss: 0.1391, Training Loss: 0.0161, Initial Validation Loss: 0.1309, Validation Loss: 0.0372,V Acc: 0.7818, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.4545
Fold [4/5] Epoch [20/100] Initial Loss: 0.1391, Training Loss: 0.0044, Initial Validation Loss: 0.1309, Validation Loss: 0.0345,V Acc: 0.7818, Top 70th Acc: 0.8961, Bottom 30th Acc: 0.5152
Stopping early at Epoch (base 0): 27  Rolling back to Epoch (base 0): 22  Top Validation Acc: 0.8961038961038961
Fold [5/5] Epoch [0/100] Initial Loss: 0.1382, Training Loss: 0.1382, Initial Validation Loss: 0.1375, Validation Loss: 0.1375,V Acc: 0.2500, Top 70th Acc: 0.3158, Bottom 30th Acc: 0.0938
Fold [5/5] Epoch [10/100] Initial Loss: 0.1382, Training Loss: 0.0351, Initial Validation Loss: 0.1375, Validation Loss: 0.0379,V Acc: 0.8796, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.7188
Fold [5/5] Epoch [20/100] Initial Loss: 0.1382, Training Loss: 0.0063, Initial Validation Loss: 0.1375, Validation Loss: 0.0248,V Acc: 0.8796, Top 70th Acc: 0.9737, Bottom 30th Acc: 0.6562
Fold [5/5] Epoch [30/100] Initial Loss: 0.1382, Training Loss: 0.0045, Initial Validation Loss: 0.1375, Validation Loss: 0.0237,V Acc: 0.8796, Top 70th Acc: 0.9737, Bottom 30th Acc: 0.6562
Stopping early at Epoch (base 0): 36  Rolling back to Epoch (base 0): 31  Top Validation Acc: 0.9736842105263158
Running train_nn.py with seed 63
CUDA:False
Training samples count:  550
Training on 163 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1394, Training Loss: 0.1394, Initial Validation Loss: 0.1392, Validation Loss: 0.1392,V Acc: 0.2523, Top 70th Acc: 0.3462, Bottom 30th Acc: 0.0303
Fold [1/5] Epoch [10/100] Initial Loss: 0.1394, Training Loss: 0.0240, Initial Validation Loss: 0.1392, Validation Loss: 0.0390,V Acc: 0.8378, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.6061
Fold [1/5] Epoch [20/100] Initial Loss: 0.1394, Training Loss: 0.0055, Initial Validation Loss: 0.1392, Validation Loss: 0.0274,V Acc: 0.8559, Top 70th Acc: 0.9872, Bottom 30th Acc: 0.5455
Fold [1/5] Epoch [30/100] Initial Loss: 0.1394, Training Loss: 0.0043, Initial Validation Loss: 0.1392, Validation Loss: 0.0252,V Acc: 0.8829, Top 70th Acc: 0.9872, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 35  Rolling back to Epoch (base 0): 30  Top Validation Acc: 0.9871794871794872
Fold [2/5] Epoch [0/100] Initial Loss: 0.1376, Training Loss: 0.1376, Initial Validation Loss: 0.1282, Validation Loss: 0.1282,V Acc: 0.2703, Top 70th Acc: 0.3590, Bottom 30th Acc: 0.0606
Fold [2/5] Epoch [10/100] Initial Loss: 0.1376, Training Loss: 0.0146, Initial Validation Loss: 0.1282, Validation Loss: 0.0384,V Acc: 0.8018, Top 70th Acc: 0.8718, Bottom 30th Acc: 0.6364
Fold [2/5] Epoch [20/100] Initial Loss: 0.1376, Training Loss: 0.0045, Initial Validation Loss: 0.1282, Validation Loss: 0.0375,V Acc: 0.7838, Top 70th Acc: 0.8974, Bottom 30th Acc: 0.5152
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.9102564102564102
Fold [3/5] Epoch [0/100] Initial Loss: 0.1393, Training Loss: 0.1393, Initial Validation Loss: 0.1338, Validation Loss: 0.1338,V Acc: 0.2545, Top 70th Acc: 0.3506, Bottom 30th Acc: 0.0303
Fold [3/5] Epoch [10/100] Initial Loss: 0.1393, Training Loss: 0.0136, Initial Validation Loss: 0.1338, Validation Loss: 0.0304,V Acc: 0.9000, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.8182
Fold [3/5] Epoch [20/100] Initial Loss: 0.1393, Training Loss: 0.0046, Initial Validation Loss: 0.1338, Validation Loss: 0.0281,V Acc: 0.8818, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.7273
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.948051948051948
63 2 [array([0.26826355, 0.052225  , 0.05801724, 0.37846908, 0.2430251 ],
      dtype=float32)]
Fold [4/5] Epoch [0/100] Initial Loss: 0.1426, Training Loss: 0.1426, Initial Validation Loss: 0.1345, Validation Loss: 0.1345,V Acc: 0.3091, Top 70th Acc: 0.3766, Bottom 30th Acc: 0.1515
Fold [4/5] Epoch [10/100] Initial Loss: 0.1426, Training Loss: 0.0202, Initial Validation Loss: 0.1345, Validation Loss: 0.0358,V Acc: 0.8364, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.5152
Stopping early at Epoch (base 0): 28  Rolling back to Epoch (base 0): 23  Top Validation Acc: 0.9230769230769231
82 0 [array([0.39449736, 0.06882004, 0.17074142, 0.19300282, 0.17293835],
      dtype=float32)]
Fold [2/5] Epoch [0/100] Initial Loss: 0.1345, Training Loss: 0.1345, Initial Validation Loss: 0.1386, Validation Loss: 0.1386,V Acc: 0.3243, Top 70th Acc: 0.3462, Bottom 30th Acc: 0.2727
Fold [2/5] Epoch [10/100] Initial Loss: 0.1345, Training Loss: 0.0298, Initial Validation Loss: 0.1386, Validation Loss: 0.0394,V Acc: 0.8378, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.5758
Fold [2/5] Epoch [20/100] Initial Loss: 0.1345, Training Loss: 0.0215, Initial Validation Loss: 0.1386, Validation Loss: 0.0381,V Acc: 0.8468, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.9230769230769231
Fold [3/5] Epoch [0/100] Initial Loss: 0.1410, Training Loss: 0.1410, Initial Validation Loss: 0.1311, Validation Loss: 0.1311,V Acc: 0.2545, Top 70th Acc: 0.3506, Bottom 30th Acc: 0.0303
Fold [3/5] Epoch [10/100] Initial Loss: 0.1410, Training Loss: 0.0315, Initial Validation Loss: 0.1311, Validation Loss: 0.0327,V Acc: 0.8455, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 19  Rolling back to Epoch (base 0): 14  Top Validation Acc: 0.948051948051948
Fold [4/5] Epoch [0/100] Initial Loss: 0.1407, Training Loss: 0.1407, Initial Validation Loss: 0.1382, Validation Loss: 0.1382,V Acc: 0.2636, Top 70th Acc: 0.2857, Bottom 30th Acc: 0.2121
Fold [4/5] Epoch [10/100] Initial Loss: 0.1407, Training Loss: 0.0463, Initial Validation Loss: 0.1382, Validation Loss: 0.0427,V Acc: 0.8091, Top 70th Acc: 0.8961, Bottom 30th Acc: 0.6061
Fold [4/5] Epoch [20/100] Initial Loss: 0.1407, Training Loss: 0.0288, Initial Validation Loss: 0.1382, Validation Loss: 0.0290,V Acc: 0.8545, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.5758
Fold [4/5] Epoch [30/100] Initial Loss: 0.1407, Training Loss: 0.0247, Initial Validation Loss: 0.1382, Validation Loss: 0.0263,V Acc: 0.8364, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.5152
Stopping early at Epoch (base 0): 36  Rolling back to Epoch (base 0): 31  Top Validation Acc: 0.974025974025974
Fold [5/5] Epoch [0/100] Initial Loss: 0.1367, Training Loss: 0.1367, Initial Validation Loss: 0.1323, Validation Loss: 0.1323,V Acc: 0.3519, Top 70th Acc: 0.4079, Bottom 30th Acc: 0.2188
Fold [5/5] Epoch [10/100] Initial Loss: 0.1367, Training Loss: 0.0468, Initial Validation Loss: 0.1323, Validation Loss: 0.0438,V Acc: 0.8056, Top 70th Acc: 0.9079, Bottom 30th Acc: 0.5625
Fold [5/5] Epoch [20/100] Initial Loss: 0.1367, Training Loss: 0.0247, Initial Validation Loss: 0.1323, Validation Loss: 0.0314,V Acc: 0.8704, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.7188
Fold [5/5] Epoch [30/100] Initial Loss: 0.1367, Training Loss: 0.0218, Initial Validation Loss: 0.1323, Validation Loss: 0.0313,V Acc: 0.8704, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.6875
Stopping early at Epoch (base 0): 31  Rolling back to Epoch (base 0): 26  Top Validation Acc: 0.9342105263157895
Running train_nn.py with seed 83
CUDA:False
Training samples count:  550
Training on 20 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1385, Training Loss: 0.1385, Initial Validation Loss: 0.1305, Validation Loss: 0.1305,V Acc: 0.3423, Top 70th Acc: 0.3846, Bottom 30th Acc: 0.2424
Fold [1/5] Epoch [10/100] Initial Loss: 0.1385, Training Loss: 0.0303, Initial Validation Loss: 0.1305, Validation Loss: 0.0380,V Acc: 0.8198, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 18  Rolling back to Epoch (base 0): 13  Top Validation Acc: 0.9358974358974359
Fold [2/5] Epoch [0/100] Initial Loss: 0.1376, Training Loss: 0.1376, Initial Validation Loss: 0.1414, Validation Loss: 0.1414,V Acc: 0.3333, Top 70th Acc: 0.3718, Bottom 30th Acc: 0.2424
Fold [2/5] Epoch [10/100] Initial Loss: 0.1376, Training Loss: 0.0368, Initial Validation Loss: 0.1414, Validation Loss: 0.0320,V Acc: 0.9189, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.8182
Fold [2/5] Epoch [20/100] Initial Loss: 0.1376, Training Loss: 0.0250, Initial Validation Loss: 0.1414, Validation Loss: 0.0237,V Acc: 0.9369, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.8485
Fold [2/5] Epoch [30/100] Initial Loss: 0.1376, Training Loss: 0.0229, Initial Validation Loss: 0.1414, Validation Loss: 0.0229,V Acc: 0.9279, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.8182
Stopping early at Epoch (base 0): 38  Rolling back to Epoch (base 0): 33  Top Validation Acc: 0.9743589743589743
Fold [3/5] Epoch [0/100] Initial Loss: 0.1400, Training Loss: 0.1400, Initial Validation Loss: 0.1316, Validation Loss: 0.1316,V Acc: 0.3818, Top 70th Acc: 0.3117, Bottom 30th Acc: 0.5455
Fold [3/5] Epoch [10/100] Initial Loss: 0.1400, Training Loss: 0.0387, Initial Validation Loss: 0.1316, Validation Loss: 0.0401,V Acc: 0.8364, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.6061
Fold [3/5] Epoch [20/100] Initial Loss: 0.1400, Training Loss: 0.0244, Initial Validation Loss: 0.1316, Validation Loss: 0.0371,V Acc: 0.7909, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.4242
Fold [3/5] Epoch [30/100] Initial Loss: 0.1400, Training Loss: 0.0202, Initial Validation Loss: 0.1316, Validation Loss: 0.0339,V Acc: 0.8000, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.4545
Stopping early at Epoch (base 0): 35  Rolling back to Epoch (base 0): 30  Top Validation Acc: 0.935064935064935
Fold [4/5] Epoch [0/100] Initial Loss: 0.1429, Training Loss: 0.1429, Initial Validation Loss: 0.1382, Validation Loss: 0.1382,V Acc: 0.2818, Top 70th Acc: 0.3117, Bottom 30th Acc: 0.2121
Fold [4/5] Epoch [10/100] Initial Loss: 0.1429, Training Loss: 0.0401, Initial Validation Loss: 0.1382, Validation Loss: 0.0493,V Acc: 0.7636, Top 70th Acc: 0.8831, Bottom 30th Acc: 0.4848
Fold [4/5] Epoch [20/100] Initial Loss: 0.1429, Training Loss: 0.0242, Initial Validation Loss: 0.1382, Validation Loss: 0.0350,V Acc: 0.8273, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 29  Rolling back to Epoch (base 0): 24  Top Validation Acc: 0.935064935064935
Fold [5/5] Epoch [0/100] Initial Loss: 0.1421, Training Loss: 0.1421, Initial Validation Loss: 0.1281, Validation Loss: 0.1281,V Acc: 0.2963, Top 70th Acc: 0.4079, Bottom 30th Acc: 0.0312
Fold [5/5] Epoch [10/100] Initial Loss: 0.1421, Training Loss: 0.0431, Initial Validation Loss: 0.1281, Validation Loss: 0.0464,V Acc: 0.7870, Top 70th Acc: 0.8816, Bottom 30th Acc: 0.5625
Fold [5/5] Epoch [20/100] Initial Loss: 0.1421, Training Loss: 0.0225, Initial Validation Loss: 0.1281, Validation Loss: 0.0323,V Acc: 0.8333, Top 70th Acc: 0.9079, Bottom 30th Acc: 0.6562
Fold [5/5] Epoch [30/100] Initial Loss: 0.1421, Training Loss: 0.0196, Initial Validation Loss: 0.1281, Validation Loss: 0.0310,V Acc: 0.8333, Top 70th Acc: 0.9079, Bottom 30th Acc: 0.6562
Fold [5/5] Epoch [40/100] Initial Loss: 0.1421, Training Loss: 0.0185, Initial Validation Loss: 0.1281, Validation Loss: 0.0315,V Acc: 0.8333, Top 70th Acc: 0.9079, Bottom 30th Acc: 0.6562
Stopping early at Epoch (base 0): 41  Rolling back to Epoch (base 0): 36  Top Validation Acc: 0.9078947368421053
83 4 [array([0.42438415, 0.0832708 , 0.08644219, 0.2605282 , 0.14537466],
      dtype=float32)]
Running train_nn.py with seed 84
CUDA:False
Training samples count:  550
Training on 20 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1365, Training Loss: 0.1365, Initial Validation Loss: 0.1340, Validation Loss: 0.1340,V Acc: 0.2523, Top 70th Acc: 0.3205, Bottom 30th Acc: 0.0909
Fold [1/5] Epoch [10/100] Initial Loss: 0.1365, Training Loss: 0.0302, Initial Validation Loss: 0.1340, Validation Loss: 0.0407,V Acc: 0.7838, Top 70th Acc: 0.8974, Bottom 30th Acc: 0.5152
Fold [1/5] Epoch [20/100] Initial Loss: 0.1365, Training Loss: 0.0234, Initial Validation Loss: 0.1340, Validation Loss: 0.0341,V Acc: 0.8198, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 27  Rolling back to Epoch (base 0): 22  Top Validation Acc: 0.9487179487179487
84 0 [array([0.44012985, 0.04388624, 0.07260045, 0.23487064, 0.20851286],
      dtype=float32)]
Fold [2/5] Epoch [0/100] Initial Loss: 0.1384, Training Loss: 0.1384, Initial Validation Loss: 0.1404, Validation Loss: 0.1404,V Acc: 0.2523, Top 70th Acc: 0.2564, Bottom 30th Acc: 0.2424
Stopping early at Epoch (base 0): 39  Rolling back to Epoch (base 0): 34  Top Validation Acc: 0.9871794871794872
Fold [2/5] Epoch [0/100] Initial Loss: 0.1389, Training Loss: 0.1389, Initial Validation Loss: 0.1369, Validation Loss: 0.1369,V Acc: 0.2973, Top 70th Acc: 0.3205, Bottom 30th Acc: 0.2424
Fold [2/5] Epoch [10/100] Initial Loss: 0.1389, Training Loss: 0.0289, Initial Validation Loss: 0.1369, Validation Loss: 0.0380,V Acc: 0.8649, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.6364
Fold [2/5] Epoch [20/100] Initial Loss: 0.1389, Training Loss: 0.0147, Initial Validation Loss: 0.1369, Validation Loss: 0.0284,V Acc: 0.8739, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.9871794871794872
Fold [3/5] Epoch [0/100] Initial Loss: 0.1407, Training Loss: 0.1407, Initial Validation Loss: 0.1311, Validation Loss: 0.1311,V Acc: 0.2636, Top 70th Acc: 0.3247, Bottom 30th Acc: 0.1212
Fold [3/5] Epoch [10/100] Initial Loss: 0.1407, Training Loss: 0.0373, Initial Validation Loss: 0.1311, Validation Loss: 0.0379,V Acc: 0.8000, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.4848
Fold [3/5] Epoch [20/100] Initial Loss: 0.1407, Training Loss: 0.0172, Initial Validation Loss: 0.1311, Validation Loss: 0.0232,V Acc: 0.8818, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.6667
Fold [3/5] Epoch [30/100] Initial Loss: 0.1407, Training Loss: 0.0135, Initial Validation Loss: 0.1311, Validation Loss: 0.0202,V Acc: 0.9000, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.7273
Fold [3/5] Epoch [40/100] Initial Loss: 0.1407, Training Loss: 0.0123, Initial Validation Loss: 0.1311, Validation Loss: 0.0201,V Acc: 0.8909, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 40  Rolling back to Epoch (base 0): 35  Top Validation Acc: 0.974025974025974
Fold [4/5] Epoch [0/100] Initial Loss: 0.1416, Training Loss: 0.1416, Initial Validation Loss: 0.1353, Validation Loss: 0.1353,V Acc: 0.2818, Top 70th Acc: 0.2857, Bottom 30th Acc: 0.2727
Fold [4/5] Epoch [10/100] Initial Loss: 0.1416, Training Loss: 0.0294, Initial Validation Loss: 0.1353, Validation Loss: 0.0412,V Acc: 0.8000, Top 70th Acc: 0.8961, Bottom 30th Acc: 0.5758
Fold [4/5] Epoch [20/100] Initial Loss: 0.1416, Training Loss: 0.0134, Initial Validation Loss: 0.1353, Validation Loss: 0.0376,V Acc: 0.7909, Top 70th Acc: 0.8701, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 20  Rolling back to Epoch (base 0): 15  Top Validation Acc: 0.8701298701298701
Fold [5/5] Epoch [0/100] Initial Loss: 0.1404, Training Loss: 0.1404, Initial Validation Loss: 0.1343, Validation Loss: 0.1343,V Acc: 0.2500, Top 70th Acc: 0.3289, Bottom 30th Acc: 0.0625
Fold [5/5] Epoch [10/100] Initial Loss: 0.1404, Training Loss: 0.0385, Initial Validation Loss: 0.1343, Validation Loss: 0.0422,V Acc: 0.8241, Top 70th Acc: 0.8947, Bottom 30th Acc: 0.6562
Fold [5/5] Epoch [20/100] Initial Loss: 0.1404, Training Loss: 0.0172, Initial Validation Loss: 0.1343, Validation Loss: 0.0269,V Acc: 0.8796, Top 70th Acc: 0.9868, Bottom 30th Acc: 0.6250
Fold [5/5] Epoch [30/100] Initial Loss: 0.1404, Training Loss: 0.0130, Initial Validation Loss: 0.1343, Validation Loss: 0.0246,V Acc: 0.8981, Top 70th Acc: 1.0000, Bottom 30th Acc: 0.6562
Fold [5/5] Epoch [40/100] Initial Loss: 0.1404, Training Loss: 0.0112, Initial Validation Loss: 0.1343, Validation Loss: 0.0239,V Acc: 0.8889, Top 70th Acc: 1.0000, Bottom 30th Acc: 0.6250
Stopping early at Epoch (base 0): 45  Rolling back to Epoch (base 0): 40  Top Validation Acc: 1.0
80 4 [array([0.6973098 , 0.05415914, 0.02906827, 0.064919  , 0.15454382],
      dtype=float32)]
Running train_nn.py with seed 81
CUDA:False
Training samples count:  550
Training on 40 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1385, Training Loss: 0.1385, Initial Validation Loss: 0.1322, Validation Loss: 0.1322,V Acc: 0.3784, Top 70th Acc: 0.5000, Bottom 30th Acc: 0.0909
Fold [1/5] Epoch [10/100] Initial Loss: 0.1385, Training Loss: 0.0242, Initial Validation Loss: 0.1322, Validation Loss: 0.0332,V Acc: 0.8919, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.7273
Fold [1/5] Epoch [20/100] Initial Loss: 0.1385, Training Loss: 0.0128, Initial Validation Loss: 0.1322, Validation Loss: 0.0315,V Acc: 0.8468, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 22  Rolling back to Epoch (base 0): 17  Top Validation Acc: 0.9487179487179487
Fold [2/5] Epoch [0/100] Initial Loss: 0.1413, Training Loss: 0.1413, Initial Validation Loss: 0.1328, Validation Loss: 0.1328,V Acc: 0.3063, Top 70th Acc: 0.3718, Bottom 30th Acc: 0.1515
Fold [2/5] Epoch [10/100] Initial Loss: 0.1413, Training Loss: 0.0292, Initial Validation Loss: 0.1328, Validation Loss: 0.0473,V Acc: 0.7568, Top 70th Acc: 0.8590, Bottom 30th Acc: 0.5152
Fold [2/5] Epoch [20/100] Initial Loss: 0.1413, Training Loss: 0.0137, Initial Validation Loss: 0.1328, Validation Loss: 0.0368,V Acc: 0.8378, Top 70th Acc: 0.8974, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 28  Rolling back to Epoch (base 0): 23  Top Validation Acc: 0.8974358974358975
Fold [3/5] Epoch [0/100] Initial Loss: 0.1392, Training Loss: 0.1392, Initial Validation Loss: 0.1360, Validation Loss: 0.1360,V Acc: 0.3636, Top 70th Acc: 0.3896, Bottom 30th Acc: 0.3030
Fold [3/5] Epoch [10/100] Initial Loss: 0.1392, Training Loss: 0.0297, Initial Validation Loss: 0.1360, Validation Loss: 0.0337,V Acc: 0.8727, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.6364
Fold [3/5] Epoch [20/100] Initial Loss: 0.1392, Training Loss: 0.0157, Initial Validation Loss: 0.1360, Validation Loss: 0.0271,V Acc: 0.8909, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 22  Rolling back to Epoch (base 0): 17  Top Validation Acc: 0.974025974025974
Fold [4/5] Epoch [0/100] Initial Loss: 0.1376, Training Loss: 0.1376, Initial Validation Loss: 0.1334, Validation Loss: 0.1334,V Acc: 0.3000, Top 70th Acc: 0.3766, Bottom 30th Acc: 0.1212
Fold [4/5] Epoch [10/100] Initial Loss: 0.1376, Training Loss: 0.0319, Initial Validation Loss: 0.1334, Validation Loss: 0.0349,V Acc: 0.8364, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.6061
Fold [4/5] Epoch [20/100] Initial Loss: 0.1376, Training Loss: 0.0152, Initial Validation Loss: 0.1334, Validation Loss: 0.0246,V Acc: 0.8727, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.6364
Fold [4/5] Epoch [30/100] Initial Loss: 0.1376, Training Loss: 0.0122, Initial Validation Loss: 0.1334, Validation Loss: 0.0236,V Acc: 0.8636, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 32  Rolling back to Epoch (base 0): 27  Top Validation Acc: 0.974025974025974
81 3 [array([0.69279337, 0.08006487, 0.0425352 , 0.04884495, 0.13576159],
      dtype=float32)]
Fold [5/5] Epoch [0/100] Initial Loss: 0.1386, Training Loss: 0.1386, Initial Validation Loss: 0.1352, Validation Loss: 0.1352,V Acc: 0.3333, Top 70th Acc: 0.3684, Bottom 30th Acc: 0.2500
Fold [5/5] Epoch [10/100] Initial Loss: 0.1386, Training Loss: 0.0288, Initial Validation Loss: 0.1352, Validation Loss: 0.0420,V Acc: 0.8519, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.6562
Fold [5/5] Epoch [20/100] Initial Loss: 0.1386, Training Loss: 0.0145, Initial Validation Loss: 0.1352, Validation Loss: 0.0339,V Acc: 0.8519, Top 70th Acc: 0.9211, Bottom 30th Acc: 0.6875
Fold [5/5] Epoch [30/100] Initial Loss: 0.1386, Training Loss: 0.0119, Initial Validation Loss: 0.1352, Validation Loss: 0.0330,V Acc: 0.8519, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.6562
Stopping early at Epoch (base 0): 33  Rolling back to Epoch (base 0): 28  Top Validation Acc: 0.9342105263157895
Running train_nn.py with seed 82
CUDA:False
Training samples count:  550
Training on 40 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1403, Training Loss: 0.1403, Initial Validation Loss: 0.1320, Validation Loss: 0.1320,V Acc: 0.2613, Top 70th Acc: 0.3462, Bottom 30th Acc: 0.0606
Fold [1/5] Epoch [10/100] Initial Loss: 0.1403, Training Loss: 0.0372, Initial Validation Loss: 0.1320, Validation Loss: 0.0504,V Acc: 0.7477, Top 70th Acc: 0.8590, Bottom 30th Acc: 0.4848
Fold [1/5] Epoch [20/100] Initial Loss: 0.1403, Training Loss: 0.0137, Initial Validation Loss: 0.1320, Validation Loss: 0.0342,V Acc: 0.8288, Top 70th Acc: 0.8974, Bottom 30th Acc: 0.6667
Fold [4/5] Epoch [10/100] Initial Loss: 0.1353, Training Loss: 0.0814, Initial Validation Loss: 0.1274, Validation Loss: 0.0779,V Acc: 0.6364, Top 70th Acc: 0.7273, Bottom 30th Acc: 0.4242
Fold [4/5] Epoch [20/100] Initial Loss: 0.1353, Training Loss: 0.0796, Initial Validation Loss: 0.1274, Validation Loss: 0.0760,V Acc: 0.6455, Top 70th Acc: 0.7013, Bottom 30th Acc: 0.5152
Fold [4/5] Epoch [30/100] Initial Loss: 0.1353, Training Loss: 0.0787, Initial Validation Loss: 0.1274, Validation Loss: 0.0768,V Acc: 0.6455, Top 70th Acc: 0.7013, Bottom 30th Acc: 0.5152
Stopping early at Epoch (base 0): 30  Rolling back to Epoch (base 0): 25  Top Validation Acc: 0.7012987012987013
Fold [5/5] Epoch [0/100] Initial Loss: 0.1369, Training Loss: 0.1369, Initial Validation Loss: 0.1305, Validation Loss: 0.1305,V Acc: 0.3056, Top 70th Acc: 0.3947, Bottom 30th Acc: 0.0938
Fold [5/5] Epoch [10/100] Initial Loss: 0.1369, Training Loss: 0.0816, Initial Validation Loss: 0.1305, Validation Loss: 0.0803,V Acc: 0.6204, Top 70th Acc: 0.7632, Bottom 30th Acc: 0.2812
Fold [5/5] Epoch [20/100] Initial Loss: 0.1369, Training Loss: 0.0788, Initial Validation Loss: 0.1305, Validation Loss: 0.0782,V Acc: 0.6204, Top 70th Acc: 0.7500, Bottom 30th Acc: 0.3125
Fold [5/5] Epoch [30/100] Initial Loss: 0.1369, Training Loss: 0.0781, Initial Validation Loss: 0.1305, Validation Loss: 0.0767,V Acc: 0.6296, Top 70th Acc: 0.7895, Bottom 30th Acc: 0.2500
Fold [5/5] Epoch [40/100] Initial Loss: 0.1369, Training Loss: 0.0776, Initial Validation Loss: 0.1305, Validation Loss: 0.0768,V Acc: 0.6389, Top 70th Acc: 0.7632, Bottom 30th Acc: 0.3438
Stopping early at Epoch (base 0): 42  Rolling back to Epoch (base 0): 37  Top Validation Acc: 0.7763157894736842
77 4 [array([0.14629984, 0.34845838, 0.11878768, 0.22848348, 0.15797062],
      dtype=float32)]
Running train_nn.py with seed 78
CUDA:False
Training samples count:  550
Training on 2 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1374, Training Loss: 0.1374, Initial Validation Loss: 0.1301, Validation Loss: 0.1301,V Acc: 0.4144, Top 70th Acc: 0.4872, Bottom 30th Acc: 0.2424
Fold [1/5] Epoch [10/100] Initial Loss: 0.1374, Training Loss: 0.0811, Initial Validation Loss: 0.1301, Validation Loss: 0.0795,V Acc: 0.6306, Top 70th Acc: 0.7821, Bottom 30th Acc: 0.2727
Fold [1/5] Epoch [20/100] Initial Loss: 0.1374, Training Loss: 0.0793, Initial Validation Loss: 0.1301, Validation Loss: 0.0789,V Acc: 0.6306, Top 70th Acc: 0.7821, Bottom 30th Acc: 0.2727
Fold [1/5] Epoch [30/100] Initial Loss: 0.1374, Training Loss: 0.0787, Initial Validation Loss: 0.1301, Validation Loss: 0.0772,V Acc: 0.6486, Top 70th Acc: 0.7821, Bottom 30th Acc: 0.3333
Stopping early at Epoch (base 0): 35  Rolling back to Epoch (base 0): 30  Top Validation Acc: 0.7435897435897436
Fold [2/5] Epoch [0/100] Initial Loss: 0.1328, Training Loss: 0.1328, Initial Validation Loss: 0.1235, Validation Loss: 0.1235,V Acc: 0.5135, Top 70th Acc: 0.6667, Bottom 30th Acc: 0.1515
Fold [2/5] Epoch [10/100] Initial Loss: 0.1328, Training Loss: 0.0787, Initial Validation Loss: 0.1235, Validation Loss: 0.0833,V Acc: 0.5856, Top 70th Acc: 0.7051, Bottom 30th Acc: 0.3030
Fold [2/5] Epoch [20/100] Initial Loss: 0.1328, Training Loss: 0.0770, Initial Validation Loss: 0.1235, Validation Loss: 0.0831,V Acc: 0.5946, Top 70th Acc: 0.6923, Bottom 30th Acc: 0.3636
Fold [2/5] Epoch [30/100] Initial Loss: 0.1328, Training Loss: 0.0767, Initial Validation Loss: 0.1235, Validation Loss: 0.0813,V Acc: 0.5946, Top 70th Acc: 0.6923, Bottom 30th Acc: 0.3636
Stopping early at Epoch (base 0): 32  Rolling back to Epoch (base 0): 27  Top Validation Acc: 0.7051282051282052
Fold [3/5] Epoch [0/100] Initial Loss: 0.1427, Training Loss: 0.1427, Initial Validation Loss: 0.1367, Validation Loss: 0.1367,V Acc: 0.3909, Top 70th Acc: 0.4545, Bottom 30th Acc: 0.2424
Fold [3/5] Epoch [10/100] Initial Loss: 0.1427, Training Loss: 0.0810, Initial Validation Loss: 0.1367, Validation Loss: 0.0842,V Acc: 0.6273, Top 70th Acc: 0.7273, Bottom 30th Acc: 0.3939
Fold [3/5] Epoch [20/100] Initial Loss: 0.1427, Training Loss: 0.0781, Initial Validation Loss: 0.1367, Validation Loss: 0.0820,V Acc: 0.6636, Top 70th Acc: 0.7143, Bottom 30th Acc: 0.5455
Fold [3/5] Epoch [30/100] Initial Loss: 0.1427, Training Loss: 0.0773, Initial Validation Loss: 0.1367, Validation Loss: 0.0818,V Acc: 0.6455, Top 70th Acc: 0.7143, Bottom 30th Acc: 0.4848
Stopping early at Epoch (base 0): 37  Rolling back to Epoch (base 0): 32  Top Validation Acc: 0.7142857142857143
Fold [4/5] Epoch [0/100] Initial Loss: 0.1433, Training Loss: 0.1433, Initial Validation Loss: 0.1306, Validation Loss: 0.1306,V Acc: 0.2909, Top 70th Acc: 0.2987, Bottom 30th Acc: 0.2727
Fold [4/5] Epoch [10/100] Initial Loss: 0.1433, Training Loss: 0.0801, Initial Validation Loss: 0.1306, Validation Loss: 0.0799,V Acc: 0.6000, Top 70th Acc: 0.7143, Bottom 30th Acc: 0.3333
Fold [4/5] Epoch [20/100] Initial Loss: 0.1433, Training Loss: 0.0779, Initial Validation Loss: 0.1306, Validation Loss: 0.0789,V Acc: 0.6091, Top 70th Acc: 0.7013, Bottom 30th Acc: 0.3939
Fold [4/5] Epoch [30/100] Initial Loss: 0.1433, Training Loss: 0.0771, Initial Validation Loss: 0.1306, Validation Loss: 0.0796,V Acc: 0.6091, Top 70th Acc: 0.7143, Bottom 30th Acc: 0.3636
Stopping early at Epoch (base 0): 34  Rolling back to Epoch (base 0): 29  Top Validation Acc: 0.7012987012987013
78 3 [array([0.12498485, 0.35397616, 0.14535545, 0.24523094, 0.13045262],
      dtype=float32)]
Fold [5/5] Epoch [0/100] Initial Loss: 0.1329, Training Loss: 0.1329, Initial Validation Loss: 0.1122, Validation Loss: 0.1122,V Acc: 0.4722, Top 70th Acc: 0.5526, Bottom 30th Acc: 0.2812
Fold [5/5] Epoch [10/100] Initial Loss: 0.1329, Training Loss: 0.0816, Initial Validation Loss: 0.1122, Validation Loss: 0.0717,V Acc: 0.6481, Top 70th Acc: 0.7895, Bottom 30th Acc: 0.3125
Fold [5/5] Epoch [20/100] Initial Loss: 0.1329, Training Loss: 0.0799, Initial Validation Loss: 0.1122, Validation Loss: 0.0707,V Acc: 0.6481, Top 70th Acc: 0.7895, Bottom 30th Acc: 0.3125
Fold [5/5] Epoch [30/100] Initial Loss: 0.1329, Training Loss: 0.0791, Initial Validation Loss: 0.1122, Validation Loss: 0.0699,V Acc: 0.6389, Top 70th Acc: 0.7895, Bottom 30th Acc: 0.2812
Stopping early at Epoch (base 0): 36  Rolling back to Epoch (base 0): 31  Top Validation Acc: 0.7763157894736842
Running train_nn.py with seed 79
CUDA:False
Training samples count:  550
Training on 2 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1409, Training Loss: 0.1409, Initial Validation Loss: 0.1336, Validation Loss: 0.1336,V Acc: 0.3604, Top 70th Acc: 0.4231, Bottom 30th Acc: 0.2121
Fold [1/5] Epoch [10/100] Initial Loss: 0.1409, Training Loss: 0.0787, Initial Validation Loss: 0.1336, Validation Loss: 0.0905,V Acc: 0.5766, Top 70th Acc: 0.6667, Bottom 30th Acc: 0.3636
Fold [1/5] Epoch [20/100] Initial Loss: 0.1409, Training Loss: 0.0767, Initial Validation Loss: 0.1336, Validation Loss: 0.0892,V Acc: 0.5856, Top 70th Acc: 0.6795, Bottom 30th Acc: 0.3636
Fold [1/5] Epoch [30/100] Initial Loss: 0.1409, Training Loss: 0.0762, Initial Validation Loss: 0.1336, Validation Loss: 0.0888,V Acc: 0.5856, Top 70th Acc: 0.6667, Bottom 30th Acc: 0.3939
Fold [1/5] Epoch [40/100] Initial Loss: 0.1409, Training Loss: 0.0758, Initial Validation Loss: 0.1336, Validation Loss: 0.0887,V Acc: 0.5856, Top 70th Acc: 0.6667, Bottom 30th Acc: 0.3939
Fold [1/5] Epoch [50/100] Initial Loss: 0.1409, Training Loss: 0.0754, Initial Validation Loss: 0.1336, Validation Loss: 0.0887,V Acc: 0.5676, Top 70th Acc: 0.6923, Bottom 30th Acc: 0.2727
Stopping early at Epoch (base 0): 51  Rolling back to Epoch (base 0): 46  Top Validation Acc: 0.6923076923076923
Fold [2/5] Epoch [0/100] Initial Loss: 0.1255, Training Loss: 0.1255, Initial Validation Loss: 0.1177, Validation Loss: 0.1177,V Acc: 0.4234, Top 70th Acc: 0.5128, Bottom 30th Acc: 0.2121
Fold [2/5] Epoch [10/100] Initial Loss: 0.1255, Training Loss: 0.0823, Initial Validation Loss: 0.1177, Validation Loss: 0.0857,V Acc: 0.6216, Top 70th Acc: 0.7308, Bottom 30th Acc: 0.3636
Fold [2/5] Epoch [20/100] Initial Loss: 0.1255, Training Loss: 0.0781, Initial Validation Loss: 0.1177, Validation Loss: 0.0820,V Acc: 0.6216, Top 70th Acc: 0.7436, Bottom 30th Acc: 0.3333
Fold [2/5] Epoch [20/100] Initial Loss: 0.1383, Training Loss: 0.0200, Initial Validation Loss: 0.1411, Validation Loss: 0.0360,V Acc: 0.8468, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.5455
Fold [2/5] Epoch [30/100] Initial Loss: 0.1383, Training Loss: 0.0161, Initial Validation Loss: 0.1411, Validation Loss: 0.0338,V Acc: 0.8468, Top 70th Acc: 0.9872, Bottom 30th Acc: 0.5152
Stopping early at Epoch (base 0): 31  Rolling back to Epoch (base 0): 26  Top Validation Acc: 0.9743589743589743
Fold [3/5] Epoch [0/100] Initial Loss: 0.1376, Training Loss: 0.1376, Initial Validation Loss: 0.1297, Validation Loss: 0.1297,V Acc: 0.2818, Top 70th Acc: 0.3766, Bottom 30th Acc: 0.0606
Fold [3/5] Epoch [10/100] Initial Loss: 0.1376, Training Loss: 0.0377, Initial Validation Loss: 0.1297, Validation Loss: 0.0428,V Acc: 0.7727, Top 70th Acc: 0.8961, Bottom 30th Acc: 0.4848
Fold [3/5] Epoch [20/100] Initial Loss: 0.1376, Training Loss: 0.0194, Initial Validation Loss: 0.1297, Validation Loss: 0.0326,V Acc: 0.8091, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.4848
Stopping early at Epoch (base 0): 21  Rolling back to Epoch (base 0): 16  Top Validation Acc: 0.922077922077922
Fold [4/5] Epoch [0/100] Initial Loss: 0.1391, Training Loss: 0.1391, Initial Validation Loss: 0.1362, Validation Loss: 0.1362,V Acc: 0.2909, Top 70th Acc: 0.3247, Bottom 30th Acc: 0.2121
Fold [4/5] Epoch [10/100] Initial Loss: 0.1391, Training Loss: 0.0381, Initial Validation Loss: 0.1362, Validation Loss: 0.0360,V Acc: 0.8636, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.6970
Fold [4/5] Epoch [20/100] Initial Loss: 0.1391, Training Loss: 0.0200, Initial Validation Loss: 0.1362, Validation Loss: 0.0261,V Acc: 0.8727, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 28  Rolling back to Epoch (base 0): 23  Top Validation Acc: 0.961038961038961
Fold [5/5] Epoch [0/100] Initial Loss: 0.1376, Training Loss: 0.1376, Initial Validation Loss: 0.1326, Validation Loss: 0.1326,V Acc: 0.2500, Top 70th Acc: 0.3026, Bottom 30th Acc: 0.1250
Fold [5/5] Epoch [10/100] Initial Loss: 0.1376, Training Loss: 0.0374, Initial Validation Loss: 0.1326, Validation Loss: 0.0434,V Acc: 0.7963, Top 70th Acc: 0.9079, Bottom 30th Acc: 0.5312
Fold [5/5] Epoch [20/100] Initial Loss: 0.1376, Training Loss: 0.0227, Initial Validation Loss: 0.1326, Validation Loss: 0.0408,V Acc: 0.7963, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.4688
Fold [5/5] Epoch [30/100] Initial Loss: 0.1376, Training Loss: 0.0165, Initial Validation Loss: 0.1326, Validation Loss: 0.0369,V Acc: 0.7870, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.4062
Fold [5/5] Epoch [40/100] Initial Loss: 0.1376, Training Loss: 0.0144, Initial Validation Loss: 0.1326, Validation Loss: 0.0363,V Acc: 0.7778, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.3750
Stopping early at Epoch (base 0): 48  Rolling back to Epoch (base 0): 43  Top Validation Acc: 0.9342105263157895
Running train_nn.py with seed 83
CUDA:False
Training samples count:  550
Training on 30 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1401, Training Loss: 0.1401, Initial Validation Loss: 0.1340, Validation Loss: 0.1340,V Acc: 0.3153, Top 70th Acc: 0.3333, Bottom 30th Acc: 0.2727
Fold [1/5] Epoch [10/100] Initial Loss: 0.1401, Training Loss: 0.0357, Initial Validation Loss: 0.1340, Validation Loss: 0.0435,V Acc: 0.7928, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.5152
Fold [1/5] Epoch [20/100] Initial Loss: 0.1401, Training Loss: 0.0195, Initial Validation Loss: 0.1340, Validation Loss: 0.0328,V Acc: 0.8378, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.9358974358974359
Fold [2/5] Epoch [0/100] Initial Loss: 0.1370, Training Loss: 0.1370, Initial Validation Loss: 0.1403, Validation Loss: 0.1403,V Acc: 0.3333, Top 70th Acc: 0.3590, Bottom 30th Acc: 0.2727
Fold [2/5] Epoch [10/100] Initial Loss: 0.1370, Training Loss: 0.0369, Initial Validation Loss: 0.1403, Validation Loss: 0.0341,V Acc: 0.8919, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.7273
Fold [2/5] Epoch [20/100] Initial Loss: 0.1370, Training Loss: 0.0257, Initial Validation Loss: 0.1403, Validation Loss: 0.0288,V Acc: 0.8739, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.6364
Fold [2/5] Epoch [30/100] Initial Loss: 0.1370, Training Loss: 0.0205, Initial Validation Loss: 0.1403, Validation Loss: 0.0257,V Acc: 0.9009, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.7273
Fold [2/5] Epoch [40/100] Initial Loss: 0.1370, Training Loss: 0.0173, Initial Validation Loss: 0.1403, Validation Loss: 0.0236,V Acc: 0.9189, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.7879
Stopping early at Epoch (base 0): 47  Rolling back to Epoch (base 0): 42  Top Validation Acc: 0.9487179487179487
Fold [3/5] Epoch [0/100] Initial Loss: 0.1375, Training Loss: 0.1375, Initial Validation Loss: 0.1307, Validation Loss: 0.1307,V Acc: 0.3636, Top 70th Acc: 0.3766, Bottom 30th Acc: 0.3333
Fold [3/5] Epoch [10/100] Initial Loss: 0.1375, Training Loss: 0.0406, Initial Validation Loss: 0.1307, Validation Loss: 0.0462,V Acc: 0.7636, Top 70th Acc: 0.8831, Bottom 30th Acc: 0.4848
Fold [3/5] Epoch [20/100] Initial Loss: 0.1375, Training Loss: 0.0179, Initial Validation Loss: 0.1307, Validation Loss: 0.0371,V Acc: 0.7909, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.4848
Stopping early at Epoch (base 0): 21  Rolling back to Epoch (base 0): 16  Top Validation Acc: 0.922077922077922
Fold [4/5] Epoch [0/100] Initial Loss: 0.1380, Training Loss: 0.1380, Initial Validation Loss: 0.1321, Validation Loss: 0.1321,V Acc: 0.4091, Top 70th Acc: 0.4416, Bottom 30th Acc: 0.3333
Fold [4/5] Epoch [10/100] Initial Loss: 0.1380, Training Loss: 0.0303, Initial Validation Loss: 0.1321, Validation Loss: 0.0399,V Acc: 0.8273, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.6061
Fold [4/5] Epoch [20/100] Initial Loss: 0.1380, Training Loss: 0.0189, Initial Validation Loss: 0.1321, Validation Loss: 0.0295,V Acc: 0.8636, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 28  Rolling back to Epoch (base 0): 23  Top Validation Acc: 0.961038961038961
Fold [5/5] Epoch [0/100] Initial Loss: 0.1398, Training Loss: 0.1398, Initial Validation Loss: 0.1267, Validation Loss: 0.1267,V Acc: 0.3611, Top 70th Acc: 0.3947, Bottom 30th Acc: 0.2812
Fold [5/5] Epoch [10/100] Initial Loss: 0.1398, Training Loss: 0.0267, Initial Validation Loss: 0.1267, Validation Loss: 0.0338,V Acc: 0.7963, Top 70th Acc: 0.9211, Bottom 30th Acc: 0.5000
Fold [5/5] Epoch [20/100] Initial Loss: 0.1398, Training Loss: 0.0169, Initial Validation Loss: 0.1267, Validation Loss: 0.0316,V Acc: 0.8056, Top 70th Acc: 0.8947, Bottom 30th Acc: 0.5938
Stopping early at Epoch (base 0): 22  Rolling back to Epoch (base 0): 17  Top Validation Acc: 0.8947368421052632
83 4 [array([0.6270981 , 0.04309326, 0.04423937, 0.12951864, 0.15605064],
      dtype=float32)]
Running train_nn.py with seed 84
CUDA:False
Training samples count:  550
Training on 30 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1394, Training Loss: 0.1394, Initial Validation Loss: 0.1350, Validation Loss: 0.1350,V Acc: 0.2523, Top 70th Acc: 0.3333, Bottom 30th Acc: 0.0606
Fold [1/5] Epoch [10/100] Initial Loss: 0.1394, Training Loss: 0.0381, Initial Validation Loss: 0.1350, Validation Loss: 0.0385,V Acc: 0.8378, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.6364
Fold [1/5] Epoch [20/100] Initial Loss: 0.1394, Training Loss: 0.0194, Initial Validation Loss: 0.1350, Validation Loss: 0.0302,V Acc: 0.8468, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.9487179487179487
84 0 [array([0.4455478 , 0.14303568, 0.1400975 , 0.07915835, 0.19216067],
      dtype=float32)]
Fold [2/5] Epoch [0/100] Initial Loss: 0.1390, Training Loss: 0.1390, Initial Validation Loss: 0.1387, Validation Loss: 0.1387,V Acc: 0.3063, Top 70th Acc: 0.3590, Bottom 30th Acc: 0.1818
Fold [2/5] Epoch [10/100] Initial Loss: 0.1390, Training Loss: 0.0385, Initial Validation Loss: 0.1387, Validation Loss: 0.0434,V Acc: 0.8018, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.4242
Fold [2/5] Epoch [20/100] Initial Loss: 0.1390, Training Loss: 0.0199, Initial Validation Loss: 0.1387, Validation Loss: 0.0329,V Acc: 0.8468, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.5758
Fold [2/5] Epoch [10/100] Initial Loss: 0.1384, Training Loss: 0.0490, Initial Validation Loss: 0.1404, Validation Loss: 0.0528,V Acc: 0.7387, Top 70th Acc: 0.8974, Bottom 30th Acc: 0.3636
Fold [2/5] Epoch [20/100] Initial Loss: 0.1384, Training Loss: 0.0260, Initial Validation Loss: 0.1404, Validation Loss: 0.0337,V Acc: 0.8378, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.5758
Fold [2/5] Epoch [30/100] Initial Loss: 0.1384, Training Loss: 0.0221, Initial Validation Loss: 0.1404, Validation Loss: 0.0321,V Acc: 0.8378, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.5152
Stopping early at Epoch (base 0): 31  Rolling back to Epoch (base 0): 26  Top Validation Acc: 0.9615384615384616
Fold [3/5] Epoch [0/100] Initial Loss: 0.1400, Training Loss: 0.1400, Initial Validation Loss: 0.1356, Validation Loss: 0.1356,V Acc: 0.2636, Top 70th Acc: 0.3377, Bottom 30th Acc: 0.0909
Fold [3/5] Epoch [10/100] Initial Loss: 0.1400, Training Loss: 0.0353, Initial Validation Loss: 0.1356, Validation Loss: 0.0518,V Acc: 0.7727, Top 70th Acc: 0.8182, Bottom 30th Acc: 0.6667
Fold [3/5] Epoch [20/100] Initial Loss: 0.1400, Training Loss: 0.0215, Initial Validation Loss: 0.1356, Validation Loss: 0.0444,V Acc: 0.8091, Top 70th Acc: 0.8701, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 28  Rolling back to Epoch (base 0): 23  Top Validation Acc: 0.8831168831168831
Fold [4/5] Epoch [0/100] Initial Loss: 0.1409, Training Loss: 0.1409, Initial Validation Loss: 0.1295, Validation Loss: 0.1295,V Acc: 0.3000, Top 70th Acc: 0.3247, Bottom 30th Acc: 0.2424
Fold [4/5] Epoch [10/100] Initial Loss: 0.1409, Training Loss: 0.0341, Initial Validation Loss: 0.1295, Validation Loss: 0.0337,V Acc: 0.8364, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.6364
Fold [4/5] Epoch [20/100] Initial Loss: 0.1409, Training Loss: 0.0238, Initial Validation Loss: 0.1295, Validation Loss: 0.0294,V Acc: 0.8364, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.935064935064935
Fold [5/5] Epoch [0/100] Initial Loss: 0.1365, Training Loss: 0.1365, Initial Validation Loss: 0.1322, Validation Loss: 0.1322,V Acc: 0.4167, Top 70th Acc: 0.4605, Bottom 30th Acc: 0.3125
Fold [5/5] Epoch [10/100] Initial Loss: 0.1365, Training Loss: 0.0320, Initial Validation Loss: 0.1322, Validation Loss: 0.0340,V Acc: 0.8704, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.7188
Stopping early at Epoch (base 0): 19  Rolling back to Epoch (base 0): 14  Top Validation Acc: 0.9473684210526315
Running train_nn.py with seed 85
CUDA:False
Training samples count:  550
Training on 20 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1413, Training Loss: 0.1413, Initial Validation Loss: 0.1340, Validation Loss: 0.1340,V Acc: 0.2883, Top 70th Acc: 0.3462, Bottom 30th Acc: 0.1515
Fold [1/5] Epoch [10/100] Initial Loss: 0.1413, Training Loss: 0.0300, Initial Validation Loss: 0.1340, Validation Loss: 0.0330,V Acc: 0.8468, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.5455
Fold [1/5] Epoch [20/100] Initial Loss: 0.1413, Training Loss: 0.0218, Initial Validation Loss: 0.1340, Validation Loss: 0.0288,V Acc: 0.8739, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.6667
Fold [1/5] Epoch [30/100] Initial Loss: 0.1413, Training Loss: 0.0196, Initial Validation Loss: 0.1340, Validation Loss: 0.0298,V Acc: 0.8649, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 30  Rolling back to Epoch (base 0): 25  Top Validation Acc: 0.9487179487179487
Fold [2/5] Epoch [0/100] Initial Loss: 0.1365, Training Loss: 0.1365, Initial Validation Loss: 0.1361, Validation Loss: 0.1361,V Acc: 0.3333, Top 70th Acc: 0.3718, Bottom 30th Acc: 0.2424
Fold [2/5] Epoch [10/100] Initial Loss: 0.1365, Training Loss: 0.0318, Initial Validation Loss: 0.1361, Validation Loss: 0.0415,V Acc: 0.8108, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.5758
Fold [2/5] Epoch [20/100] Initial Loss: 0.1365, Training Loss: 0.0214, Initial Validation Loss: 0.1361, Validation Loss: 0.0342,V Acc: 0.8378, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.6364
Fold [2/5] Epoch [30/100] Initial Loss: 0.1365, Training Loss: 0.0200, Initial Validation Loss: 0.1361, Validation Loss: 0.0327,V Acc: 0.8288, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 30  Rolling back to Epoch (base 0): 25  Top Validation Acc: 0.9358974358974359
85 1 [array([0.5567734 , 0.03163745, 0.18990286, 0.11934907, 0.10233719],
      dtype=float32)]
Fold [3/5] Epoch [0/100] Initial Loss: 0.1379, Training Loss: 0.1379, Initial Validation Loss: 0.1382, Validation Loss: 0.1382,V Acc: 0.2545, Top 70th Acc: 0.3117, Bottom 30th Acc: 0.1212
Fold [3/5] Epoch [10/100] Initial Loss: 0.1379, Training Loss: 0.0366, Initial Validation Loss: 0.1382, Validation Loss: 0.0331,V Acc: 0.9091, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.7879
Fold [3/5] Epoch [20/100] Initial Loss: 0.1379, Training Loss: 0.0239, Initial Validation Loss: 0.1382, Validation Loss: 0.0263,V Acc: 0.8727, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6970
Fold [3/5] Epoch [30/100] Initial Loss: 0.1379, Training Loss: 0.0217, Initial Validation Loss: 0.1382, Validation Loss: 0.0262,V Acc: 0.8727, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 31  Rolling back to Epoch (base 0): 26  Top Validation Acc: 0.948051948051948
Fold [4/5] Epoch [0/100] Initial Loss: 0.1396, Training Loss: 0.1396, Initial Validation Loss: 0.1343, Validation Loss: 0.1343,V Acc: 0.2545, Top 70th Acc: 0.3506, Bottom 30th Acc: 0.0303
Fold [4/5] Epoch [10/100] Initial Loss: 0.1396, Training Loss: 0.0290, Initial Validation Loss: 0.1343, Validation Loss: 0.0378,V Acc: 0.8455, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6061
Fold [4/5] Epoch [20/100] Initial Loss: 0.1396, Training Loss: 0.0212, Initial Validation Loss: 0.1343, Validation Loss: 0.0366,V Acc: 0.8455, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 20  Rolling back to Epoch (base 0): 15  Top Validation Acc: 0.948051948051948
Fold [5/5] Epoch [0/100] Initial Loss: 0.1419, Training Loss: 0.1419, Initial Validation Loss: 0.1273, Validation Loss: 0.1273,V Acc: 0.2593, Top 70th Acc: 0.3421, Bottom 30th Acc: 0.0625
Fold [5/5] Epoch [10/100] Initial Loss: 0.1419, Training Loss: 0.0304, Initial Validation Loss: 0.1273, Validation Loss: 0.0355,V Acc: 0.7963, Top 70th Acc: 0.8947, Bottom 30th Acc: 0.5625
Fold [5/5] Epoch [20/100] Initial Loss: 0.1419, Training Loss: 0.0206, Initial Validation Loss: 0.1273, Validation Loss: 0.0320,V Acc: 0.8333, Top 70th Acc: 0.8947, Bottom 30th Acc: 0.6875
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.8947368421052632
Running train_nn.py with seed 86
CUDA:False
Training samples count:  550
Training on 20 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1376, Training Loss: 0.1376, Initial Validation Loss: 0.1340, Validation Loss: 0.1340,V Acc: 0.2613, Top 70th Acc: 0.3333, Bottom 30th Acc: 0.0909
Fold [1/5] Epoch [10/100] Initial Loss: 0.1376, Training Loss: 0.0292, Initial Validation Loss: 0.1340, Validation Loss: 0.0330,V Acc: 0.8649, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.6667
Fold [1/5] Epoch [20/100] Initial Loss: 0.1376, Training Loss: 0.0218, Initial Validation Loss: 0.1340, Validation Loss: 0.0307,V Acc: 0.8739, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 21  Rolling back to Epoch (base 0): 16  Top Validation Acc: 0.9487179487179487
Fold [2/5] Epoch [0/100] Initial Loss: 0.1384, Training Loss: 0.1384, Initial Validation Loss: 0.1320, Validation Loss: 0.1320,V Acc: 0.2883, Top 70th Acc: 0.3333, Bottom 30th Acc: 0.1818
Fold [2/5] Epoch [10/100] Initial Loss: 0.1384, Training Loss: 0.0364, Initial Validation Loss: 0.1320, Validation Loss: 0.0357,V Acc: 0.8559, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.6667
Fold [2/5] Epoch [20/100] Initial Loss: 0.1384, Training Loss: 0.0242, Initial Validation Loss: 0.1320, Validation Loss: 0.0268,V Acc: 0.8829, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.7576
Stopping early at Epoch (base 0): 22  Rolling back to Epoch (base 0): 17  Top Validation Acc: 0.9358974358974359
Fold [3/5] Epoch [0/100] Initial Loss: 0.1397, Training Loss: 0.1397, Initial Validation Loss: 0.1350, Validation Loss: 0.1350,V Acc: 0.2636, Top 70th Acc: 0.2857, Bottom 30th Acc: 0.2121
Fold [4/5] Epoch [20/100] Initial Loss: 0.1426, Training Loss: 0.0053, Initial Validation Loss: 0.1345, Validation Loss: 0.0277,V Acc: 0.8636, Top 70th Acc: 0.9870, Bottom 30th Acc: 0.5758
Fold [4/5] Epoch [30/100] Initial Loss: 0.1426, Training Loss: 0.0042, Initial Validation Loss: 0.1345, Validation Loss: 0.0277,V Acc: 0.8455, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 30  Rolling back to Epoch (base 0): 25  Top Validation Acc: 0.974025974025974
Fold [5/5] Epoch [0/100] Initial Loss: 0.1379, Training Loss: 0.1379, Initial Validation Loss: 0.1343, Validation Loss: 0.1343,V Acc: 0.2500, Top 70th Acc: 0.3553, Bottom 30th Acc: 0.0000
Fold [5/5] Epoch [10/100] Initial Loss: 0.1379, Training Loss: 0.0192, Initial Validation Loss: 0.1343, Validation Loss: 0.0304,V Acc: 0.8704, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.6875
Fold [5/5] Epoch [20/100] Initial Loss: 0.1379, Training Loss: 0.0047, Initial Validation Loss: 0.1343, Validation Loss: 0.0232,V Acc: 0.9074, Top 70th Acc: 0.9868, Bottom 30th Acc: 0.7188
Fold [5/5] Epoch [30/100] Initial Loss: 0.1379, Training Loss: 0.0036, Initial Validation Loss: 0.1343, Validation Loss: 0.0230,V Acc: 0.8981, Top 70th Acc: 1.0000, Bottom 30th Acc: 0.6562
Stopping early at Epoch (base 0): 33  Rolling back to Epoch (base 0): 28  Top Validation Acc: 1.0
Running train_nn.py with seed 64
CUDA:False
Training samples count:  550
Training on 163 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1386, Training Loss: 0.1386, Initial Validation Loss: 0.1364, Validation Loss: 0.1364,V Acc: 0.2793, Top 70th Acc: 0.3590, Bottom 30th Acc: 0.0909
Fold [1/5] Epoch [10/100] Initial Loss: 0.1386, Training Loss: 0.0151, Initial Validation Loss: 0.1364, Validation Loss: 0.0398,V Acc: 0.8288, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.5455
Fold [1/5] Epoch [20/100] Initial Loss: 0.1386, Training Loss: 0.0049, Initial Validation Loss: 0.1364, Validation Loss: 0.0355,V Acc: 0.8378, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.5758
Fold [1/5] Epoch [30/100] Initial Loss: 0.1386, Training Loss: 0.0039, Initial Validation Loss: 0.1364, Validation Loss: 0.0348,V Acc: 0.8468, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 33  Rolling back to Epoch (base 0): 28  Top Validation Acc: 0.9358974358974359
Fold [2/5] Epoch [0/100] Initial Loss: 0.1373, Training Loss: 0.1373, Initial Validation Loss: 0.1308, Validation Loss: 0.1308,V Acc: 0.3694, Top 70th Acc: 0.4359, Bottom 30th Acc: 0.2121
Fold [2/5] Epoch [10/100] Initial Loss: 0.1373, Training Loss: 0.0108, Initial Validation Loss: 0.1308, Validation Loss: 0.0289,V Acc: 0.8378, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.6061
Fold [2/5] Epoch [20/100] Initial Loss: 0.1373, Training Loss: 0.0044, Initial Validation Loss: 0.1308, Validation Loss: 0.0269,V Acc: 0.8559, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 22  Rolling back to Epoch (base 0): 17  Top Validation Acc: 0.9615384615384616
Fold [3/5] Epoch [0/100] Initial Loss: 0.1388, Training Loss: 0.1388, Initial Validation Loss: 0.1347, Validation Loss: 0.1347,V Acc: 0.3182, Top 70th Acc: 0.4026, Bottom 30th Acc: 0.1212
Fold [3/5] Epoch [10/100] Initial Loss: 0.1388, Training Loss: 0.0177, Initial Validation Loss: 0.1347, Validation Loss: 0.0327,V Acc: 0.8182, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.5152
Fold [3/5] Epoch [20/100] Initial Loss: 0.1388, Training Loss: 0.0054, Initial Validation Loss: 0.1347, Validation Loss: 0.0265,V Acc: 0.8727, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6970
Fold [3/5] Epoch [30/100] Initial Loss: 0.1388, Training Loss: 0.0042, Initial Validation Loss: 0.1347, Validation Loss: 0.0262,V Acc: 0.8818, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.7273
Stopping early at Epoch (base 0): 30  Rolling back to Epoch (base 0): 25  Top Validation Acc: 0.948051948051948
Fold [4/5] Epoch [0/100] Initial Loss: 0.1411, Training Loss: 0.1411, Initial Validation Loss: 0.1366, Validation Loss: 0.1366,V Acc: 0.3000, Top 70th Acc: 0.3117, Bottom 30th Acc: 0.2727
Fold [4/5] Epoch [10/100] Initial Loss: 0.1411, Training Loss: 0.0204, Initial Validation Loss: 0.1366, Validation Loss: 0.0404,V Acc: 0.8182, Top 70th Acc: 0.8961, Bottom 30th Acc: 0.6364
Fold [4/5] Epoch [20/100] Initial Loss: 0.1411, Training Loss: 0.0055, Initial Validation Loss: 0.1366, Validation Loss: 0.0334,V Acc: 0.8364, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.6061
Fold [4/5] Epoch [30/100] Initial Loss: 0.1411, Training Loss: 0.0042, Initial Validation Loss: 0.1366, Validation Loss: 0.0313,V Acc: 0.8636, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6667
Fold [4/5] Epoch [40/100] Initial Loss: 0.1411, Training Loss: 0.0039, Initial Validation Loss: 0.1366, Validation Loss: 0.0293,V Acc: 0.8636, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.6364
Fold [4/5] Epoch [50/100] Initial Loss: 0.1411, Training Loss: 0.0038, Initial Validation Loss: 0.1366, Validation Loss: 0.0278,V Acc: 0.8636, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.6364
Fold [4/5] Epoch [60/100] Initial Loss: 0.1411, Training Loss: 0.0036, Initial Validation Loss: 0.1366, Validation Loss: 0.0271,V Acc: 0.8636, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.6061
Fold [4/5] Epoch [70/100] Initial Loss: 0.1411, Training Loss: 0.0036, Initial Validation Loss: 0.1366, Validation Loss: 0.0262,V Acc: 0.8636, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.6061
Fold [4/5] Epoch [80/100] Initial Loss: 0.1411, Training Loss: 0.0035, Initial Validation Loss: 0.1366, Validation Loss: 0.0258,V Acc: 0.8636, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 82  Rolling back to Epoch (base 0): 77  Top Validation Acc: 0.974025974025974
64 3 [array([0.32179698, 0.04085372, 0.08110881, 0.29420337, 0.26203713],
      dtype=float32)]
Fold [5/5] Epoch [0/100] Initial Loss: 0.1367, Training Loss: 0.1367, Initial Validation Loss: 0.1300, Validation Loss: 0.1300,V Acc: 0.3889, Top 70th Acc: 0.4868, Bottom 30th Acc: 0.1562
Fold [5/5] Epoch [10/100] Initial Loss: 0.1367, Training Loss: 0.0272, Initial Validation Loss: 0.1300, Validation Loss: 0.0553,V Acc: 0.6944, Top 70th Acc: 0.8289, Bottom 30th Acc: 0.3750
Fold [5/5] Epoch [20/100] Initial Loss: 0.1367, Training Loss: 0.0073, Initial Validation Loss: 0.1300, Validation Loss: 0.0509,V Acc: 0.7500, Top 70th Acc: 0.8553, Bottom 30th Acc: 0.5000
Fold [5/5] Epoch [30/100] Initial Loss: 0.1367, Training Loss: 0.0043, Initial Validation Loss: 0.1300, Validation Loss: 0.0442,V Acc: 0.7685, Top 70th Acc: 0.9079, Bottom 30th Acc: 0.4375
Fold [5/5] Epoch [40/100] Initial Loss: 0.1367, Training Loss: 0.0036, Initial Validation Loss: 0.1300, Validation Loss: 0.0421,V Acc: 0.7593, Top 70th Acc: 0.9079, Bottom 30th Acc: 0.4062
Fold [5/5] Epoch [50/100] Initial Loss: 0.1367, Training Loss: 0.0033, Initial Validation Loss: 0.1300, Validation Loss: 0.0404,V Acc: 0.7500, Top 70th Acc: 0.9211, Bottom 30th Acc: 0.3438
Fold [5/5] Epoch [60/100] Initial Loss: 0.1367, Training Loss: 0.0032, Initial Validation Loss: 0.1300, Validation Loss: 0.0389,V Acc: 0.7500, Top 70th Acc: 0.9211, Bottom 30th Acc: 0.3438
Fold [5/5] Epoch [70/100] Initial Loss: 0.1367, Training Loss: 0.0031, Initial Validation Loss: 0.1300, Validation Loss: 0.0384,V Acc: 0.7593, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.3438
Stopping early at Epoch (base 0): 74  Rolling back to Epoch (base 0): 69  Top Validation Acc: 0.9342105263157895
Running train_nn.py with seed 65
CUDA:False
Training samples count:  550
Training on 163 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1384, Training Loss: 0.1384, Initial Validation Loss: 0.1355, Validation Loss: 0.1355,V Acc: 0.3514, Top 70th Acc: 0.4615, Bottom 30th Acc: 0.0909
Fold [1/5] Epoch [10/100] Initial Loss: 0.1384, Training Loss: 0.0194, Initial Validation Loss: 0.1355, Validation Loss: 0.0372,V Acc: 0.8468, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.6364
Fold [1/5] Epoch [20/100] Initial Loss: 0.1384, Training Loss: 0.0060, Initial Validation Loss: 0.1355, Validation Loss: 0.0350,V Acc: 0.8288, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.9358974358974359
65 0 [array([0.1901521 , 0.02305317, 0.05636031, 0.09296612, 0.6374683 ],
      dtype=float32)]
Fold [1/5] Epoch [30/100] Initial Loss: 0.1403, Training Loss: 0.0105, Initial Validation Loss: 0.1320, Validation Loss: 0.0355,V Acc: 0.8108, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 30  Rolling back to Epoch (base 0): 25  Top Validation Acc: 0.9230769230769231
82 0 [array([0.5924238 , 0.03211502, 0.04487893, 0.13503288, 0.19554937],
      dtype=float32)]
Fold [2/5] Epoch [0/100] Initial Loss: 0.1360, Training Loss: 0.1360, Initial Validation Loss: 0.1419, Validation Loss: 0.1419,V Acc: 0.2883, Top 70th Acc: 0.3205, Bottom 30th Acc: 0.2121
Fold [2/5] Epoch [10/100] Initial Loss: 0.1360, Training Loss: 0.0334, Initial Validation Loss: 0.1419, Validation Loss: 0.0458,V Acc: 0.8288, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.6061
Fold [2/5] Epoch [20/100] Initial Loss: 0.1360, Training Loss: 0.0150, Initial Validation Loss: 0.1419, Validation Loss: 0.0329,V Acc: 0.8649, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.6364
Fold [2/5] Epoch [30/100] Initial Loss: 0.1360, Training Loss: 0.0118, Initial Validation Loss: 0.1419, Validation Loss: 0.0321,V Acc: 0.8559, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 33  Rolling back to Epoch (base 0): 28  Top Validation Acc: 0.9487179487179487
Fold [3/5] Epoch [0/100] Initial Loss: 0.1388, Training Loss: 0.1388, Initial Validation Loss: 0.1303, Validation Loss: 0.1303,V Acc: 0.2636, Top 70th Acc: 0.3247, Bottom 30th Acc: 0.1212
Fold [3/5] Epoch [10/100] Initial Loss: 0.1388, Training Loss: 0.0365, Initial Validation Loss: 0.1303, Validation Loss: 0.0397,V Acc: 0.7636, Top 70th Acc: 0.8831, Bottom 30th Acc: 0.4848
Fold [3/5] Epoch [20/100] Initial Loss: 0.1388, Training Loss: 0.0155, Initial Validation Loss: 0.1303, Validation Loss: 0.0268,V Acc: 0.8364, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.5152
Fold [3/5] Epoch [30/100] Initial Loss: 0.1388, Training Loss: 0.0120, Initial Validation Loss: 0.1303, Validation Loss: 0.0256,V Acc: 0.8455, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 35  Rolling back to Epoch (base 0): 30  Top Validation Acc: 0.974025974025974
Fold [4/5] Epoch [0/100] Initial Loss: 0.1388, Training Loss: 0.1388, Initial Validation Loss: 0.1353, Validation Loss: 0.1353,V Acc: 0.3091, Top 70th Acc: 0.4026, Bottom 30th Acc: 0.0909
Fold [4/5] Epoch [10/100] Initial Loss: 0.1388, Training Loss: 0.0430, Initial Validation Loss: 0.1353, Validation Loss: 0.0400,V Acc: 0.7909, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.5152
Fold [4/5] Epoch [20/100] Initial Loss: 0.1388, Training Loss: 0.0167, Initial Validation Loss: 0.1353, Validation Loss: 0.0253,V Acc: 0.8909, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.7273
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.961038961038961
Fold [5/5] Epoch [0/100] Initial Loss: 0.1358, Training Loss: 0.1358, Initial Validation Loss: 0.1296, Validation Loss: 0.1296,V Acc: 0.4537, Top 70th Acc: 0.5658, Bottom 30th Acc: 0.1875
Fold [5/5] Epoch [10/100] Initial Loss: 0.1358, Training Loss: 0.0305, Initial Validation Loss: 0.1296, Validation Loss: 0.0384,V Acc: 0.8241, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.5625
Fold [5/5] Epoch [20/100] Initial Loss: 0.1358, Training Loss: 0.0140, Initial Validation Loss: 0.1296, Validation Loss: 0.0302,V Acc: 0.8333, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.5312
Stopping early at Epoch (base 0): 22  Rolling back to Epoch (base 0): 17  Top Validation Acc: 0.9473684210526315
Running train_nn.py with seed 83
CUDA:False
Training samples count:  550
Training on 40 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1383, Training Loss: 0.1383, Initial Validation Loss: 0.1329, Validation Loss: 0.1329,V Acc: 0.3694, Top 70th Acc: 0.4359, Bottom 30th Acc: 0.2121
Fold [1/5] Epoch [10/100] Initial Loss: 0.1383, Training Loss: 0.0306, Initial Validation Loss: 0.1329, Validation Loss: 0.0393,V Acc: 0.8378, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.5758
Fold [1/5] Epoch [20/100] Initial Loss: 0.1383, Training Loss: 0.0152, Initial Validation Loss: 0.1329, Validation Loss: 0.0312,V Acc: 0.8378, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.6061
Fold [1/5] Epoch [30/100] Initial Loss: 0.1383, Training Loss: 0.0124, Initial Validation Loss: 0.1329, Validation Loss: 0.0291,V Acc: 0.8559, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.6364
Fold [1/5] Epoch [40/100] Initial Loss: 0.1383, Training Loss: 0.0115, Initial Validation Loss: 0.1329, Validation Loss: 0.0297,V Acc: 0.8288, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 40  Rolling back to Epoch (base 0): 35  Top Validation Acc: 0.9487179487179487
Fold [2/5] Epoch [0/100] Initial Loss: 0.1397, Training Loss: 0.1397, Initial Validation Loss: 0.1425, Validation Loss: 0.1425,V Acc: 0.2523, Top 70th Acc: 0.1923, Bottom 30th Acc: 0.3939
Fold [2/5] Epoch [10/100] Initial Loss: 0.1397, Training Loss: 0.0378, Initial Validation Loss: 0.1425, Validation Loss: 0.0417,V Acc: 0.8649, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.6667
Fold [2/5] Epoch [20/100] Initial Loss: 0.1397, Training Loss: 0.0178, Initial Validation Loss: 0.1425, Validation Loss: 0.0256,V Acc: 0.9099, Top 70th Acc: 0.9872, Bottom 30th Acc: 0.7273
Fold [2/5] Epoch [30/100] Initial Loss: 0.1397, Training Loss: 0.0137, Initial Validation Loss: 0.1425, Validation Loss: 0.0234,V Acc: 0.9099, Top 70th Acc: 0.9872, Bottom 30th Acc: 0.7273
Stopping early at Epoch (base 0): 35  Rolling back to Epoch (base 0): 30  Top Validation Acc: 0.9871794871794872
Fold [3/5] Epoch [0/100] Initial Loss: 0.1406, Training Loss: 0.1406, Initial Validation Loss: 0.1312, Validation Loss: 0.1312,V Acc: 0.2545, Top 70th Acc: 0.3377, Bottom 30th Acc: 0.0606
Fold [3/5] Epoch [10/100] Initial Loss: 0.1406, Training Loss: 0.0355, Initial Validation Loss: 0.1312, Validation Loss: 0.0386,V Acc: 0.7909, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.4545
Stopping early at Epoch (base 0): 19  Rolling back to Epoch (base 0): 14  Top Validation Acc: 0.974025974025974
Fold [4/5] Epoch [0/100] Initial Loss: 0.1395, Training Loss: 0.1395, Initial Validation Loss: 0.1353, Validation Loss: 0.1353,V Acc: 0.2545, Top 70th Acc: 0.3377, Bottom 30th Acc: 0.0606
Fold [4/5] Epoch [10/100] Initial Loss: 0.1395, Training Loss: 0.0377, Initial Validation Loss: 0.1353, Validation Loss: 0.0445,V Acc: 0.7818, Top 70th Acc: 0.8961, Bottom 30th Acc: 0.5152
Fold [4/5] Epoch [20/100] Initial Loss: 0.1395, Training Loss: 0.0140, Initial Validation Loss: 0.1353, Validation Loss: 0.0295,V Acc: 0.8727, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.961038961038961
Fold [5/5] Epoch [0/100] Initial Loss: 0.1407, Training Loss: 0.1407, Initial Validation Loss: 0.1293, Validation Loss: 0.1293,V Acc: 0.2500, Top 70th Acc: 0.3289, Bottom 30th Acc: 0.0625
Fold [5/5] Epoch [10/100] Initial Loss: 0.1407, Training Loss: 0.0266, Initial Validation Loss: 0.1293, Validation Loss: 0.0377,V Acc: 0.8056, Top 70th Acc: 0.8947, Bottom 30th Acc: 0.5938
Fold [5/5] Epoch [20/100] Initial Loss: 0.1407, Training Loss: 0.0133, Initial Validation Loss: 0.1293, Validation Loss: 0.0318,V Acc: 0.8241, Top 70th Acc: 0.8947, Bottom 30th Acc: 0.6562
Fold [5/5] Epoch [30/100] Initial Loss: 0.1407, Training Loss: 0.0111, Initial Validation Loss: 0.1293, Validation Loss: 0.0320,V Acc: 0.8241, Top 70th Acc: 0.8947, Bottom 30th Acc: 0.6562
Fold [5/5] Epoch [40/100] Initial Loss: 0.1407, Training Loss: 0.0101, Initial Validation Loss: 0.1293, Validation Loss: 0.0317,V Acc: 0.8333, Top 70th Acc: 0.8947, Bottom 30th Acc: 0.6875
Stopping early at Epoch (base 0): 42  Rolling back to Epoch (base 0): 37  Top Validation Acc: 0.8947368421052632
83 4 [array([0.5909886 , 0.05313885, 0.06218041, 0.10268467, 0.19100747],
      dtype=float32)]
Running train_nn.py with seed 84
CUDA:False
Training samples count:  550
Training on 40 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1380, Training Loss: 0.1380, Initial Validation Loss: 0.1340, Validation Loss: 0.1340,V Acc: 0.3063, Top 70th Acc: 0.3333, Bottom 30th Acc: 0.2424
Fold [1/5] Epoch [10/100] Initial Loss: 0.1380, Training Loss: 0.0223, Initial Validation Loss: 0.1340, Validation Loss: 0.0347,V Acc: 0.8108, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.4545
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.7435897435897436
Fold [3/5] Epoch [0/100] Initial Loss: 0.1347, Training Loss: 0.1347, Initial Validation Loss: 0.1234, Validation Loss: 0.1234,V Acc: 0.4727, Top 70th Acc: 0.4805, Bottom 30th Acc: 0.4545
Fold [3/5] Epoch [10/100] Initial Loss: 0.1347, Training Loss: 0.0847, Initial Validation Loss: 0.1234, Validation Loss: 0.0692,V Acc: 0.6909, Top 70th Acc: 0.7792, Bottom 30th Acc: 0.4848
Fold [3/5] Epoch [20/100] Initial Loss: 0.1347, Training Loss: 0.0835, Initial Validation Loss: 0.1234, Validation Loss: 0.0651,V Acc: 0.7000, Top 70th Acc: 0.7922, Bottom 30th Acc: 0.4848
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.8051948051948052
Fold [4/5] Epoch [0/100] Initial Loss: 0.1332, Training Loss: 0.1332, Initial Validation Loss: 0.1248, Validation Loss: 0.1248,V Acc: 0.4636, Top 70th Acc: 0.4935, Bottom 30th Acc: 0.3939
Stopping early at Epoch (base 0): 9  Rolling back to Epoch (base 0): 4  Top Validation Acc: 0.6493506493506493
Fold [5/5] Epoch [0/100] Initial Loss: 0.1386, Training Loss: 0.1386, Initial Validation Loss: 0.1289, Validation Loss: 0.1289,V Acc: 0.3611, Top 70th Acc: 0.3289, Bottom 30th Acc: 0.4375
Fold [5/5] Epoch [10/100] Initial Loss: 0.1386, Training Loss: 0.0821, Initial Validation Loss: 0.1289, Validation Loss: 0.0746,V Acc: 0.6389, Top 70th Acc: 0.7763, Bottom 30th Acc: 0.3125
Fold [5/5] Epoch [20/100] Initial Loss: 0.1386, Training Loss: 0.0806, Initial Validation Loss: 0.1289, Validation Loss: 0.0727,V Acc: 0.6574, Top 70th Acc: 0.7632, Bottom 30th Acc: 0.4062
Fold [5/5] Epoch [30/100] Initial Loss: 0.1386, Training Loss: 0.0802, Initial Validation Loss: 0.1289, Validation Loss: 0.0715,V Acc: 0.6759, Top 70th Acc: 0.7763, Bottom 30th Acc: 0.4375
Fold [5/5] Epoch [40/100] Initial Loss: 0.1386, Training Loss: 0.0798, Initial Validation Loss: 0.1289, Validation Loss: 0.0711,V Acc: 0.6667, Top 70th Acc: 0.7632, Bottom 30th Acc: 0.4375
Stopping early at Epoch (base 0): 42  Rolling back to Epoch (base 0): 37  Top Validation Acc: 0.7631578947368421
79 4 [array([0.13032667, 0.3713864 , 0.13227692, 0.21168357, 0.1543264 ],
      dtype=float32)]
Running train_nn.py with seed 80
CUDA:False
Training samples count:  550
Training on 2 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1332, Training Loss: 0.1332, Initial Validation Loss: 0.1259, Validation Loss: 0.1259,V Acc: 0.3964, Top 70th Acc: 0.5513, Bottom 30th Acc: 0.0303
Fold [1/5] Epoch [10/100] Initial Loss: 0.1332, Training Loss: 0.0794, Initial Validation Loss: 0.1259, Validation Loss: 0.0858,V Acc: 0.6126, Top 70th Acc: 0.7436, Bottom 30th Acc: 0.3030
Fold [1/5] Epoch [20/100] Initial Loss: 0.1332, Training Loss: 0.0782, Initial Validation Loss: 0.1259, Validation Loss: 0.0842,V Acc: 0.6306, Top 70th Acc: 0.7564, Bottom 30th Acc: 0.3333
Fold [1/5] Epoch [30/100] Initial Loss: 0.1332, Training Loss: 0.0776, Initial Validation Loss: 0.1259, Validation Loss: 0.0839,V Acc: 0.6126, Top 70th Acc: 0.7692, Bottom 30th Acc: 0.2424
Stopping early at Epoch (base 0): 31  Rolling back to Epoch (base 0): 26  Top Validation Acc: 0.7564102564102564
Fold [2/5] Epoch [0/100] Initial Loss: 0.1352, Training Loss: 0.1352, Initial Validation Loss: 0.1333, Validation Loss: 0.1333,V Acc: 0.3514, Top 70th Acc: 0.4231, Bottom 30th Acc: 0.1818
Fold [2/5] Epoch [10/100] Initial Loss: 0.1352, Training Loss: 0.0798, Initial Validation Loss: 0.1333, Validation Loss: 0.0859,V Acc: 0.6036, Top 70th Acc: 0.7179, Bottom 30th Acc: 0.3333
Fold [2/5] Epoch [20/100] Initial Loss: 0.1352, Training Loss: 0.0775, Initial Validation Loss: 0.1333, Validation Loss: 0.0839,V Acc: 0.6216, Top 70th Acc: 0.7179, Bottom 30th Acc: 0.3939
Fold [2/5] Epoch [30/100] Initial Loss: 0.1352, Training Loss: 0.0772, Initial Validation Loss: 0.1333, Validation Loss: 0.0828,V Acc: 0.6306, Top 70th Acc: 0.7436, Bottom 30th Acc: 0.3636
Fold [2/5] Epoch [40/100] Initial Loss: 0.1352, Training Loss: 0.0768, Initial Validation Loss: 0.1333, Validation Loss: 0.0828,V Acc: 0.6306, Top 70th Acc: 0.7051, Bottom 30th Acc: 0.4545
Stopping early at Epoch (base 0): 40  Rolling back to Epoch (base 0): 35  Top Validation Acc: 0.7051282051282052
Fold [3/5] Epoch [0/100] Initial Loss: 0.1346, Training Loss: 0.1346, Initial Validation Loss: 0.1189, Validation Loss: 0.1189,V Acc: 0.4455, Top 70th Acc: 0.4675, Bottom 30th Acc: 0.3939
Fold [3/5] Epoch [10/100] Initial Loss: 0.1346, Training Loss: 0.0832, Initial Validation Loss: 0.1189, Validation Loss: 0.0697,V Acc: 0.7182, Top 70th Acc: 0.7532, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 18  Rolling back to Epoch (base 0): 13  Top Validation Acc: 0.7662337662337663
Fold [4/5] Epoch [0/100] Initial Loss: 0.1424, Training Loss: 0.1424, Initial Validation Loss: 0.1318, Validation Loss: 0.1318,V Acc: 0.3364, Top 70th Acc: 0.3636, Bottom 30th Acc: 0.2727
Fold [4/5] Epoch [10/100] Initial Loss: 0.1424, Training Loss: 0.0789, Initial Validation Loss: 0.1318, Validation Loss: 0.0881,V Acc: 0.5636, Top 70th Acc: 0.6623, Bottom 30th Acc: 0.3333
Stopping early at Epoch (base 0): 15  Rolling back to Epoch (base 0): 10  Top Validation Acc: 0.6493506493506493
Fold [5/5] Epoch [0/100] Initial Loss: 0.1367, Training Loss: 0.1367, Initial Validation Loss: 0.1296, Validation Loss: 0.1296,V Acc: 0.2778, Top 70th Acc: 0.3553, Bottom 30th Acc: 0.0938
Fold [5/5] Epoch [10/100] Initial Loss: 0.1367, Training Loss: 0.0826, Initial Validation Loss: 0.1296, Validation Loss: 0.0729,V Acc: 0.6667, Top 70th Acc: 0.7368, Bottom 30th Acc: 0.5000
Fold [5/5] Epoch [20/100] Initial Loss: 0.1367, Training Loss: 0.0809, Initial Validation Loss: 0.1296, Validation Loss: 0.0698,V Acc: 0.6667, Top 70th Acc: 0.7895, Bottom 30th Acc: 0.3750
Fold [5/5] Epoch [30/100] Initial Loss: 0.1367, Training Loss: 0.0804, Initial Validation Loss: 0.1296, Validation Loss: 0.0690,V Acc: 0.6667, Top 70th Acc: 0.8026, Bottom 30th Acc: 0.3438
Fold [5/5] Epoch [40/100] Initial Loss: 0.1367, Training Loss: 0.0792, Initial Validation Loss: 0.1296, Validation Loss: 0.0684,V Acc: 0.6667, Top 70th Acc: 0.8026, Bottom 30th Acc: 0.3438
Stopping early at Epoch (base 0): 43  Rolling back to Epoch (base 0): 38  Top Validation Acc: 0.8026315789473685
80 4 [array([0.14491174, 0.33138213, 0.12978761, 0.24536549, 0.14855304],
      dtype=float32)]
Running train_nn.py with seed 81
CUDA:False
Training samples count:  550
Training on 2 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1320, Training Loss: 0.1320, Initial Validation Loss: 0.1223, Validation Loss: 0.1223,V Acc: 0.4234, Top 70th Acc: 0.5513, Bottom 30th Acc: 0.1212
Fold [1/5] Epoch [10/100] Initial Loss: 0.1320, Training Loss: 0.0806, Initial Validation Loss: 0.1223, Validation Loss: 0.0811,V Acc: 0.5946, Top 70th Acc: 0.7308, Bottom 30th Acc: 0.2727
Fold [1/5] Epoch [20/100] Initial Loss: 0.1320, Training Loss: 0.0789, Initial Validation Loss: 0.1223, Validation Loss: 0.0783,V Acc: 0.6126, Top 70th Acc: 0.7436, Bottom 30th Acc: 0.3030
Stopping early at Epoch (base 0): 20  Rolling back to Epoch (base 0): 15  Top Validation Acc: 0.7435897435897436
Fold [2/5] Epoch [0/100] Initial Loss: 0.1373, Training Loss: 0.1373, Initial Validation Loss: 0.1251, Validation Loss: 0.1251,V Acc: 0.4414, Top 70th Acc: 0.5256, Bottom 30th Acc: 0.2424
Fold [2/5] Epoch [10/100] Initial Loss: 0.1373, Training Loss: 0.0757, Initial Validation Loss: 0.1251, Validation Loss: 0.0954,V Acc: 0.5405, Top 70th Acc: 0.6026, Bottom 30th Acc: 0.3939
Stopping early at Epoch (base 0): 11  Rolling back to Epoch (base 0): 6  Top Validation Acc: 0.6153846153846154
Fold [3/5] Epoch [0/100] Initial Loss: 0.1385, Training Loss: 0.1385, Initial Validation Loss: 0.1312, Validation Loss: 0.1312,V Acc: 0.4455, Top 70th Acc: 0.5455, Bottom 30th Acc: 0.2121
Fold [3/5] Epoch [10/100] Initial Loss: 0.1385, Training Loss: 0.0826, Initial Validation Loss: 0.1312, Validation Loss: 0.0742,V Acc: 0.6545, Top 70th Acc: 0.7403, Bottom 30th Acc: 0.4545
Fold [3/5] Epoch [20/100] Initial Loss: 0.1385, Training Loss: 0.0804, Initial Validation Loss: 0.1312, Validation Loss: 0.0713,V Acc: 0.6545, Top 70th Acc: 0.7662, Bottom 30th Acc: 0.3939
Stopping early at Epoch (base 0): 29  Rolling back to Epoch (base 0): 24  Top Validation Acc: 0.9358974358974359
Fold [3/5] Epoch [0/100] Initial Loss: 0.1391, Training Loss: 0.1391, Initial Validation Loss: 0.1349, Validation Loss: 0.1349,V Acc: 0.2636, Top 70th Acc: 0.3377, Bottom 30th Acc: 0.0909
Fold [3/5] Epoch [10/100] Initial Loss: 0.1391, Training Loss: 0.0394, Initial Validation Loss: 0.1349, Validation Loss: 0.0482,V Acc: 0.7727, Top 70th Acc: 0.8571, Bottom 30th Acc: 0.5758
Fold [3/5] Epoch [20/100] Initial Loss: 0.1391, Training Loss: 0.0173, Initial Validation Loss: 0.1349, Validation Loss: 0.0395,V Acc: 0.8273, Top 70th Acc: 0.8831, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.8831168831168831
Fold [4/5] Epoch [0/100] Initial Loss: 0.1381, Training Loss: 0.1381, Initial Validation Loss: 0.1281, Validation Loss: 0.1281,V Acc: 0.3182, Top 70th Acc: 0.3766, Bottom 30th Acc: 0.1818
Fold [4/5] Epoch [10/100] Initial Loss: 0.1381, Training Loss: 0.0336, Initial Validation Loss: 0.1281, Validation Loss: 0.0383,V Acc: 0.7727, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.4242
Fold [4/5] Epoch [20/100] Initial Loss: 0.1381, Training Loss: 0.0200, Initial Validation Loss: 0.1281, Validation Loss: 0.0266,V Acc: 0.8545, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6364
Fold [4/5] Epoch [30/100] Initial Loss: 0.1381, Training Loss: 0.0168, Initial Validation Loss: 0.1281, Validation Loss: 0.0256,V Acc: 0.8545, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 33  Rolling back to Epoch (base 0): 28  Top Validation Acc: 0.961038961038961
Fold [5/5] Epoch [0/100] Initial Loss: 0.1380, Training Loss: 0.1380, Initial Validation Loss: 0.1329, Validation Loss: 0.1329,V Acc: 0.3056, Top 70th Acc: 0.3289, Bottom 30th Acc: 0.2500
Fold [5/5] Epoch [10/100] Initial Loss: 0.1380, Training Loss: 0.0414, Initial Validation Loss: 0.1329, Validation Loss: 0.0451,V Acc: 0.8241, Top 70th Acc: 0.8816, Bottom 30th Acc: 0.6875
Fold [5/5] Epoch [20/100] Initial Loss: 0.1380, Training Loss: 0.0205, Initial Validation Loss: 0.1329, Validation Loss: 0.0302,V Acc: 0.8611, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.6562
Fold [5/5] Epoch [30/100] Initial Loss: 0.1380, Training Loss: 0.0171, Initial Validation Loss: 0.1329, Validation Loss: 0.0274,V Acc: 0.8704, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.6562
Stopping early at Epoch (base 0): 35  Rolling back to Epoch (base 0): 30  Top Validation Acc: 0.9473684210526315
Running train_nn.py with seed 85
CUDA:False
Training samples count:  550
Training on 30 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1431, Training Loss: 0.1431, Initial Validation Loss: 0.1339, Validation Loss: 0.1339,V Acc: 0.2523, Top 70th Acc: 0.3333, Bottom 30th Acc: 0.0606
Fold [1/5] Epoch [10/100] Initial Loss: 0.1431, Training Loss: 0.0359, Initial Validation Loss: 0.1339, Validation Loss: 0.0432,V Acc: 0.7748, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.4545
Fold [1/5] Epoch [20/100] Initial Loss: 0.1431, Training Loss: 0.0208, Initial Validation Loss: 0.1339, Validation Loss: 0.0341,V Acc: 0.8198, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.5455
Fold [1/5] Epoch [30/100] Initial Loss: 0.1431, Training Loss: 0.0172, Initial Validation Loss: 0.1339, Validation Loss: 0.0306,V Acc: 0.8468, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 38  Rolling back to Epoch (base 0): 33  Top Validation Acc: 0.9358974358974359
Fold [2/5] Epoch [0/100] Initial Loss: 0.1386, Training Loss: 0.1386, Initial Validation Loss: 0.1372, Validation Loss: 0.1372,V Acc: 0.3514, Top 70th Acc: 0.3974, Bottom 30th Acc: 0.2424
Fold [2/5] Epoch [10/100] Initial Loss: 0.1386, Training Loss: 0.0401, Initial Validation Loss: 0.1372, Validation Loss: 0.0469,V Acc: 0.7658, Top 70th Acc: 0.8974, Bottom 30th Acc: 0.4545
Fold [2/5] Epoch [20/100] Initial Loss: 0.1386, Training Loss: 0.0207, Initial Validation Loss: 0.1372, Validation Loss: 0.0337,V Acc: 0.8468, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.6061
Fold [2/5] Epoch [30/100] Initial Loss: 0.1386, Training Loss: 0.0167, Initial Validation Loss: 0.1372, Validation Loss: 0.0350,V Acc: 0.8468, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 32  Rolling back to Epoch (base 0): 27  Top Validation Acc: 0.9358974358974359
85 1 [array([0.76980126, 0.05669392, 0.04184415, 0.06188438, 0.06977634],
      dtype=float32)]
Fold [3/5] Epoch [0/100] Initial Loss: 0.1355, Training Loss: 0.1355, Initial Validation Loss: 0.1350, Validation Loss: 0.1350,V Acc: 0.4182, Top 70th Acc: 0.4545, Bottom 30th Acc: 0.3333
Fold [3/5] Epoch [10/100] Initial Loss: 0.1355, Training Loss: 0.0306, Initial Validation Loss: 0.1350, Validation Loss: 0.0304,V Acc: 0.9000, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.7273
Fold [3/5] Epoch [20/100] Initial Loss: 0.1355, Training Loss: 0.0198, Initial Validation Loss: 0.1350, Validation Loss: 0.0264,V Acc: 0.8818, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 20  Rolling back to Epoch (base 0): 15  Top Validation Acc: 0.961038961038961
Fold [4/5] Epoch [0/100] Initial Loss: 0.1393, Training Loss: 0.1393, Initial Validation Loss: 0.1349, Validation Loss: 0.1349,V Acc: 0.3182, Top 70th Acc: 0.2727, Bottom 30th Acc: 0.4242
Fold [4/5] Epoch [10/100] Initial Loss: 0.1393, Training Loss: 0.0352, Initial Validation Loss: 0.1349, Validation Loss: 0.0520,V Acc: 0.7727, Top 70th Acc: 0.8442, Bottom 30th Acc: 0.6061
Fold [4/5] Epoch [20/100] Initial Loss: 0.1393, Training Loss: 0.0176, Initial Validation Loss: 0.1349, Validation Loss: 0.0390,V Acc: 0.8182, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.5758
Fold [4/5] Epoch [30/100] Initial Loss: 0.1393, Training Loss: 0.0147, Initial Validation Loss: 0.1349, Validation Loss: 0.0378,V Acc: 0.8091, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.5152
Stopping early at Epoch (base 0): 30  Rolling back to Epoch (base 0): 25  Top Validation Acc: 0.935064935064935
Fold [5/5] Epoch [0/100] Initial Loss: 0.1377, Training Loss: 0.1377, Initial Validation Loss: 0.1266, Validation Loss: 0.1266,V Acc: 0.3148, Top 70th Acc: 0.3684, Bottom 30th Acc: 0.1875
Fold [5/5] Epoch [10/100] Initial Loss: 0.1377, Training Loss: 0.0302, Initial Validation Loss: 0.1266, Validation Loss: 0.0372,V Acc: 0.7963, Top 70th Acc: 0.8947, Bottom 30th Acc: 0.5625
Fold [5/5] Epoch [20/100] Initial Loss: 0.1377, Training Loss: 0.0172, Initial Validation Loss: 0.1266, Validation Loss: 0.0321,V Acc: 0.8241, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.5625
Stopping early at Epoch (base 0): 20  Rolling back to Epoch (base 0): 15  Top Validation Acc: 0.9342105263157895
Running train_nn.py with seed 86
CUDA:False
Training samples count:  550
Training on 30 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1384, Training Loss: 0.1384, Initial Validation Loss: 0.1349, Validation Loss: 0.1349,V Acc: 0.2703, Top 70th Acc: 0.3462, Bottom 30th Acc: 0.0909
Fold [1/5] Epoch [10/100] Initial Loss: 0.1384, Training Loss: 0.0316, Initial Validation Loss: 0.1349, Validation Loss: 0.0388,V Acc: 0.8288, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.5455
Fold [1/5] Epoch [20/100] Initial Loss: 0.1384, Training Loss: 0.0191, Initial Validation Loss: 0.1349, Validation Loss: 0.0301,V Acc: 0.8829, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.7273
Fold [1/5] Epoch [30/100] Initial Loss: 0.1384, Training Loss: 0.0168, Initial Validation Loss: 0.1349, Validation Loss: 0.0298,V Acc: 0.9009, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.7879
Stopping early at Epoch (base 0): 30  Rolling back to Epoch (base 0): 25  Top Validation Acc: 0.9487179487179487
Fold [2/5] Epoch [0/100] Initial Loss: 0.1383, Training Loss: 0.1383, Initial Validation Loss: 0.1332, Validation Loss: 0.1332,V Acc: 0.3153, Top 70th Acc: 0.3462, Bottom 30th Acc: 0.2424
Fold [2/5] Epoch [10/100] Initial Loss: 0.1383, Training Loss: 0.0413, Initial Validation Loss: 0.1332, Validation Loss: 0.0453,V Acc: 0.7928, Top 70th Acc: 0.8974, Bottom 30th Acc: 0.5455
Fold [2/5] Epoch [20/100] Initial Loss: 0.1383, Training Loss: 0.0210, Initial Validation Loss: 0.1332, Validation Loss: 0.0289,V Acc: 0.8288, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.4848
Fold [3/5] Epoch [10/100] Initial Loss: 0.1397, Training Loss: 0.0443, Initial Validation Loss: 0.1350, Validation Loss: 0.0508,V Acc: 0.7364, Top 70th Acc: 0.8701, Bottom 30th Acc: 0.4242
Fold [3/5] Epoch [20/100] Initial Loss: 0.1397, Training Loss: 0.0231, Initial Validation Loss: 0.1350, Validation Loss: 0.0331,V Acc: 0.8182, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.935064935064935
Fold [4/5] Epoch [0/100] Initial Loss: 0.1379, Training Loss: 0.1379, Initial Validation Loss: 0.1341, Validation Loss: 0.1341,V Acc: 0.2727, Top 70th Acc: 0.3636, Bottom 30th Acc: 0.0606
Fold [4/5] Epoch [10/100] Initial Loss: 0.1379, Training Loss: 0.0322, Initial Validation Loss: 0.1341, Validation Loss: 0.0436,V Acc: 0.8000, Top 70th Acc: 0.8831, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 18  Rolling back to Epoch (base 0): 13  Top Validation Acc: 0.9090909090909091
Fold [5/5] Epoch [0/100] Initial Loss: 0.1408, Training Loss: 0.1408, Initial Validation Loss: 0.1348, Validation Loss: 0.1348,V Acc: 0.2407, Top 70th Acc: 0.3026, Bottom 30th Acc: 0.0938
Fold [5/5] Epoch [10/100] Initial Loss: 0.1408, Training Loss: 0.0440, Initial Validation Loss: 0.1348, Validation Loss: 0.0434,V Acc: 0.8241, Top 70th Acc: 0.8816, Bottom 30th Acc: 0.6875
Fold [5/5] Epoch [20/100] Initial Loss: 0.1408, Training Loss: 0.0257, Initial Validation Loss: 0.1348, Validation Loss: 0.0304,V Acc: 0.8796, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.7188
Fold [5/5] Epoch [30/100] Initial Loss: 0.1408, Training Loss: 0.0211, Initial Validation Loss: 0.1348, Validation Loss: 0.0299,V Acc: 0.8611, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.6875
Stopping early at Epoch (base 0): 31  Rolling back to Epoch (base 0): 26  Top Validation Acc: 0.9342105263157895
86 4 [array([0.37298042, 0.08165549, 0.1278817 , 0.2788454 , 0.13863702],
      dtype=float32)]
Running train_nn.py with seed 87
CUDA:False
Training samples count:  550
Training on 20 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1352, Training Loss: 0.1352, Initial Validation Loss: 0.1325, Validation Loss: 0.1325,V Acc: 0.4144, Top 70th Acc: 0.5769, Bottom 30th Acc: 0.0303
Fold [1/5] Epoch [10/100] Initial Loss: 0.1352, Training Loss: 0.0391, Initial Validation Loss: 0.1325, Validation Loss: 0.0492,V Acc: 0.7928, Top 70th Acc: 0.8718, Bottom 30th Acc: 0.6061
Fold [1/5] Epoch [20/100] Initial Loss: 0.1352, Training Loss: 0.0283, Initial Validation Loss: 0.1325, Validation Loss: 0.0415,V Acc: 0.8198, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.5758
Fold [1/5] Epoch [30/100] Initial Loss: 0.1352, Training Loss: 0.0220, Initial Validation Loss: 0.1325, Validation Loss: 0.0376,V Acc: 0.8288, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.6061
Fold [1/5] Epoch [40/100] Initial Loss: 0.1352, Training Loss: 0.0191, Initial Validation Loss: 0.1325, Validation Loss: 0.0366,V Acc: 0.8198, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 49  Rolling back to Epoch (base 0): 44  Top Validation Acc: 0.9358974358974359
Fold [2/5] Epoch [0/100] Initial Loss: 0.1382, Training Loss: 0.1382, Initial Validation Loss: 0.1287, Validation Loss: 0.1287,V Acc: 0.3964, Top 70th Acc: 0.4487, Bottom 30th Acc: 0.2727
Fold [2/5] Epoch [10/100] Initial Loss: 0.1382, Training Loss: 0.0288, Initial Validation Loss: 0.1287, Validation Loss: 0.0412,V Acc: 0.7928, Top 70th Acc: 0.8974, Bottom 30th Acc: 0.5455
Fold [2/5] Epoch [20/100] Initial Loss: 0.1382, Training Loss: 0.0200, Initial Validation Loss: 0.1287, Validation Loss: 0.0396,V Acc: 0.7928, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.5152
Stopping early at Epoch (base 0): 20  Rolling back to Epoch (base 0): 15  Top Validation Acc: 0.9102564102564102
Fold [3/5] Epoch [0/100] Initial Loss: 0.1361, Training Loss: 0.1361, Initial Validation Loss: 0.1311, Validation Loss: 0.1311,V Acc: 0.4182, Top 70th Acc: 0.5065, Bottom 30th Acc: 0.2121
Fold [3/5] Epoch [10/100] Initial Loss: 0.1361, Training Loss: 0.0302, Initial Validation Loss: 0.1311, Validation Loss: 0.0312,V Acc: 0.8818, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.7273
Fold [3/5] Epoch [20/100] Initial Loss: 0.1361, Training Loss: 0.0228, Initial Validation Loss: 0.1311, Validation Loss: 0.0296,V Acc: 0.8727, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.7576
Stopping early at Epoch (base 0): 22  Rolling back to Epoch (base 0): 17  Top Validation Acc: 0.935064935064935
Fold [4/5] Epoch [0/100] Initial Loss: 0.1392, Training Loss: 0.1392, Initial Validation Loss: 0.1339, Validation Loss: 0.1339,V Acc: 0.2545, Top 70th Acc: 0.3247, Bottom 30th Acc: 0.0909
Fold [4/5] Epoch [10/100] Initial Loss: 0.1392, Training Loss: 0.0393, Initial Validation Loss: 0.1339, Validation Loss: 0.0429,V Acc: 0.8364, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.6667
Fold [4/5] Epoch [20/100] Initial Loss: 0.1392, Training Loss: 0.0236, Initial Validation Loss: 0.1339, Validation Loss: 0.0327,V Acc: 0.8818, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.7576
Fold [4/5] Epoch [30/100] Initial Loss: 0.1392, Training Loss: 0.0208, Initial Validation Loss: 0.1339, Validation Loss: 0.0301,V Acc: 0.8818, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.7273
Stopping early at Epoch (base 0): 37  Rolling back to Epoch (base 0): 32  Top Validation Acc: 0.948051948051948
Fold [5/5] Epoch [0/100] Initial Loss: 0.1418, Training Loss: 0.1418, Initial Validation Loss: 0.1327, Validation Loss: 0.1327,V Acc: 0.2593, Top 70th Acc: 0.3289, Bottom 30th Acc: 0.0938
Fold [5/5] Epoch [10/100] Initial Loss: 0.1418, Training Loss: 0.0452, Initial Validation Loss: 0.1327, Validation Loss: 0.0415,V Acc: 0.7963, Top 70th Acc: 0.9211, Bottom 30th Acc: 0.5000
Fold [5/5] Epoch [20/100] Initial Loss: 0.1418, Training Loss: 0.0220, Initial Validation Loss: 0.1327, Validation Loss: 0.0303,V Acc: 0.8519, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.5938
Stopping early at Epoch (base 0): 21  Rolling back to Epoch (base 0): 16  Top Validation Acc: 0.9605263157894737
87 4 [array([0.30752116, 0.10447438, 0.07586902, 0.27674797, 0.23538741],
      dtype=float32)]
Running train_nn.py with seed 88
CUDA:False
Training samples count:  550
Training on 20 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1357, Training Loss: 0.1357, Initial Validation Loss: 0.1314, Validation Loss: 0.1314,V Acc: 0.3153, Top 70th Acc: 0.3974, Bottom 30th Acc: 0.1212
Fold [1/5] Epoch [10/100] Initial Loss: 0.1357, Training Loss: 0.0392, Initial Validation Loss: 0.1314, Validation Loss: 0.0415,V Acc: 0.8288, Top 70th Acc: 0.8846, Bottom 30th Acc: 0.6970
Fold [1/5] Epoch [20/100] Initial Loss: 0.1357, Training Loss: 0.0242, Initial Validation Loss: 0.1314, Validation Loss: 0.0318,V Acc: 0.8378, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.5758
Fold [1/5] Epoch [30/100] Initial Loss: 0.1357, Training Loss: 0.0216, Initial Validation Loss: 0.1314, Validation Loss: 0.0316,V Acc: 0.8198, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.4848
Stopping early at Epoch (base 0): 30  Rolling back to Epoch (base 0): 25  Top Validation Acc: 0.9615384615384616
Fold [2/5] Epoch [0/100] Initial Loss: 0.1364, Training Loss: 0.1364, Initial Validation Loss: 0.1328, Validation Loss: 0.1328,V Acc: 0.3333, Top 70th Acc: 0.3846, Bottom 30th Acc: 0.2121
Fold [2/5] Epoch [10/100] Initial Loss: 0.1364, Training Loss: 0.0304, Initial Validation Loss: 0.1328, Validation Loss: 0.0304,V Acc: 0.9009, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.7273
Stopping early at Epoch (base 0): 17  Rolling back to Epoch (base 0): 12  Top Validation Acc: 0.9743589743589743
Fold [3/5] Epoch [0/100] Initial Loss: 0.1409, Training Loss: 0.1409, Initial Validation Loss: 0.1360, Validation Loss: 0.1360,V Acc: 0.2909, Top 70th Acc: 0.2727, Bottom 30th Acc: 0.3333
Fold [3/5] Epoch [10/100] Initial Loss: 0.1409, Training Loss: 0.0405, Initial Validation Loss: 0.1360, Validation Loss: 0.0401,V Acc: 0.8455, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.6364
Fold [3/5] Epoch [20/100] Initial Loss: 0.1409, Training Loss: 0.0240, Initial Validation Loss: 0.1360, Validation Loss: 0.0296,V Acc: 0.8364, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.5455
Fold [3/5] Epoch [30/100] Initial Loss: 0.1409, Training Loss: 0.0215, Initial Validation Loss: 0.1360, Validation Loss: 0.0292,V Acc: 0.8455, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.5758
Fold [2/5] Epoch [0/100] Initial Loss: 0.1393, Training Loss: 0.1393, Initial Validation Loss: 0.1375, Validation Loss: 0.1375,V Acc: 0.3423, Top 70th Acc: 0.3846, Bottom 30th Acc: 0.2424
Fold [2/5] Epoch [10/100] Initial Loss: 0.1393, Training Loss: 0.0242, Initial Validation Loss: 0.1375, Validation Loss: 0.0405,V Acc: 0.8018, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.4848
Fold [2/5] Epoch [20/100] Initial Loss: 0.1393, Training Loss: 0.0051, Initial Validation Loss: 0.1375, Validation Loss: 0.0315,V Acc: 0.8198, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.4848
Fold [2/5] Epoch [30/100] Initial Loss: 0.1393, Training Loss: 0.0036, Initial Validation Loss: 0.1375, Validation Loss: 0.0299,V Acc: 0.8468, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 38  Rolling back to Epoch (base 0): 33  Top Validation Acc: 0.9615384615384616
Fold [3/5] Epoch [0/100] Initial Loss: 0.1402, Training Loss: 0.1402, Initial Validation Loss: 0.1294, Validation Loss: 0.1294,V Acc: 0.4545, Top 70th Acc: 0.5065, Bottom 30th Acc: 0.3333
Fold [3/5] Epoch [10/100] Initial Loss: 0.1402, Training Loss: 0.0120, Initial Validation Loss: 0.1294, Validation Loss: 0.0351,V Acc: 0.8364, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.6364
Fold [3/5] Epoch [20/100] Initial Loss: 0.1402, Training Loss: 0.0044, Initial Validation Loss: 0.1294, Validation Loss: 0.0308,V Acc: 0.8545, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.6667
Fold [3/5] Epoch [30/100] Initial Loss: 0.1402, Training Loss: 0.0037, Initial Validation Loss: 0.1294, Validation Loss: 0.0302,V Acc: 0.8455, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 36  Rolling back to Epoch (base 0): 31  Top Validation Acc: 0.948051948051948
Fold [4/5] Epoch [0/100] Initial Loss: 0.1380, Training Loss: 0.1380, Initial Validation Loss: 0.1320, Validation Loss: 0.1320,V Acc: 0.2909, Top 70th Acc: 0.3247, Bottom 30th Acc: 0.2121
Fold [4/5] Epoch [10/100] Initial Loss: 0.1380, Training Loss: 0.0091, Initial Validation Loss: 0.1320, Validation Loss: 0.0323,V Acc: 0.8455, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6061
Fold [4/5] Epoch [20/100] Initial Loss: 0.1380, Training Loss: 0.0043, Initial Validation Loss: 0.1320, Validation Loss: 0.0303,V Acc: 0.8455, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.948051948051948
Fold [5/5] Epoch [0/100] Initial Loss: 0.1391, Training Loss: 0.1391, Initial Validation Loss: 0.1338, Validation Loss: 0.1338,V Acc: 0.2685, Top 70th Acc: 0.3289, Bottom 30th Acc: 0.1250
Fold [5/5] Epoch [10/100] Initial Loss: 0.1391, Training Loss: 0.0288, Initial Validation Loss: 0.1338, Validation Loss: 0.0463,V Acc: 0.7593, Top 70th Acc: 0.8816, Bottom 30th Acc: 0.4688
Fold [5/5] Epoch [20/100] Initial Loss: 0.1391, Training Loss: 0.0071, Initial Validation Loss: 0.1338, Validation Loss: 0.0358,V Acc: 0.8148, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.5312
Fold [5/5] Epoch [30/100] Initial Loss: 0.1391, Training Loss: 0.0049, Initial Validation Loss: 0.1338, Validation Loss: 0.0319,V Acc: 0.8519, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.6562
Fold [5/5] Epoch [40/100] Initial Loss: 0.1391, Training Loss: 0.0041, Initial Validation Loss: 0.1338, Validation Loss: 0.0293,V Acc: 0.8611, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.6562
Fold [5/5] Epoch [50/100] Initial Loss: 0.1391, Training Loss: 0.0039, Initial Validation Loss: 0.1338, Validation Loss: 0.0272,V Acc: 0.8704, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.7188
Fold [5/5] Epoch [60/100] Initial Loss: 0.1391, Training Loss: 0.0037, Initial Validation Loss: 0.1338, Validation Loss: 0.0269,V Acc: 0.8611, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.6875
Fold [5/5] Epoch [70/100] Initial Loss: 0.1391, Training Loss: 0.0036, Initial Validation Loss: 0.1338, Validation Loss: 0.0263,V Acc: 0.8611, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.6875
Stopping early at Epoch (base 0): 70  Rolling back to Epoch (base 0): 65  Top Validation Acc: 0.9342105263157895
Running train_nn.py with seed 66
CUDA:False
Training samples count:  550
Training on 163 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1372, Training Loss: 0.1372, Initial Validation Loss: 0.1391, Validation Loss: 0.1391,V Acc: 0.3604, Top 70th Acc: 0.4103, Bottom 30th Acc: 0.2424
Fold [1/5] Epoch [10/100] Initial Loss: 0.1372, Training Loss: 0.0186, Initial Validation Loss: 0.1391, Validation Loss: 0.0418,V Acc: 0.8108, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 18  Rolling back to Epoch (base 0): 13  Top Validation Acc: 0.8974358974358975
Fold [2/5] Epoch [0/100] Initial Loss: 0.1382, Training Loss: 0.1382, Initial Validation Loss: 0.1378, Validation Loss: 0.1378,V Acc: 0.2523, Top 70th Acc: 0.3462, Bottom 30th Acc: 0.0303
Fold [2/5] Epoch [10/100] Initial Loss: 0.1382, Training Loss: 0.0220, Initial Validation Loss: 0.1378, Validation Loss: 0.0425,V Acc: 0.8198, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.6061
Fold [2/5] Epoch [20/100] Initial Loss: 0.1382, Training Loss: 0.0049, Initial Validation Loss: 0.1378, Validation Loss: 0.0318,V Acc: 0.8559, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.6061
Fold [2/5] Epoch [30/100] Initial Loss: 0.1382, Training Loss: 0.0040, Initial Validation Loss: 0.1378, Validation Loss: 0.0311,V Acc: 0.8378, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 32  Rolling back to Epoch (base 0): 27  Top Validation Acc: 0.9615384615384616
Fold [3/5] Epoch [0/100] Initial Loss: 0.1393, Training Loss: 0.1393, Initial Validation Loss: 0.1287, Validation Loss: 0.1287,V Acc: 0.3909, Top 70th Acc: 0.4545, Bottom 30th Acc: 0.2424
Fold [3/5] Epoch [10/100] Initial Loss: 0.1393, Training Loss: 0.0230, Initial Validation Loss: 0.1287, Validation Loss: 0.0382,V Acc: 0.8364, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.6061
Fold [3/5] Epoch [20/100] Initial Loss: 0.1393, Training Loss: 0.0059, Initial Validation Loss: 0.1287, Validation Loss: 0.0272,V Acc: 0.8455, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.5758
Fold [3/5] Epoch [30/100] Initial Loss: 0.1393, Training Loss: 0.0043, Initial Validation Loss: 0.1287, Validation Loss: 0.0281,V Acc: 0.8455, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 31  Rolling back to Epoch (base 0): 26  Top Validation Acc: 0.948051948051948
Fold [4/5] Epoch [0/100] Initial Loss: 0.1362, Training Loss: 0.1362, Initial Validation Loss: 0.1359, Validation Loss: 0.1359,V Acc: 0.2909, Top 70th Acc: 0.3636, Bottom 30th Acc: 0.1212
Fold [4/5] Epoch [10/100] Initial Loss: 0.1362, Training Loss: 0.0113, Initial Validation Loss: 0.1359, Validation Loss: 0.0301,V Acc: 0.8636, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.6364
Fold [4/5] Epoch [20/100] Initial Loss: 0.1362, Training Loss: 0.0044, Initial Validation Loss: 0.1359, Validation Loss: 0.0286,V Acc: 0.8455, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.961038961038961
66 3 [array([0.31195852, 0.08783386, 0.09225491, 0.2059199 , 0.30203283],
      dtype=float32)]
Fold [5/5] Epoch [0/100] Initial Loss: 0.1418, Training Loss: 0.1418, Initial Validation Loss: 0.1293, Validation Loss: 0.1293,V Acc: 0.3426, Top 70th Acc: 0.4474, Bottom 30th Acc: 0.0938
Fold [5/5] Epoch [10/100] Initial Loss: 0.1418, Training Loss: 0.0137, Initial Validation Loss: 0.1293, Validation Loss: 0.0304,V Acc: 0.8611, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.6250
Fold [5/5] Epoch [20/100] Initial Loss: 0.1418, Training Loss: 0.0048, Initial Validation Loss: 0.1293, Validation Loss: 0.0252,V Acc: 0.8611, Top 70th Acc: 0.9737, Bottom 30th Acc: 0.5938
Fold [5/5] Epoch [30/100] Initial Loss: 0.1418, Training Loss: 0.0039, Initial Validation Loss: 0.1293, Validation Loss: 0.0247,V Acc: 0.8704, Top 70th Acc: 0.9737, Bottom 30th Acc: 0.6250
Stopping early at Epoch (base 0): 32  Rolling back to Epoch (base 0): 27  Top Validation Acc: 0.9736842105263158
Running train_nn.py with seed 67
CUDA:False
Training samples count:  550
Training on 163 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1390, Training Loss: 0.1390, Initial Validation Loss: 0.1352, Validation Loss: 0.1352,V Acc: 0.3063, Top 70th Acc: 0.3333, Bottom 30th Acc: 0.2424
Stopping early at Epoch (base 0): 19  Rolling back to Epoch (base 0): 14  Top Validation Acc: 0.9487179487179487
84 0 [array([0.42152953, 0.09747267, 0.12919347, 0.08620921, 0.2655951 ],
      dtype=float32)]
Fold [2/5] Epoch [0/100] Initial Loss: 0.1386, Training Loss: 0.1386, Initial Validation Loss: 0.1396, Validation Loss: 0.1396,V Acc: 0.2523, Top 70th Acc: 0.2949, Bottom 30th Acc: 0.1515
Fold [2/5] Epoch [10/100] Initial Loss: 0.1386, Training Loss: 0.0416, Initial Validation Loss: 0.1396, Validation Loss: 0.0454,V Acc: 0.8108, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.5758
Fold [2/5] Epoch [20/100] Initial Loss: 0.1386, Training Loss: 0.0169, Initial Validation Loss: 0.1396, Validation Loss: 0.0303,V Acc: 0.8829, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.6970
Fold [2/5] Epoch [30/100] Initial Loss: 0.1386, Training Loss: 0.0115, Initial Validation Loss: 0.1396, Validation Loss: 0.0288,V Acc: 0.8468, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 33  Rolling back to Epoch (base 0): 28  Top Validation Acc: 0.9743589743589743
Fold [3/5] Epoch [0/100] Initial Loss: 0.1386, Training Loss: 0.1386, Initial Validation Loss: 0.1346, Validation Loss: 0.1346,V Acc: 0.3091, Top 70th Acc: 0.3766, Bottom 30th Acc: 0.1515
Fold [3/5] Epoch [10/100] Initial Loss: 0.1386, Training Loss: 0.0253, Initial Validation Loss: 0.1346, Validation Loss: 0.0454,V Acc: 0.7727, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.4545
Fold [3/5] Epoch [20/100] Initial Loss: 0.1386, Training Loss: 0.0136, Initial Validation Loss: 0.1346, Validation Loss: 0.0363,V Acc: 0.8273, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.6061
Fold [3/5] Epoch [30/100] Initial Loss: 0.1386, Training Loss: 0.0116, Initial Validation Loss: 0.1346, Validation Loss: 0.0351,V Acc: 0.8455, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 30  Rolling back to Epoch (base 0): 25  Top Validation Acc: 0.935064935064935
Fold [4/5] Epoch [0/100] Initial Loss: 0.1409, Training Loss: 0.1409, Initial Validation Loss: 0.1301, Validation Loss: 0.1301,V Acc: 0.3182, Top 70th Acc: 0.3766, Bottom 30th Acc: 0.1818
Fold [4/5] Epoch [10/100] Initial Loss: 0.1409, Training Loss: 0.0289, Initial Validation Loss: 0.1301, Validation Loss: 0.0360,V Acc: 0.7909, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.4545
Fold [4/5] Epoch [20/100] Initial Loss: 0.1409, Training Loss: 0.0146, Initial Validation Loss: 0.1301, Validation Loss: 0.0269,V Acc: 0.8727, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.7273
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.961038961038961
Fold [5/5] Epoch [0/100] Initial Loss: 0.1367, Training Loss: 0.1367, Initial Validation Loss: 0.1340, Validation Loss: 0.1340,V Acc: 0.2870, Top 70th Acc: 0.3026, Bottom 30th Acc: 0.2500
Fold [5/5] Epoch [10/100] Initial Loss: 0.1367, Training Loss: 0.0338, Initial Validation Loss: 0.1340, Validation Loss: 0.0369,V Acc: 0.8333, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.5625
Fold [5/5] Epoch [20/100] Initial Loss: 0.1367, Training Loss: 0.0174, Initial Validation Loss: 0.1340, Validation Loss: 0.0297,V Acc: 0.8704, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.7188
Fold [5/5] Epoch [30/100] Initial Loss: 0.1367, Training Loss: 0.0131, Initial Validation Loss: 0.1340, Validation Loss: 0.0268,V Acc: 0.8981, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.7812
Fold [5/5] Epoch [40/100] Initial Loss: 0.1367, Training Loss: 0.0114, Initial Validation Loss: 0.1340, Validation Loss: 0.0260,V Acc: 0.8796, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.7188
Stopping early at Epoch (base 0): 47  Rolling back to Epoch (base 0): 42  Top Validation Acc: 0.9473684210526315
Running train_nn.py with seed 85
CUDA:False
Training samples count:  550
Training on 40 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1389, Training Loss: 0.1389, Initial Validation Loss: 0.1327, Validation Loss: 0.1327,V Acc: 0.3063, Top 70th Acc: 0.3462, Bottom 30th Acc: 0.2121
Fold [1/5] Epoch [10/100] Initial Loss: 0.1389, Training Loss: 0.0295, Initial Validation Loss: 0.1327, Validation Loss: 0.0397,V Acc: 0.7748, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.4545
Fold [1/5] Epoch [20/100] Initial Loss: 0.1389, Training Loss: 0.0132, Initial Validation Loss: 0.1327, Validation Loss: 0.0310,V Acc: 0.8108, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.5152
Fold [1/5] Epoch [30/100] Initial Loss: 0.1389, Training Loss: 0.0107, Initial Validation Loss: 0.1327, Validation Loss: 0.0312,V Acc: 0.7928, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.4545
Stopping early at Epoch (base 0): 30  Rolling back to Epoch (base 0): 25  Top Validation Acc: 0.9358974358974359
Fold [2/5] Epoch [0/100] Initial Loss: 0.1375, Training Loss: 0.1375, Initial Validation Loss: 0.1362, Validation Loss: 0.1362,V Acc: 0.3153, Top 70th Acc: 0.3590, Bottom 30th Acc: 0.2121
Fold [2/5] Epoch [10/100] Initial Loss: 0.1375, Training Loss: 0.0316, Initial Validation Loss: 0.1362, Validation Loss: 0.0403,V Acc: 0.8378, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.5758
Fold [2/5] Epoch [20/100] Initial Loss: 0.1375, Training Loss: 0.0152, Initial Validation Loss: 0.1362, Validation Loss: 0.0293,V Acc: 0.8649, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 29  Rolling back to Epoch (base 0): 24  Top Validation Acc: 0.9615384615384616
85 1 [array([0.65645397, 0.03487915, 0.07753919, 0.05168483, 0.17944288],
      dtype=float32)]
Fold [3/5] Epoch [0/100] Initial Loss: 0.1385, Training Loss: 0.1385, Initial Validation Loss: 0.1361, Validation Loss: 0.1361,V Acc: 0.3636, Top 70th Acc: 0.4675, Bottom 30th Acc: 0.1212
Fold [3/5] Epoch [10/100] Initial Loss: 0.1385, Training Loss: 0.0334, Initial Validation Loss: 0.1361, Validation Loss: 0.0371,V Acc: 0.8364, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.5455
Fold [3/5] Epoch [20/100] Initial Loss: 0.1385, Training Loss: 0.0160, Initial Validation Loss: 0.1361, Validation Loss: 0.0258,V Acc: 0.8545, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 29  Rolling back to Epoch (base 0): 24  Top Validation Acc: 0.974025974025974
Fold [4/5] Epoch [0/100] Initial Loss: 0.1378, Training Loss: 0.1378, Initial Validation Loss: 0.1348, Validation Loss: 0.1348,V Acc: 0.3364, Top 70th Acc: 0.4156, Bottom 30th Acc: 0.1515
Fold [4/5] Epoch [10/100] Initial Loss: 0.1378, Training Loss: 0.0220, Initial Validation Loss: 0.1348, Validation Loss: 0.0370,V Acc: 0.8182, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.5152
Fold [4/5] Epoch [20/100] Initial Loss: 0.1378, Training Loss: 0.0130, Initial Validation Loss: 0.1348, Validation Loss: 0.0340,V Acc: 0.8273, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.5758
Fold [4/5] Epoch [30/100] Initial Loss: 0.1378, Training Loss: 0.0110, Initial Validation Loss: 0.1348, Validation Loss: 0.0321,V Acc: 0.8455, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 30  Rolling back to Epoch (base 0): 25  Top Validation Acc: 0.935064935064935
Fold [5/5] Epoch [0/100] Initial Loss: 0.1396, Training Loss: 0.1396, Initial Validation Loss: 0.1283, Validation Loss: 0.1283,V Acc: 0.3796, Top 70th Acc: 0.4079, Bottom 30th Acc: 0.3125
Fold [5/5] Epoch [10/100] Initial Loss: 0.1396, Training Loss: 0.0253, Initial Validation Loss: 0.1283, Validation Loss: 0.0342,V Acc: 0.8056, Top 70th Acc: 0.9079, Bottom 30th Acc: 0.5625
Fold [5/5] Epoch [20/100] Initial Loss: 0.1396, Training Loss: 0.0146, Initial Validation Loss: 0.1283, Validation Loss: 0.0300,V Acc: 0.8148, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.5000
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.9473684210526315
Running train_nn.py with seed 86
CUDA:False
Training samples count:  550
Training on 40 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1357, Training Loss: 0.1357, Initial Validation Loss: 0.1310, Validation Loss: 0.1310,V Acc: 0.3604, Top 70th Acc: 0.4103, Bottom 30th Acc: 0.2424
Fold [1/5] Epoch [10/100] Initial Loss: 0.1357, Training Loss: 0.0322, Initial Validation Loss: 0.1310, Validation Loss: 0.0472,V Acc: 0.7658, Top 70th Acc: 0.8974, Bottom 30th Acc: 0.4545
Fold [1/5] Epoch [20/100] Initial Loss: 0.1357, Training Loss: 0.0159, Initial Validation Loss: 0.1310, Validation Loss: 0.0365,V Acc: 0.8288, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.7662337662337663
Fold [4/5] Epoch [0/100] Initial Loss: 0.1360, Training Loss: 0.1360, Initial Validation Loss: 0.1281, Validation Loss: 0.1281,V Acc: 0.4000, Top 70th Acc: 0.4286, Bottom 30th Acc: 0.3333
Fold [4/5] Epoch [10/100] Initial Loss: 0.1360, Training Loss: 0.0822, Initial Validation Loss: 0.1281, Validation Loss: 0.0729,V Acc: 0.6455, Top 70th Acc: 0.8052, Bottom 30th Acc: 0.2727
Fold [4/5] Epoch [20/100] Initial Loss: 0.1360, Training Loss: 0.0811, Initial Validation Loss: 0.1281, Validation Loss: 0.0717,V Acc: 0.6545, Top 70th Acc: 0.7922, Bottom 30th Acc: 0.3333
Stopping early at Epoch (base 0): 27  Rolling back to Epoch (base 0): 22  Top Validation Acc: 0.7922077922077922
81 3 [array([0.1439989 , 0.31913635, 0.16631418, 0.21584365, 0.15470701],
      dtype=float32)]
Fold [5/5] Epoch [0/100] Initial Loss: 0.1382, Training Loss: 0.1382, Initial Validation Loss: 0.1361, Validation Loss: 0.1361,V Acc: 0.3796, Top 70th Acc: 0.3421, Bottom 30th Acc: 0.4688
Fold [5/5] Epoch [10/100] Initial Loss: 0.1382, Training Loss: 0.0798, Initial Validation Loss: 0.1361, Validation Loss: 0.0836,V Acc: 0.6204, Top 70th Acc: 0.7368, Bottom 30th Acc: 0.3438
Fold [5/5] Epoch [20/100] Initial Loss: 0.1382, Training Loss: 0.0782, Initial Validation Loss: 0.1361, Validation Loss: 0.0817,V Acc: 0.6389, Top 70th Acc: 0.7500, Bottom 30th Acc: 0.3750
Fold [5/5] Epoch [30/100] Initial Loss: 0.1382, Training Loss: 0.0777, Initial Validation Loss: 0.1361, Validation Loss: 0.0813,V Acc: 0.6296, Top 70th Acc: 0.7368, Bottom 30th Acc: 0.3750
Fold [5/5] Epoch [40/100] Initial Loss: 0.1382, Training Loss: 0.0774, Initial Validation Loss: 0.1361, Validation Loss: 0.0820,V Acc: 0.6389, Top 70th Acc: 0.7500, Bottom 30th Acc: 0.3750
Stopping early at Epoch (base 0): 43  Rolling back to Epoch (base 0): 38  Top Validation Acc: 0.7236842105263158
Running train_nn.py with seed 82
CUDA:False
Training samples count:  550
Training on 2 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1361, Training Loss: 0.1361, Initial Validation Loss: 0.1252, Validation Loss: 0.1252,V Acc: 0.3243, Top 70th Acc: 0.3718, Bottom 30th Acc: 0.2121
Fold [1/5] Epoch [10/100] Initial Loss: 0.1361, Training Loss: 0.0802, Initial Validation Loss: 0.1252, Validation Loss: 0.0843,V Acc: 0.5856, Top 70th Acc: 0.6410, Bottom 30th Acc: 0.4545
Fold [1/5] Epoch [20/100] Initial Loss: 0.1361, Training Loss: 0.0777, Initial Validation Loss: 0.1252, Validation Loss: 0.0807,V Acc: 0.6126, Top 70th Acc: 0.6923, Bottom 30th Acc: 0.4242
Fold [1/5] Epoch [30/100] Initial Loss: 0.1361, Training Loss: 0.0768, Initial Validation Loss: 0.1252, Validation Loss: 0.0801,V Acc: 0.6216, Top 70th Acc: 0.7308, Bottom 30th Acc: 0.3636
Stopping early at Epoch (base 0): 34  Rolling back to Epoch (base 0): 29  Top Validation Acc: 0.7564102564102564
82 0 [array([0.11718588, 0.35842833, 0.1275842 , 0.25036657, 0.14643492],
      dtype=float32)]
Fold [2/5] Epoch [0/100] Initial Loss: 0.1264, Training Loss: 0.1264, Initial Validation Loss: 0.1192, Validation Loss: 0.1192,V Acc: 0.5405, Top 70th Acc: 0.6923, Bottom 30th Acc: 0.1818
Fold [2/5] Epoch [10/100] Initial Loss: 0.1264, Training Loss: 0.0807, Initial Validation Loss: 0.1192, Validation Loss: 0.0831,V Acc: 0.6577, Top 70th Acc: 0.7564, Bottom 30th Acc: 0.4242
Fold [2/5] Epoch [20/100] Initial Loss: 0.1264, Training Loss: 0.0782, Initial Validation Loss: 0.1192, Validation Loss: 0.0832,V Acc: 0.6577, Top 70th Acc: 0.7564, Bottom 30th Acc: 0.4242
Stopping early at Epoch (base 0): 20  Rolling back to Epoch (base 0): 15  Top Validation Acc: 0.7564102564102564
Fold [3/5] Epoch [0/100] Initial Loss: 0.1372, Training Loss: 0.1372, Initial Validation Loss: 0.1281, Validation Loss: 0.1281,V Acc: 0.2727, Top 70th Acc: 0.3506, Bottom 30th Acc: 0.0909
Fold [3/5] Epoch [10/100] Initial Loss: 0.1372, Training Loss: 0.0795, Initial Validation Loss: 0.1281, Validation Loss: 0.0824,V Acc: 0.6000, Top 70th Acc: 0.7143, Bottom 30th Acc: 0.3333
Fold [3/5] Epoch [20/100] Initial Loss: 0.1372, Training Loss: 0.0782, Initial Validation Loss: 0.1281, Validation Loss: 0.0823,V Acc: 0.5909, Top 70th Acc: 0.7273, Bottom 30th Acc: 0.2727
Stopping early at Epoch (base 0): 22  Rolling back to Epoch (base 0): 17  Top Validation Acc: 0.7402597402597403
Fold [4/5] Epoch [0/100] Initial Loss: 0.1354, Training Loss: 0.1354, Initial Validation Loss: 0.1270, Validation Loss: 0.1270,V Acc: 0.4636, Top 70th Acc: 0.5844, Bottom 30th Acc: 0.1818
Fold [4/5] Epoch [10/100] Initial Loss: 0.1354, Training Loss: 0.0833, Initial Validation Loss: 0.1270, Validation Loss: 0.0733,V Acc: 0.6636, Top 70th Acc: 0.7403, Bottom 30th Acc: 0.4848
Fold [4/5] Epoch [20/100] Initial Loss: 0.1354, Training Loss: 0.0815, Initial Validation Loss: 0.1270, Validation Loss: 0.0713,V Acc: 0.6545, Top 70th Acc: 0.7273, Bottom 30th Acc: 0.4848
Fold [4/5] Epoch [30/100] Initial Loss: 0.1354, Training Loss: 0.0808, Initial Validation Loss: 0.1270, Validation Loss: 0.0707,V Acc: 0.6636, Top 70th Acc: 0.7403, Bottom 30th Acc: 0.4848
Stopping early at Epoch (base 0): 37  Rolling back to Epoch (base 0): 32  Top Validation Acc: 0.7272727272727273
Fold [5/5] Epoch [0/100] Initial Loss: 0.1319, Training Loss: 0.1319, Initial Validation Loss: 0.1230, Validation Loss: 0.1230,V Acc: 0.5278, Top 70th Acc: 0.5526, Bottom 30th Acc: 0.4688
Fold [5/5] Epoch [10/100] Initial Loss: 0.1319, Training Loss: 0.0806, Initial Validation Loss: 0.1230, Validation Loss: 0.0791,V Acc: 0.6204, Top 70th Acc: 0.7368, Bottom 30th Acc: 0.3438
Fold [5/5] Epoch [20/100] Initial Loss: 0.1319, Training Loss: 0.0785, Initial Validation Loss: 0.1230, Validation Loss: 0.0788,V Acc: 0.6204, Top 70th Acc: 0.7368, Bottom 30th Acc: 0.3438
Stopping early at Epoch (base 0): 27  Rolling back to Epoch (base 0): 22  Top Validation Acc: 0.75
Running train_nn.py with seed 83
CUDA:False
Training samples count:  550
Training on 2 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1382, Training Loss: 0.1382, Initial Validation Loss: 0.1329, Validation Loss: 0.1329,V Acc: 0.3694, Top 70th Acc: 0.3718, Bottom 30th Acc: 0.3636
Fold [1/5] Epoch [10/100] Initial Loss: 0.1382, Training Loss: 0.0802, Initial Validation Loss: 0.1329, Validation Loss: 0.0814,V Acc: 0.6126, Top 70th Acc: 0.6923, Bottom 30th Acc: 0.4242
Fold [1/5] Epoch [20/100] Initial Loss: 0.1382, Training Loss: 0.0776, Initial Validation Loss: 0.1329, Validation Loss: 0.0797,V Acc: 0.6216, Top 70th Acc: 0.7179, Bottom 30th Acc: 0.3939
Fold [1/5] Epoch [30/100] Initial Loss: 0.1382, Training Loss: 0.0768, Initial Validation Loss: 0.1329, Validation Loss: 0.0793,V Acc: 0.5946, Top 70th Acc: 0.7179, Bottom 30th Acc: 0.3030
Fold [1/5] Epoch [40/100] Initial Loss: 0.1382, Training Loss: 0.0765, Initial Validation Loss: 0.1329, Validation Loss: 0.0788,V Acc: 0.5856, Top 70th Acc: 0.7051, Bottom 30th Acc: 0.3030
Fold [1/5] Epoch [50/100] Initial Loss: 0.1382, Training Loss: 0.0759, Initial Validation Loss: 0.1329, Validation Loss: 0.0789,V Acc: 0.5946, Top 70th Acc: 0.7308, Bottom 30th Acc: 0.2727
Stopping early at Epoch (base 0): 50  Rolling back to Epoch (base 0): 45  Top Validation Acc: 0.7307692307692307
Fold [2/5] Epoch [0/100] Initial Loss: 0.1246, Training Loss: 0.1246, Initial Validation Loss: 0.1150, Validation Loss: 0.1150,V Acc: 0.5946, Top 70th Acc: 0.7051, Bottom 30th Acc: 0.3333
Fold [2/5] Epoch [10/100] Initial Loss: 0.1246, Training Loss: 0.0814, Initial Validation Loss: 0.1150, Validation Loss: 0.0798,V Acc: 0.6847, Top 70th Acc: 0.7821, Bottom 30th Acc: 0.4545
Fold [2/5] Epoch [20/100] Initial Loss: 0.1246, Training Loss: 0.0798, Initial Validation Loss: 0.1150, Validation Loss: 0.0766,V Acc: 0.7027, Top 70th Acc: 0.7821, Bottom 30th Acc: 0.5152
Fold [2/5] Epoch [30/100] Initial Loss: 0.1246, Training Loss: 0.0788, Initial Validation Loss: 0.1150, Validation Loss: 0.0750,V Acc: 0.6937, Top 70th Acc: 0.7692, Bottom 30th Acc: 0.5152
Stopping early at Epoch (base 0): 35  Rolling back to Epoch (base 0): 30  Top Validation Acc: 0.7564102564102564
Fold [3/5] Epoch [0/100] Initial Loss: 0.1273, Training Loss: 0.1273, Initial Validation Loss: 0.1130, Validation Loss: 0.1130,V Acc: 0.4545, Top 70th Acc: 0.5455, Bottom 30th Acc: 0.2424
Fold [2/5] Epoch [30/100] Initial Loss: 0.1383, Training Loss: 0.0176, Initial Validation Loss: 0.1332, Validation Loss: 0.0279,V Acc: 0.8288, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.4848
Stopping early at Epoch (base 0): 30  Rolling back to Epoch (base 0): 25  Top Validation Acc: 0.9743589743589743
Fold [3/5] Epoch [0/100] Initial Loss: 0.1393, Training Loss: 0.1393, Initial Validation Loss: 0.1362, Validation Loss: 0.1362,V Acc: 0.2545, Top 70th Acc: 0.3247, Bottom 30th Acc: 0.0909
Fold [3/5] Epoch [10/100] Initial Loss: 0.1393, Training Loss: 0.0403, Initial Validation Loss: 0.1362, Validation Loss: 0.0406,V Acc: 0.8000, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.5152
Fold [3/5] Epoch [20/100] Initial Loss: 0.1393, Training Loss: 0.0188, Initial Validation Loss: 0.1362, Validation Loss: 0.0307,V Acc: 0.8545, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 21  Rolling back to Epoch (base 0): 16  Top Validation Acc: 0.935064935064935
Fold [4/5] Epoch [0/100] Initial Loss: 0.1408, Training Loss: 0.1408, Initial Validation Loss: 0.1360, Validation Loss: 0.1360,V Acc: 0.3818, Top 70th Acc: 0.3766, Bottom 30th Acc: 0.3939
Fold [4/5] Epoch [10/100] Initial Loss: 0.1408, Training Loss: 0.0329, Initial Validation Loss: 0.1360, Validation Loss: 0.0448,V Acc: 0.7909, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.5152
Fold [4/5] Epoch [20/100] Initial Loss: 0.1408, Training Loss: 0.0166, Initial Validation Loss: 0.1360, Validation Loss: 0.0406,V Acc: 0.7636, Top 70th Acc: 0.8961, Bottom 30th Acc: 0.4545
Stopping early at Epoch (base 0): 20  Rolling back to Epoch (base 0): 15  Top Validation Acc: 0.8961038961038961
Fold [5/5] Epoch [0/100] Initial Loss: 0.1383, Training Loss: 0.1383, Initial Validation Loss: 0.1329, Validation Loss: 0.1329,V Acc: 0.3333, Top 70th Acc: 0.3289, Bottom 30th Acc: 0.3438
Fold [5/5] Epoch [10/100] Initial Loss: 0.1383, Training Loss: 0.0387, Initial Validation Loss: 0.1329, Validation Loss: 0.0418,V Acc: 0.8148, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.5312
Fold [5/5] Epoch [20/100] Initial Loss: 0.1383, Training Loss: 0.0199, Initial Validation Loss: 0.1329, Validation Loss: 0.0294,V Acc: 0.8519, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.5938
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.9605263157894737
86 4 [array([0.78145415, 0.0197549 , 0.04975132, 0.11031024, 0.03872938],
      dtype=float32)]
Running train_nn.py with seed 87
CUDA:False
Training samples count:  550
Training on 30 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1435, Training Loss: 0.1435, Initial Validation Loss: 0.1402, Validation Loss: 0.1402,V Acc: 0.2252, Top 70th Acc: 0.2692, Bottom 30th Acc: 0.1212
Fold [1/5] Epoch [10/100] Initial Loss: 0.1435, Training Loss: 0.0259, Initial Validation Loss: 0.1402, Validation Loss: 0.0400,V Acc: 0.8649, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.6667
Fold [1/5] Epoch [20/100] Initial Loss: 0.1435, Training Loss: 0.0182, Initial Validation Loss: 0.1402, Validation Loss: 0.0367,V Acc: 0.8559, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.9230769230769231
Fold [2/5] Epoch [0/100] Initial Loss: 0.1388, Training Loss: 0.1388, Initial Validation Loss: 0.1313, Validation Loss: 0.1313,V Acc: 0.3514, Top 70th Acc: 0.3974, Bottom 30th Acc: 0.2424
Fold [2/5] Epoch [10/100] Initial Loss: 0.1388, Training Loss: 0.0374, Initial Validation Loss: 0.1313, Validation Loss: 0.0504,V Acc: 0.6937, Top 70th Acc: 0.8590, Bottom 30th Acc: 0.3030
Fold [2/5] Epoch [20/100] Initial Loss: 0.1388, Training Loss: 0.0194, Initial Validation Loss: 0.1313, Validation Loss: 0.0402,V Acc: 0.7748, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.4545
Fold [2/5] Epoch [30/100] Initial Loss: 0.1388, Training Loss: 0.0160, Initial Validation Loss: 0.1313, Validation Loss: 0.0397,V Acc: 0.7838, Top 70th Acc: 0.8974, Bottom 30th Acc: 0.5152
Stopping early at Epoch (base 0): 30  Rolling back to Epoch (base 0): 25  Top Validation Acc: 0.8974358974358975
Fold [3/5] Epoch [0/100] Initial Loss: 0.1364, Training Loss: 0.1364, Initial Validation Loss: 0.1320, Validation Loss: 0.1320,V Acc: 0.3455, Top 70th Acc: 0.3506, Bottom 30th Acc: 0.3333
Fold [3/5] Epoch [10/100] Initial Loss: 0.1364, Training Loss: 0.0283, Initial Validation Loss: 0.1320, Validation Loss: 0.0337,V Acc: 0.8091, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.5152
Fold [3/5] Epoch [20/100] Initial Loss: 0.1364, Training Loss: 0.0207, Initial Validation Loss: 0.1320, Validation Loss: 0.0320,V Acc: 0.8273, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.5152
Stopping early at Epoch (base 0): 20  Rolling back to Epoch (base 0): 15  Top Validation Acc: 0.961038961038961
Fold [4/5] Epoch [0/100] Initial Loss: 0.1371, Training Loss: 0.1371, Initial Validation Loss: 0.1349, Validation Loss: 0.1349,V Acc: 0.2818, Top 70th Acc: 0.3636, Bottom 30th Acc: 0.0909
Fold [4/5] Epoch [10/100] Initial Loss: 0.1371, Training Loss: 0.0512, Initial Validation Loss: 0.1349, Validation Loss: 0.0515,V Acc: 0.7455, Top 70th Acc: 0.8961, Bottom 30th Acc: 0.3939
Fold [4/5] Epoch [20/100] Initial Loss: 0.1371, Training Loss: 0.0224, Initial Validation Loss: 0.1349, Validation Loss: 0.0318,V Acc: 0.8455, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.961038961038961
Fold [5/5] Epoch [0/100] Initial Loss: 0.1371, Training Loss: 0.1371, Initial Validation Loss: 0.1302, Validation Loss: 0.1302,V Acc: 0.3611, Top 70th Acc: 0.4342, Bottom 30th Acc: 0.1875
Fold [5/5] Epoch [10/100] Initial Loss: 0.1371, Training Loss: 0.0423, Initial Validation Loss: 0.1302, Validation Loss: 0.0422,V Acc: 0.7778, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.4062
Fold [5/5] Epoch [20/100] Initial Loss: 0.1371, Training Loss: 0.0201, Initial Validation Loss: 0.1302, Validation Loss: 0.0309,V Acc: 0.8519, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.6562
Stopping early at Epoch (base 0): 21  Rolling back to Epoch (base 0): 16  Top Validation Acc: 0.9342105263157895
87 4 [array([0.697401  , 0.05557774, 0.04852812, 0.11035036, 0.08814284],
      dtype=float32)]
Running train_nn.py with seed 88
CUDA:False
Training samples count:  550
Training on 30 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1373, Training Loss: 0.1373, Initial Validation Loss: 0.1348, Validation Loss: 0.1348,V Acc: 0.2703, Top 70th Acc: 0.2564, Bottom 30th Acc: 0.3030
Fold [1/5] Epoch [10/100] Initial Loss: 0.1373, Training Loss: 0.0313, Initial Validation Loss: 0.1348, Validation Loss: 0.0380,V Acc: 0.8468, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.6364
Fold [1/5] Epoch [20/100] Initial Loss: 0.1373, Training Loss: 0.0200, Initial Validation Loss: 0.1348, Validation Loss: 0.0317,V Acc: 0.8559, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.9615384615384616
Fold [2/5] Epoch [0/100] Initial Loss: 0.1364, Training Loss: 0.1364, Initial Validation Loss: 0.1352, Validation Loss: 0.1352,V Acc: 0.2523, Top 70th Acc: 0.3462, Bottom 30th Acc: 0.0303
Fold [2/5] Epoch [10/100] Initial Loss: 0.1364, Training Loss: 0.0291, Initial Validation Loss: 0.1352, Validation Loss: 0.0316,V Acc: 0.8919, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.7273
Fold [2/5] Epoch [20/100] Initial Loss: 0.1364, Training Loss: 0.0192, Initial Validation Loss: 0.1352, Validation Loss: 0.0278,V Acc: 0.8559, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.9487179487179487
Fold [3/5] Epoch [0/100] Initial Loss: 0.1391, Training Loss: 0.1391, Initial Validation Loss: 0.1324, Validation Loss: 0.1324,V Acc: 0.3364, Top 70th Acc: 0.3766, Bottom 30th Acc: 0.2424
Fold [3/5] Epoch [10/100] Initial Loss: 0.1391, Training Loss: 0.0359, Initial Validation Loss: 0.1324, Validation Loss: 0.0403,V Acc: 0.8273, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.6364
Fold [3/5] Epoch [20/100] Initial Loss: 0.1391, Training Loss: 0.0267, Initial Validation Loss: 0.1324, Validation Loss: 0.0348,V Acc: 0.8182, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.5152
Stopping early at Epoch (base 0): 31  Rolling back to Epoch (base 0): 26  Top Validation Acc: 0.974025974025974
88 2 [array([0.37289292, 0.03588352, 0.19172837, 0.1629735 , 0.2365217 ],
      dtype=float32)]
Fold [4/5] Epoch [0/100] Initial Loss: 0.1349, Training Loss: 0.1349, Initial Validation Loss: 0.1285, Validation Loss: 0.1285,V Acc: 0.4727, Top 70th Acc: 0.6104, Bottom 30th Acc: 0.1515
Fold [4/5] Epoch [10/100] Initial Loss: 0.1349, Training Loss: 0.0311, Initial Validation Loss: 0.1285, Validation Loss: 0.0391,V Acc: 0.8182, Top 70th Acc: 0.8831, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 18  Rolling back to Epoch (base 0): 13  Top Validation Acc: 0.9090909090909091
Fold [5/5] Epoch [0/100] Initial Loss: 0.1378, Training Loss: 0.1378, Initial Validation Loss: 0.1336, Validation Loss: 0.1336,V Acc: 0.2685, Top 70th Acc: 0.2368, Bottom 30th Acc: 0.3438
Fold [5/5] Epoch [10/100] Initial Loss: 0.1378, Training Loss: 0.0359, Initial Validation Loss: 0.1336, Validation Loss: 0.0442,V Acc: 0.7870, Top 70th Acc: 0.8816, Bottom 30th Acc: 0.5625
Fold [5/5] Epoch [20/100] Initial Loss: 0.1378, Training Loss: 0.0226, Initial Validation Loss: 0.1336, Validation Loss: 0.0337,V Acc: 0.8519, Top 70th Acc: 0.9211, Bottom 30th Acc: 0.6875
Stopping early at Epoch (base 0): 29  Rolling back to Epoch (base 0): 24  Top Validation Acc: 0.9342105263157895
Running train_nn.py with seed 89
CUDA:False
Training samples count:  550
Training on 20 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1342, Training Loss: 0.1342, Initial Validation Loss: 0.1300, Validation Loss: 0.1300,V Acc: 0.4144, Top 70th Acc: 0.5256, Bottom 30th Acc: 0.1515
Fold [1/5] Epoch [10/100] Initial Loss: 0.1342, Training Loss: 0.0342, Initial Validation Loss: 0.1300, Validation Loss: 0.0453,V Acc: 0.8108, Top 70th Acc: 0.8846, Bottom 30th Acc: 0.6364
Fold [1/5] Epoch [20/100] Initial Loss: 0.1342, Training Loss: 0.0225, Initial Validation Loss: 0.1300, Validation Loss: 0.0393,V Acc: 0.8288, Top 70th Acc: 0.8718, Bottom 30th Acc: 0.7273
Fold [1/5] Epoch [30/100] Initial Loss: 0.1342, Training Loss: 0.0203, Initial Validation Loss: 0.1300, Validation Loss: 0.0393,V Acc: 0.8288, Top 70th Acc: 0.8846, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 31  Rolling back to Epoch (base 0): 26  Top Validation Acc: 0.8717948717948718
Fold [2/5] Epoch [0/100] Initial Loss: 0.1369, Training Loss: 0.1369, Initial Validation Loss: 0.1325, Validation Loss: 0.1325,V Acc: 0.3153, Top 70th Acc: 0.3846, Bottom 30th Acc: 0.1515
Fold [2/5] Epoch [10/100] Initial Loss: 0.1369, Training Loss: 0.0356, Initial Validation Loss: 0.1325, Validation Loss: 0.0479,V Acc: 0.7387, Top 70th Acc: 0.8718, Bottom 30th Acc: 0.4242
Fold [2/5] Epoch [20/100] Initial Loss: 0.1369, Training Loss: 0.0226, Initial Validation Loss: 0.1325, Validation Loss: 0.0381,V Acc: 0.7928, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.4848
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.9230769230769231
Fold [3/5] Epoch [0/100] Initial Loss: 0.1383, Training Loss: 0.1383, Initial Validation Loss: 0.1324, Validation Loss: 0.1324,V Acc: 0.3818, Top 70th Acc: 0.4416, Bottom 30th Acc: 0.2424
Fold [3/5] Epoch [10/100] Initial Loss: 0.1383, Training Loss: 0.0455, Initial Validation Loss: 0.1324, Validation Loss: 0.0411,V Acc: 0.8182, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.5455
Fold [3/5] Epoch [20/100] Initial Loss: 0.1383, Training Loss: 0.0247, Initial Validation Loss: 0.1324, Validation Loss: 0.0285,V Acc: 0.8636, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.935064935064935
89 2 [array([0.4503527 , 0.14163728, 0.09076487, 0.13740033, 0.17984489],
      dtype=float32)]
Fold [4/5] Epoch [0/100] Initial Loss: 0.1377, Training Loss: 0.1377, Initial Validation Loss: 0.1316, Validation Loss: 0.1316,V Acc: 0.2636, Top 70th Acc: 0.2597, Bottom 30th Acc: 0.2727
Fold [4/5] Epoch [10/100] Initial Loss: 0.1377, Training Loss: 0.0355, Initial Validation Loss: 0.1316, Validation Loss: 0.0440,V Acc: 0.7909, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.5152
Fold [4/5] Epoch [20/100] Initial Loss: 0.1377, Training Loss: 0.0235, Initial Validation Loss: 0.1316, Validation Loss: 0.0379,V Acc: 0.8455, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.935064935064935
Fold [5/5] Epoch [0/100] Initial Loss: 0.1393, Training Loss: 0.1393, Initial Validation Loss: 0.1349, Validation Loss: 0.1349,V Acc: 0.2407, Top 70th Acc: 0.2895, Bottom 30th Acc: 0.1250
Fold [5/5] Epoch [10/100] Initial Loss: 0.1393, Training Loss: 0.0369, Initial Validation Loss: 0.1349, Validation Loss: 0.0402,V Acc: 0.8519, Top 70th Acc: 0.9079, Bottom 30th Acc: 0.7188
Fold [5/5] Epoch [20/100] Initial Loss: 0.1393, Training Loss: 0.0251, Initial Validation Loss: 0.1349, Validation Loss: 0.0298,V Acc: 0.8611, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.6562
Fold [5/5] Epoch [30/100] Initial Loss: 0.1393, Training Loss: 0.0227, Initial Validation Loss: 0.1349, Validation Loss: 0.0295,V Acc: 0.8426, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.5625
Stopping early at Epoch (base 0): 33  Rolling back to Epoch (base 0): 28  Top Validation Acc: 0.9605263157894737
Running train_nn.py with seed 90
CUDA:False
Training samples count:  550
Training on 20 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1373, Training Loss: 0.1373, Initial Validation Loss: 0.1354, Validation Loss: 0.1354,V Acc: 0.3153, Top 70th Acc: 0.3333, Bottom 30th Acc: 0.2727
Fold [1/5] Epoch [10/100] Initial Loss: 0.1373, Training Loss: 0.0325, Initial Validation Loss: 0.1354, Validation Loss: 0.0382,V Acc: 0.8288, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.5152
Fold [1/5] Epoch [20/100] Initial Loss: 0.1373, Training Loss: 0.0236, Initial Validation Loss: 0.1354, Validation Loss: 0.0340,V Acc: 0.8288, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.5152
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.9615384615384616
Fold [2/5] Epoch [0/100] Initial Loss: 0.1377, Training Loss: 0.1377, Initial Validation Loss: 0.1335, Validation Loss: 0.1335,V Acc: 0.3333, Top 70th Acc: 0.3718, Bottom 30th Acc: 0.2424
Fold [2/5] Epoch [10/100] Initial Loss: 0.1377, Training Loss: 0.0379, Initial Validation Loss: 0.1335, Validation Loss: 0.0439,V Acc: 0.8018, Top 70th Acc: 0.8846, Bottom 30th Acc: 0.6061
Fold [2/5] Epoch [20/100] Initial Loss: 0.1377, Training Loss: 0.0224, Initial Validation Loss: 0.1335, Validation Loss: 0.0334,V Acc: 0.8288, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 29  Rolling back to Epoch (base 0): 24  Top Validation Acc: 0.9358974358974359
Fold [3/5] Epoch [0/100] Initial Loss: 0.1375, Training Loss: 0.1375, Initial Validation Loss: 0.1300, Validation Loss: 0.1300,V Acc: 0.3273, Top 70th Acc: 0.3766, Bottom 30th Acc: 0.2121
Fold [3/5] Epoch [10/100] Initial Loss: 0.1375, Training Loss: 0.0348, Initial Validation Loss: 0.1300, Validation Loss: 0.0407,V Acc: 0.7909, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.5152
Fold [3/5] Epoch [20/100] Initial Loss: 0.1375, Training Loss: 0.0212, Initial Validation Loss: 0.1300, Validation Loss: 0.0372,V Acc: 0.8000, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.4848
Stopping early at Epoch (base 0): 22  Rolling back to Epoch (base 0): 17  Top Validation Acc: 0.961038961038961
Fold [4/5] Epoch [0/100] Initial Loss: 0.1398, Training Loss: 0.1398, Initial Validation Loss: 0.1375, Validation Loss: 0.1375,V Acc: 0.2545, Top 70th Acc: 0.3117, Bottom 30th Acc: 0.1212
Fold [4/5] Epoch [10/100] Initial Loss: 0.1398, Training Loss: 0.0363, Initial Validation Loss: 0.1375, Validation Loss: 0.0378,V Acc: 0.8182, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.5758
Fold [4/5] Epoch [20/100] Initial Loss: 0.1398, Training Loss: 0.0242, Initial Validation Loss: 0.1375, Validation Loss: 0.0320,V Acc: 0.8727, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.7273
Stopping early at Epoch (base 0): 22  Rolling back to Epoch (base 0): 17  Top Validation Acc: 0.935064935064935
90 3 [array([0.2131076 , 0.13785663, 0.13119857, 0.18556388, 0.3322733 ],
      dtype=float32)]
Fold [1/5] Epoch [30/100] Initial Loss: 0.1357, Training Loss: 0.0122, Initial Validation Loss: 0.1310, Validation Loss: 0.0323,V Acc: 0.8378, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.5758
Fold [1/5] Epoch [40/100] Initial Loss: 0.1357, Training Loss: 0.0108, Initial Validation Loss: 0.1310, Validation Loss: 0.0317,V Acc: 0.8468, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.6061
Fold [1/5] Epoch [50/100] Initial Loss: 0.1357, Training Loss: 0.0101, Initial Validation Loss: 0.1310, Validation Loss: 0.0308,V Acc: 0.8559, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 57  Rolling back to Epoch (base 0): 52  Top Validation Acc: 0.9487179487179487
Fold [2/5] Epoch [0/100] Initial Loss: 0.1408, Training Loss: 0.1408, Initial Validation Loss: 0.1346, Validation Loss: 0.1346,V Acc: 0.3063, Top 70th Acc: 0.3462, Bottom 30th Acc: 0.2121
Fold [2/5] Epoch [10/100] Initial Loss: 0.1408, Training Loss: 0.0298, Initial Validation Loss: 0.1346, Validation Loss: 0.0350,V Acc: 0.8739, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.7576
Fold [2/5] Epoch [20/100] Initial Loss: 0.1408, Training Loss: 0.0152, Initial Validation Loss: 0.1346, Validation Loss: 0.0310,V Acc: 0.8198, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.4848
Stopping early at Epoch (base 0): 22  Rolling back to Epoch (base 0): 17  Top Validation Acc: 0.9487179487179487
Fold [3/5] Epoch [0/100] Initial Loss: 0.1390, Training Loss: 0.1390, Initial Validation Loss: 0.1339, Validation Loss: 0.1339,V Acc: 0.3727, Top 70th Acc: 0.4156, Bottom 30th Acc: 0.2727
Fold [3/5] Epoch [10/100] Initial Loss: 0.1390, Training Loss: 0.0315, Initial Validation Loss: 0.1339, Validation Loss: 0.0410,V Acc: 0.7727, Top 70th Acc: 0.8831, Bottom 30th Acc: 0.5152
Fold [3/5] Epoch [20/100] Initial Loss: 0.1390, Training Loss: 0.0147, Initial Validation Loss: 0.1339, Validation Loss: 0.0302,V Acc: 0.8000, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.4545
Stopping early at Epoch (base 0): 21  Rolling back to Epoch (base 0): 16  Top Validation Acc: 0.948051948051948
Fold [4/5] Epoch [0/100] Initial Loss: 0.1380, Training Loss: 0.1380, Initial Validation Loss: 0.1357, Validation Loss: 0.1357,V Acc: 0.2636, Top 70th Acc: 0.3377, Bottom 30th Acc: 0.0909
Fold [4/5] Epoch [10/100] Initial Loss: 0.1380, Training Loss: 0.0306, Initial Validation Loss: 0.1357, Validation Loss: 0.0446,V Acc: 0.8182, Top 70th Acc: 0.8831, Bottom 30th Acc: 0.6667
Fold [4/5] Epoch [20/100] Initial Loss: 0.1380, Training Loss: 0.0135, Initial Validation Loss: 0.1357, Validation Loss: 0.0398,V Acc: 0.8000, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 21  Rolling back to Epoch (base 0): 16  Top Validation Acc: 0.9090909090909091
Fold [5/5] Epoch [0/100] Initial Loss: 0.1403, Training Loss: 0.1403, Initial Validation Loss: 0.1346, Validation Loss: 0.1346,V Acc: 0.2500, Top 70th Acc: 0.2632, Bottom 30th Acc: 0.2188
Fold [5/5] Epoch [10/100] Initial Loss: 0.1403, Training Loss: 0.0413, Initial Validation Loss: 0.1346, Validation Loss: 0.0469,V Acc: 0.8056, Top 70th Acc: 0.8553, Bottom 30th Acc: 0.6875
Fold [5/5] Epoch [20/100] Initial Loss: 0.1403, Training Loss: 0.0151, Initial Validation Loss: 0.1346, Validation Loss: 0.0315,V Acc: 0.8426, Top 70th Acc: 0.9211, Bottom 30th Acc: 0.6562
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.9342105263157895
86 4 [array([0.6477678 , 0.03538443, 0.10850407, 0.10708408, 0.10125977],
      dtype=float32)]
Running train_nn.py with seed 87
CUDA:False
Training samples count:  550
Training on 40 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1354, Training Loss: 0.1354, Initial Validation Loss: 0.1336, Validation Loss: 0.1336,V Acc: 0.3784, Top 70th Acc: 0.3846, Bottom 30th Acc: 0.3636
Fold [1/5] Epoch [10/100] Initial Loss: 0.1354, Training Loss: 0.0245, Initial Validation Loss: 0.1336, Validation Loss: 0.0435,V Acc: 0.8198, Top 70th Acc: 0.8974, Bottom 30th Acc: 0.6364
Fold [1/5] Epoch [20/100] Initial Loss: 0.1354, Training Loss: 0.0125, Initial Validation Loss: 0.1336, Validation Loss: 0.0397,V Acc: 0.8288, Top 70th Acc: 0.8974, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.8974358974358975
Fold [2/5] Epoch [0/100] Initial Loss: 0.1397, Training Loss: 0.1397, Initial Validation Loss: 0.1336, Validation Loss: 0.1336,V Acc: 0.3153, Top 70th Acc: 0.3077, Bottom 30th Acc: 0.3333
Fold [2/5] Epoch [10/100] Initial Loss: 0.1397, Training Loss: 0.0354, Initial Validation Loss: 0.1336, Validation Loss: 0.0489,V Acc: 0.7658, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.4242
Fold [2/5] Epoch [20/100] Initial Loss: 0.1397, Training Loss: 0.0148, Initial Validation Loss: 0.1336, Validation Loss: 0.0365,V Acc: 0.7928, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.4848
Fold [2/5] Epoch [30/100] Initial Loss: 0.1397, Training Loss: 0.0112, Initial Validation Loss: 0.1336, Validation Loss: 0.0352,V Acc: 0.7838, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.4545
Stopping early at Epoch (base 0): 33  Rolling back to Epoch (base 0): 28  Top Validation Acc: 0.9230769230769231
Fold [3/5] Epoch [0/100] Initial Loss: 0.1373, Training Loss: 0.1373, Initial Validation Loss: 0.1324, Validation Loss: 0.1324,V Acc: 0.3364, Top 70th Acc: 0.3636, Bottom 30th Acc: 0.2727
Fold [3/5] Epoch [10/100] Initial Loss: 0.1373, Training Loss: 0.0399, Initial Validation Loss: 0.1324, Validation Loss: 0.0401,V Acc: 0.8091, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.5152
Fold [3/5] Epoch [20/100] Initial Loss: 0.1373, Training Loss: 0.0168, Initial Validation Loss: 0.1324, Validation Loss: 0.0247,V Acc: 0.8727, Top 70th Acc: 0.9870, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.987012987012987
Fold [4/5] Epoch [0/100] Initial Loss: 0.1384, Training Loss: 0.1384, Initial Validation Loss: 0.1353, Validation Loss: 0.1353,V Acc: 0.2273, Top 70th Acc: 0.2727, Bottom 30th Acc: 0.1212
Fold [4/5] Epoch [10/100] Initial Loss: 0.1384, Training Loss: 0.0258, Initial Validation Loss: 0.1353, Validation Loss: 0.0315,V Acc: 0.8636, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 18  Rolling back to Epoch (base 0): 13  Top Validation Acc: 0.948051948051948
Fold [5/5] Epoch [0/100] Initial Loss: 0.1379, Training Loss: 0.1379, Initial Validation Loss: 0.1298, Validation Loss: 0.1298,V Acc: 0.4074, Top 70th Acc: 0.4737, Bottom 30th Acc: 0.2500
Fold [5/5] Epoch [10/100] Initial Loss: 0.1379, Training Loss: 0.0307, Initial Validation Loss: 0.1298, Validation Loss: 0.0337,V Acc: 0.8426, Top 70th Acc: 0.9737, Bottom 30th Acc: 0.5312
Fold [5/5] Epoch [20/100] Initial Loss: 0.1379, Training Loss: 0.0139, Initial Validation Loss: 0.1298, Validation Loss: 0.0278,V Acc: 0.8426, Top 70th Acc: 0.9737, Bottom 30th Acc: 0.5312
Stopping early at Epoch (base 0): 28  Rolling back to Epoch (base 0): 23  Top Validation Acc: 0.9736842105263158
87 4 [array([0.3795319 , 0.17212044, 0.0250363 , 0.05222462, 0.37108675],
      dtype=float32)]
Running train_nn.py with seed 88
CUDA:False
Training samples count:  550
Training on 40 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1410, Training Loss: 0.1410, Initial Validation Loss: 0.1351, Validation Loss: 0.1351,V Acc: 0.4054, Top 70th Acc: 0.4744, Bottom 30th Acc: 0.2424
Fold [1/5] Epoch [10/100] Initial Loss: 0.1410, Training Loss: 0.0308, Initial Validation Loss: 0.1351, Validation Loss: 0.0390,V Acc: 0.8198, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.5758
Fold [1/5] Epoch [20/100] Initial Loss: 0.1410, Training Loss: 0.0143, Initial Validation Loss: 0.1351, Validation Loss: 0.0309,V Acc: 0.8649, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.9358974358974359
Fold [2/5] Epoch [0/100] Initial Loss: 0.1382, Training Loss: 0.1382, Initial Validation Loss: 0.1361, Validation Loss: 0.1361,V Acc: 0.3243, Top 70th Acc: 0.3462, Bottom 30th Acc: 0.2727
Fold [2/5] Epoch [10/100] Initial Loss: 0.1382, Training Loss: 0.0272, Initial Validation Loss: 0.1361, Validation Loss: 0.0334,V Acc: 0.8649, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.7273
Fold [3/5] Epoch [10/100] Initial Loss: 0.1273, Training Loss: 0.0804, Initial Validation Loss: 0.1130, Validation Loss: 0.0799,V Acc: 0.6182, Top 70th Acc: 0.7143, Bottom 30th Acc: 0.3939
Fold [3/5] Epoch [20/100] Initial Loss: 0.1273, Training Loss: 0.0783, Initial Validation Loss: 0.1130, Validation Loss: 0.0798,V Acc: 0.6000, Top 70th Acc: 0.7013, Bottom 30th Acc: 0.3636
Stopping early at Epoch (base 0): 22  Rolling back to Epoch (base 0): 17  Top Validation Acc: 0.7142857142857143
Fold [4/5] Epoch [0/100] Initial Loss: 0.1410, Training Loss: 0.1410, Initial Validation Loss: 0.1382, Validation Loss: 0.1382,V Acc: 0.3909, Top 70th Acc: 0.3117, Bottom 30th Acc: 0.5758
Fold [4/5] Epoch [10/100] Initial Loss: 0.1410, Training Loss: 0.0828, Initial Validation Loss: 0.1382, Validation Loss: 0.0764,V Acc: 0.6909, Top 70th Acc: 0.8052, Bottom 30th Acc: 0.4242
Fold [4/5] Epoch [20/100] Initial Loss: 0.1410, Training Loss: 0.0797, Initial Validation Loss: 0.1382, Validation Loss: 0.0744,V Acc: 0.6727, Top 70th Acc: 0.8052, Bottom 30th Acc: 0.3636
Fold [4/5] Epoch [30/100] Initial Loss: 0.1410, Training Loss: 0.0785, Initial Validation Loss: 0.1382, Validation Loss: 0.0731,V Acc: 0.6909, Top 70th Acc: 0.7792, Bottom 30th Acc: 0.4848
Stopping early at Epoch (base 0): 31  Rolling back to Epoch (base 0): 26  Top Validation Acc: 0.7922077922077922
Fold [5/5] Epoch [0/100] Initial Loss: 0.1325, Training Loss: 0.1325, Initial Validation Loss: 0.1182, Validation Loss: 0.1182,V Acc: 0.4815, Top 70th Acc: 0.5526, Bottom 30th Acc: 0.3125
Fold [5/5] Epoch [10/100] Initial Loss: 0.1325, Training Loss: 0.0779, Initial Validation Loss: 0.1182, Validation Loss: 0.0862,V Acc: 0.5556, Top 70th Acc: 0.6711, Bottom 30th Acc: 0.2812
Fold [5/5] Epoch [20/100] Initial Loss: 0.1325, Training Loss: 0.0765, Initial Validation Loss: 0.1182, Validation Loss: 0.0848,V Acc: 0.5648, Top 70th Acc: 0.6711, Bottom 30th Acc: 0.3125
Fold [5/5] Epoch [30/100] Initial Loss: 0.1325, Training Loss: 0.0765, Initial Validation Loss: 0.1182, Validation Loss: 0.0848,V Acc: 0.5648, Top 70th Acc: 0.6842, Bottom 30th Acc: 0.2812
Stopping early at Epoch (base 0): 30  Rolling back to Epoch (base 0): 25  Top Validation Acc: 0.6842105263157895
83 4 [array([0.1278318 , 0.34524488, 0.16127032, 0.22835179, 0.13730124],
      dtype=float32)]
Running train_nn.py with seed 84
CUDA:False
Training samples count:  550
Training on 2 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1338, Training Loss: 0.1338, Initial Validation Loss: 0.1237, Validation Loss: 0.1237,V Acc: 0.4144, Top 70th Acc: 0.5641, Bottom 30th Acc: 0.0606
Fold [1/5] Epoch [10/100] Initial Loss: 0.1338, Training Loss: 0.0811, Initial Validation Loss: 0.1237, Validation Loss: 0.0801,V Acc: 0.6126, Top 70th Acc: 0.7692, Bottom 30th Acc: 0.2424
Fold [1/5] Epoch [20/100] Initial Loss: 0.1338, Training Loss: 0.0791, Initial Validation Loss: 0.1237, Validation Loss: 0.0784,V Acc: 0.6216, Top 70th Acc: 0.7564, Bottom 30th Acc: 0.3030
Fold [1/5] Epoch [30/100] Initial Loss: 0.1338, Training Loss: 0.0788, Initial Validation Loss: 0.1237, Validation Loss: 0.0782,V Acc: 0.6216, Top 70th Acc: 0.7564, Bottom 30th Acc: 0.3030
Stopping early at Epoch (base 0): 32  Rolling back to Epoch (base 0): 27  Top Validation Acc: 0.7435897435897436
84 0 [array([0.16165878, 0.3428762 , 0.13696697, 0.22206734, 0.13643073],
      dtype=float32)]
Fold [2/5] Epoch [0/100] Initial Loss: 0.1370, Training Loss: 0.1370, Initial Validation Loss: 0.1341, Validation Loss: 0.1341,V Acc: 0.3874, Top 70th Acc: 0.4744, Bottom 30th Acc: 0.1818
Fold [2/5] Epoch [10/100] Initial Loss: 0.1370, Training Loss: 0.0804, Initial Validation Loss: 0.1341, Validation Loss: 0.0863,V Acc: 0.6306, Top 70th Acc: 0.7051, Bottom 30th Acc: 0.4545
Fold [2/5] Epoch [20/100] Initial Loss: 0.1370, Training Loss: 0.0781, Initial Validation Loss: 0.1341, Validation Loss: 0.0848,V Acc: 0.6486, Top 70th Acc: 0.7179, Bottom 30th Acc: 0.4848
Fold [2/5] Epoch [30/100] Initial Loss: 0.1370, Training Loss: 0.0772, Initial Validation Loss: 0.1341, Validation Loss: 0.0836,V Acc: 0.6306, Top 70th Acc: 0.7308, Bottom 30th Acc: 0.3939
Stopping early at Epoch (base 0): 35  Rolling back to Epoch (base 0): 30  Top Validation Acc: 0.7307692307692307
Fold [3/5] Epoch [0/100] Initial Loss: 0.1374, Training Loss: 0.1374, Initial Validation Loss: 0.1322, Validation Loss: 0.1322,V Acc: 0.2545, Top 70th Acc: 0.3377, Bottom 30th Acc: 0.0606
Fold [3/5] Epoch [10/100] Initial Loss: 0.1374, Training Loss: 0.0786, Initial Validation Loss: 0.1322, Validation Loss: 0.0862,V Acc: 0.5727, Top 70th Acc: 0.6753, Bottom 30th Acc: 0.3333
Fold [3/5] Epoch [20/100] Initial Loss: 0.1374, Training Loss: 0.0764, Initial Validation Loss: 0.1322, Validation Loss: 0.0854,V Acc: 0.5727, Top 70th Acc: 0.6623, Bottom 30th Acc: 0.3636
Stopping early at Epoch (base 0): 27  Rolling back to Epoch (base 0): 22  Top Validation Acc: 0.6623376623376623
Fold [4/5] Epoch [0/100] Initial Loss: 0.1352, Training Loss: 0.1352, Initial Validation Loss: 0.1211, Validation Loss: 0.1211,V Acc: 0.3636, Top 70th Acc: 0.4545, Bottom 30th Acc: 0.1515
Fold [4/5] Epoch [10/100] Initial Loss: 0.1352, Training Loss: 0.0838, Initial Validation Loss: 0.1211, Validation Loss: 0.0719,V Acc: 0.6727, Top 70th Acc: 0.7792, Bottom 30th Acc: 0.4242
Fold [4/5] Epoch [20/100] Initial Loss: 0.1352, Training Loss: 0.0812, Initial Validation Loss: 0.1211, Validation Loss: 0.0709,V Acc: 0.6727, Top 70th Acc: 0.7922, Bottom 30th Acc: 0.3939
Fold [4/5] Epoch [30/100] Initial Loss: 0.1352, Training Loss: 0.0805, Initial Validation Loss: 0.1211, Validation Loss: 0.0680,V Acc: 0.6727, Top 70th Acc: 0.8052, Bottom 30th Acc: 0.3636
Stopping early at Epoch (base 0): 31  Rolling back to Epoch (base 0): 26  Top Validation Acc: 0.8051948051948052
Fold [5/5] Epoch [0/100] Initial Loss: 0.1355, Training Loss: 0.1355, Initial Validation Loss: 0.1297, Validation Loss: 0.1297,V Acc: 0.2870, Top 70th Acc: 0.3553, Bottom 30th Acc: 0.1250
Fold [5/5] Epoch [10/100] Initial Loss: 0.1355, Training Loss: 0.0823, Initial Validation Loss: 0.1297, Validation Loss: 0.0788,V Acc: 0.6204, Top 70th Acc: 0.7237, Bottom 30th Acc: 0.3750
Fold [5/5] Epoch [20/100] Initial Loss: 0.1355, Training Loss: 0.0798, Initial Validation Loss: 0.1297, Validation Loss: 0.0769,V Acc: 0.6389, Top 70th Acc: 0.7500, Bottom 30th Acc: 0.3750
Stopping early at Epoch (base 0): 29  Rolling back to Epoch (base 0): 24  Top Validation Acc: 0.7631578947368421
Running train_nn.py with seed 85
CUDA:False
Training samples count:  550
Training on 2 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1287, Training Loss: 0.1287, Initial Validation Loss: 0.1160, Validation Loss: 0.1160,V Acc: 0.4324, Top 70th Acc: 0.5000, Bottom 30th Acc: 0.2727
Fold [1/5] Epoch [10/100] Initial Loss: 0.1287, Training Loss: 0.0810, Initial Validation Loss: 0.1160, Validation Loss: 0.0780,V Acc: 0.6126, Top 70th Acc: 0.7179, Bottom 30th Acc: 0.3636
Fold [1/5] Epoch [20/100] Initial Loss: 0.1287, Training Loss: 0.0793, Initial Validation Loss: 0.1160, Validation Loss: 0.0766,V Acc: 0.6306, Top 70th Acc: 0.7179, Bottom 30th Acc: 0.4242
Fold [1/5] Epoch [30/100] Initial Loss: 0.1287, Training Loss: 0.0781, Initial Validation Loss: 0.1160, Validation Loss: 0.0767,V Acc: 0.6396, Top 70th Acc: 0.7179, Bottom 30th Acc: 0.4545
Stopping early at Epoch (base 0): 37  Rolling back to Epoch (base 0): 32  Top Validation Acc: 0.7307692307692307
Fold [2/5] Epoch [0/100] Initial Loss: 0.1380, Training Loss: 0.1380, Initial Validation Loss: 0.1341, Validation Loss: 0.1341,V Acc: 0.4414, Top 70th Acc: 0.5256, Bottom 30th Acc: 0.2424
Fold [2/5] Epoch [10/100] Initial Loss: 0.1380, Training Loss: 0.0814, Initial Validation Loss: 0.1341, Validation Loss: 0.0787,V Acc: 0.6306, Top 70th Acc: 0.7821, Bottom 30th Acc: 0.2727
Fold [2/5] Epoch [20/100] Initial Loss: 0.1380, Training Loss: 0.0800, Initial Validation Loss: 0.1341, Validation Loss: 0.0770,V Acc: 0.6306, Top 70th Acc: 0.7949, Bottom 30th Acc: 0.2424
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.7948717948717948
85 1 [array([0.13762477, 0.37766793, 0.15111655, 0.19543456, 0.13815622],
      dtype=float32)]
Fold [1/5] Epoch [10/100] Initial Loss: 0.1390, Training Loss: 0.0203, Initial Validation Loss: 0.1352, Validation Loss: 0.0393,V Acc: 0.8198, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.5758
Fold [1/5] Epoch [20/100] Initial Loss: 0.1390, Training Loss: 0.0054, Initial Validation Loss: 0.1352, Validation Loss: 0.0348,V Acc: 0.8018, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.5152
Fold [1/5] Epoch [30/100] Initial Loss: 0.1390, Training Loss: 0.0041, Initial Validation Loss: 0.1352, Validation Loss: 0.0340,V Acc: 0.8018, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.4545
Fold [1/5] Epoch [40/100] Initial Loss: 0.1390, Training Loss: 0.0038, Initial Validation Loss: 0.1352, Validation Loss: 0.0332,V Acc: 0.7928, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.3939
Fold [1/5] Epoch [50/100] Initial Loss: 0.1390, Training Loss: 0.0036, Initial Validation Loss: 0.1352, Validation Loss: 0.0331,V Acc: 0.7928, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.3939
Fold [1/5] Epoch [60/100] Initial Loss: 0.1390, Training Loss: 0.0035, Initial Validation Loss: 0.1352, Validation Loss: 0.0327,V Acc: 0.7928, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.3939
Stopping early at Epoch (base 0): 67  Rolling back to Epoch (base 0): 62  Top Validation Acc: 0.9743589743589743
67 0 [array([0.22020072, 0.065244  , 0.0478773 , 0.24064027, 0.42603773],
      dtype=float32)]
Fold [2/5] Epoch [0/100] Initial Loss: 0.1394, Training Loss: 0.1394, Initial Validation Loss: 0.1343, Validation Loss: 0.1343,V Acc: 0.2432, Top 70th Acc: 0.2949, Bottom 30th Acc: 0.1212
Fold [2/5] Epoch [10/100] Initial Loss: 0.1394, Training Loss: 0.0180, Initial Validation Loss: 0.1343, Validation Loss: 0.0366,V Acc: 0.8108, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.5455
Fold [2/5] Epoch [20/100] Initial Loss: 0.1394, Training Loss: 0.0052, Initial Validation Loss: 0.1343, Validation Loss: 0.0305,V Acc: 0.8378, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 28  Rolling back to Epoch (base 0): 23  Top Validation Acc: 0.9358974358974359
Fold [3/5] Epoch [0/100] Initial Loss: 0.1413, Training Loss: 0.1413, Initial Validation Loss: 0.1341, Validation Loss: 0.1341,V Acc: 0.2727, Top 70th Acc: 0.3247, Bottom 30th Acc: 0.1515
Fold [3/5] Epoch [10/100] Initial Loss: 0.1413, Training Loss: 0.0221, Initial Validation Loss: 0.1341, Validation Loss: 0.0395,V Acc: 0.8364, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.5758
Fold [3/5] Epoch [20/100] Initial Loss: 0.1413, Training Loss: 0.0050, Initial Validation Loss: 0.1341, Validation Loss: 0.0259,V Acc: 0.9091, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.7576
Fold [3/5] Epoch [30/100] Initial Loss: 0.1413, Training Loss: 0.0038, Initial Validation Loss: 0.1341, Validation Loss: 0.0253,V Acc: 0.9000, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.7273
Stopping early at Epoch (base 0): 37  Rolling back to Epoch (base 0): 32  Top Validation Acc: 0.974025974025974
Fold [4/5] Epoch [0/100] Initial Loss: 0.1404, Training Loss: 0.1404, Initial Validation Loss: 0.1336, Validation Loss: 0.1336,V Acc: 0.4364, Top 70th Acc: 0.4935, Bottom 30th Acc: 0.3030
Fold [4/5] Epoch [10/100] Initial Loss: 0.1404, Training Loss: 0.0147, Initial Validation Loss: 0.1336, Validation Loss: 0.0387,V Acc: 0.7909, Top 70th Acc: 0.8961, Bottom 30th Acc: 0.5455
Fold [4/5] Epoch [20/100] Initial Loss: 0.1404, Training Loss: 0.0049, Initial Validation Loss: 0.1336, Validation Loss: 0.0327,V Acc: 0.8000, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.4242
Fold [4/5] Epoch [30/100] Initial Loss: 0.1404, Training Loss: 0.0039, Initial Validation Loss: 0.1336, Validation Loss: 0.0314,V Acc: 0.8364, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.5152
Fold [4/5] Epoch [40/100] Initial Loss: 0.1404, Training Loss: 0.0036, Initial Validation Loss: 0.1336, Validation Loss: 0.0315,V Acc: 0.8273, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.5152
Stopping early at Epoch (base 0): 41  Rolling back to Epoch (base 0): 36  Top Validation Acc: 0.961038961038961
Fold [5/5] Epoch [0/100] Initial Loss: 0.1378, Training Loss: 0.1378, Initial Validation Loss: 0.1335, Validation Loss: 0.1335,V Acc: 0.3333, Top 70th Acc: 0.4079, Bottom 30th Acc: 0.1562
Fold [5/5] Epoch [10/100] Initial Loss: 0.1378, Training Loss: 0.0126, Initial Validation Loss: 0.1335, Validation Loss: 0.0305,V Acc: 0.8519, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.5938
Fold [5/5] Epoch [20/100] Initial Loss: 0.1378, Training Loss: 0.0048, Initial Validation Loss: 0.1335, Validation Loss: 0.0266,V Acc: 0.8796, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.6875
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.9605263157894737
Running train_nn.py with seed 68
CUDA:False
Training samples count:  550
Training on 163 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1384, Training Loss: 0.1384, Initial Validation Loss: 0.1386, Validation Loss: 0.1386,V Acc: 0.3964, Top 70th Acc: 0.4744, Bottom 30th Acc: 0.2121
Fold [1/5] Epoch [10/100] Initial Loss: 0.1384, Training Loss: 0.0236, Initial Validation Loss: 0.1386, Validation Loss: 0.0400,V Acc: 0.8288, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.5455
Fold [1/5] Epoch [20/100] Initial Loss: 0.1384, Training Loss: 0.0058, Initial Validation Loss: 0.1386, Validation Loss: 0.0281,V Acc: 0.8468, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.5455
Fold [1/5] Epoch [30/100] Initial Loss: 0.1384, Training Loss: 0.0041, Initial Validation Loss: 0.1386, Validation Loss: 0.0252,V Acc: 0.8919, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.7273
Fold [1/5] Epoch [40/100] Initial Loss: 0.1384, Training Loss: 0.0036, Initial Validation Loss: 0.1386, Validation Loss: 0.0241,V Acc: 0.8919, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 48  Rolling back to Epoch (base 0): 43  Top Validation Acc: 0.9871794871794872
Fold [2/5] Epoch [0/100] Initial Loss: 0.1380, Training Loss: 0.1380, Initial Validation Loss: 0.1371, Validation Loss: 0.1371,V Acc: 0.2523, Top 70th Acc: 0.3333, Bottom 30th Acc: 0.0606
Fold [2/5] Epoch [10/100] Initial Loss: 0.1380, Training Loss: 0.0234, Initial Validation Loss: 0.1371, Validation Loss: 0.0337,V Acc: 0.8559, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.5758
Fold [2/5] Epoch [20/100] Initial Loss: 0.1380, Training Loss: 0.0054, Initial Validation Loss: 0.1371, Validation Loss: 0.0214,V Acc: 0.9189, Top 70th Acc: 0.9872, Bottom 30th Acc: 0.7576
Fold [2/5] Epoch [30/100] Initial Loss: 0.1380, Training Loss: 0.0042, Initial Validation Loss: 0.1371, Validation Loss: 0.0212,V Acc: 0.9279, Top 70th Acc: 1.0000, Bottom 30th Acc: 0.7576
Stopping early at Epoch (base 0): 31  Rolling back to Epoch (base 0): 26  Top Validation Acc: 1.0
Fold [3/5] Epoch [0/100] Initial Loss: 0.1411, Training Loss: 0.1411, Initial Validation Loss: 0.1306, Validation Loss: 0.1306,V Acc: 0.2545, Top 70th Acc: 0.2727, Bottom 30th Acc: 0.2121
Fold [3/5] Epoch [10/100] Initial Loss: 0.1411, Training Loss: 0.0219, Initial Validation Loss: 0.1306, Validation Loss: 0.0451,V Acc: 0.7273, Top 70th Acc: 0.8312, Bottom 30th Acc: 0.4848
Stopping early at Epoch (base 0): 17  Rolling back to Epoch (base 0): 12  Top Validation Acc: 0.8571428571428571
Fold [4/5] Epoch [0/100] Initial Loss: 0.1371, Training Loss: 0.1371, Initial Validation Loss: 0.1373, Validation Loss: 0.1373,V Acc: 0.3091, Top 70th Acc: 0.3636, Bottom 30th Acc: 0.1818
Fold [4/5] Epoch [10/100] Initial Loss: 0.1371, Training Loss: 0.0187, Initial Validation Loss: 0.1373, Validation Loss: 0.0250,V Acc: 0.9273, Top 70th Acc: 1.0000, Bottom 30th Acc: 0.7576
Fold [4/5] Epoch [20/100] Initial Loss: 0.1371, Training Loss: 0.0054, Initial Validation Loss: 0.1373, Validation Loss: 0.0200,V Acc: 0.9182, Top 70th Acc: 1.0000, Bottom 30th Acc: 0.7273
Stopping early at Epoch (base 0): 22  Rolling back to Epoch (base 0): 17  Top Validation Acc: 1.0
Fold [5/5] Epoch [0/100] Initial Loss: 0.1390, Training Loss: 0.1390, Initial Validation Loss: 0.1292, Validation Loss: 0.1292,V Acc: 0.4259, Top 70th Acc: 0.5395, Bottom 30th Acc: 0.1562
Fold [5/5] Epoch [10/100] Initial Loss: 0.1390, Training Loss: 0.0137, Initial Validation Loss: 0.1292, Validation Loss: 0.0292,V Acc: 0.8519, Top 70th Acc: 0.9211, Bottom 30th Acc: 0.6875
Fold [5/5] Epoch [20/100] Initial Loss: 0.1390, Training Loss: 0.0051, Initial Validation Loss: 0.1292, Validation Loss: 0.0238,V Acc: 0.8611, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.6562/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)

Fold [3/5] Epoch [30/100] Initial Loss: 0.1391, Training Loss: 0.0192, Initial Validation Loss: 0.1324, Validation Loss: 0.0295,V Acc: 0.8273, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.5152
Fold [3/5] Epoch [40/100] Initial Loss: 0.1391, Training Loss: 0.0167, Initial Validation Loss: 0.1324, Validation Loss: 0.0293,V Acc: 0.8455, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 42  Rolling back to Epoch (base 0): 37  Top Validation Acc: 0.974025974025974
88 2 [array([0.73074824, 0.05107179, 0.04993824, 0.04680022, 0.12144148],
      dtype=float32)]
Fold [4/5] Epoch [0/100] Initial Loss: 0.1413, Training Loss: 0.1413, Initial Validation Loss: 0.1334, Validation Loss: 0.1334,V Acc: 0.3000, Top 70th Acc: 0.3636, Bottom 30th Acc: 0.1515
Fold [4/5] Epoch [10/100] Initial Loss: 0.1413, Training Loss: 0.0287, Initial Validation Loss: 0.1334, Validation Loss: 0.0352,V Acc: 0.8455, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.6364
Fold [4/5] Epoch [20/100] Initial Loss: 0.1413, Training Loss: 0.0187, Initial Validation Loss: 0.1334, Validation Loss: 0.0315,V Acc: 0.8455, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 27  Rolling back to Epoch (base 0): 22  Top Validation Acc: 0.935064935064935
Fold [5/5] Epoch [0/100] Initial Loss: 0.1378, Training Loss: 0.1378, Initial Validation Loss: 0.1336, Validation Loss: 0.1336,V Acc: 0.2778, Top 70th Acc: 0.3026, Bottom 30th Acc: 0.2188
Fold [5/5] Epoch [10/100] Initial Loss: 0.1378, Training Loss: 0.0365, Initial Validation Loss: 0.1336, Validation Loss: 0.0479,V Acc: 0.7593, Top 70th Acc: 0.8684, Bottom 30th Acc: 0.5000
Fold [5/5] Epoch [20/100] Initial Loss: 0.1378, Training Loss: 0.0199, Initial Validation Loss: 0.1336, Validation Loss: 0.0357,V Acc: 0.8333, Top 70th Acc: 0.9211, Bottom 30th Acc: 0.6250
Stopping early at Epoch (base 0): 27  Rolling back to Epoch (base 0): 22  Top Validation Acc: 0.9342105263157895
Running train_nn.py with seed 89
CUDA:False
Training samples count:  550
Training on 30 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1399, Training Loss: 0.1399, Initial Validation Loss: 0.1361, Validation Loss: 0.1361,V Acc: 0.3423, Top 70th Acc: 0.4231, Bottom 30th Acc: 0.1515
Fold [1/5] Epoch [10/100] Initial Loss: 0.1399, Training Loss: 0.0289, Initial Validation Loss: 0.1361, Validation Loss: 0.0419,V Acc: 0.8108, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.5455
Fold [1/5] Epoch [20/100] Initial Loss: 0.1399, Training Loss: 0.0166, Initial Validation Loss: 0.1361, Validation Loss: 0.0371,V Acc: 0.7928, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.4848
Stopping early at Epoch (base 0): 22  Rolling back to Epoch (base 0): 17  Top Validation Acc: 0.9102564102564102
Fold [2/5] Epoch [0/100] Initial Loss: 0.1415, Training Loss: 0.1415, Initial Validation Loss: 0.1357, Validation Loss: 0.1357,V Acc: 0.2523, Top 70th Acc: 0.3205, Bottom 30th Acc: 0.0909
Fold [2/5] Epoch [10/100] Initial Loss: 0.1415, Training Loss: 0.0377, Initial Validation Loss: 0.1357, Validation Loss: 0.0456,V Acc: 0.7838, Top 70th Acc: 0.8590, Bottom 30th Acc: 0.6061
Fold [2/5] Epoch [20/100] Initial Loss: 0.1415, Training Loss: 0.0204, Initial Validation Loss: 0.1357, Validation Loss: 0.0401,V Acc: 0.7477, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.3636
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.9102564102564102
Fold [3/5] Epoch [0/100] Initial Loss: 0.1416, Training Loss: 0.1416, Initial Validation Loss: 0.1336, Validation Loss: 0.1336,V Acc: 0.3273, Top 70th Acc: 0.3766, Bottom 30th Acc: 0.2121
Fold [3/5] Epoch [10/100] Initial Loss: 0.1416, Training Loss: 0.0429, Initial Validation Loss: 0.1336, Validation Loss: 0.0426,V Acc: 0.8182, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.6061
Fold [3/5] Epoch [20/100] Initial Loss: 0.1416, Training Loss: 0.0216, Initial Validation Loss: 0.1336, Validation Loss: 0.0312,V Acc: 0.8545, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.6970
Fold [3/5] Epoch [30/100] Initial Loss: 0.1416, Training Loss: 0.0176, Initial Validation Loss: 0.1336, Validation Loss: 0.0298,V Acc: 0.8636, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 36  Rolling back to Epoch (base 0): 31  Top Validation Acc: 0.935064935064935
89 2 [array([0.8197241 , 0.03593725, 0.03562403, 0.05249974, 0.05621484],
      dtype=float32)]
Fold [4/5] Epoch [0/100] Initial Loss: 0.1401, Training Loss: 0.1401, Initial Validation Loss: 0.1331, Validation Loss: 0.1331,V Acc: 0.3273, Top 70th Acc: 0.3636, Bottom 30th Acc: 0.2424
Fold [4/5] Epoch [10/100] Initial Loss: 0.1401, Training Loss: 0.0354, Initial Validation Loss: 0.1331, Validation Loss: 0.0433,V Acc: 0.7909, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.5152
Fold [4/5] Epoch [20/100] Initial Loss: 0.1401, Training Loss: 0.0211, Initial Validation Loss: 0.1331, Validation Loss: 0.0320,V Acc: 0.8364, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 27  Rolling back to Epoch (base 0): 22  Top Validation Acc: 0.948051948051948
Fold [5/5] Epoch [0/100] Initial Loss: 0.1346, Training Loss: 0.1346, Initial Validation Loss: 0.1328, Validation Loss: 0.1328,V Acc: 0.3981, Top 70th Acc: 0.4342, Bottom 30th Acc: 0.3125
Fold [5/5] Epoch [10/100] Initial Loss: 0.1346, Training Loss: 0.0352, Initial Validation Loss: 0.1328, Validation Loss: 0.0380,V Acc: 0.8426, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.5938
Fold [5/5] Epoch [20/100] Initial Loss: 0.1346, Training Loss: 0.0222, Initial Validation Loss: 0.1328, Validation Loss: 0.0280,V Acc: 0.8704, Top 70th Acc: 0.9737, Bottom 30th Acc: 0.6250
Fold [5/5] Epoch [30/100] Initial Loss: 0.1346, Training Loss: 0.0186, Initial Validation Loss: 0.1328, Validation Loss: 0.0257,V Acc: 0.8704, Top 70th Acc: 0.9737, Bottom 30th Acc: 0.6250
Fold [5/5] Epoch [40/100] Initial Loss: 0.1346, Training Loss: 0.0173, Initial Validation Loss: 0.1328, Validation Loss: 0.0245,V Acc: 0.8981, Top 70th Acc: 0.9737, Bottom 30th Acc: 0.7188
Fold [5/5] Epoch [50/100] Initial Loss: 0.1346, Training Loss: 0.0165, Initial Validation Loss: 0.1328, Validation Loss: 0.0230,V Acc: 0.8889, Top 70th Acc: 0.9737, Bottom 30th Acc: 0.6875
Stopping early at Epoch (base 0): 58  Rolling back to Epoch (base 0): 53  Top Validation Acc: 0.9736842105263158
Running train_nn.py with seed 90
CUDA:False
Training samples count:  550
Training on 30 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1432, Training Loss: 0.1432, Initial Validation Loss: 0.1365, Validation Loss: 0.1365,V Acc: 0.2883, Top 70th Acc: 0.2949, Bottom 30th Acc: 0.2727
Fold [1/5] Epoch [10/100] Initial Loss: 0.1432, Training Loss: 0.0388, Initial Validation Loss: 0.1365, Validation Loss: 0.0436,V Acc: 0.7928, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.5152
Fold [1/5] Epoch [20/100] Initial Loss: 0.1432, Training Loss: 0.0229, Initial Validation Loss: 0.1365, Validation Loss: 0.0351,V Acc: 0.8108, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.5455
Fold [1/5] Epoch [30/100] Initial Loss: 0.1432, Training Loss: 0.0185, Initial Validation Loss: 0.1365, Validation Loss: 0.0328,V Acc: 0.8288, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 32  Rolling back to Epoch (base 0): 27  Top Validation Acc: 0.9358974358974359
Fold [2/5] Epoch [0/100] Initial Loss: 0.1388, Training Loss: 0.1388, Initial Validation Loss: 0.1367, Validation Loss: 0.1367,V Acc: 0.2793, Top 70th Acc: 0.2949, Bottom 30th Acc: 0.2424
Fold [2/5] Epoch [10/100] Initial Loss: 0.1388, Training Loss: 0.0338, Initial Validation Loss: 0.1367, Validation Loss: 0.0429,V Acc: 0.8198, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.5758
Fold [2/5] Epoch [20/100] Initial Loss: 0.1388, Training Loss: 0.0200, Initial Validation Loss: 0.1367, Validation Loss: 0.0364,V Acc: 0.8018, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.5152
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.9358974358974359
Fold [3/5] Epoch [0/100] Initial Loss: 0.1385, Training Loss: 0.1385, Initial Validation Loss: 0.1321, Validation Loss: 0.1321,V Acc: 0.2545, Top 70th Acc: 0.3117, Bottom 30th Acc: 0.1212
Fold [3/5] Epoch [10/100] Initial Loss: 0.1385, Training Loss: 0.0313, Initial Validation Loss: 0.1321, Validation Loss: 0.0385,V Acc: 0.8000, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.5455
Fold [5/5] Epoch [0/100] Initial Loss: 0.1399, Training Loss: 0.1399, Initial Validation Loss: 0.1301, Validation Loss: 0.1301,V Acc: 0.3148, Top 70th Acc: 0.3553, Bottom 30th Acc: 0.2188
Fold [5/5] Epoch [10/100] Initial Loss: 0.1399, Training Loss: 0.0328, Initial Validation Loss: 0.1301, Validation Loss: 0.0323,V Acc: 0.8426, Top 70th Acc: 0.9211, Bottom 30th Acc: 0.6562
Fold [5/5] Epoch [20/100] Initial Loss: 0.1399, Training Loss: 0.0232, Initial Validation Loss: 0.1301, Validation Loss: 0.0294,V Acc: 0.8704, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.7188
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.9210526315789473
Running train_nn.py with seed 91
CUDA:False
Training samples count:  550
Training on 20 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1381, Training Loss: 0.1381, Initial Validation Loss: 0.1377, Validation Loss: 0.1377,V Acc: 0.2523, Top 70th Acc: 0.2436, Bottom 30th Acc: 0.2727
Fold [1/5] Epoch [10/100] Initial Loss: 0.1381, Training Loss: 0.0322, Initial Validation Loss: 0.1377, Validation Loss: 0.0376,V Acc: 0.8468, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.6667
Fold [1/5] Epoch [20/100] Initial Loss: 0.1381, Training Loss: 0.0224, Initial Validation Loss: 0.1377, Validation Loss: 0.0342,V Acc: 0.8468, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 22  Rolling back to Epoch (base 0): 17  Top Validation Acc: 0.9487179487179487
Fold [2/5] Epoch [0/100] Initial Loss: 0.1384, Training Loss: 0.1384, Initial Validation Loss: 0.1283, Validation Loss: 0.1283,V Acc: 0.3784, Top 70th Acc: 0.4231, Bottom 30th Acc: 0.2727
Fold [2/5] Epoch [10/100] Initial Loss: 0.1384, Training Loss: 0.0348, Initial Validation Loss: 0.1283, Validation Loss: 0.0356,V Acc: 0.8288, Top 70th Acc: 0.8974, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 19  Rolling back to Epoch (base 0): 14  Top Validation Acc: 0.8974358974358975
Fold [3/5] Epoch [0/100] Initial Loss: 0.1330, Training Loss: 0.1330, Initial Validation Loss: 0.1279, Validation Loss: 0.1279,V Acc: 0.3364, Top 70th Acc: 0.4156, Bottom 30th Acc: 0.1515
Fold [3/5] Epoch [10/100] Initial Loss: 0.1330, Training Loss: 0.0435, Initial Validation Loss: 0.1279, Validation Loss: 0.0558,V Acc: 0.7273, Top 70th Acc: 0.8571, Bottom 30th Acc: 0.4242
Fold [3/5] Epoch [20/100] Initial Loss: 0.1330, Training Loss: 0.0218, Initial Validation Loss: 0.1279, Validation Loss: 0.0437,V Acc: 0.8091, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 28  Rolling back to Epoch (base 0): 23  Top Validation Acc: 0.8961038961038961
Fold [4/5] Epoch [0/100] Initial Loss: 0.1354, Training Loss: 0.1354, Initial Validation Loss: 0.1350, Validation Loss: 0.1350,V Acc: 0.3364, Top 70th Acc: 0.4156, Bottom 30th Acc: 0.1515
Fold [4/5] Epoch [10/100] Initial Loss: 0.1354, Training Loss: 0.0398, Initial Validation Loss: 0.1350, Validation Loss: 0.0446,V Acc: 0.8182, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.6061
Fold [4/5] Epoch [20/100] Initial Loss: 0.1354, Training Loss: 0.0246, Initial Validation Loss: 0.1350, Validation Loss: 0.0293,V Acc: 0.9091, Top 70th Acc: 0.9870, Bottom 30th Acc: 0.7273
Stopping early at Epoch (base 0): 28  Rolling back to Epoch (base 0): 23  Top Validation Acc: 0.974025974025974
Fold [5/5] Epoch [0/100] Initial Loss: 0.1384, Training Loss: 0.1384, Initial Validation Loss: 0.1281, Validation Loss: 0.1281,V Acc: 0.3704, Top 70th Acc: 0.4737, Bottom 30th Acc: 0.1250
Fold [5/5] Epoch [10/100] Initial Loss: 0.1384, Training Loss: 0.0352, Initial Validation Loss: 0.1281, Validation Loss: 0.0359,V Acc: 0.7870, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.4062
Fold [5/5] Epoch [20/100] Initial Loss: 0.1384, Training Loss: 0.0242, Initial Validation Loss: 0.1281, Validation Loss: 0.0321,V Acc: 0.8056, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.4375
Stopping early at Epoch (base 0): 20  Rolling back to Epoch (base 0): 15  Top Validation Acc: 0.9605263157894737
91 4 [array([0.29433233, 0.09992095, 0.2463737 , 0.20590584, 0.15346713],
      dtype=float32)]
Running train_nn.py with seed 92
CUDA:False
Training samples count:  550
Training on 20 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1369, Training Loss: 0.1369, Initial Validation Loss: 0.1287, Validation Loss: 0.1287,V Acc: 0.2613, Top 70th Acc: 0.3590, Bottom 30th Acc: 0.0303
Fold [1/5] Epoch [10/100] Initial Loss: 0.1369, Training Loss: 0.0433, Initial Validation Loss: 0.1287, Validation Loss: 0.0428,V Acc: 0.7838, Top 70th Acc: 0.8846, Bottom 30th Acc: 0.5455
Fold [1/5] Epoch [20/100] Initial Loss: 0.1369, Training Loss: 0.0234, Initial Validation Loss: 0.1287, Validation Loss: 0.0341,V Acc: 0.7928, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.4545
Stopping early at Epoch (base 0): 22  Rolling back to Epoch (base 0): 17  Top Validation Acc: 0.9102564102564102
92 0 [array([0.35097378, 0.10335989, 0.10562976, 0.29585925, 0.14417736],
      dtype=float32)]
Fold [2/5] Epoch [0/100] Initial Loss: 0.1386, Training Loss: 0.1386, Initial Validation Loss: 0.1321, Validation Loss: 0.1321,V Acc: 0.4685, Top 70th Acc: 0.5897, Bottom 30th Acc: 0.1818
Fold [2/5] Epoch [10/100] Initial Loss: 0.1386, Training Loss: 0.0317, Initial Validation Loss: 0.1321, Validation Loss: 0.0386,V Acc: 0.8198, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.5152
Fold [2/5] Epoch [20/100] Initial Loss: 0.1386, Training Loss: 0.0216, Initial Validation Loss: 0.1321, Validation Loss: 0.0346,V Acc: 0.8378, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 28  Rolling back to Epoch (base 0): 23  Top Validation Acc: 0.9230769230769231
Fold [3/5] Epoch [0/100] Initial Loss: 0.1397, Training Loss: 0.1397, Initial Validation Loss: 0.1332, Validation Loss: 0.1332,V Acc: 0.2818, Top 70th Acc: 0.3377, Bottom 30th Acc: 0.1515
Fold [3/5] Epoch [10/100] Initial Loss: 0.1397, Training Loss: 0.0408, Initial Validation Loss: 0.1332, Validation Loss: 0.0438,V Acc: 0.7909, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.5152
Fold [3/5] Epoch [20/100] Initial Loss: 0.1397, Training Loss: 0.0264, Initial Validation Loss: 0.1332, Validation Loss: 0.0331,V Acc: 0.8455, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6061
Fold [3/5] Epoch [30/100] Initial Loss: 0.1397, Training Loss: 0.0218, Initial Validation Loss: 0.1332, Validation Loss: 0.0296,V Acc: 0.8727, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.7273
Stopping early at Epoch (base 0): 35  Rolling back to Epoch (base 0): 30  Top Validation Acc: 0.935064935064935
Fold [4/5] Epoch [0/100] Initial Loss: 0.1410, Training Loss: 0.1410, Initial Validation Loss: 0.1341, Validation Loss: 0.1341,V Acc: 0.2818, Top 70th Acc: 0.3506, Bottom 30th Acc: 0.1212
Fold [4/5] Epoch [10/100] Initial Loss: 0.1410, Training Loss: 0.0323, Initial Validation Loss: 0.1341, Validation Loss: 0.0343,V Acc: 0.8455, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.6364
Fold [4/5] Epoch [20/100] Initial Loss: 0.1410, Training Loss: 0.0227, Initial Validation Loss: 0.1341, Validation Loss: 0.0286,V Acc: 0.8727, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.7273
Stopping early at Epoch (base 0): 21  Rolling back to Epoch (base 0): 16  Top Validation Acc: 0.948051948051948
Fold [5/5] Epoch [0/100] Initial Loss: 0.1372, Training Loss: 0.1372, Initial Validation Loss: 0.1347, Validation Loss: 0.1347,V Acc: 0.2963, Top 70th Acc: 0.3684, Bottom 30th Acc: 0.1250
Fold [5/5] Epoch [10/100] Initial Loss: 0.1372, Training Loss: 0.0275, Initial Validation Loss: 0.1347, Validation Loss: 0.0401,V Acc: 0.8148, Top 70th Acc: 0.9079, Bottom 30th Acc: 0.5938
Stopping early at Epoch (base 0): 19  Rolling back to Epoch (base 0): 14  Top Validation Acc: 0.9078947368421053
Running train_nn.py with seed 93
CUDA:False
Training samples count:  550
Training on 20 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1413, Training Loss: 0.1413, Initial Validation Loss: 0.1310, Validation Loss: 0.1310,V Acc: 0.3694, Top 70th Acc: 0.3846, Bottom 30th Acc: 0.3333
Fold [1/5] Epoch [10/100] Initial Loss: 0.1413, Training Loss: 0.0407, Initial Validation Loss: 0.1310, Validation Loss: 0.0494,V Acc: 0.7748, Top 70th Acc: 0.8205, Bottom 30th Acc: 0.6667
Fold [1/5] Epoch [20/100] Initial Loss: 0.1413, Training Loss: 0.0232, Initial Validation Loss: 0.1310, Validation Loss: 0.0427,V Acc: 0.7658, Top 70th Acc: 0.8590, Bottom 30th Acc: 0.5455
Fold [2/5] Epoch [20/100] Initial Loss: 0.1382, Training Loss: 0.0143, Initial Validation Loss: 0.1361, Validation Loss: 0.0289,V Acc: 0.8649, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.7273
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.9230769230769231
Fold [3/5] Epoch [0/100] Initial Loss: 0.1388, Training Loss: 0.1388, Initial Validation Loss: 0.1336, Validation Loss: 0.1336,V Acc: 0.3273, Top 70th Acc: 0.3636, Bottom 30th Acc: 0.2424
Fold [3/5] Epoch [10/100] Initial Loss: 0.1388, Training Loss: 0.0279, Initial Validation Loss: 0.1336, Validation Loss: 0.0372,V Acc: 0.8273, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.6061
Fold [3/5] Epoch [20/100] Initial Loss: 0.1388, Training Loss: 0.0160, Initial Validation Loss: 0.1336, Validation Loss: 0.0300,V Acc: 0.8727, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6970
Fold [3/5] Epoch [30/100] Initial Loss: 0.1388, Training Loss: 0.0122, Initial Validation Loss: 0.1336, Validation Loss: 0.0263,V Acc: 0.8545, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 35  Rolling back to Epoch (base 0): 30  Top Validation Acc: 0.948051948051948
88 2 [array([0.76360494, 0.10581724, 0.02993006, 0.03260378, 0.06804395],
      dtype=float32)]
Fold [4/5] Epoch [0/100] Initial Loss: 0.1383, Training Loss: 0.1383, Initial Validation Loss: 0.1323, Validation Loss: 0.1323,V Acc: 0.3182, Top 70th Acc: 0.4156, Bottom 30th Acc: 0.0909
Fold [4/5] Epoch [10/100] Initial Loss: 0.1383, Training Loss: 0.0322, Initial Validation Loss: 0.1323, Validation Loss: 0.0417,V Acc: 0.8000, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.5455
Fold [4/5] Epoch [20/100] Initial Loss: 0.1383, Training Loss: 0.0156, Initial Validation Loss: 0.1323, Validation Loss: 0.0299,V Acc: 0.8364, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.5455
Fold [4/5] Epoch [30/100] Initial Loss: 0.1383, Training Loss: 0.0122, Initial Validation Loss: 0.1323, Validation Loss: 0.0281,V Acc: 0.8455, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 33  Rolling back to Epoch (base 0): 28  Top Validation Acc: 0.961038961038961
Fold [5/5] Epoch [0/100] Initial Loss: 0.1389, Training Loss: 0.1389, Initial Validation Loss: 0.1344, Validation Loss: 0.1344,V Acc: 0.2315, Top 70th Acc: 0.3158, Bottom 30th Acc: 0.0312
Fold [5/5] Epoch [10/100] Initial Loss: 0.1389, Training Loss: 0.0339, Initial Validation Loss: 0.1344, Validation Loss: 0.0444,V Acc: 0.8148, Top 70th Acc: 0.8684, Bottom 30th Acc: 0.6875
Fold [5/5] Epoch [20/100] Initial Loss: 0.1389, Training Loss: 0.0141, Initial Validation Loss: 0.1344, Validation Loss: 0.0334,V Acc: 0.8056, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.5000
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.9210526315789473
Running train_nn.py with seed 89
CUDA:False
Training samples count:  550
Training on 40 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1358, Training Loss: 0.1358, Initial Validation Loss: 0.1315, Validation Loss: 0.1315,V Acc: 0.3784, Top 70th Acc: 0.4359, Bottom 30th Acc: 0.2424
Fold [1/5] Epoch [10/100] Initial Loss: 0.1358, Training Loss: 0.0318, Initial Validation Loss: 0.1315, Validation Loss: 0.0446,V Acc: 0.7748, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.4545
Fold [1/5] Epoch [20/100] Initial Loss: 0.1358, Training Loss: 0.0163, Initial Validation Loss: 0.1315, Validation Loss: 0.0359,V Acc: 0.8198, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.5455
Fold [1/5] Epoch [30/100] Initial Loss: 0.1358, Training Loss: 0.0113, Initial Validation Loss: 0.1315, Validation Loss: 0.0333,V Acc: 0.8198, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 31  Rolling back to Epoch (base 0): 26  Top Validation Acc: 0.9358974358974359
Fold [2/5] Epoch [0/100] Initial Loss: 0.1397, Training Loss: 0.1397, Initial Validation Loss: 0.1372, Validation Loss: 0.1372,V Acc: 0.2523, Top 70th Acc: 0.2949, Bottom 30th Acc: 0.1515
Fold [2/5] Epoch [10/100] Initial Loss: 0.1397, Training Loss: 0.0341, Initial Validation Loss: 0.1372, Validation Loss: 0.0381,V Acc: 0.8018, Top 70th Acc: 0.8974, Bottom 30th Acc: 0.5758
Fold [2/5] Epoch [20/100] Initial Loss: 0.1397, Training Loss: 0.0136, Initial Validation Loss: 0.1372, Validation Loss: 0.0305,V Acc: 0.8468, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.9487179487179487
Fold [3/5] Epoch [0/100] Initial Loss: 0.1399, Training Loss: 0.1399, Initial Validation Loss: 0.1341, Validation Loss: 0.1341,V Acc: 0.2727, Top 70th Acc: 0.3247, Bottom 30th Acc: 0.1515
Fold [3/5] Epoch [10/100] Initial Loss: 0.1399, Training Loss: 0.0298, Initial Validation Loss: 0.1341, Validation Loss: 0.0293,V Acc: 0.8545, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6364
Fold [3/5] Epoch [20/100] Initial Loss: 0.1399, Training Loss: 0.0145, Initial Validation Loss: 0.1341, Validation Loss: 0.0231,V Acc: 0.8636, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 21  Rolling back to Epoch (base 0): 16  Top Validation Acc: 0.961038961038961
89 2 [array([0.4198762 , 0.0695215 , 0.12854177, 0.07883836, 0.30322218],
      dtype=float32)]
Fold [4/5] Epoch [0/100] Initial Loss: 0.1397, Training Loss: 0.1397, Initial Validation Loss: 0.1333, Validation Loss: 0.1333,V Acc: 0.3091, Top 70th Acc: 0.3896, Bottom 30th Acc: 0.1212
Fold [4/5] Epoch [10/100] Initial Loss: 0.1397, Training Loss: 0.0332, Initial Validation Loss: 0.1333, Validation Loss: 0.0450,V Acc: 0.7909, Top 70th Acc: 0.8831, Bottom 30th Acc: 0.5758
Fold [4/5] Epoch [20/100] Initial Loss: 0.1397, Training Loss: 0.0138, Initial Validation Loss: 0.1333, Validation Loss: 0.0343,V Acc: 0.8455, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.6667
Fold [4/5] Epoch [30/100] Initial Loss: 0.1397, Training Loss: 0.0110, Initial Validation Loss: 0.1333, Validation Loss: 0.0340,V Acc: 0.8455, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 33  Rolling back to Epoch (base 0): 28  Top Validation Acc: 0.935064935064935
Fold [5/5] Epoch [0/100] Initial Loss: 0.1390, Training Loss: 0.1390, Initial Validation Loss: 0.1342, Validation Loss: 0.1342,V Acc: 0.2870, Top 70th Acc: 0.3553, Bottom 30th Acc: 0.1250
Fold [5/5] Epoch [10/100] Initial Loss: 0.1390, Training Loss: 0.0237, Initial Validation Loss: 0.1342, Validation Loss: 0.0297,V Acc: 0.8611, Top 70th Acc: 0.9737, Bottom 30th Acc: 0.5938
Fold [5/5] Epoch [20/100] Initial Loss: 0.1390, Training Loss: 0.0144, Initial Validation Loss: 0.1342, Validation Loss: 0.0222,V Acc: 0.9074, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.7812
Fold [5/5] Epoch [30/100] Initial Loss: 0.1390, Training Loss: 0.0123, Initial Validation Loss: 0.1342, Validation Loss: 0.0209,V Acc: 0.9074, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.7812
Stopping early at Epoch (base 0): 38  Rolling back to Epoch (base 0): 33  Top Validation Acc: 0.9473684210526315
Running train_nn.py with seed 90
CUDA:False
Training samples count:  550
Training on 40 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1360, Training Loss: 0.1360, Initial Validation Loss: 0.1337, Validation Loss: 0.1337,V Acc: 0.2793, Top 70th Acc: 0.3462, Bottom 30th Acc: 0.1212
Fold [1/5] Epoch [10/100] Initial Loss: 0.1360, Training Loss: 0.0402, Initial Validation Loss: 0.1337, Validation Loss: 0.0534,V Acc: 0.7658, Top 70th Acc: 0.8718, Bottom 30th Acc: 0.5152
Fold [1/5] Epoch [20/100] Initial Loss: 0.1360, Training Loss: 0.0159, Initial Validation Loss: 0.1337, Validation Loss: 0.0324,V Acc: 0.8559, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 29  Rolling back to Epoch (base 0): 24  Top Validation Acc: 0.9230769230769231
Fold [2/5] Epoch [0/100] Initial Loss: 0.1385, Training Loss: 0.1385, Initial Validation Loss: 0.1358, Validation Loss: 0.1358,V Acc: 0.3243, Top 70th Acc: 0.3590, Bottom 30th Acc: 0.2424
Fold [2/5] Epoch [10/100] Initial Loss: 0.1385, Training Loss: 0.0341, Initial Validation Loss: 0.1358, Validation Loss: 0.0458,V Acc: 0.8198, Top 70th Acc: 0.8846, Bottom 30th Acc: 0.6667
Fold [2/5] Epoch [20/100] Initial Loss: 0.1385, Training Loss: 0.0147, Initial Validation Loss: 0.1358, Validation Loss: 0.0373,V Acc: 0.8468, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.6667
Fold [3/5] Epoch [0/100] Initial Loss: 0.1401, Training Loss: 0.1401, Initial Validation Loss: 0.1371, Validation Loss: 0.1371,V Acc: 0.2636, Top 70th Acc: 0.3506, Bottom 30th Acc: 0.0606
Fold [3/5] Epoch [10/100] Initial Loss: 0.1401, Training Loss: 0.0818, Initial Validation Loss: 0.1371, Validation Loss: 0.0793,V Acc: 0.6636, Top 70th Acc: 0.7532, Bottom 30th Acc: 0.4545
Fold [3/5] Epoch [20/100] Initial Loss: 0.1401, Training Loss: 0.0796, Initial Validation Loss: 0.1371, Validation Loss: 0.0762,V Acc: 0.6636, Top 70th Acc: 0.7532, Bottom 30th Acc: 0.4545
Fold [3/5] Epoch [30/100] Initial Loss: 0.1401, Training Loss: 0.0789, Initial Validation Loss: 0.1371, Validation Loss: 0.0751,V Acc: 0.6818, Top 70th Acc: 0.7532, Bottom 30th Acc: 0.5152
Fold [3/5] Epoch [40/100] Initial Loss: 0.1401, Training Loss: 0.0781, Initial Validation Loss: 0.1371, Validation Loss: 0.0749,V Acc: 0.6818, Top 70th Acc: 0.7662, Bottom 30th Acc: 0.4848
Stopping early at Epoch (base 0): 46  Rolling back to Epoch (base 0): 41  Top Validation Acc: 0.7532467532467533
Fold [4/5] Epoch [0/100] Initial Loss: 0.1298, Training Loss: 0.1298, Initial Validation Loss: 0.1173, Validation Loss: 0.1173,V Acc: 0.4000, Top 70th Acc: 0.5195, Bottom 30th Acc: 0.1212
Fold [4/5] Epoch [10/100] Initial Loss: 0.1298, Training Loss: 0.0791, Initial Validation Loss: 0.1173, Validation Loss: 0.0829,V Acc: 0.6091, Top 70th Acc: 0.7403, Bottom 30th Acc: 0.3030
Fold [4/5] Epoch [20/100] Initial Loss: 0.1298, Training Loss: 0.0775, Initial Validation Loss: 0.1173, Validation Loss: 0.0818,V Acc: 0.6091, Top 70th Acc: 0.7273, Bottom 30th Acc: 0.3333
Fold [4/5] Epoch [30/100] Initial Loss: 0.1298, Training Loss: 0.0770, Initial Validation Loss: 0.1173, Validation Loss: 0.0814,V Acc: 0.6455, Top 70th Acc: 0.7403, Bottom 30th Acc: 0.4242
Fold [4/5] Epoch [40/100] Initial Loss: 0.1298, Training Loss: 0.0765, Initial Validation Loss: 0.1173, Validation Loss: 0.0808,V Acc: 0.6273, Top 70th Acc: 0.7532, Bottom 30th Acc: 0.3333
Stopping early at Epoch (base 0): 42  Rolling back to Epoch (base 0): 37  Top Validation Acc: 0.7532467532467533
Fold [5/5] Epoch [0/100] Initial Loss: 0.1376, Training Loss: 0.1376, Initial Validation Loss: 0.1187, Validation Loss: 0.1187,V Acc: 0.3889, Top 70th Acc: 0.5395, Bottom 30th Acc: 0.0312
Fold [5/5] Epoch [10/100] Initial Loss: 0.1376, Training Loss: 0.0795, Initial Validation Loss: 0.1187, Validation Loss: 0.0828,V Acc: 0.5833, Top 70th Acc: 0.6842, Bottom 30th Acc: 0.3438
Fold [5/5] Epoch [20/100] Initial Loss: 0.1376, Training Loss: 0.0779, Initial Validation Loss: 0.1187, Validation Loss: 0.0813,V Acc: 0.5833, Top 70th Acc: 0.7105, Bottom 30th Acc: 0.2812
Stopping early at Epoch (base 0): 28  Rolling back to Epoch (base 0): 23  Top Validation Acc: 0.6973684210526315
Running train_nn.py with seed 86
CUDA:False
Training samples count:  550
Training on 2 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1461, Training Loss: 0.1461, Initial Validation Loss: 0.1345, Validation Loss: 0.1345,V Acc: 0.3153, Top 70th Acc: 0.4359, Bottom 30th Acc: 0.0303
Fold [1/5] Epoch [10/100] Initial Loss: 0.1461, Training Loss: 0.0811, Initial Validation Loss: 0.1345, Validation Loss: 0.0791,V Acc: 0.6396, Top 70th Acc: 0.7308, Bottom 30th Acc: 0.4242
Stopping early at Epoch (base 0): 18  Rolling back to Epoch (base 0): 13  Top Validation Acc: 0.717948717948718
Fold [2/5] Epoch [0/100] Initial Loss: 0.1377, Training Loss: 0.1377, Initial Validation Loss: 0.1263, Validation Loss: 0.1263,V Acc: 0.3153, Top 70th Acc: 0.3590, Bottom 30th Acc: 0.2121
Fold [2/5] Epoch [10/100] Initial Loss: 0.1377, Training Loss: 0.0826, Initial Validation Loss: 0.1263, Validation Loss: 0.0754,V Acc: 0.6757, Top 70th Acc: 0.7436, Bottom 30th Acc: 0.5152
Fold [2/5] Epoch [20/100] Initial Loss: 0.1377, Training Loss: 0.0795, Initial Validation Loss: 0.1263, Validation Loss: 0.0732,V Acc: 0.6486, Top 70th Acc: 0.7564, Bottom 30th Acc: 0.3939
Fold [2/5] Epoch [30/100] Initial Loss: 0.1377, Training Loss: 0.0786, Initial Validation Loss: 0.1263, Validation Loss: 0.0711,V Acc: 0.6577, Top 70th Acc: 0.7821, Bottom 30th Acc: 0.3636
Stopping early at Epoch (base 0): 34  Rolling back to Epoch (base 0): 29  Top Validation Acc: 0.782051282051282
Fold [3/5] Epoch [0/100] Initial Loss: 0.1358, Training Loss: 0.1358, Initial Validation Loss: 0.1285, Validation Loss: 0.1285,V Acc: 0.3909, Top 70th Acc: 0.4805, Bottom 30th Acc: 0.1818
Fold [3/5] Epoch [10/100] Initial Loss: 0.1358, Training Loss: 0.0810, Initial Validation Loss: 0.1285, Validation Loss: 0.0832,V Acc: 0.5818, Top 70th Acc: 0.7143, Bottom 30th Acc: 0.2727
Fold [3/5] Epoch [20/100] Initial Loss: 0.1358, Training Loss: 0.0786, Initial Validation Loss: 0.1285, Validation Loss: 0.0807,V Acc: 0.5727, Top 70th Acc: 0.7143, Bottom 30th Acc: 0.2424
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.7272727272727273
Fold [4/5] Epoch [0/100] Initial Loss: 0.1398, Training Loss: 0.1398, Initial Validation Loss: 0.1302, Validation Loss: 0.1302,V Acc: 0.4727, Top 70th Acc: 0.5065, Bottom 30th Acc: 0.3939
Fold [4/5] Epoch [10/100] Initial Loss: 0.1398, Training Loss: 0.0799, Initial Validation Loss: 0.1302, Validation Loss: 0.0835,V Acc: 0.6000, Top 70th Acc: 0.7532, Bottom 30th Acc: 0.2424
Fold [4/5] Epoch [20/100] Initial Loss: 0.1398, Training Loss: 0.0784, Initial Validation Loss: 0.1302, Validation Loss: 0.0817,V Acc: 0.6091, Top 70th Acc: 0.7532, Bottom 30th Acc: 0.2727
Fold [4/5] Epoch [30/100] Initial Loss: 0.1398, Training Loss: 0.0780, Initial Validation Loss: 0.1302, Validation Loss: 0.0815,V Acc: 0.6091, Top 70th Acc: 0.7403, Bottom 30th Acc: 0.3030
Fold [4/5] Epoch [40/100] Initial Loss: 0.1398, Training Loss: 0.0773, Initial Validation Loss: 0.1302, Validation Loss: 0.0811,V Acc: 0.6091, Top 70th Acc: 0.7532, Bottom 30th Acc: 0.2727
Fold [4/5] Epoch [50/100] Initial Loss: 0.1398, Training Loss: 0.0765, Initial Validation Loss: 0.1302, Validation Loss: 0.0812,V Acc: 0.6091, Top 70th Acc: 0.7273, Bottom 30th Acc: 0.3333
Stopping early at Epoch (base 0): 52  Rolling back to Epoch (base 0): 47  Top Validation Acc: 0.7402597402597403
Fold [5/5] Epoch [0/100] Initial Loss: 0.1322, Training Loss: 0.1322, Initial Validation Loss: 0.1172, Validation Loss: 0.1172,V Acc: 0.5278, Top 70th Acc: 0.5789, Bottom 30th Acc: 0.4062
Fold [5/5] Epoch [10/100] Initial Loss: 0.1322, Training Loss: 0.0813, Initial Validation Loss: 0.1172, Validation Loss: 0.0845,V Acc: 0.5833, Top 70th Acc: 0.6842, Bottom 30th Acc: 0.3438
Fold [5/5] Epoch [20/100] Initial Loss: 0.1322, Training Loss: 0.0783, Initial Validation Loss: 0.1172, Validation Loss: 0.0826,V Acc: 0.6204, Top 70th Acc: 0.7368, Bottom 30th Acc: 0.3438
Fold [5/5] Epoch [30/100] Initial Loss: 0.1322, Training Loss: 0.0774, Initial Validation Loss: 0.1172, Validation Loss: 0.0815,V Acc: 0.6296, Top 70th Acc: 0.7237, Bottom 30th Acc: 0.4062
Fold [5/5] Epoch [40/100] Initial Loss: 0.1322, Training Loss: 0.0767, Initial Validation Loss: 0.1172, Validation Loss: 0.0817,V Acc: 0.6389, Top 70th Acc: 0.7368, Bottom 30th Acc: 0.4062
Stopping early at Epoch (base 0): 43  Rolling back to Epoch (base 0): 38  Top Validation Acc: 0.7368421052631579
86 4 [array([0.13702229, 0.3474756 , 0.14060777, 0.23968826, 0.13520607],
      dtype=float32)]
Running train_nn.py with seed 87
CUDA:False
Training samples count:  550
Training on 2 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1354, Training Loss: 0.1354, Initial Validation Loss: 0.1336, Validation Loss: 0.1336,V Acc: 0.3243, Top 70th Acc: 0.3846, Bottom 30th Acc: 0.1818
Fold [1/5] Epoch [10/100] Initial Loss: 0.1354, Training Loss: 0.0819, Initial Validation Loss: 0.1336, Validation Loss: 0.0786,V Acc: 0.6577, Top 70th Acc: 0.7436, Bottom 30th Acc: 0.4545
Fold [1/5] Epoch [20/100] Initial Loss: 0.1354, Training Loss: 0.0794, Initial Validation Loss: 0.1336, Validation Loss: 0.0773,V Acc: 0.6486, Top 70th Acc: 0.7564, Bottom 30th Acc: 0.3939
Stopping early at Epoch (base 0): 29  Rolling back to Epoch (base 0): 24  Top Validation Acc: 0.7564102564102564
Fold [2/5] Epoch [0/100] Initial Loss: 0.1396, Training Loss: 0.1396, Initial Validation Loss: 0.1272, Validation Loss: 0.1272,V Acc: 0.3153, Top 70th Acc: 0.3590, Bottom 30th Acc: 0.2121
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.9473684210526315
68 4 [array([0.22447474, 0.03260604, 0.07589345, 0.30620274, 0.36082304],
      dtype=float32)]
Running train_nn.py with seed 69
CUDA:False
Training samples count:  550
Training on 163 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1387, Training Loss: 0.1387, Initial Validation Loss: 0.1309, Validation Loss: 0.1309,V Acc: 0.4595, Top 70th Acc: 0.5385, Bottom 30th Acc: 0.2727
Fold [1/5] Epoch [10/100] Initial Loss: 0.1387, Training Loss: 0.0116, Initial Validation Loss: 0.1309, Validation Loss: 0.0376,V Acc: 0.8108, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.5152
Fold [1/5] Epoch [20/100] Initial Loss: 0.1387, Training Loss: 0.0049, Initial Validation Loss: 0.1309, Validation Loss: 0.0343,V Acc: 0.8198, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.5455
Fold [1/5] Epoch [30/100] Initial Loss: 0.1387, Training Loss: 0.0039, Initial Validation Loss: 0.1309, Validation Loss: 0.0324,V Acc: 0.8468, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 39  Rolling back to Epoch (base 0): 34  Top Validation Acc: 0.9487179487179487
69 0 [array([0.21626753, 0.07124434, 0.02878434, 0.12996103, 0.55374277],
      dtype=float32)]
Fold [2/5] Epoch [0/100] Initial Loss: 0.1382, Training Loss: 0.1382, Initial Validation Loss: 0.1375, Validation Loss: 0.1375,V Acc: 0.3153, Top 70th Acc: 0.3590, Bottom 30th Acc: 0.2121
Fold [2/5] Epoch [10/100] Initial Loss: 0.1382, Training Loss: 0.0240, Initial Validation Loss: 0.1375, Validation Loss: 0.0355,V Acc: 0.8649, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.6970
Fold [2/5] Epoch [20/100] Initial Loss: 0.1382, Training Loss: 0.0054, Initial Validation Loss: 0.1375, Validation Loss: 0.0272,V Acc: 0.8829, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 20  Rolling back to Epoch (base 0): 15  Top Validation Acc: 0.9743589743589743
Fold [3/5] Epoch [0/100] Initial Loss: 0.1381, Training Loss: 0.1381, Initial Validation Loss: 0.1330, Validation Loss: 0.1330,V Acc: 0.3636, Top 70th Acc: 0.3896, Bottom 30th Acc: 0.3030
Fold [3/5] Epoch [10/100] Initial Loss: 0.1381, Training Loss: 0.0210, Initial Validation Loss: 0.1330, Validation Loss: 0.0403,V Acc: 0.8091, Top 70th Acc: 0.8961, Bottom 30th Acc: 0.6061
Fold [3/5] Epoch [20/100] Initial Loss: 0.1381, Training Loss: 0.0048, Initial Validation Loss: 0.1330, Validation Loss: 0.0286,V Acc: 0.8636, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.7273
Fold [3/5] Epoch [30/100] Initial Loss: 0.1381, Training Loss: 0.0038, Initial Validation Loss: 0.1330, Validation Loss: 0.0280,V Acc: 0.8818, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.7879
Stopping early at Epoch (base 0): 30  Rolling back to Epoch (base 0): 25  Top Validation Acc: 0.922077922077922
Fold [4/5] Epoch [0/100] Initial Loss: 0.1393, Training Loss: 0.1393, Initial Validation Loss: 0.1366, Validation Loss: 0.1366,V Acc: 0.2545, Top 70th Acc: 0.3377, Bottom 30th Acc: 0.0606
Fold [4/5] Epoch [10/100] Initial Loss: 0.1393, Training Loss: 0.0191, Initial Validation Loss: 0.1366, Validation Loss: 0.0374,V Acc: 0.8091, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.4848
Fold [4/5] Epoch [20/100] Initial Loss: 0.1393, Training Loss: 0.0062, Initial Validation Loss: 0.1366, Validation Loss: 0.0269,V Acc: 0.8727, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.6667
Fold [4/5] Epoch [30/100] Initial Loss: 0.1393, Training Loss: 0.0044, Initial Validation Loss: 0.1366, Validation Loss: 0.0255,V Acc: 0.8636, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.6061
Fold [4/5] Epoch [40/100] Initial Loss: 0.1393, Training Loss: 0.0039, Initial Validation Loss: 0.1366, Validation Loss: 0.0253,V Acc: 0.8818, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 40  Rolling back to Epoch (base 0): 35  Top Validation Acc: 0.974025974025974
Fold [5/5] Epoch [0/100] Initial Loss: 0.1383, Training Loss: 0.1383, Initial Validation Loss: 0.1304, Validation Loss: 0.1304,V Acc: 0.2593, Top 70th Acc: 0.3289, Bottom 30th Acc: 0.0938
Fold [5/5] Epoch [10/100] Initial Loss: 0.1383, Training Loss: 0.0144, Initial Validation Loss: 0.1304, Validation Loss: 0.0311,V Acc: 0.8148, Top 70th Acc: 0.9737, Bottom 30th Acc: 0.4375
Fold [5/5] Epoch [20/100] Initial Loss: 0.1383, Training Loss: 0.0049, Initial Validation Loss: 0.1304, Validation Loss: 0.0267,V Acc: 0.8519, Top 70th Acc: 0.9868, Bottom 30th Acc: 0.5312
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.9868421052631579
Running train_nn.py with seed 70
CUDA:False
Training samples count:  550
Training on 163 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1436, Training Loss: 0.1436, Initial Validation Loss: 0.1376, Validation Loss: 0.1376,V Acc: 0.2613, Top 70th Acc: 0.3333, Bottom 30th Acc: 0.0909
Fold [1/5] Epoch [10/100] Initial Loss: 0.1436, Training Loss: 0.0260, Initial Validation Loss: 0.1376, Validation Loss: 0.0415,V Acc: 0.8378, Top 70th Acc: 0.8846, Bottom 30th Acc: 0.7273
Fold [1/5] Epoch [20/100] Initial Loss: 0.1436, Training Loss: 0.0059, Initial Validation Loss: 0.1376, Validation Loss: 0.0310,V Acc: 0.8198, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.5152
Fold [1/5] Epoch [30/100] Initial Loss: 0.1436, Training Loss: 0.0041, Initial Validation Loss: 0.1376, Validation Loss: 0.0301,V Acc: 0.8559, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.6061
Fold [1/5] Epoch [40/100] Initial Loss: 0.1436, Training Loss: 0.0037, Initial Validation Loss: 0.1376, Validation Loss: 0.0291,V Acc: 0.8468, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 46  Rolling back to Epoch (base 0): 41  Top Validation Acc: 0.9615384615384616
Fold [2/5] Epoch [0/100] Initial Loss: 0.1425, Training Loss: 0.1425, Initial Validation Loss: 0.1364, Validation Loss: 0.1364,V Acc: 0.2523, Top 70th Acc: 0.3205, Bottom 30th Acc: 0.0909
Fold [2/5] Epoch [10/100] Initial Loss: 0.1425, Training Loss: 0.0216, Initial Validation Loss: 0.1364, Validation Loss: 0.0375,V Acc: 0.8378, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.6364
Fold [2/5] Epoch [20/100] Initial Loss: 0.1425, Training Loss: 0.0051, Initial Validation Loss: 0.1364, Validation Loss: 0.0263,V Acc: 0.8829, Top 70th Acc: 0.9872, Bottom 30th Acc: 0.6364
Fold [2/5] Epoch [30/100] Initial Loss: 0.1425, Training Loss: 0.0040, Initial Validation Loss: 0.1364, Validation Loss: 0.0250,V Acc: 0.9009, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.7273
Stopping early at Epoch (base 0): 35  Rolling back to Epoch (base 0): 30  Top Validation Acc: 0.9743589743589743
70 1 [array([0.14129184, 0.13599652, 0.10478626, 0.32801002, 0.28991535],
      dtype=float32)]
Fold [3/5] Epoch [0/100] Initial Loss: 0.1385, Training Loss: 0.1385, Initial Validation Loss: 0.1363, Validation Loss: 0.1363,V Acc: 0.3000, Top 70th Acc: 0.3117, Bottom 30th Acc: 0.2727
Fold [3/5] Epoch [10/100] Initial Loss: 0.1385, Training Loss: 0.0202, Initial Validation Loss: 0.1363, Validation Loss: 0.0343,V Acc: 0.8545, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.6667
Fold [3/5] Epoch [20/100] Initial Loss: 0.1385, Training Loss: 0.0051, Initial Validation Loss: 0.1363, Validation Loss: 0.0274,V Acc: 0.8727, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 22  Rolling back to Epoch (base 0): 17  Top Validation Acc: 0.961038961038961
Fold [4/5] Epoch [0/100] Initial Loss: 0.1382, Training Loss: 0.1382, Initial Validation Loss: 0.1392, Validation Loss: 0.1392,V Acc: 0.2636, Top 70th Acc: 0.3506, Bottom 30th Acc: 0.0606
Fold [4/5] Epoch [10/100] Initial Loss: 0.1382, Training Loss: 0.0153, Initial Validation Loss: 0.1392, Validation Loss: 0.0301,V Acc: 0.8727, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.6364
Fold [4/5] Epoch [20/100] Initial Loss: 0.1382, Training Loss: 0.0045, Initial Validation Loss: 0.1392, Validation Loss: 0.0254,V Acc: 0.8909, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.6970
Fold [4/5] Epoch [30/100] Initial Loss: 0.1382, Training Loss: 0.0037, Initial Validation Loss: 0.1392, Validation Loss: 0.0250,V Acc: 0.8909, Top 70th Acc: 0.9870, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 37  Rolling back to Epoch (base 0): 32  Top Validation Acc:
Fold [3/5] Epoch [20/100] Initial Loss: 0.1385, Training Loss: 0.0188, Initial Validation Loss: 0.1321, Validation Loss: 0.0326,V Acc: 0.8182, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 22  Rolling back to Epoch (base 0): 17  Top Validation Acc: 0.935064935064935
Fold [4/5] Epoch [0/100] Initial Loss: 0.1394, Training Loss: 0.1394, Initial Validation Loss: 0.1356, Validation Loss: 0.1356,V Acc: 0.3364, Top 70th Acc: 0.3636, Bottom 30th Acc: 0.2727
Fold [4/5] Epoch [10/100] Initial Loss: 0.1394, Training Loss: 0.0264, Initial Validation Loss: 0.1356, Validation Loss: 0.0347,V Acc: 0.8364, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.6061
Fold [4/5] Epoch [20/100] Initial Loss: 0.1394, Training Loss: 0.0191, Initial Validation Loss: 0.1356, Validation Loss: 0.0346,V Acc: 0.8455, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 20  Rolling back to Epoch (base 0): 15  Top Validation Acc: 0.948051948051948
90 3 [array([0.66440946, 0.14309514, 0.06083299, 0.06563458, 0.06602786],
      dtype=float32)]
Fold [5/5] Epoch [0/100] Initial Loss: 0.1380, Training Loss: 0.1380, Initial Validation Loss: 0.1280, Validation Loss: 0.1280,V Acc: 0.3611, Top 70th Acc: 0.4342, Bottom 30th Acc: 0.1875
Fold [5/5] Epoch [10/100] Initial Loss: 0.1380, Training Loss: 0.0305, Initial Validation Loss: 0.1280, Validation Loss: 0.0352,V Acc: 0.8611, Top 70th Acc: 0.9211, Bottom 30th Acc: 0.7188
Fold [5/5] Epoch [20/100] Initial Loss: 0.1380, Training Loss: 0.0184, Initial Validation Loss: 0.1280, Validation Loss: 0.0315,V Acc: 0.8519, Top 70th Acc: 0.9211, Bottom 30th Acc: 0.6875
Fold [5/5] Epoch [30/100] Initial Loss: 0.1380, Training Loss: 0.0161, Initial Validation Loss: 0.1280, Validation Loss: 0.0309,V Acc: 0.8426, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.6250
Fold [5/5] Epoch [40/100] Initial Loss: 0.1380, Training Loss: 0.0149, Initial Validation Loss: 0.1280, Validation Loss: 0.0312,V Acc: 0.8241, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.5625
Stopping early at Epoch (base 0): 40  Rolling back to Epoch (base 0): 35  Top Validation Acc: 0.9342105263157895
Running train_nn.py with seed 91
CUDA:False
Training samples count:  550
Training on 30 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1404, Training Loss: 0.1404, Initial Validation Loss: 0.1377, Validation Loss: 0.1377,V Acc: 0.2523, Top 70th Acc: 0.3205, Bottom 30th Acc: 0.0909
Fold [1/5] Epoch [10/100] Initial Loss: 0.1404, Training Loss: 0.0337, Initial Validation Loss: 0.1377, Validation Loss: 0.0387,V Acc: 0.8378, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 19  Rolling back to Epoch (base 0): 14  Top Validation Acc: 0.9615384615384616
Fold [2/5] Epoch [0/100] Initial Loss: 0.1381, Training Loss: 0.1381, Initial Validation Loss: 0.1312, Validation Loss: 0.1312,V Acc: 0.2703, Top 70th Acc: 0.3205, Bottom 30th Acc: 0.1515
Fold [2/5] Epoch [10/100] Initial Loss: 0.1381, Training Loss: 0.0271, Initial Validation Loss: 0.1312, Validation Loss: 0.0303,V Acc: 0.8559, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 18  Rolling back to Epoch (base 0): 13  Top Validation Acc: 0.9230769230769231
Fold [3/5] Epoch [0/100] Initial Loss: 0.1382, Training Loss: 0.1382, Initial Validation Loss: 0.1348, Validation Loss: 0.1348,V Acc: 0.2909, Top 70th Acc: 0.3377, Bottom 30th Acc: 0.1818
Fold [3/5] Epoch [10/100] Initial Loss: 0.1382, Training Loss: 0.0373, Initial Validation Loss: 0.1348, Validation Loss: 0.0536,V Acc: 0.7273, Top 70th Acc: 0.8571, Bottom 30th Acc: 0.4242
Fold [3/5] Epoch [20/100] Initial Loss: 0.1382, Training Loss: 0.0188, Initial Validation Loss: 0.1348, Validation Loss: 0.0414,V Acc: 0.8091, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.5758
Fold [3/5] Epoch [30/100] Initial Loss: 0.1382, Training Loss: 0.0153, Initial Validation Loss: 0.1348, Validation Loss: 0.0391,V Acc: 0.8182, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 31  Rolling back to Epoch (base 0): 26  Top Validation Acc: 0.922077922077922
Fold [4/5] Epoch [0/100] Initial Loss: 0.1364, Training Loss: 0.1364, Initial Validation Loss: 0.1366, Validation Loss: 0.1366,V Acc: 0.3636, Top 70th Acc: 0.4286, Bottom 30th Acc: 0.2121
Fold [4/5] Epoch [10/100] Initial Loss: 0.1364, Training Loss: 0.0290, Initial Validation Loss: 0.1366, Validation Loss: 0.0330,V Acc: 0.8636, Top 70th Acc: 0.9870, Bottom 30th Acc: 0.5758
Fold [4/5] Epoch [20/100] Initial Loss: 0.1364, Training Loss: 0.0182, Initial Validation Loss: 0.1366, Validation Loss: 0.0271,V Acc: 0.8818, Top 70th Acc: 0.9870, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 27  Rolling back to Epoch (base 0): 22  Top Validation Acc: 0.987012987012987
Fold [5/5] Epoch [0/100] Initial Loss: 0.1400, Training Loss: 0.1400, Initial Validation Loss: 0.1301, Validation Loss: 0.1301,V Acc: 0.2963, Top 70th Acc: 0.3553, Bottom 30th Acc: 0.1562
Fold [5/5] Epoch [10/100] Initial Loss: 0.1400, Training Loss: 0.0276, Initial Validation Loss: 0.1301, Validation Loss: 0.0327,V Acc: 0.8148, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.5000
Stopping early at Epoch (base 0): 19  Rolling back to Epoch (base 0): 14  Top Validation Acc: 0.9473684210526315
91 4 [array([0.57668394, 0.0480224 , 0.06378252, 0.11754794, 0.19396323],
      dtype=float32)]
Running train_nn.py with seed 92
CUDA:False
Training samples count:  550
Training on 30 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1406, Training Loss: 0.1406, Initial Validation Loss: 0.1319, Validation Loss: 0.1319,V Acc: 0.2523, Top 70th Acc: 0.3590, Bottom 30th Acc: 0.0000
Fold [1/5] Epoch [10/100] Initial Loss: 0.1406, Training Loss: 0.0482, Initial Validation Loss: 0.1319, Validation Loss: 0.0454,V Acc: 0.7477, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.3636
Fold [1/5] Epoch [20/100] Initial Loss: 0.1406, Training Loss: 0.0185, Initial Validation Loss: 0.1319, Validation Loss: 0.0285,V Acc: 0.8468, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 28  Rolling back to Epoch (base 0): 23  Top Validation Acc: 0.9615384615384616
92 0 [array([0.69273615, 0.07380179, 0.0305836 , 0.11764093, 0.08523754],
      dtype=float32)]
Fold [2/5] Epoch [0/100] Initial Loss: 0.1388, Training Loss: 0.1388, Initial Validation Loss: 0.1348, Validation Loss: 0.1348,V Acc: 0.3333, Top 70th Acc: 0.4359, Bottom 30th Acc: 0.0909
Fold [2/5] Epoch [10/100] Initial Loss: 0.1388, Training Loss: 0.0443, Initial Validation Loss: 0.1348, Validation Loss: 0.0536,V Acc: 0.7387, Top 70th Acc: 0.8590, Bottom 30th Acc: 0.4545
Fold [2/5] Epoch [20/100] Initial Loss: 0.1388, Training Loss: 0.0190, Initial Validation Loss: 0.1348, Validation Loss: 0.0322,V Acc: 0.8288, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.5152
Fold [2/5] Epoch [30/100] Initial Loss: 0.1388, Training Loss: 0.0151, Initial Validation Loss: 0.1348, Validation Loss: 0.0315,V Acc: 0.8468, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 33  Rolling back to Epoch (base 0): 28  Top Validation Acc: 0.9615384615384616
Fold [3/5] Epoch [0/100] Initial Loss: 0.1348, Training Loss: 0.1348, Initial Validation Loss: 0.1280, Validation Loss: 0.1280,V Acc: 0.4727, Top 70th Acc: 0.5455, Bottom 30th Acc: 0.3030
Fold [3/5] Epoch [10/100] Initial Loss: 0.1348, Training Loss: 0.0265, Initial Validation Loss: 0.1280, Validation Loss: 0.0320,V Acc: 0.8636, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6667
Fold [3/5] Epoch [20/100] Initial Loss: 0.1348, Training Loss: 0.0169, Initial Validation Loss: 0.1280, Validation Loss: 0.0287,V Acc: 0.8545, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.948051948051948
Fold [4/5] Epoch [0/100] Initial Loss: 0.1386, Training Loss: 0.1386, Initial Validation Loss: 0.1346, Validation Loss: 0.1346,V Acc: 0.3909, Top 70th Acc: 0.4156, Bottom 30th Acc: 0.3333
Fold [4/5] Epoch [10/100] Initial Loss: 0.1386, Training Loss: 0.0280, Initial Validation Loss: 0.1346, Validation Loss: 0.0325,V Acc: 0.8909, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.7879
Fold [4/5] Epoch [20/100] Initial Loss: 0.1386, Training Loss: 0.0176, Initial Validation Loss: 0.1346, Validation Loss: 0.0272,V Acc: 0.8818, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.7273
Stopping early at Epoch (base 0): 28  Rolling back to Epoch (base 0): 23  Top Validation Acc: 0.8589743589743589
Fold [2/5] Epoch [0/100] Initial Loss: 0.1385, Training Loss: 0.1385, Initial Validation Loss: 0.1401, Validation Loss: 0.1401,V Acc: 0.2523, Top 70th Acc: 0.2821, Bottom 30th Acc: 0.1818
Fold [2/5] Epoch [10/100] Initial Loss: 0.1385, Training Loss: 0.0498, Initial Validation Loss: 0.1401, Validation Loss: 0.0465,V Acc: 0.8198, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.6061
Fold [2/5] Epoch [20/100] Initial Loss: 0.1385, Training Loss: 0.0263, Initial Validation Loss: 0.1401, Validation Loss: 0.0289,V Acc: 0.9189, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.8182
Fold [2/5] Epoch [30/100] Initial Loss: 0.1385, Training Loss: 0.0236, Initial Validation Loss: 0.1401, Validation Loss: 0.0292,V Acc: 0.9009, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.7576
Stopping early at Epoch (base 0): 30  Rolling back to Epoch (base 0): 25  Top Validation Acc: 0.9615384615384616
Fold [3/5] Epoch [0/100] Initial Loss: 0.1419, Training Loss: 0.1419, Initial Validation Loss: 0.1315, Validation Loss: 0.1315,V Acc: 0.2545, Top 70th Acc: 0.3636, Bottom 30th Acc: 0.0000
Fold [3/5] Epoch [10/100] Initial Loss: 0.1419, Training Loss: 0.0341, Initial Validation Loss: 0.1315, Validation Loss: 0.0411,V Acc: 0.8000, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.5455
Fold [3/5] Epoch [20/100] Initial Loss: 0.1419, Training Loss: 0.0240, Initial Validation Loss: 0.1315, Validation Loss: 0.0349,V Acc: 0.8091, Top 70th Acc: 0.8961, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 29  Rolling back to Epoch (base 0): 24  Top Validation Acc: 0.8961038961038961
Fold [4/5] Epoch [0/100] Initial Loss: 0.1385, Training Loss: 0.1385, Initial Validation Loss: 0.1377, Validation Loss: 0.1377,V Acc: 0.3545, Top 70th Acc: 0.3766, Bottom 30th Acc: 0.3030
Fold [4/5] Epoch [10/100] Initial Loss: 0.1385, Training Loss: 0.0408, Initial Validation Loss: 0.1377, Validation Loss: 0.0374,V Acc: 0.8818, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.7576
Fold [4/5] Epoch [20/100] Initial Loss: 0.1385, Training Loss: 0.0250, Initial Validation Loss: 0.1377, Validation Loss: 0.0310,V Acc: 0.8636, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.948051948051948
Fold [5/5] Epoch [0/100] Initial Loss: 0.1386, Training Loss: 0.1386, Initial Validation Loss: 0.1299, Validation Loss: 0.1299,V Acc: 0.4167, Top 70th Acc: 0.4868, Bottom 30th Acc: 0.2500
Fold [5/5] Epoch [10/100] Initial Loss: 0.1386, Training Loss: 0.0354, Initial Validation Loss: 0.1299, Validation Loss: 0.0393,V Acc: 0.8241, Top 70th Acc: 0.9211, Bottom 30th Acc: 0.5938
Fold [5/5] Epoch [20/100] Initial Loss: 0.1386, Training Loss: 0.0235, Initial Validation Loss: 0.1299, Validation Loss: 0.0351,V Acc: 0.8333, Top 70th Acc: 0.9079, Bottom 30th Acc: 0.6562
Stopping early at Epoch (base 0): 27  Rolling back to Epoch (base 0): 22  Top Validation Acc: 0.9078947368421053
93 4 [array([0.43428642, 0.10110086, 0.11848742, 0.25431067, 0.09181464],
      dtype=float32)]
Running train_nn.py with seed 94
CUDA:False
Training samples count:  550
Training on 20 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1400, Training Loss: 0.1400, Initial Validation Loss: 0.1361, Validation Loss: 0.1361,V Acc: 0.3514, Top 70th Acc: 0.3846, Bottom 30th Acc: 0.2727
Fold [1/5] Epoch [10/100] Initial Loss: 0.1400, Training Loss: 0.0281, Initial Validation Loss: 0.1361, Validation Loss: 0.0441,V Acc: 0.7658, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.4242
Fold [1/5] Epoch [20/100] Initial Loss: 0.1400, Training Loss: 0.0204, Initial Validation Loss: 0.1361, Validation Loss: 0.0408,V Acc: 0.7748, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.4545
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.9102564102564102
Fold [2/5] Epoch [0/100] Initial Loss: 0.1415, Training Loss: 0.1415, Initial Validation Loss: 0.1372, Validation Loss: 0.1372,V Acc: 0.2523, Top 70th Acc: 0.2821, Bottom 30th Acc: 0.1818
Fold [2/5] Epoch [10/100] Initial Loss: 0.1415, Training Loss: 0.0409, Initial Validation Loss: 0.1372, Validation Loss: 0.0392,V Acc: 0.8288, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.5455
Fold [2/5] Epoch [20/100] Initial Loss: 0.1415, Training Loss: 0.0281, Initial Validation Loss: 0.1372, Validation Loss: 0.0319,V Acc: 0.8198, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.4545
Fold [2/5] Epoch [30/100] Initial Loss: 0.1415, Training Loss: 0.0235, Initial Validation Loss: 0.1372, Validation Loss: 0.0289,V Acc: 0.8468, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.5455
Fold [2/5] Epoch [40/100] Initial Loss: 0.1415, Training Loss: 0.0215, Initial Validation Loss: 0.1372, Validation Loss: 0.0278,V Acc: 0.8649, Top 70th Acc: 0.9872, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 45  Rolling back to Epoch (base 0): 40  Top Validation Acc: 0.9743589743589743
Fold [3/5] Epoch [0/100] Initial Loss: 0.1377, Training Loss: 0.1377, Initial Validation Loss: 0.1346, Validation Loss: 0.1346,V Acc: 0.2636, Top 70th Acc: 0.3506, Bottom 30th Acc: 0.0606
Fold [3/5] Epoch [10/100] Initial Loss: 0.1377, Training Loss: 0.0354, Initial Validation Loss: 0.1346, Validation Loss: 0.0404,V Acc: 0.8545, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.7273
Fold [3/5] Epoch [20/100] Initial Loss: 0.1377, Training Loss: 0.0233, Initial Validation Loss: 0.1346, Validation Loss: 0.0300,V Acc: 0.8545, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 29  Rolling back to Epoch (base 0): 24  Top Validation Acc: 0.922077922077922
94 2 [array([0.30576265, 0.08207907, 0.21322605, 0.23661467, 0.16231756],
      dtype=float32)]
Fold [4/5] Epoch [0/100] Initial Loss: 0.1397, Training Loss: 0.1397, Initial Validation Loss: 0.1335, Validation Loss: 0.1335,V Acc: 0.2636, Top 70th Acc: 0.3117, Bottom 30th Acc: 0.1515
Fold [4/5] Epoch [10/100] Initial Loss: 0.1397, Training Loss: 0.0377, Initial Validation Loss: 0.1335, Validation Loss: 0.0449,V Acc: 0.8273, Top 70th Acc: 0.8831, Bottom 30th Acc: 0.6970
Fold [4/5] Epoch [20/100] Initial Loss: 0.1397, Training Loss: 0.0222, Initial Validation Loss: 0.1335, Validation Loss: 0.0388,V Acc: 0.8182, Top 70th Acc: 0.8831, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 27  Rolling back to Epoch (base 0): 22  Top Validation Acc: 0.8831168831168831
Fold [5/5] Epoch [0/100] Initial Loss: 0.1373, Training Loss: 0.1373, Initial Validation Loss: 0.1313, Validation Loss: 0.1313,V Acc: 0.3241, Top 70th Acc: 0.3553, Bottom 30th Acc: 0.2500
Fold [5/5] Epoch [10/100] Initial Loss: 0.1373, Training Loss: 0.0436, Initial Validation Loss: 0.1313, Validation Loss: 0.0403,V Acc: 0.8056, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.5000
Fold [5/5] Epoch [20/100] Initial Loss: 0.1373, Training Loss: 0.0239, Initial Validation Loss: 0.1313, Validation Loss: 0.0268,V Acc: 0.8981, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.8125
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.9473684210526315
Running train_nn.py with seed 95
CUDA:False
Training samples count:  550
Training on 20 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1349, Training Loss: 0.1349, Initial Validation Loss: 0.1366, Validation Loss: 0.1366,V Acc: 0.2613, Top 70th Acc: 0.3590, Bottom 30th Acc: 0.0303
Fold [1/5] Epoch [10/100] Initial Loss: 0.1349, Training Loss: 0.0347, Initial Validation Loss: 0.1366, Validation Loss: 0.0348,V Acc: 0.8649, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.6364
Fold [1/5] Epoch [20/100] Initial Loss: 0.1349, Training Loss: 0.0247, Initial Validation Loss: 0.1366, Validation Loss: 0.0303,V Acc: 0.8919, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.7273
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.9615384615384616
Fold [2/5] Epoch [0/100] Initial Loss: 0.1403, Training Loss: 0.1403, Initial Validation Loss: 0.1357, Validation Loss: 0.1357,V Acc: 0.2523, Top 70th Acc: 0.3333, Bottom 30th Acc: 0.0606
Fold [2/5] Epoch [10/100] Initial Loss: 0.1403, Training Loss: 0.0407, Initial Validation Loss: 0.1357, Validation Loss: 0.0402,V Acc: 0.8198, Top 70th Acc: 0.8846, Bottom 30th Acc: 0.6667/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)

Stopping early at Epoch (base 0): 28  Rolling back to Epoch (base 0): 23  Top Validation Acc: 0.9230769230769231
Fold [3/5] Epoch [0/100] Initial Loss: 0.1387, Training Loss: 0.1387, Initial Validation Loss: 0.1306, Validation Loss: 0.1306,V Acc: 0.3545, Top 70th Acc: 0.3896, Bottom 30th Acc: 0.2727
Fold [3/5] Epoch [10/100] Initial Loss: 0.1387, Training Loss: 0.0252, Initial Validation Loss: 0.1306, Validation Loss: 0.0312,V Acc: 0.8364, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.6061
Fold [3/5] Epoch [20/100] Initial Loss: 0.1387, Training Loss: 0.0147, Initial Validation Loss: 0.1306, Validation Loss: 0.0294,V Acc: 0.8273, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 21  Rolling back to Epoch (base 0): 16  Top Validation Acc: 0.948051948051948
Fold [4/5] Epoch [0/100] Initial Loss: 0.1381, Training Loss: 0.1381, Initial Validation Loss: 0.1357, Validation Loss: 0.1357,V Acc: 0.3818, Top 70th Acc: 0.4416, Bottom 30th Acc: 0.2424
Fold [4/5] Epoch [10/100] Initial Loss: 0.1381, Training Loss: 0.0355, Initial Validation Loss: 0.1357, Validation Loss: 0.0394,V Acc: 0.8364, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.5758
Fold [4/5] Epoch [20/100] Initial Loss: 0.1381, Training Loss: 0.0171, Initial Validation Loss: 0.1357, Validation Loss: 0.0252,V Acc: 0.8818, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.6667
Fold [4/5] Epoch [30/100] Initial Loss: 0.1381, Training Loss: 0.0134, Initial Validation Loss: 0.1357, Validation Loss: 0.0237,V Acc: 0.8909, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.7273
Stopping early at Epoch (base 0): 36  Rolling back to Epoch (base 0): 31  Top Validation Acc: 0.961038961038961
90 3 [array([0.73525465, 0.10514102, 0.04546224, 0.06097503, 0.0531671 ],
      dtype=float32)]
Fold [5/5] Epoch [0/100] Initial Loss: 0.1380, Training Loss: 0.1380, Initial Validation Loss: 0.1291, Validation Loss: 0.1291,V Acc: 0.2500, Top 70th Acc: 0.3158, Bottom 30th Acc: 0.0938
Fold [5/5] Epoch [10/100] Initial Loss: 0.1380, Training Loss: 0.0358, Initial Validation Loss: 0.1291, Validation Loss: 0.0410,V Acc: 0.8333, Top 70th Acc: 0.9211, Bottom 30th Acc: 0.6250
Stopping early at Epoch (base 0): 19  Rolling back to Epoch (base 0): 14  Top Validation Acc: 0.9342105263157895
Running train_nn.py with seed 91
CUDA:False
Training samples count:  550
Training on 40 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1375, Training Loss: 0.1375, Initial Validation Loss: 0.1375, Validation Loss: 0.1375,V Acc: 0.2613, Top 70th Acc: 0.3333, Bottom 30th Acc: 0.0909
Fold [1/5] Epoch [10/100] Initial Loss: 0.1375, Training Loss: 0.0236, Initial Validation Loss: 0.1375, Validation Loss: 0.0324,V Acc: 0.9009, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.7879
Fold [1/5] Epoch [20/100] Initial Loss: 0.1375, Training Loss: 0.0130, Initial Validation Loss: 0.1375, Validation Loss: 0.0286,V Acc: 0.8829, Top 70th Acc: 0.9872, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 29  Rolling back to Epoch (base 0): 24  Top Validation Acc: 0.9871794871794872
Fold [2/5] Epoch [0/100] Initial Loss: 0.1388, Training Loss: 0.1388, Initial Validation Loss: 0.1314, Validation Loss: 0.1314,V Acc: 0.3243, Top 70th Acc: 0.3462, Bottom 30th Acc: 0.2727
Fold [2/5] Epoch [10/100] Initial Loss: 0.1388, Training Loss: 0.0348, Initial Validation Loss: 0.1314, Validation Loss: 0.0388,V Acc: 0.7928, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.5152
Fold [2/5] Epoch [20/100] Initial Loss: 0.1388, Training Loss: 0.0187, Initial Validation Loss: 0.1314, Validation Loss: 0.0346,V Acc: 0.8018, Top 70th Acc: 0.8846, Bottom 30th Acc: 0.6061
Fold [2/5] Epoch [30/100] Initial Loss: 0.1388, Training Loss: 0.0133, Initial Validation Loss: 0.1314, Validation Loss: 0.0307,V Acc: 0.8198, Top 70th Acc: 0.8974, Bottom 30th Acc: 0.6364
Fold [2/5] Epoch [40/100] Initial Loss: 0.1388, Training Loss: 0.0110, Initial Validation Loss: 0.1314, Validation Loss: 0.0284,V Acc: 0.8378, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.6364
Fold [2/5] Epoch [50/100] Initial Loss: 0.1388, Training Loss: 0.0104, Initial Validation Loss: 0.1314, Validation Loss: 0.0260,V Acc: 0.8288, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.6061
Fold [2/5] Epoch [60/100] Initial Loss: 0.1388, Training Loss: 0.0098, Initial Validation Loss: 0.1314, Validation Loss: 0.0254,V Acc: 0.8378, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 61  Rolling back to Epoch (base 0): 56  Top Validation Acc: 0.9230769230769231
Fold [3/5] Epoch [0/100] Initial Loss: 0.1368, Training Loss: 0.1368, Initial Validation Loss: 0.1339, Validation Loss: 0.1339,V Acc: 0.2545, Top 70th Acc: 0.3636, Bottom 30th Acc: 0.0000
Fold [3/5] Epoch [10/100] Initial Loss: 0.1368, Training Loss: 0.0315, Initial Validation Loss: 0.1339, Validation Loss: 0.0489,V Acc: 0.7636, Top 70th Acc: 0.8961, Bottom 30th Acc: 0.4545
Fold [3/5] Epoch [20/100] Initial Loss: 0.1368, Training Loss: 0.0142, Initial Validation Loss: 0.1339, Validation Loss: 0.0376,V Acc: 0.7818, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.4242
Fold [3/5] Epoch [30/100] Initial Loss: 0.1368, Training Loss: 0.0112, Initial Validation Loss: 0.1339, Validation Loss: 0.0360,V Acc: 0.8182, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 36  Rolling back to Epoch (base 0): 31  Top Validation Acc: 0.922077922077922
Fold [4/5] Epoch [0/100] Initial Loss: 0.1370, Training Loss: 0.1370, Initial Validation Loss: 0.1378, Validation Loss: 0.1378,V Acc: 0.3000, Top 70th Acc: 0.3636, Bottom 30th Acc: 0.1515
Fold [4/5] Epoch [10/100] Initial Loss: 0.1370, Training Loss: 0.0369, Initial Validation Loss: 0.1378, Validation Loss: 0.0433,V Acc: 0.8273, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.5758
Fold [4/5] Epoch [20/100] Initial Loss: 0.1370, Training Loss: 0.0160, Initial Validation Loss: 0.1378, Validation Loss: 0.0256,V Acc: 0.8727, Top 70th Acc: 0.9870, Bottom 30th Acc: 0.6061
Fold [4/5] Epoch [30/100] Initial Loss: 0.1370, Training Loss: 0.0127, Initial Validation Loss: 0.1378, Validation Loss: 0.0251,V Acc: 0.8909, Top 70th Acc: 0.9870, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 38  Rolling back to Epoch (base 0): 33  Top Validation Acc: 0.987012987012987
Fold [5/5] Epoch [0/100] Initial Loss: 0.1380, Training Loss: 0.1380, Initial Validation Loss: 0.1319, Validation Loss: 0.1319,V Acc: 0.2870, Top 70th Acc: 0.3684, Bottom 30th Acc: 0.0938
Fold [5/5] Epoch [10/100] Initial Loss: 0.1380, Training Loss: 0.0342, Initial Validation Loss: 0.1319, Validation Loss: 0.0367,V Acc: 0.7963, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.4375
Fold [5/5] Epoch [20/100] Initial Loss: 0.1380, Training Loss: 0.0183, Initial Validation Loss: 0.1319, Validation Loss: 0.0277,V Acc: 0.8426, Top 70th Acc: 0.9737, Bottom 30th Acc: 0.5312
Fold [5/5] Epoch [30/100] Initial Loss: 0.1380, Training Loss: 0.0131, Initial Validation Loss: 0.1319, Validation Loss: 0.0266,V Acc: 0.8704, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.6875
Stopping early at Epoch (base 0): 33  Rolling back to Epoch (base 0): 28  Top Validation Acc: 0.9605263157894737
91 4 [array([0.68286526, 0.06337772, 0.04749449, 0.12133969, 0.08492283],
      dtype=float32)]
Running train_nn.py with seed 92
CUDA:False
Training samples count:  550
Training on 40 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1383, Training Loss: 0.1383, Initial Validation Loss: 0.1306, Validation Loss: 0.1306,V Acc: 0.2523, Top 70th Acc: 0.3462, Bottom 30th Acc: 0.0303
Fold [1/5] Epoch [10/100] Initial Loss: 0.1383, Training Loss: 0.0311, Initial Validation Loss: 0.1306, Validation Loss: 0.0339,V Acc: 0.8378, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.6061
Fold [1/5] Epoch [20/100] Initial Loss: 0.1383, Training Loss: 0.0132, Initial Validation Loss: 0.1306, Validation Loss: 0.0253,V Acc: 0.8468, Top 70th Acc: 0.9872, Bottom 30th Acc: 0.5152
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.9743589743589743
92 0 [array([0.24489775, 0.1117202 , 0.10906097, 0.11863843, 0.41568264],
      dtype=float32)]
Fold [2/5] Epoch [0/100] Initial Loss: 0.1391, Training Loss: 0.1391, Initial Validation Loss: 0.1363, Validation Loss: 0.1363,V Acc: 0.2973, Top 70th Acc: 0.3462, Bottom 30th Acc: 0.1818
Fold [2/5] Epoch [10/100] Initial Loss: 0.1396, Training Loss: 0.0790, Initial Validation Loss: 0.1272, Validation Loss: 0.0887,V Acc: 0.5766, Top 70th Acc: 0.6667, Bottom 30th Acc: 0.3636
Fold [2/5] Epoch [20/100] Initial Loss: 0.1396, Training Loss: 0.0765, Initial Validation Loss: 0.1272, Validation Loss: 0.0882,V Acc: 0.5676, Top 70th Acc: 0.6923, Bottom 30th Acc: 0.2727
Stopping early at Epoch (base 0): 20  Rolling back to Epoch (base 0): 15  Top Validation Acc: 0.6923076923076923
Fold [3/5] Epoch [0/100] Initial Loss: 0.1410, Training Loss: 0.1410, Initial Validation Loss: 0.1313, Validation Loss: 0.1313,V Acc: 0.4182, Top 70th Acc: 0.4286, Bottom 30th Acc: 0.3939
Fold [3/5] Epoch [10/100] Initial Loss: 0.1410, Training Loss: 0.0828, Initial Validation Loss: 0.1313, Validation Loss: 0.0770,V Acc: 0.6727, Top 70th Acc: 0.7532, Bottom 30th Acc: 0.4848
Fold [3/5] Epoch [20/100] Initial Loss: 0.1410, Training Loss: 0.0799, Initial Validation Loss: 0.1313, Validation Loss: 0.0737,V Acc: 0.6818, Top 70th Acc: 0.7532, Bottom 30th Acc: 0.5152
Fold [3/5] Epoch [30/100] Initial Loss: 0.1410, Training Loss: 0.0788, Initial Validation Loss: 0.1313, Validation Loss: 0.0729,V Acc: 0.6818, Top 70th Acc: 0.7662, Bottom 30th Acc: 0.4848
Fold [3/5] Epoch [40/100] Initial Loss: 0.1410, Training Loss: 0.0782, Initial Validation Loss: 0.1313, Validation Loss: 0.0724,V Acc: 0.6545, Top 70th Acc: 0.7662, Bottom 30th Acc: 0.3939
Stopping early at Epoch (base 0): 45  Rolling back to Epoch (base 0): 40  Top Validation Acc: 0.7532467532467533
Fold [4/5] Epoch [0/100] Initial Loss: 0.1333, Training Loss: 0.1333, Initial Validation Loss: 0.1265, Validation Loss: 0.1265,V Acc: 0.3909, Top 70th Acc: 0.5065, Bottom 30th Acc: 0.1212
Fold [4/5] Epoch [10/100] Initial Loss: 0.1333, Training Loss: 0.0807, Initial Validation Loss: 0.1265, Validation Loss: 0.0805,V Acc: 0.6182, Top 70th Acc: 0.7273, Bottom 30th Acc: 0.3636
Fold [4/5] Epoch [20/100] Initial Loss: 0.1333, Training Loss: 0.0784, Initial Validation Loss: 0.1265, Validation Loss: 0.0790,V Acc: 0.6182, Top 70th Acc: 0.7143, Bottom 30th Acc: 0.3939
Fold [4/5] Epoch [30/100] Initial Loss: 0.1333, Training Loss: 0.0783, Initial Validation Loss: 0.1265, Validation Loss: 0.0788,V Acc: 0.6273, Top 70th Acc: 0.7273, Bottom 30th Acc: 0.3939
Stopping early at Epoch (base 0): 33  Rolling back to Epoch (base 0): 28  Top Validation Acc: 0.7532467532467533
Fold [5/5] Epoch [0/100] Initial Loss: 0.1364, Training Loss: 0.1364, Initial Validation Loss: 0.1269, Validation Loss: 0.1269,V Acc: 0.4074, Top 70th Acc: 0.5263, Bottom 30th Acc: 0.1250
Fold [5/5] Epoch [10/100] Initial Loss: 0.1364, Training Loss: 0.0821, Initial Validation Loss: 0.1269, Validation Loss: 0.0760,V Acc: 0.6389, Top 70th Acc: 0.7632, Bottom 30th Acc: 0.3438
Fold [5/5] Epoch [20/100] Initial Loss: 0.1364, Training Loss: 0.0797, Initial Validation Loss: 0.1269, Validation Loss: 0.0739,V Acc: 0.6389, Top 70th Acc: 0.7632, Bottom 30th Acc: 0.3438
Fold [5/5] Epoch [30/100] Initial Loss: 0.1364, Training Loss: 0.0792, Initial Validation Loss: 0.1269, Validation Loss: 0.0724,V Acc: 0.6574, Top 70th Acc: 0.7895, Bottom 30th Acc: 0.3438
Stopping early at Epoch (base 0): 33  Rolling back to Epoch (base 0): 28  Top Validation Acc: 0.7763157894736842
87 4 [array([0.1434776 , 0.3281134 , 0.16496079, 0.22674175, 0.13670646],
      dtype=float32)]
Running train_nn.py with seed 88
CUDA:False
Training samples count:  550
Training on 2 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1343, Training Loss: 0.1343, Initial Validation Loss: 0.1253, Validation Loss: 0.1253,V Acc: 0.4054, Top 70th Acc: 0.4615, Bottom 30th Acc: 0.2727
Fold [1/5] Epoch [10/100] Initial Loss: 0.1343, Training Loss: 0.0826, Initial Validation Loss: 0.1253, Validation Loss: 0.0740,V Acc: 0.6667, Top 70th Acc: 0.7308, Bottom 30th Acc: 0.5152
Fold [1/5] Epoch [20/100] Initial Loss: 0.1343, Training Loss: 0.0807, Initial Validation Loss: 0.1253, Validation Loss: 0.0723,V Acc: 0.6667, Top 70th Acc: 0.7436, Bottom 30th Acc: 0.4848
Stopping early at Epoch (base 0): 29  Rolling back to Epoch (base 0): 24  Top Validation Acc: 0.7435897435897436
Fold [2/5] Epoch [0/100] Initial Loss: 0.1350, Training Loss: 0.1350, Initial Validation Loss: 0.1277, Validation Loss: 0.1277,V Acc: 0.5225, Top 70th Acc: 0.6410, Bottom 30th Acc: 0.2424
Fold [2/5] Epoch [10/100] Initial Loss: 0.1350, Training Loss: 0.0806, Initial Validation Loss: 0.1277, Validation Loss: 0.0822,V Acc: 0.6126, Top 70th Acc: 0.7051, Bottom 30th Acc: 0.3939
Fold [2/5] Epoch [20/100] Initial Loss: 0.1350, Training Loss: 0.0785, Initial Validation Loss: 0.1277, Validation Loss: 0.0818,V Acc: 0.6306, Top 70th Acc: 0.7179, Bottom 30th Acc: 0.4242
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.717948717948718
Fold [3/5] Epoch [0/100] Initial Loss: 0.1386, Training Loss: 0.1386, Initial Validation Loss: 0.1287, Validation Loss: 0.1287,V Acc: 0.3091, Top 70th Acc: 0.3506, Bottom 30th Acc: 0.2121
Fold [3/5] Epoch [10/100] Initial Loss: 0.1386, Training Loss: 0.0834, Initial Validation Loss: 0.1287, Validation Loss: 0.0726,V Acc: 0.6909, Top 70th Acc: 0.8312, Bottom 30th Acc: 0.3636
Fold [3/5] Epoch [20/100] Initial Loss: 0.1386, Training Loss: 0.0815, Initial Validation Loss: 0.1287, Validation Loss: 0.0694,V Acc: 0.6727, Top 70th Acc: 0.8312, Bottom 30th Acc: 0.3030
Fold [3/5] Epoch [30/100] Initial Loss: 0.1386, Training Loss: 0.0809, Initial Validation Loss: 0.1287, Validation Loss: 0.0685,V Acc: 0.7091, Top 70th Acc: 0.8442, Bottom 30th Acc: 0.3939
Fold [3/5] Epoch [40/100] Initial Loss: 0.1386, Training Loss: 0.0806, Initial Validation Loss: 0.1287, Validation Loss: 0.0673,V Acc: 0.7091, Top 70th Acc: 0.8571, Bottom 30th Acc: 0.3636
Stopping early at Epoch (base 0): 42  Rolling back to Epoch (base 0): 37  Top Validation Acc: 0.8571428571428571
88 2 [array([0.14361586, 0.35755318, 0.14205429, 0.22096013, 0.13581651],
      dtype=float32)]
Fold [4/5] Epoch [0/100] Initial Loss: 0.1401, Training Loss: 0.1401, Initial Validation Loss: 0.1329, Validation Loss: 0.1329,V Acc: 0.3727, Top 70th Acc: 0.4805, Bottom 30th Acc: 0.1212
Fold [4/5] Epoch [10/100] Initial Loss: 0.1401, Training Loss: 0.0797, Initial Validation Loss: 0.1329, Validation Loss: 0.0873,V Acc: 0.5818, Top 70th Acc: 0.6883, Bottom 30th Acc: 0.3333
Fold [4/5] Epoch [20/100] Initial Loss: 0.1401, Training Loss: 0.0769, Initial Validation Loss: 0.1329, Validation Loss: 0.0860,V Acc: 0.5727, Top 70th Acc: 0.7013, Bottom 30th Acc: 0.2727
Stopping early at Epoch (base 0): 28  Rolling back to Epoch (base 0): 23  Top Validation Acc: 0.7012987012987013
Fold [5/5] Epoch [0/100] Initial Loss: 0.1380, Training Loss: 0.1380, Initial Validation Loss: 0.1321, Validation Loss: 0.1321,V Acc: 0.3519, Top 70th Acc: 0.3684, Bottom 30th Acc: 0.3125
Fold [5/5] Epoch [10/100] Initial Loss: 0.1380, Training Loss: 0.0782, Initial Validation Loss: 0.1321, Validation Loss: 0.0876,V Acc: 0.5833, Top 70th Acc: 0.6842, Bottom 30th Acc: 0.3438
Fold [5/5] Epoch [20/100] Initial Loss: 0.1380, Training Loss: 0.0761, Initial Validation Loss: 0.1321, Validation Loss: 0.0876,V Acc: 0.5741, Top 70th Acc: 0.6842, Bottom 30th Acc: 0.3125
Stopping early at Epoch (base 0): 20  Rolling back to Epoch (base 0): 15  Top Validation Acc: 0.6842105263157895
Running train_nn.py with seed 89
CUDA:False
Training samples count:  550
Training on 2 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1312, Training Loss: 0.1312, Initial Validation Loss: 0.1243, Validation Loss: 0.1243,V Acc: 0.5045, Top 70th Acc: 0.5897, Bottom 30th Acc: 0.3030
Fold [1/5] Epoch [10/100] Initial Loss: 0.1312, Training Loss: 0.0805, Initial Validation Loss: 0.1243, Validation Loss: 0.0817,V Acc: 0.6216, Top 70th Acc: 0.7308, Bottom 30th Acc: 0.3636
Fold [1/5] Epoch [20/100] Initial Loss: 0.1312, Training Loss: 0.0785, Initial Validation Loss: 0.1243, Validation Loss: 0.0800,V Acc: 0.6036, Top 70th Acc: 0.7308, Bottom 30th Acc: 0.3030
Fold [1/5] Epoch [30/100] Initial Loss: 0.1312, Training Loss: 0.0777, Initial Validation Loss: 0.1243, Validation Loss: 0.0791,V Acc: 0.6216, Top 70th Acc: 0.7436, Bottom 30th Acc: 0.3333/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
 0.987012987012987
Fold [5/5] Epoch [0/100] Initial Loss: 0.1384, Training Loss: 0.1384, Initial Validation Loss: 0.1263, Validation Loss: 0.1263,V Acc: 0.3796, Top 70th Acc: 0.4737, Bottom 30th Acc: 0.1562
Fold [5/5] Epoch [10/100] Initial Loss: 0.1384, Training Loss: 0.0114, Initial Validation Loss: 0.1263, Validation Loss: 0.0288,V Acc: 0.8241, Top 70th Acc: 0.9079, Bottom 30th Acc: 0.6250
Stopping early at Epoch (base 0): 18  Rolling back to Epoch (base 0): 13  Top Validation Acc: 0.8947368421052632
Running train_nn.py with seed 71
CUDA:False
Training samples count:  550
Training on 163 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1434, Training Loss: 0.1434, Initial Validation Loss: 0.1384, Validation Loss: 0.1384,V Acc: 0.2793, Top 70th Acc: 0.3590, Bottom 30th Acc: 0.0909
Fold [1/5] Epoch [10/100] Initial Loss: 0.1434, Training Loss: 0.0194, Initial Validation Loss: 0.1384, Validation Loss: 0.0477,V Acc: 0.8018, Top 70th Acc: 0.8974, Bottom 30th Acc: 0.5758
Fold [1/5] Epoch [20/100] Initial Loss: 0.1434, Training Loss: 0.0069, Initial Validation Loss: 0.1384, Validation Loss: 0.0384,V Acc: 0.8198, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.5455
Fold [1/5] Epoch [30/100] Initial Loss: 0.1434, Training Loss: 0.0050, Initial Validation Loss: 0.1384, Validation Loss: 0.0342,V Acc: 0.8559, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.6364
Fold [1/5] Epoch [40/100] Initial Loss: 0.1434, Training Loss: 0.0044, Initial Validation Loss: 0.1384, Validation Loss: 0.0308,V Acc: 0.8739, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.6364
Fold [1/5] Epoch [50/100] Initial Loss: 0.1434, Training Loss: 0.0043, Initial Validation Loss: 0.1384, Validation Loss: 0.0283,V Acc: 0.8829, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.6667
Fold [1/5] Epoch [60/100] Initial Loss: 0.1434, Training Loss: 0.0041, Initial Validation Loss: 0.1384, Validation Loss: 0.0278,V Acc: 0.8739, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.6364
Fold [1/5] Epoch [70/100] Initial Loss: 0.1434, Training Loss: 0.0040, Initial Validation Loss: 0.1384, Validation Loss: 0.0266,V Acc: 0.8919, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.6970
Fold [1/5] Epoch [80/100] Initial Loss: 0.1434, Training Loss: 0.0038, Initial Validation Loss: 0.1384, Validation Loss: 0.0257,V Acc: 0.8919, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 89  Rolling back to Epoch (base 0): 84  Top Validation Acc: 0.9743589743589743
Fold [2/5] Epoch [0/100] Initial Loss: 0.1383, Training Loss: 0.1383, Initial Validation Loss: 0.1318, Validation Loss: 0.1318,V Acc: 0.2523, Top 70th Acc: 0.3462, Bottom 30th Acc: 0.0303
Fold [2/5] Epoch [10/100] Initial Loss: 0.1383, Training Loss: 0.0185, Initial Validation Loss: 0.1318, Validation Loss: 0.0355,V Acc: 0.8739, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.7576
Fold [2/5] Epoch [20/100] Initial Loss: 0.1383, Training Loss: 0.0047, Initial Validation Loss: 0.1318, Validation Loss: 0.0269,V Acc: 0.8739, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.6667
Fold [2/5] Epoch [30/100] Initial Loss: 0.1383, Training Loss: 0.0037, Initial Validation Loss: 0.1318, Validation Loss: 0.0263,V Acc: 0.8559, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 32  Rolling back to Epoch (base 0): 27  Top Validation Acc: 0.9615384615384616
Fold [3/5] Epoch [0/100] Initial Loss: 0.1413, Training Loss: 0.1413, Initial Validation Loss: 0.1307, Validation Loss: 0.1307,V Acc: 0.3273, Top 70th Acc: 0.3506, Bottom 30th Acc: 0.2727
Fold [3/5] Epoch [10/100] Initial Loss: 0.1413, Training Loss: 0.0185, Initial Validation Loss: 0.1307, Validation Loss: 0.0402,V Acc: 0.7636, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.4242
Fold [3/5] Epoch [20/100] Initial Loss: 0.1413, Training Loss: 0.0048, Initial Validation Loss: 0.1307, Validation Loss: 0.0342,V Acc: 0.7909, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.4848
Stopping early at Epoch (base 0): 27  Rolling back to Epoch (base 0): 22  Top Validation Acc: 0.9090909090909091
Fold [4/5] Epoch [0/100] Initial Loss: 0.1396, Training Loss: 0.1396, Initial Validation Loss: 0.1370, Validation Loss: 0.1370,V Acc: 0.2545, Top 70th Acc: 0.2987, Bottom 30th Acc: 0.1515
Fold [4/5] Epoch [10/100] Initial Loss: 0.1396, Training Loss: 0.0297, Initial Validation Loss: 0.1370, Validation Loss: 0.0468,V Acc: 0.7727, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.4242
Fold [4/5] Epoch [20/100] Initial Loss: 0.1396, Training Loss: 0.0056, Initial Validation Loss: 0.1370, Validation Loss: 0.0334,V Acc: 0.8273, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.5455
Fold [4/5] Epoch [30/100] Initial Loss: 0.1396, Training Loss: 0.0041, Initial Validation Loss: 0.1370, Validation Loss: 0.0315,V Acc: 0.8364, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 36  Rolling back to Epoch (base 0): 31  Top Validation Acc: 0.935064935064935
71 3 [array([0.09257568, 0.04470192, 0.01713732, 0.1315343 , 0.7140507 ],
      dtype=float32)]
Fold [5/5] Epoch [0/100] Initial Loss: 0.1361, Training Loss: 0.1361, Initial Validation Loss: 0.1351, Validation Loss: 0.1351,V Acc: 0.2778, Top 70th Acc: 0.3158, Bottom 30th Acc: 0.1875
Fold [5/5] Epoch [10/100] Initial Loss: 0.1361, Training Loss: 0.0241, Initial Validation Loss: 0.1351, Validation Loss: 0.0372,V Acc: 0.8519, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.6562
Fold [5/5] Epoch [20/100] Initial Loss: 0.1361, Training Loss: 0.0051, Initial Validation Loss: 0.1351, Validation Loss: 0.0250,V Acc: 0.8981, Top 70th Acc: 1.0000, Bottom 30th Acc: 0.6562
Stopping early at Epoch (base 0): 27  Rolling back to Epoch (base 0): 22  Top Validation Acc: 1.0
Running train_nn.py with seed 72
CUDA:False
Training samples count:  550
Training on 163 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1385, Training Loss: 0.1385, Initial Validation Loss: 0.1377, Validation Loss: 0.1377,V Acc: 0.3694, Top 70th Acc: 0.4103, Bottom 30th Acc: 0.2727
Fold [1/5] Epoch [10/100] Initial Loss: 0.1385, Training Loss: 0.0158, Initial Validation Loss: 0.1377, Validation Loss: 0.0329,V Acc: 0.8739, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.6667
Fold [1/5] Epoch [20/100] Initial Loss: 0.1385, Training Loss: 0.0054, Initial Validation Loss: 0.1377, Validation Loss: 0.0251,V Acc: 0.9009, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.7273
Fold [1/5] Epoch [30/100] Initial Loss: 0.1385, Training Loss: 0.0041, Initial Validation Loss: 0.1377, Validation Loss: 0.0247,V Acc: 0.8919, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 31  Rolling back to Epoch (base 0): 26  Top Validation Acc: 0.9743589743589743
Fold [2/5] Epoch [0/100] Initial Loss: 0.1372, Training Loss: 0.1372, Initial Validation Loss: 0.1282, Validation Loss: 0.1282,V Acc: 0.4234, Top 70th Acc: 0.5000, Bottom 30th Acc: 0.2424
Fold [2/5] Epoch [10/100] Initial Loss: 0.1372, Training Loss: 0.0119, Initial Validation Loss: 0.1282, Validation Loss: 0.0236,V Acc: 0.8829, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.7273
Fold [2/5] Epoch [20/100] Initial Loss: 0.1372, Training Loss: 0.0049, Initial Validation Loss: 0.1282, Validation Loss: 0.0197,V Acc: 0.8739, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 29  Rolling back to Epoch (base 0): 24  Top Validation Acc: 0.9743589743589743
Fold [3/5] Epoch [0/100] Initial Loss: 0.1390, Training Loss: 0.1390, Initial Validation Loss: 0.1304, Validation Loss: 0.1304,V Acc: 0.3636, Top 70th Acc: 0.4675, Bottom 30th Acc: 0.1212
Fold [3/5] Epoch [10/100] Initial Loss: 0.1390, Training Loss: 0.0175, Initial Validation Loss: 0.1304, Validation Loss: 0.0352,V Acc: 0.8182, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.5455
Fold [3/5] Epoch [20/100] Initial Loss: 0.1390, Training Loss: 0.0045, Initial Validation Loss: 0.1304, Validation Loss: 0.0294,V Acc: 0.8182, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.5455
Fold [3/5] Epoch [30/100] Initial Loss: 0.1390, Training Loss: 0.0036, Initial Validation Loss: 0.1304, Validation Loss: 0.0283,V Acc: 0.8364, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 33  Rolling back to Epoch (base 0): 28  Top Validation Acc: 0.948051948051948
Fold [4/5] Epoch [0/100] Initial Loss: 0.1392, Training Loss: 0.1392, Initial Validation Loss: 0.1362, Validation Loss: 0.1362,V Acc: 0.2545, Top 70th Acc: 0.3506, Bottom 30th Acc: 0.0303
Stopping early at Epoch (base 0): 22  Rolling back to Epoch (base 0): 17  Top Validation Acc: 0.948051948051948
Fold [5/5] Epoch [0/100] Initial Loss: 0.1388, Training Loss: 0.1388, Initial Validation Loss: 0.1347, Validation Loss: 0.1347,V Acc: 0.3056, Top 70th Acc: 0.3026, Bottom 30th Acc: 0.3125
Fold [5/5] Epoch [10/100] Initial Loss: 0.1388, Training Loss: 0.0317, Initial Validation Loss: 0.1347, Validation Loss: 0.0444,V Acc: 0.8148, Top 70th Acc: 0.9079, Bottom 30th Acc: 0.5938
Fold [5/5] Epoch [20/100] Initial Loss: 0.1388, Training Loss: 0.0174, Initial Validation Loss: 0.1347, Validation Loss: 0.0350,V Acc: 0.8611, Top 70th Acc: 0.9211, Bottom 30th Acc: 0.7188
Fold [5/5] Epoch [30/100] Initial Loss: 0.1388, Training Loss: 0.0149, Initial Validation Loss: 0.1347, Validation Loss: 0.0335,V Acc: 0.8611, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.6875
Stopping early at Epoch (base 0): 32  Rolling back to Epoch (base 0): 27  Top Validation Acc: 0.9342105263157895
Running train_nn.py with seed 93
CUDA:False
Training samples count:  550
Training on 30 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1433, Training Loss: 0.1433, Initial Validation Loss: 0.1311, Validation Loss: 0.1311,V Acc: 0.3153, Top 70th Acc: 0.3462, Bottom 30th Acc: 0.2424
Fold [1/5] Epoch [10/100] Initial Loss: 0.1433, Training Loss: 0.0268, Initial Validation Loss: 0.1311, Validation Loss: 0.0409,V Acc: 0.7838, Top 70th Acc: 0.8718, Bottom 30th Acc: 0.5758
Fold [1/5] Epoch [20/100] Initial Loss: 0.1433, Training Loss: 0.0160, Initial Validation Loss: 0.1311, Validation Loss: 0.0414,V Acc: 0.7748, Top 70th Acc: 0.8718, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 21  Rolling back to Epoch (base 0): 16  Top Validation Acc: 0.8717948717948718
Fold [2/5] Epoch [0/100] Initial Loss: 0.1375, Training Loss: 0.1375, Initial Validation Loss: 0.1388, Validation Loss: 0.1388,V Acc: 0.2523, Top 70th Acc: 0.3077, Bottom 30th Acc: 0.1212
Fold [2/5] Epoch [10/100] Initial Loss: 0.1375, Training Loss: 0.0285, Initial Validation Loss: 0.1388, Validation Loss: 0.0306,V Acc: 0.9099, Top 70th Acc: 0.9872, Bottom 30th Acc: 0.7273
Fold [2/5] Epoch [20/100] Initial Loss: 0.1375, Training Loss: 0.0198, Initial Validation Loss: 0.1388, Validation Loss: 0.0260,V Acc: 0.9009, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.7273
Stopping early at Epoch (base 0): 22  Rolling back to Epoch (base 0): 17  Top Validation Acc: 0.9743589743589743
Fold [3/5] Epoch [0/100] Initial Loss: 0.1371, Training Loss: 0.1371, Initial Validation Loss: 0.1302, Validation Loss: 0.1302,V Acc: 0.3364, Top 70th Acc: 0.4026, Bottom 30th Acc: 0.1818
Fold [3/5] Epoch [10/100] Initial Loss: 0.1371, Training Loss: 0.0271, Initial Validation Loss: 0.1302, Validation Loss: 0.0396,V Acc: 0.8091, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.5758
Fold [3/5] Epoch [20/100] Initial Loss: 0.1371, Training Loss: 0.0165, Initial Validation Loss: 0.1302, Validation Loss: 0.0362,V Acc: 0.8182, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.9090909090909091
Fold [4/5] Epoch [0/100] Initial Loss: 0.1419, Training Loss: 0.1419, Initial Validation Loss: 0.1397, Validation Loss: 0.1397,V Acc: 0.2545, Top 70th Acc: 0.2857, Bottom 30th Acc: 0.1818
Fold [4/5] Epoch [10/100] Initial Loss: 0.1419, Training Loss: 0.0398, Initial Validation Loss: 0.1397, Validation Loss: 0.0363,V Acc: 0.8545, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6364
Fold [4/5] Epoch [20/100] Initial Loss: 0.1419, Training Loss: 0.0219, Initial Validation Loss: 0.1397, Validation Loss: 0.0283,V Acc: 0.8636, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6667
Fold [4/5] Epoch [30/100] Initial Loss: 0.1419, Training Loss: 0.0170, Initial Validation Loss: 0.1397, Validation Loss: 0.0268,V Acc: 0.8727, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 31  Rolling back to Epoch (base 0): 26  Top Validation Acc: 0.948051948051948
Fold [5/5] Epoch [0/100] Initial Loss: 0.1402, Training Loss: 0.1402, Initial Validation Loss: 0.1311, Validation Loss: 0.1311,V Acc: 0.2778, Top 70th Acc: 0.3026, Bottom 30th Acc: 0.2188
Fold [5/5] Epoch [10/100] Initial Loss: 0.1402, Training Loss: 0.0312, Initial Validation Loss: 0.1311, Validation Loss: 0.0370,V Acc: 0.8241, Top 70th Acc: 0.8947, Bottom 30th Acc: 0.6562
Fold [5/5] Epoch [20/100] Initial Loss: 0.1402, Training Loss: 0.0196, Initial Validation Loss: 0.1311, Validation Loss: 0.0276,V Acc: 0.8426, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.5938
Stopping early at Epoch (base 0): 29  Rolling back to Epoch (base 0): 24  Top Validation Acc: 0.9605263157894737
93 4 [array([0.7548315 , 0.10229423, 0.02764173, 0.08791787, 0.02731459],
      dtype=float32)]
Running train_nn.py with seed 94
CUDA:False
Training samples count:  550
Training on 30 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1388, Training Loss: 0.1388, Initial Validation Loss: 0.1359, Validation Loss: 0.1359,V Acc: 0.2703, Top 70th Acc: 0.3333, Bottom 30th Acc: 0.1212
Fold [1/5] Epoch [10/100] Initial Loss: 0.1388, Training Loss: 0.0312, Initial Validation Loss: 0.1359, Validation Loss: 0.0417,V Acc: 0.8288, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 17  Rolling back to Epoch (base 0): 12  Top Validation Acc: 0.9102564102564102
Fold [2/5] Epoch [0/100] Initial Loss: 0.1377, Training Loss: 0.1377, Initial Validation Loss: 0.1339, Validation Loss: 0.1339,V Acc: 0.2793, Top 70th Acc: 0.3590, Bottom 30th Acc: 0.0909
Fold [2/5] Epoch [10/100] Initial Loss: 0.1377, Training Loss: 0.0332, Initial Validation Loss: 0.1339, Validation Loss: 0.0306,V Acc: 0.8649, Top 70th Acc: 0.9872, Bottom 30th Acc: 0.5758
Fold [2/5] Epoch [20/100] Initial Loss: 0.1377, Training Loss: 0.0189, Initial Validation Loss: 0.1339, Validation Loss: 0.0228,V Acc: 0.9009, Top 70th Acc: 1.0000, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 1.0
Fold [3/5] Epoch [0/100] Initial Loss: 0.1430, Training Loss: 0.1430, Initial Validation Loss: 0.1358, Validation Loss: 0.1358,V Acc: 0.2818, Top 70th Acc: 0.3766, Bottom 30th Acc: 0.0606
Fold [3/5] Epoch [10/100] Initial Loss: 0.1430, Training Loss: 0.0350, Initial Validation Loss: 0.1358, Validation Loss: 0.0408,V Acc: 0.8000, Top 70th Acc: 0.8961, Bottom 30th Acc: 0.5758
Fold [3/5] Epoch [20/100] Initial Loss: 0.1430, Training Loss: 0.0193, Initial Validation Loss: 0.1358, Validation Loss: 0.0300,V Acc: 0.8455, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.6364
Fold [3/5] Epoch [30/100] Initial Loss: 0.1430, Training Loss: 0.0160, Initial Validation Loss: 0.1358, Validation Loss: 0.0256,V Acc: 0.8455, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.5455
Fold [3/5] Epoch [40/100] Initial Loss: 0.1430, Training Loss: 0.0145, Initial Validation Loss: 0.1358, Validation Loss: 0.0240,V Acc: 0.8818, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 45  Rolling back to Epoch (base 0): 40  Top Validation Acc: 0.961038961038961
94 2 [array([0.7615755 , 0.0457973 , 0.02191092, 0.06565741, 0.10505888],
      dtype=float32)]
Fold [4/5] Epoch [0/100] Initial Loss: 0.1378, Training Loss: 0.1378, Initial Validation Loss: 0.1318, Validation Loss: 0.1318,V Acc: 0.2727, Top 70th Acc: 0.2987, Bottom 30th Acc: 0.2121
Fold [4/5] Epoch [10/100] Initial Loss: 0.1378, Training Loss: 0.0296, Initial Validation Loss: 0.1318, Validation Loss: 0.0429,V Acc: 0.7636, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.4242
Fold [4/5] Epoch [20/100] Initial Loss: 0.1378, Training Loss: 0.0187, Initial Validation Loss: 0.1318, Validation Loss: 0.0348,V Acc: 0.8091, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 27  Rolling back to Epoch (base 0): 22  Top Validation Acc: 0.922077922077922
Fold [5/5] Epoch [0/100] Initial Loss: 0.1373, Training Loss: 0.1373, Initial Validation Loss: 0.1322, Validation Loss: 0.1322,V Acc: 0.2500, Top 70th Acc: 0.3158, Bottom 30th Acc: 0.0938
Fold [5/5] Epoch [10/100] Initial Loss: 0.1373, Training Loss: 0.0352, Initial Validation Loss: 0.1322, Validation Loss: 0.0334,V Acc: 0.8704, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.6875
Fold [2/5] Epoch [20/100] Initial Loss: 0.1403, Training Loss: 0.0247, Initial Validation Loss: 0.1357, Validation Loss: 0.0306,V Acc: 0.8829, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.7879
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.9358974358974359
Fold [3/5] Epoch [0/100] Initial Loss: 0.1419, Training Loss: 0.1419, Initial Validation Loss: 0.1381, Validation Loss: 0.1381,V Acc: 0.3182, Top 70th Acc: 0.2857, Bottom 30th Acc: 0.3939
Fold [3/5] Epoch [10/100] Initial Loss: 0.1419, Training Loss: 0.0401, Initial Validation Loss: 0.1381, Validation Loss: 0.0526,V Acc: 0.7818, Top 70th Acc: 0.8442, Bottom 30th Acc: 0.6364
Fold [3/5] Epoch [20/100] Initial Loss: 0.1419, Training Loss: 0.0226, Initial Validation Loss: 0.1381, Validation Loss: 0.0407,V Acc: 0.8273, Top 70th Acc: 0.8961, Bottom 30th Acc: 0.6667
Fold [3/5] Epoch [30/100] Initial Loss: 0.1419, Training Loss: 0.0192, Initial Validation Loss: 0.1381, Validation Loss: 0.0399,V Acc: 0.8273, Top 70th Acc: 0.8961, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 32  Rolling back to Epoch (base 0): 27  Top Validation Acc: 0.8961038961038961
Fold [4/5] Epoch [0/100] Initial Loss: 0.1412, Training Loss: 0.1412, Initial Validation Loss: 0.1330, Validation Loss: 0.1330,V Acc: 0.2273, Top 70th Acc: 0.2987, Bottom 30th Acc: 0.0606
Fold [4/5] Epoch [10/100] Initial Loss: 0.1412, Training Loss: 0.0400, Initial Validation Loss: 0.1330, Validation Loss: 0.0551,V Acc: 0.7455, Top 70th Acc: 0.8442, Bottom 30th Acc: 0.5152
Fold [4/5] Epoch [20/100] Initial Loss: 0.1412, Training Loss: 0.0214, Initial Validation Loss: 0.1330, Validation Loss: 0.0471,V Acc: 0.7545, Top 70th Acc: 0.8571, Bottom 30th Acc: 0.5152
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.8571428571428571
Fold [5/5] Epoch [0/100] Initial Loss: 0.1379, Training Loss: 0.1379, Initial Validation Loss: 0.1294, Validation Loss: 0.1294,V Acc: 0.3426, Top 70th Acc: 0.4342, Bottom 30th Acc: 0.1250
Fold [5/5] Epoch [10/100] Initial Loss: 0.1379, Training Loss: 0.0376, Initial Validation Loss: 0.1294, Validation Loss: 0.0336,V Acc: 0.8426, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.5938
Fold [5/5] Epoch [20/100] Initial Loss: 0.1379, Training Loss: 0.0265, Initial Validation Loss: 0.1294, Validation Loss: 0.0239,V Acc: 0.8889, Top 70th Acc: 0.9737, Bottom 30th Acc: 0.6875
Fold [5/5] Epoch [30/100] Initial Loss: 0.1379, Training Loss: 0.0241, Initial Validation Loss: 0.1294, Validation Loss: 0.0218,V Acc: 0.8981, Top 70th Acc: 0.9737, Bottom 30th Acc: 0.7188
Fold [5/5] Epoch [40/100] Initial Loss: 0.1379, Training Loss: 0.0226, Initial Validation Loss: 0.1294, Validation Loss: 0.0220,V Acc: 0.9074, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.7812
Stopping early at Epoch (base 0): 42  Rolling back to Epoch (base 0): 37  Top Validation Acc: 0.9605263157894737
95 4 [array([0.31831056, 0.07777483, 0.18458067, 0.28230622, 0.13702768],
      dtype=float32)]
Running train_nn.py with seed 96
CUDA:False
Training samples count:  550
Training on 20 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1393, Training Loss: 0.1393, Initial Validation Loss: 0.1375, Validation Loss: 0.1375,V Acc: 0.2342, Top 70th Acc: 0.2308, Bottom 30th Acc: 0.2424
Fold [1/5] Epoch [10/100] Initial Loss: 0.1393, Training Loss: 0.0381, Initial Validation Loss: 0.1375, Validation Loss: 0.0464,V Acc: 0.8198, Top 70th Acc: 0.8974, Bottom 30th Acc: 0.6364
Fold [1/5] Epoch [20/100] Initial Loss: 0.1393, Training Loss: 0.0228, Initial Validation Loss: 0.1375, Validation Loss: 0.0366,V Acc: 0.8288, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.9102564102564102
Fold [2/5] Epoch [0/100] Initial Loss: 0.1370, Training Loss: 0.1370, Initial Validation Loss: 0.1334, Validation Loss: 0.1334,V Acc: 0.3784, Top 70th Acc: 0.4359, Bottom 30th Acc: 0.2424
Fold [2/5] Epoch [10/100] Initial Loss: 0.1370, Training Loss: 0.0377, Initial Validation Loss: 0.1334, Validation Loss: 0.0345,V Acc: 0.8378, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 19  Rolling back to Epoch (base 0): 14  Top Validation Acc: 0.9358974358974359
Fold [3/5] Epoch [0/100] Initial Loss: 0.1371, Training Loss: 0.1371, Initial Validation Loss: 0.1352, Validation Loss: 0.1352,V Acc: 0.3636, Top 70th Acc: 0.4286, Bottom 30th Acc: 0.2121
Fold [3/5] Epoch [10/100] Initial Loss: 0.1371, Training Loss: 0.0400, Initial Validation Loss: 0.1352, Validation Loss: 0.0370,V Acc: 0.8818, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.7879
Fold [3/5] Epoch [20/100] Initial Loss: 0.1371, Training Loss: 0.0272, Initial Validation Loss: 0.1352, Validation Loss: 0.0271,V Acc: 0.9091, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.8182
Stopping early at Epoch (base 0): 28  Rolling back to Epoch (base 0): 23  Top Validation Acc: 0.948051948051948
Fold [4/5] Epoch [0/100] Initial Loss: 0.1363, Training Loss: 0.1363, Initial Validation Loss: 0.1265, Validation Loss: 0.1265,V Acc: 0.4091, Top 70th Acc: 0.5325, Bottom 30th Acc: 0.1212
Fold [4/5] Epoch [10/100] Initial Loss: 0.1363, Training Loss: 0.0283, Initial Validation Loss: 0.1265, Validation Loss: 0.0423,V Acc: 0.8091, Top 70th Acc: 0.8831, Bottom 30th Acc: 0.6364
Fold [4/5] Epoch [20/100] Initial Loss: 0.1363, Training Loss: 0.0211, Initial Validation Loss: 0.1265, Validation Loss: 0.0419,V Acc: 0.8091, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 29  Rolling back to Epoch (base 0): 24  Top Validation Acc: 0.8831168831168831
Fold [5/5] Epoch [0/100] Initial Loss: 0.1359, Training Loss: 0.1359, Initial Validation Loss: 0.1272, Validation Loss: 0.1272,V Acc: 0.3148, Top 70th Acc: 0.3684, Bottom 30th Acc: 0.1875
Fold [5/5] Epoch [10/100] Initial Loss: 0.1359, Training Loss: 0.0337, Initial Validation Loss: 0.1272, Validation Loss: 0.0355,V Acc: 0.8333, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.5938
Fold [5/5] Epoch [20/100] Initial Loss: 0.1359, Training Loss: 0.0236, Initial Validation Loss: 0.1272, Validation Loss: 0.0317,V Acc: 0.8148, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.5312
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.9342105263157895
96 4 [array([0.34177205, 0.10776282, 0.09476226, 0.30480167, 0.15090126],
      dtype=float32)]
Running train_nn.py with seed 97
CUDA:False
Training samples count:  550
Training on 20 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1367, Training Loss: 0.1367, Initial Validation Loss: 0.1367, Validation Loss: 0.1367,V Acc: 0.2793, Top 70th Acc: 0.3205, Bottom 30th Acc: 0.1818
Fold [1/5] Epoch [10/100] Initial Loss: 0.1367, Training Loss: 0.0325, Initial Validation Loss: 0.1367, Validation Loss: 0.0386,V Acc: 0.8378, Top 70th Acc: 0.8974, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 19  Rolling back to Epoch (base 0): 14  Top Validation Acc: 0.9230769230769231
Fold [2/5] Epoch [0/100] Initial Loss: 0.1370, Training Loss: 0.1370, Initial Validation Loss: 0.1324, Validation Loss: 0.1324,V Acc: 0.3874, Top 70th Acc: 0.4359, Bottom 30th Acc: 0.2727
Fold [2/5] Epoch [10/100] Initial Loss: 0.1370, Training Loss: 0.0338, Initial Validation Loss: 0.1324, Validation Loss: 0.0356,V Acc: 0.8288, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.5455
Fold [2/5] Epoch [20/100] Initial Loss: 0.1370, Training Loss: 0.0243, Initial Validation Loss: 0.1324, Validation Loss: 0.0297,V Acc: 0.8649, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.9487179487179487
97 1 [array([0.36617863, 0.2004054 , 0.09723881, 0.21298467, 0.12319258],
      dtype=float32)]
Fold [3/5] Epoch [0/100] Initial Loss: 0.1402, Training Loss: 0.1402, Initial Validation Loss: 0.1344, Validation Loss: 0.1344,V Acc: 0.3091, Top 70th Acc: 0.2597, Bottom 30th Acc: 0.4242
Fold [3/5] Epoch [10/100] Initial Loss: 0.1402, Training Loss: 0.0380, Initial Validation Loss: 0.1344, Validation Loss: 0.0361,V Acc: 0.8545, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.5758
Fold [3/5] Epoch [20/100] Initial Loss: 0.1402, Training Loss: 0.0258, Initial Validation Loss: 0.1344, Validation Loss: 0.0280,V Acc: 0.8818, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.6970
Fold [2/5] Epoch [10/100] Initial Loss: 0.1391, Training Loss: 0.0238, Initial Validation Loss: 0.1363, Validation Loss: 0.0361,V Acc: 0.8468, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.6364
Fold [2/5] Epoch [20/100] Initial Loss: 0.1391, Training Loss: 0.0123, Initial Validation Loss: 0.1363, Validation Loss: 0.0319,V Acc: 0.8288, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.5455
Fold [2/5] Epoch [30/100] Initial Loss: 0.1391, Training Loss: 0.0102, Initial Validation Loss: 0.1363, Validation Loss: 0.0318,V Acc: 0.8378, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 38  Rolling back to Epoch (base 0): 33  Top Validation Acc: 0.9615384615384616
Fold [3/5] Epoch [0/100] Initial Loss: 0.1363, Training Loss: 0.1363, Initial Validation Loss: 0.1305, Validation Loss: 0.1305,V Acc: 0.3636, Top 70th Acc: 0.4286, Bottom 30th Acc: 0.2121
Fold [3/5] Epoch [10/100] Initial Loss: 0.1363, Training Loss: 0.0309, Initial Validation Loss: 0.1305, Validation Loss: 0.0416,V Acc: 0.8000, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.5455
Fold [3/5] Epoch [20/100] Initial Loss: 0.1363, Training Loss: 0.0147, Initial Validation Loss: 0.1305, Validation Loss: 0.0331,V Acc: 0.8182, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.5758
Fold [3/5] Epoch [30/100] Initial Loss: 0.1363, Training Loss: 0.0111, Initial Validation Loss: 0.1305, Validation Loss: 0.0306,V Acc: 0.8273, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.5455
Fold [3/5] Epoch [40/100] Initial Loss: 0.1363, Training Loss: 0.0099, Initial Validation Loss: 0.1305, Validation Loss: 0.0294,V Acc: 0.8455, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 42  Rolling back to Epoch (base 0): 37  Top Validation Acc: 0.935064935064935
Fold [4/5] Epoch [0/100] Initial Loss: 0.1383, Training Loss: 0.1383, Initial Validation Loss: 0.1362, Validation Loss: 0.1362,V Acc: 0.2636, Top 70th Acc: 0.3636, Bottom 30th Acc: 0.0303
Fold [4/5] Epoch [10/100] Initial Loss: 0.1383, Training Loss: 0.0300, Initial Validation Loss: 0.1362, Validation Loss: 0.0334,V Acc: 0.8545, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6364
Fold [4/5] Epoch [20/100] Initial Loss: 0.1383, Training Loss: 0.0136, Initial Validation Loss: 0.1362, Validation Loss: 0.0239,V Acc: 0.8818, Top 70th Acc: 0.9870, Bottom 30th Acc: 0.6364
Fold [4/5] Epoch [30/100] Initial Loss: 0.1383, Training Loss: 0.0112, Initial Validation Loss: 0.1362, Validation Loss: 0.0228,V Acc: 0.9000, Top 70th Acc: 0.9870, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 38  Rolling back to Epoch (base 0): 33  Top Validation Acc: 0.961038961038961
Fold [5/5] Epoch [0/100] Initial Loss: 0.1428, Training Loss: 0.1428, Initial Validation Loss: 0.1378, Validation Loss: 0.1378,V Acc: 0.2593, Top 70th Acc: 0.3026, Bottom 30th Acc: 0.1562
Fold [5/5] Epoch [10/100] Initial Loss: 0.1428, Training Loss: 0.0353, Initial Validation Loss: 0.1378, Validation Loss: 0.0466,V Acc: 0.7685, Top 70th Acc: 0.8553, Bottom 30th Acc: 0.5625
Fold [5/5] Epoch [20/100] Initial Loss: 0.1428, Training Loss: 0.0156, Initial Validation Loss: 0.1378, Validation Loss: 0.0370,V Acc: 0.8148, Top 70th Acc: 0.9079, Bottom 30th Acc: 0.5938
Fold [5/5] Epoch [30/100] Initial Loss: 0.1428, Training Loss: 0.0120, Initial Validation Loss: 0.1378, Validation Loss: 0.0348,V Acc: 0.8611, Top 70th Acc: 0.9211, Bottom 30th Acc: 0.7188
Stopping early at Epoch (base 0): 31  Rolling back to Epoch (base 0): 26  Top Validation Acc: 0.9210526315789473
Running train_nn.py with seed 93
CUDA:False
Training samples count:  550
Training on 40 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1411, Training Loss: 0.1411, Initial Validation Loss: 0.1327, Validation Loss: 0.1327,V Acc: 0.3063, Top 70th Acc: 0.3077, Bottom 30th Acc: 0.3030
Fold [1/5] Epoch [10/100] Initial Loss: 0.1411, Training Loss: 0.0412, Initial Validation Loss: 0.1327, Validation Loss: 0.0531,V Acc: 0.7387, Top 70th Acc: 0.8590, Bottom 30th Acc: 0.4545
Fold [1/5] Epoch [20/100] Initial Loss: 0.1411, Training Loss: 0.0142, Initial Validation Loss: 0.1327, Validation Loss: 0.0360,V Acc: 0.8018, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.5152
Fold [1/5] Epoch [30/100] Initial Loss: 0.1411, Training Loss: 0.0111, Initial Validation Loss: 0.1327, Validation Loss: 0.0357,V Acc: 0.8018, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.5152
Stopping early at Epoch (base 0): 30  Rolling back to Epoch (base 0): 25  Top Validation Acc: 0.9230769230769231
Fold [2/5] Epoch [0/100] Initial Loss: 0.1363, Training Loss: 0.1363, Initial Validation Loss: 0.1373, Validation Loss: 0.1373,V Acc: 0.2973, Top 70th Acc: 0.3590, Bottom 30th Acc: 0.1515
Fold [2/5] Epoch [10/100] Initial Loss: 0.1363, Training Loss: 0.0318, Initial Validation Loss: 0.1373, Validation Loss: 0.0332,V Acc: 0.8829, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.6667
Fold [2/5] Epoch [20/100] Initial Loss: 0.1363, Training Loss: 0.0156, Initial Validation Loss: 0.1373, Validation Loss: 0.0260,V Acc: 0.8919, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 28  Rolling back to Epoch (base 0): 23  Top Validation Acc: 0.9871794871794872
Fold [3/5] Epoch [0/100] Initial Loss: 0.1407, Training Loss: 0.1407, Initial Validation Loss: 0.1328, Validation Loss: 0.1328,V Acc: 0.2545, Top 70th Acc: 0.3117, Bottom 30th Acc: 0.1212
Fold [3/5] Epoch [10/100] Initial Loss: 0.1407, Training Loss: 0.0320, Initial Validation Loss: 0.1328, Validation Loss: 0.0470,V Acc: 0.7091, Top 70th Acc: 0.8961, Bottom 30th Acc: 0.2727
Fold [3/5] Epoch [20/100] Initial Loss: 0.1407, Training Loss: 0.0149, Initial Validation Loss: 0.1328, Validation Loss: 0.0351,V Acc: 0.8091, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.4848
Fold [3/5] Epoch [30/100] Initial Loss: 0.1407, Training Loss: 0.0122, Initial Validation Loss: 0.1328, Validation Loss: 0.0351,V Acc: 0.8182, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 34  Rolling back to Epoch (base 0): 29  Top Validation Acc: 0.922077922077922
Fold [4/5] Epoch [0/100] Initial Loss: 0.1362, Training Loss: 0.1362, Initial Validation Loss: 0.1362, Validation Loss: 0.1362,V Acc: 0.2545, Top 70th Acc: 0.3506, Bottom 30th Acc: 0.0303
Fold [4/5] Epoch [10/100] Initial Loss: 0.1362, Training Loss: 0.0300, Initial Validation Loss: 0.1362, Validation Loss: 0.0391,V Acc: 0.8364, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.6061
Fold [4/5] Epoch [20/100] Initial Loss: 0.1362, Training Loss: 0.0150, Initial Validation Loss: 0.1362, Validation Loss: 0.0324,V Acc: 0.8545, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.961038961038961
Fold [5/5] Epoch [0/100] Initial Loss: 0.1404, Training Loss: 0.1404, Initial Validation Loss: 0.1309, Validation Loss: 0.1309,V Acc: 0.4074, Top 70th Acc: 0.5263, Bottom 30th Acc: 0.1250
Fold [5/5] Epoch [10/100] Initial Loss: 0.1404, Training Loss: 0.0398, Initial Validation Loss: 0.1309, Validation Loss: 0.0422,V Acc: 0.7778, Top 70th Acc: 0.8947, Bottom 30th Acc: 0.5000
Fold [5/5] Epoch [20/100] Initial Loss: 0.1404, Training Loss: 0.0158, Initial Validation Loss: 0.1309, Validation Loss: 0.0313,V Acc: 0.8333, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.5938
Fold [5/5] Epoch [30/100] Initial Loss: 0.1404, Training Loss: 0.0124, Initial Validation Loss: 0.1309, Validation Loss: 0.0296,V Acc: 0.8426, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.5938
Stopping early at Epoch (base 0): 37  Rolling back to Epoch (base 0): 32  Top Validation Acc: 0.9605263157894737
93 4 [array([0.70061946, 0.12540317, 0.0227611 , 0.05282839, 0.0983879 ],
      dtype=float32)]
Running train_nn.py with seed 94
CUDA:False
Training samples count:  550
Training on 40 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1410, Training Loss: 0.1410, Initial Validation Loss: 0.1382, Validation Loss: 0.1382,V Acc: 0.2432, Top 70th Acc: 0.2436, Bottom 30th Acc: 0.2424
Fold [1/5] Epoch [10/100] Initial Loss: 0.1410, Training Loss: 0.0378, Initial Validation Loss: 0.1382, Validation Loss: 0.0484,V Acc: 0.7658, Top 70th Acc: 0.8846, Bottom 30th Acc: 0.4848
Fold [1/5] Epoch [20/100] Initial Loss: 0.1410, Training Loss: 0.0136, Initial Validation Loss: 0.1382, Validation Loss: 0.0386,V Acc: 0.8108, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.5758
Fold [1/5] Epoch [40/100] Initial Loss: 0.1312, Training Loss: 0.0772, Initial Validation Loss: 0.1243, Validation Loss: 0.0779,V Acc: 0.6306, Top 70th Acc: 0.7436, Bottom 30th Acc: 0.3636
Stopping early at Epoch (base 0): 45  Rolling back to Epoch (base 0): 40  Top Validation Acc: 0.7435897435897436
Fold [2/5] Epoch [0/100] Initial Loss: 0.1290, Training Loss: 0.1290, Initial Validation Loss: 0.1173, Validation Loss: 0.1173,V Acc: 0.5946, Top 70th Acc: 0.6667, Bottom 30th Acc: 0.4242
Fold [2/5] Epoch [10/100] Initial Loss: 0.1290, Training Loss: 0.0793, Initial Validation Loss: 0.1173, Validation Loss: 0.0856,V Acc: 0.6126, Top 70th Acc: 0.7051, Bottom 30th Acc: 0.3939
Stopping early at Epoch (base 0): 17  Rolling back to Epoch (base 0): 12  Top Validation Acc: 0.7051282051282052
Fold [3/5] Epoch [0/100] Initial Loss: 0.1378, Training Loss: 0.1378, Initial Validation Loss: 0.1272, Validation Loss: 0.1272,V Acc: 0.3818, Top 70th Acc: 0.5325, Bottom 30th Acc: 0.0303
Fold [3/5] Epoch [10/100] Initial Loss: 0.1378, Training Loss: 0.0829, Initial Validation Loss: 0.1272, Validation Loss: 0.0704,V Acc: 0.6818, Top 70th Acc: 0.7792, Bottom 30th Acc: 0.4545
Fold [3/5] Epoch [20/100] Initial Loss: 0.1378, Training Loss: 0.0812, Initial Validation Loss: 0.1272, Validation Loss: 0.0682,V Acc: 0.6909, Top 70th Acc: 0.7922, Bottom 30th Acc: 0.4545
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.7792207792207793
89 2 [array([0.15377091, 0.35199335, 0.14043988, 0.21603113, 0.13776472],
      dtype=float32)]
Fold [4/5] Epoch [0/100] Initial Loss: 0.1371, Training Loss: 0.1371, Initial Validation Loss: 0.1293, Validation Loss: 0.1293,V Acc: 0.3364, Top 70th Acc: 0.4416, Bottom 30th Acc: 0.0909
Fold [4/5] Epoch [10/100] Initial Loss: 0.1371, Training Loss: 0.0811, Initial Validation Loss: 0.1293, Validation Loss: 0.0792,V Acc: 0.5909, Top 70th Acc: 0.7143, Bottom 30th Acc: 0.3030
Stopping early at Epoch (base 0): 15  Rolling back to Epoch (base 0): 10  Top Validation Acc: 0.7012987012987013
Fold [5/5] Epoch [0/100] Initial Loss: 0.1396, Training Loss: 0.1396, Initial Validation Loss: 0.1323, Validation Loss: 0.1323,V Acc: 0.3241, Top 70th Acc: 0.4474, Bottom 30th Acc: 0.0312
Fold [5/5] Epoch [10/100] Initial Loss: 0.1396, Training Loss: 0.0792, Initial Validation Loss: 0.1323, Validation Loss: 0.0830,V Acc: 0.6296, Top 70th Acc: 0.7368, Bottom 30th Acc: 0.3750
Fold [5/5] Epoch [20/100] Initial Loss: 0.1396, Training Loss: 0.0776, Initial Validation Loss: 0.1323, Validation Loss: 0.0817,V Acc: 0.6389, Top 70th Acc: 0.7368, Bottom 30th Acc: 0.4062
Fold [5/5] Epoch [30/100] Initial Loss: 0.1396, Training Loss: 0.0770, Initial Validation Loss: 0.1323, Validation Loss: 0.0810,V Acc: 0.6296, Top 70th Acc: 0.7237, Bottom 30th Acc: 0.4062
Stopping early at Epoch (base 0): 31  Rolling back to Epoch (base 0): 26  Top Validation Acc: 0.75
Running train_nn.py with seed 90
CUDA:False
Training samples count:  550
Training on 2 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1378, Training Loss: 0.1378, Initial Validation Loss: 0.1303, Validation Loss: 0.1303,V Acc: 0.4955, Top 70th Acc: 0.5000, Bottom 30th Acc: 0.4848
Fold [1/5] Epoch [10/100] Initial Loss: 0.1378, Training Loss: 0.0809, Initial Validation Loss: 0.1303, Validation Loss: 0.0812,V Acc: 0.6216, Top 70th Acc: 0.7436, Bottom 30th Acc: 0.3333
Fold [1/5] Epoch [20/100] Initial Loss: 0.1378, Training Loss: 0.0783, Initial Validation Loss: 0.1303, Validation Loss: 0.0798,V Acc: 0.6396, Top 70th Acc: 0.7436, Bottom 30th Acc: 0.3939
Fold [1/5] Epoch [30/100] Initial Loss: 0.1378, Training Loss: 0.0777, Initial Validation Loss: 0.1303, Validation Loss: 0.0791,V Acc: 0.6216, Top 70th Acc: 0.7436, Bottom 30th Acc: 0.3333
Stopping early at Epoch (base 0): 30  Rolling back to Epoch (base 0): 25  Top Validation Acc: 0.7435897435897436
Fold [2/5] Epoch [0/100] Initial Loss: 0.1385, Training Loss: 0.1385, Initial Validation Loss: 0.1348, Validation Loss: 0.1348,V Acc: 0.3153, Top 70th Acc: 0.3462, Bottom 30th Acc: 0.2424
Fold [2/5] Epoch [10/100] Initial Loss: 0.1385, Training Loss: 0.0777, Initial Validation Loss: 0.1348, Validation Loss: 0.0883,V Acc: 0.5856, Top 70th Acc: 0.7308, Bottom 30th Acc: 0.2424
Fold [2/5] Epoch [20/100] Initial Loss: 0.1385, Training Loss: 0.0760, Initial Validation Loss: 0.1348, Validation Loss: 0.0878,V Acc: 0.6036, Top 70th Acc: 0.6795, Bottom 30th Acc: 0.4242
Fold [2/5] Epoch [30/100] Initial Loss: 0.1385, Training Loss: 0.0750, Initial Validation Loss: 0.1348, Validation Loss: 0.0871,V Acc: 0.6216, Top 70th Acc: 0.7179, Bottom 30th Acc: 0.3939
Stopping early at Epoch (base 0): 32  Rolling back to Epoch (base 0): 27  Top Validation Acc: 0.717948717948718
Fold [3/5] Epoch [0/100] Initial Loss: 0.1341, Training Loss: 0.1341, Initial Validation Loss: 0.1254, Validation Loss: 0.1254,V Acc: 0.4000, Top 70th Acc: 0.5065, Bottom 30th Acc: 0.1515
Fold [3/5] Epoch [10/100] Initial Loss: 0.1341, Training Loss: 0.0811, Initial Validation Loss: 0.1254, Validation Loss: 0.0792,V Acc: 0.6182, Top 70th Acc: 0.7273, Bottom 30th Acc: 0.3636
Stopping early at Epoch (base 0): 17  Rolling back to Epoch (base 0): 12  Top Validation Acc: 0.7402597402597403
Fold [4/5] Epoch [0/100] Initial Loss: 0.1366, Training Loss: 0.1366, Initial Validation Loss: 0.1301, Validation Loss: 0.1301,V Acc: 0.2636, Top 70th Acc: 0.3636, Bottom 30th Acc: 0.0303
Fold [4/5] Epoch [10/100] Initial Loss: 0.1366, Training Loss: 0.0805, Initial Validation Loss: 0.1301, Validation Loss: 0.0806,V Acc: 0.6364, Top 70th Acc: 0.7403, Bottom 30th Acc: 0.3939
Fold [4/5] Epoch [20/100] Initial Loss: 0.1366, Training Loss: 0.0779, Initial Validation Loss: 0.1301, Validation Loss: 0.0798,V Acc: 0.6364, Top 70th Acc: 0.7403, Bottom 30th Acc: 0.3939
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.7402597402597403
90 3 [array([0.1278562 , 0.33293286, 0.15305713, 0.24328893, 0.14286494],
      dtype=float32)]
Fold [5/5] Epoch [0/100] Initial Loss: 0.1352, Training Loss: 0.1352, Initial Validation Loss: 0.1220, Validation Loss: 0.1220,V Acc: 0.5185, Top 70th Acc: 0.5658, Bottom 30th Acc: 0.4062
Fold [5/5] Epoch [10/100] Initial Loss: 0.1352, Training Loss: 0.0832, Initial Validation Loss: 0.1220, Validation Loss: 0.0725,V Acc: 0.6574, Top 70th Acc: 0.7500, Bottom 30th Acc: 0.4375
Fold [5/5] Epoch [20/100] Initial Loss: 0.1352, Training Loss: 0.0813, Initial Validation Loss: 0.1220, Validation Loss: 0.0700,V Acc: 0.6389, Top 70th Acc: 0.7500, Bottom 30th Acc: 0.3750
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.75
Running train_nn.py with seed 91
CUDA:False
Training samples count:  550
Training on 2 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1330, Training Loss: 0.1330, Initial Validation Loss: 0.1271, Validation Loss: 0.1271,V Acc: 0.3964, Top 70th Acc: 0.4744, Bottom 30th Acc: 0.2121
Fold [1/5] Epoch [10/100] Initial Loss: 0.1330, Training Loss: 0.0794, Initial Validation Loss: 0.1271, Validation Loss: 0.0888,V Acc: 0.6216, Top 70th Acc: 0.6667, Bottom 30th Acc: 0.5152
Fold [1/5] Epoch [20/100] Initial Loss: 0.1330, Training Loss: 0.0765, Initial Validation Loss: 0.1271, Validation Loss: 0.0884,V Acc: 0.5946, Top 70th Acc: 0.6667, Bottom 30th Acc: 0.4242
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.6794871794871795
Fold [2/5] Epoch [0/100] Initial Loss: 0.1365, Training Loss: 0.1365, Initial Validation Loss: 0.1261, Validation Loss: 0.1261,V Acc: 0.2883, Top 70th Acc: 0.3590, Bottom 30th Acc: 0.1212
Fold [2/5] Epoch [10/100] Initial Loss: 0.1365, Training Loss: 0.0845, Initial Validation Loss: 0.1261, Validation Loss: 0.0674,V Acc: 0.6757, Top 70th Acc: 0.7949, Bottom 30th Acc: 0.3939
Fold [2/5] Epoch [20/100] Initial Loss: 0.1365, Training Loss: 0.0825, Initial Validation Loss: 0.1261, Validation Loss: 0.0660,V Acc: 0.6937, Top 70th Acc: 0.7949, Bottom 30th Acc: 0.4545
Fold [2/5] Epoch [30/100] Initial Loss: 0.1365, Training Loss: 0.0822, Initial Validation Loss: 0.1261, Validation Loss: 0.0649,V Acc: 0.6847, Top 70th Acc: 0.8077, Bottom 30th Acc: 0.3939
Fold [5/5] Epoch [20/100] Initial Loss: 0.1373, Training Loss: 0.0186, Initial Validation Loss: 0.1322, Validation Loss: 0.0272,V Acc: 0.8519, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.6562
Stopping early at Epoch (base 0): 28  Rolling back to Epoch (base 0): 23  Top Validation Acc: 0.9473684210526315
Running train_nn.py with seed 95
CUDA:False
Training samples count:  550
Training on 30 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1361, Training Loss: 0.1361, Initial Validation Loss: 0.1388, Validation Loss: 0.1388,V Acc: 0.2973, Top 70th Acc: 0.2949, Bottom 30th Acc: 0.3030
Fold [1/5] Epoch [10/100] Initial Loss: 0.1361, Training Loss: 0.0347, Initial Validation Loss: 0.1388, Validation Loss: 0.0344,V Acc: 0.8649, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.6061
Fold [1/5] Epoch [20/100] Initial Loss: 0.1361, Training Loss: 0.0195, Initial Validation Loss: 0.1388, Validation Loss: 0.0239,V Acc: 0.9099, Top 70th Acc: 1.0000, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 1.0
Fold [2/5] Epoch [0/100] Initial Loss: 0.1381, Training Loss: 0.1381, Initial Validation Loss: 0.1321, Validation Loss: 0.1321,V Acc: 0.3694, Top 70th Acc: 0.3718, Bottom 30th Acc: 0.3636
Fold [2/5] Epoch [10/100] Initial Loss: 0.1381, Training Loss: 0.0264, Initial Validation Loss: 0.1321, Validation Loss: 0.0336,V Acc: 0.8108, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.5758
Fold [2/5] Epoch [20/100] Initial Loss: 0.1381, Training Loss: 0.0172, Initial Validation Loss: 0.1321, Validation Loss: 0.0279,V Acc: 0.8559, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 29  Rolling back to Epoch (base 0): 24  Top Validation Acc: 0.9487179487179487
Fold [3/5] Epoch [0/100] Initial Loss: 0.1384, Training Loss: 0.1384, Initial Validation Loss: 0.1369, Validation Loss: 0.1369,V Acc: 0.2727, Top 70th Acc: 0.3636, Bottom 30th Acc: 0.0606
Fold [3/5] Epoch [10/100] Initial Loss: 0.1384, Training Loss: 0.0415, Initial Validation Loss: 0.1369, Validation Loss: 0.0509,V Acc: 0.7818, Top 70th Acc: 0.8831, Bottom 30th Acc: 0.5455
Fold [3/5] Epoch [20/100] Initial Loss: 0.1384, Training Loss: 0.0182, Initial Validation Loss: 0.1369, Validation Loss: 0.0328,V Acc: 0.8545, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.6667
Fold [3/5] Epoch [30/100] Initial Loss: 0.1384, Training Loss: 0.0146, Initial Validation Loss: 0.1369, Validation Loss: 0.0336,V Acc: 0.8455, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 30  Rolling back to Epoch (base 0): 25  Top Validation Acc: 0.948051948051948
Fold [4/5] Epoch [0/100] Initial Loss: 0.1386, Training Loss: 0.1386, Initial Validation Loss: 0.1299, Validation Loss: 0.1299,V Acc: 0.3182, Top 70th Acc: 0.3766, Bottom 30th Acc: 0.1818
Fold [4/5] Epoch [10/100] Initial Loss: 0.1386, Training Loss: 0.0282, Initial Validation Loss: 0.1299, Validation Loss: 0.0501,V Acc: 0.7273, Top 70th Acc: 0.8701, Bottom 30th Acc: 0.3939
Fold [4/5] Epoch [20/100] Initial Loss: 0.1386, Training Loss: 0.0141, Initial Validation Loss: 0.1299, Validation Loss: 0.0430,V Acc: 0.7455, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.3636
Stopping early at Epoch (base 0): 28  Rolling back to Epoch (base 0): 23  Top Validation Acc: 0.9090909090909091
Fold [5/5] Epoch [0/100] Initial Loss: 0.1395, Training Loss: 0.1395, Initial Validation Loss: 0.1296, Validation Loss: 0.1296,V Acc: 0.2963, Top 70th Acc: 0.3421, Bottom 30th Acc: 0.1875
Fold [5/5] Epoch [10/100] Initial Loss: 0.1395, Training Loss: 0.0325, Initial Validation Loss: 0.1296, Validation Loss: 0.0330,V Acc: 0.8519, Top 70th Acc: 0.9211, Bottom 30th Acc: 0.6875
Fold [5/5] Epoch [20/100] Initial Loss: 0.1395, Training Loss: 0.0189, Initial Validation Loss: 0.1296, Validation Loss: 0.0219,V Acc: 0.8889, Top 70th Acc: 0.9737, Bottom 30th Acc: 0.6875
Fold [5/5] Epoch [30/100] Initial Loss: 0.1395, Training Loss: 0.0165, Initial Validation Loss: 0.1296, Validation Loss: 0.0206,V Acc: 0.8796, Top 70th Acc: 0.9868, Bottom 30th Acc: 0.6250
Stopping early at Epoch (base 0): 32  Rolling back to Epoch (base 0): 27  Top Validation Acc: 0.9868421052631579
95 4 [array([0.5435619 , 0.03383422, 0.07120848, 0.0879672 , 0.26342833],
      dtype=float32)]
Running train_nn.py with seed 96
CUDA:False
Training samples count:  550
Training on 30 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1400, Training Loss: 0.1400, Initial Validation Loss: 0.1372, Validation Loss: 0.1372,V Acc: 0.2793, Top 70th Acc: 0.3077, Bottom 30th Acc: 0.2121
Fold [1/5] Epoch [10/100] Initial Loss: 0.1400, Training Loss: 0.0420, Initial Validation Loss: 0.1372, Validation Loss: 0.0550,V Acc: 0.7387, Top 70th Acc: 0.8333, Bottom 30th Acc: 0.5152
Fold [1/5] Epoch [20/100] Initial Loss: 0.1400, Training Loss: 0.0185, Initial Validation Loss: 0.1372, Validation Loss: 0.0327,V Acc: 0.8198, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.5152
Fold [1/5] Epoch [30/100] Initial Loss: 0.1400, Training Loss: 0.0150, Initial Validation Loss: 0.1372, Validation Loss: 0.0319,V Acc: 0.8288, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.5152
Stopping early at Epoch (base 0): 39  Rolling back to Epoch (base 0): 34  Top Validation Acc: 0.9487179487179487
Fold [2/5] Epoch [0/100] Initial Loss: 0.1393, Training Loss: 0.1393, Initial Validation Loss: 0.1344, Validation Loss: 0.1344,V Acc: 0.4054, Top 70th Acc: 0.4615, Bottom 30th Acc: 0.2727
Fold [2/5] Epoch [10/100] Initial Loss: 0.1393, Training Loss: 0.0401, Initial Validation Loss: 0.1344, Validation Loss: 0.0367,V Acc: 0.8468, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.6364
Fold [2/5] Epoch [20/100] Initial Loss: 0.1393, Training Loss: 0.0192, Initial Validation Loss: 0.1344, Validation Loss: 0.0259,V Acc: 0.8288, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.5152
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.9615384615384616
Fold [3/5] Epoch [0/100] Initial Loss: 0.1410, Training Loss: 0.1410, Initial Validation Loss: 0.1364, Validation Loss: 0.1364,V Acc: 0.2636, Top 70th Acc: 0.3377, Bottom 30th Acc: 0.0909
Fold [3/5] Epoch [10/100] Initial Loss: 0.1410, Training Loss: 0.0321, Initial Validation Loss: 0.1364, Validation Loss: 0.0317,V Acc: 0.8818, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.7576
Fold [3/5] Epoch [20/100] Initial Loss: 0.1410, Training Loss: 0.0192, Initial Validation Loss: 0.1364, Validation Loss: 0.0274,V Acc: 0.8909, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.7273
Stopping early at Epoch (base 0): 21  Rolling back to Epoch (base 0): 16  Top Validation Acc: 0.961038961038961
Fold [4/5] Epoch [0/100] Initial Loss: 0.1410, Training Loss: 0.1410, Initial Validation Loss: 0.1318, Validation Loss: 0.1318,V Acc: 0.3091, Top 70th Acc: 0.3506, Bottom 30th Acc: 0.2121
Fold [4/5] Epoch [10/100] Initial Loss: 0.1410, Training Loss: 0.0400, Initial Validation Loss: 0.1318, Validation Loss: 0.0465,V Acc: 0.7545, Top 70th Acc: 0.8831, Bottom 30th Acc: 0.4545
Fold [4/5] Epoch [20/100] Initial Loss: 0.1410, Training Loss: 0.0171, Initial Validation Loss: 0.1318, Validation Loss: 0.0392,V Acc: 0.8000, Top 70th Acc: 0.8961, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 20  Rolling back to Epoch (base 0): 15  Top Validation Acc: 0.8961038961038961
Fold [5/5] Epoch [0/100] Initial Loss: 0.1425, Training Loss: 0.1425, Initial Validation Loss: 0.1331, Validation Loss: 0.1331,V Acc: 0.2500, Top 70th Acc: 0.2895, Bottom 30th Acc: 0.1562
Fold [5/5] Epoch [10/100] Initial Loss: 0.1425, Training Loss: 0.0260, Initial Validation Loss: 0.1331, Validation Loss: 0.0350,V Acc: 0.8241, Top 70th Acc: 0.9079, Bottom 30th Acc: 0.6250
Stopping early at Epoch (base 0): 18  Rolling back to Epoch (base 0): 13  Top Validation Acc: 0.9210526315789473
96 4 [array([0.5784962 , 0.09243352, 0.06042487, 0.10444874, 0.16419663],
      dtype=float32)]
Running train_nn.py with seed 97
CUDA:False
Training samples count:  550
Training on 30 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1369, Training Loss: 0.1369, Initial Validation Loss: 0.1364, Validation Loss: 0.1364,V Acc: 0.3243, Top 70th Acc: 0.3590, Bottom 30th Acc: 0.2424
Fold [1/5] Epoch [10/100] Initial Loss: 0.1369, Training Loss: 0.0279, Initial Validation Loss: 0.1364, Validation Loss: 0.0356,V Acc: 0.8559, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.7273
Stopping early at Epoch (base 0): 28  Rolling back to Epoch (base 0): 23  Top Validation Acc: 0.961038961038961
Fold [4/5] Epoch [0/100] Initial Loss: 0.1406, Training Loss: 0.1406, Initial Validation Loss: 0.1344, Validation Loss: 0.1344,V Acc: 0.2727, Top 70th Acc: 0.2727, Bottom 30th Acc: 0.2727
Fold [4/5] Epoch [10/100] Initial Loss: 0.1406, Training Loss: 0.0339, Initial Validation Loss: 0.1344, Validation Loss: 0.0392,V Acc: 0.8364, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.6667
Fold [4/5] Epoch [20/100] Initial Loss: 0.1406, Training Loss: 0.0241, Initial Validation Loss: 0.1344, Validation Loss: 0.0315,V Acc: 0.8545, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6364
Fold [4/5] Epoch [30/100] Initial Loss: 0.1406, Training Loss: 0.0222, Initial Validation Loss: 0.1344, Validation Loss: 0.0307,V Acc: 0.8636, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 33  Rolling back to Epoch (base 0): 28  Top Validation Acc: 0.948051948051948
Fold [5/5] Epoch [0/100] Initial Loss: 0.1378, Training Loss: 0.1378, Initial Validation Loss: 0.1281, Validation Loss: 0.1281,V Acc: 0.2685, Top 70th Acc: 0.3289, Bottom 30th Acc: 0.1250
Fold [5/5] Epoch [10/100] Initial Loss: 0.1378, Training Loss: 0.0296, Initial Validation Loss: 0.1281, Validation Loss: 0.0419,V Acc: 0.7870, Top 70th Acc: 0.8421, Bottom 30th Acc: 0.6562
Fold [5/5] Epoch [20/100] Initial Loss: 0.1378, Training Loss: 0.0209, Initial Validation Loss: 0.1281, Validation Loss: 0.0397,V Acc: 0.7593, Top 70th Acc: 0.8947, Bottom 30th Acc: 0.4375
Stopping early at Epoch (base 0): 27  Rolling back to Epoch (base 0): 22  Top Validation Acc: 0.8947368421052632
Running train_nn.py with seed 98
CUDA:False
Training samples count:  550
Training on 20 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1329, Training Loss: 0.1329, Initial Validation Loss: 0.1325, Validation Loss: 0.1325,V Acc: 0.4685, Top 70th Acc: 0.5256, Bottom 30th Acc: 0.3333
Fold [1/5] Epoch [10/100] Initial Loss: 0.1329, Training Loss: 0.0342, Initial Validation Loss: 0.1325, Validation Loss: 0.0356,V Acc: 0.8288, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.4848
Fold [1/5] Epoch [20/100] Initial Loss: 0.1329, Training Loss: 0.0248, Initial Validation Loss: 0.1325, Validation Loss: 0.0293,V Acc: 0.8649, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.6061
Fold [1/5] Epoch [30/100] Initial Loss: 0.1329, Training Loss: 0.0220, Initial Validation Loss: 0.1325, Validation Loss: 0.0285,V Acc: 0.8468, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 31  Rolling back to Epoch (base 0): 26  Top Validation Acc: 0.9615384615384616
98 0 [array([0.22211207, 0.09233586, 0.18312642, 0.25860128, 0.24382429],
      dtype=float32)]
Fold [2/5] Epoch [0/100] Initial Loss: 0.1392, Training Loss: 0.1392, Initial Validation Loss: 0.1286, Validation Loss: 0.1286,V Acc: 0.3243, Top 70th Acc: 0.3718, Bottom 30th Acc: 0.2121
Fold [2/5] Epoch [10/100] Initial Loss: 0.1392, Training Loss: 0.0424, Initial Validation Loss: 0.1286, Validation Loss: 0.0520,V Acc: 0.7117, Top 70th Acc: 0.8077, Bottom 30th Acc: 0.4848
Fold [2/5] Epoch [20/100] Initial Loss: 0.1392, Training Loss: 0.0244, Initial Validation Loss: 0.1286, Validation Loss: 0.0419,V Acc: 0.7568, Top 70th Acc: 0.8462, Bottom 30th Acc: 0.5455
Fold [2/5] Epoch [30/100] Initial Loss: 0.1392, Training Loss: 0.0202, Initial Validation Loss: 0.1286, Validation Loss: 0.0390,V Acc: 0.7838, Top 70th Acc: 0.8590, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 38  Rolling back to Epoch (base 0): 33  Top Validation Acc: 0.8846153846153846
Fold [3/5] Epoch [0/100] Initial Loss: 0.1415, Training Loss: 0.1415, Initial Validation Loss: 0.1390, Validation Loss: 0.1390,V Acc: 0.2455, Top 70th Acc: 0.2468, Bottom 30th Acc: 0.2424
Fold [3/5] Epoch [10/100] Initial Loss: 0.1415, Training Loss: 0.0375, Initial Validation Loss: 0.1390, Validation Loss: 0.0490,V Acc: 0.7727, Top 70th Acc: 0.8701, Bottom 30th Acc: 0.5455
Fold [3/5] Epoch [20/100] Initial Loss: 0.1415, Training Loss: 0.0236, Initial Validation Loss: 0.1390, Validation Loss: 0.0338,V Acc: 0.8636, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 27  Rolling back to Epoch (base 0): 22  Top Validation Acc: 0.961038961038961
Fold [4/5] Epoch [0/100] Initial Loss: 0.1383, Training Loss: 0.1383, Initial Validation Loss: 0.1320, Validation Loss: 0.1320,V Acc: 0.2727, Top 70th Acc: 0.3506, Bottom 30th Acc: 0.0909
Fold [4/5] Epoch [10/100] Initial Loss: 0.1383, Training Loss: 0.0321, Initial Validation Loss: 0.1320, Validation Loss: 0.0338,V Acc: 0.8636, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 19  Rolling back to Epoch (base 0): 14  Top Validation Acc: 0.922077922077922
Fold [5/5] Epoch [0/100] Initial Loss: 0.1367, Training Loss: 0.1367, Initial Validation Loss: 0.1318, Validation Loss: 0.1318,V Acc: 0.3426, Top 70th Acc: 0.3684, Bottom 30th Acc: 0.2812
Fold [5/5] Epoch [10/100] Initial Loss: 0.1367, Training Loss: 0.0426, Initial Validation Loss: 0.1318, Validation Loss: 0.0398,V Acc: 0.8426, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.5938
Fold [5/5] Epoch [20/100] Initial Loss: 0.1367, Training Loss: 0.0255, Initial Validation Loss: 0.1318, Validation Loss: 0.0296,V Acc: 0.8796, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.7188
Fold [5/5] Epoch [30/100] Initial Loss: 0.1367, Training Loss: 0.0211, Initial Validation Loss: 0.1318, Validation Loss: 0.0281,V Acc: 0.8981, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.8125
Stopping early at Epoch (base 0): 30  Rolling back to Epoch (base 0): 25  Top Validation Acc: 0.9342105263157895
Running train_nn.py with seed 99
CUDA:False
Training samples count:  550
Training on 20 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1376, Training Loss: 0.1376, Initial Validation Loss: 0.1302, Validation Loss: 0.1302,V Acc: 0.2973, Top 70th Acc: 0.3590, Bottom 30th Acc: 0.1515
Fold [1/5] Epoch [10/100] Initial Loss: 0.1376, Training Loss: 0.0376, Initial Validation Loss: 0.1302, Validation Loss: 0.0424,V Acc: 0.7928, Top 70th Acc: 0.8846, Bottom 30th Acc: 0.5758
Fold [1/5] Epoch [20/100] Initial Loss: 0.1376, Training Loss: 0.0277, Initial Validation Loss: 0.1302, Validation Loss: 0.0336,V Acc: 0.8288, Top 70th Acc: 0.8974, Bottom 30th Acc: 0.6667
Fold [1/5] Epoch [30/100] Initial Loss: 0.1376, Training Loss: 0.0234, Initial Validation Loss: 0.1302, Validation Loss: 0.0281,V Acc: 0.8739, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.7273
Stopping early at Epoch (base 0): 36  Rolling back to Epoch (base 0): 31  Top Validation Acc: 0.9358974358974359
Fold [2/5] Epoch [0/100] Initial Loss: 0.1354, Training Loss: 0.1354, Initial Validation Loss: 0.1348, Validation Loss: 0.1348,V Acc: 0.2973, Top 70th Acc: 0.3462, Bottom 30th Acc: 0.1818
Fold [2/5] Epoch [10/100] Initial Loss: 0.1354, Training Loss: 0.0389, Initial Validation Loss: 0.1348, Validation Loss: 0.0382,V Acc: 0.8468, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.6667
Fold [2/5] Epoch [20/100] Initial Loss: 0.1354, Training Loss: 0.0247, Initial Validation Loss: 0.1348, Validation Loss: 0.0293,V Acc: 0.8919, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.7879
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.9358974358974359
Fold [3/5] Epoch [0/100] Initial Loss: 0.1398, Training Loss: 0.1398, Initial Validation Loss: 0.1321, Validation Loss: 0.1321,V Acc: 0.3182, Top 70th Acc: 0.3506, Bottom 30th Acc: 0.2424
Fold [3/5] Epoch [10/100] Initial Loss: 0.1398, Training Loss: 0.0359, Initial Validation Loss: 0.1321, Validation Loss: 0.0424,V Acc: 0.8000, Top 70th Acc: 0.8961, Bottom 30th Acc: 0.5758
Fold [3/5] Epoch [20/100] Initial Loss: 0.1398, Training Loss: 0.0226, Initial Validation Loss: 0.1321, Validation Loss: 0.0354,V Acc: 0.8273, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.8961038961038961
Fold [4/5] Epoch [0/100] Initial Loss: 0.1348, Training Loss: 0.1348, Initial Validation Loss: 0.1285, Validation Loss: 0.1285,V Acc: 0.3636, Top 70th Acc: 0.3377, Bottom 30th Acc: 0.4242
Fold [4/5] Epoch [10/100] Initial Loss: 0.1348, Training Loss: 0.0376, Initial Validation Loss: 0.1285, Validation Loss: 0.0369,V Acc: 0.8545, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.6667
Fold [4/5] Epoch [10/100] Initial Loss: 0.1392, Training Loss: 0.0181, Initial Validation Loss: 0.1362, Validation Loss: 0.0338,V Acc: 0.8818, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.6970
Fold [4/5] Epoch [20/100] Initial Loss: 0.1392, Training Loss: 0.0053, Initial Validation Loss: 0.1362, Validation Loss: 0.0282,V Acc: 0.8909, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.7273
Stopping early at Epoch (base 0): 27  Rolling back to Epoch (base 0): 22  Top Validation Acc: 0.961038961038961
72 3 [array([0.37246516, 0.0280227 , 0.10432519, 0.1364734 , 0.35871363],
      dtype=float32)]
Fold [5/5] Epoch [0/100] Initial Loss: 0.1391, Training Loss: 0.1391, Initial Validation Loss: 0.1306, Validation Loss: 0.1306,V Acc: 0.2593, Top 70th Acc: 0.3553, Bottom 30th Acc: 0.0312
Fold [5/5] Epoch [10/100] Initial Loss: 0.1391, Training Loss: 0.0158, Initial Validation Loss: 0.1306, Validation Loss: 0.0386,V Acc: 0.7963, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.4688
Fold [5/5] Epoch [20/100] Initial Loss: 0.1391, Training Loss: 0.0052, Initial Validation Loss: 0.1306, Validation Loss: 0.0356,V Acc: 0.7963, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.4688
Fold [5/5] Epoch [30/100] Initial Loss: 0.1391, Training Loss: 0.0039, Initial Validation Loss: 0.1306, Validation Loss: 0.0346,V Acc: 0.7870, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.4375
Fold [5/5] Epoch [40/100] Initial Loss: 0.1391, Training Loss: 0.0035, Initial Validation Loss: 0.1306, Validation Loss: 0.0334,V Acc: 0.8148, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.5312
Fold [5/5] Epoch [50/100] Initial Loss: 0.1391, Training Loss: 0.0033, Initial Validation Loss: 0.1306, Validation Loss: 0.0330,V Acc: 0.8148, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.5312
Stopping early at Epoch (base 0): 56  Rolling back to Epoch (base 0): 51  Top Validation Acc: 0.9473684210526315
Running train_nn.py with seed 73
CUDA:False
Training samples count:  550
Training on 163 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1377, Training Loss: 0.1377, Initial Validation Loss: 0.1339, Validation Loss: 0.1339,V Acc: 0.2703, Top 70th Acc: 0.3333, Bottom 30th Acc: 0.1212
Fold [1/5] Epoch [10/100] Initial Loss: 0.1377, Training Loss: 0.0139, Initial Validation Loss: 0.1339, Validation Loss: 0.0344,V Acc: 0.8378, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.5758
Fold [1/5] Epoch [20/100] Initial Loss: 0.1377, Training Loss: 0.0046, Initial Validation Loss: 0.1339, Validation Loss: 0.0295,V Acc: 0.8739, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.9487179487179487
73 0 [array([0.35276705, 0.04489022, 0.08845659, 0.19869073, 0.31519538],
      dtype=float32)]
Fold [2/5] Epoch [0/100] Initial Loss: 0.1398, Training Loss: 0.1398, Initial Validation Loss: 0.1317, Validation Loss: 0.1317,V Acc: 0.3694, Top 70th Acc: 0.4744, Bottom 30th Acc: 0.1212
Fold [2/5] Epoch [10/100] Initial Loss: 0.1398, Training Loss: 0.0144, Initial Validation Loss: 0.1317, Validation Loss: 0.0344,V Acc: 0.8378, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.6667
Fold [2/5] Epoch [20/100] Initial Loss: 0.1398, Training Loss: 0.0048, Initial Validation Loss: 0.1317, Validation Loss: 0.0300,V Acc: 0.8559, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.7273
Stopping early at Epoch (base 0): 27  Rolling back to Epoch (base 0): 22  Top Validation Acc: 0.9102564102564102
Fold [3/5] Epoch [0/100] Initial Loss: 0.1383, Training Loss: 0.1383, Initial Validation Loss: 0.1310, Validation Loss: 0.1310,V Acc: 0.4091, Top 70th Acc: 0.4416, Bottom 30th Acc: 0.3333
Fold [3/5] Epoch [10/100] Initial Loss: 0.1383, Training Loss: 0.0175, Initial Validation Loss: 0.1310, Validation Loss: 0.0351,V Acc: 0.8455, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.6364
Fold [3/5] Epoch [20/100] Initial Loss: 0.1383, Training Loss: 0.0050, Initial Validation Loss: 0.1310, Validation Loss: 0.0298,V Acc: 0.8545, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.935064935064935
Fold [4/5] Epoch [0/100] Initial Loss: 0.1384, Training Loss: 0.1384, Initial Validation Loss: 0.1376, Validation Loss: 0.1376,V Acc: 0.2545, Top 70th Acc: 0.3377, Bottom 30th Acc: 0.0606
Fold [4/5] Epoch [10/100] Initial Loss: 0.1384, Training Loss: 0.0140, Initial Validation Loss: 0.1376, Validation Loss: 0.0305,V Acc: 0.8818, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.6667
Fold [4/5] Epoch [20/100] Initial Loss: 0.1384, Training Loss: 0.0051, Initial Validation Loss: 0.1376, Validation Loss: 0.0263,V Acc: 0.8727, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.6364
Fold [4/5] Epoch [30/100] Initial Loss: 0.1384, Training Loss: 0.0041, Initial Validation Loss: 0.1376, Validation Loss: 0.0262,V Acc: 0.8636, Top 70th Acc: 0.9870, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 36  Rolling back to Epoch (base 0): 31  Top Validation Acc: 0.987012987012987
Fold [5/5] Epoch [0/100] Initial Loss: 0.1388, Training Loss: 0.1388, Initial Validation Loss: 0.1335, Validation Loss: 0.1335,V Acc: 0.3981, Top 70th Acc: 0.5000, Bottom 30th Acc: 0.1562
Fold [5/5] Epoch [10/100] Initial Loss: 0.1388, Training Loss: 0.0141, Initial Validation Loss: 0.1335, Validation Loss: 0.0352,V Acc: 0.8426, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.6250
Fold [5/5] Epoch [20/100] Initial Loss: 0.1388, Training Loss: 0.0044, Initial Validation Loss: 0.1335, Validation Loss: 0.0321,V Acc: 0.8519, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.6250
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.9342105263157895
Running train_nn.py with seed 74
CUDA:False
Training samples count:  550
Training on 163 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1380, Training Loss: 0.1380, Initial Validation Loss: 0.1357, Validation Loss: 0.1357,V Acc: 0.2523, Top 70th Acc: 0.3333, Bottom 30th Acc: 0.0606
Fold [1/5] Epoch [10/100] Initial Loss: 0.1380, Training Loss: 0.0272, Initial Validation Loss: 0.1357, Validation Loss: 0.0400,V Acc: 0.8468, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.6667
Fold [1/5] Epoch [20/100] Initial Loss: 0.1380, Training Loss: 0.0054, Initial Validation Loss: 0.1357, Validation Loss: 0.0272,V Acc: 0.8559, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.6061
Fold [1/5] Epoch [30/100] Initial Loss: 0.1380, Training Loss: 0.0042, Initial Validation Loss: 0.1357, Validation Loss: 0.0263,V Acc: 0.8649, Top 70th Acc: 0.9872, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 31  Rolling back to Epoch (base 0): 26  Top Validation Acc: 0.9743589743589743
Fold [2/5] Epoch [0/100] Initial Loss: 0.1385, Training Loss: 0.1385, Initial Validation Loss: 0.1386, Validation Loss: 0.1386,V Acc: 0.3153, Top 70th Acc: 0.3333, Bottom 30th Acc: 0.2727
Fold [2/5] Epoch [10/100] Initial Loss: 0.1385, Training Loss: 0.0179, Initial Validation Loss: 0.1386, Validation Loss: 0.0309,V Acc: 0.8919, Top 70th Acc: 0.9872, Bottom 30th Acc: 0.6667
Fold [2/5] Epoch [20/100] Initial Loss: 0.1385, Training Loss: 0.0041, Initial Validation Loss: 0.1386, Validation Loss: 0.0266,V Acc: 0.8739, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 21  Rolling back to Epoch (base 0): 16  Top Validation Acc: 0.9615384615384616
Fold [3/5] Epoch [0/100] Initial Loss: 0.1383, Training Loss: 0.1383, Initial Validation Loss: 0.1335, Validation Loss: 0.1335,V Acc: 0.3273, Top 70th Acc: 0.3636, Bottom 30th Acc: 0.2424
Fold [3/5] Epoch [10/100] Initial Loss: 0.1383, Training Loss: 0.0129, Initial Validation Loss: 0.1335, Validation Loss: 0.0333,V Acc: 0.8545, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.6970
Fold [3/5] Epoch [20/100] Initial Loss: 0.1383, Training Loss: 0.0045, Initial Validation Loss: 0.1335, Validation Loss: 0.0320,V Acc: 0.8455, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.935064935064935
74 2 [array([0.29173908, 0.05234979, 0.06547925, 0.33435565, 0.25607628],
      dtype=float32)]
Fold [4/5] Epoch [0/100] Initial Loss: 0.1398, Training Loss: 0.1398, Initial Validation Loss: 0.1363, Validation Loss: 0.1363,V Acc: 0.2545, Top 70th Acc: 0.3117, Bottom 30th Acc: 0.1212/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)

Stopping early at Epoch (base 0): 33  Rolling back to Epoch (base 0): 28  Top Validation Acc: 0.8076923076923077
Fold [3/5] Epoch [0/100] Initial Loss: 0.1378, Training Loss: 0.1378, Initial Validation Loss: 0.1275, Validation Loss: 0.1275,V Acc: 0.4636, Top 70th Acc: 0.4935, Bottom 30th Acc: 0.3939
Fold [3/5] Epoch [10/100] Initial Loss: 0.1378, Training Loss: 0.0769, Initial Validation Loss: 0.1275, Validation Loss: 0.0912,V Acc: 0.5818, Top 70th Acc: 0.6883, Bottom 30th Acc: 0.3333
Stopping early at Epoch (base 0): 18  Rolling back to Epoch (base 0): 13  Top Validation Acc: 0.6883116883116883
Fold [4/5] Epoch [0/100] Initial Loss: 0.1356, Training Loss: 0.1356, Initial Validation Loss: 0.1305, Validation Loss: 0.1305,V Acc: 0.2909, Top 70th Acc: 0.3636, Bottom 30th Acc: 0.1212
Fold [4/5] Epoch [10/100] Initial Loss: 0.1356, Training Loss: 0.0807, Initial Validation Loss: 0.1305, Validation Loss: 0.0815,V Acc: 0.6182, Top 70th Acc: 0.7403, Bottom 30th Acc: 0.3333
Fold [4/5] Epoch [20/100] Initial Loss: 0.1356, Training Loss: 0.0787, Initial Validation Loss: 0.1305, Validation Loss: 0.0803,V Acc: 0.6182, Top 70th Acc: 0.7403, Bottom 30th Acc: 0.3333
Fold [4/5] Epoch [30/100] Initial Loss: 0.1356, Training Loss: 0.0779, Initial Validation Loss: 0.1305, Validation Loss: 0.0789,V Acc: 0.6182, Top 70th Acc: 0.7403, Bottom 30th Acc: 0.3333
Stopping early at Epoch (base 0): 33  Rolling back to Epoch (base 0): 28  Top Validation Acc: 0.7532467532467533
Fold [5/5] Epoch [0/100] Initial Loss: 0.1293, Training Loss: 0.1293, Initial Validation Loss: 0.1122, Validation Loss: 0.1122,V Acc: 0.3796, Top 70th Acc: 0.4737, Bottom 30th Acc: 0.1562
Fold [5/5] Epoch [10/100] Initial Loss: 0.1293, Training Loss: 0.0826, Initial Validation Loss: 0.1122, Validation Loss: 0.0743,V Acc: 0.6481, Top 70th Acc: 0.7895, Bottom 30th Acc: 0.3125
Fold [5/5] Epoch [20/100] Initial Loss: 0.1293, Training Loss: 0.0807, Initial Validation Loss: 0.1122, Validation Loss: 0.0704,V Acc: 0.6667, Top 70th Acc: 0.8158, Bottom 30th Acc: 0.3125
Fold [5/5] Epoch [30/100] Initial Loss: 0.1293, Training Loss: 0.0804, Initial Validation Loss: 0.1122, Validation Loss: 0.0697,V Acc: 0.6759, Top 70th Acc: 0.8026, Bottom 30th Acc: 0.3750
Fold [5/5] Epoch [40/100] Initial Loss: 0.1293, Training Loss: 0.0798, Initial Validation Loss: 0.1122, Validation Loss: 0.0695,V Acc: 0.6389, Top 70th Acc: 0.8026, Bottom 30th Acc: 0.2500
Stopping early at Epoch (base 0): 42  Rolling back to Epoch (base 0): 37  Top Validation Acc: 0.7894736842105263
91 4 [array([0.12447619, 0.33427978, 0.16533178, 0.22885372, 0.14705853],
      dtype=float32)]
Running train_nn.py with seed 92
CUDA:False
Training samples count:  550
Training on 2 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1405, Training Loss: 0.1405, Initial Validation Loss: 0.1302, Validation Loss: 0.1302,V Acc: 0.2523, Top 70th Acc: 0.3590, Bottom 30th Acc: 0.0000
Fold [1/5] Epoch [10/100] Initial Loss: 0.1405, Training Loss: 0.0801, Initial Validation Loss: 0.1302, Validation Loss: 0.0816,V Acc: 0.6036, Top 70th Acc: 0.7051, Bottom 30th Acc: 0.3636
Fold [1/5] Epoch [20/100] Initial Loss: 0.1405, Training Loss: 0.0781, Initial Validation Loss: 0.1302, Validation Loss: 0.0798,V Acc: 0.6036, Top 70th Acc: 0.7436, Bottom 30th Acc: 0.2727
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.7051282051282052
92 0 [array([0.14069165, 0.33321148, 0.1306789 , 0.22799985, 0.16741808],
      dtype=float32)]
Fold [2/5] Epoch [0/100] Initial Loss: 0.1355, Training Loss: 0.1355, Initial Validation Loss: 0.1282, Validation Loss: 0.1282,V Acc: 0.4054, Top 70th Acc: 0.4615, Bottom 30th Acc: 0.2727
Fold [2/5] Epoch [10/100] Initial Loss: 0.1355, Training Loss: 0.0815, Initial Validation Loss: 0.1282, Validation Loss: 0.0811,V Acc: 0.6036, Top 70th Acc: 0.7564, Bottom 30th Acc: 0.2424
Fold [2/5] Epoch [20/100] Initial Loss: 0.1355, Training Loss: 0.0782, Initial Validation Loss: 0.1282, Validation Loss: 0.0786,V Acc: 0.6216, Top 70th Acc: 0.7564, Bottom 30th Acc: 0.3030
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.7564102564102564
Fold [3/5] Epoch [0/100] Initial Loss: 0.1395, Training Loss: 0.1395, Initial Validation Loss: 0.1339, Validation Loss: 0.1339,V Acc: 0.2545, Top 70th Acc: 0.3506, Bottom 30th Acc: 0.0303
Fold [3/5] Epoch [10/100] Initial Loss: 0.1395, Training Loss: 0.0828, Initial Validation Loss: 0.1339, Validation Loss: 0.0782,V Acc: 0.6273, Top 70th Acc: 0.7662, Bottom 30th Acc: 0.3030
Fold [3/5] Epoch [20/100] Initial Loss: 0.1395, Training Loss: 0.0800, Initial Validation Loss: 0.1339, Validation Loss: 0.0759,V Acc: 0.6182, Top 70th Acc: 0.7532, Bottom 30th Acc: 0.3030
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.7532467532467533
Fold [4/5] Epoch [0/100] Initial Loss: 0.1368, Training Loss: 0.1368, Initial Validation Loss: 0.1310, Validation Loss: 0.1310,V Acc: 0.4091, Top 70th Acc: 0.4156, Bottom 30th Acc: 0.3939
Fold [4/5] Epoch [10/100] Initial Loss: 0.1368, Training Loss: 0.0813, Initial Validation Loss: 0.1310, Validation Loss: 0.0814,V Acc: 0.6182, Top 70th Acc: 0.7143, Bottom 30th Acc: 0.3939
Fold [4/5] Epoch [20/100] Initial Loss: 0.1368, Training Loss: 0.0793, Initial Validation Loss: 0.1310, Validation Loss: 0.0797,V Acc: 0.6455, Top 70th Acc: 0.7273, Bottom 30th Acc: 0.4545
Fold [4/5] Epoch [30/100] Initial Loss: 0.1368, Training Loss: 0.0789, Initial Validation Loss: 0.1310, Validation Loss: 0.0801,V Acc: 0.6091, Top 70th Acc: 0.7403, Bottom 30th Acc: 0.3030
Stopping early at Epoch (base 0): 30  Rolling back to Epoch (base 0): 25  Top Validation Acc: 0.7402597402597403
Fold [5/5] Epoch [0/100] Initial Loss: 0.1355, Training Loss: 0.1355, Initial Validation Loss: 0.1276, Validation Loss: 0.1276,V Acc: 0.4352, Top 70th Acc: 0.5000, Bottom 30th Acc: 0.2812
Fold [5/5] Epoch [10/100] Initial Loss: 0.1355, Training Loss: 0.0815, Initial Validation Loss: 0.1276, Validation Loss: 0.0821,V Acc: 0.6574, Top 70th Acc: 0.6974, Bottom 30th Acc: 0.5625
Fold [5/5] Epoch [20/100] Initial Loss: 0.1355, Training Loss: 0.0786, Initial Validation Loss: 0.1276, Validation Loss: 0.0803,V Acc: 0.6574, Top 70th Acc: 0.7105, Bottom 30th Acc: 0.5312
Stopping early at Epoch (base 0): 29  Rolling back to Epoch (base 0): 24  Top Validation Acc: 0.7236842105263158
Running train_nn.py with seed 93
CUDA:False
Training samples count:  550
Training on 2 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1366, Training Loss: 0.1366, Initial Validation Loss: 0.1243, Validation Loss: 0.1243,V Acc: 0.4234, Top 70th Acc: 0.4359, Bottom 30th Acc: 0.3939
Fold [1/5] Epoch [10/100] Initial Loss: 0.1366, Training Loss: 0.0784, Initial Validation Loss: 0.1243, Validation Loss: 0.0844,V Acc: 0.5856, Top 70th Acc: 0.6538, Bottom 30th Acc: 0.4242
Stopping early at Epoch (base 0): 18  Rolling back to Epoch (base 0): 13  Top Validation Acc: 0.6794871794871795
Fold [2/5] Epoch [0/100] Initial Loss: 0.1360, Training Loss: 0.1360, Initial Validation Loss: 0.1306, Validation Loss: 0.1306,V Acc: 0.4144, Top 70th Acc: 0.5385, Bottom 30th Acc: 0.1212
Fold [2/5] Epoch [10/100] Initial Loss: 0.1360, Training Loss: 0.0819, Initial Validation Loss: 0.1306, Validation Loss: 0.0778,V Acc: 0.6667, Top 70th Acc: 0.7564, Bottom 30th Acc: 0.4545
Fold [2/5] Epoch [20/100] Initial Loss: 0.1360, Training Loss: 0.0801, Initial Validation Loss: 0.1306, Validation Loss: 0.0754,V Acc: 0.6667, Top 70th Acc: 0.7821, Bottom 30th Acc: 0.3939
Stopping early at Epoch (base 0): 29  Rolling back to Epoch (base 0): 24  Top Validation Acc: 0.782051282051282
Fold [3/5] Epoch [0/100] Initial Loss: 0.1415, Training Loss: 0.1415, Initial Validation Loss: 0.1317, Validation Loss: 0.1317,V Acc: 0.2545, Top 70th Acc: 0.3506, Bottom 30th Acc: 0.0303
Fold [3/5] Epoch [10/100] Initial Loss: 0.1415, Training Loss: 0.0798, Initial Validation Loss: 0.1317, Validation Loss: 0.0831,V Acc: 0.6000, Top 70th Acc: 0.6883, Bottom 30th Acc: 0.3939
Fold [3/5] Epoch [20/100] Initial Loss: 0.1415, Training Loss: 0.0777, Initial Validation Loss: 0.1317, Validation Loss: 0.0815,V Acc: 0.6091, Top 70th Acc: 0.7013, Bottom 30th Acc: 0.3939
Stopping early at Epoch (base 0): 22  Rolling back to Epoch (base 0): 17  Top Validation Acc: 0.8974358974358975
Fold [2/5] Epoch [0/100] Initial Loss: 0.1381, Training Loss: 0.1381, Initial Validation Loss: 0.1336, Validation Loss: 0.1336,V Acc: 0.3514, Top 70th Acc: 0.4487, Bottom 30th Acc: 0.1212
Fold [2/5] Epoch [10/100] Initial Loss: 0.1381, Training Loss: 0.0303, Initial Validation Loss: 0.1336, Validation Loss: 0.0340,V Acc: 0.8468, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.6061
Fold [2/5] Epoch [20/100] Initial Loss: 0.1381, Training Loss: 0.0142, Initial Validation Loss: 0.1336, Validation Loss: 0.0273,V Acc: 0.8829, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 28  Rolling back to Epoch (base 0): 23  Top Validation Acc: 0.9743589743589743
Fold [3/5] Epoch [0/100] Initial Loss: 0.1395, Training Loss: 0.1395, Initial Validation Loss: 0.1338, Validation Loss: 0.1338,V Acc: 0.3636, Top 70th Acc: 0.3896, Bottom 30th Acc: 0.3030
Fold [3/5] Epoch [10/100] Initial Loss: 0.1395, Training Loss: 0.0306, Initial Validation Loss: 0.1338, Validation Loss: 0.0423,V Acc: 0.8000, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.5455
Fold [3/5] Epoch [20/100] Initial Loss: 0.1395, Training Loss: 0.0169, Initial Validation Loss: 0.1338, Validation Loss: 0.0316,V Acc: 0.8364, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.5758
Fold [3/5] Epoch [30/100] Initial Loss: 0.1395, Training Loss: 0.0132, Initial Validation Loss: 0.1338, Validation Loss: 0.0282,V Acc: 0.8364, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 38  Rolling back to Epoch (base 0): 33  Top Validation Acc: 0.948051948051948
94 2 [array([0.55934006, 0.03819908, 0.03248967, 0.08275248, 0.28721878],
      dtype=float32)]
Fold [4/5] Epoch [0/100] Initial Loss: 0.1381, Training Loss: 0.1381, Initial Validation Loss: 0.1325, Validation Loss: 0.1325,V Acc: 0.3727, Top 70th Acc: 0.3766, Bottom 30th Acc: 0.3636
Fold [4/5] Epoch [10/100] Initial Loss: 0.1381, Training Loss: 0.0295, Initial Validation Loss: 0.1325, Validation Loss: 0.0452,V Acc: 0.7727, Top 70th Acc: 0.8831, Bottom 30th Acc: 0.5152
Fold [4/5] Epoch [20/100] Initial Loss: 0.1381, Training Loss: 0.0162, Initial Validation Loss: 0.1325, Validation Loss: 0.0364,V Acc: 0.8273, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.5455
Fold [4/5] Epoch [30/100] Initial Loss: 0.1381, Training Loss: 0.0124, Initial Validation Loss: 0.1325, Validation Loss: 0.0324,V Acc: 0.8455, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6061
Fold [4/5] Epoch [40/100] Initial Loss: 0.1381, Training Loss: 0.0111, Initial Validation Loss: 0.1325, Validation Loss: 0.0299,V Acc: 0.8455, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 45  Rolling back to Epoch (base 0): 40  Top Validation Acc: 0.935064935064935
Fold [5/5] Epoch [0/100] Initial Loss: 0.1373, Training Loss: 0.1373, Initial Validation Loss: 0.1328, Validation Loss: 0.1328,V Acc: 0.2685, Top 70th Acc: 0.3289, Bottom 30th Acc: 0.1250
Fold [5/5] Epoch [10/100] Initial Loss: 0.1373, Training Loss: 0.0262, Initial Validation Loss: 0.1328, Validation Loss: 0.0311,V Acc: 0.8519, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.6250
Fold [5/5] Epoch [20/100] Initial Loss: 0.1373, Training Loss: 0.0138, Initial Validation Loss: 0.1328, Validation Loss: 0.0263,V Acc: 0.8704, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.6875
Fold [5/5] Epoch [30/100] Initial Loss: 0.1373, Training Loss: 0.0114, Initial Validation Loss: 0.1328, Validation Loss: 0.0259,V Acc: 0.8796, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.7188
Stopping early at Epoch (base 0): 32  Rolling back to Epoch (base 0): 27  Top Validation Acc: 0.9473684210526315
Running train_nn.py with seed 95
CUDA:False
Training samples count:  550
Training on 40 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1375, Training Loss: 0.1375, Initial Validation Loss: 0.1361, Validation Loss: 0.1361,V Acc: 0.3153, Top 70th Acc: 0.3333, Bottom 30th Acc: 0.2727
Fold [1/5] Epoch [10/100] Initial Loss: 0.1375, Training Loss: 0.0312, Initial Validation Loss: 0.1361, Validation Loss: 0.0393,V Acc: 0.8108, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.5152
Fold [1/5] Epoch [20/100] Initial Loss: 0.1375, Training Loss: 0.0172, Initial Validation Loss: 0.1361, Validation Loss: 0.0303,V Acc: 0.8559, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 29  Rolling back to Epoch (base 0): 24  Top Validation Acc: 0.9743589743589743
Fold [2/5] Epoch [0/100] Initial Loss: 0.1377, Training Loss: 0.1377, Initial Validation Loss: 0.1317, Validation Loss: 0.1317,V Acc: 0.3694, Top 70th Acc: 0.4487, Bottom 30th Acc: 0.1818
Fold [2/5] Epoch [10/100] Initial Loss: 0.1377, Training Loss: 0.0350, Initial Validation Loss: 0.1317, Validation Loss: 0.0431,V Acc: 0.7838, Top 70th Acc: 0.8846, Bottom 30th Acc: 0.5455
Fold [2/5] Epoch [20/100] Initial Loss: 0.1377, Training Loss: 0.0160, Initial Validation Loss: 0.1317, Validation Loss: 0.0310,V Acc: 0.8559, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.7273
Fold [2/5] Epoch [30/100] Initial Loss: 0.1377, Training Loss: 0.0126, Initial Validation Loss: 0.1317, Validation Loss: 0.0300,V Acc: 0.8468, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 32  Rolling back to Epoch (base 0): 27  Top Validation Acc: 0.9358974358974359
Fold [3/5] Epoch [0/100] Initial Loss: 0.1374, Training Loss: 0.1374, Initial Validation Loss: 0.1383, Validation Loss: 0.1383,V Acc: 0.2364, Top 70th Acc: 0.2597, Bottom 30th Acc: 0.1818
Fold [3/5] Epoch [10/100] Initial Loss: 0.1374, Training Loss: 0.0275, Initial Validation Loss: 0.1383, Validation Loss: 0.0413,V Acc: 0.8364, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.6667
Fold [3/5] Epoch [20/100] Initial Loss: 0.1374, Training Loss: 0.0138, Initial Validation Loss: 0.1383, Validation Loss: 0.0353,V Acc: 0.8364, Top 70th Acc: 0.8961, Bottom 30th Acc: 0.6970
Fold [3/5] Epoch [30/100] Initial Loss: 0.1374, Training Loss: 0.0113, Initial Validation Loss: 0.1383, Validation Loss: 0.0356,V Acc: 0.8364, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 30  Rolling back to Epoch (base 0): 25  Top Validation Acc: 0.9090909090909091
Fold [4/5] Epoch [0/100] Initial Loss: 0.1378, Training Loss: 0.1378, Initial Validation Loss: 0.1313, Validation Loss: 0.1313,V Acc: 0.3091, Top 70th Acc: 0.3506, Bottom 30th Acc: 0.2121
Fold [4/5] Epoch [10/100] Initial Loss: 0.1378, Training Loss: 0.0344, Initial Validation Loss: 0.1313, Validation Loss: 0.0553,V Acc: 0.7364, Top 70th Acc: 0.8312, Bottom 30th Acc: 0.5152
Fold [4/5] Epoch [20/100] Initial Loss: 0.1378, Training Loss: 0.0126, Initial Validation Loss: 0.1313, Validation Loss: 0.0446,V Acc: 0.7455, Top 70th Acc: 0.8831, Bottom 30th Acc: 0.4242
Fold [4/5] Epoch [30/100] Initial Loss: 0.1378, Training Loss: 0.0103, Initial Validation Loss: 0.1313, Validation Loss: 0.0431,V Acc: 0.7636, Top 70th Acc: 0.8831, Bottom 30th Acc: 0.4848
Fold [4/5] Epoch [40/100] Initial Loss: 0.1378, Training Loss: 0.0097, Initial Validation Loss: 0.1313, Validation Loss: 0.0431,V Acc: 0.7545, Top 70th Acc: 0.8831, Bottom 30th Acc: 0.4545
Stopping early at Epoch (base 0): 40  Rolling back to Epoch (base 0): 35  Top Validation Acc: 0.8831168831168831
Fold [5/5] Epoch [0/100] Initial Loss: 0.1362, Training Loss: 0.1362, Initial Validation Loss: 0.1244, Validation Loss: 0.1244,V Acc: 0.3241, Top 70th Acc: 0.3816, Bottom 30th Acc: 0.1875
Fold [5/5] Epoch [10/100] Initial Loss: 0.1362, Training Loss: 0.0298, Initial Validation Loss: 0.1244, Validation Loss: 0.0264,V Acc: 0.8611, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.6250
Fold [5/5] Epoch [20/100] Initial Loss: 0.1362, Training Loss: 0.0152, Initial Validation Loss: 0.1244, Validation Loss: 0.0199,V Acc: 0.8981, Top 70th Acc: 0.9737, Bottom 30th Acc: 0.7188
Stopping early at Epoch (base 0): 28  Rolling back to Epoch (base 0): 23  Top Validation Acc: 0.9736842105263158
95 4 [array([0.49428585, 0.02805833, 0.07946466, 0.05553988, 0.34265128],
      dtype=float32)]
Running train_nn.py with seed 96
CUDA:False
Training samples count:  550
Training on 40 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1355, Training Loss: 0.1355, Initial Validation Loss: 0.1333, Validation Loss: 0.1333,V Acc: 0.4234, Top 70th Acc: 0.4872, Bottom 30th Acc: 0.2727/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)

Fold [4/5] Epoch [20/100] Initial Loss: 0.1348, Training Loss: 0.0254, Initial Validation Loss: 0.1285, Validation Loss: 0.0300,V Acc: 0.8364, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.5152
Stopping early at Epoch (base 0): 29  Rolling back to Epoch (base 0): 24  Top Validation Acc: 0.974025974025974
Fold [5/5] Epoch [0/100] Initial Loss: 0.1384, Training Loss: 0.1384, Initial Validation Loss: 0.1346, Validation Loss: 0.1346,V Acc: 0.2963, Top 70th Acc: 0.2763, Bottom 30th Acc: 0.3438
Fold [5/5] Epoch [10/100] Initial Loss: 0.1384, Training Loss: 0.0435, Initial Validation Loss: 0.1346, Validation Loss: 0.0530,V Acc: 0.7685, Top 70th Acc: 0.8684, Bottom 30th Acc: 0.5312
Stopping early at Epoch (base 0): 18  Rolling back to Epoch (base 0): 13  Top Validation Acc: 0.868421052631579
99 4 [array([0.4301964 , 0.11046765, 0.08498096, 0.19951852, 0.17483652],
      dtype=float32)]
Running train_nn.py with seed 100
CUDA:False
Training samples count:  550
Training on 20 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1369, Training Loss: 0.1369, Initial Validation Loss: 0.1356, Validation Loss: 0.1356,V Acc: 0.3423, Top 70th Acc: 0.4487, Bottom 30th Acc: 0.0909
Fold [1/5] Epoch [10/100] Initial Loss: 0.1369, Training Loss: 0.0381, Initial Validation Loss: 0.1356, Validation Loss: 0.0489,V Acc: 0.7568, Top 70th Acc: 0.8846, Bottom 30th Acc: 0.4545
Fold [1/5] Epoch [20/100] Initial Loss: 0.1369, Training Loss: 0.0261, Initial Validation Loss: 0.1356, Validation Loss: 0.0366,V Acc: 0.7928, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.4545
Fold [1/5] Epoch [30/100] Initial Loss: 0.1369, Training Loss: 0.0227, Initial Validation Loss: 0.1356, Validation Loss: 0.0326,V Acc: 0.8739, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 33  Rolling back to Epoch (base 0): 28  Top Validation Acc: 0.9743589743589743
Fold [2/5] Epoch [0/100] Initial Loss: 0.1370, Training Loss: 0.1370, Initial Validation Loss: 0.1338, Validation Loss: 0.1338,V Acc: 0.3243, Top 70th Acc: 0.3846, Bottom 30th Acc: 0.1818
Fold [2/5] Epoch [10/100] Initial Loss: 0.1370, Training Loss: 0.0405, Initial Validation Loss: 0.1338, Validation Loss: 0.0439,V Acc: 0.8198, Top 70th Acc: 0.8974, Bottom 30th Acc: 0.6364
Fold [2/5] Epoch [20/100] Initial Loss: 0.1370, Training Loss: 0.0237, Initial Validation Loss: 0.1338, Validation Loss: 0.0357,V Acc: 0.8288, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 21  Rolling back to Epoch (base 0): 16  Top Validation Acc: 0.9358974358974359
Fold [3/5] Epoch [0/100] Initial Loss: 0.1399, Training Loss: 0.1399, Initial Validation Loss: 0.1272, Validation Loss: 0.1272,V Acc: 0.2727, Top 70th Acc: 0.3117, Bottom 30th Acc: 0.1818
Fold [3/5] Epoch [10/100] Initial Loss: 0.1399, Training Loss: 0.0424, Initial Validation Loss: 0.1272, Validation Loss: 0.0547,V Acc: 0.7182, Top 70th Acc: 0.7792, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 18  Rolling back to Epoch (base 0): 13  Top Validation Acc: 0.7792207792207793
100 2 [array([0.3468899 , 0.05018474, 0.09573779, 0.30045465, 0.2067329 ],
      dtype=float32)]
Fold [4/5] Epoch [0/100] Initial Loss: 0.1381, Training Loss: 0.1381, Initial Validation Loss: 0.1395, Validation Loss: 0.1395,V Acc: 0.2636, Top 70th Acc: 0.3377, Bottom 30th Acc: 0.0909
Fold [4/5] Epoch [10/100] Initial Loss: 0.1381, Training Loss: 0.0416, Initial Validation Loss: 0.1395, Validation Loss: 0.0452,V Acc: 0.8000, Top 70th Acc: 0.8961, Bottom 30th Acc: 0.5758
Fold [4/5] Epoch [20/100] Initial Loss: 0.1381, Training Loss: 0.0270, Initial Validation Loss: 0.1395, Validation Loss: 0.0331,V Acc: 0.8364, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.5758
Fold [4/5] Epoch [30/100] Initial Loss: 0.1381, Training Loss: 0.0235, Initial Validation Loss: 0.1395, Validation Loss: 0.0326,V Acc: 0.8364, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 32  Rolling back to Epoch (base 0): 27  Top Validation Acc: 0.935064935064935
Fold [5/5] Epoch [0/100] Initial Loss: 0.1402, Training Loss: 0.1402, Initial Validation Loss: 0.1305, Validation Loss: 0.1305,V Acc: 0.2500, Top 70th Acc: 0.3553, Bottom 30th Acc: 0.0000
Fold [5/5] Epoch [10/100] Initial Loss: 0.1402, Training Loss: 0.0422, Initial Validation Loss: 0.1305, Validation Loss: 0.0453,V Acc: 0.7963, Top 70th Acc: 0.9211, Bottom 30th Acc: 0.5000
Fold [5/5] Epoch [20/100] Initial Loss: 0.1402, Training Loss: 0.0254, Initial Validation Loss: 0.1305, Validation Loss: 0.0335,V Acc: 0.8519, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.6250
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.9210526315789473

Stopping early at Epoch (base 0): 19  Rolling back to Epoch (base 0): 14  Top Validation Acc: 0.9615384615384616
Fold [2/5] Epoch [0/100] Initial Loss: 0.1363, Training Loss: 0.1363, Initial Validation Loss: 0.1335, Validation Loss: 0.1335,V Acc: 0.3694, Top 70th Acc: 0.4103, Bottom 30th Acc: 0.2727
Fold [2/5] Epoch [10/100] Initial Loss: 0.1363, Training Loss: 0.0448, Initial Validation Loss: 0.1335, Validation Loss: 0.0455,V Acc: 0.7658, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.3939
Fold [2/5] Epoch [20/100] Initial Loss: 0.1363, Training Loss: 0.0206, Initial Validation Loss: 0.1335, Validation Loss: 0.0322,V Acc: 0.8378, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.5758
Fold [2/5] Epoch [30/100] Initial Loss: 0.1363, Training Loss: 0.0165, Initial Validation Loss: 0.1335, Validation Loss: 0.0321,V Acc: 0.8288, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.4848
Stopping early at Epoch (base 0): 30  Rolling back to Epoch (base 0): 25  Top Validation Acc: 0.9743589743589743
97 1 [array([0.7672692 , 0.0569354 , 0.02735729, 0.08860709, 0.05983095],
      dtype=float32)]
Fold [3/5] Epoch [0/100] Initial Loss: 0.1389, Training Loss: 0.1389, Initial Validation Loss: 0.1342, Validation Loss: 0.1342,V Acc: 0.2545, Top 70th Acc: 0.3377, Bottom 30th Acc: 0.0606
Fold [3/5] Epoch [10/100] Initial Loss: 0.1389, Training Loss: 0.0260, Initial Validation Loss: 0.1342, Validation Loss: 0.0266,V Acc: 0.9000, Top 70th Acc: 0.9870, Bottom 30th Acc: 0.6970
Fold [3/5] Epoch [20/100] Initial Loss: 0.1389, Training Loss: 0.0180, Initial Validation Loss: 0.1342, Validation Loss: 0.0241,V Acc: 0.8909, Top 70th Acc: 0.9870, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.987012987012987
Fold [4/5] Epoch [0/100] Initial Loss: 0.1362, Training Loss: 0.1362, Initial Validation Loss: 0.1316, Validation Loss: 0.1316,V Acc: 0.4455, Top 70th Acc: 0.4935, Bottom 30th Acc: 0.3333
Fold [4/5] Epoch [10/100] Initial Loss: 0.1362, Training Loss: 0.0287, Initial Validation Loss: 0.1316, Validation Loss: 0.0349,V Acc: 0.8545, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.6667
Fold [4/5] Epoch [20/100] Initial Loss: 0.1362, Training Loss: 0.0171, Initial Validation Loss: 0.1316, Validation Loss: 0.0313,V Acc: 0.8455, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 22  Rolling back to Epoch (base 0): 17  Top Validation Acc: 0.961038961038961
Fold [5/5] Epoch [0/100] Initial Loss: 0.1371, Training Loss: 0.1371, Initial Validation Loss: 0.1272, Validation Loss: 0.1272,V Acc: 0.3981, Top 70th Acc: 0.4474, Bottom 30th Acc: 0.2812
Fold [5/5] Epoch [10/100] Initial Loss: 0.1371, Training Loss: 0.0297, Initial Validation Loss: 0.1272, Validation Loss: 0.0458,V Acc: 0.7593, Top 70th Acc: 0.8684, Bottom 30th Acc: 0.5000
Fold [5/5] Epoch [20/100] Initial Loss: 0.1371, Training Loss: 0.0164, Initial Validation Loss: 0.1272, Validation Loss: 0.0385,V Acc: 0.7778, Top 70th Acc: 0.9079, Bottom 30th Acc: 0.4688
Stopping early at Epoch (base 0): 27  Rolling back to Epoch (base 0): 22  Top Validation Acc: 0.881578947368421
Running train_nn.py with seed 98
CUDA:False
Training samples count:  550
Training on 30 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1392, Training Loss: 0.1392, Initial Validation Loss: 0.1375, Validation Loss: 0.1375,V Acc: 0.3423, Top 70th Acc: 0.3718, Bottom 30th Acc: 0.2727
Fold [1/5] Epoch [10/100] Initial Loss: 0.1392, Training Loss: 0.0326, Initial Validation Loss: 0.1375, Validation Loss: 0.0343,V Acc: 0.8468, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.6061
Fold [1/5] Epoch [20/100] Initial Loss: 0.1392, Training Loss: 0.0196, Initial Validation Loss: 0.1375, Validation Loss: 0.0255,V Acc: 0.8919, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.7273
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.9743589743589743
98 0 [array([0.55041355, 0.07570467, 0.03870374, 0.08280972, 0.2523683 ],
      dtype=float32)]
Fold [2/5] Epoch [0/100] Initial Loss: 0.1383, Training Loss: 0.1383, Initial Validation Loss: 0.1283, Validation Loss: 0.1283,V Acc: 0.3333, Top 70th Acc: 0.3974, Bottom 30th Acc: 0.1818
Fold [2/5] Epoch [10/100] Initial Loss: 0.1383, Training Loss: 0.0351, Initial Validation Loss: 0.1283, Validation Loss: 0.0416,V Acc: 0.8018, Top 70th Acc: 0.8846, Bottom 30th Acc: 0.6061
Fold [2/5] Epoch [20/100] Initial Loss: 0.1383, Training Loss: 0.0184, Initial Validation Loss: 0.1283, Validation Loss: 0.0319,V Acc: 0.8018, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.5455
Fold [2/5] Epoch [30/100] Initial Loss: 0.1383, Training Loss: 0.0159, Initial Validation Loss: 0.1283, Validation Loss: 0.0289,V Acc: 0.8378, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 38  Rolling back to Epoch (base 0): 33  Top Validation Acc: 0.9358974358974359
Fold [3/5] Epoch [0/100] Initial Loss: 0.1400, Training Loss: 0.1400, Initial Validation Loss: 0.1377, Validation Loss: 0.1377,V Acc: 0.2818, Top 70th Acc: 0.2987, Bottom 30th Acc: 0.2424
Fold [3/5] Epoch [10/100] Initial Loss: 0.1400, Training Loss: 0.0378, Initial Validation Loss: 0.1377, Validation Loss: 0.0488,V Acc: 0.7818, Top 70th Acc: 0.8571, Bottom 30th Acc: 0.6061
Fold [3/5] Epoch [20/100] Initial Loss: 0.1400, Training Loss: 0.0187, Initial Validation Loss: 0.1377, Validation Loss: 0.0312,V Acc: 0.8636, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 27  Rolling back to Epoch (base 0): 22  Top Validation Acc: 0.935064935064935
Fold [4/5] Epoch [0/100] Initial Loss: 0.1397, Training Loss: 0.1397, Initial Validation Loss: 0.1298, Validation Loss: 0.1298,V Acc: 0.3455, Top 70th Acc: 0.3377, Bottom 30th Acc: 0.3636
Fold [4/5] Epoch [10/100] Initial Loss: 0.1397, Training Loss: 0.0404, Initial Validation Loss: 0.1298, Validation Loss: 0.0429,V Acc: 0.7909, Top 70th Acc: 0.8961, Bottom 30th Acc: 0.5455
Fold [4/5] Epoch [20/100] Initial Loss: 0.1397, Training Loss: 0.0177, Initial Validation Loss: 0.1298, Validation Loss: 0.0346,V Acc: 0.8273, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 21  Rolling back to Epoch (base 0): 16  Top Validation Acc: 0.935064935064935
Fold [5/5] Epoch [0/100] Initial Loss: 0.1392, Training Loss: 0.1392, Initial Validation Loss: 0.1337, Validation Loss: 0.1337,V Acc: 0.3056, Top 70th Acc: 0.3947, Bottom 30th Acc: 0.0938
Fold [5/5] Epoch [10/100] Initial Loss: 0.1392, Training Loss: 0.0268, Initial Validation Loss: 0.1337, Validation Loss: 0.0338,V Acc: 0.8426, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.5938
Fold [5/5] Epoch [20/100] Initial Loss: 0.1392, Training Loss: 0.0167, Initial Validation Loss: 0.1337, Validation Loss: 0.0310,V Acc: 0.8611, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.6562
Stopping early at Epoch (base 0): 22  Rolling back to Epoch (base 0): 17  Top Validation Acc: 0.9473684210526315
Running train_nn.py with seed 99
CUDA:False
Training samples count:  550
Training on 30 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1403, Training Loss: 0.1403, Initial Validation Loss: 0.1336, Validation Loss: 0.1336,V Acc: 0.3514, Top 70th Acc: 0.4103, Bottom 30th Acc: 0.2121
Fold [1/5] Epoch [10/100] Initial Loss: 0.1403, Training Loss: 0.0343, Initial Validation Loss: 0.1336, Validation Loss: 0.0403,V Acc: 0.8018, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.5455
Fold [1/5] Epoch [20/100] Initial Loss: 0.1403, Training Loss: 0.0194, Initial Validation Loss: 0.1336, Validation Loss: 0.0302,V Acc: 0.8559, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.6667
Fold [1/5] Epoch [30/100] Initial Loss: 0.1403, Training Loss: 0.0161, Initial Validation Loss: 0.1336, Validation Loss: 0.0280,V Acc: 0.8739, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.6667
Fold [1/5] Epoch [40/100] Initial Loss: 0.1403, Training Loss: 0.0147, Initial Validation Loss: 0.1336, Validation Loss: 0.0275,V Acc: 0.8739, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 45  Rolling back to Epoch (base 0): 40  Top Validation Acc: 0.9615384615384616
Fold [2/5] Epoch [0/100] Initial Loss: 0.1408, Training Loss: 0.1408, Initial Validation Loss: 0.1366, Validation Loss: 0.1366,V Acc: 0.3243, Top 70th Acc: 0.3590, Bottom 30th Acc: 0.2424
Fold [4/5] Epoch [10/100] Initial Loss: 0.1398, Training Loss: 0.0269, Initial Validation Loss: 0.1363, Validation Loss: 0.0476,V Acc: 0.7909, Top 70th Acc: 0.8701, Bottom 30th Acc: 0.6061
Fold [4/5] Epoch [20/100] Initial Loss: 0.1398, Training Loss: 0.0063, Initial Validation Loss: 0.1363, Validation Loss: 0.0350,V Acc: 0.8364, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.6061
Fold [4/5] Epoch [30/100] Initial Loss: 0.1398, Training Loss: 0.0043, Initial Validation Loss: 0.1363, Validation Loss: 0.0317,V Acc: 0.8273, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.5152
Fold [4/5] Epoch [40/100] Initial Loss: 0.1398, Training Loss: 0.0038, Initial Validation Loss: 0.1363, Validation Loss: 0.0311,V Acc: 0.8364, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.5758
Fold [4/5] Epoch [50/100] Initial Loss: 0.1398, Training Loss: 0.0036, Initial Validation Loss: 0.1363, Validation Loss: 0.0309,V Acc: 0.8455, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 51  Rolling back to Epoch (base 0): 46  Top Validation Acc: 0.961038961038961
Fold [5/5] Epoch [0/100] Initial Loss: 0.1424, Training Loss: 0.1424, Initial Validation Loss: 0.1315, Validation Loss: 0.1315,V Acc: 0.2778, Top 70th Acc: 0.3553, Bottom 30th Acc: 0.0938
Fold [5/5] Epoch [10/100] Initial Loss: 0.1424, Training Loss: 0.0154, Initial Validation Loss: 0.1315, Validation Loss: 0.0396,V Acc: 0.7593, Top 70th Acc: 0.8947, Bottom 30th Acc: 0.4375
Fold [5/5] Epoch [20/100] Initial Loss: 0.1424, Training Loss: 0.0058, Initial Validation Loss: 0.1315, Validation Loss: 0.0325,V Acc: 0.8148, Top 70th Acc: 0.9211, Bottom 30th Acc: 0.5625
Fold [5/5] Epoch [30/100] Initial Loss: 0.1424, Training Loss: 0.0046, Initial Validation Loss: 0.1315, Validation Loss: 0.0317,V Acc: 0.8056, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.4688
Stopping early at Epoch (base 0): 36  Rolling back to Epoch (base 0): 31  Top Validation Acc: 0.9605263157894737
Running train_nn.py with seed 75
CUDA:False
Training samples count:  550
Training on 163 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1390, Training Loss: 0.1390, Initial Validation Loss: 0.1347, Validation Loss: 0.1347,V Acc: 0.4054, Top 70th Acc: 0.4487, Bottom 30th Acc: 0.3030
Fold [1/5] Epoch [10/100] Initial Loss: 0.1390, Training Loss: 0.0163, Initial Validation Loss: 0.1347, Validation Loss: 0.0433,V Acc: 0.8018, Top 70th Acc: 0.8846, Bottom 30th Acc: 0.6061
Fold [1/5] Epoch [20/100] Initial Loss: 0.1390, Training Loss: 0.0055, Initial Validation Loss: 0.1347, Validation Loss: 0.0369,V Acc: 0.8108, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.5455
Fold [1/5] Epoch [30/100] Initial Loss: 0.1390, Training Loss: 0.0040, Initial Validation Loss: 0.1347, Validation Loss: 0.0356,V Acc: 0.8108, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.5455
Fold [1/5] Epoch [40/100] Initial Loss: 0.1390, Training Loss: 0.0036, Initial Validation Loss: 0.1347, Validation Loss: 0.0346,V Acc: 0.8198, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.5455
Fold [1/5] Epoch [50/100] Initial Loss: 0.1390, Training Loss: 0.0033, Initial Validation Loss: 0.1347, Validation Loss: 0.0339,V Acc: 0.8378, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 59  Rolling back to Epoch (base 0): 54  Top Validation Acc: 0.9358974358974359
Fold [2/5] Epoch [0/100] Initial Loss: 0.1391, Training Loss: 0.1391, Initial Validation Loss: 0.1395, Validation Loss: 0.1395,V Acc: 0.2613, Top 70th Acc: 0.2949, Bottom 30th Acc: 0.1818
Fold [2/5] Epoch [10/100] Initial Loss: 0.1391, Training Loss: 0.0223, Initial Validation Loss: 0.1395, Validation Loss: 0.0378,V Acc: 0.8378, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.6061
Fold [2/5] Epoch [20/100] Initial Loss: 0.1391, Training Loss: 0.0064, Initial Validation Loss: 0.1395, Validation Loss: 0.0302,V Acc: 0.8559, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.6364
Fold [2/5] Epoch [30/100] Initial Loss: 0.1391, Training Loss: 0.0046, Initial Validation Loss: 0.1395, Validation Loss: 0.0282,V Acc: 0.8649, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.6061
Fold [2/5] Epoch [40/100] Initial Loss: 0.1391, Training Loss: 0.0040, Initial Validation Loss: 0.1395, Validation Loss: 0.0270,V Acc: 0.8739, Top 70th Acc: 0.9872, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 44  Rolling back to Epoch (base 0): 39  Top Validation Acc: 0.9743589743589743
Fold [3/5] Epoch [0/100] Initial Loss: 0.1377, Training Loss: 0.1377, Initial Validation Loss: 0.1295, Validation Loss: 0.1295,V Acc: 0.4636, Top 70th Acc: 0.4935, Bottom 30th Acc: 0.3939
Fold [3/5] Epoch [10/100] Initial Loss: 0.1377, Training Loss: 0.0162, Initial Validation Loss: 0.1295, Validation Loss: 0.0296,V Acc: 0.8727, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.7273
Fold [3/5] Epoch [20/100] Initial Loss: 0.1377, Training Loss: 0.0048, Initial Validation Loss: 0.1295, Validation Loss: 0.0230,V Acc: 0.8909, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.7576
Fold [3/5] Epoch [30/100] Initial Loss: 0.1377, Training Loss: 0.0039, Initial Validation Loss: 0.1295, Validation Loss: 0.0229,V Acc: 0.8545, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 32  Rolling back to Epoch (base 0): 27  Top Validation Acc: 0.948051948051948
Fold [4/5] Epoch [0/100] Initial Loss: 0.1425, Training Loss: 0.1425, Initial Validation Loss: 0.1307, Validation Loss: 0.1307,V Acc: 0.3182, Top 70th Acc: 0.4026, Bottom 30th Acc: 0.1212
Fold [4/5] Epoch [10/100] Initial Loss: 0.1425, Training Loss: 0.0164, Initial Validation Loss: 0.1307, Validation Loss: 0.0310,V Acc: 0.8545, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6364
Fold [4/5] Epoch [20/100] Initial Loss: 0.1425, Training Loss: 0.0050, Initial Validation Loss: 0.1307, Validation Loss: 0.0237,V Acc: 0.8636, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.6061
Fold [4/5] Epoch [30/100] Initial Loss: 0.1425, Training Loss: 0.0041, Initial Validation Loss: 0.1307, Validation Loss: 0.0227,V Acc: 0.8727, Top 70th Acc: 0.9870, Bottom 30th Acc: 0.6061
Fold [4/5] Epoch [40/100] Initial Loss: 0.1425, Training Loss: 0.0038, Initial Validation Loss: 0.1307, Validation Loss: 0.0231,V Acc: 0.8636, Top 70th Acc: 0.9870, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 40  Rolling back to Epoch (base 0): 35  Top Validation Acc: 0.987012987012987
Fold [5/5] Epoch [0/100] Initial Loss: 0.1362, Training Loss: 0.1362, Initial Validation Loss: 0.1325, Validation Loss: 0.1325,V Acc: 0.3704, Top 70th Acc: 0.4211, Bottom 30th Acc: 0.2500
Fold [5/5] Epoch [10/100] Initial Loss: 0.1362, Training Loss: 0.0192, Initial Validation Loss: 0.1325, Validation Loss: 0.0376,V Acc: 0.8426, Top 70th Acc: 0.9079, Bottom 30th Acc: 0.6875
Fold [5/5] Epoch [20/100] Initial Loss: 0.1362, Training Loss: 0.0057, Initial Validation Loss: 0.1325, Validation Loss: 0.0306,V Acc: 0.8426, Top 70th Acc: 0.9737, Bottom 30th Acc: 0.5312
Fold [5/5] Epoch [30/100] Initial Loss: 0.1362, Training Loss: 0.0043, Initial Validation Loss: 0.1325, Validation Loss: 0.0298,V Acc: 0.8333, Top 70th Acc: 0.9868, Bottom 30th Acc: 0.4688
Stopping early at Epoch (base 0): 36  Rolling back to Epoch (base 0): 31  Top Validation Acc: 0.9736842105263158
75 4 [array([0.13263746, 0.07275299, 0.08288395, 0.19220757, 0.519518  ],
      dtype=float32)]
Running train_nn.py with seed 76
CUDA:False
Training samples count:  550
Training on 163 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1366, Training Loss: 0.1366, Initial Validation Loss: 0.1331, Validation Loss: 0.1331,V Acc: 0.3964, Top 70th Acc: 0.5385, Bottom 30th Acc: 0.0606
Fold [1/5] Epoch [10/100] Initial Loss: 0.1366, Training Loss: 0.0148, Initial Validation Loss: 0.1331, Validation Loss: 0.0240,V Acc: 0.9009, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.7273
Fold [1/5] Epoch [20/100] Initial Loss: 0.1366, Training Loss: 0.0054, Initial Validation Loss: 0.1331, Validation Loss: 0.0204,V Acc: 0.9189, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.7879
Fold [1/5] Epoch [30/100] Initial Loss: 0.1366, Training Loss: 0.0041, Initial Validation Loss: 0.1331, Validation Loss: 0.0203,V Acc: 0.9189, Top 70th Acc: 0.9872, Bottom 30th Acc: 0.7576
Stopping early at Epoch (base 0): 32  Rolling back to Epoch (base 0): 27  Top Validation Acc: 0.9871794871794872
Fold [2/5] Epoch [0/100] Initial Loss: 0.1400, Training Loss: 0.1400, Initial Validation Loss: 0.1342, Validation Loss: 0.1342,V Acc: 0.2523, Top 70th Acc: 0.2436, Bottom 30th Acc: 0.2727
Stopping early at Epoch (base 0): 22  Rolling back to Epoch (base 0): 17  Top Validation Acc: 0.6883116883116883
Fold [4/5] Epoch [0/100] Initial Loss: 0.1410, Training Loss: 0.1410, Initial Validation Loss: 0.1377, Validation Loss: 0.1377,V Acc: 0.2545, Top 70th Acc: 0.3636, Bottom 30th Acc: 0.0000
Fold [4/5] Epoch [10/100] Initial Loss: 0.1410, Training Loss: 0.0811, Initial Validation Loss: 0.1377, Validation Loss: 0.0793,V Acc: 0.6273, Top 70th Acc: 0.7403, Bottom 30th Acc: 0.3636
Fold [4/5] Epoch [20/100] Initial Loss: 0.1410, Training Loss: 0.0788, Initial Validation Loss: 0.1377, Validation Loss: 0.0765,V Acc: 0.6545, Top 70th Acc: 0.7662, Bottom 30th Acc: 0.3939
Fold [4/5] Epoch [30/100] Initial Loss: 0.1410, Training Loss: 0.0781, Initial Validation Loss: 0.1377, Validation Loss: 0.0760,V Acc: 0.6545, Top 70th Acc: 0.7792, Bottom 30th Acc: 0.3636
Stopping early at Epoch (base 0): 32  Rolling back to Epoch (base 0): 27  Top Validation Acc: 0.7922077922077922
Fold [5/5] Epoch [0/100] Initial Loss: 0.1328, Training Loss: 0.1328, Initial Validation Loss: 0.1213, Validation Loss: 0.1213,V Acc: 0.4907, Top 70th Acc: 0.5000, Bottom 30th Acc: 0.4688
Fold [5/5] Epoch [10/100] Initial Loss: 0.1328, Training Loss: 0.0815, Initial Validation Loss: 0.1213, Validation Loss: 0.0755,V Acc: 0.6574, Top 70th Acc: 0.7763, Bottom 30th Acc: 0.3750
Fold [5/5] Epoch [20/100] Initial Loss: 0.1328, Training Loss: 0.0797, Initial Validation Loss: 0.1213, Validation Loss: 0.0740,V Acc: 0.6481, Top 70th Acc: 0.7763, Bottom 30th Acc: 0.3438
Stopping early at Epoch (base 0): 27  Rolling back to Epoch (base 0): 22  Top Validation Acc: 0.7631578947368421
93 4 [array([0.15611146, 0.33431724, 0.15855792, 0.22713536, 0.12387798],
      dtype=float32)]
Running train_nn.py with seed 94
CUDA:False
Training samples count:  550
Training on 2 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1385, Training Loss: 0.1385, Initial Validation Loss: 0.1349, Validation Loss: 0.1349,V Acc: 0.2523, Top 70th Acc: 0.3590, Bottom 30th Acc: 0.0000
Fold [1/5] Epoch [10/100] Initial Loss: 0.1385, Training Loss: 0.0806, Initial Validation Loss: 0.1349, Validation Loss: 0.0826,V Acc: 0.6126, Top 70th Acc: 0.7308, Bottom 30th Acc: 0.3333
Fold [1/5] Epoch [20/100] Initial Loss: 0.1385, Training Loss: 0.0783, Initial Validation Loss: 0.1349, Validation Loss: 0.0810,V Acc: 0.6036, Top 70th Acc: 0.7308, Bottom 30th Acc: 0.3030
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.7307692307692307
Fold [2/5] Epoch [0/100] Initial Loss: 0.1363, Training Loss: 0.1363, Initial Validation Loss: 0.1273, Validation Loss: 0.1273,V Acc: 0.3333, Top 70th Acc: 0.3590, Bottom 30th Acc: 0.2727
Fold [2/5] Epoch [10/100] Initial Loss: 0.1363, Training Loss: 0.0824, Initial Validation Loss: 0.1273, Validation Loss: 0.0778,V Acc: 0.6486, Top 70th Acc: 0.7436, Bottom 30th Acc: 0.4242
Fold [2/5] Epoch [20/100] Initial Loss: 0.1363, Training Loss: 0.0800, Initial Validation Loss: 0.1273, Validation Loss: 0.0752,V Acc: 0.6577, Top 70th Acc: 0.7692, Bottom 30th Acc: 0.3939
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.7564102564102564
Fold [3/5] Epoch [0/100] Initial Loss: 0.1332, Training Loss: 0.1332, Initial Validation Loss: 0.1212, Validation Loss: 0.1212,V Acc: 0.4636, Top 70th Acc: 0.5844, Bottom 30th Acc: 0.1818
Fold [3/5] Epoch [10/100] Initial Loss: 0.1332, Training Loss: 0.0810, Initial Validation Loss: 0.1212, Validation Loss: 0.0801,V Acc: 0.6273, Top 70th Acc: 0.7273, Bottom 30th Acc: 0.3939
Fold [3/5] Epoch [20/100] Initial Loss: 0.1332, Training Loss: 0.0793, Initial Validation Loss: 0.1212, Validation Loss: 0.0774,V Acc: 0.6364, Top 70th Acc: 0.7273, Bottom 30th Acc: 0.4242
Fold [3/5] Epoch [30/100] Initial Loss: 0.1332, Training Loss: 0.0787, Initial Validation Loss: 0.1212, Validation Loss: 0.0770,V Acc: 0.6364, Top 70th Acc: 0.7273, Bottom 30th Acc: 0.4242
Fold [3/5] Epoch [40/100] Initial Loss: 0.1332, Training Loss: 0.0786, Initial Validation Loss: 0.1212, Validation Loss: 0.0766,V Acc: 0.6364, Top 70th Acc: 0.7273, Bottom 30th Acc: 0.4242
Fold [3/5] Epoch [50/100] Initial Loss: 0.1332, Training Loss: 0.0781, Initial Validation Loss: 0.1212, Validation Loss: 0.0765,V Acc: 0.6455, Top 70th Acc: 0.7532, Bottom 30th Acc: 0.3939
Stopping early at Epoch (base 0): 52  Rolling back to Epoch (base 0): 47  Top Validation Acc: 0.7532467532467533
94 2 [array([0.1647325 , 0.3353341 , 0.1277732 , 0.23996976, 0.13219042],
      dtype=float32)]
Fold [4/5] Epoch [0/100] Initial Loss: 0.1279, Training Loss: 0.1279, Initial Validation Loss: 0.1157, Validation Loss: 0.1157,V Acc: 0.4818, Top 70th Acc: 0.5065, Bottom 30th Acc: 0.4242
Fold [4/5] Epoch [10/100] Initial Loss: 0.1279, Training Loss: 0.0791, Initial Validation Loss: 0.1157, Validation Loss: 0.0845,V Acc: 0.5909, Top 70th Acc: 0.6883, Bottom 30th Acc: 0.3636
Stopping early at Epoch (base 0): 19  Rolling back to Epoch (base 0): 14  Top Validation Acc: 0.7142857142857143
Fold [5/5] Epoch [0/100] Initial Loss: 0.1355, Training Loss: 0.1355, Initial Validation Loss: 0.1244, Validation Loss: 0.1244,V Acc: 0.4259, Top 70th Acc: 0.5000, Bottom 30th Acc: 0.2500
Fold [5/5] Epoch [10/100] Initial Loss: 0.1355, Training Loss: 0.0804, Initial Validation Loss: 0.1244, Validation Loss: 0.0788,V Acc: 0.6296, Top 70th Acc: 0.7368, Bottom 30th Acc: 0.3750
Fold [5/5] Epoch [20/100] Initial Loss: 0.1355, Training Loss: 0.0786, Initial Validation Loss: 0.1244, Validation Loss: 0.0762,V Acc: 0.6481, Top 70th Acc: 0.7368, Bottom 30th Acc: 0.4375
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.7368421052631579
Running train_nn.py with seed 95
CUDA:False
Training samples count:  550
Training on 2 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1381, Training Loss: 0.1381, Initial Validation Loss: 0.1307, Validation Loss: 0.1307,V Acc: 0.4955, Top 70th Acc: 0.5256, Bottom 30th Acc: 0.4242
Fold [1/5] Epoch [10/100] Initial Loss: 0.1381, Training Loss: 0.0810, Initial Validation Loss: 0.1307, Validation Loss: 0.0778,V Acc: 0.6667, Top 70th Acc: 0.7692, Bottom 30th Acc: 0.4242
Fold [1/5] Epoch [20/100] Initial Loss: 0.1381, Training Loss: 0.0795, Initial Validation Loss: 0.1307, Validation Loss: 0.0764,V Acc: 0.6667, Top 70th Acc: 0.7692, Bottom 30th Acc: 0.4242
Fold [1/5] Epoch [30/100] Initial Loss: 0.1381, Training Loss: 0.0788, Initial Validation Loss: 0.1307, Validation Loss: 0.0754,V Acc: 0.6577, Top 70th Acc: 0.7949, Bottom 30th Acc: 0.3333
Fold [1/5] Epoch [40/100] Initial Loss: 0.1381, Training Loss: 0.0783, Initial Validation Loss: 0.1307, Validation Loss: 0.0748,V Acc: 0.6486, Top 70th Acc: 0.7821, Bottom 30th Acc: 0.3333
Stopping early at Epoch (base 0): 49  Rolling back to Epoch (base 0): 44  Top Validation Acc: 0.7948717948717948
Fold [2/5] Epoch [0/100] Initial Loss: 0.1303, Training Loss: 0.1303, Initial Validation Loss: 0.1143, Validation Loss: 0.1143,V Acc: 0.4505, Top 70th Acc: 0.5769, Bottom 30th Acc: 0.1515
Fold [2/5] Epoch [10/100] Initial Loss: 0.1303, Training Loss: 0.0807, Initial Validation Loss: 0.1143, Validation Loss: 0.0792,V Acc: 0.6216, Top 70th Acc: 0.7179, Bottom 30th Acc: 0.3939
Stopping early at Epoch (base 0): 15  Rolling back to Epoch (base 0): 10  Top Validation Acc: 0.717948717948718
Fold [3/5] Epoch [0/100] Initial Loss: 0.1302, Training Loss: 0.1302, Initial Validation Loss: 0.1231, Validation Loss: 0.1231,V Acc: 0.4091, Top 70th Acc: 0.4935, Bottom 30th Acc: 0.2121
Fold [3/5] Epoch [10/100] Initial Loss: 0.1302, Training Loss: 0.0793, Initial Validation Loss: 0.1231, Validation Loss: 0.0840,V Acc: 0.6182, Top 70th Acc: 0.6883, Bottom 30th Acc: 0.4545
Fold [3/5] Epoch [20/100] Initial Loss: 0.1302, Training Loss: 0.0780, Initial Validation Loss: 0.1231, Validation Loss: 0.0831,V Acc: 0.6182, Top 70th Acc: 0.7013, Bottom 30th Acc: 0.4242
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.7012987012987013
Fold [4/5] Epoch [0/100] Initial Loss: 0.1414, Training Loss: 0.1414, Initial Validation Loss: 0.1296, Validation Loss: 0.1296,V Acc: 0.4909, Top 70th Acc: 0.6234, Bottom 30th Acc: 0.1818
Fold [1/5] Epoch [10/100] Initial Loss: 0.1355, Training Loss: 0.0308, Initial Validation Loss: 0.1333, Validation Loss: 0.0407,V Acc: 0.8378, Top 70th Acc: 0.8974, Bottom 30th Acc: 0.6970
Fold [1/5] Epoch [20/100] Initial Loss: 0.1355, Training Loss: 0.0149, Initial Validation Loss: 0.1333, Validation Loss: 0.0273,V Acc: 0.8739, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.6667
Fold [1/5] Epoch [30/100] Initial Loss: 0.1355, Training Loss: 0.0124, Initial Validation Loss: 0.1333, Validation Loss: 0.0272,V Acc: 0.8829, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 31  Rolling back to Epoch (base 0): 26  Top Validation Acc: 0.9615384615384616
Fold [2/5] Epoch [0/100] Initial Loss: 0.1391, Training Loss: 0.1391, Initial Validation Loss: 0.1341, Validation Loss: 0.1341,V Acc: 0.4144, Top 70th Acc: 0.4615, Bottom 30th Acc: 0.3030
Fold [2/5] Epoch [10/100] Initial Loss: 0.1391, Training Loss: 0.0332, Initial Validation Loss: 0.1341, Validation Loss: 0.0328,V Acc: 0.8198, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.5455
Fold [2/5] Epoch [20/100] Initial Loss: 0.1391, Training Loss: 0.0189, Initial Validation Loss: 0.1341, Validation Loss: 0.0284,V Acc: 0.8468, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.9230769230769231
Fold [3/5] Epoch [0/100] Initial Loss: 0.1402, Training Loss: 0.1402, Initial Validation Loss: 0.1360, Validation Loss: 0.1360,V Acc: 0.3636, Top 70th Acc: 0.4286, Bottom 30th Acc: 0.2121
Fold [3/5] Epoch [10/100] Initial Loss: 0.1402, Training Loss: 0.0364, Initial Validation Loss: 0.1360, Validation Loss: 0.0380,V Acc: 0.8182, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.5152
Fold [3/5] Epoch [20/100] Initial Loss: 0.1402, Training Loss: 0.0152, Initial Validation Loss: 0.1360, Validation Loss: 0.0253,V Acc: 0.8909, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.6970
Fold [3/5] Epoch [30/100] Initial Loss: 0.1402, Training Loss: 0.0124, Initial Validation Loss: 0.1360, Validation Loss: 0.0245,V Acc: 0.8727, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 32  Rolling back to Epoch (base 0): 27  Top Validation Acc: 0.961038961038961
Fold [4/5] Epoch [0/100] Initial Loss: 0.1397, Training Loss: 0.1397, Initial Validation Loss: 0.1330, Validation Loss: 0.1330,V Acc: 0.2545, Top 70th Acc: 0.3247, Bottom 30th Acc: 0.0909
Fold [4/5] Epoch [10/100] Initial Loss: 0.1397, Training Loss: 0.0333, Initial Validation Loss: 0.1330, Validation Loss: 0.0471,V Acc: 0.7455, Top 70th Acc: 0.8701, Bottom 30th Acc: 0.4545
Fold [4/5] Epoch [20/100] Initial Loss: 0.1397, Training Loss: 0.0193, Initial Validation Loss: 0.1330, Validation Loss: 0.0429,V Acc: 0.7455, Top 70th Acc: 0.8831, Bottom 30th Acc: 0.4242
Fold [4/5] Epoch [30/100] Initial Loss: 0.1397, Training Loss: 0.0124, Initial Validation Loss: 0.1330, Validation Loss: 0.0375,V Acc: 0.7818, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.4545
Fold [4/5] Epoch [40/100] Initial Loss: 0.1397, Training Loss: 0.0104, Initial Validation Loss: 0.1330, Validation Loss: 0.0369,V Acc: 0.7909, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.4848
Stopping early at Epoch (base 0): 46  Rolling back to Epoch (base 0): 41  Top Validation Acc: 0.922077922077922
Fold [5/5] Epoch [0/100] Initial Loss: 0.1371, Training Loss: 0.1371, Initial Validation Loss: 0.1292, Validation Loss: 0.1292,V Acc: 0.2870, Top 70th Acc: 0.3553, Bottom 30th Acc: 0.1250
Fold [5/5] Epoch [10/100] Initial Loss: 0.1371, Training Loss: 0.0250, Initial Validation Loss: 0.1292, Validation Loss: 0.0334,V Acc: 0.8056, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.4688
Fold [5/5] Epoch [20/100] Initial Loss: 0.1371, Training Loss: 0.0126, Initial Validation Loss: 0.1292, Validation Loss: 0.0289,V Acc: 0.8333, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.5312
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.9473684210526315
96 4 [array([0.70922583, 0.04882978, 0.04345096, 0.08759215, 0.11090127],
      dtype=float32)]
Running train_nn.py with seed 97
CUDA:False
Training samples count:  550
Training on 40 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1358, Training Loss: 0.1358, Initial Validation Loss: 0.1361, Validation Loss: 0.1361,V Acc: 0.3604, Top 70th Acc: 0.3718, Bottom 30th Acc: 0.3333
Fold [1/5] Epoch [10/100] Initial Loss: 0.1358, Training Loss: 0.0301, Initial Validation Loss: 0.1361, Validation Loss: 0.0375,V Acc: 0.8829, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.7576
Fold [1/5] Epoch [20/100] Initial Loss: 0.1358, Training Loss: 0.0159, Initial Validation Loss: 0.1361, Validation Loss: 0.0285,V Acc: 0.8739, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.9743589743589743
Fold [2/5] Epoch [0/100] Initial Loss: 0.1403, Training Loss: 0.1403, Initial Validation Loss: 0.1378, Validation Loss: 0.1378,V Acc: 0.2523, Top 70th Acc: 0.1795, Bottom 30th Acc: 0.4242
Fold [2/5] Epoch [10/100] Initial Loss: 0.1403, Training Loss: 0.0258, Initial Validation Loss: 0.1378, Validation Loss: 0.0320,V Acc: 0.8468, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.5758
Fold [2/5] Epoch [20/100] Initial Loss: 0.1403, Training Loss: 0.0140, Initial Validation Loss: 0.1378, Validation Loss: 0.0285,V Acc: 0.8649, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 21  Rolling back to Epoch (base 0): 16  Top Validation Acc: 0.9615384615384616
97 1 [array([0.47183028, 0.10928001, 0.10317435, 0.08748403, 0.2282314 ],
      dtype=float32)]
Fold [3/5] Epoch [0/100] Initial Loss: 0.1409, Training Loss: 0.1409, Initial Validation Loss: 0.1333, Validation Loss: 0.1333,V Acc: 0.3455, Top 70th Acc: 0.4026, Bottom 30th Acc: 0.2121
Fold [3/5] Epoch [10/100] Initial Loss: 0.1409, Training Loss: 0.0298, Initial Validation Loss: 0.1333, Validation Loss: 0.0290,V Acc: 0.9000, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.7576
Fold [3/5] Epoch [20/100] Initial Loss: 0.1409, Training Loss: 0.0146, Initial Validation Loss: 0.1333, Validation Loss: 0.0234,V Acc: 0.8909, Top 70th Acc: 0.9870, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.974025974025974
Fold [4/5] Epoch [0/100] Initial Loss: 0.1404, Training Loss: 0.1404, Initial Validation Loss: 0.1344, Validation Loss: 0.1344,V Acc: 0.3182, Top 70th Acc: 0.3766, Bottom 30th Acc: 0.1818
Fold [4/5] Epoch [10/100] Initial Loss: 0.1404, Training Loss: 0.0233, Initial Validation Loss: 0.1344, Validation Loss: 0.0319,V Acc: 0.8455, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.5758
Fold [4/5] Epoch [20/100] Initial Loss: 0.1404, Training Loss: 0.0132, Initial Validation Loss: 0.1344, Validation Loss: 0.0308,V Acc: 0.8727, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.948051948051948
Fold [5/5] Epoch [0/100] Initial Loss: 0.1381, Training Loss: 0.1381, Initial Validation Loss: 0.1291, Validation Loss: 0.1291,V Acc: 0.2870, Top 70th Acc: 0.3289, Bottom 30th Acc: 0.1875
Fold [5/5] Epoch [10/100] Initial Loss: 0.1381, Training Loss: 0.0272, Initial Validation Loss: 0.1291, Validation Loss: 0.0473,V Acc: 0.7315, Top 70th Acc: 0.8553, Bottom 30th Acc: 0.4375
Fold [5/5] Epoch [20/100] Initial Loss: 0.1381, Training Loss: 0.0140, Initial Validation Loss: 0.1291, Validation Loss: 0.0444,V Acc: 0.7685, Top 70th Acc: 0.8684, Bottom 30th Acc: 0.5312
Fold [5/5] Epoch [30/100] Initial Loss: 0.1381, Training Loss: 0.0106, Initial Validation Loss: 0.1291, Validation Loss: 0.0438,V Acc: 0.7685, Top 70th Acc: 0.8684, Bottom 30th Acc: 0.5312
Stopping early at Epoch (base 0): 33  Rolling back to Epoch (base 0): 28  Top Validation Acc: 0.881578947368421
Running train_nn.py with seed 98
CUDA:False
Training samples count:  550
Training on 40 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1411, Training Loss: 0.1411, Initial Validation Loss: 0.1385, Validation Loss: 0.1385,V Acc: 0.3243, Top 70th Acc: 0.3462, Bottom 30th Acc: 0.2727
Fold [1/5] Epoch [10/100] Initial Loss: 0.1411, Training Loss: 0.0293, Initial Validation Loss: 0.1385, Validation Loss: 0.0340,V Acc: 0.8018, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.3939/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)

Fold [2/5] Epoch [10/100] Initial Loss: 0.1408, Training Loss: 0.0359, Initial Validation Loss: 0.1366, Validation Loss: 0.0387,V Acc: 0.8559, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.6970
Fold [2/5] Epoch [20/100] Initial Loss: 0.1408, Training Loss: 0.0172, Initial Validation Loss: 0.1366, Validation Loss: 0.0295,V Acc: 0.8559, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.9358974358974359
Fold [3/5] Epoch [0/100] Initial Loss: 0.1380, Training Loss: 0.1380, Initial Validation Loss: 0.1320, Validation Loss: 0.1320,V Acc: 0.3000, Top 70th Acc: 0.3766, Bottom 30th Acc: 0.1212
Fold [3/5] Epoch [10/100] Initial Loss: 0.1380, Training Loss: 0.0256, Initial Validation Loss: 0.1320, Validation Loss: 0.0331,V Acc: 0.8182, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.5455
Fold [3/5] Epoch [20/100] Initial Loss: 0.1380, Training Loss: 0.0164, Initial Validation Loss: 0.1320, Validation Loss: 0.0298,V Acc: 0.8182, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.4848
Stopping early at Epoch (base 0): 28  Rolling back to Epoch (base 0): 23  Top Validation Acc: 0.948051948051948
Fold [4/5] Epoch [0/100] Initial Loss: 0.1376, Training Loss: 0.1376, Initial Validation Loss: 0.1322, Validation Loss: 0.1322,V Acc: 0.3727, Top 70th Acc: 0.4935, Bottom 30th Acc: 0.0909
Fold [4/5] Epoch [10/100] Initial Loss: 0.1376, Training Loss: 0.0366, Initial Validation Loss: 0.1322, Validation Loss: 0.0413,V Acc: 0.8182, Top 70th Acc: 0.8961, Bottom 30th Acc: 0.6364
Fold [4/5] Epoch [20/100] Initial Loss: 0.1376, Training Loss: 0.0185, Initial Validation Loss: 0.1322, Validation Loss: 0.0286,V Acc: 0.8909, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.7576
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.922077922077922
Fold [5/5] Epoch [0/100] Initial Loss: 0.1409, Training Loss: 0.1409, Initial Validation Loss: 0.1364, Validation Loss: 0.1364,V Acc: 0.2685, Top 70th Acc: 0.2632, Bottom 30th Acc: 0.2812
Fold [5/5] Epoch [10/100] Initial Loss: 0.1409, Training Loss: 0.0340, Initial Validation Loss: 0.1364, Validation Loss: 0.0408,V Acc: 0.8333, Top 70th Acc: 0.9211, Bottom 30th Acc: 0.6250
Fold [5/5] Epoch [20/100] Initial Loss: 0.1409, Training Loss: 0.0171, Initial Validation Loss: 0.1364, Validation Loss: 0.0327,V Acc: 0.8426, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.5938
Stopping early at Epoch (base 0): 21  Rolling back to Epoch (base 0): 16  Top Validation Acc: 0.9605263157894737
99 4 [array([0.7386587 , 0.05256415, 0.03648154, 0.10290159, 0.06939404],
      dtype=float32)]
Running train_nn.py with seed 100
CUDA:False
Training samples count:  550
Training on 30 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1416, Training Loss: 0.1416, Initial Validation Loss: 0.1393, Validation Loss: 0.1393,V Acc: 0.3333, Top 70th Acc: 0.3718, Bottom 30th Acc: 0.2424
Fold [1/5] Epoch [10/100] Initial Loss: 0.1416, Training Loss: 0.0303, Initial Validation Loss: 0.1393, Validation Loss: 0.0335,V Acc: 0.8739, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.6364
Fold [1/5] Epoch [20/100] Initial Loss: 0.1416, Training Loss: 0.0191, Initial Validation Loss: 0.1393, Validation Loss: 0.0245,V Acc: 0.9189, Top 70th Acc: 1.0000, Bottom 30th Acc: 0.7273
Fold [1/5] Epoch [30/100] Initial Loss: 0.1416, Training Loss: 0.0166, Initial Validation Loss: 0.1393, Validation Loss: 0.0237,V Acc: 0.9189, Top 70th Acc: 1.0000, Bottom 30th Acc: 0.7273
Stopping early at Epoch (base 0): 33  Rolling back to Epoch (base 0): 28  Top Validation Acc: 1.0
Fold [2/5] Epoch [0/100] Initial Loss: 0.1368, Training Loss: 0.1368, Initial Validation Loss: 0.1375, Validation Loss: 0.1375,V Acc: 0.2973, Top 70th Acc: 0.3333, Bottom 30th Acc: 0.2121
Fold [2/5] Epoch [10/100] Initial Loss: 0.1368, Training Loss: 0.0428, Initial Validation Loss: 0.1375, Validation Loss: 0.0470,V Acc: 0.8108, Top 70th Acc: 0.8718, Bottom 30th Acc: 0.6667
Fold [2/5] Epoch [20/100] Initial Loss: 0.1368, Training Loss: 0.0175, Initial Validation Loss: 0.1375, Validation Loss: 0.0366,V Acc: 0.8468, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 21  Rolling back to Epoch (base 0): 16  Top Validation Acc: 0.9487179487179487
Fold [3/5] Epoch [0/100] Initial Loss: 0.1400, Training Loss: 0.1400, Initial Validation Loss: 0.1270, Validation Loss: 0.1270,V Acc: 0.3818, Top 70th Acc: 0.4286, Bottom 30th Acc: 0.2727
Fold [3/5] Epoch [10/100] Initial Loss: 0.1400, Training Loss: 0.0406, Initial Validation Loss: 0.1270, Validation Loss: 0.0507,V Acc: 0.7091, Top 70th Acc: 0.8312, Bottom 30th Acc: 0.4242
Fold [3/5] Epoch [20/100] Initial Loss: 0.1400, Training Loss: 0.0162, Initial Validation Loss: 0.1270, Validation Loss: 0.0373,V Acc: 0.7727, Top 70th Acc: 0.8831, Bottom 30th Acc: 0.5152
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.922077922077922
100 2 [array([0.6603037 , 0.06284465, 0.03840666, 0.12967429, 0.1087706 ],
      dtype=float32)]
Fold [4/5] Epoch [0/100] Initial Loss: 0.1400, Training Loss: 0.1400, Initial Validation Loss: 0.1399, Validation Loss: 0.1399,V Acc: 0.1909, Top 70th Acc: 0.1818, Bottom 30th Acc: 0.2121
Fold [4/5] Epoch [10/100] Initial Loss: 0.1400, Training Loss: 0.0439, Initial Validation Loss: 0.1399, Validation Loss: 0.0463,V Acc: 0.7818, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.4848
Fold [4/5] Epoch [20/100] Initial Loss: 0.1400, Training Loss: 0.0227, Initial Validation Loss: 0.1399, Validation Loss: 0.0281,V Acc: 0.8818, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.6970
Fold [4/5] Epoch [30/100] Initial Loss: 0.1400, Training Loss: 0.0185, Initial Validation Loss: 0.1399, Validation Loss: 0.0256,V Acc: 0.8909, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 32  Rolling back to Epoch (base 0): 27  Top Validation Acc: 0.974025974025974
Fold [5/5] Epoch [0/100] Initial Loss: 0.1403, Training Loss: 0.1403, Initial Validation Loss: 0.1320, Validation Loss: 0.1320,V Acc: 0.2778, Top 70th Acc: 0.3026, Bottom 30th Acc: 0.2188
Fold [5/5] Epoch [10/100] Initial Loss: 0.1403, Training Loss: 0.0466, Initial Validation Loss: 0.1320, Validation Loss: 0.0548,V Acc: 0.6667, Top 70th Acc: 0.8421, Bottom 30th Acc: 0.2500
Fold [5/5] Epoch [20/100] Initial Loss: 0.1403, Training Loss: 0.0189, Initial Validation Loss: 0.1320, Validation Loss: 0.0343,V Acc: 0.8333, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.5938
Fold [5/5] Epoch [30/100] Initial Loss: 0.1403, Training Loss: 0.0151, Initial Validation Loss: 0.1320, Validation Loss: 0.0346,V Acc: 0.8148, Top 70th Acc: 0.9079, Bottom 30th Acc: 0.5938
Stopping early at Epoch (base 0): 30  Rolling back to Epoch (base 0): 25  Top Validation Acc: 0.9078947368421053
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)

Fold [2/5] Epoch [10/100] Initial Loss: 0.1400, Training Loss: 0.0263, Initial Validation Loss: 0.1342, Validation Loss: 0.0459,V Acc: 0.7838, Top 70th Acc: 0.8590, Bottom 30th Acc: 0.6061
Fold [2/5] Epoch [20/100] Initial Loss: 0.1400, Training Loss: 0.0072, Initial Validation Loss: 0.1342, Validation Loss: 0.0396,V Acc: 0.7928, Top 70th Acc: 0.8974, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.8974358974358975
Fold [3/5] Epoch [0/100] Initial Loss: 0.1388, Training Loss: 0.1388, Initial Validation Loss: 0.1357, Validation Loss: 0.1357,V Acc: 0.2727, Top 70th Acc: 0.3636, Bottom 30th Acc: 0.0606
Fold [3/5] Epoch [10/100] Initial Loss: 0.1388, Training Loss: 0.0138, Initial Validation Loss: 0.1357, Validation Loss: 0.0350,V Acc: 0.8364, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.5758
Fold [3/5] Epoch [20/100] Initial Loss: 0.1388, Training Loss: 0.0048, Initial Validation Loss: 0.1357, Validation Loss: 0.0310,V Acc: 0.8455, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.6364
Fold [3/5] Epoch [30/100] Initial Loss: 0.1388, Training Loss: 0.0038, Initial Validation Loss: 0.1357, Validation Loss: 0.0297,V Acc: 0.8545, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6364
Fold [3/5] Epoch [40/100] Initial Loss: 0.1388, Training Loss: 0.0035, Initial Validation Loss: 0.1357, Validation Loss: 0.0292,V Acc: 0.8545, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6364
Fold [3/5] Epoch [50/100] Initial Loss: 0.1388, Training Loss: 0.0034, Initial Validation Loss: 0.1357, Validation Loss: 0.0290,V Acc: 0.8545, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 51  Rolling back to Epoch (base 0): 46  Top Validation Acc: 0.948051948051948
Fold [4/5] Epoch [0/100] Initial Loss: 0.1397, Training Loss: 0.1397, Initial Validation Loss: 0.1370, Validation Loss: 0.1370,V Acc: 0.2727, Top 70th Acc: 0.2857, Bottom 30th Acc: 0.2424
Fold [4/5] Epoch [10/100] Initial Loss: 0.1397, Training Loss: 0.0147, Initial Validation Loss: 0.1370, Validation Loss: 0.0339,V Acc: 0.8727, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.7576
Fold [4/5] Epoch [20/100] Initial Loss: 0.1397, Training Loss: 0.0051, Initial Validation Loss: 0.1370, Validation Loss: 0.0294,V Acc: 0.8727, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 28  Rolling back to Epoch (base 0): 23  Top Validation Acc: 0.948051948051948
76 3 [array([0.2034617 , 0.07451317, 0.12011063, 0.27970234, 0.32221222],
      dtype=float32)]
Fold [5/5] Epoch [0/100] Initial Loss: 0.1393, Training Loss: 0.1393, Initial Validation Loss: 0.1282, Validation Loss: 0.1282,V Acc: 0.2870, Top 70th Acc: 0.3421, Bottom 30th Acc: 0.1562
Fold [5/5] Epoch [10/100] Initial Loss: 0.1393, Training Loss: 0.0159, Initial Validation Loss: 0.1282, Validation Loss: 0.0501,V Acc: 0.7130, Top 70th Acc: 0.8158, Bottom 30th Acc: 0.4688
Fold [5/5] Epoch [20/100] Initial Loss: 0.1393, Training Loss: 0.0052, Initial Validation Loss: 0.1282, Validation Loss: 0.0459,V Acc: 0.7222, Top 70th Acc: 0.8553, Bottom 30th Acc: 0.4062
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.8421052631578947
Running train_nn.py with seed 77
CUDA:False
Training samples count:  550
Training on 163 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1372, Training Loss: 0.1372, Initial Validation Loss: 0.1363, Validation Loss: 0.1363,V Acc: 0.3333, Top 70th Acc: 0.3333, Bottom 30th Acc: 0.3333
Fold [1/5] Epoch [10/100] Initial Loss: 0.1372, Training Loss: 0.0140, Initial Validation Loss: 0.1363, Validation Loss: 0.0294,V Acc: 0.8649, Top 70th Acc: 0.9872, Bottom 30th Acc: 0.5758
Fold [1/5] Epoch [20/100] Initial Loss: 0.1372, Training Loss: 0.0047, Initial Validation Loss: 0.1363, Validation Loss: 0.0272,V Acc: 0.8559, Top 70th Acc: 0.9872, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 27  Rolling back to Epoch (base 0): 22  Top Validation Acc: 0.9871794871794872
Fold [2/5] Epoch [0/100] Initial Loss: 0.1385, Training Loss: 0.1385, Initial Validation Loss: 0.1331, Validation Loss: 0.1331,V Acc: 0.3153, Top 70th Acc: 0.3590, Bottom 30th Acc: 0.2121
Fold [2/5] Epoch [10/100] Initial Loss: 0.1385, Training Loss: 0.0220, Initial Validation Loss: 0.1331, Validation Loss: 0.0437,V Acc: 0.7658, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.4242
Fold [2/5] Epoch [20/100] Initial Loss: 0.1385, Training Loss: 0.0049, Initial Validation Loss: 0.1331, Validation Loss: 0.0351,V Acc: 0.8288, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 28  Rolling back to Epoch (base 0): 23  Top Validation Acc: 0.9487179487179487
Fold [3/5] Epoch [0/100] Initial Loss: 0.1395, Training Loss: 0.1395, Initial Validation Loss: 0.1319, Validation Loss: 0.1319,V Acc: 0.3273, Top 70th Acc: 0.3247, Bottom 30th Acc: 0.3333
Fold [3/5] Epoch [10/100] Initial Loss: 0.1395, Training Loss: 0.0189, Initial Validation Loss: 0.1319, Validation Loss: 0.0361,V Acc: 0.8273, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.5758
Fold [3/5] Epoch [20/100] Initial Loss: 0.1395, Training Loss: 0.0046, Initial Validation Loss: 0.1319, Validation Loss: 0.0261,V Acc: 0.8818, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.974025974025974
Fold [4/5] Epoch [0/100] Initial Loss: 0.1403, Training Loss: 0.1403, Initial Validation Loss: 0.1358, Validation Loss: 0.1358,V Acc: 0.4000, Top 70th Acc: 0.4805, Bottom 30th Acc: 0.2121
Fold [4/5] Epoch [10/100] Initial Loss: 0.1403, Training Loss: 0.0160, Initial Validation Loss: 0.1358, Validation Loss: 0.0250,V Acc: 0.9091, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.7879
Fold [4/5] Epoch [20/100] Initial Loss: 0.1403, Training Loss: 0.0058, Initial Validation Loss: 0.1358, Validation Loss: 0.0200,V Acc: 0.9000, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.7273
Fold [4/5] Epoch [30/100] Initial Loss: 0.1403, Training Loss: 0.0044, Initial Validation Loss: 0.1358, Validation Loss: 0.0201,V Acc: 0.9000, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.7273
Stopping early at Epoch (base 0): 31  Rolling back to Epoch (base 0): 26  Top Validation Acc: 0.974025974025974
Fold [5/5] Epoch [0/100] Initial Loss: 0.1382, Training Loss: 0.1382, Initial Validation Loss: 0.1339, Validation Loss: 0.1339,V Acc: 0.2963, Top 70th Acc: 0.4079, Bottom 30th Acc: 0.0312
Fold [5/5] Epoch [10/100] Initial Loss: 0.1382, Training Loss: 0.0123, Initial Validation Loss: 0.1339, Validation Loss: 0.0307,V Acc: 0.8704, Top 70th Acc: 0.9079, Bottom 30th Acc: 0.7812
Fold [5/5] Epoch [20/100] Initial Loss: 0.1382, Training Loss: 0.0048, Initial Validation Loss: 0.1339, Validation Loss: 0.0269,V Acc: 0.8611, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.6875
Fold [5/5] Epoch [30/100] Initial Loss: 0.1382, Training Loss: 0.0040, Initial Validation Loss: 0.1339, Validation Loss: 0.0277,V Acc: 0.8611, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.6875
Stopping early at Epoch (base 0): 31  Rolling back to Epoch (base 0): 26  Top Validation Acc: 0.9342105263157895
77 4 [array([0.1900367 , 0.05221777, 0.04661082, 0.10509061, 0.6060441 ],
      dtype=float32)]
Running train_nn.py with seed 78
CUDA:False
Training samples count:  550
Training on 163 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1384, Training Loss: 0.1384, Initial Validation Loss: 0.1365, Validation Loss: 0.1365,V Acc: 0.3153, Top 70th Acc: 0.3590, Bottom 30th Acc: 0.2121
Fold [1/5] Epoch [10/100] Initial Loss: 0.1384, Training Loss: 0.0204, Initial Validation Loss: 0.1365, Validation Loss: 0.0369,V Acc: 0.8559, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.6970
Fold [1/5] Epoch [20/100] Initial Loss: 0.1384, Training Loss: 0.0068, Initial Validation Loss: 0.1365, Validation Loss: 0.0355,V Acc: 0.8559, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.9358974358974359
Fold [2/5] Epoch [0/100] Initial Loss: 0.1391, Training Loss: 0.1391, Initial Validation Loss: 0.1364, Validation Loss: 0.1364,V Acc: 0.2613, Top 70th Acc: 0.2436, Bottom 30th Acc: 0.3030
Fold [2/5] Epoch [10/100] Initial Loss: 0.1391, Training Loss: 0.0178, Initial Validation Loss: 0.1364, Validation Loss: 0.0396,V Acc: 0.8288, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.6061
Fold [4/5] Epoch [10/100] Initial Loss: 0.1414, Training Loss: 0.0800, Initial Validation Loss: 0.1296, Validation Loss: 0.0841,V Acc: 0.6000, Top 70th Acc: 0.7273, Bottom 30th Acc: 0.3030
Fold [4/5] Epoch [20/100] Initial Loss: 0.1414, Training Loss: 0.0785, Initial Validation Loss: 0.1296, Validation Loss: 0.0813,V Acc: 0.6182, Top 70th Acc: 0.7403, Bottom 30th Acc: 0.3333
Fold [4/5] Epoch [30/100] Initial Loss: 0.1414, Training Loss: 0.0776, Initial Validation Loss: 0.1296, Validation Loss: 0.0809,V Acc: 0.6182, Top 70th Acc: 0.7403, Bottom 30th Acc: 0.3333
Stopping early at Epoch (base 0): 36  Rolling back to Epoch (base 0): 31  Top Validation Acc: 0.7402597402597403
Fold [5/5] Epoch [0/100] Initial Loss: 0.1290, Training Loss: 0.1290, Initial Validation Loss: 0.1116, Validation Loss: 0.1116,V Acc: 0.5926, Top 70th Acc: 0.7105, Bottom 30th Acc: 0.3125
Fold [5/5] Epoch [10/100] Initial Loss: 0.1290, Training Loss: 0.0806, Initial Validation Loss: 0.1116, Validation Loss: 0.0738,V Acc: 0.6111, Top 70th Acc: 0.7632, Bottom 30th Acc: 0.2500
Fold [5/5] Epoch [20/100] Initial Loss: 0.1290, Training Loss: 0.0787, Initial Validation Loss: 0.1116, Validation Loss: 0.0732,V Acc: 0.6481, Top 70th Acc: 0.7632, Bottom 30th Acc: 0.3750
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.7631578947368421
95 4 [array([0.16326044, 0.32936537, 0.13588132, 0.22787797, 0.14361486],
      dtype=float32)]
Running train_nn.py with seed 96
CUDA:False
Training samples count:  550
Training on 2 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1332, Training Loss: 0.1332, Initial Validation Loss: 0.1239, Validation Loss: 0.1239,V Acc: 0.5135, Top 70th Acc: 0.5641, Bottom 30th Acc: 0.3939
Fold [1/5] Epoch [10/100] Initial Loss: 0.1332, Training Loss: 0.0812, Initial Validation Loss: 0.1239, Validation Loss: 0.0839,V Acc: 0.5856, Top 70th Acc: 0.6795, Bottom 30th Acc: 0.3636
Fold [1/5] Epoch [20/100] Initial Loss: 0.1332, Training Loss: 0.0788, Initial Validation Loss: 0.1239, Validation Loss: 0.0821,V Acc: 0.5856, Top 70th Acc: 0.6795, Bottom 30th Acc: 0.3636
Fold [1/5] Epoch [30/100] Initial Loss: 0.1332, Training Loss: 0.0777, Initial Validation Loss: 0.1239, Validation Loss: 0.0807,V Acc: 0.6216, Top 70th Acc: 0.7436, Bottom 30th Acc: 0.3333
Stopping early at Epoch (base 0): 36  Rolling back to Epoch (base 0): 31  Top Validation Acc: 0.6923076923076923
Fold [2/5] Epoch [0/100] Initial Loss: 0.1380, Training Loss: 0.1380, Initial Validation Loss: 0.1308, Validation Loss: 0.1308,V Acc: 0.2793, Top 70th Acc: 0.3718, Bottom 30th Acc: 0.0606
Fold [2/5] Epoch [10/100] Initial Loss: 0.1380, Training Loss: 0.0826, Initial Validation Loss: 0.1308, Validation Loss: 0.0761,V Acc: 0.6667, Top 70th Acc: 0.8077, Bottom 30th Acc: 0.3333
Fold [2/5] Epoch [20/100] Initial Loss: 0.1380, Training Loss: 0.0810, Initial Validation Loss: 0.1308, Validation Loss: 0.0735,V Acc: 0.6847, Top 70th Acc: 0.8077, Bottom 30th Acc: 0.3939
Stopping early at Epoch (base 0): 28  Rolling back to Epoch (base 0): 23  Top Validation Acc: 0.8076923076923077
Fold [3/5] Epoch [0/100] Initial Loss: 0.1366, Training Loss: 0.1366, Initial Validation Loss: 0.1322, Validation Loss: 0.1322,V Acc: 0.3182, Top 70th Acc: 0.3896, Bottom 30th Acc: 0.1515
Fold [3/5] Epoch [10/100] Initial Loss: 0.1366, Training Loss: 0.0826, Initial Validation Loss: 0.1322, Validation Loss: 0.0774,V Acc: 0.6455, Top 70th Acc: 0.7662, Bottom 30th Acc: 0.3636
Fold [3/5] Epoch [20/100] Initial Loss: 0.1366, Training Loss: 0.0806, Initial Validation Loss: 0.1322, Validation Loss: 0.0749,V Acc: 0.6636, Top 70th Acc: 0.7922, Bottom 30th Acc: 0.3636
Fold [3/5] Epoch [30/100] Initial Loss: 0.1366, Training Loss: 0.0797, Initial Validation Loss: 0.1322, Validation Loss: 0.0734,V Acc: 0.6636, Top 70th Acc: 0.8052, Bottom 30th Acc: 0.3333
Stopping early at Epoch (base 0): 35  Rolling back to Epoch (base 0): 30  Top Validation Acc: 0.8051948051948052
Fold [4/5] Epoch [0/100] Initial Loss: 0.1368, Training Loss: 0.1368, Initial Validation Loss: 0.1261, Validation Loss: 0.1261,V Acc: 0.4909, Top 70th Acc: 0.5974, Bottom 30th Acc: 0.2424
Fold [4/5] Epoch [10/100] Initial Loss: 0.1368, Training Loss: 0.0784, Initial Validation Loss: 0.1261, Validation Loss: 0.0851,V Acc: 0.5818, Top 70th Acc: 0.6753, Bottom 30th Acc: 0.3636
Stopping early at Epoch (base 0): 17  Rolling back to Epoch (base 0): 12  Top Validation Acc: 0.6883116883116883
Fold [5/5] Epoch [0/100] Initial Loss: 0.1378, Training Loss: 0.1378, Initial Validation Loss: 0.1269, Validation Loss: 0.1269,V Acc: 0.3889, Top 70th Acc: 0.4868, Bottom 30th Acc: 0.1562
Fold [5/5] Epoch [10/100] Initial Loss: 0.1378, Training Loss: 0.0804, Initial Validation Loss: 0.1269, Validation Loss: 0.0809,V Acc: 0.6296, Top 70th Acc: 0.6711, Bottom 30th Acc: 0.5312
Fold [5/5] Epoch [20/100] Initial Loss: 0.1378, Training Loss: 0.0777, Initial Validation Loss: 0.1269, Validation Loss: 0.0790,V Acc: 0.6389, Top 70th Acc: 0.6711, Bottom 30th Acc: 0.5625
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.6842105263157895
96 4 [array([0.12302566, 0.36363292, 0.15695114, 0.2258334 , 0.13055688],
      dtype=float32)]
Running train_nn.py with seed 97
CUDA:False
Training samples count:  550
Training on 2 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1353, Training Loss: 0.1353, Initial Validation Loss: 0.1322, Validation Loss: 0.1322,V Acc: 0.3604, Top 70th Acc: 0.3718, Bottom 30th Acc: 0.3333
Fold [1/5] Epoch [10/100] Initial Loss: 0.1353, Training Loss: 0.0803, Initial Validation Loss: 0.1322, Validation Loss: 0.0852,V Acc: 0.6306, Top 70th Acc: 0.7308, Bottom 30th Acc: 0.3939
Fold [1/5] Epoch [20/100] Initial Loss: 0.1353, Training Loss: 0.0781, Initial Validation Loss: 0.1322, Validation Loss: 0.0830,V Acc: 0.6306, Top 70th Acc: 0.7436, Bottom 30th Acc: 0.3636
Fold [1/5] Epoch [30/100] Initial Loss: 0.1353, Training Loss: 0.0773, Initial Validation Loss: 0.1322, Validation Loss: 0.0833,V Acc: 0.6306, Top 70th Acc: 0.7436, Bottom 30th Acc: 0.3636
Stopping early at Epoch (base 0): 38  Rolling back to Epoch (base 0): 33  Top Validation Acc: 0.7307692307692307
Fold [2/5] Epoch [0/100] Initial Loss: 0.1369, Training Loss: 0.1369, Initial Validation Loss: 0.1252, Validation Loss: 0.1252,V Acc: 0.5315, Top 70th Acc: 0.5897, Bottom 30th Acc: 0.3939
Fold [2/5] Epoch [10/100] Initial Loss: 0.1369, Training Loss: 0.0797, Initial Validation Loss: 0.1252, Validation Loss: 0.0842,V Acc: 0.5676, Top 70th Acc: 0.7051, Bottom 30th Acc: 0.2424
Stopping early at Epoch (base 0): 11  Rolling back to Epoch (base 0): 6  Top Validation Acc: 0.6794871794871795
97 1 [array([0.14347139, 0.37218556, 0.16831943, 0.15221675, 0.16380684],
      dtype=float32)]
Fold [3/5] Epoch [0/100] Initial Loss: 0.1335, Training Loss: 0.1335, Initial Validation Loss: 0.1233, Validation Loss: 0.1233,V Acc: 0.3909, Top 70th Acc: 0.4675, Bottom 30th Acc: 0.2121
Fold [3/5] Epoch [10/100] Initial Loss: 0.1335, Training Loss: 0.0800, Initial Validation Loss: 0.1233, Validation Loss: 0.0830,V Acc: 0.6182, Top 70th Acc: 0.7143, Bottom 30th Acc: 0.3939
Fold [3/5] Epoch [20/100] Initial Loss: 0.1335, Training Loss: 0.0776, Initial Validation Loss: 0.1233, Validation Loss: 0.0801,V Acc: 0.6455, Top 70th Acc: 0.7532, Bottom 30th Acc: 0.3939
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.7272727272727273
Fold [4/5] Epoch [0/100] Initial Loss: 0.1392, Training Loss: 0.1392, Initial Validation Loss: 0.1305, Validation Loss: 0.1305,V Acc: 0.3909, Top 70th Acc: 0.5065, Bottom 30th Acc: 0.1212
Fold [4/5] Epoch [10/100] Initial Loss: 0.1392, Training Loss: 0.0810, Initial Validation Loss: 0.1305, Validation Loss: 0.0807,V Acc: 0.6273, Top 70th Acc: 0.7403, Bottom 30th Acc: 0.3636
Fold [4/5] Epoch [20/100] Initial Loss: 0.1392, Training Loss: 0.0782, Initial Validation Loss: 0.1305, Validation Loss: 0.0788,V Acc: 0.6545, Top 70th Acc: 0.7403, Bottom 30th Acc: 0.4545
Stopping early at Epoch (base 0): 22  Rolling back to Epoch (base 0): 17  Top Validation Acc: 0.7272727272727273
Fold [5/5] Epoch [0/100] Initial Loss: 0.1391, Training Loss: 0.1391, Initial Validation Loss: 0.1284, Validation Loss: 0.1284,V Acc: 0.2500, Top 70th Acc: 0.3553, Bottom 30th Acc: 0.0000
Fold [1/5] Epoch [20/100] Initial Loss: 0.1411, Training Loss: 0.0149, Initial Validation Loss: 0.1385, Validation Loss: 0.0246,V Acc: 0.8739, Top 70th Acc: 1.0000, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 28  Rolling back to Epoch (base 0): 23  Top Validation Acc: 1.0
98 0 [array([0.40416703, 0.07001896, 0.09573657, 0.07819238, 0.35188502],
      dtype=float32)]
Fold [2/5] Epoch [0/100] Initial Loss: 0.1387, Training Loss: 0.1387, Initial Validation Loss: 0.1300, Validation Loss: 0.1300,V Acc: 0.2703, Top 70th Acc: 0.3205, Bottom 30th Acc: 0.1515
Fold [2/5] Epoch [10/100] Initial Loss: 0.1387, Training Loss: 0.0350, Initial Validation Loss: 0.1300, Validation Loss: 0.0443,V Acc: 0.7748, Top 70th Acc: 0.8846, Bottom 30th Acc: 0.5152
Fold [2/5] Epoch [20/100] Initial Loss: 0.1387, Training Loss: 0.0136, Initial Validation Loss: 0.1300, Validation Loss: 0.0318,V Acc: 0.8018, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.5152
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.9230769230769231
Fold [3/5] Epoch [0/100] Initial Loss: 0.1391, Training Loss: 0.1391, Initial Validation Loss: 0.1374, Validation Loss: 0.1374,V Acc: 0.3545, Top 70th Acc: 0.4026, Bottom 30th Acc: 0.2424
Fold [3/5] Epoch [10/100] Initial Loss: 0.1391, Training Loss: 0.0281, Initial Validation Loss: 0.1374, Validation Loss: 0.0402,V Acc: 0.8545, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.6970
Fold [3/5] Epoch [20/100] Initial Loss: 0.1391, Training Loss: 0.0142, Initial Validation Loss: 0.1374, Validation Loss: 0.0317,V Acc: 0.8727, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6970
Fold [3/5] Epoch [30/100] Initial Loss: 0.1391, Training Loss: 0.0119, Initial Validation Loss: 0.1374, Validation Loss: 0.0296,V Acc: 0.8909, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.7576
Fold [3/5] Epoch [40/100] Initial Loss: 0.1391, Training Loss: 0.0107, Initial Validation Loss: 0.1374, Validation Loss: 0.0285,V Acc: 0.8818, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.7273
Stopping early at Epoch (base 0): 46  Rolling back to Epoch (base 0): 41  Top Validation Acc: 0.948051948051948
Fold [4/5] Epoch [0/100] Initial Loss: 0.1392, Training Loss: 0.1392, Initial Validation Loss: 0.1323, Validation Loss: 0.1323,V Acc: 0.2818, Top 70th Acc: 0.3117, Bottom 30th Acc: 0.2121
Fold [4/5] Epoch [10/100] Initial Loss: 0.1392, Training Loss: 0.0308, Initial Validation Loss: 0.1323, Validation Loss: 0.0346,V Acc: 0.8182, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.5152
Fold [4/5] Epoch [20/100] Initial Loss: 0.1392, Training Loss: 0.0160, Initial Validation Loss: 0.1323, Validation Loss: 0.0280,V Acc: 0.8364, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.5455
Fold [4/5] Epoch [30/100] Initial Loss: 0.1392, Training Loss: 0.0113, Initial Validation Loss: 0.1323, Validation Loss: 0.0267,V Acc: 0.8545, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 33  Rolling back to Epoch (base 0): 28  Top Validation Acc: 0.948051948051948
Fold [5/5] Epoch [0/100] Initial Loss: 0.1358, Training Loss: 0.1358, Initial Validation Loss: 0.1299, Validation Loss: 0.1299,V Acc: 0.3426, Top 70th Acc: 0.3947, Bottom 30th Acc: 0.2188
Fold [5/5] Epoch [10/100] Initial Loss: 0.1358, Training Loss: 0.0260, Initial Validation Loss: 0.1299, Validation Loss: 0.0353,V Acc: 0.8426, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.6250
Fold [5/5] Epoch [20/100] Initial Loss: 0.1358, Training Loss: 0.0134, Initial Validation Loss: 0.1299, Validation Loss: 0.0306,V Acc: 0.8333, Top 70th Acc: 0.9737, Bottom 30th Acc: 0.5000
Stopping early at Epoch (base 0): 22  Rolling back to Epoch (base 0): 17  Top Validation Acc: 0.9736842105263158
Running train_nn.py with seed 99
CUDA:False
Training samples count:  550
Training on 40 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1394, Training Loss: 0.1394, Initial Validation Loss: 0.1314, Validation Loss: 0.1314,V Acc: 0.2523, Top 70th Acc: 0.3462, Bottom 30th Acc: 0.0303
Fold [1/5] Epoch [10/100] Initial Loss: 0.1394, Training Loss: 0.0293, Initial Validation Loss: 0.1314, Validation Loss: 0.0353,V Acc: 0.8108, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.5455
Fold [1/5] Epoch [20/100] Initial Loss: 0.1394, Training Loss: 0.0156, Initial Validation Loss: 0.1314, Validation Loss: 0.0273,V Acc: 0.8468, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 29  Rolling back to Epoch (base 0): 24  Top Validation Acc: 0.9615384615384616
Fold [2/5] Epoch [0/100] Initial Loss: 0.1378, Training Loss: 0.1378, Initial Validation Loss: 0.1385, Validation Loss: 0.1385,V Acc: 0.2793, Top 70th Acc: 0.2821, Bottom 30th Acc: 0.2727
Fold [2/5] Epoch [10/100] Initial Loss: 0.1378, Training Loss: 0.0251, Initial Validation Loss: 0.1385, Validation Loss: 0.0343,V Acc: 0.8468, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.6061
Fold [2/5] Epoch [20/100] Initial Loss: 0.1378, Training Loss: 0.0134, Initial Validation Loss: 0.1385, Validation Loss: 0.0313,V Acc: 0.8378, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.5758
Fold [2/5] Epoch [30/100] Initial Loss: 0.1378, Training Loss: 0.0112, Initial Validation Loss: 0.1385, Validation Loss: 0.0295,V Acc: 0.8468, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 34  Rolling back to Epoch (base 0): 29  Top Validation Acc: 0.9358974358974359
Fold [3/5] Epoch [0/100] Initial Loss: 0.1398, Training Loss: 0.1398, Initial Validation Loss: 0.1336, Validation Loss: 0.1336,V Acc: 0.2636, Top 70th Acc: 0.3377, Bottom 30th Acc: 0.0909
Fold [3/5] Epoch [10/100] Initial Loss: 0.1398, Training Loss: 0.0298, Initial Validation Loss: 0.1336, Validation Loss: 0.0366,V Acc: 0.8000, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.4848
Fold [3/5] Epoch [20/100] Initial Loss: 0.1398, Training Loss: 0.0150, Initial Validation Loss: 0.1336, Validation Loss: 0.0316,V Acc: 0.8182, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.922077922077922
Fold [4/5] Epoch [0/100] Initial Loss: 0.1354, Training Loss: 0.1354, Initial Validation Loss: 0.1276, Validation Loss: 0.1276,V Acc: 0.3455, Top 70th Acc: 0.4416, Bottom 30th Acc: 0.1212
Fold [4/5] Epoch [10/100] Initial Loss: 0.1354, Training Loss: 0.0286, Initial Validation Loss: 0.1276, Validation Loss: 0.0356,V Acc: 0.8727, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.7273
Fold [4/5] Epoch [20/100] Initial Loss: 0.1354, Training Loss: 0.0148, Initial Validation Loss: 0.1276, Validation Loss: 0.0277,V Acc: 0.8727, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.961038961038961
Fold [5/5] Epoch [0/100] Initial Loss: 0.1378, Training Loss: 0.1378, Initial Validation Loss: 0.1337, Validation Loss: 0.1337,V Acc: 0.2778, Top 70th Acc: 0.3158, Bottom 30th Acc: 0.1875
Fold [5/5] Epoch [10/100] Initial Loss: 0.1378, Training Loss: 0.0321, Initial Validation Loss: 0.1337, Validation Loss: 0.0446,V Acc: 0.8148, Top 70th Acc: 0.8947, Bottom 30th Acc: 0.6250
Fold [5/5] Epoch [20/100] Initial Loss: 0.1378, Training Loss: 0.0166, Initial Validation Loss: 0.1337, Validation Loss: 0.0360,V Acc: 0.7963, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.4062
Fold [5/5] Epoch [30/100] Initial Loss: 0.1378, Training Loss: 0.0130, Initial Validation Loss: 0.1337, Validation Loss: 0.0332,V Acc: 0.8333, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.5312
Fold [5/5] Epoch [40/100] Initial Loss: 0.1378, Training Loss: 0.0117, Initial Validation Loss: 0.1337, Validation Loss: 0.0313,V Acc: 0.8241, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.5000
Fold [5/5] Epoch [50/100] Initial Loss: 0.1378, Training Loss: 0.0108, Initial Validation Loss: 0.1337, Validation Loss: 0.0310,V Acc: 0.8519, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.5938
Stopping early at Epoch (base 0): 50  Rolling back to Epoch (base 0): 45  Top Validation Acc: 0.9605263157894737
99 4 [array([0.62041956, 0.08559608, 0.07088958, 0.15899077, 0.06410396],
      dtype=float32)]
Running train_nn.py with seed 100
CUDA:False
Training samples count:  550
Training on 40 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1377, Training Loss: 0.1377, Initial Validation Loss: 0.1382, Validation Loss: 0.1382,V Acc: 0.3063, Top 70th Acc: 0.3333, Bottom 30th Acc: 0.2424/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)

Fold [1/5] Epoch [10/100] Initial Loss: 0.1377, Training Loss: 0.0277, Initial Validation Loss: 0.1382, Validation Loss: 0.0365,V Acc: 0.8559, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.5758
Fold [1/5] Epoch [20/100] Initial Loss: 0.1377, Training Loss: 0.0152, Initial Validation Loss: 0.1382, Validation Loss: 0.0285,V Acc: 0.8829, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 27  Rolling back to Epoch (base 0): 22  Top Validation Acc: 0.9615384615384616
Fold [2/5] Epoch [0/100] Initial Loss: 0.1386, Training Loss: 0.1386, Initial Validation Loss: 0.1383, Validation Loss: 0.1383,V Acc: 0.2883, Top 70th Acc: 0.3590, Bottom 30th Acc: 0.1212
Fold [2/5] Epoch [10/100] Initial Loss: 0.1386, Training Loss: 0.0363, Initial Validation Loss: 0.1383, Validation Loss: 0.0458,V Acc: 0.7658, Top 70th Acc: 0.8974, Bottom 30th Acc: 0.4545
Fold [2/5] Epoch [20/100] Initial Loss: 0.1386, Training Loss: 0.0200, Initial Validation Loss: 0.1383, Validation Loss: 0.0405,V Acc: 0.8108, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.5455
Fold [2/5] Epoch [30/100] Initial Loss: 0.1386, Training Loss: 0.0126, Initial Validation Loss: 0.1383, Validation Loss: 0.0367,V Acc: 0.8288, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.5455
Fold [2/5] Epoch [40/100] Initial Loss: 0.1386, Training Loss: 0.0108, Initial Validation Loss: 0.1383, Validation Loss: 0.0346,V Acc: 0.8378, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 42  Rolling back to Epoch (base 0): 37  Top Validation Acc: 0.9358974358974359
Fold [3/5] Epoch [0/100] Initial Loss: 0.1406, Training Loss: 0.1406, Initial Validation Loss: 0.1283, Validation Loss: 0.1283,V Acc: 0.2545, Top 70th Acc: 0.2857, Bottom 30th Acc: 0.1818
Fold [3/5] Epoch [10/100] Initial Loss: 0.1406, Training Loss: 0.0284, Initial Validation Loss: 0.1283, Validation Loss: 0.0420,V Acc: 0.7636, Top 70th Acc: 0.8571, Bottom 30th Acc: 0.5455
Fold [3/5] Epoch [20/100] Initial Loss: 0.1406, Training Loss: 0.0129, Initial Validation Loss: 0.1283, Validation Loss: 0.0374,V Acc: 0.7455, Top 70th Acc: 0.8961, Bottom 30th Acc: 0.3939
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.8961038961038961
100 2 [array([0.48666057, 0.03584991, 0.16312928, 0.11790409, 0.19645613],
      dtype=float32)]
Fold [4/5] Epoch [0/100] Initial Loss: 0.1410, Training Loss: 0.1410, Initial Validation Loss: 0.1393, Validation Loss: 0.1393,V Acc: 0.2636, Top 70th Acc: 0.2208, Bottom 30th Acc: 0.3636
Fold [4/5] Epoch [10/100] Initial Loss: 0.1410, Training Loss: 0.0309, Initial Validation Loss: 0.1393, Validation Loss: 0.0326,V Acc: 0.8727, Top 70th Acc: 0.9870, Bottom 30th Acc: 0.6061
Fold [4/5] Epoch [20/100] Initial Loss: 0.1410, Training Loss: 0.0169, Initial Validation Loss: 0.1393, Validation Loss: 0.0239,V Acc: 0.8636, Top 70th Acc: 0.9870, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 29  Rolling back to Epoch (base 0): 24  Top Validation Acc: 0.974025974025974
Fold [5/5] Epoch [0/100] Initial Loss: 0.1389, Training Loss: 0.1389, Initial Validation Loss: 0.1307, Validation Loss: 0.1307,V Acc: 0.2963, Top 70th Acc: 0.2895, Bottom 30th Acc: 0.3125
Fold [5/5] Epoch [10/100] Initial Loss: 0.1389, Training Loss: 0.0256, Initial Validation Loss: 0.1307, Validation Loss: 0.0362,V Acc: 0.8056, Top 70th Acc: 0.9211, Bottom 30th Acc: 0.5312
Fold [5/5] Epoch [20/100] Initial Loss: 0.1389, Training Loss: 0.0146, Initial Validation Loss: 0.1307, Validation Loss: 0.0312,V Acc: 0.7963, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.4062
Fold [5/5] Epoch [30/100] Initial Loss: 0.1389, Training Loss: 0.0125, Initial Validation Loss: 0.1307, Validation Loss: 0.0297,V Acc: 0.8056, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.4375
Stopping early at Epoch (base 0): 35  Rolling back to Epoch (base 0): 30  Top Validation Acc: 0.9605263157894737

Fold [5/5] Epoch [10/100] Initial Loss: 0.1391, Training Loss: 0.0838, Initial Validation Loss: 0.1284, Validation Loss: 0.0738,V Acc: 0.6481, Top 70th Acc: 0.6974, Bottom 30th Acc: 0.5312
Fold [5/5] Epoch [20/100] Initial Loss: 0.1391, Training Loss: 0.0813, Initial Validation Loss: 0.1284, Validation Loss: 0.0717,V Acc: 0.6296, Top 70th Acc: 0.6974, Bottom 30th Acc: 0.4688
Stopping early at Epoch (base 0): 22  Rolling back to Epoch (base 0): 17  Top Validation Acc: 0.7368421052631579
Running train_nn.py with seed 98
CUDA:False
Training samples count:  550
Training on 2 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1356, Training Loss: 0.1356, Initial Validation Loss: 0.1303, Validation Loss: 0.1303,V Acc: 0.5315, Top 70th Acc: 0.5513, Bottom 30th Acc: 0.4848
Fold [1/5] Epoch [10/100] Initial Loss: 0.1356, Training Loss: 0.0806, Initial Validation Loss: 0.1303, Validation Loss: 0.0816,V Acc: 0.6306, Top 70th Acc: 0.7564, Bottom 30th Acc: 0.3333
Fold [1/5] Epoch [20/100] Initial Loss: 0.1356, Training Loss: 0.0789, Initial Validation Loss: 0.1303, Validation Loss: 0.0792,V Acc: 0.6306, Top 70th Acc: 0.7692, Bottom 30th Acc: 0.3030
Fold [1/5] Epoch [30/100] Initial Loss: 0.1356, Training Loss: 0.0782, Initial Validation Loss: 0.1303, Validation Loss: 0.0780,V Acc: 0.6306, Top 70th Acc: 0.7692, Bottom 30th Acc: 0.3030
Stopping early at Epoch (base 0): 35  Rolling back to Epoch (base 0): 30  Top Validation Acc: 0.7564102564102564
98 0 [array([0.1604492 , 0.35545474, 0.12646167, 0.22487819, 0.13275616],
      dtype=float32)]
Fold [2/5] Epoch [0/100] Initial Loss: 0.1257, Training Loss: 0.1257, Initial Validation Loss: 0.1092, Validation Loss: 0.1092,V Acc: 0.4595, Top 70th Acc: 0.5256, Bottom 30th Acc: 0.3030
Fold [2/5] Epoch [10/100] Initial Loss: 0.1257, Training Loss: 0.0806, Initial Validation Loss: 0.1092, Validation Loss: 0.0775,V Acc: 0.6126, Top 70th Acc: 0.7179, Bottom 30th Acc: 0.3636
Fold [2/5] Epoch [20/100] Initial Loss: 0.1257, Training Loss: 0.0787, Initial Validation Loss: 0.1092, Validation Loss: 0.0768,V Acc: 0.6126, Top 70th Acc: 0.7179, Bottom 30th Acc: 0.3636
Stopping early at Epoch (base 0): 26  Rolling back to Epoch (base 0): 21  Top Validation Acc: 0.717948717948718
Fold [3/5] Epoch [0/100] Initial Loss: 0.1380, Training Loss: 0.1380, Initial Validation Loss: 0.1356, Validation Loss: 0.1356,V Acc: 0.3455, Top 70th Acc: 0.4286, Bottom 30th Acc: 0.1515
Fold [3/5] Epoch [10/100] Initial Loss: 0.1380, Training Loss: 0.0793, Initial Validation Loss: 0.1356, Validation Loss: 0.0900,V Acc: 0.5636, Top 70th Acc: 0.7143, Bottom 30th Acc: 0.2121
Fold [3/5] Epoch [20/100] Initial Loss: 0.1380, Training Loss: 0.0772, Initial Validation Loss: 0.1356, Validation Loss: 0.0881,V Acc: 0.5636, Top 70th Acc: 0.7143, Bottom 30th Acc: 0.2121
Fold [3/5] Epoch [30/100] Initial Loss: 0.1380, Training Loss: 0.0764, Initial Validation Loss: 0.1356, Validation Loss: 0.0875,V Acc: 0.5636, Top 70th Acc: 0.7143, Bottom 30th Acc: 0.2121
Stopping early at Epoch (base 0): 30  Rolling back to Epoch (base 0): 25  Top Validation Acc: 0.7142857142857143
Fold [4/5] Epoch [0/100] Initial Loss: 0.1308, Training Loss: 0.1308, Initial Validation Loss: 0.1171, Validation Loss: 0.1171,V Acc: 0.5182, Top 70th Acc: 0.5325, Bottom 30th Acc: 0.4848
Fold [4/5] Epoch [10/100] Initial Loss: 0.1308, Training Loss: 0.0816, Initial Validation Loss: 0.1171, Validation Loss: 0.0758,V Acc: 0.6455, Top 70th Acc: 0.7143, Bottom 30th Acc: 0.4848
Fold [4/5] Epoch [20/100] Initial Loss: 0.1308, Training Loss: 0.0797, Initial Validation Loss: 0.1171, Validation Loss: 0.0750,V Acc: 0.6364, Top 70th Acc: 0.7273, Bottom 30th Acc: 0.4242
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.7142857142857143
Fold [5/5] Epoch [0/100] Initial Loss: 0.1364, Training Loss: 0.1364, Initial Validation Loss: 0.1317, Validation Loss: 0.1317,V Acc: 0.2500, Top 70th Acc: 0.3553, Bottom 30th Acc: 0.0000
Fold [5/5] Epoch [10/100] Initial Loss: 0.1364, Training Loss: 0.0810, Initial Validation Loss: 0.1317, Validation Loss: 0.0786,V Acc: 0.6481, Top 70th Acc: 0.7763, Bottom 30th Acc: 0.3438
Fold [5/5] Epoch [20/100] Initial Loss: 0.1364, Training Loss: 0.0793, Initial Validation Loss: 0.1317, Validation Loss: 0.0775,V Acc: 0.6574, Top 70th Acc: 0.7763, Bottom 30th Acc: 0.3750
Fold [5/5] Epoch [30/100] Initial Loss: 0.1364, Training Loss: 0.0789, Initial Validation Loss: 0.1317, Validation Loss: 0.0764,V Acc: 0.6574, Top 70th Acc: 0.7895, Bottom 30th Acc: 0.3438
Stopping early at Epoch (base 0): 31  Rolling back to Epoch (base 0): 26  Top Validation Acc: 0.7894736842105263
Running train_nn.py with seed 99
CUDA:False
Training samples count:  550
Training on 2 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1406, Training Loss: 0.1406, Initial Validation Loss: 0.1285, Validation Loss: 0.1285,V Acc: 0.4414, Top 70th Acc: 0.4615, Bottom 30th Acc: 0.3939
Fold [1/5] Epoch [10/100] Initial Loss: 0.1406, Training Loss: 0.0807, Initial Validation Loss: 0.1285, Validation Loss: 0.0810,V Acc: 0.6216, Top 70th Acc: 0.7308, Bottom 30th Acc: 0.3636
Fold [1/5] Epoch [20/100] Initial Loss: 0.1406, Training Loss: 0.0785, Initial Validation Loss: 0.1285, Validation Loss: 0.0796,V Acc: 0.6126, Top 70th Acc: 0.7179, Bottom 30th Acc: 0.3636
Fold [1/5] Epoch [30/100] Initial Loss: 0.1406, Training Loss: 0.0778, Initial Validation Loss: 0.1285, Validation Loss: 0.0791,V Acc: 0.6216, Top 70th Acc: 0.7308, Bottom 30th Acc: 0.3636
Stopping early at Epoch (base 0): 31  Rolling back to Epoch (base 0): 26  Top Validation Acc: 0.6923076923076923
Fold [2/5] Epoch [0/100] Initial Loss: 0.1354, Training Loss: 0.1354, Initial Validation Loss: 0.1293, Validation Loss: 0.1293,V Acc: 0.4955, Top 70th Acc: 0.5513, Bottom 30th Acc: 0.3636
Fold [2/5] Epoch [10/100] Initial Loss: 0.1354, Training Loss: 0.0801, Initial Validation Loss: 0.1293, Validation Loss: 0.0858,V Acc: 0.5946, Top 70th Acc: 0.7179, Bottom 30th Acc: 0.3030
Fold [2/5] Epoch [20/100] Initial Loss: 0.1354, Training Loss: 0.0776, Initial Validation Loss: 0.1293, Validation Loss: 0.0828,V Acc: 0.6126, Top 70th Acc: 0.7308, Bottom 30th Acc: 0.3333
Fold [2/5] Epoch [30/100] Initial Loss: 0.1354, Training Loss: 0.0768, Initial Validation Loss: 0.1293, Validation Loss: 0.0824,V Acc: 0.5946, Top 70th Acc: 0.7308, Bottom 30th Acc: 0.2727
Fold [2/5] Epoch [40/100] Initial Loss: 0.1354, Training Loss: 0.0763, Initial Validation Loss: 0.1293, Validation Loss: 0.0809,V Acc: 0.6126, Top 70th Acc: 0.7564, Bottom 30th Acc: 0.2727
Stopping early at Epoch (base 0): 43  Rolling back to Epoch (base 0): 38  Top Validation Acc: 0.717948717948718
Fold [3/5] Epoch [0/100] Initial Loss: 0.1402, Training Loss: 0.1402, Initial Validation Loss: 0.1321, Validation Loss: 0.1321,V Acc: 0.3273, Top 70th Acc: 0.3636, Bottom 30th Acc: 0.2424
Fold [3/5] Epoch [10/100] Initial Loss: 0.1402, Training Loss: 0.0812, Initial Validation Loss: 0.1321, Validation Loss: 0.0788,V Acc: 0.6636, Top 70th Acc: 0.7792, Bottom 30th Acc: 0.3939
Fold [3/5] Epoch [20/100] Initial Loss: 0.1402, Training Loss: 0.0795, Initial Validation Loss: 0.1321, Validation Loss: 0.0768,V Acc: 0.6727, Top 70th Acc: 0.7792, Bottom 30th Acc: 0.4242
Fold [3/5] Epoch [30/100] Initial Loss: 0.1402, Training Loss: 0.0784, Initial Validation Loss: 0.1321, Validation Loss: 0.0767,V Acc: 0.6818, Top 70th Acc: 0.7792, Bottom 30th Acc: 0.4545
Stopping early at Epoch (base 0): 34  Rolling back to Epoch (base 0): 29  Top Validation Acc: 0.7792207792207793
Fold [4/5] Epoch [0/100] Initial Loss: 0.1378, Training Loss: 0.1378, Initial Validation Loss: 0.1273, Validation Loss: 0.1273,V Acc: 0.3182, Top 70th Acc: 0.3636, Bottom 30th Acc: 0.2121
Fold [4/5] Epoch [10/100] Initial Loss: 0.1378, Training Loss: 0.0809, Initial Validation Loss: 0.1273, Validation Loss: 0.0754,V Acc: 0.6091, Top 70th Acc: 0.7013, Bottom 30th Acc: 0.3939
Stopping early at Epoch (base 0): 19  Rolling back to Epoch (base 0): 14  Top Validation Acc: 0.7532467532467533
Fold [5/5] Epoch [0/100] Initial Loss: 0.1368, Training Loss: 0.1368, Initial Validation Loss: 0.1265, Validation Loss: 0.1265,V Acc: 0.4352, Top 70th Acc: 0.4868, Bottom 30th Acc: 0.3125
Fold [2/5] Epoch [20/100] Initial Loss: 0.1391, Training Loss: 0.0049, Initial Validation Loss: 0.1364, Validation Loss: 0.0333,V Acc: 0.8468, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.6061
Fold [2/5] Epoch [30/100] Initial Loss: 0.1391, Training Loss: 0.0039, Initial Validation Loss: 0.1364, Validation Loss: 0.0324,V Acc: 0.8559, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 31  Rolling back to Epoch (base 0): 26  Top Validation Acc: 0.9487179487179487
Fold [3/5] Epoch [0/100] Initial Loss: 0.1379, Training Loss: 0.1379, Initial Validation Loss: 0.1359, Validation Loss: 0.1359,V Acc: 0.3182, Top 70th Acc: 0.3636, Bottom 30th Acc: 0.2121
Fold [3/5] Epoch [10/100] Initial Loss: 0.1379, Training Loss: 0.0222, Initial Validation Loss: 0.1359, Validation Loss: 0.0404,V Acc: 0.8545, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.6970
Fold [3/5] Epoch [20/100] Initial Loss: 0.1379, Training Loss: 0.0057, Initial Validation Loss: 0.1359, Validation Loss: 0.0316,V Acc: 0.8727, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6970
Fold [3/5] Epoch [30/100] Initial Loss: 0.1379, Training Loss: 0.0041, Initial Validation Loss: 0.1359, Validation Loss: 0.0306,V Acc: 0.8545, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6364
Fold [3/5] Epoch [40/100] Initial Loss: 0.1379, Training Loss: 0.0038, Initial Validation Loss: 0.1359, Validation Loss: 0.0295,V Acc: 0.8909, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.7576
Fold [3/5] Epoch [50/100] Initial Loss: 0.1379, Training Loss: 0.0036, Initial Validation Loss: 0.1359, Validation Loss: 0.0283,V Acc: 0.8909, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.7576
Fold [3/5] Epoch [60/100] Initial Loss: 0.1379, Training Loss: 0.0036, Initial Validation Loss: 0.1359, Validation Loss: 0.0276,V Acc: 0.9000, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.7879
Stopping early at Epoch (base 0): 65  Rolling back to Epoch (base 0): 60  Top Validation Acc: 0.948051948051948
Fold [4/5] Epoch [0/100] Initial Loss: 0.1419, Training Loss: 0.1419, Initial Validation Loss: 0.1310, Validation Loss: 0.1310,V Acc: 0.2818, Top 70th Acc: 0.3506, Bottom 30th Acc: 0.1212
Fold [4/5] Epoch [10/100] Initial Loss: 0.1419, Training Loss: 0.0124, Initial Validation Loss: 0.1310, Validation Loss: 0.0337,V Acc: 0.8364, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 18  Rolling back to Epoch (base 0): 13  Top Validation Acc: 0.922077922077922
78 3 [array([0.21863581, 0.07054276, 0.05372753, 0.17254767, 0.48454624],
      dtype=float32)]
Fold [5/5] Epoch [0/100] Initial Loss: 0.1412, Training Loss: 0.1412, Initial Validation Loss: 0.1311, Validation Loss: 0.1311,V Acc: 0.3704, Top 70th Acc: 0.4342, Bottom 30th Acc: 0.2188
Fold [5/5] Epoch [10/100] Initial Loss: 0.1412, Training Loss: 0.0196, Initial Validation Loss: 0.1311, Validation Loss: 0.0410,V Acc: 0.7870, Top 70th Acc: 0.9079, Bottom 30th Acc: 0.5000
Fold [5/5] Epoch [20/100] Initial Loss: 0.1412, Training Loss: 0.0045, Initial Validation Loss: 0.1311, Validation Loss: 0.0333,V Acc: 0.8056, Top 70th Acc: 0.9211, Bottom 30th Acc: 0.5312
Fold [5/5] Epoch [30/100] Initial Loss: 0.1412, Training Loss: 0.0035, Initial Validation Loss: 0.1311, Validation Loss: 0.0321,V Acc: 0.8148, Top 70th Acc: 0.9211, Bottom 30th Acc: 0.5625
Fold [5/5] Epoch [40/100] Initial Loss: 0.1412, Training Loss: 0.0033, Initial Validation Loss: 0.1311, Validation Loss: 0.0314,V Acc: 0.8333, Top 70th Acc: 0.9211, Bottom 30th Acc: 0.6250
Fold [5/5] Epoch [50/100] Initial Loss: 0.1412, Training Loss: 0.0032, Initial Validation Loss: 0.1311, Validation Loss: 0.0313,V Acc: 0.8241, Top 70th Acc: 0.9211, Bottom 30th Acc: 0.5938
Fold [5/5] Epoch [60/100] Initial Loss: 0.1412, Training Loss: 0.0031, Initial Validation Loss: 0.1311, Validation Loss: 0.0308,V Acc: 0.8333, Top 70th Acc: 0.9211, Bottom 30th Acc: 0.6250
Stopping early at Epoch (base 0): 64  Rolling back to Epoch (base 0): 59  Top Validation Acc: 0.9210526315789473
Running train_nn.py with seed 79
CUDA:False
Training samples count:  550
Training on 163 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1382, Training Loss: 0.1382, Initial Validation Loss: 0.1351, Validation Loss: 0.1351,V Acc: 0.3153, Top 70th Acc: 0.3333, Bottom 30th Acc: 0.2727
Fold [1/5] Epoch [10/100] Initial Loss: 0.1382, Training Loss: 0.0194, Initial Validation Loss: 0.1351, Validation Loss: 0.0413,V Acc: 0.8108, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.5152
Fold [1/5] Epoch [20/100] Initial Loss: 0.1382, Training Loss: 0.0047, Initial Validation Loss: 0.1351, Validation Loss: 0.0344,V Acc: 0.8288, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.9358974358974359
Fold [2/5] Epoch [0/100] Initial Loss: 0.1351, Training Loss: 0.1351, Initial Validation Loss: 0.1335, Validation Loss: 0.1335,V Acc: 0.4595, Top 70th Acc: 0.4744, Bottom 30th Acc: 0.4242
Fold [2/5] Epoch [10/100] Initial Loss: 0.1351, Training Loss: 0.0160, Initial Validation Loss: 0.1335, Validation Loss: 0.0418,V Acc: 0.8108, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.5758
Fold [2/5] Epoch [20/100] Initial Loss: 0.1351, Training Loss: 0.0049, Initial Validation Loss: 0.1335, Validation Loss: 0.0358,V Acc: 0.8108, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.4848
Stopping early at Epoch (base 0): 27  Rolling back to Epoch (base 0): 22  Top Validation Acc: 0.9487179487179487
Fold [3/5] Epoch [0/100] Initial Loss: 0.1405, Training Loss: 0.1405, Initial Validation Loss: 0.1339, Validation Loss: 0.1339,V Acc: 0.2636, Top 70th Acc: 0.3377, Bottom 30th Acc: 0.0909
Fold [3/5] Epoch [10/100] Initial Loss: 0.1405, Training Loss: 0.0254, Initial Validation Loss: 0.1339, Validation Loss: 0.0352,V Acc: 0.8455, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.6364
Fold [3/5] Epoch [20/100] Initial Loss: 0.1405, Training Loss: 0.0050, Initial Validation Loss: 0.1339, Validation Loss: 0.0256,V Acc: 0.8545, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6364
Fold [3/5] Epoch [30/100] Initial Loss: 0.1405, Training Loss: 0.0040, Initial Validation Loss: 0.1339, Validation Loss: 0.0259,V Acc: 0.8455, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 30  Rolling back to Epoch (base 0): 25  Top Validation Acc: 0.961038961038961
Fold [4/5] Epoch [0/100] Initial Loss: 0.1382, Training Loss: 0.1382, Initial Validation Loss: 0.1319, Validation Loss: 0.1319,V Acc: 0.4091, Top 70th Acc: 0.4805, Bottom 30th Acc: 0.2424
Fold [4/5] Epoch [10/100] Initial Loss: 0.1382, Training Loss: 0.0153, Initial Validation Loss: 0.1319, Validation Loss: 0.0395,V Acc: 0.7636, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.3636
Fold [4/5] Epoch [20/100] Initial Loss: 0.1382, Training Loss: 0.0048, Initial Validation Loss: 0.1319, Validation Loss: 0.0364,V Acc: 0.7909, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.4545
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.948051948051948
Fold [5/5] Epoch [0/100] Initial Loss: 0.1390, Training Loss: 0.1390, Initial Validation Loss: 0.1327, Validation Loss: 0.1327,V Acc: 0.2500, Top 70th Acc: 0.3421, Bottom 30th Acc: 0.0312
Fold [5/5] Epoch [10/100] Initial Loss: 0.1390, Training Loss: 0.0140, Initial Validation Loss: 0.1327, Validation Loss: 0.0254,V Acc: 0.9074, Top 70th Acc: 0.9737, Bottom 30th Acc: 0.7500
Fold [5/5] Epoch [20/100] Initial Loss: 0.1390, Training Loss: 0.0049, Initial Validation Loss: 0.1327, Validation Loss: 0.0219,V Acc: 0.9074, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.7812
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.9605263157894737
79 4 [array([0.3105486 , 0.03993716, 0.1447528 , 0.2221267 , 0.28263462],
      dtype=float32)]
Running train_nn.py with seed 80
CUDA:False
Training samples count:  550
Training on 163 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1351, Training Loss: 0.1351, Initial Validation Loss: 0.1352, Validation Loss: 0.1352,V Acc: 0.3514, Top 70th Acc: 0.3846, Bottom 30th Acc: 0.2727
Fold [1/5] Epoch [10/100] Initial Loss: 0.1351, Training Loss: 0.0128, Initial Validation Loss: 0.1352, Validation Loss: 0.0327,V Acc: 0.8649, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.6364/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)

Fold [5/5] Epoch [10/100] Initial Loss: 0.1368, Training Loss: 0.0808, Initial Validation Loss: 0.1265, Validation Loss: 0.0781,V Acc: 0.6481, Top 70th Acc: 0.7368, Bottom 30th Acc: 0.4375
Fold [5/5] Epoch [20/100] Initial Loss: 0.1368, Training Loss: 0.0785, Initial Validation Loss: 0.1265, Validation Loss: 0.0763,V Acc: 0.6759, Top 70th Acc: 0.7632, Bottom 30th Acc: 0.4688
Fold [5/5] Epoch [30/100] Initial Loss: 0.1368, Training Loss: 0.0779, Initial Validation Loss: 0.1265, Validation Loss: 0.0747,V Acc: 0.6574, Top 70th Acc: 0.7763, Bottom 30th Acc: 0.3750
Fold [5/5] Epoch [40/100] Initial Loss: 0.1368, Training Loss: 0.0776, Initial Validation Loss: 0.1265, Validation Loss: 0.0747,V Acc: 0.6574, Top 70th Acc: 0.7763, Bottom 30th Acc: 0.3750
Stopping early at Epoch (base 0): 42  Rolling back to Epoch (base 0): 37  Top Validation Acc: 0.7631578947368421
99 4 [array([0.12951049, 0.31391215, 0.14029005, 0.24872445, 0.16756281],
      dtype=float32)]
Running train_nn.py with seed 100
CUDA:False
Training samples count:  550
Training on 2 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1332, Training Loss: 0.1332, Initial Validation Loss: 0.1293, Validation Loss: 0.1293,V Acc: 0.3514, Top 70th Acc: 0.4103, Bottom 30th Acc: 0.2121
Fold [1/5] Epoch [10/100] Initial Loss: 0.1332, Training Loss: 0.0778, Initial Validation Loss: 0.1293, Validation Loss: 0.0900,V Acc: 0.5946, Top 70th Acc: 0.7179, Bottom 30th Acc: 0.3030
Stopping early at Epoch (base 0): 16  Rolling back to Epoch (base 0): 11  Top Validation Acc: 0.717948717948718
Fold [2/5] Epoch [0/100] Initial Loss: 0.1331, Training Loss: 0.1331, Initial Validation Loss: 0.1256, Validation Loss: 0.1256,V Acc: 0.4324, Top 70th Acc: 0.4744, Bottom 30th Acc: 0.3333
Fold [2/5] Epoch [10/100] Initial Loss: 0.1331, Training Loss: 0.0813, Initial Validation Loss: 0.1256, Validation Loss: 0.0849,V Acc: 0.6036, Top 70th Acc: 0.6923, Bottom 30th Acc: 0.3939
Fold [2/5] Epoch [20/100] Initial Loss: 0.1331, Training Loss: 0.0783, Initial Validation Loss: 0.1256, Validation Loss: 0.0829,V Acc: 0.6216, Top 70th Acc: 0.7051, Bottom 30th Acc: 0.4242
Fold [2/5] Epoch [30/100] Initial Loss: 0.1331, Training Loss: 0.0772, Initial Validation Loss: 0.1256, Validation Loss: 0.0819,V Acc: 0.5856, Top 70th Acc: 0.7051, Bottom 30th Acc: 0.3030
Stopping early at Epoch (base 0): 34  Rolling back to Epoch (base 0): 29  Top Validation Acc: 0.6923076923076923
Fold [3/5] Epoch [0/100] Initial Loss: 0.1407, Training Loss: 0.1407, Initial Validation Loss: 0.1229, Validation Loss: 0.1229,V Acc: 0.3182, Top 70th Acc: 0.3766, Bottom 30th Acc: 0.1818
Fold [3/5] Epoch [10/100] Initial Loss: 0.1407, Training Loss: 0.0821, Initial Validation Loss: 0.1229, Validation Loss: 0.0737,V Acc: 0.6273, Top 70th Acc: 0.7273, Bottom 30th Acc: 0.3939
Fold [3/5] Epoch [20/100] Initial Loss: 0.1407, Training Loss: 0.0807, Initial Validation Loss: 0.1229, Validation Loss: 0.0735,V Acc: 0.6000, Top 70th Acc: 0.7143, Bottom 30th Acc: 0.3333
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.7012987012987013
100 2 [array([0.15389644, 0.34986317, 0.1433562 , 0.21361156, 0.13927265],
      dtype=float32)]
Fold [4/5] Epoch [0/100] Initial Loss: 0.1341, Training Loss: 0.1341, Initial Validation Loss: 0.1270, Validation Loss: 0.1270,V Acc: 0.4273, Top 70th Acc: 0.5714, Bottom 30th Acc: 0.0909
Fold [4/5] Epoch [10/100] Initial Loss: 0.1341, Training Loss: 0.0807, Initial Validation Loss: 0.1270, Validation Loss: 0.0847,V Acc: 0.6091, Top 70th Acc: 0.7143, Bottom 30th Acc: 0.3636
Stopping early at Epoch (base 0): 12  Rolling back to Epoch (base 0): 7  Top Validation Acc: 0.6883116883116883
Fold [5/5] Epoch [0/100] Initial Loss: 0.1404, Training Loss: 0.1404, Initial Validation Loss: 0.1307, Validation Loss: 0.1307,V Acc: 0.3056, Top 70th Acc: 0.3026, Bottom 30th Acc: 0.3125
Fold [5/5] Epoch [10/100] Initial Loss: 0.1404, Training Loss: 0.0829, Initial Validation Loss: 0.1307, Validation Loss: 0.0722,V Acc: 0.6944, Top 70th Acc: 0.8158, Bottom 30th Acc: 0.4062
Fold [5/5] Epoch [20/100] Initial Loss: 0.1404, Training Loss: 0.0812, Initial Validation Loss: 0.1307, Validation Loss: 0.0704,V Acc: 0.6944, Top 70th Acc: 0.8026, Bottom 30th Acc: 0.4375
Fold [5/5] Epoch [30/100] Initial Loss: 0.1404, Training Loss: 0.0808, Initial Validation Loss: 0.1307, Validation Loss: 0.0697,V Acc: 0.6944, Top 70th Acc: 0.8026, Bottom 30th Acc: 0.4375
Stopping early at Epoch (base 0): 30  Rolling back to Epoch (base 0): 25  Top Validation Acc: 0.8026315789473685

Fold [1/5] Epoch [20/100] Initial Loss: 0.1351, Training Loss: 0.0045, Initial Validation Loss: 0.1352, Validation Loss: 0.0298,V Acc: 0.8649, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.6061
Fold [1/5] Epoch [30/100] Initial Loss: 0.1351, Training Loss: 0.0038, Initial Validation Loss: 0.1352, Validation Loss: 0.0301,V Acc: 0.8649, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 38  Rolling back to Epoch (base 0): 33  Top Validation Acc: 0.9743589743589743
Fold [2/5] Epoch [0/100] Initial Loss: 0.1377, Training Loss: 0.1377, Initial Validation Loss: 0.1357, Validation Loss: 0.1357,V Acc: 0.4595, Top 70th Acc: 0.5256, Bottom 30th Acc: 0.3030
Fold [2/5] Epoch [10/100] Initial Loss: 0.1377, Training Loss: 0.0142, Initial Validation Loss: 0.1357, Validation Loss: 0.0364,V Acc: 0.8559, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.6061
Fold [2/5] Epoch [20/100] Initial Loss: 0.1377, Training Loss: 0.0047, Initial Validation Loss: 0.1357, Validation Loss: 0.0345,V Acc: 0.8378, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 21  Rolling back to Epoch (base 0): 16  Top Validation Acc: 0.9615384615384616
Fold [3/5] Epoch [0/100] Initial Loss: 0.1376, Training Loss: 0.1376, Initial Validation Loss: 0.1311, Validation Loss: 0.1311,V Acc: 0.2909, Top 70th Acc: 0.3506, Bottom 30th Acc: 0.1515
Fold [3/5] Epoch [10/100] Initial Loss: 0.1376, Training Loss: 0.0160, Initial Validation Loss: 0.1311, Validation Loss: 0.0334,V Acc: 0.8182, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.6061
Fold [3/5] Epoch [20/100] Initial Loss: 0.1376, Training Loss: 0.0059, Initial Validation Loss: 0.1311, Validation Loss: 0.0309,V Acc: 0.8182, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 21  Rolling back to Epoch (base 0): 16  Top Validation Acc: 0.935064935064935
Fold [4/5] Epoch [0/100] Initial Loss: 0.1419, Training Loss: 0.1419, Initial Validation Loss: 0.1331, Validation Loss: 0.1331,V Acc: 0.3091, Top 70th Acc: 0.3247, Bottom 30th Acc: 0.2727
Fold [4/5] Epoch [10/100] Initial Loss: 0.1419, Training Loss: 0.0119, Initial Validation Loss: 0.1331, Validation Loss: 0.0371,V Acc: 0.8091, Top 70th Acc: 0.8961, Bottom 30th Acc: 0.6061
Fold [4/5] Epoch [20/100] Initial Loss: 0.1419, Training Loss: 0.0047, Initial Validation Loss: 0.1331, Validation Loss: 0.0339,V Acc: 0.8273, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.9090909090909091
Fold [5/5] Epoch [0/100] Initial Loss: 0.1397, Training Loss: 0.1397, Initial Validation Loss: 0.1343, Validation Loss: 0.1343,V Acc: 0.2315, Top 70th Acc: 0.2895, Bottom 30th Acc: 0.0938
Fold [5/5] Epoch [10/100] Initial Loss: 0.1397, Training Loss: 0.0209, Initial Validation Loss: 0.1343, Validation Loss: 0.0328,V Acc: 0.8611, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.6250
Fold [5/5] Epoch [20/100] Initial Loss: 0.1397, Training Loss: 0.0047, Initial Validation Loss: 0.1343, Validation Loss: 0.0253,V Acc: 0.8611, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.6250
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.9736842105263158
80 4 [array([0.15136237, 0.04230674, 0.10724271, 0.17934798, 0.51974016],
      dtype=float32)]
Running train_nn.py with seed 81
CUDA:False
Training samples count:  550
Training on 163 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1380, Training Loss: 0.1380, Initial Validation Loss: 0.1340, Validation Loss: 0.1340,V Acc: 0.2613, Top 70th Acc: 0.3462, Bottom 30th Acc: 0.0606
Fold [1/5] Epoch [10/100] Initial Loss: 0.1380, Training Loss: 0.0187, Initial Validation Loss: 0.1340, Validation Loss: 0.0414,V Acc: 0.7928, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.4242
Fold [1/5] Epoch [20/100] Initial Loss: 0.1380, Training Loss: 0.0063, Initial Validation Loss: 0.1340, Validation Loss: 0.0335,V Acc: 0.8288, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 27  Rolling back to Epoch (base 0): 22  Top Validation Acc: 0.9487179487179487
Fold [2/5] Epoch [0/100] Initial Loss: 0.1416, Training Loss: 0.1416, Initial Validation Loss: 0.1319, Validation Loss: 0.1319,V Acc: 0.2883, Top 70th Acc: 0.3590, Bottom 30th Acc: 0.1212
Fold [2/5] Epoch [10/100] Initial Loss: 0.1416, Training Loss: 0.0156, Initial Validation Loss: 0.1319, Validation Loss: 0.0362,V Acc: 0.8198, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.6061
Fold [2/5] Epoch [20/100] Initial Loss: 0.1416, Training Loss: 0.0050, Initial Validation Loss: 0.1319, Validation Loss: 0.0308,V Acc: 0.8378, Top 70th Acc: 0.8974, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.8974358974358975
Fold [3/5] Epoch [0/100] Initial Loss: 0.1379, Training Loss: 0.1379, Initial Validation Loss: 0.1353, Validation Loss: 0.1353,V Acc: 0.2909, Top 70th Acc: 0.3896, Bottom 30th Acc: 0.0606
Fold [3/5] Epoch [10/100] Initial Loss: 0.1379, Training Loss: 0.0122, Initial Validation Loss: 0.1353, Validation Loss: 0.0271,V Acc: 0.9000, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.7273
Fold [3/5] Epoch [20/100] Initial Loss: 0.1379, Training Loss: 0.0047, Initial Validation Loss: 0.1353, Validation Loss: 0.0243,V Acc: 0.9000, Top 70th Acc: 0.9870, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 27  Rolling back to Epoch (base 0): 22  Top Validation Acc: 0.987012987012987
Fold [4/5] Epoch [0/100] Initial Loss: 0.1399, Training Loss: 0.1399, Initial Validation Loss: 0.1340, Validation Loss: 0.1340,V Acc: 0.2727, Top 70th Acc: 0.3636, Bottom 30th Acc: 0.0606
Fold [4/5] Epoch [10/100] Initial Loss: 0.1399, Training Loss: 0.0119, Initial Validation Loss: 0.1340, Validation Loss: 0.0283,V Acc: 0.8364, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.5455
Fold [4/5] Epoch [20/100] Initial Loss: 0.1399, Training Loss: 0.0048, Initial Validation Loss: 0.1340, Validation Loss: 0.0256,V Acc: 0.8364, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.5152
Stopping early at Epoch (base 0): 22  Rolling back to Epoch (base 0): 17  Top Validation Acc: 0.961038961038961
81 3 [array([0.31750023, 0.0400348 , 0.08557348, 0.251242  , 0.30564946],
      dtype=float32)]
Fold [5/5] Epoch [0/100] Initial Loss: 0.1365, Training Loss: 0.1365, Initial Validation Loss: 0.1343, Validation Loss: 0.1343,V Acc: 0.3796, Top 70th Acc: 0.4342, Bottom 30th Acc: 0.2500
Fold [5/5] Epoch [10/100] Initial Loss: 0.1365, Training Loss: 0.0204, Initial Validation Loss: 0.1343, Validation Loss: 0.0463,V Acc: 0.8056, Top 70th Acc: 0.8947, Bottom 30th Acc: 0.5938
Fold [5/5] Epoch [20/100] Initial Loss: 0.1365, Training Loss: 0.0056, Initial Validation Loss: 0.1343, Validation Loss: 0.0373,V Acc: 0.8426, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.6250
Fold [5/5] Epoch [30/100] Initial Loss: 0.1365, Training Loss: 0.0040, Initial Validation Loss: 0.1343, Validation Loss: 0.0362,V Acc: 0.8056, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.4375
Fold [5/5] Epoch [40/100] Initial Loss: 0.1365, Training Loss: 0.0035, Initial Validation Loss: 0.1343, Validation Loss: 0.0342,V Acc: 0.8333, Top 70th Acc: 0.9868, Bottom 30th Acc: 0.4688
Fold [5/5] Epoch [50/100] Initial Loss: 0.1365, Training Loss: 0.0033, Initial Validation Loss: 0.1343, Validation Loss: 0.0331,V Acc: 0.8333, Top 70th Acc: 0.9868, Bottom 30th Acc: 0.4688
Fold [5/5] Epoch [60/100] Initial Loss: 0.1365, Training Loss: 0.0032, Initial Validation Loss: 0.1343, Validation Loss: 0.0322,V Acc: 0.8333, Top 70th Acc: 0.9868, Bottom 30th Acc: 0.4688
Fold [5/5] Epoch [70/100] Initial Loss: 0.1365, Training Loss: 0.0031, Initial Validation Loss: 0.1343, Validation Loss: 0.0313,V Acc: 0.8426, Top 70th Acc: 0.9868, Bottom 30th Acc: 0.5000
Fold [5/5] Epoch [80/100] Initial Loss: 0.1365, Training Loss: 0.0030, Initial Validation Loss: 0.1343, Validation Loss: 0.0310,V Acc: 0.8611, Top 70th Acc: 0.9868, Bottom 30th Acc: 0.5625
Stopping early at Epoch (base 0): 83  Rolling back to Epoch (base 0): 78  Top Validation Acc: 0.9736842105263158
Running train_nn.py with seed 82
CUDA:False
Training samples count:  550
Training on 163 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1387, Training Loss: 0.1387, Initial Validation Loss: 0.1306, Validation Loss: 0.1306,V Acc: 0.2523, Top 70th Acc: 0.3462, Bottom 30th Acc: 0.0303
Fold [1/5] Epoch [10/100] Initial Loss: 0.1387, Training Loss: 0.0107, Initial Validation Loss: 0.1306, Validation Loss: 0.0271,V Acc: 0.8829, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.7576
Fold [1/5] Epoch [20/100] Initial Loss: 0.1387, Training Loss: 0.0044, Initial Validation Loss: 0.1306, Validation Loss: 0.0247,V Acc: 0.9099, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.8182
Stopping early at Epoch (base 0): 22  Rolling back to Epoch (base 0): 17  Top Validation Acc: 0.9487179487179487
82 0 [array([0.41600436, 0.02945662, 0.06509544, 0.15365449, 0.33578902],
      dtype=float32)]
Fold [2/5] Epoch [0/100] Initial Loss: 0.1363, Training Loss: 0.1363, Initial Validation Loss: 0.1408, Validation Loss: 0.1408,V Acc: 0.3153, Top 70th Acc: 0.3718, Bottom 30th Acc: 0.1818
Fold [2/5] Epoch [10/100] Initial Loss: 0.1363, Training Loss: 0.0167, Initial Validation Loss: 0.1408, Validation Loss: 0.0348,V Acc: 0.8559, Top 70th Acc: 0.9872, Bottom 30th Acc: 0.5455
Fold [2/5] Epoch [20/100] Initial Loss: 0.1363, Training Loss: 0.0048, Initial Validation Loss: 0.1408, Validation Loss: 0.0269,V Acc: 0.8919, Top 70th Acc: 1.0000, Bottom 30th Acc: 0.6364
Fold [2/5] Epoch [30/100] Initial Loss: 0.1363, Training Loss: 0.0038, Initial Validation Loss: 0.1408, Validation Loss: 0.0262,V Acc: 0.8919, Top 70th Acc: 1.0000, Bottom 30th Acc: 0.6364
Fold [2/5] Epoch [40/100] Initial Loss: 0.1363, Training Loss: 0.0036, Initial Validation Loss: 0.1408, Validation Loss: 0.0254,V Acc: 0.8919, Top 70th Acc: 1.0000, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 46  Rolling back to Epoch (base 0): 41  Top Validation Acc: 1.0
Fold [3/5] Epoch [0/100] Initial Loss: 0.1390, Training Loss: 0.1390, Initial Validation Loss: 0.1319, Validation Loss: 0.1319,V Acc: 0.2727, Top 70th Acc: 0.3377, Bottom 30th Acc: 0.1212
Fold [3/5] Epoch [10/100] Initial Loss: 0.1390, Training Loss: 0.0266, Initial Validation Loss: 0.1319, Validation Loss: 0.0405,V Acc: 0.7636, Top 70th Acc: 0.8961, Bottom 30th Acc: 0.4545
Fold [3/5] Epoch [20/100] Initial Loss: 0.1390, Training Loss: 0.0057, Initial Validation Loss: 0.1319, Validation Loss: 0.0286,V Acc: 0.8455, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6061
Fold [3/5] Epoch [30/100] Initial Loss: 0.1390, Training Loss: 0.0042, Initial Validation Loss: 0.1319, Validation Loss: 0.0270,V Acc: 0.8455, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 37  Rolling back to Epoch (base 0): 32  Top Validation Acc: 0.935064935064935
Fold [4/5] Epoch [0/100] Initial Loss: 0.1402, Training Loss: 0.1402, Initial Validation Loss: 0.1344, Validation Loss: 0.1344,V Acc: 0.2545, Top 70th Acc: 0.3377, Bottom 30th Acc: 0.0606
Fold [4/5] Epoch [10/100] Initial Loss: 0.1402, Training Loss: 0.0157, Initial Validation Loss: 0.1344, Validation Loss: 0.0299,V Acc: 0.8545, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.6061
Fold [4/5] Epoch [20/100] Initial Loss: 0.1402, Training Loss: 0.0046, Initial Validation Loss: 0.1344, Validation Loss: 0.0272,V Acc: 0.8273, Top 70th Acc: 0.9870, Bottom 30th Acc: 0.4545
Stopping early at Epoch (base 0): 21  Rolling back to Epoch (base 0): 16  Top Validation Acc: 0.987012987012987
Fold [5/5] Epoch [0/100] Initial Loss: 0.1397, Training Loss: 0.1397, Initial Validation Loss: 0.1344, Validation Loss: 0.1344,V Acc: 0.3519, Top 70th Acc: 0.4474, Bottom 30th Acc: 0.1250
Fold [5/5] Epoch [10/100] Initial Loss: 0.1397, Training Loss: 0.0194, Initial Validation Loss: 0.1344, Validation Loss: 0.0302,V Acc: 0.8704, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.7188
Fold [5/5] Epoch [20/100] Initial Loss: 0.1397, Training Loss: 0.0054, Initial Validation Loss: 0.1344, Validation Loss: 0.0229,V Acc: 0.8981, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.7500
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.9605263157894737
Running train_nn.py with seed 83
CUDA:False
Training samples count:  550
Training on 163 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1396, Training Loss: 0.1396, Initial Validation Loss: 0.1337, Validation Loss: 0.1337,V Acc: 0.3694, Top 70th Acc: 0.4487, Bottom 30th Acc: 0.1818
Fold [1/5] Epoch [10/100] Initial Loss: 0.1396, Training Loss: 0.0181, Initial Validation Loss: 0.1337, Validation Loss: 0.0400,V Acc: 0.8378, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 19  Rolling back to Epoch (base 0): 14  Top Validation Acc: 0.9487179487179487
Fold [2/5] Epoch [0/100] Initial Loss: 0.1370, Training Loss: 0.1370, Initial Validation Loss: 0.1400, Validation Loss: 0.1400,V Acc: 0.2613, Top 70th Acc: 0.3077, Bottom 30th Acc: 0.1515
Fold [2/5] Epoch [10/100] Initial Loss: 0.1370, Training Loss: 0.0139, Initial Validation Loss: 0.1400, Validation Loss: 0.0282,V Acc: 0.8919, Top 70th Acc: 1.0000, Bottom 30th Acc: 0.6364
Fold [2/5] Epoch [20/100] Initial Loss: 0.1370, Training Loss: 0.0052, Initial Validation Loss: 0.1400, Validation Loss: 0.0260,V Acc: 0.8739, Top 70th Acc: 1.0000, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 20  Rolling back to Epoch (base 0): 15  Top Validation Acc: 1.0
Fold [3/5] Epoch [0/100] Initial Loss: 0.1386, Training Loss: 0.1386, Initial Validation Loss: 0.1291, Validation Loss: 0.1291,V Acc: 0.4182, Top 70th Acc: 0.5195, Bottom 30th Acc: 0.1818
Fold [3/5] Epoch [10/100] Initial Loss: 0.1386, Training Loss: 0.0234, Initial Validation Loss: 0.1291, Validation Loss: 0.0492,V Acc: 0.7727, Top 70th Acc: 0.8701, Bottom 30th Acc: 0.5455
Fold [3/5] Epoch [20/100] Initial Loss: 0.1386, Training Loss: 0.0059, Initial Validation Loss: 0.1291, Validation Loss: 0.0432,V Acc: 0.7636, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.4242
Fold [3/5] Epoch [30/100] Initial Loss: 0.1386, Training Loss: 0.0041, Initial Validation Loss: 0.1291, Validation Loss: 0.0428,V Acc: 0.7636, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.4242
Fold [3/5] Epoch [40/100] Initial Loss: 0.1386, Training Loss: 0.0036, Initial Validation Loss: 0.1291, Validation Loss: 0.0409,V Acc: 0.7545, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.3939
Fold [3/5] Epoch [50/100] Initial Loss: 0.1386, Training Loss: 0.0033, Initial Validation Loss: 0.1291, Validation Loss: 0.0396,V Acc: 0.7636, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.3636
Fold [3/5] Epoch [60/100] Initial Loss: 0.1386, Training Loss: 0.0031, Initial Validation Loss: 0.1291, Validation Loss: 0.0383,V Acc: 0.7636, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.3636
Fold [3/5] Epoch [70/100] Initial Loss: 0.1386, Training Loss: 0.0030, Initial Validation Loss: 0.1291, Validation Loss: 0.0373,V Acc: 0.7727, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.3939
Stopping early at Epoch (base 0): 70  Rolling back to Epoch (base 0): 65  Top Validation Acc: 0.935064935064935
Fold [4/5] Epoch [0/100] Initial Loss: 0.1368, Training Loss: 0.1368, Initial Validation Loss: 0.1332, Validation Loss: 0.1332,V Acc: 0.4091, Top 70th Acc: 0.5195, Bottom 30th Acc: 0.1515
Fold [4/5] Epoch [10/100] Initial Loss: 0.1368, Training Loss: 0.0146, Initial Validation Loss: 0.1332, Validation Loss: 0.0388,V Acc: 0.8000, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.4848
Stopping early at Epoch (base 0): 18  Rolling back to Epoch (base 0): 13  Top Validation Acc: 0.922077922077922
Fold [5/5] Epoch [0/100] Initial Loss: 0.1400, Training Loss: 0.1400, Initial Validation Loss: 0.1299, Validation Loss: 0.1299,V Acc: 0.2500, Top 70th Acc: 0.2895, Bottom 30th Acc: 0.1562
Fold [5/5] Epoch [10/100] Initial Loss: 0.1400, Training Loss: 0.0360, Initial Validation Loss: 0.1299, Validation Loss: 0.0514,V Acc: 0.7222, Top 70th Acc: 0.8289, Bottom 30th Acc: 0.4688
Fold [5/5] Epoch [20/100] Initial Loss: 0.1400, Training Loss: 0.0070, Initial Validation Loss: 0.1299, Validation Loss: 0.0373,V Acc: 0.7685, Top 70th Acc: 0.9079, Bottom 30th Acc: 0.4375
Fold [5/5] Epoch [30/100] Initial Loss: 0.1400, Training Loss: 0.0049, Initial Validation Loss: 0.1299, Validation Loss: 0.0348,V Acc: 0.7685, Top 70th Acc: 0.9211, Bottom 30th Acc: 0.4062
Fold [5/5] Epoch [40/100] Initial Loss: 0.1400, Training Loss: 0.0042, Initial Validation Loss: 0.1299, Validation Loss: 0.0327,V Acc: 0.7870, Top 70th Acc: 0.9211, Bottom 30th Acc: 0.4688
Fold [5/5] Epoch [50/100] Initial Loss: 0.1400, Training Loss: 0.0039, Initial Validation Loss: 0.1299, Validation Loss: 0.0321,V Acc: 0.7500, Top 70th Acc: 0.9079, Bottom 30th Acc: 0.3750
Fold [5/5] Epoch [60/100] Initial Loss: 0.1400, Training Loss: 0.0037, Initial Validation Loss: 0.1299, Validation Loss: 0.0311,V Acc: 0.7685, Top 70th Acc: 0.9211, Bottom 30th Acc: 0.4062
Stopping early at Epoch (base 0): 60  Rolling back to Epoch (base 0): 55  Top Validation Acc: 0.9210526315789473
83 4 [array([0.2518099 , 0.06248967, 0.05974222, 0.2936534 , 0.3323048 ],
      dtype=float32)]
Running train_nn.py with seed 84
CUDA:False
Training samples count:  550
Training on 163 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1374, Training Loss: 0.1374, Initial Validation Loss: 0.1323, Validation Loss: 0.1323,V Acc: 0.3423, Top 70th Acc: 0.4103, Bottom 30th Acc: 0.1818
Fold [1/5] Epoch [10/100] Initial Loss: 0.1374, Training Loss: 0.0155, Initial Validation Loss: 0.1323, Validation Loss: 0.0391,V Acc: 0.7928, Top 70th Acc: 0.8974, Bottom 30th Acc: 0.5455
Fold [1/5] Epoch [20/100] Initial Loss: 0.1374, Training Loss: 0.0054, Initial Validation Loss: 0.1323, Validation Loss: 0.0346,V Acc: 0.8108, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.5758
Fold [1/5] Epoch [30/100] Initial Loss: 0.1374, Training Loss: 0.0043, Initial Validation Loss: 0.1323, Validation Loss: 0.0333,V Acc: 0.8198, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.6061
Fold [1/5] Epoch [40/100] Initial Loss: 0.1374, Training Loss: 0.0039, Initial Validation Loss: 0.1323, Validation Loss: 0.0322,V Acc: 0.8378, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 41  Rolling back to Epoch (base 0): 36  Top Validation Acc: 0.9102564102564102
84 0 [array([0.22873223, 0.09392902, 0.06442253, 0.17706868, 0.4358476 ],
      dtype=float32)]
Fold [2/5] Epoch [0/100] Initial Loss: 0.1372, Training Loss: 0.1372, Initial Validation Loss: 0.1371, Validation Loss: 0.1371,V Acc: 0.3243, Top 70th Acc: 0.4359, Bottom 30th Acc: 0.0606
Fold [2/5] Epoch [10/100] Initial Loss: 0.1372, Training Loss: 0.0107, Initial Validation Loss: 0.1371, Validation Loss: 0.0261,V Acc: 0.8829, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 19  Rolling back to Epoch (base 0): 14  Top Validation Acc: 0.9871794871794872
Fold [3/5] Epoch [0/100] Initial Loss: 0.1421, Training Loss: 0.1421, Initial Validation Loss: 0.1328, Validation Loss: 0.1328,V Acc: 0.3727, Top 70th Acc: 0.4545, Bottom 30th Acc: 0.1818
Fold [3/5] Epoch [10/100] Initial Loss: 0.1421, Training Loss: 0.0104, Initial Validation Loss: 0.1328, Validation Loss: 0.0399,V Acc: 0.8000, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.4848
Stopping early at Epoch (base 0): 18  Rolling back to Epoch (base 0): 13  Top Validation Acc: 0.8961038961038961
Fold [4/5] Epoch [0/100] Initial Loss: 0.1403, Training Loss: 0.1403, Initial Validation Loss: 0.1304, Validation Loss: 0.1304,V Acc: 0.2636, Top 70th Acc: 0.2468, Bottom 30th Acc: 0.3030
Fold [4/5] Epoch [10/100] Initial Loss: 0.1403, Training Loss: 0.0366, Initial Validation Loss: 0.1304, Validation Loss: 0.0486,V Acc: 0.7545, Top 70th Acc: 0.8831, Bottom 30th Acc: 0.4545
Fold [4/5] Epoch [20/100] Initial Loss: 0.1403, Training Loss: 0.0071, Initial Validation Loss: 0.1304, Validation Loss: 0.0315,V Acc: 0.8455, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.6667
Fold [4/5] Epoch [30/100] Initial Loss: 0.1403, Training Loss: 0.0041, Initial Validation Loss: 0.1304, Validation Loss: 0.0302,V Acc: 0.8364, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 32  Rolling back to Epoch (base 0): 27  Top Validation Acc: 0.9090909090909091
Fold [5/5] Epoch [0/100] Initial Loss: 0.1389, Training Loss: 0.1389, Initial Validation Loss: 0.1326, Validation Loss: 0.1326,V Acc: 0.3426, Top 70th Acc: 0.3816, Bottom 30th Acc: 0.2500
Fold [5/5] Epoch [10/100] Initial Loss: 0.1389, Training Loss: 0.0205, Initial Validation Loss: 0.1326, Validation Loss: 0.0386,V Acc: 0.8519, Top 70th Acc: 0.8947, Bottom 30th Acc: 0.7500
Fold [5/5] Epoch [20/100] Initial Loss: 0.1389, Training Loss: 0.0050, Initial Validation Loss: 0.1326, Validation Loss: 0.0292,V Acc: 0.8519, Top 70th Acc: 0.9737, Bottom 30th Acc: 0.5625
Fold [5/5] Epoch [30/100] Initial Loss: 0.1389, Training Loss: 0.0040, Initial Validation Loss: 0.1326, Validation Loss: 0.0288,V Acc: 0.8611, Top 70th Acc: 0.9737, Bottom 30th Acc: 0.5938
Stopping early at Epoch (base 0): 34  Rolling back to Epoch (base 0): 29  Top Validation Acc: 0.9605263157894737
Running train_nn.py with seed 85
CUDA:False
Training samples count:  550
Training on 163 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1399, Training Loss: 0.1399, Initial Validation Loss: 0.1338, Validation Loss: 0.1338,V Acc: 0.2523, Top 70th Acc: 0.3333, Bottom 30th Acc: 0.0606
Fold [1/5] Epoch [10/100] Initial Loss: 0.1399, Training Loss: 0.0194, Initial Validation Loss: 0.1338, Validation Loss: 0.0401,V Acc: 0.7928, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.4848
Fold [1/5] Epoch [20/100] Initial Loss: 0.1399, Training Loss: 0.0050, Initial Validation Loss: 0.1338, Validation Loss: 0.0327,V Acc: 0.8108, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.5152
Fold [1/5] Epoch [30/100] Initial Loss: 0.1399, Training Loss: 0.0037, Initial Validation Loss: 0.1338, Validation Loss: 0.0325,V Acc: 0.8018, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.4848
Stopping early at Epoch (base 0): 34  Rolling back to Epoch (base 0): 29  Top Validation Acc: 0.9487179487179487
Fold [2/5] Epoch [0/100] Initial Loss: 0.1377, Training Loss: 0.1377, Initial Validation Loss: 0.1387, Validation Loss: 0.1387,V Acc: 0.3063, Top 70th Acc: 0.3590, Bottom 30th Acc: 0.1818
Fold [2/5] Epoch [10/100] Initial Loss: 0.1377, Training Loss: 0.0171, Initial Validation Loss: 0.1387, Validation Loss: 0.0398,V Acc: 0.8108, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.5455
Fold [2/5] Epoch [20/100] Initial Loss: 0.1377, Training Loss: 0.0051, Initial Validation Loss: 0.1387, Validation Loss: 0.0335,V Acc: 0.8468, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 27  Rolling back to Epoch (base 0): 22  Top Validation Acc: 0.9615384615384616
85 1 [array([0.3566781 , 0.04571031, 0.08112072, 0.26028067, 0.25621012],
      dtype=float32)]
Fold [3/5] Epoch [0/100] Initial Loss: 0.1394, Training Loss: 0.1394, Initial Validation Loss: 0.1375, Validation Loss: 0.1375,V Acc: 0.2727, Top 70th Acc: 0.3506, Bottom 30th Acc: 0.0909
Fold [3/5] Epoch [10/100] Initial Loss: 0.1394, Training Loss: 0.0195, Initial Validation Loss: 0.1375, Validation Loss: 0.0337,V Acc: 0.8364, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.5758
Fold [3/5] Epoch [20/100] Initial Loss: 0.1394, Training Loss: 0.0062, Initial Validation Loss: 0.1375, Validation Loss: 0.0286,V Acc: 0.8545, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 22  Rolling back to Epoch (base 0): 17  Top Validation Acc: 0.948051948051948
Fold [4/5] Epoch [0/100] Initial Loss: 0.1388, Training Loss: 0.1388, Initial Validation Loss: 0.1352, Validation Loss: 0.1352,V Acc: 0.3364, Top 70th Acc: 0.3377, Bottom 30th Acc: 0.3333
Fold [4/5] Epoch [10/100] Initial Loss: 0.1388, Training Loss: 0.0209, Initial Validation Loss: 0.1352, Validation Loss: 0.0368,V Acc: 0.8455, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6061
Fold [4/5] Epoch [20/100] Initial Loss: 0.1388, Training Loss: 0.0049, Initial Validation Loss: 0.1352, Validation Loss: 0.0283,V Acc: 0.8636, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 27  Rolling back to Epoch (base 0): 22  Top Validation Acc: 0.948051948051948
Fold [5/5] Epoch [0/100] Initial Loss: 0.1392, Training Loss: 0.1392, Initial Validation Loss: 0.1269, Validation Loss: 0.1269,V Acc: 0.2778, Top 70th Acc: 0.3421, Bottom 30th Acc: 0.1250
Fold [5/5] Epoch [10/100] Initial Loss: 0.1392, Training Loss: 0.0268, Initial Validation Loss: 0.1269, Validation Loss: 0.0443,V Acc: 0.7593, Top 70th Acc: 0.8289, Bottom 30th Acc: 0.5938
Fold [5/5] Epoch [20/100] Initial Loss: 0.1392, Training Loss: 0.0057, Initial Validation Loss: 0.1269, Validation Loss: 0.0336,V Acc: 0.8056, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.5000
Fold [5/5] Epoch [30/100] Initial Loss: 0.1392, Training Loss: 0.0042, Initial Validation Loss: 0.1269, Validation Loss: 0.0319,V Acc: 0.8056, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.4688
Fold [5/5] Epoch [40/100] Initial Loss: 0.1392, Training Loss: 0.0039, Initial Validation Loss: 0.1269, Validation Loss: 0.0309,V Acc: 0.8056, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.5000
Fold [5/5] Epoch [50/100] Initial Loss: 0.1392, Training Loss: 0.0037, Initial Validation Loss: 0.1269, Validation Loss: 0.0304,V Acc: 0.8148, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.5000
Stopping early at Epoch (base 0): 51  Rolling back to Epoch (base 0): 46  Top Validation Acc: 0.9473684210526315
Running train_nn.py with seed 86
CUDA:False
Training samples count:  550
Training on 163 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1414, Training Loss: 0.1414, Initial Validation Loss: 0.1348, Validation Loss: 0.1348,V Acc: 0.2523, Top 70th Acc: 0.3590, Bottom 30th Acc: 0.0000
Fold [1/5] Epoch [10/100] Initial Loss: 0.1414, Training Loss: 0.0333, Initial Validation Loss: 0.1348, Validation Loss: 0.0456,V Acc: 0.8198, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.5758
Fold [1/5] Epoch [20/100] Initial Loss: 0.1414, Training Loss: 0.0078, Initial Validation Loss: 0.1348, Validation Loss: 0.0332,V Acc: 0.8468, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.6061
Fold [1/5] Epoch [30/100] Initial Loss: 0.1414, Training Loss: 0.0047, Initial Validation Loss: 0.1348, Validation Loss: 0.0290,V Acc: 0.8468, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.5455
Fold [1/5] Epoch [40/100] Initial Loss: 0.1414, Training Loss: 0.0038, Initial Validation Loss: 0.1348, Validation Loss: 0.0263,V Acc: 0.8829, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.6970
Fold [1/5] Epoch [50/100] Initial Loss: 0.1414, Training Loss: 0.0034, Initial Validation Loss: 0.1348, Validation Loss: 0.0247,V Acc: 0.9009, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.7576
Fold [1/5] Epoch [60/100] Initial Loss: 0.1414, Training Loss: 0.0032, Initial Validation Loss: 0.1348, Validation Loss: 0.0230,V Acc: 0.9189, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.8182
Fold [1/5] Epoch [70/100] Initial Loss: 0.1414, Training Loss: 0.0032, Initial Validation Loss: 0.1348, Validation Loss: 0.0221,V Acc: 0.9099, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.7576
Fold [1/5] Epoch [80/100] Initial Loss: 0.1414, Training Loss: 0.0031, Initial Validation Loss: 0.1348, Validation Loss: 0.0217,V Acc: 0.9189, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.8182
Fold [1/5] Epoch [90/100] Initial Loss: 0.1414, Training Loss: 0.0031, Initial Validation Loss: 0.1348, Validation Loss: 0.0219,V Acc: 0.9009, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.7576
Stopping early at Epoch (base 0): 94  Rolling back to Epoch (base 0): 89  Top Validation Acc: 0.9743589743589743
Fold [2/5] Epoch [0/100] Initial Loss: 0.1393, Training Loss: 0.1393, Initial Validation Loss: 0.1344, Validation Loss: 0.1344,V Acc: 0.2523, Top 70th Acc: 0.3205, Bottom 30th Acc: 0.0909
Fold [2/5] Epoch [10/100] Initial Loss: 0.1393, Training Loss: 0.0147, Initial Validation Loss: 0.1344, Validation Loss: 0.0314,V Acc: 0.8559, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 19  Rolling back to Epoch (base 0): 14  Top Validation Acc: 0.9487179487179487
Fold [3/5] Epoch [0/100] Initial Loss: 0.1411, Training Loss: 0.1411, Initial Validation Loss: 0.1350, Validation Loss: 0.1350,V Acc: 0.3545, Top 70th Acc: 0.4026, Bottom 30th Acc: 0.2424
Fold [3/5] Epoch [10/100] Initial Loss: 0.1411, Training Loss: 0.0142, Initial Validation Loss: 0.1350, Validation Loss: 0.0296,V Acc: 0.8273, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.5152
Fold [3/5] Epoch [20/100] Initial Loss: 0.1411, Training Loss: 0.0051, Initial Validation Loss: 0.1350, Validation Loss: 0.0237,V Acc: 0.8545, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.6061
Fold [3/5] Epoch [30/100] Initial Loss: 0.1411, Training Loss: 0.0041, Initial Validation Loss: 0.1350, Validation Loss: 0.0230,V Acc: 0.8727, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 34  Rolling back to Epoch (base 0): 29  Top Validation Acc: 0.961038961038961
Fold [4/5] Epoch [0/100] Initial Loss: 0.1368, Training Loss: 0.1368, Initial Validation Loss: 0.1348, Validation Loss: 0.1348,V Acc: 0.2909, Top 70th Acc: 0.3377, Bottom 30th Acc: 0.1818
Fold [4/5] Epoch [10/100] Initial Loss: 0.1368, Training Loss: 0.0128, Initial Validation Loss: 0.1348, Validation Loss: 0.0361,V Acc: 0.8000, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.4545
Fold [4/5] Epoch [20/100] Initial Loss: 0.1368, Training Loss: 0.0046, Initial Validation Loss: 0.1348, Validation Loss: 0.0335,V Acc: 0.8273, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.935064935064935
Fold [5/5] Epoch [0/100] Initial Loss: 0.1404, Training Loss: 0.1404, Initial Validation Loss: 0.1350, Validation Loss: 0.1350,V Acc: 0.2500, Top 70th Acc: 0.3026, Bottom 30th Acc: 0.1250
Fold [5/5] Epoch [10/100] Initial Loss: 0.1404, Training Loss: 0.0208, Initial Validation Loss: 0.1350, Validation Loss: 0.0366,V Acc: 0.8426, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.6250
Fold [5/5] Epoch [20/100] Initial Loss: 0.1404, Training Loss: 0.0048, Initial Validation Loss: 0.1350, Validation Loss: 0.0280,V Acc: 0.8704, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.6875
Fold [5/5] Epoch [30/100] Initial Loss: 0.1404, Training Loss: 0.0039, Initial Validation Loss: 0.1350, Validation Loss: 0.0279,V Acc: 0.8889, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.7812
Stopping early at Epoch (base 0): 31  Rolling back to Epoch (base 0): 26  Top Validation Acc: 0.9342105263157895
86 4 [array([0.17689614, 0.06130579, 0.04514834, 0.16875376, 0.547896  ],
      dtype=float32)]
Running train_nn.py with seed 87
CUDA:False
Training samples count:  550
Training on 163 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1388, Training Loss: 0.1388, Initial Validation Loss: 0.1382, Validation Loss: 0.1382,V Acc: 0.3333, Top 70th Acc: 0.4103, Bottom 30th Acc: 0.1515
Fold [1/5] Epoch [10/100] Initial Loss: 0.1388, Training Loss: 0.0215, Initial Validation Loss: 0.1382, Validation Loss: 0.0400,V Acc: 0.8378, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.6364
Fold [1/5] Epoch [20/100] Initial Loss: 0.1388, Training Loss: 0.0047, Initial Validation Loss: 0.1382, Validation Loss: 0.0279,V Acc: 0.8919, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.6970
Fold [1/5] Epoch [30/100] Initial Loss: 0.1388, Training Loss: 0.0037, Initial Validation Loss: 0.1382, Validation Loss: 0.0274,V Acc: 0.8919, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 37  Rolling back to Epoch (base 0): 32  Top Validation Acc: 0.9743589743589743
Fold [2/5] Epoch [0/100] Initial Loss: 0.1383, Training Loss: 0.1383, Initial Validation Loss: 0.1319, Validation Loss: 0.1319,V Acc: 0.4054, Top 70th Acc: 0.4744, Bottom 30th Acc: 0.2424
Fold [2/5] Epoch [10/100] Initial Loss: 0.1383, Training Loss: 0.0150, Initial Validation Loss: 0.1319, Validation Loss: 0.0406,V Acc: 0.7928, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.4848
Fold [2/5] Epoch [20/100] Initial Loss: 0.1383, Training Loss: 0.0043, Initial Validation Loss: 0.1319, Validation Loss: 0.0354,V Acc: 0.7928, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.4848
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.9358974358974359
Fold [3/5] Epoch [0/100] Initial Loss: 0.1391, Training Loss: 0.1391, Initial Validation Loss: 0.1354, Validation Loss: 0.1354,V Acc: 0.2818, Top 70th Acc: 0.2727, Bottom 30th Acc: 0.3030
Fold [3/5] Epoch [10/100] Initial Loss: 0.1391, Training Loss: 0.0172, Initial Validation Loss: 0.1354, Validation Loss: 0.0350,V Acc: 0.8364, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.6364
Fold [3/5] Epoch [20/100] Initial Loss: 0.1391, Training Loss: 0.0054, Initial Validation Loss: 0.1354, Validation Loss: 0.0270,V Acc: 0.8818, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.7273
Fold [3/5] Epoch [30/100] Initial Loss: 0.1391, Training Loss: 0.0042, Initial Validation Loss: 0.1354, Validation Loss: 0.0257,V Acc: 0.8727, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 31  Rolling back to Epoch (base 0): 26  Top Validation Acc: 0.961038961038961
Fold [4/5] Epoch [0/100] Initial Loss: 0.1378, Training Loss: 0.1378, Initial Validation Loss: 0.1357, Validation Loss: 0.1357,V Acc: 0.2727, Top 70th Acc: 0.3506, Bottom 30th Acc: 0.0909
Fold [4/5] Epoch [10/100] Initial Loss: 0.1378, Training Loss: 0.0208, Initial Validation Loss: 0.1357, Validation Loss: 0.0350,V Acc: 0.8455, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.5758
Fold [4/5] Epoch [20/100] Initial Loss: 0.1378, Training Loss: 0.0056, Initial Validation Loss: 0.1357, Validation Loss: 0.0249,V Acc: 0.8909, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.7273
Fold [4/5] Epoch [30/100] Initial Loss: 0.1378, Training Loss: 0.0042, Initial Validation Loss: 0.1357, Validation Loss: 0.0229,V Acc: 0.9000, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.7273
Fold [4/5] Epoch [40/100] Initial Loss: 0.1378, Training Loss: 0.0039, Initial Validation Loss: 0.1357, Validation Loss: 0.0217,V Acc: 0.9091, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.7576
Fold [4/5] Epoch [50/100] Initial Loss: 0.1378, Training Loss: 0.0037, Initial Validation Loss: 0.1357, Validation Loss: 0.0215,V Acc: 0.9182, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.7879
Stopping early at Epoch (base 0): 58  Rolling back to Epoch (base 0): 53  Top Validation Acc: 0.987012987012987
Fold [5/5] Epoch [0/100] Initial Loss: 0.1395, Training Loss: 0.1395, Initial Validation Loss: 0.1306, Validation Loss: 0.1306,V Acc: 0.3611, Top 70th Acc: 0.4342, Bottom 30th Acc: 0.1875
Fold [5/5] Epoch [10/100] Initial Loss: 0.1395, Training Loss: 0.0141, Initial Validation Loss: 0.1306, Validation Loss: 0.0273,V Acc: 0.8426, Top 70th Acc: 0.9737, Bottom 30th Acc: 0.5312
Fold [5/5] Epoch [20/100] Initial Loss: 0.1395, Training Loss: 0.0050, Initial Validation Loss: 0.1306, Validation Loss: 0.0220,V Acc: 0.8704, Top 70th Acc: 0.9868, Bottom 30th Acc: 0.5938
Fold [5/5] Epoch [30/100] Initial Loss: 0.1395, Training Loss: 0.0040, Initial Validation Loss: 0.1306, Validation Loss: 0.0215,V Acc: 0.8796, Top 70th Acc: 0.9868, Bottom 30th Acc: 0.6250
Stopping early at Epoch (base 0): 36  Rolling back to Epoch (base 0): 31  Top Validation Acc: 0.9868421052631579
87 4 [array([0.18144055, 0.0568459 , 0.04589302, 0.1937948 , 0.52202576],
      dtype=float32)]
Running train_nn.py with seed 88
CUDA:False
Training samples count:  550
Training on 163 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1386, Training Loss: 0.1386, Initial Validation Loss: 0.1351, Validation Loss: 0.1351,V Acc: 0.2523, Top 70th Acc: 0.3590, Bottom 30th Acc: 0.0000
Fold [1/5] Epoch [10/100] Initial Loss: 0.1386, Training Loss: 0.0171, Initial Validation Loss: 0.1351, Validation Loss: 0.0356,V Acc: 0.8198, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.5152
Fold [1/5] Epoch [20/100] Initial Loss: 0.1386, Training Loss: 0.0051, Initial Validation Loss: 0.1351, Validation Loss: 0.0276,V Acc: 0.8739, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.6364
Fold [1/5] Epoch [30/100] Initial Loss: 0.1386, Training Loss: 0.0040, Initial Validation Loss: 0.1351, Validation Loss: 0.0278,V Acc: 0.8559, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 36  Rolling back to Epoch (base 0): 31  Top Validation Acc: 0.9487179487179487
Fold [2/5] Epoch [0/100] Initial Loss: 0.1411, Training Loss: 0.1411, Initial Validation Loss: 0.1365, Validation Loss: 0.1365,V Acc: 0.2793, Top 70th Acc: 0.3205, Bottom 30th Acc: 0.1818
Fold [2/5] Epoch [10/100] Initial Loss: 0.1411, Training Loss: 0.0207, Initial Validation Loss: 0.1365, Validation Loss: 0.0403,V Acc: 0.8018, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.5152
Fold [2/5] Epoch [20/100] Initial Loss: 0.1411, Training Loss: 0.0057, Initial Validation Loss: 0.1365, Validation Loss: 0.0343,V Acc: 0.8108, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.5152
Fold [2/5] Epoch [30/100] Initial Loss: 0.1411, Training Loss: 0.0044, Initial Validation Loss: 0.1365, Validation Loss: 0.0324,V Acc: 0.8378, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.5758
Fold [2/5] Epoch [40/100] Initial Loss: 0.1411, Training Loss: 0.0039, Initial Validation Loss: 0.1365, Validation Loss: 0.0317,V Acc: 0.8378, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.5758
Fold [2/5] Epoch [50/100] Initial Loss: 0.1411, Training Loss: 0.0037, Initial Validation Loss: 0.1365, Validation Loss: 0.0310,V Acc: 0.8468, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 56  Rolling back to Epoch (base 0): 51  Top Validation Acc: 0.9487179487179487
Fold [3/5] Epoch [0/100] Initial Loss: 0.1389, Training Loss: 0.1389, Initial Validation Loss: 0.1322, Validation Loss: 0.1322,V Acc: 0.3091, Top 70th Acc: 0.3636, Bottom 30th Acc: 0.1818
Fold [3/5] Epoch [10/100] Initial Loss: 0.1389, Training Loss: 0.0173, Initial Validation Loss: 0.1322, Validation Loss: 0.0362,V Acc: 0.8000, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.4242
Fold [3/5] Epoch [20/100] Initial Loss: 0.1389, Training Loss: 0.0048, Initial Validation Loss: 0.1322, Validation Loss: 0.0294,V Acc: 0.8182, Top 70th Acc: 0.9870, Bottom 30th Acc: 0.4242
Fold [3/5] Epoch [30/100] Initial Loss: 0.1389, Training Loss: 0.0037, Initial Validation Loss: 0.1322, Validation Loss: 0.0285,V Acc: 0.8273, Top 70th Acc: 0.9870, Bottom 30th Acc: 0.4545
Fold [3/5] Epoch [40/100] Initial Loss: 0.1389, Training Loss: 0.0035, Initial Validation Loss: 0.1322, Validation Loss: 0.0284,V Acc: 0.8273, Top 70th Acc: 0.9870, Bottom 30th Acc: 0.4545
Fold [3/5] Epoch [50/100] Initial Loss: 0.1389, Training Loss: 0.0034, Initial Validation Loss: 0.1322, Validation Loss: 0.0275,V Acc: 0.8364, Top 70th Acc: 0.9870, Bottom 30th Acc: 0.4848
Fold [3/5] Epoch [60/100] Initial Loss: 0.1389, Training Loss: 0.0033, Initial Validation Loss: 0.1322, Validation Loss: 0.0274,V Acc: 0.8273, Top 70th Acc: 0.9870, Bottom 30th Acc: 0.4545
Stopping early at Epoch (base 0): 61  Rolling back to Epoch (base 0): 56  Top Validation Acc: 0.987012987012987
88 2 [array([0.23704453, 0.04394647, 0.11221761, 0.17719446, 0.429597  ],
      dtype=float32)]
Fold [4/5] Epoch [0/100] Initial Loss: 0.1443, Training Loss: 0.1443, Initial Validation Loss: 0.1358, Validation Loss: 0.1358,V Acc: 0.2636, Top 70th Acc: 0.2857, Bottom 30th Acc: 0.2121
Fold [4/5] Epoch [10/100] Initial Loss: 0.1443, Training Loss: 0.0211, Initial Validation Loss: 0.1358, Validation Loss: 0.0395,V Acc: 0.8182, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.6061
Fold [4/5] Epoch [20/100] Initial Loss: 0.1443, Training Loss: 0.0053, Initial Validation Loss: 0.1358, Validation Loss: 0.0290,V Acc: 0.8364, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.5455
Fold [4/5] Epoch [30/100] Initial Loss: 0.1443, Training Loss: 0.0040, Initial Validation Loss: 0.1358, Validation Loss: 0.0278,V Acc: 0.8364, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.5758
Fold [4/5] Epoch [40/100] Initial Loss: 0.1443, Training Loss: 0.0037, Initial Validation Loss: 0.1358, Validation Loss: 0.0271,V Acc: 0.8455, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 49  Rolling back to Epoch (base 0): 44  Top Validation Acc: 0.948051948051948
Fold [5/5] Epoch [0/100] Initial Loss: 0.1369, Training Loss: 0.1369, Initial Validation Loss: 0.1320, Validation Loss: 0.1320,V Acc: 0.2685, Top 70th Acc: 0.3553, Bottom 30th Acc: 0.0625
Fold [5/5] Epoch [10/100] Initial Loss: 0.1369, Training Loss: 0.0161, Initial Validation Loss: 0.1320, Validation Loss: 0.0396,V Acc: 0.8426, Top 70th Acc: 0.8947, Bottom 30th Acc: 0.7188
Fold [5/5] Epoch [20/100] Initial Loss: 0.1369, Training Loss: 0.0047, Initial Validation Loss: 0.1320, Validation Loss: 0.0336,V Acc: 0.8426, Top 70th Acc: 0.8947, Bottom 30th Acc: 0.7188
Fold [5/5] Epoch [30/100] Initial Loss: 0.1369, Training Loss: 0.0037, Initial Validation Loss: 0.1320, Validation Loss: 0.0338,V Acc: 0.8241, Top 70th Acc: 0.9211, Bottom 30th Acc: 0.5938
Stopping early at Epoch (base 0): 30  Rolling back to Epoch (base 0): 25  Top Validation Acc: 0.9210526315789473
Running train_nn.py with seed 89
CUDA:False
Training samples count:  550
Training on 163 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1409, Training Loss: 0.1409, Initial Validation Loss: 0.1347, Validation Loss: 0.1347,V Acc: 0.3243, Top 70th Acc: 0.3718, Bottom 30th Acc: 0.2121
Fold [1/5] Epoch [10/100] Initial Loss: 0.1409, Training Loss: 0.0151, Initial Validation Loss: 0.1347, Validation Loss: 0.0366,V Acc: 0.7928, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.4848
Fold [1/5] Epoch [20/100] Initial Loss: 0.1409, Training Loss: 0.0051, Initial Validation Loss: 0.1347, Validation Loss: 0.0339,V Acc: 0.8198, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 20  Rolling back to Epoch (base 0): 15  Top Validation Acc: 0.9102564102564102
Fold [2/5] Epoch [0/100] Initial Loss: 0.1429, Training Loss: 0.1429, Initial Validation Loss: 0.1361, Validation Loss: 0.1361,V Acc: 0.2252, Top 70th Acc: 0.2821, Bottom 30th Acc: 0.0909
Fold [2/5] Epoch [10/100] Initial Loss: 0.1429, Training Loss: 0.0189, Initial Validation Loss: 0.1361, Validation Loss: 0.0369,V Acc: 0.7928, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.5152
Fold [2/5] Epoch [20/100] Initial Loss: 0.1429, Training Loss: 0.0052, Initial Validation Loss: 0.1361, Validation Loss: 0.0272,V Acc: 0.8559, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.5758
Fold [2/5] Epoch [30/100] Initial Loss: 0.1429, Training Loss: 0.0040, Initial Validation Loss: 0.1361, Validation Loss: 0.0244,V Acc: 0.8739, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.6364
Fold [2/5] Epoch [40/100] Initial Loss: 0.1429, Training Loss: 0.0037, Initial Validation Loss: 0.1361, Validation Loss: 0.0237,V Acc: 0.8829, Top 70th Acc: 0.9872, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 46  Rolling back to Epoch (base 0): 41  Top Validation Acc: 0.9871794871794872
Fold [3/5] Epoch [0/100] Initial Loss: 0.1381, Training Loss: 0.1381, Initial Validation Loss: 0.1328, Validation Loss: 0.1328,V Acc: 0.3091, Top 70th Acc: 0.3636, Bottom 30th Acc: 0.1818
Fold [3/5] Epoch [10/100] Initial Loss: 0.1381, Training Loss: 0.0233, Initial Validation Loss: 0.1328, Validation Loss: 0.0364,V Acc: 0.8273, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.6061
Fold [3/5] Epoch [20/100] Initial Loss: 0.1381, Training Loss: 0.0052, Initial Validation Loss: 0.1328, Validation Loss: 0.0266,V Acc: 0.8545, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.6970
Fold [3/5] Epoch [30/100] Initial Loss: 0.1381, Training Loss: 0.0040, Initial Validation Loss: 0.1328, Validation Loss: 0.0254,V Acc: 0.8727, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.7273
Stopping early at Epoch (base 0): 30  Rolling back to Epoch (base 0): 25  Top Validation Acc: 0.935064935064935
89 2 [array([0.29795805, 0.06980706, 0.05895491, 0.16517901, 0.408101  ],
      dtype=float32)]
Fold [4/5] Epoch [0/100] Initial Loss: 0.1370, Training Loss: 0.1370, Initial Validation Loss: 0.1310, Validation Loss: 0.1310,V Acc: 0.3909, Top 70th Acc: 0.4935, Bottom 30th Acc: 0.1515
Fold [4/5] Epoch [10/100] Initial Loss: 0.1370, Training Loss: 0.0212, Initial Validation Loss: 0.1310, Validation Loss: 0.0445,V Acc: 0.7909, Top 70th Acc: 0.8961, Bottom 30th Acc: 0.5455
Fold [4/5] Epoch [20/100] Initial Loss: 0.1370, Training Loss: 0.0044, Initial Validation Loss: 0.1310, Validation Loss: 0.0353,V Acc: 0.8091, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.4848
Stopping early at Epoch (base 0): 27  Rolling back to Epoch (base 0): 22  Top Validation Acc: 0.935064935064935
Fold [5/5] Epoch [0/100] Initial Loss: 0.1376, Training Loss: 0.1376, Initial Validation Loss: 0.1358, Validation Loss: 0.1358,V Acc: 0.2500, Top 70th Acc: 0.3421, Bottom 30th Acc: 0.0312
Fold [5/5] Epoch [10/100] Initial Loss: 0.1376, Training Loss: 0.0166, Initial Validation Loss: 0.1358, Validation Loss: 0.0309,V Acc: 0.8981, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.7500
Stopping early at Epoch (base 0): 18  Rolling back to Epoch (base 0): 13  Top Validation Acc: 0.9473684210526315
Running train_nn.py with seed 90
CUDA:False
Training samples count:  550
Training on 163 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1403, Training Loss: 0.1403, Initial Validation Loss: 0.1369, Validation Loss: 0.1369,V Acc: 0.2523, Top 70th Acc: 0.3590, Bottom 30th Acc: 0.0000
Fold [1/5] Epoch [10/100] Initial Loss: 0.1403, Training Loss: 0.0296, Initial Validation Loss: 0.1369, Validation Loss: 0.0581,V Acc: 0.7387, Top 70th Acc: 0.8462, Bottom 30th Acc: 0.4848
Fold [1/5] Epoch [20/100] Initial Loss: 0.1403, Training Loss: 0.0058, Initial Validation Loss: 0.1369, Validation Loss: 0.0417,V Acc: 0.7748, Top 70th Acc: 0.8718, Bottom 30th Acc: 0.5455
Fold [1/5] Epoch [30/100] Initial Loss: 0.1403, Training Loss: 0.0040, Initial Validation Loss: 0.1369, Validation Loss: 0.0406,V Acc: 0.7748, Top 70th Acc: 0.8718, Bottom 30th Acc: 0.5455
Fold [1/5] Epoch [40/100] Initial Loss: 0.1403, Training Loss: 0.0036, Initial Validation Loss: 0.1369, Validation Loss: 0.0398,V Acc: 0.7748, Top 70th Acc: 0.8718, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 44  Rolling back to Epoch (base 0): 39  Top Validation Acc: 0.8717948717948718
Fold [2/5] Epoch [0/100] Initial Loss: 0.1409, Training Loss: 0.1409, Initial Validation Loss: 0.1369, Validation Loss: 0.1369,V Acc: 0.2613, Top 70th Acc: 0.3205, Bottom 30th Acc: 0.1212
Fold [2/5] Epoch [10/100] Initial Loss: 0.1409, Training Loss: 0.0220, Initial Validation Loss: 0.1369, Validation Loss: 0.0332,V Acc: 0.8468, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.5758
Fold [2/5] Epoch [20/100] Initial Loss: 0.1409, Training Loss: 0.0049, Initial Validation Loss: 0.1369, Validation Loss: 0.0201,V Acc: 0.8829, Top 70th Acc: 0.9872, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 27  Rolling back to Epoch (base 0): 22  Top Validation Acc: 0.9871794871794872
Fold [3/5] Epoch [0/100] Initial Loss: 0.1392, Training Loss: 0.1392, Initial Validation Loss: 0.1336, Validation Loss: 0.1336,V Acc: 0.2545, Top 70th Acc: 0.2727, Bottom 30th Acc: 0.2121
Fold [3/5] Epoch [10/100] Initial Loss: 0.1392, Training Loss: 0.0192, Initial Validation Loss: 0.1336, Validation Loss: 0.0323,V Acc: 0.8636, Top 70th Acc: 0.9870, Bottom 30th Acc: 0.5758
Fold [3/5] Epoch [20/100] Initial Loss: 0.1392, Training Loss: 0.0052, Initial Validation Loss: 0.1336, Validation Loss: 0.0285,V Acc: 0.8545, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 27  Rolling back to Epoch (base 0): 22  Top Validation Acc: 0.974025974025974
Fold [4/5] Epoch [0/100] Initial Loss: 0.1403, Training Loss: 0.1403, Initial Validation Loss: 0.1378, Validation Loss: 0.1378,V Acc: 0.2636, Top 70th Acc: 0.3377, Bottom 30th Acc: 0.0909
Fold [4/5] Epoch [10/100] Initial Loss: 0.1403, Training Loss: 0.0262, Initial Validation Loss: 0.1378, Validation Loss: 0.0357,V Acc: 0.8091, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.4545
Fold [4/5] Epoch [20/100] Initial Loss: 0.1403, Training Loss: 0.0051, Initial Validation Loss: 0.1378, Validation Loss: 0.0259,V Acc: 0.8818, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.6667
Fold [4/5] Epoch [30/100] Initial Loss: 0.1403, Training Loss: 0.0039, Initial Validation Loss: 0.1378, Validation Loss: 0.0259,V Acc: 0.8909, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.7273
Stopping early at Epoch (base 0): 34  Rolling back to Epoch (base 0): 29  Top Validation Acc: 0.974025974025974
90 3 [array([0.30421847, 0.08810522, 0.17587078, 0.28373522, 0.14807023],
      dtype=float32)]
Fold [5/5] Epoch [0/100] Initial Loss: 0.1398, Training Loss: 0.1398, Initial Validation Loss: 0.1296, Validation Loss: 0.1296,V Acc: 0.2500, Top 70th Acc: 0.3421, Bottom 30th Acc: 0.0312
Fold [5/5] Epoch [10/100] Initial Loss: 0.1398, Training Loss: 0.0191, Initial Validation Loss: 0.1296, Validation Loss: 0.0374,V Acc: 0.8426, Top 70th Acc: 0.9079, Bottom 30th Acc: 0.6875
Fold [5/5] Epoch [20/100] Initial Loss: 0.1398, Training Loss: 0.0052, Initial Validation Loss: 0.1296, Validation Loss: 0.0330,V Acc: 0.8611, Top 70th Acc: 0.9211, Bottom 30th Acc: 0.7188
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.9210526315789473
Running train_nn.py with seed 91
CUDA:False
Training samples count:  550
Training on 163 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1357, Training Loss: 0.1357, Initial Validation Loss: 0.1332, Validation Loss: 0.1332,V Acc: 0.3694, Top 70th Acc: 0.3590, Bottom 30th Acc: 0.3939
Fold [1/5] Epoch [10/100] Initial Loss: 0.1357, Training Loss: 0.0160, Initial Validation Loss: 0.1332, Validation Loss: 0.0398,V Acc: 0.8468, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.6667
Fold [1/5] Epoch [20/100] Initial Loss: 0.1357, Training Loss: 0.0061, Initial Validation Loss: 0.1332, Validation Loss: 0.0368,V Acc: 0.8288, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.5758
Fold [1/5] Epoch [30/100] Initial Loss: 0.1357, Training Loss: 0.0046, Initial Validation Loss: 0.1332, Validation Loss: 0.0360,V Acc: 0.8288, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.5758/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)

Stopping early at Epoch (base 0): 30  Rolling back to Epoch (base 0): 25  Top Validation Acc: 0.9358974358974359
Fold [2/5] Epoch [0/100] Initial Loss: 0.1379, Training Loss: 0.1379, Initial Validation Loss: 0.1280, Validation Loss: 0.1280,V Acc: 0.4054, Top 70th Acc: 0.4744, Bottom 30th Acc: 0.2424
Fold [2/5] Epoch [10/100] Initial Loss: 0.1379, Training Loss: 0.0142, Initial Validation Loss: 0.1280, Validation Loss: 0.0335,V Acc: 0.7928, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.5152
Fold [2/5] Epoch [20/100] Initial Loss: 0.1379, Training Loss: 0.0056, Initial Validation Loss: 0.1280, Validation Loss: 0.0289,V Acc: 0.8108, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.5455
Fold [2/5] Epoch [30/100] Initial Loss: 0.1379, Training Loss: 0.0042, Initial Validation Loss: 0.1280, Validation Loss: 0.0288,V Acc: 0.8108, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 31  Rolling back to Epoch (base 0): 26  Top Validation Acc: 0.9230769230769231
Fold [3/5] Epoch [0/100] Initial Loss: 0.1377, Training Loss: 0.1377, Initial Validation Loss: 0.1334, Validation Loss: 0.1334,V Acc: 0.3545, Top 70th Acc: 0.4156, Bottom 30th Acc: 0.2121
Fold [3/5] Epoch [10/100] Initial Loss: 0.1377, Training Loss: 0.0161, Initial Validation Loss: 0.1334, Validation Loss: 0.0367,V Acc: 0.8727, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6970
Fold [3/5] Epoch [20/100] Initial Loss: 0.1377, Training Loss: 0.0050, Initial Validation Loss: 0.1334, Validation Loss: 0.0292,V Acc: 0.8545, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 22  Rolling back to Epoch (base 0): 17  Top Validation Acc: 0.974025974025974
Fold [4/5] Epoch [0/100] Initial Loss: 0.1394, Training Loss: 0.1394, Initial Validation Loss: 0.1367, Validation Loss: 0.1367,V Acc: 0.3000, Top 70th Acc: 0.3766, Bottom 30th Acc: 0.1212
Fold [4/5] Epoch [10/100] Initial Loss: 0.1394, Training Loss: 0.0324, Initial Validation Loss: 0.1367, Validation Loss: 0.0423,V Acc: 0.8000, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.5152
Fold [4/5] Epoch [20/100] Initial Loss: 0.1394, Training Loss: 0.0064, Initial Validation Loss: 0.1367, Validation Loss: 0.0291,V Acc: 0.9000, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.7273
Fold [4/5] Epoch [30/100] Initial Loss: 0.1394, Training Loss: 0.0042, Initial Validation Loss: 0.1367, Validation Loss: 0.0273,V Acc: 0.8909, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 32  Rolling back to Epoch (base 0): 27  Top Validation Acc: 0.974025974025974
Fold [5/5] Epoch [0/100] Initial Loss: 0.1400, Training Loss: 0.1400, Initial Validation Loss: 0.1312, Validation Loss: 0.1312,V Acc: 0.2500, Top 70th Acc: 0.3421, Bottom 30th Acc: 0.0312
Fold [5/5] Epoch [10/100] Initial Loss: 0.1400, Training Loss: 0.0241, Initial Validation Loss: 0.1312, Validation Loss: 0.0413,V Acc: 0.7870, Top 70th Acc: 0.9211, Bottom 30th Acc: 0.4688
Fold [5/5] Epoch [20/100] Initial Loss: 0.1400, Training Loss: 0.0053, Initial Validation Loss: 0.1312, Validation Loss: 0.0326,V Acc: 0.8241, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.5312
Fold [5/5] Epoch [30/100] Initial Loss: 0.1400, Training Loss: 0.0040, Initial Validation Loss: 0.1312, Validation Loss: 0.0315,V Acc: 0.8333, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.5312
Fold [5/5] Epoch [40/100] Initial Loss: 0.1400, Training Loss: 0.0036, Initial Validation Loss: 0.1312, Validation Loss: 0.0310,V Acc: 0.8333, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.5312
Stopping early at Epoch (base 0): 43  Rolling back to Epoch (base 0): 38  Top Validation Acc: 0.9605263157894737
91 4 [array([0.4118537 , 0.07500828, 0.07028611, 0.2402931 , 0.20255883],
      dtype=float32)]
Running train_nn.py with seed 92
CUDA:False
Training samples count:  550
Training on 163 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1386, Training Loss: 0.1386, Initial Validation Loss: 0.1293, Validation Loss: 0.1293,V Acc: 0.2793, Top 70th Acc: 0.3590, Bottom 30th Acc: 0.0909
Fold [1/5] Epoch [10/100] Initial Loss: 0.1386, Training Loss: 0.0105, Initial Validation Loss: 0.1293, Validation Loss: 0.0280,V Acc: 0.8468, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.6061
Fold [1/5] Epoch [20/100] Initial Loss: 0.1386, Training Loss: 0.0045, Initial Validation Loss: 0.1293, Validation Loss: 0.0256,V Acc: 0.8468, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.9487179487179487
92 0 [array([0.13330053, 0.06001887, 0.09016004, 0.33497694, 0.38154364],
      dtype=float32)]
Fold [2/5] Epoch [0/100] Initial Loss: 0.1396, Training Loss: 0.1396, Initial Validation Loss: 0.1330, Validation Loss: 0.1330,V Acc: 0.4234, Top 70th Acc: 0.5641, Bottom 30th Acc: 0.0909
Fold [2/5] Epoch [10/100] Initial Loss: 0.1396, Training Loss: 0.0112, Initial Validation Loss: 0.1330, Validation Loss: 0.0367,V Acc: 0.8198, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.5455
Fold [2/5] Epoch [20/100] Initial Loss: 0.1396, Training Loss: 0.0043, Initial Validation Loss: 0.1330, Validation Loss: 0.0324,V Acc: 0.8468, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 22  Rolling back to Epoch (base 0): 17  Top Validation Acc: 0.9487179487179487
Fold [3/5] Epoch [0/100] Initial Loss: 0.1411, Training Loss: 0.1411, Initial Validation Loss: 0.1338, Validation Loss: 0.1338,V Acc: 0.3727, Top 70th Acc: 0.4156, Bottom 30th Acc: 0.2727
Fold [3/5] Epoch [10/100] Initial Loss: 0.1411, Training Loss: 0.0256, Initial Validation Loss: 0.1338, Validation Loss: 0.0400,V Acc: 0.7909, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.4848
Fold [3/5] Epoch [20/100] Initial Loss: 0.1411, Training Loss: 0.0068, Initial Validation Loss: 0.1338, Validation Loss: 0.0359,V Acc: 0.8091, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.5455
Fold [3/5] Epoch [30/100] Initial Loss: 0.1411, Training Loss: 0.0048, Initial Validation Loss: 0.1338, Validation Loss: 0.0349,V Acc: 0.7909, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.4545
Stopping early at Epoch (base 0): 38  Rolling back to Epoch (base 0): 33  Top Validation Acc: 0.935064935064935
Fold [4/5] Epoch [0/100] Initial Loss: 0.1384, Training Loss: 0.1384, Initial Validation Loss: 0.1371, Validation Loss: 0.1371,V Acc: 0.2545, Top 70th Acc: 0.2857, Bottom 30th Acc: 0.1818
Fold [4/5] Epoch [10/100] Initial Loss: 0.1384, Training Loss: 0.0160, Initial Validation Loss: 0.1371, Validation Loss: 0.0360,V Acc: 0.8091, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.4848
Stopping early at Epoch (base 0): 18  Rolling back to Epoch (base 0): 13  Top Validation Acc: 0.948051948051948
Fold [5/5] Epoch [0/100] Initial Loss: 0.1370, Training Loss: 0.1370, Initial Validation Loss: 0.1359, Validation Loss: 0.1359,V Acc: 0.3056, Top 70th Acc: 0.3421, Bottom 30th Acc: 0.2188
Fold [5/5] Epoch [10/100] Initial Loss: 0.1370, Training Loss: 0.0136, Initial Validation Loss: 0.1359, Validation Loss: 0.0394,V Acc: 0.8333, Top 70th Acc: 0.9079, Bottom 30th Acc: 0.6562
Fold [5/5] Epoch [20/100] Initial Loss: 0.1370, Training Loss: 0.0051, Initial Validation Loss: 0.1359, Validation Loss: 0.0342,V Acc: 0.8333, Top 70th Acc: 0.9211, Bottom 30th Acc: 0.6250
Stopping early at Epoch (base 0): 27  Rolling back to Epoch (base 0): 22  Top Validation Acc: 0.9210526315789473
Running train_nn.py with seed 93
CUDA:False
Training samples count:  550
Training on 163 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1400, Training Loss: 0.1400, Initial Validation Loss: 0.1336, Validation Loss: 0.1336,V Acc: 0.2703, Top 70th Acc: 0.3205, Bottom 30th Acc: 0.1515
Fold [1/5] Epoch [10/100] Initial Loss: 0.1400, Training Loss: 0.0317, Initial Validation Loss: 0.1336, Validation Loss: 0.0496,V Acc: 0.8018, Top 70th Acc: 0.8846, Bottom 30th Acc: 0.6061
Fold [1/5] Epoch [20/100] Initial Loss: 0.1400, Training Loss: 0.0053, Initial Validation Loss: 0.1336, Validation Loss: 0.0372,V Acc: 0.8378, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 28  Rolling back to Epoch (base 0): 23  Top Validation Acc: 0.9102564102564102
Fold [2/5] Epoch [0/100] Initial Loss: 0.1384, Training Loss: 0.1384, Initial Validation Loss: 0.1401, Validation Loss: 0.1401,V Acc: 0.2523, Top 70th Acc: 0.3333, Bottom 30th Acc: 0.0606
Fold [2/5] Epoch [10/100] Initial Loss: 0.1384, Training Loss: 0.0194, Initial Validation Loss: 0.1401, Validation Loss: 0.0300,V Acc: 0.8829, Top 70th Acc: 1.0000, Bottom 30th Acc: 0.6061
Fold [2/5] Epoch [20/100] Initial Loss: 0.1384, Training Loss: 0.0065, Initial Validation Loss: 0.1401, Validation Loss: 0.0264,V Acc: 0.8468, Top 70th Acc: 0.9872, Bottom 30th Acc: 0.5152
Stopping early at Epoch (base 0): 22  Rolling back to Epoch (base 0): 17  Top Validation Acc: 0.9871794871794872
Fold [3/5] Epoch [0/100] Initial Loss: 0.1394, Training Loss: 0.1394, Initial Validation Loss: 0.1336, Validation Loss: 0.1336,V Acc: 0.3364, Top 70th Acc: 0.3636, Bottom 30th Acc: 0.2727
Fold [3/5] Epoch [10/100] Initial Loss: 0.1394, Training Loss: 0.0296, Initial Validation Loss: 0.1336, Validation Loss: 0.0509,V Acc: 0.7273, Top 70th Acc: 0.8442, Bottom 30th Acc: 0.4545
Fold [3/5] Epoch [20/100] Initial Loss: 0.1394, Training Loss: 0.0062, Initial Validation Loss: 0.1336, Validation Loss: 0.0339,V Acc: 0.8182, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.5455
Fold [3/5] Epoch [30/100] Initial Loss: 0.1394, Training Loss: 0.0042, Initial Validation Loss: 0.1336, Validation Loss: 0.0326,V Acc: 0.8273, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 32  Rolling back to Epoch (base 0): 27  Top Validation Acc: 0.935064935064935
Fold [4/5] Epoch [0/100] Initial Loss: 0.1375, Training Loss: 0.1375, Initial Validation Loss: 0.1376, Validation Loss: 0.1376,V Acc: 0.2545, Top 70th Acc: 0.3247, Bottom 30th Acc: 0.0909
Fold [4/5] Epoch [10/100] Initial Loss: 0.1375, Training Loss: 0.0127, Initial Validation Loss: 0.1376, Validation Loss: 0.0286,V Acc: 0.9091, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.7879
Fold [4/5] Epoch [20/100] Initial Loss: 0.1375, Training Loss: 0.0046, Initial Validation Loss: 0.1376, Validation Loss: 0.0261,V Acc: 0.8909, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.7273
Stopping early at Epoch (base 0): 27  Rolling back to Epoch (base 0): 22  Top Validation Acc: 0.974025974025974
Fold [5/5] Epoch [0/100] Initial Loss: 0.1364, Training Loss: 0.1364, Initial Validation Loss: 0.1283, Validation Loss: 0.1283,V Acc: 0.3611, Top 70th Acc: 0.3684, Bottom 30th Acc: 0.3438
Fold [5/5] Epoch [10/100] Initial Loss: 0.1364, Training Loss: 0.0159, Initial Validation Loss: 0.1283, Validation Loss: 0.0358,V Acc: 0.8056, Top 70th Acc: 0.9211, Bottom 30th Acc: 0.5312
Fold [5/5] Epoch [20/100] Initial Loss: 0.1364, Training Loss: 0.0066, Initial Validation Loss: 0.1283, Validation Loss: 0.0312,V Acc: 0.8241, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.5312
Fold [5/5] Epoch [30/100] Initial Loss: 0.1364, Training Loss: 0.0052, Initial Validation Loss: 0.1283, Validation Loss: 0.0314,V Acc: 0.8148, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.4688
Stopping early at Epoch (base 0): 30  Rolling back to Epoch (base 0): 25  Top Validation Acc: 0.9605263157894737
93 4 [array([0.26001334, 0.04512972, 0.07342057, 0.3438203 , 0.27761608],
      dtype=float32)]
Running train_nn.py with seed 94
CUDA:False
Training samples count:  550
Training on 163 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1368, Training Loss: 0.1368, Initial Validation Loss: 0.1340, Validation Loss: 0.1340,V Acc: 0.2883, Top 70th Acc: 0.3974, Bottom 30th Acc: 0.0303
Fold [1/5] Epoch [10/100] Initial Loss: 0.1368, Training Loss: 0.0159, Initial Validation Loss: 0.1340, Validation Loss: 0.0379,V Acc: 0.8018, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.5455
Fold [1/5] Epoch [20/100] Initial Loss: 0.1368, Training Loss: 0.0051, Initial Validation Loss: 0.1340, Validation Loss: 0.0340,V Acc: 0.8288, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.5758
Fold [1/5] Epoch [30/100] Initial Loss: 0.1368, Training Loss: 0.0041, Initial Validation Loss: 0.1340, Validation Loss: 0.0326,V Acc: 0.8378, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.5758
Fold [1/5] Epoch [40/100] Initial Loss: 0.1368, Training Loss: 0.0037, Initial Validation Loss: 0.1340, Validation Loss: 0.0315,V Acc: 0.8468, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.5758
Fold [1/5] Epoch [50/100] Initial Loss: 0.1368, Training Loss: 0.0037, Initial Validation Loss: 0.1340, Validation Loss: 0.0313,V Acc: 0.8378, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 59  Rolling back to Epoch (base 0): 54  Top Validation Acc: 0.9487179487179487
Fold [2/5] Epoch [0/100] Initial Loss: 0.1404, Training Loss: 0.1404, Initial Validation Loss: 0.1362, Validation Loss: 0.1362,V Acc: 0.2523, Top 70th Acc: 0.2692, Bottom 30th Acc: 0.2121
Fold [2/5] Epoch [10/100] Initial Loss: 0.1404, Training Loss: 0.0194, Initial Validation Loss: 0.1362, Validation Loss: 0.0321,V Acc: 0.8378, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.5152
Fold [2/5] Epoch [20/100] Initial Loss: 0.1404, Training Loss: 0.0049, Initial Validation Loss: 0.1362, Validation Loss: 0.0239,V Acc: 0.8739, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.9743589743589743
Fold [3/5] Epoch [0/100] Initial Loss: 0.1366, Training Loss: 0.1366, Initial Validation Loss: 0.1321, Validation Loss: 0.1321,V Acc: 0.4182, Top 70th Acc: 0.5325, Bottom 30th Acc: 0.1515
Fold [3/5] Epoch [10/100] Initial Loss: 0.1366, Training Loss: 0.0159, Initial Validation Loss: 0.1321, Validation Loss: 0.0396,V Acc: 0.7909, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.4848
Fold [3/5] Epoch [20/100] Initial Loss: 0.1366, Training Loss: 0.0055, Initial Validation Loss: 0.1321, Validation Loss: 0.0342,V Acc: 0.8000, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.5152
Stopping early at Epoch (base 0): 21  Rolling back to Epoch (base 0): 16  Top Validation Acc: 0.935064935064935
94 2 [array([0.18488726, 0.0575709 , 0.04522933, 0.2613817 , 0.4509308 ],
      dtype=float32)]
Fold [4/5] Epoch [0/100] Initial Loss: 0.1390, Training Loss: 0.1390, Initial Validation Loss: 0.1326, Validation Loss: 0.1326,V Acc: 0.2636, Top 70th Acc: 0.3377, Bottom 30th Acc: 0.0909
Fold [4/5] Epoch [10/100] Initial Loss: 0.1390, Training Loss: 0.0148, Initial Validation Loss: 0.1326, Validation Loss: 0.0378,V Acc: 0.7818, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.4545
Fold [4/5] Epoch [20/100] Initial Loss: 0.1390, Training Loss: 0.0051, Initial Validation Loss: 0.1326, Validation Loss: 0.0338,V Acc: 0.7727, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.3939
Fold [4/5] Epoch [30/100] Initial Loss: 0.1390, Training Loss: 0.0040, Initial Validation Loss: 0.1326, Validation Loss: 0.0333,V Acc: 0.8091, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.4848
Stopping early at Epoch (base 0): 38  Rolling back to Epoch (base 0): 33  Top Validation Acc: 0.961038961038961
Fold [5/5] Epoch [0/100] Initial Loss: 0.1367, Training Loss: 0.1367, Initial Validation Loss: 0.1310, Validation Loss: 0.1310,V Acc: 0.3333, Top 70th Acc: 0.3553, Bottom 30th Acc: 0.2812
Fold [5/5] Epoch [10/100] Initial Loss: 0.1367, Training Loss: 0.0142, Initial Validation Loss: 0.1310, Validation Loss: 0.0313,V Acc: 0.8704, Top 70th Acc: 0.9211, Bottom 30th Acc: 0.7500
Fold [5/5] Epoch [20/100] Initial Loss: 0.1367, Training Loss: 0.0050, Initial Validation Loss: 0.1310, Validation Loss: 0.0273,V Acc: 0.8519, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.6562
Fold [5/5] Epoch [30/100] Initial Loss: 0.1367, Training Loss: 0.0041, Initial Validation Loss: 0.1310, Validation Loss: 0.0263,V Acc: 0.8611, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.6875
Stopping early at Epoch (base 0): 31  Rolling back to Epoch (base 0): 26  Top Validation Acc: 0.9342105263157895
Running train_nn.py with seed 95
CUDA:False
Training samples count:  550
Training on 163 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1371, Training Loss: 0.1371, Initial Validation Loss: 0.1385, Validation Loss: 0.1385,V Acc: 0.2613, Top 70th Acc: 0.3590, Bottom 30th Acc: 0.0303
Fold [1/5] Epoch [10/100] Initial Loss: 0.1371, Training Loss: 0.0150, Initial Validation Loss: 0.1385, Validation Loss: 0.0326,V Acc: 0.9009, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.7273
Fold [1/5] Epoch [20/100] Initial Loss: 0.1371, Training Loss: 0.0050, Initial Validation Loss: 0.1385, Validation Loss: 0.0258,V Acc: 0.9009, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.7273
Stopping early at Epoch (base 0): 23  Rolling back to Epoch (base 0): 18  Top Validation Acc: 0.9743589743589743
Fold [2/5] Epoch [0/100] Initial Loss: 0.1376, Training Loss: 0.1376, Initial Validation Loss: 0.1337, Validation Loss: 0.1337,V Acc: 0.2523, Top 70th Acc: 0.3462, Bottom 30th Acc: 0.0303
Fold [2/5] Epoch [10/100] Initial Loss: 0.1376, Training Loss: 0.0141, Initial Validation Loss: 0.1337, Validation Loss: 0.0320,V Acc: 0.8468, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.6667
Fold [2/5] Epoch [20/100] Initial Loss: 0.1376, Training Loss: 0.0045, Initial Validation Loss: 0.1337, Validation Loss: 0.0286,V Acc: 0.8288, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 24  Rolling back to Epoch (base 0): 19  Top Validation Acc: 0.9615384615384616
Fold [3/5] Epoch [0/100] Initial Loss: 0.1362, Training Loss: 0.1362, Initial Validation Loss: 0.1370, Validation Loss: 0.1370,V Acc: 0.4000, Top 70th Acc: 0.4675, Bottom 30th Acc: 0.2424
Fold [3/5] Epoch [10/100] Initial Loss: 0.1362, Training Loss: 0.0203, Initial Validation Loss: 0.1370, Validation Loss: 0.0474,V Acc: 0.8091, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.5758
Fold [3/5] Epoch [20/100] Initial Loss: 0.1362, Training Loss: 0.0060, Initial Validation Loss: 0.1370, Validation Loss: 0.0401,V Acc: 0.8455, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6061
Fold [3/5] Epoch [30/100] Initial Loss: 0.1362, Training Loss: 0.0044, Initial Validation Loss: 0.1370, Validation Loss: 0.0380,V Acc: 0.8727, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.7273
Fold [3/5] Epoch [40/100] Initial Loss: 0.1362, Training Loss: 0.0040, Initial Validation Loss: 0.1370, Validation Loss: 0.0369,V Acc: 0.8636, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.6970
Fold [3/5] Epoch [50/100] Initial Loss: 0.1362, Training Loss: 0.0038, Initial Validation Loss: 0.1370, Validation Loss: 0.0361,V Acc: 0.8545, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.6667
Fold [3/5] Epoch [60/100] Initial Loss: 0.1362, Training Loss: 0.0036, Initial Validation Loss: 0.1370, Validation Loss: 0.0358,V Acc: 0.8455, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6061
Fold [3/5] Epoch [70/100] Initial Loss: 0.1362, Training Loss: 0.0034, Initial Validation Loss: 0.1370, Validation Loss: 0.0353,V Acc: 0.8545, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.6667
Fold [3/5] Epoch [80/100] Initial Loss: 0.1362, Training Loss: 0.0033, Initial Validation Loss: 0.1370, Validation Loss: 0.0354,V Acc: 0.8545, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6364
Fold [3/5] Epoch [90/100] Initial Loss: 0.1362, Training Loss: 0.0032, Initial Validation Loss: 0.1370, Validation Loss: 0.0348,V Acc: 0.8636, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 92  Rolling back to Epoch (base 0): 87  Top Validation Acc: 0.948051948051948
Fold [4/5] Epoch [0/100] Initial Loss: 0.1387, Training Loss: 0.1387, Initial Validation Loss: 0.1302, Validation Loss: 0.1302,V Acc: 0.3000, Top 70th Acc: 0.3636, Bottom 30th Acc: 0.1515
Fold [4/5] Epoch [10/100] Initial Loss: 0.1387, Training Loss: 0.0105, Initial Validation Loss: 0.1302, Validation Loss: 0.0440,V Acc: 0.7636, Top 70th Acc: 0.8831, Bottom 30th Acc: 0.4848
Fold [4/5] Epoch [20/100] Initial Loss: 0.1387, Training Loss: 0.0044, Initial Validation Loss: 0.1302, Validation Loss: 0.0405,V Acc: 0.7818, Top 70th Acc: 0.8831, Bottom 30th Acc: 0.5455
Stopping early at Epoch (base 0): 28  Rolling back to Epoch (base 0): 23  Top Validation Acc: 0.8831168831168831
Fold [5/5] Epoch [0/100] Initial Loss: 0.1423, Training Loss: 0.1423, Initial Validation Loss: 0.1303, Validation Loss: 0.1303,V Acc: 0.3148, Top 70th Acc: 0.3158, Bottom 30th Acc: 0.3125
Fold [5/5] Epoch [10/100] Initial Loss: 0.1423, Training Loss: 0.0369, Initial Validation Loss: 0.1303, Validation Loss: 0.0440,V Acc: 0.8148, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.5000
Fold [5/5] Epoch [20/100] Initial Loss: 0.1423, Training Loss: 0.0060, Initial Validation Loss: 0.1303, Validation Loss: 0.0248,V Acc: 0.8426, Top 70th Acc: 0.9737, Bottom 30th Acc: 0.5312
Stopping early at Epoch (base 0): 25  Rolling back to Epoch (base 0): 20  Top Validation Acc: 0.9736842105263158
95 4 [array([0.43386024, 0.02674354, 0.1118456 , 0.14153658, 0.286014  ],
      dtype=float32)]
Running train_nn.py with seed 96
CUDA:False
Training samples count:  550
Training on 163 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1361, Training Loss: 0.1361, Initial Validation Loss: 0.1337, Validation Loss: 0.1337,V Acc: 0.3514, Top 70th Acc: 0.4103, Bottom 30th Acc: 0.2121
Fold [1/5] Epoch [10/100] Initial Loss: 0.1361, Training Loss: 0.0149, Initial Validation Loss: 0.1337, Validation Loss: 0.0378,V Acc: 0.8559, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.6364
Fold [1/5] Epoch [20/100] Initial Loss: 0.1361, Training Loss: 0.0047, Initial Validation Loss: 0.1337, Validation Loss: 0.0323,V Acc: 0.8649, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.6970
Fold [1/5] Epoch [30/100] Initial Loss: 0.1361, Training Loss: 0.0036, Initial Validation Loss: 0.1337, Validation Loss: 0.0328,V Acc: 0.8559, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 30  Rolling back to Epoch (base 0): 25  Top Validation Acc: 0.9358974358974359
Fold [2/5] Epoch [0/100] Initial Loss: 0.1384, Training Loss: 0.1384, Initial Validation Loss: 0.1358, Validation Loss: 0.1358,V Acc: 0.2793, Top 70th Acc: 0.3333, Bottom 30th Acc: 0.1515
Fold [2/5] Epoch [10/100] Initial Loss: 0.1384, Training Loss: 0.0193, Initial Validation Loss: 0.1358, Validation Loss: 0.0316,V Acc: 0.8468, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.6667
Fold [2/5] Epoch [20/100] Initial Loss: 0.1384, Training Loss: 0.0046, Initial Validation Loss: 0.1358, Validation Loss: 0.0271,V Acc: 0.8559, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 20  Rolling back to Epoch (base 0): 15  Top Validation Acc: 0.9358974358974359
Fold [3/5] Epoch [0/100] Initial Loss: 0.1385, Training Loss: 0.1385, Initial Validation Loss: 0.1332, Validation Loss: 0.1332,V Acc: 0.3182, Top 70th Acc: 0.4156, Bottom 30th Acc: 0.0909
Fold [3/5] Epoch [10/100] Initial Loss: 0.1385, Training Loss: 0.0218, Initial Validation Loss: 0.1332, Validation Loss: 0.0397,V Acc: 0.8364, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.6667
Fold [3/5] Epoch [20/100] Initial Loss: 0.1385, Training Loss: 0.0057, Initial Validation Loss: 0.1332, Validation Loss: 0.0270,V Acc: 0.8636, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.6061
Fold [3/5] Epoch [30/100] Initial Loss: 0.1385, Training Loss: 0.0041, Initial Validation Loss: 0.1332, Validation Loss: 0.0259,V Acc: 0.8545, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 36  Rolling back to Epoch (base 0): 31  Top Validation Acc: 0.961038961038961
Fold [4/5] Epoch [0/100] Initial Loss: 0.1391, Training Loss: 0.1391, Initial Validation Loss: 0.1326, Validation Loss: 0.1326,V Acc: 0.3091, Top 70th Acc: 0.4026, Bottom 30th Acc: 0.0909
Fold [4/5] Epoch [10/100] Initial Loss: 0.1391, Training Loss: 0.0258, Initial Validation Loss: 0.1326, Validation Loss: 0.0399,V Acc: 0.8273, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.6061
Fold [4/5] Epoch [20/100] Initial Loss: 0.1391, Training Loss: 0.0050, Initial Validation Loss: 0.1326, Validation Loss: 0.0257,V Acc: 0.8727, Top 70th Acc: 0.9870, Bottom 30th Acc: 0.6061
Fold [4/5] Epoch [30/100] Initial Loss: 0.1391, Training Loss: 0.0038, Initial Validation Loss: 0.1326, Validation Loss: 0.0256,V Acc: 0.8818, Top 70th Acc: 0.9870, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 32  Rolling back to Epoch (base 0): 27  Top Validation Acc: 0.987012987012987
Fold [5/5] Epoch [0/100] Initial Loss: 0.1389, Training Loss: 0.1389, Initial Validation Loss: 0.1301, Validation Loss: 0.1301,V Acc: 0.3704, Top 70th Acc: 0.4474, Bottom 30th Acc: 0.1875
Fold [5/5] Epoch [10/100] Initial Loss: 0.1389, Training Loss: 0.0128, Initial Validation Loss: 0.1301, Validation Loss: 0.0327,V Acc: 0.8519, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.6562
Fold [5/5] Epoch [20/100] Initial Loss: 0.1389, Training Loss: 0.0048, Initial Validation Loss: 0.1301, Validation Loss: 0.0278,V Acc: 0.8519, Top 70th Acc: 0.9737, Bottom 30th Acc: 0.5625
Stopping early at Epoch (base 0): 28  Rolling back to Epoch (base 0): 23  Top Validation Acc: 0.9605263157894737
96 4 [array([0.18913308, 0.16207804, 0.07651551, 0.26886582, 0.30340752],
      dtype=float32)]
Running train_nn.py with seed 97
CUDA:False
Training samples count:  550
Training on 163 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1370, Training Loss: 0.1370, Initial Validation Loss: 0.1390, Validation Loss: 0.1390,V Acc: 0.2613, Top 70th Acc: 0.3205, Bottom 30th Acc: 0.1212
Fold [1/5] Epoch [10/100] Initial Loss: 0.1370, Training Loss: 0.0191, Initial Validation Loss: 0.1390, Validation Loss: 0.0364,V Acc: 0.8649, Top 70th Acc: 0.8974, Bottom 30th Acc: 0.7879
Fold [1/5] Epoch [20/100] Initial Loss: 0.1370, Training Loss: 0.0051, Initial Validation Loss: 0.1390, Validation Loss: 0.0269,V Acc: 0.8919, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.7273
Stopping early at Epoch (base 0): 27  Rolling back to Epoch (base 0): 22  Top Validation Acc: 0.9743589743589743
Fold [2/5] Epoch [0/100] Initial Loss: 0.1383, Training Loss: 0.1383, Initial Validation Loss: 0.1356, Validation Loss: 0.1356,V Acc: 0.3243, Top 70th Acc: 0.4103, Bottom 30th Acc: 0.1212
Fold [2/5] Epoch [10/100] Initial Loss: 0.1383, Training Loss: 0.0153, Initial Validation Loss: 0.1356, Validation Loss: 0.0322,V Acc: 0.8468, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.5455
Fold [2/5] Epoch [20/100] Initial Loss: 0.1383, Training Loss: 0.0051, Initial Validation Loss: 0.1356, Validation Loss: 0.0280,V Acc: 0.8468, Top 70th Acc: 0.9872, Bottom 30th Acc: 0.5152
Fold [2/5] Epoch [30/100] Initial Loss: 0.1383, Training Loss: 0.0040, Initial Validation Loss: 0.1356, Validation Loss: 0.0267,V Acc: 0.8468, Top 70th Acc: 1.0000, Bottom 30th Acc: 0.4848
Stopping early at Epoch (base 0): 34  Rolling back to Epoch (base 0): 29  Top Validation Acc: 1.0
97 1 [array([0.26469907, 0.04929406, 0.0939503 , 0.40932834, 0.18272829],
      dtype=float32)]
Fold [3/5] Epoch [0/100] Initial Loss: 0.1394, Training Loss: 0.1394, Initial Validation Loss: 0.1344, Validation Loss: 0.1344,V Acc: 0.2545, Top 70th Acc: 0.3506, Bottom 30th Acc: 0.0303
Fold [3/5] Epoch [10/100] Initial Loss: 0.1394, Training Loss: 0.0195, Initial Validation Loss: 0.1344, Validation Loss: 0.0340,V Acc: 0.8364, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.5758
Fold [3/5] Epoch [20/100] Initial Loss: 0.1394, Training Loss: 0.0053, Initial Validation Loss: 0.1344, Validation Loss: 0.0277,V Acc: 0.8636, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.6364
Fold [3/5] Epoch [30/100] Initial Loss: 0.1394, Training Loss: 0.0041, Initial Validation Loss: 0.1344, Validation Loss: 0.0266,V Acc: 0.8727, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.6667
Fold [3/5] Epoch [40/100] Initial Loss: 0.1394, Training Loss: 0.0037, Initial Validation Loss: 0.1344, Validation Loss: 0.0264,V Acc: 0.8818, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 46  Rolling back to Epoch (base 0): 41  Top Validation Acc: 0.974025974025974
Fold [4/5] Epoch [0/100] Initial Loss: 0.1433, Training Loss: 0.1433, Initial Validation Loss: 0.1350, Validation Loss: 0.1350,V Acc: 0.2273, Top 70th Acc: 0.2727, Bottom 30th Acc: 0.1212
Fold [4/5] Epoch [10/100] Initial Loss: 0.1433, Training Loss: 0.0135, Initial Validation Loss: 0.1350, Validation Loss: 0.0312,V Acc: 0.8636, Top 70th Acc: 0.9870, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 19  Rolling back to Epoch (base 0): 14  Top Validation Acc: 0.974025974025974
Fold [5/5] Epoch [0/100] Initial Loss: 0.1387, Training Loss: 0.1387, Initial Validation Loss: 0.1277, Validation Loss: 0.1277,V Acc: 0.3333, Top 70th Acc: 0.4079, Bottom 30th Acc: 0.1562
Fold [5/5] Epoch [10/100] Initial Loss: 0.1387, Training Loss: 0.0158, Initial Validation Loss: 0.1277, Validation Loss: 0.0442,V Acc: 0.7685, Top 70th Acc: 0.8553, Bottom 30th Acc: 0.5625
Stopping early at Epoch (base 0): 19  Rolling back to Epoch (base 0): 14  Top Validation Acc: 0.8421052631578947
Running train_nn.py with seed 98
CUDA:False
Training samples count:  550
Training on 163 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1383, Training Loss: 0.1383, Initial Validation Loss: 0.1375, Validation Loss: 0.1375,V Acc: 0.3243, Top 70th Acc: 0.3974, Bottom 30th Acc: 0.1515
Fold [1/5] Epoch [10/100] Initial Loss: 0.1383, Training Loss: 0.0238, Initial Validation Loss: 0.1375, Validation Loss: 0.0340,V Acc: 0.8559, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.6061
Fold [1/5] Epoch [20/100] Initial Loss: 0.1383, Training Loss: 0.0057, Initial Validation Loss: 0.1375, Validation Loss: 0.0229,V Acc: 0.9099, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.7576
Stopping early at Epoch (base 0): 28  Rolling back to Epoch (base 0): 23  Top Validation Acc: 0.9743589743589743
98 0 [array([0.44337496, 0.05318467, 0.06957383, 0.18569534, 0.2481713 ],
      dtype=float32)]
Fold [2/5] Epoch [0/100] Initial Loss: 0.1375, Training Loss: 0.1375, Initial Validation Loss: 0.1256, Validation Loss: 0.1256,V Acc: 0.2883, Top 70th Acc: 0.3462, Bottom 30th Acc: 0.1515
Fold [2/5] Epoch [10/100] Initial Loss: 0.1375, Training Loss: 0.0193, Initial Validation Loss: 0.1256, Validation Loss: 0.0428,V Acc: 0.7568, Top 70th Acc: 0.8718, Bottom 30th Acc: 0.4848
Fold [2/5] Epoch [20/100] Initial Loss: 0.1375, Training Loss: 0.0047, Initial Validation Loss: 0.1256, Validation Loss: 0.0372,V Acc: 0.7748, Top 70th Acc: 0.8974, Bottom 30th Acc: 0.4848
Fold [2/5] Epoch [30/100] Initial Loss: 0.1375, Training Loss: 0.0036, Initial Validation Loss: 0.1256, Validation Loss: 0.0358,V Acc: 0.7928, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.5152
Fold [2/5] Epoch [40/100] Initial Loss: 0.1375, Training Loss: 0.0033, Initial Validation Loss: 0.1256, Validation Loss: 0.0344,V Acc: 0.8018, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.5455
Fold [2/5] Epoch [50/100] Initial Loss: 0.1375, Training Loss: 0.0032, Initial Validation Loss: 0.1256, Validation Loss: 0.0336,V Acc: 0.8108, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.5758
Fold [2/5] Epoch [60/100] Initial Loss: 0.1375, Training Loss: 0.0032, Initial Validation Loss: 0.1256, Validation Loss: 0.0328,V Acc: 0.8198, Top 70th Acc: 0.9103, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 60  Rolling back to Epoch (base 0): 55  Top Validation Acc: 0.9102564102564102
Fold [3/5] Epoch [0/100] Initial Loss: 0.1428, Training Loss: 0.1428, Initial Validation Loss: 0.1385, Validation Loss: 0.1385,V Acc: 0.3455, Top 70th Acc: 0.3896, Bottom 30th Acc: 0.2424
Fold [3/5] Epoch [10/100] Initial Loss: 0.1428, Training Loss: 0.0175, Initial Validation Loss: 0.1385, Validation Loss: 0.0419,V Acc: 0.8000, Top 70th Acc: 0.8961, Bottom 30th Acc: 0.5758
Fold [3/5] Epoch [20/100] Initial Loss: 0.1428, Training Loss: 0.0051, Initial Validation Loss: 0.1385, Validation Loss: 0.0359,V Acc: 0.8273, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.6061
Fold [3/5] Epoch [30/100] Initial Loss: 0.1428, Training Loss: 0.0037, Initial Validation Loss: 0.1385, Validation Loss: 0.0355,V Acc: 0.8273, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.5758
Stopping early at Epoch (base 0): 36  Rolling back to Epoch (base 0): 31  Top Validation Acc: 0.922077922077922
Fold [4/5] Epoch [0/100] Initial Loss: 0.1391, Training Loss: 0.1391, Initial Validation Loss: 0.1330, Validation Loss: 0.1330,V Acc: 0.2545, Top 70th Acc: 0.3377, Bottom 30th Acc: 0.0606
Fold [4/5] Epoch [10/100] Initial Loss: 0.1391, Training Loss: 0.0229, Initial Validation Loss: 0.1330, Validation Loss: 0.0379,V Acc: 0.7909, Top 70th Acc: 0.8961, Bottom 30th Acc: 0.5455
Fold [4/5] Epoch [20/100] Initial Loss: 0.1391, Training Loss: 0.0050, Initial Validation Loss: 0.1330, Validation Loss: 0.0256,V Acc: 0.8364, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.5455
Fold [4/5] Epoch [30/100] Initial Loss: 0.1391, Training Loss: 0.0040, Initial Validation Loss: 0.1330, Validation Loss: 0.0243,V Acc: 0.8455, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.5758
Fold [4/5] Epoch [40/100] Initial Loss: 0.1391, Training Loss: 0.0038, Initial Validation Loss: 0.1330, Validation Loss: 0.0241,V Acc: 0.8545, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.6061
Stopping early at Epoch (base 0): 44  Rolling back to Epoch (base 0): 39  Top Validation Acc: 0.974025974025974
Fold [5/5] Epoch [0/100] Initial Loss: 0.1356, Training Loss: 0.1356, Initial Validation Loss: 0.1310, Validation Loss: 0.1310,V Acc: 0.3796, Top 70th Acc: 0.4474, Bottom 30th Acc: 0.2188
Fold [5/5] Epoch [10/100] Initial Loss: 0.1356, Training Loss: 0.0177, Initial Validation Loss: 0.1310, Validation Loss: 0.0345,V Acc: 0.8796, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.6875
Fold [5/5] Epoch [20/100] Initial Loss: 0.1356, Training Loss: 0.0058, Initial Validation Loss: 0.1310, Validation Loss: 0.0299,V Acc: 0.8796, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.6875
Fold [5/5] Epoch [30/100] Initial Loss: 0.1356, Training Loss: 0.0046, Initial Validation Loss: 0.1310, Validation Loss: 0.0292,V Acc: 0.8704, Top 70th Acc: 0.9737, Bottom 30th Acc: 0.6250
Stopping early at Epoch (base 0): 33  Rolling back to Epoch (base 0): 28  Top Validation Acc: 0.9736842105263158
Running train_nn.py with seed 99
CUDA:False
Training samples count:  550
Training on 163 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1403, Training Loss: 0.1403, Initial Validation Loss: 0.1340, Validation Loss: 0.1340,V Acc: 0.2703, Top 70th Acc: 0.3205, Bottom 30th Acc: 0.1515
Fold [1/5] Epoch [10/100] Initial Loss: 0.1403, Training Loss: 0.0145, Initial Validation Loss: 0.1340, Validation Loss: 0.0274,V Acc: 0.8919, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.7576
Fold [1/5] Epoch [20/100] Initial Loss: 0.1403, Training Loss: 0.0051, Initial Validation Loss: 0.1340, Validation Loss: 0.0247,V Acc: 0.8829, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.7273
Stopping early at Epoch (base 0): 22  Rolling back to Epoch (base 0): 17  Top Validation Acc: 0.9487179487179487
Fold [2/5] Epoch [0/100] Initial Loss: 0.1379, Training Loss: 0.1379, Initial Validation Loss: 0.1366, Validation Loss: 0.1366,V Acc: 0.2703, Top 70th Acc: 0.3462, Bottom 30th Acc: 0.0909
Fold [2/5] Epoch [10/100] Initial Loss: 0.1379, Training Loss: 0.0129, Initial Validation Loss: 0.1366, Validation Loss: 0.0375,V Acc: 0.8288, Top 70th Acc: 0.9231, Bottom 30th Acc: 0.6061
Fold [2/5] Epoch [20/100] Initial Loss: 0.1379, Training Loss: 0.0046, Initial Validation Loss: 0.1366, Validation Loss: 0.0337,V Acc: 0.8198, Top 70th Acc: 0.9487, Bottom 30th Acc: 0.5152
Stopping early at Epoch (base 0): 22  Rolling back to Epoch (base 0): 17  Top Validation Acc: 0.9487179487179487
Fold [3/5] Epoch [0/100] Initial Loss: 0.1384, Training Loss: 0.1384, Initial Validation Loss: 0.1336, Validation Loss: 0.1336,V Acc: 0.3000, Top 70th Acc: 0.3506, Bottom 30th Acc: 0.1818
Fold [3/5] Epoch [10/100] Initial Loss: 0.1384, Training Loss: 0.0145, Initial Validation Loss: 0.1336, Validation Loss: 0.0341,V Acc: 0.8182, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.5152
Stopping early at Epoch (base 0): 19  Rolling back to Epoch (base 0): 14  Top Validation Acc: 0.922077922077922
Fold [4/5] Epoch [0/100] Initial Loss: 0.1388, Training Loss: 0.1388, Initial Validation Loss: 0.1326, Validation Loss: 0.1326,V Acc: 0.2545, Top 70th Acc: 0.2857, Bottom 30th Acc: 0.1818
Fold [4/5] Epoch [10/100] Initial Loss: 0.1388, Training Loss: 0.0150, Initial Validation Loss: 0.1326, Validation Loss: 0.0319,V Acc: 0.8273, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.5455
Fold [4/5] Epoch [20/100] Initial Loss: 0.1388, Training Loss: 0.0050, Initial Validation Loss: 0.1326, Validation Loss: 0.0283,V Acc: 0.8364, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.5758
Fold [4/5] Epoch [30/100] Initial Loss: 0.1388, Training Loss: 0.0041, Initial Validation Loss: 0.1326, Validation Loss: 0.0275,V Acc: 0.8636, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.6061
Fold [4/5] Epoch [40/100] Initial Loss: 0.1388, Training Loss: 0.0038, Initial Validation Loss: 0.1326, Validation Loss: 0.0266,V Acc: 0.8727, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.6364
Fold [4/5] Epoch [50/100] Initial Loss: 0.1388, Training Loss: 0.0037, Initial Validation Loss: 0.1326, Validation Loss: 0.0261,V Acc: 0.8727, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.6364
Stopping early at Epoch (base 0): 54  Rolling back to Epoch (base 0): 49  Top Validation Acc: 0.974025974025974
Fold [5/5] Epoch [0/100] Initial Loss: 0.1362, Training Loss: 0.1362, Initial Validation Loss: 0.1320, Validation Loss: 0.1320,V Acc: 0.3241, Top 70th Acc: 0.4079, Bottom 30th Acc: 0.1250
Fold [5/5] Epoch [10/100] Initial Loss: 0.1362, Training Loss: 0.0152, Initial Validation Loss: 0.1320, Validation Loss: 0.0367,V Acc: 0.8333, Top 70th Acc: 0.9474, Bottom 30th Acc: 0.5625
Fold [5/5] Epoch [20/100] Initial Loss: 0.1362, Training Loss: 0.0053, Initial Validation Loss: 0.1320, Validation Loss: 0.0335,V Acc: 0.8519, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.5938
Fold [5/5] Epoch [30/100] Initial Loss: 0.1362, Training Loss: 0.0043, Initial Validation Loss: 0.1320, Validation Loss: 0.0335,V Acc: 0.8426, Top 70th Acc: 0.9605, Bottom 30th Acc: 0.5625
Stopping early at Epoch (base 0): 32  Rolling back to Epoch (base 0): 27  Top Validation Acc: 0.9605263157894737
99 4 [array([0.38002136, 0.12769228, 0.10515245, 0.24521309, 0.1419208 ],
      dtype=float32)]
Running train_nn.py with seed 100
CUDA:False
Training samples count:  550
Training on 163 features
Fold [1/5] Epoch [0/100] Initial Loss: 0.1368, Training Loss: 0.1368, Initial Validation Loss: 0.1370, Validation Loss: 0.1370,V Acc: 0.3153, Top 70th Acc: 0.3846, Bottom 30th Acc: 0.1515
Fold [1/5] Epoch [10/100] Initial Loss: 0.1368, Training Loss: 0.0172, Initial Validation Loss: 0.1370, Validation Loss: 0.0333,V Acc: 0.8378, Top 70th Acc: 0.9744, Bottom 30th Acc: 0.5152
Fold [1/5] Epoch [20/100] Initial Loss: 0.1368, Training Loss: 0.0054, Initial Validation Loss: 0.1370, Validation Loss: 0.0251,V Acc: 0.9009, Top 70th Acc: 0.9872, Bottom 30th Acc: 0.6970
Stopping early at Epoch (base 0): 27  Rolling back to Epoch (base 0): 22  Top Validation Acc: 0.9871794871794872
Fold [2/5] Epoch [0/100] Initial Loss: 0.1419, Training Loss: 0.1419, Initial Validation Loss: 0.1374, Validation Loss: 0.1374,V Acc: 0.2883, Top 70th Acc: 0.3590, Bottom 30th Acc: 0.1212
Fold [2/5] Epoch [10/100] Initial Loss: 0.1419, Training Loss: 0.0162, Initial Validation Loss: 0.1374, Validation Loss: 0.0351,V Acc: 0.8468, Top 70th Acc: 0.9359, Bottom 30th Acc: 0.6364
Fold [2/5] Epoch [20/100] Initial Loss: 0.1419, Training Loss: 0.0045, Initial Validation Loss: 0.1374, Validation Loss: 0.0289,V Acc: 0.8739, Top 70th Acc: 0.9615, Bottom 30th Acc: 0.6667
Stopping early at Epoch (base 0): 22  Rolling back to Epoch (base 0): 17  Top Validation Acc: 0.9615384615384616
Fold [3/5] Epoch [0/100] Initial Loss: 0.1403, Training Loss: 0.1403, Initial Validation Loss: 0.1264, Validation Loss: 0.1264,V Acc: 0.2636, Top 70th Acc: 0.3377, Bottom 30th Acc: 0.0909
Fold [3/5] Epoch [10/100] Initial Loss: 0.1403, Training Loss: 0.0140, Initial Validation Loss: 0.1264, Validation Loss: 0.0404,V Acc: 0.7455, Top 70th Acc: 0.8831, Bottom 30th Acc: 0.4242
Stopping early at Epoch (base 0): 17  Rolling back to Epoch (base 0): 12  Top Validation Acc: 0.8571428571428571
100 2 [array([0.18859667, 0.03621595, 0.04294366, 0.251031  , 0.48121268],
      dtype=float32)]
Fold [4/5] Epoch [0/100] Initial Loss: 0.1379, Training Loss: 0.1379, Initial Validation Loss: 0.1369, Validation Loss: 0.1369,V Acc: 0.3818, Top 70th Acc: 0.4026, Bottom 30th Acc: 0.3333
Fold [4/5] Epoch [10/100] Initial Loss: 0.1379, Training Loss: 0.0236, Initial Validation Loss: 0.1369, Validation Loss: 0.0474,V Acc: 0.8000, Top 70th Acc: 0.9091, Bottom 30th Acc: 0.5455
Fold [4/5] Epoch [20/100] Initial Loss: 0.1379, Training Loss: 0.0070, Initial Validation Loss: 0.1369, Validation Loss: 0.0439,V Acc: 0.8000, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.5152
Fold [4/5] Epoch [30/100] Initial Loss: 0.1379, Training Loss: 0.0050, Initial Validation Loss: 0.1369, Validation Loss: 0.0418,V Acc: 0.8273, Top 70th Acc: 0.9221, Bottom 30th Acc: 0.6061
Fold [4/5] Epoch [40/100] Initial Loss: 0.1379, Training Loss: 0.0044, Initial Validation Loss: 0.1369, Validation Loss: 0.0401,V Acc: 0.8364, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.6061
Fold [4/5] Epoch [50/100] Initial Loss: 0.1379, Training Loss: 0.0040, Initial Validation Loss: 0.1369, Validation Loss: 0.0386,V Acc: 0.8364, Top 70th Acc: 0.9351, Bottom 30th Acc: 0.6061/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/twood/DLBCL-Classifier/src_python/nn.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(x)
/home/twood/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)

Fold [4/5] Epoch [60/100] Initial Loss: 0.1379, Training Loss: 0.0038, Initial Validation Loss: 0.1369, Validation Loss: 0.0368,V Acc: 0.8364, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.5758
Fold [4/5] Epoch [70/100] Initial Loss: 0.1379, Training Loss: 0.0037, Initial Validation Loss: 0.1369, Validation Loss: 0.0352,V Acc: 0.8364, Top 70th Acc: 0.9481, Bottom 30th Acc: 0.5758
Fold [4/5] Epoch [80/100] Initial Loss: 0.1379, Training Loss: 0.0036, Initial Validation Loss: 0.1369, Validation Loss: 0.0347,V Acc: 0.8273, Top 70th Acc: 0.9740, Bottom 30th Acc: 0.4848
Fold [4/5] Epoch [90/100] Initial Loss: 0.1379, Training Loss: 0.0035, Initial Validation Loss: 0.1369, Validation Loss: 0.0339,V Acc: 0.8364, Top 70th Acc: 0.9610, Bottom 30th Acc: 0.5455
Fold [5/5] Epoch [0/100] Initial Loss: 0.1379, Training Loss: 0.1379, Initial Validation Loss: 0.1315, Validation Loss: 0.1315,V Acc: 0.2407, Top 70th Acc: 0.3158, Bottom 30th Acc: 0.0625
Fold [5/5] Epoch [10/100] Initial Loss: 0.1379, Training Loss: 0.0110, Initial Validation Loss: 0.1315, Validation Loss: 0.0310,V Acc: 0.8333, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.5938
Fold [5/5] Epoch [20/100] Initial Loss: 0.1379, Training Loss: 0.0042, Initial Validation Loss: 0.1315, Validation Loss: 0.0289,V Acc: 0.8426, Top 70th Acc: 0.9342, Bottom 30th Acc: 0.6250
Stopping early at Epoch (base 0): 21  Rolling back to Epoch (base 0): 16  Top Validation Acc: 0.9342105263157895
