dev.off()
dev.off()
dev.off()
dev.off()
rm(list = ls())
source("src_R/load_libraries.R")
nm_gsm_features = read.csv('data_tables/NM_supp_cnmf/c)ConsClust. - Marker Selection-Table 1.tsv', sep='\t', header = 2, skip=1)
nm_c1_sig = nm_gsm_features[(nm_gsm_features$Cluster == 1) & (nm_gsm_features$fisher_q_withinCluster < 0.10), 'Alteration']
nm_c2_sig = nm_gsm_features[(nm_gsm_features$Cluster == 2) & (nm_gsm_features$fisher_q_withinCluster < 0.10), 'Alteration']
nm_c3_sig = nm_gsm_features[(nm_gsm_features$Cluster == 3) & (nm_gsm_features$fisher_q_withinCluster < 0.10), 'Alteration']
nm_c4_sig = nm_gsm_features[(nm_gsm_features$Cluster == 4) & (nm_gsm_features$fisher_q_withinCluster < 0.10), 'Alteration']
nm_c5_sig = nm_gsm_features[(nm_gsm_features$Cluster == 5) & (nm_gsm_features$fisher_q_withinCluster < 0.10), 'Alteration']
nm_c1_sig = toupper(make.names(nm_c1_sig))
nm_c2_sig = toupper(make.names(nm_c2_sig))
nm_c3_sig = toupper(make.names(nm_c3_sig))
nm_c4_sig = toupper(make.names(nm_c4_sig))
nm_c5_sig = toupper(make.names(nm_c5_sig))
new_qval_df =  read.csv('data_tables/qval_dfs/fisher_exact_5x2.Sep_23_2022.combined.tsv',
sep='\t', row.names=1)
new_qval_df$gene = rownames(new_qval_df)
new_c1_sig = new_qval_df[((new_qval_df$C1_nf >= 0.30) & (new_qval_df$q < 0.10)) |
((new_qval_df$q < 0.10) & (new_qval_df$cluster == 'C1')), 'gene']
new_c2_sig = new_qval_df[((new_qval_df$C2_nf >= 0.30) & (new_qval_df$q < 0.10)) |
((new_qval_df$q < 0.10) & (new_qval_df$cluster == 'C2')), 'gene']
new_c3_sig = new_qval_df[((new_qval_df$C3_nf >= 0.30) & (new_qval_df$q < 0.10)) |
((new_qval_df$q < 0.10) & (new_qval_df$cluster == 'C3')), 'gene']
new_c4_sig = new_qval_df[((new_qval_df$C4_nf >= 0.30) & (new_qval_df$q < 0.10)) |
((new_qval_df$q < 0.10) & (new_qval_df$cluster == 'C4')), 'gene']
new_c5_sig = new_qval_df[((new_qval_df$C5_nf >= 0.30) & (new_qval_df$q < 0.10)) |
((new_qval_df$q < 0.10) & (new_qval_df$cluster == 'C5')), 'gene']
# Manually add in a couple edge cases/exceptions
new_c2_sig = c(new_c2_sig, 'X10Q23.31.DEL')
new_c3_sig = c(new_c3_sig, 'X12P.AMP')
pdf("./plots/paper_figures/c1_venn.pdf", height = 11, width = 8.5, paper = "letter")
grid.newpage()
v = venn.diagram(
x = list(nm_c1_sig, new_c1_sig),
category.names = c("C1 NM" , "C1 New"),
scaled=FALSE,
disable.logging = TRUE,
filename=NULL,
cat.pos = c(60, -60),
cat.dist = c(0.35, 0.35),
margin=0.1
)
v
nm_c1_sig
new_c1_sig
grid.draw(v)
grid
source("~/Desktop/DLBCL-Classifier/src_R/plot_feature_venns.R")
source("~/Desktop/DLBCL-Classifier/src_R/plot_feature_venns.R")
dev.off()
source("~/Desktop/DLBCL-Classifier/src_R/plot_feature_venns.R")
source("~/Desktop/DLBCL-Classifier/src_R/plot_sensitivity_specificity_experiment.R")
source("~/Desktop/DLBCL-Classifier/src_R/plot_sensitivity_specificity_experiments_testset.R")
source("~/Desktop/DLBCL-Classifier/src_R/plot_ccf_experiment_testset.R")
source("~/Desktop/DLBCL-Classifier/src_R/plot_ccf_experiment.R")
source("~/Desktop/DLBCL-Classifier/src_R/plot_cluster_alluvials.R")
source("~/Desktop/DLBCL-Classifier/src_R/plot_puritysim_experiment.R")
p.adjust(c(0.00409172, 0.00674363, 0.02076256, 0.02348755, 0.02452045,
0.02841746, 0.02860407, 0.04427513, 0.05938394, 0.06438087,
0.06485877, 0.0813463 , 0.08319648, 0.08436258, 0.08704282,
0.09016976, 0.09886818, 0.10085342, 0.1036364 , 0.10464147,
0.10464147, 0.14524779, 0.15278945, 0.18558772, 0.18660935,
0.18778736, 0.21168101, 0.21883289, 0.22657382, 0.24624226,
0.2508724 , 0.26160072, 0.28303598, 0.29771014, 0.30252673,
0.30252673, 0.31597376, 0.32575158, 0.32575158, 0.33125997,
0.34064884, 0.34064884, 0.34064884, 0.34399022, 0.35672316,
0.35763121, 0.36182598, 0.36870634, 0.36870634, 0.36870634,
0.37290635, 0.37815137, 0.40347962, 0.40682563, 0.40705138,
0.41788898, 0.41788898, 0.41788898, 0.44482471, 0.44482471,
0.44482471, 0.46216345, 0.47008547, 0.47008547, 0.47008547,
0.47205149, 0.48283741, 0.49749484, 0.49749484, 0.49749484,
0.49749484, 0.49749484, 0.49749484, 0.49749484, 0.49780507,
0.49780507, 0.49780507, 0.50140997, 0.54424342, 0.54775647,
0.56982159, 0.60018068, 0.60018068, 0.60018068, 0.60882578,
0.6212238 , 0.66479982, 0.66479982, 0.68275698, 0.69832222,
0.70490683, 0.70490683, 0.70490683, 0.70490683, 0.72100282,
0.73277701, 0.73277701, 0.74762273, 0.7535194 , 0.7535194 ,
0.75760015, 0.76968569, 0.79346662, 0.80252488, 0.80296715,
0.80296715, 0.82027569, 0.82803647, 0.82880075, 0.84238167,
0.84584701, 1.        , 1.        , 1.        , 1.        ,
1.        , 1.        , 1.        , 1.        , 1.        ,
1.        , 1.        , 1.        , 1.        , 1.        ,
1.        , 1.        , 1.        , 1.        , 1.        ,
1.        , 1.        , 1.        , 1.        , 1.        ,
1.        , 1.        , 1.        , 1.        , 1.        ,
1.        , 1.        , 1.        , 1.        , 1.        ,
1.        , 1.        , 1.        , 1.        , 1.        ,
1.        , 1.        , 1.        , 1.        , 1.        ,
1.        , 1.        , 1.        , 1.        , 1.        ,
1.        , 1.        , 1.        , 1.        , 1.        ,
1.        , 1.        ))
?p.adjust
p.adjust(c(0.00409172, 0.00674363, 0.02076256, 0.02348755, 0.02452045,
0.02841746, 0.02860407, 0.04427513, 0.05938394, 0.06438087,
0.06485877, 0.0813463 , 0.08319648, 0.08436258, 0.08704282,
0.09016976, 0.09886818, 0.10085342, 0.1036364 , 0.10464147,
0.10464147, 0.14524779, 0.15278945, 0.18558772, 0.18660935,
0.18778736, 0.21168101, 0.21883289, 0.22657382, 0.24624226,
0.2508724 , 0.26160072, 0.28303598, 0.29771014, 0.30252673,
0.30252673, 0.31597376, 0.32575158, 0.32575158, 0.33125997,
0.34064884, 0.34064884, 0.34064884, 0.34399022, 0.35672316,
0.35763121, 0.36182598, 0.36870634, 0.36870634, 0.36870634,
0.37290635, 0.37815137, 0.40347962, 0.40682563, 0.40705138,
0.41788898, 0.41788898, 0.41788898, 0.44482471, 0.44482471,
0.44482471, 0.46216345, 0.47008547, 0.47008547, 0.47008547,
0.47205149, 0.48283741, 0.49749484, 0.49749484, 0.49749484,
0.49749484, 0.49749484, 0.49749484, 0.49749484, 0.49780507,
0.49780507, 0.49780507, 0.50140997, 0.54424342, 0.54775647,
0.56982159, 0.60018068, 0.60018068, 0.60018068, 0.60882578,
0.6212238 , 0.66479982, 0.66479982, 0.68275698, 0.69832222,
0.70490683, 0.70490683, 0.70490683, 0.70490683, 0.72100282,
0.73277701, 0.73277701, 0.74762273, 0.7535194 , 0.7535194 ,
0.75760015, 0.76968569, 0.79346662, 0.80252488, 0.80296715,
0.80296715, 0.82027569, 0.82803647, 0.82880075, 0.84238167,
0.84584701, 1.        , 1.        , 1.        , 1.        ,
1.        , 1.        , 1.        , 1.        , 1.        ,
1.        , 1.        , 1.        , 1.        , 1.        ,
1.        , 1.        , 1.        , 1.        , 1.        ,
1.        , 1.        , 1.        , 1.        , 1.        ,
1.        , 1.        , 1.        , 1.        , 1.        ,
1.        , 1.        , 1.        , 1.        , 1.        ,
1.        , 1.        , 1.        , 1.        , 1.        ,
1.        , 1.        , 1.        , 1.        , 1.        ,
1.        , 1.        , 1.        , 1.        , 1.        ,
1.        , 1.        , 1.        , 1.        , 1.        ,
1.        , 1.        ), method='BH')
source("~/Desktop/DLBCL-Classifier/src_R/plot_step1.R")
source("~/Desktop/DLBCL-Classifier/src_R/plot_step1.R")
rm(list = ls())
source('src_R/load_libraries.R')
performancetable = read.csv('evaluation_validation_set/allmodelsevaluated.tsv', sep='\t')
source("~/Desktop/DLBCL-Classifier/src_R/plot_step1.R")
source("~/Desktop/DLBCL-Classifier/src_R/plot_step2A.R")
source("~/Desktop/DLBCL-Classifier/src_R/plot_step1.R")
source("~/Desktop/DLBCL-Classifier/src_R/plot_step2A.R")
source("~/Desktop/DLBCL-Classifier/src_R/plot_step1.R")
source("~/Desktop/DLBCL-Classifier/src_R/plot_step2A.R")
source("~/Desktop/DLBCL-Classifier/src_R/plot_step2B.R")
rm(list = ls())
source('src_R/load_libraries.R')
performancetable = read.csv('evaluation_validation_set/allmodelsevaluated.tsv', sep='\t')
View(performancetable)
source("~/Desktop/DLBCL-Classifier/src_R/plot_step2C.R")
source("~/Desktop/DLBCL-Classifier/src_R/plot_step2C.R")
source("~/Desktop/DLBCL-Classifier/src_R/plot_step2C.R")
source("~/Desktop/DLBCL-Classifier/src_R/plot_step1.R")
source("~/Desktop/DLBCL-Classifier/src_R/plot_step2A.R")
source("~/Desktop/DLBCL-Classifier/src_R/plot_step2B.R")
source("~/Desktop/DLBCL-Classifier/src_R/plot_step2C.R")
rm(list = ls())
source('src_R/load_libraries.R')
performancetable = read.csv('evaluation_test_set/test_set_metric_evaluations.tsv', sep='\t', row.names=1)
View(performancetable)
source("~/Desktop/DLBCL-Classifier/src_R/plot_step2B_testset.R")
rm(list = ls())
source('src_R/load_libraries.R')
performancetable = read.csv('evaluation_test_set/test_set_metric_evaluations.tsv', sep='\t', row.names=1)
View(performancetable)
source("~/Desktop/DLBCL-Classifier/src_R/plot_step2C_testset.R")
View(current_table)
View(performancetable)
source("~/Desktop/DLBCL-Classifier/src_R/plot_step2C_testset.R")
source("~/Desktop/DLBCL-Classifier/src_R/plot_sensitivity_specificity_experiment.R")
rm(list = ls())
source("src_R/load_libraries.R")
resultsDropout = read.csv('random_dropout_experiment/resultstable_random_dropout.txt', sep='\t')
rm(list = ls())
source("src_R/load_libraries.R")
resultsDropout = read.csv('random_dropout_experiment/resultstable_random_dropout.txt', sep='\t')
resultsAddIn = read.csv('random_add_in_experiment/resultstable_random_add_in.txt', sep='\t')
source("~/Desktop/DLBCL-Classifier/src_R/plot_sensitivity_specificity_experiment.R")
source("~/Desktop/DLBCL-Classifier/src_R/plot_sensitivity_specificity_experiments_testset.R")
rm(list = ls())
source("src_R/load_libraries.R")
resultsDropout = read.csv('random_dropout_experiment/resultstable_random_dropout_testset.txt', sep='\t')
View(resultsDropout)
resultsAddIn = read.csv('random_add_in_experiment/resultstable_random_add_in_testset.txt', sep='\t')
View(resultsAddIn)
rm(list = ls())
source("src_R/load_libraries.R")
resultsDropout = read.csv('random_dropout_experiment/resultstable_random_dropout.txt', sep='\t')
resultsAddIn = read.csv('random_add_in_experiment/resultstable_random_add_in.txt', sep='\t')
View(resultsAddIn)
View(resultsDropout)
source("~/Desktop/DLBCL-Classifier/src_R/plot_sensitivity_specificity_experiments_testset.R")
rm(list = ls())
source("src_R/load_libraries.R")
resultsDropout = read.csv('random_dropout_experiment/resultstable_random_dropout_testset.txt', sep='\t')
resultsAddIn = read.csv('random_add_in_experiment/resultstable_random_add_in_testset.txt', sep='\t')
dropout_label = 'Sensitivity: TP / (TP + FN)'
add_in_label = 'False Positive Rate : FP / (FP + TN)'
newDF = data.frame(resultsDropout$dropout_probability,
resultsDropout$mut_count_total / (resultsDropout$mut_count_total + resultsDropout$mut_count_dropped),
resultsDropout$amp_count_total / (resultsDropout$amp_count_total + resultsDropout$amp_count_dropped),
resultsDropout$del_count_total / (resultsDropout$del_count_total + resultsDropout$del_count_dropped),
resultsDropout$sv_count_total / (resultsDropout$sv_count_total + resultsDropout$sv_count_dropped))
colnames(newDF) = c('dropout_probability', 'perc_mut', 'perc_amp', 'perc_del', 'perc_sv')
melted_df = melt(newDF, id = 'dropout_probability')
melted_df$MarkerType = 'Mutation'
melted_df[melted_df$variable == 'perc_amp', 'MarkerType'] = 'Amp'
melted_df[melted_df$variable == 'perc_del', 'MarkerType'] = 'Del'
melted_df[melted_df$variable == 'perc_sv', 'MarkerType'] = 'SV'
resultsDropout_2 = resultsDropout[, c('dropout_probability', 'accuracyAll',	'Kappa', 'Performance',
'lowerAccuracy',	'upperAccuracy',	'lowerKappa',	'upperKappa',
'lowerPerformance',	'upperPerformance')]
resultsDropout_2 = rbind(resultsDropout_2)
p = ggplot(resultsDropout_2, aes(x=1-dropout_probability, y=Performance)) +
geom_point() +
theme_bw() +
geom_errorbar(aes(ymax = resultsDropout_2$upperPerformance, ymin = resultsDropout_2$lowerPerformance), width=0.01) +
labs(x=dropout_label, y='Performance') +
theme(axis.title.x = element_text(size=22),
axis.title.y = element_text(size=22),
axis.text.x = element_text(size=18),
axis.text.y = element_text(size=18)) +
ylim(c(0, 1)) +
ggtitle('Dropout') +
scale_x_reverse(expand = c(0.01, 0), limits=c(0,1), breaks=seq(0, 1, 0.1))
p2 = ggplot(data=melted_df, aes(x=dropout_probability, y=value, color=MarkerType)) +
geom_point() +
geom_line() +
theme_bw() +
theme(axis.text.x = element_blank(),
axis.text.y = element_text(size=10),
axis.title.x = element_blank(),
axis.title.y = element_text(size=11),
legend.position = c(0.2, 0.3),
legend.title = element_text(size = 7),
legend.text = element_text(size = 7),
legend.key.size = unit(3, 'mm'),
panel.grid.minor.y = element_blank()) +
labs(y = 'Relative Saturation') +
scale_x_continuous(expand = c(0.01, 0), limits = c(0, 1), breaks=seq(0, 1, 0.1)) +
scale_y_continuous(limits = c(0, 1), breaks=seq(0, 1, 0.2)) +
scale_color_manual(breaks = c('Mutation', 'Amp', 'Del', 'SV'),
values = c('#000000', '#fa2f4e', '#21f4ff', '#00b05e'))
p2
p
resultsDropout_2
p = ggplot(resultsDropout_2, aes(x=1-dropout_probability, y=Performance)) +
geom_point() +
theme_bw() +
geom_errorbar(aes(ymax = resultsDropout_2$upperPerformance, ymin = resultsDropout_2$lowerPerformance), width=0.01) +
labs(x=dropout_label, y='Performance') +
theme(axis.title.x = element_text(size=22),
axis.title.y = element_text(size=22),
axis.text.x = element_text(size=18),
axis.text.y = element_text(size=18)) +
ylim(c(0, 1)) +
ggtitle('Dropout') +
scale_x_reverse(expand = c(0.01, 0), limits=c(0,1), breaks=seq(0, 1, 0.1))
p
resultsDropout_2$Performance
1-resultsDropout_2$dropout_probability
p = ggplot(resultsDropout_2, aes(x=1-dropout_probability, y=Performance)) +
geom_point()
p
resultsDropout_2$upperPerformance
p = ggplot(resultsDropout_2, aes(x=1-dropout_probability, y=Performance)) +
geom_point() +
theme_bw() +
geom_errorbar(aes(ymax = resultsDropout_2$upperPerformance, ymin = resultsDropout_2$lowerPerformance), width=0.01)
p
p = ggplot(resultsDropout_2, aes(x=1-dropout_probability, y=Performance)) +
geom_point() +
theme_bw() +
geom_errorbar(aes(ymax = resultsDropout_2$upperPerformance, ymin = resultsDropout_2$lowerPerformance), width=0.01) +
labs(x=dropout_label, y='Performance') +
theme(axis.title.x = element_text(size=22),
axis.title.y = element_text(size=22),
axis.text.x = element_text(size=18),
axis.text.y = element_text(size=18)) +
ylim(c(0, 1)) +
ggtitle('Dropout')
p
p = ggplot(resultsDropout_2, aes(x=1-dropout_probability, y=Performance)) +
geom_point() +
theme_bw() +
geom_errorbar(aes(ymax = resultsDropout_2$upperPerformance, ymin = resultsDropout_2$lowerPerformance), width=0.01) +
labs(x=dropout_label, y='Performance') +
theme(axis.title.x = element_text(size=22),
axis.title.y = element_text(size=22),
axis.text.x = element_text(size=18),
axis.text.y = element_text(size=18)) +
ylim(c(0, 1)) +
ggtitle('Dropout')
p
p = ggplot(resultsDropout_2, aes(x=1-dropout_probability, y=Performance)) +
geom_point() +
theme_bw() +
geom_errorbar(aes(ymax = resultsDropout_2$upperPerformance, ymin = resultsDropout_2$lowerPerformance), width=0.01) +
labs(x=dropout_label, y='Performance') +
theme(axis.title.x = element_text(size=22),
axis.title.y = element_text(size=22),
axis.text.x = element_text(size=18),
axis.text.y = element_text(size=18)) +
ylim(c(0, 1)) +
ggtitle('Dropout') +
scale_x_reverse(expand = c(0.01, 0), limits=c(0,1), breaks=seq(0, 1, 0.1))
p
p = ggplot(resultsDropout_2, aes(x=1-dropout_probability, y=Performance)) +
p = ggplot(resultsDropout_2, aes(x=1-dropout_probability, y=Performance)) +
geom_point() +
theme_bw() +
geom_errorbar(aes(ymax = resultsDropout_2$upperPerformance, ymin = resultsDropout_2$lowerPerformance), width=0.01) +
labs(x=dropout_label, y='Performance') +
theme(axis.title.x = element_text(size=22),
axis.title.y = element_text(size=22),
axis.text.x = element_text(size=18),
axis.text.y = element_text(size=18)) +
ylim(c(0, 1)) +
ggtitle('Dropout') +
#scale_x_reverse(expand = c(0.01, 0), limits=c(0,1), breaks=seq(0, 1, 0.1))
scale_x_reverse(breaks=seq(0, 1, 0.1))
p = ggplot(resultsDropout_2, aes(x=1-dropout_probability, y=Performance)) +
geom_point() +
theme_bw() +
geom_errorbar(aes(ymax = resultsDropout_2$upperPerformance, ymin = resultsDropout_2$lowerPerformance), width=0.01) +
labs(x=dropout_label, y='Performance') +
theme(axis.title.x = element_text(size=22),
axis.title.y = element_text(size=22),
axis.text.x = element_text(size=18),
axis.text.y = element_text(size=18)) +
ylim(c(0, 1)) +
ggtitle('Dropout') +
scale_x_reverse(breaks=seq(0, 1, 0.1))
p
resultsDropout_2
source("~/Desktop/DLBCL-Classifier/src_R/plot_sensitivity_specificity_experiments_testset.R")
p = ggplot(resultsDropout_2, aes(x=1-dropout_probability, y=Performance)) +
geom_point() +
theme_bw() +
geom_errorbar(aes(ymax = resultsDropout_2$upperPerformance, ymin = resultsDropout_2$lowerPerformance), width=0.01) +
labs(x=dropout_label, y='Performance') +
theme(axis.title.x = element_text(size=22),
axis.title.y = element_text(size=22),
axis.text.x = element_text(size=18),
axis.text.y = element_text(size=18)) +
ylim(c(0, 1)) +
ggtitle('Dropout') +
scale_x_reverse(breaks=seq(0, 1, 0.1), expand = c(0.01, 0))
p
source("~/Desktop/DLBCL-Classifier/src_R/plot_sensitivity_specificity_experiments_testset.R")
p = ggplot(resultsDropout_2, aes(x=1-dropout_probability, y=Performance)) +
geom_point() +
theme_bw() +
geom_errorbar(aes(ymax = resultsDropout_2$upperPerformance, ymin = resultsDropout_2$lowerPerformance), width=0.01) +
labs(x=dropout_label, y='Performance') +
theme(axis.title.x = element_text(size=22),
axis.title.y = element_text(size=22),
axis.text.x = element_text(size=18),
axis.text.y = element_text(size=18)) +
ylim(c(0, 1)) +
ggtitle('Dropout') +
scale_x_reverse(breaks=seq(0, 1, 0.1), expand = c(0.01, 0), limits=c(1, 0))
p
source("~/Desktop/DLBCL-Classifier/src_R/plot_sensitivity_specificity_experiments_testset.R")
source("~/Desktop/DLBCL-Classifier/src_R/plot_sensitivity_specificity_experiment.R")
source("~/Desktop/DLBCL-Classifier/src_R/plot_ccf_experiment.R")
source("~/Desktop/DLBCL-Classifier/src_R/plot_ccf_experiment_testset.R")
source("~/Desktop/DLBCL-Classifier/src_R/plot_accuracy_integ.R")
?scale_y_continuous
seq(0,1,0.1)
p_train = ggplot(plot_df_train, aes(x=ConfidenceCutoff)) +
geom_line(aes(y=TotalAccuracy * 550, color='red')) +
geom_line(aes(y=Samples)) +
scale_y_continuous(name = 'Samples Above Threshold', sec.axis = sec_axis(~./550, name = 'Accuracy of Samples Above Threshold'),
breaks=c(0,500,100)) +
theme_bw() +
theme(axis.title.y.right = element_text(color = "red", size=18),
axis.text.y.right = element_text(color = "red"),
axis.ticks.y.right = element_line(color = "red"),
axis.title.y.left = element_text(size=18),
axis.title.x = element_text(size=18),
legend.position = "none") +
ggtitle('Train Set')
p_train
p_train = ggplot(plot_df_train, aes(x=ConfidenceCutoff)) +
geom_line(aes(y=TotalAccuracy * 550, color='red')) +
geom_line(aes(y=Samples)) +
scale_y_continuous(name = 'Samples Above Threshold', sec.axis = sec_axis(~./550, name = 'Accuracy of Samples Above Threshold'),
breaks=seq(0,500,100)) +
theme_bw() +
theme(axis.title.y.right = element_text(color = "red", size=18),
axis.text.y.right = element_text(color = "red"),
axis.ticks.y.right = element_line(color = "red"),
axis.title.y.left = element_text(size=18),
axis.title.x = element_text(size=18),
legend.position = "none") +
ggtitle('Train Set')
p_train
p_train = ggplot(plot_df_train, aes(x=ConfidenceCutoff)) +
geom_line(aes(y=TotalAccuracy * 550, color='red')) +
geom_line(aes(y=Samples)) +
scale_y_continuous(name = 'Samples Above Threshold', sec.axis = sec_axis(~./550, name = 'Accuracy of Samples Above Threshold'),
breaks=seq(0,600,100)) +
theme_bw() +
theme(axis.title.y.right = element_text(color = "red", size=18),
axis.text.y.right = element_text(color = "red"),
axis.ticks.y.right = element_line(color = "red"),
axis.title.y.left = element_text(size=18),
axis.title.x = element_text(size=18),
legend.position = "none") +
ggtitle('Train Set')
p_train
p_train = ggplot(plot_df_train, aes(x=ConfidenceCutoff)) +
geom_line(aes(y=TotalAccuracy * 550, color='red')) +
geom_line(aes(y=Samples)) +
scale_y_continuous(name = 'Samples Above Threshold', sec.axis = sec_axis(~./550, name = 'Accuracy of Samples Above Threshold'),
breaks=seq(0,550,50)) +
theme_bw() +
theme(axis.title.y.right = element_text(color = "red", size=18),
axis.text.y.right = element_text(color = "red"),
axis.ticks.y.right = element_line(color = "red"),
axis.title.y.left = element_text(size=18),
axis.title.x = element_text(size=18),
legend.position = "none") +
ggtitle('Train Set')
p_train
p_train = ggplot(plot_df_train, aes(x=ConfidenceCutoff)) +
geom_line(aes(y=TotalAccuracy * 550, color='red')) +
geom_line(aes(y=Samples)) +
scale_y_continuous(name = 'Samples Above Threshold', sec.axis = sec_axis(~./550, name = 'Accuracy of Samples Above Threshold',
breaks=seq(0, 1, 0.1)),
breaks=seq(0,550,50)) +
theme_bw() +
theme(axis.title.y.right = element_text(color = "red", size=18),
axis.text.y.right = element_text(color = "red"),
axis.ticks.y.right = element_line(color = "red"),
axis.title.y.left = element_text(size=18),
axis.title.x = element_text(size=18),
legend.position = "none") +
ggtitle('Train Set')
p_train
p_train = ggplot(plot_df_train, aes(x=ConfidenceCutoff)) +
geom_line(aes(y=TotalAccuracy * 550, color='red')) +
geom_line(aes(y=Samples)) +
scale_y_continuous(name = 'Samples Above Threshold', sec.axis = sec_axis(~./550, name = 'Accuracy of Samples Above Threshold',
breaks=seq(0, 1, 0.25)),
breaks=seq(0,550,50)) +
theme_bw() +
theme(axis.title.y.right = element_text(color = "red", size=18),
axis.text.y.right = element_text(color = "red"),
axis.ticks.y.right = element_line(color = "red"),
axis.title.y.left = element_text(size=18),
axis.title.x = element_text(size=18),
legend.position = "none") +
ggtitle('Train Set')
p_train
p_train = ggplot(plot_df_train, aes(x=ConfidenceCutoff)) +
geom_line(aes(y=TotalAccuracy * 550, color='red')) +
geom_line(aes(y=Samples)) +
scale_y_continuous(name = 'Samples Above Threshold', sec.axis = sec_axis(~./550, name = 'Accuracy of Samples Above Threshold'),
breaks=seq(0,550,50)) +
theme_bw() +
theme(axis.title.y.right = element_text(color = "red", size=18),
axis.text.y.right = element_text(color = "red"),
axis.ticks.y.right = element_line(color = "red"),
axis.title.y.left = element_text(size=18),
axis.title.x = element_text(size=18),
legend.position = "none") +
ggtitle('Train Set')
p_train
450/550
500/550
50/550
550/50
550/10
p_train = ggplot(plot_df_train, aes(x=ConfidenceCutoff)) +
geom_line(aes(y=TotalAccuracy * 550, color='red')) +
geom_line(aes(y=Samples)) +
scale_y_continuous(name = 'Samples Above Threshold', sec.axis = sec_axis(~./550, name = 'Accuracy of Samples Above Threshold',
breaks=seq(0,1,0.1)),
breaks=seq(0,550,55)) +
theme_bw() +
theme(axis.title.y.right = element_text(color = "red", size=18),
axis.text.y.right = element_text(color = "red"),
axis.ticks.y.right = element_line(color = "red"),
axis.title.y.left = element_text(size=18),
axis.title.x = element_text(size=18),
legend.position = "none") +
ggtitle('Train Set')
p_train
p_test = ggplot(plot_df_test, aes(x=ConfidenceCutoff)) +
geom_line(aes(y=TotalAccuracy * 149, color='red')) +
geom_line(aes(y=Samples)) +
scale_y_continuous(name = 'Samples Above Threshold', sec.axis = sec_axis(~./149, name = 'Accuracy of Samples Above Threshold')) +
theme_bw() +
theme(axis.title.y.right = element_text(color = "red", size=18),
axis.text.y.right = element_text(color = "red"),
axis.ticks.y.right = element_line(color = "red"),
axis.title.y.left = element_text(size=18),
axis.title.x = element_text(size=18),
legend.position = "none") +
ggtitle('Test Set')
p_test
source("~/Desktop/DLBCL-Classifier/src_R/plot_accuracy_integ.R")
source("~/Desktop/DLBCL-Classifier/src_R/plot_cluster_alluvials.R")
source("~/Desktop/DLBCL-Classifier/src_R/plot_confidences_gaddygrams.R")
source("~/Desktop/DLBCL-Classifier/src_R/plot_confidences_gaddygrams.R")
source("~/Desktop/DLBCL-Classifier/src_R/plot_puritysim_experiment.R")
source("~/Desktop/DLBCL-Classifier/src_R/plot_training_history.R")
source("~/Desktop/DLBCL-Classifier/src_R/plot_step2C.R")
gsm = read.csv('data_tables/gsm/DLBCL.699.fullGSM.Sep_23_2022.tsv', row.names=1)
gsm
gsm = read.csv('data_tables/gsm/DLBCL.699.fullGSM.Sep_23_2022.tsv', row.names=1, sep='\t')
gsm
rowSums(gsm != 0.0)
sort(rowSums(gsm != 0.0))
