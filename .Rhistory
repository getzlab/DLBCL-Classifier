axis.text.x = element_text(size=18),
axis.text.y = element_text(size=18)) +
ylim(c(0, 1)) +
ggtitle('Dropout') +
scale_x_reverse(expand = c(0.01, 0), limits=c(0,1), breaks=seq(0, 1, 0.1))
p2 = ggplot(data=melted_df, aes(x=dropout_probability, y=value, color=MarkerType)) +
geom_point() +
geom_line() +
theme_bw() +
theme(axis.text.x = element_blank(),
axis.text.y = element_text(size=10),
axis.title.x = element_blank(),
axis.title.y = element_text(size=11),
legend.position = c(0.2, 0.3),
legend.title = element_text(size = 7),
legend.text = element_text(size = 7),
legend.key.size = unit(3, 'mm'),
panel.grid.minor.y = element_blank()) +
labs(y = 'Relative Saturation') +
scale_x_continuous(expand = c(0.01, 0), limits = c(0, 1), breaks=seq(0, 1, 0.1)) +
scale_y_continuous(limits = c(0, 1), breaks=seq(0, 1, 0.2)) +
scale_color_manual(breaks = c('Mutation', 'Amp', 'Del', 'SV'),
values = c('#000000', '#fa2f4e', '#21f4ff', '#00b05e'))
p2
p
resultsDropout_2
p = ggplot(resultsDropout_2, aes(x=1-dropout_probability, y=Performance)) +
geom_point() +
theme_bw() +
geom_errorbar(aes(ymax = resultsDropout_2$upperPerformance, ymin = resultsDropout_2$lowerPerformance), width=0.01) +
labs(x=dropout_label, y='Performance') +
theme(axis.title.x = element_text(size=22),
axis.title.y = element_text(size=22),
axis.text.x = element_text(size=18),
axis.text.y = element_text(size=18)) +
ylim(c(0, 1)) +
ggtitle('Dropout') +
scale_x_reverse(expand = c(0.01, 0), limits=c(0,1), breaks=seq(0, 1, 0.1))
p
resultsDropout_2$Performance
1-resultsDropout_2$dropout_probability
p = ggplot(resultsDropout_2, aes(x=1-dropout_probability, y=Performance)) +
geom_point()
p
resultsDropout_2$upperPerformance
p = ggplot(resultsDropout_2, aes(x=1-dropout_probability, y=Performance)) +
geom_point() +
theme_bw() +
geom_errorbar(aes(ymax = resultsDropout_2$upperPerformance, ymin = resultsDropout_2$lowerPerformance), width=0.01)
p
p = ggplot(resultsDropout_2, aes(x=1-dropout_probability, y=Performance)) +
geom_point() +
theme_bw() +
geom_errorbar(aes(ymax = resultsDropout_2$upperPerformance, ymin = resultsDropout_2$lowerPerformance), width=0.01) +
labs(x=dropout_label, y='Performance') +
theme(axis.title.x = element_text(size=22),
axis.title.y = element_text(size=22),
axis.text.x = element_text(size=18),
axis.text.y = element_text(size=18)) +
ylim(c(0, 1)) +
ggtitle('Dropout')
p
p = ggplot(resultsDropout_2, aes(x=1-dropout_probability, y=Performance)) +
geom_point() +
theme_bw() +
geom_errorbar(aes(ymax = resultsDropout_2$upperPerformance, ymin = resultsDropout_2$lowerPerformance), width=0.01) +
labs(x=dropout_label, y='Performance') +
theme(axis.title.x = element_text(size=22),
axis.title.y = element_text(size=22),
axis.text.x = element_text(size=18),
axis.text.y = element_text(size=18)) +
ylim(c(0, 1)) +
ggtitle('Dropout')
p
p = ggplot(resultsDropout_2, aes(x=1-dropout_probability, y=Performance)) +
geom_point() +
theme_bw() +
geom_errorbar(aes(ymax = resultsDropout_2$upperPerformance, ymin = resultsDropout_2$lowerPerformance), width=0.01) +
labs(x=dropout_label, y='Performance') +
theme(axis.title.x = element_text(size=22),
axis.title.y = element_text(size=22),
axis.text.x = element_text(size=18),
axis.text.y = element_text(size=18)) +
ylim(c(0, 1)) +
ggtitle('Dropout') +
scale_x_reverse(expand = c(0.01, 0), limits=c(0,1), breaks=seq(0, 1, 0.1))
p
p = ggplot(resultsDropout_2, aes(x=1-dropout_probability, y=Performance)) +
p = ggplot(resultsDropout_2, aes(x=1-dropout_probability, y=Performance)) +
geom_point() +
theme_bw() +
geom_errorbar(aes(ymax = resultsDropout_2$upperPerformance, ymin = resultsDropout_2$lowerPerformance), width=0.01) +
labs(x=dropout_label, y='Performance') +
theme(axis.title.x = element_text(size=22),
axis.title.y = element_text(size=22),
axis.text.x = element_text(size=18),
axis.text.y = element_text(size=18)) +
ylim(c(0, 1)) +
ggtitle('Dropout') +
#scale_x_reverse(expand = c(0.01, 0), limits=c(0,1), breaks=seq(0, 1, 0.1))
scale_x_reverse(breaks=seq(0, 1, 0.1))
p = ggplot(resultsDropout_2, aes(x=1-dropout_probability, y=Performance)) +
geom_point() +
theme_bw() +
geom_errorbar(aes(ymax = resultsDropout_2$upperPerformance, ymin = resultsDropout_2$lowerPerformance), width=0.01) +
labs(x=dropout_label, y='Performance') +
theme(axis.title.x = element_text(size=22),
axis.title.y = element_text(size=22),
axis.text.x = element_text(size=18),
axis.text.y = element_text(size=18)) +
ylim(c(0, 1)) +
ggtitle('Dropout') +
scale_x_reverse(breaks=seq(0, 1, 0.1))
p
resultsDropout_2
source("~/Desktop/DLBCL-Classifier/src_R/plot_sensitivity_specificity_experiments_testset.R")
p = ggplot(resultsDropout_2, aes(x=1-dropout_probability, y=Performance)) +
geom_point() +
theme_bw() +
geom_errorbar(aes(ymax = resultsDropout_2$upperPerformance, ymin = resultsDropout_2$lowerPerformance), width=0.01) +
labs(x=dropout_label, y='Performance') +
theme(axis.title.x = element_text(size=22),
axis.title.y = element_text(size=22),
axis.text.x = element_text(size=18),
axis.text.y = element_text(size=18)) +
ylim(c(0, 1)) +
ggtitle('Dropout') +
scale_x_reverse(breaks=seq(0, 1, 0.1), expand = c(0.01, 0))
p
source("~/Desktop/DLBCL-Classifier/src_R/plot_sensitivity_specificity_experiments_testset.R")
p = ggplot(resultsDropout_2, aes(x=1-dropout_probability, y=Performance)) +
geom_point() +
theme_bw() +
geom_errorbar(aes(ymax = resultsDropout_2$upperPerformance, ymin = resultsDropout_2$lowerPerformance), width=0.01) +
labs(x=dropout_label, y='Performance') +
theme(axis.title.x = element_text(size=22),
axis.title.y = element_text(size=22),
axis.text.x = element_text(size=18),
axis.text.y = element_text(size=18)) +
ylim(c(0, 1)) +
ggtitle('Dropout') +
scale_x_reverse(breaks=seq(0, 1, 0.1), expand = c(0.01, 0), limits=c(1, 0))
p
source("~/Desktop/DLBCL-Classifier/src_R/plot_sensitivity_specificity_experiments_testset.R")
source("~/Desktop/DLBCL-Classifier/src_R/plot_sensitivity_specificity_experiment.R")
source("~/Desktop/DLBCL-Classifier/src_R/plot_ccf_experiment.R")
source("~/Desktop/DLBCL-Classifier/src_R/plot_ccf_experiment_testset.R")
source("~/Desktop/DLBCL-Classifier/src_R/plot_accuracy_integ.R")
?scale_y_continuous
seq(0,1,0.1)
p_train = ggplot(plot_df_train, aes(x=ConfidenceCutoff)) +
geom_line(aes(y=TotalAccuracy * 550, color='red')) +
geom_line(aes(y=Samples)) +
scale_y_continuous(name = 'Samples Above Threshold', sec.axis = sec_axis(~./550, name = 'Accuracy of Samples Above Threshold'),
breaks=c(0,500,100)) +
theme_bw() +
theme(axis.title.y.right = element_text(color = "red", size=18),
axis.text.y.right = element_text(color = "red"),
axis.ticks.y.right = element_line(color = "red"),
axis.title.y.left = element_text(size=18),
axis.title.x = element_text(size=18),
legend.position = "none") +
ggtitle('Train Set')
p_train
p_train = ggplot(plot_df_train, aes(x=ConfidenceCutoff)) +
geom_line(aes(y=TotalAccuracy * 550, color='red')) +
geom_line(aes(y=Samples)) +
scale_y_continuous(name = 'Samples Above Threshold', sec.axis = sec_axis(~./550, name = 'Accuracy of Samples Above Threshold'),
breaks=seq(0,500,100)) +
theme_bw() +
theme(axis.title.y.right = element_text(color = "red", size=18),
axis.text.y.right = element_text(color = "red"),
axis.ticks.y.right = element_line(color = "red"),
axis.title.y.left = element_text(size=18),
axis.title.x = element_text(size=18),
legend.position = "none") +
ggtitle('Train Set')
p_train
p_train = ggplot(plot_df_train, aes(x=ConfidenceCutoff)) +
geom_line(aes(y=TotalAccuracy * 550, color='red')) +
geom_line(aes(y=Samples)) +
scale_y_continuous(name = 'Samples Above Threshold', sec.axis = sec_axis(~./550, name = 'Accuracy of Samples Above Threshold'),
breaks=seq(0,600,100)) +
theme_bw() +
theme(axis.title.y.right = element_text(color = "red", size=18),
axis.text.y.right = element_text(color = "red"),
axis.ticks.y.right = element_line(color = "red"),
axis.title.y.left = element_text(size=18),
axis.title.x = element_text(size=18),
legend.position = "none") +
ggtitle('Train Set')
p_train
p_train = ggplot(plot_df_train, aes(x=ConfidenceCutoff)) +
geom_line(aes(y=TotalAccuracy * 550, color='red')) +
geom_line(aes(y=Samples)) +
scale_y_continuous(name = 'Samples Above Threshold', sec.axis = sec_axis(~./550, name = 'Accuracy of Samples Above Threshold'),
breaks=seq(0,550,50)) +
theme_bw() +
theme(axis.title.y.right = element_text(color = "red", size=18),
axis.text.y.right = element_text(color = "red"),
axis.ticks.y.right = element_line(color = "red"),
axis.title.y.left = element_text(size=18),
axis.title.x = element_text(size=18),
legend.position = "none") +
ggtitle('Train Set')
p_train
p_train = ggplot(plot_df_train, aes(x=ConfidenceCutoff)) +
geom_line(aes(y=TotalAccuracy * 550, color='red')) +
geom_line(aes(y=Samples)) +
scale_y_continuous(name = 'Samples Above Threshold', sec.axis = sec_axis(~./550, name = 'Accuracy of Samples Above Threshold',
breaks=seq(0, 1, 0.1)),
breaks=seq(0,550,50)) +
theme_bw() +
theme(axis.title.y.right = element_text(color = "red", size=18),
axis.text.y.right = element_text(color = "red"),
axis.ticks.y.right = element_line(color = "red"),
axis.title.y.left = element_text(size=18),
axis.title.x = element_text(size=18),
legend.position = "none") +
ggtitle('Train Set')
p_train
p_train = ggplot(plot_df_train, aes(x=ConfidenceCutoff)) +
geom_line(aes(y=TotalAccuracy * 550, color='red')) +
geom_line(aes(y=Samples)) +
scale_y_continuous(name = 'Samples Above Threshold', sec.axis = sec_axis(~./550, name = 'Accuracy of Samples Above Threshold',
breaks=seq(0, 1, 0.25)),
breaks=seq(0,550,50)) +
theme_bw() +
theme(axis.title.y.right = element_text(color = "red", size=18),
axis.text.y.right = element_text(color = "red"),
axis.ticks.y.right = element_line(color = "red"),
axis.title.y.left = element_text(size=18),
axis.title.x = element_text(size=18),
legend.position = "none") +
ggtitle('Train Set')
p_train
p_train = ggplot(plot_df_train, aes(x=ConfidenceCutoff)) +
geom_line(aes(y=TotalAccuracy * 550, color='red')) +
geom_line(aes(y=Samples)) +
scale_y_continuous(name = 'Samples Above Threshold', sec.axis = sec_axis(~./550, name = 'Accuracy of Samples Above Threshold'),
breaks=seq(0,550,50)) +
theme_bw() +
theme(axis.title.y.right = element_text(color = "red", size=18),
axis.text.y.right = element_text(color = "red"),
axis.ticks.y.right = element_line(color = "red"),
axis.title.y.left = element_text(size=18),
axis.title.x = element_text(size=18),
legend.position = "none") +
ggtitle('Train Set')
p_train
450/550
500/550
50/550
550/50
550/10
p_train = ggplot(plot_df_train, aes(x=ConfidenceCutoff)) +
geom_line(aes(y=TotalAccuracy * 550, color='red')) +
geom_line(aes(y=Samples)) +
scale_y_continuous(name = 'Samples Above Threshold', sec.axis = sec_axis(~./550, name = 'Accuracy of Samples Above Threshold',
breaks=seq(0,1,0.1)),
breaks=seq(0,550,55)) +
theme_bw() +
theme(axis.title.y.right = element_text(color = "red", size=18),
axis.text.y.right = element_text(color = "red"),
axis.ticks.y.right = element_line(color = "red"),
axis.title.y.left = element_text(size=18),
axis.title.x = element_text(size=18),
legend.position = "none") +
ggtitle('Train Set')
p_train
p_test = ggplot(plot_df_test, aes(x=ConfidenceCutoff)) +
geom_line(aes(y=TotalAccuracy * 149, color='red')) +
geom_line(aes(y=Samples)) +
scale_y_continuous(name = 'Samples Above Threshold', sec.axis = sec_axis(~./149, name = 'Accuracy of Samples Above Threshold')) +
theme_bw() +
theme(axis.title.y.right = element_text(color = "red", size=18),
axis.text.y.right = element_text(color = "red"),
axis.ticks.y.right = element_line(color = "red"),
axis.title.y.left = element_text(size=18),
axis.title.x = element_text(size=18),
legend.position = "none") +
ggtitle('Test Set')
p_test
source("~/Desktop/DLBCL-Classifier/src_R/plot_accuracy_integ.R")
source("~/Desktop/DLBCL-Classifier/src_R/plot_cluster_alluvials.R")
source("~/Desktop/DLBCL-Classifier/src_R/plot_confidences_gaddygrams.R")
source("~/Desktop/DLBCL-Classifier/src_R/plot_confidences_gaddygrams.R")
source("~/Desktop/DLBCL-Classifier/src_R/plot_puritysim_experiment.R")
source("~/Desktop/DLBCL-Classifier/src_R/plot_training_history.R")
source("~/Desktop/DLBCL-Classifier/src_R/plot_step2C.R")
gsm = read.csv('data_tables/gsm/DLBCL.699.fullGSM.Sep_23_2022.tsv', row.names=1)
gsm
gsm = read.csv('data_tables/gsm/DLBCL.699.fullGSM.Sep_23_2022.tsv', row.names=1, sep='\t')
gsm
rowSums(gsm != 0.0)
sort(rowSums(gsm != 0.0))
rm(list = ls())
source('src_R/load_libraries.R')
conf_table = read.csv('evaluation_test_set/NN_reducedV3.4_removeN5_nfeatures21_testsetEval.tsv',
sep='\t', row.names=1)
conf_table = conf_table[order(conf_table$PredictedCluster, conf_table$Confidence), ]
cohorts = read.csv('data_tables/sample_sets/ShippStaudtSets.purity0.2.txt', sep='\t', row.names=1)
cohorts = cohorts[rownames(cohorts) %in% rownames(conf_table),]
cohorts = cohorts[rownames(conf_table), ]
conf_table$cohort = cohorts$cohort
group.colors = c("#FF10F0","#000000")
output_fn = 'plots/test_set/confidences_gaddygram_testset'
conf_table$breaks = seq(1,nrow(conf_table))
conf_table
conf_table[conf_table$PredictedCluster == 1,]
conf_table[(conf_table$PredictedCluster == 1) && (conf_table$Confidence > 0.70),]
conf_table[(conf_table$PredictedCluster == 1) & (conf_table$Confidence > 0.70),]
nrow(conf_table[(conf_table$PredictedCluster == 1) & (conf_table$Confidence > 0.70),])
nrow(conf_table)
rm(list = ls())
source('src_R/load_libraries.R')
conf_table = read.csv('evaluation_test_set/NN_reducedV3.4_removeN5_nfeatures21_testsetEval.tsv',
sep='\t', row.names=1)
conf_table = conf_table[order(conf_table$PredictedCluster, conf_table$Confidence), ]
cohorts = read.csv('data_tables/sample_sets/ShippStaudtSets.purity0.2.txt', sep='\t', row.names=1)
cohorts = cohorts[rownames(cohorts) %in% rownames(conf_table),]
cohorts = cohorts[rownames(conf_table), ]
conf_table$cohort = cohorts$cohort
group.colors = c("#FF10F0","#000000")
output_fn = 'plots/test_set/confidences_gaddygram_testset'
nrow(conf_table)
rm(list = ls())
source('src_R/load_libraries.R')
conf_table = read.csv('evaluation_test_set/NN_reducedV3.4_removeN5_nfeatures21_testsetEval.tsv',
sep='\t', row.names=1)
rm(list = ls())
source('src_R/load_libraries.R')
conf_table = read.csv('evaluation_test_set/NN_reducedV3.4_removeN5_nfeatures21_testsetEval.tsv',
sep='\t', row.names=1)
conf_table = conf_table[order(conf_table$PredictedCluster, conf_table$Confidence), ]
cohorts = read.csv('data_tables/sample_sets/ShippStaudtSets.purity0.2.txt', sep='\t', row.names=1)
cohorts = cohorts[rownames(cohorts) %in% rownames(conf_table),]
cohorts = cohorts[rownames(conf_table), ]
conf_table$cohort = cohorts$cohort
group.colors = c("#FF10F0","#000000")
output_fn = 'plots/test_set/confidences_gaddygram_testset'
conf_table$breaks = seq(1,nrow(conf_table))
conf_table_train = read.csv('evaluation_validation_set/confidence_adjusted_tables/NN_reducedV3.4_removeN5_nfeatures21_pMax0.93856484.tsv',
sep='\t', row.names=1)
conf_table_train$Confidence = apply(conf_table_train, 1, max)
conf_table_train$PredictedCluster = apply(conf_table_train[,1:5], 1, which.max)
conf_table_train$PredictedCluster = mapvalues(conf_table_train$PredictedCluster,
from=c(1,2,3,4,5),
to=c('C1', 'C2', 'C3', 'C4', 'C5'))
conf_table_train = conf_table_train[order(conf_table_train$PredictedCluster, conf_table_train$Confidence), ]
labels = read.csv('data_tables/confidence_tables/baseline_probabilities.connectivity_based.sensitivity_power2.Sep_23_2022.tsv',
sep='\t', row.names=1)
labels = labels[rownames(conf_table_train),]
conf_table_train$TrueCluster = labels$cluster
conf_table_train$TrueCluster = mapvalues(conf_table_train$TrueCluster,
from=c(1,2,3,4,5),
to=c('C1', 'C2', 'C3', 'C4', 'C5'))
conf_table_train$Correctness = (conf_table_train$PredictedCluster == conf_table_train$TrueCluster)
conf_table_train$Correctness = mapvalues(conf_table_train$Correctness, from=c(TRUE, FALSE), to=c('True', 'False'))
cohorts = read.csv('data_tables/sample_sets/ShippStaudtSets.purity0.2.txt', sep='\t', row.names=1)
cohorts = cohorts[rownames(cohorts) %in% rownames(conf_table_train),]
cohorts = cohorts[rownames(conf_table_train), ]
conf_table_train$cohort = cohorts$cohort
conf_table_train$cohort = mapvalues(conf_table_train$cohort,
from=c('Shipp', 'Staudt', 'TCGA'),
to=c('Chapuy et al.', 'Schmitz et al.', 'Schmitz et al.'))
group.colors = c("#000000","#E3140F")
conf_table_train$breaks = seq(1,nrow(conf_table_train))
conf_table_all = rbind(conf_table[, c('Confidence', 'PredictedCluster', 'TrueCluster')])
conf_table_all$PredictedCluster = paste('C', conf_table_all$PredictedCluster, sep='')
conf_table_all$TrueCluster = paste('C', conf_table_all$TrueCluster, sep='')
conf_table_all = rbind(conf_table_all, conf_table_train[, c('Confidence', 'PredictedCluster', 'TrueCluster')])
conf_table_all = conf_table_all[order(conf_table_all$PredictedCluster, conf_table_all$Confidence), ]
conf_table_all$Correctness = conf_table_all$PredictedCluster == conf_table_all$TrueCluster
hc_all = conf_table_all[conf_table_all$Confidence > 0.70, ]
acc = sum(hc_all$Correctness) / nrow(hc_all)
conf_table_all
conf_table_all[(conf_table_all$PredictedCluster == 1) & (conf_table_all$Confidence > 0.70), ]
conf_table_all[(conf_table_all$PredictedCluster == 'C1') & (conf_table_all$Confidence > 0.70), ]
nrow(conf_table_all[(conf_table_all$PredictedCluster == 'C1') & (conf_table_all$Confidence > 0.70), ])
nrow(conf_table_all[conf_table_all$PredictedCluster == 'C1', ]) / nrow(conf_table_all[(conf_table_all$PredictedCluster == 'C1') & (conf_table_all$Confidence > 0.70), ])
nrow(conf_table_all[conf_table_all$PredictedCluster == 'C1', ])
nrow(conf_table_all[(conf_table_all$PredictedCluster == 'C1') & (conf_table_all$Confidence > 0.70), ]) / nrow(conf_table_all[conf_table_all$PredictedCluster == 'C1', ])
nrow(conf_table_all[(conf_table_all$PredictedCluster == 'C2') & (conf_table_all$Confidence > 0.70), ]) / nrow(conf_table_all[conf_table_all$PredictedCluster == 'C2', ])
nrow(conf_table_all[(conf_table_all$PredictedCluster == 'C3') & (conf_table_all$Confidence > 0.70), ]) / nrow(conf_table_all[conf_table_all$PredictedCluster == 'C3', ])
nrow(conf_table_all[(conf_table_all$PredictedCluster == 'C4') & (conf_table_all$Confidence > 0.70), ]) / nrow(conf_table_all[conf_table_all$PredictedCluster == 'C4', ])
nrow(conf_table_all[(conf_table_all$PredictedCluster == 'C5') & (conf_table_all$Confidence > 0.70), ]) / nrow(conf_table_all[conf_table_all$PredictedCluster == 'C5', ])
source("~/Desktop/DLBCL-Classifier/src_R/plot_step1.R")
source("~/Desktop/DLBCL-Classifier/src_R/plot_panelperformance.R")
rm(list = ls())
source('src_R/load_libraries.R')
performancetable = read.csv('evaluation_panel_sets/evaluation_panels.tsv', sep='\t')
rownames(performancetable) = performancetable$experiment
performancetable$experiment <-
factor(performancetable$experiment, levels = performancetable$experiment[order(performancetable$performance)])
View(performancetable)
rm(list = ls())
source('src_R/load_libraries.R')
performancetable = read.csv('evaluation_panel_sets/evaluation_panels.tsv', sep='\t', row.names = 1)
rownames(performancetable) = performancetable$experiment
View(performancetable)
rm(list = ls())
source('src_R/load_libraries.R')
performancetable = read.csv('evaluation_panel_sets/evaluation_panels.tsv', sep='\t')
View(performancetable)
rm(list = ls())
source('src_R/load_libraries.R')
performancetable = read.csv('evaluation_panel_sets/evaluation_panels.tsv', sep='\t', row.names=1)
View(performancetable)
rm(list = ls())
source('src_R/load_libraries.R')
performancetable = read.csv('evaluation_panel_sets/evaluation_panels.tsv', sep='\t', row.names=1)
rownames(performancetable) = performancetable$experiment
rm(list = ls())
source('src_R/load_libraries.R')
performancetable = read.csv('evaluation_panel_sets/evaluation_panels.tsv', sep='\t', row.names=1)
current_table = performancetable
current_table$experiment = rownames(current_table)
current_table$experiment <-
factor(current_table$experiment, levels = current_table$experiment[order(current_table$performance)])
current_colors = c("#00BA38","#E3140F","#497DE7")
output_fn = 'plots/combined_performance_panels'
widths = c(1.5,1,1)
p1 = ggplot(data=current_table, aes(x=experiment, y=accuracyAll, color=Model)) +
scale_y_continuous(limit = c((floor(10*min(current_table$performance)) / 10) - 0.1, 1), breaks=seq(0,1,by=.1)) +
geom_point() +
theme(plot.title = element_text(hjust = 0.5),
title = element_text(size=20)) +
xlab("Model") +
ylab("Accuracy") +
theme_bw() +
theme(panel.grid = element_line(colour = "#e8e8e8")) +
geom_errorbar(aes(ymax = current_table$lowerAcc, ymin = current_table$upperAcc), width=0) +
theme(axis.text.x = element_text(colour="grey20",size=10,angle=0,hjust=.5,vjust=.5,face="plain"),
axis.text.y = element_text(colour="grey20",size=10,angle=0,vjust=0,face="plain"),
axis.title.x = element_text(colour="grey20",size=15,angle=0,hjust=.5,vjust=0,face="plain"),
axis.title.y = element_blank(),
legend.position='none') +
scale_colour_manual(values = current_colors) +
coord_flip()
p2 = ggplot(data=current_table, aes(x=experiment, y=Kappa, color=Model)) +
scale_y_continuous(limit = c((floor(10*min(current_table$performance)) / 10) - 0.1, 1), breaks=seq(0,1,by=.1)) +
geom_point() +
theme(plot.title = element_text(hjust = 0.5),
title = element_text(size=20)) +
xlab("Model") +
ylab("K") +
theme_bw() +
theme(panel.grid = element_line(colour = "#e8e8e8")) +
geom_errorbar(aes(ymax = current_table$upperKappa, ymin = current_table$lowerKappa), width=0) +
theme(axis.text.x = element_text(colour="grey20",size=10,angle=0,hjust=.5,vjust=.5,face="plain"),
axis.text.y = element_blank(),
axis.title.x = element_text(colour="grey20",size=15,angle=0,hjust=.5,vjust=0,face="plain"),
axis.title.y = element_blank(),
legend.position = "none") +
scale_colour_manual(values=current_colors) +
coord_flip()
p3 = ggplot(data=current_table, aes(x=experiment, y=performance, color=Model)) +
scale_y_continuous(limit = c((floor(10*min(current_table$performance)) / 10) - 0.1, 1), breaks=seq(0,1,by=.1)) +
geom_point() +
theme(plot.title = element_text(hjust = 0.5),
title = element_text(size=20)) +
xlab("Model") +
ylab("Performance") +
theme_bw() +
theme(panel.grid = element_line(colour = "#e8e8e8")) +
geom_errorbar(aes(ymax = current_table$upperPerformance, ymin = current_table$lowerPerformance), width=0) +
theme(axis.text.x = element_text(colour="grey20",size=10,angle=0,hjust=.5,vjust=.5,face="plain"),
axis.text.y = element_blank(),
axis.title.x = element_text(colour="grey20",size=15,angle=0,hjust=.5,vjust=0,face="plain"),
axis.title.y = element_blank(),
legend.position = c(.26, 0.92),
legend.title = element_text(size=9)) +
scale_colour_manual(values=current_colors) +
geom_hline(yintercept=max(current_table$performance) -
(max(current_table$performance) - max(current_table$lowerPerformance)) * 2, linetype="dashed",
color = "black", size=0.3) +
coord_flip()
p4 = plot_grid(p1,p2,p3, nrow=1, rel_widths = widths)
View(performancetable)
source("~/Desktop/DLBCL-Classifier/src_R/plot_panelperformance.R")
current_table
rm(list = ls())
source('src_R/load_libraries.R')
performancetable = read.csv('evaluation_panel_sets/evaluation_panels.tsv', sep='\t', row.names=1)
current_table = performancetable
current_table$experiment = rownames(current_table)
current_table$experiment <-
factor(current_table$experiment, levels = current_table$experiment[order(current_table$performance)])
current_table$Model = 'Panel'
current_table['dlbclass', 'Model'] = 'DLBclass'
current_table
rm(list = ls())
source('src_R/load_libraries.R')
performancetable = read.csv('evaluation_panel_sets/evaluation_panels.tsv', sep='\t', row.names=1)
current_table = performancetable
current_table$experiment = rownames(current_table)
current_table$experiment <-
factor(current_table$experiment, levels = current_table$experiment[order(current_table$performance)])
current_table$Model = 'Panel'
current_table['dlbclass', 'Model'] = 'DLBclass'
current_table
source("~/Desktop/DLBCL-Classifier/src_R/plot_panelperformance.R")
source("~/Desktop/DLBCL-Classifier/src_R/plot_panelperformance.R")
source("~/Desktop/DLBCL-Classifier/src_R/plot_panelperformance.R")
source("~/Desktop/DLBCL-Classifier/src_R/plot_panelperformance.R")
source("~/Desktop/DLBCL-Classifier/src_R/plot_panelperformance.R")
source("~/Desktop/DLBCL-Classifier/src_R/plot_panelperformance.R")
source("~/Desktop/DLBCL-Classifier/src_R/plot_panelperformance.R")
pwd()
getwd()
source("~/Desktop/DLBCL-Classifier/src_R/plot_s1_stats.R")
